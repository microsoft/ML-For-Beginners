# Classificadores de culin√°ria 2

Nesta segunda li√ß√£o de classifica√ß√£o, voc√™ explorar√° outras maneiras de classificar dados num√©ricos. Voc√™ tamb√©m aprender√° sobre as ramifica√ß√µes para escolher um classificador em vez de outro.

## [Question√°rio inicial](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/23?loc=ptbr)

### Pr√©-requisito

Presumimos que voc√™ tenha conclu√≠do as li√ß√µes anteriores e tenha um arquivo com o _dataset_ em sua pasta `data` chamado _cleaned_cuisines.csv_.

### Prepara√ß√£o

Carregando o arquivo _notebook.ipynb_ com o _dataset_ e o dividimos em dataframes X e y, estamos prontos para o processo de constru√ß√£o do modelo.

## Um mapa de classifica√ß√£o

Anteriormente, voc√™ aprendeu sobre as v√°rias op√ß√µes para classificar dados usando a planilha da Microsoft. O Scikit-learn oferece uma planilha semelhante, com mais informa√ß√µes, que pode ajudar ainda mais a restringir seus estimadores (outro termo para classificadores):

![Mapa da ML do Scikit-learn](../images/map.png)
> Dica: [visite este site](https://scikit-learn.org/stable/tutorial/machine_learning_map/) para ler a documenta√ß√£o.

### O plano

Este mapa √© muito √∫til, uma vez que voc√™ tenha uma compreens√£o clara de seus dados, pois voc√™ pode 'andar' no mapa ao longo dos caminhos para ent√£o, tomar uma decis√£o:

- Temos mais que 50 amostras
- Queremos prever uma categoria
- N√≥s rotulamos os dados
- Temos menos de 100 mil amostras
- ‚ú® Podemos escolher um SVC linear
- Se isso n√£o funcionar, j√° que temos dados num√©ricos:
     - Podemos tentar um classificador KNeighbors ‚ú®
       - Se n√£o funcionar, tente o ‚ú® SVC e ‚ú® Classificadores de conjunto (ensemble)

Esta √© uma trilha muito √∫til a seguir.

## Exerc√≠cio - dividindo os dados

Seguindo este caminho, devemos come√ßar importando algumas bibliotecas.

1. Importe essas bibliotecas:

    ```python
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    import numpy as np
    ```

1. Divida os dados em dados de treinamento e teste:

    ```python
    X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)
    ```

## Classificador linear SVC

O Clustering de Vetores de Suporte (SVC, ou no ingl√™s, Support-Vector clustering) √© um filho da fam√≠lia de m√°quinas de vetores de suporte de t√©cnicas de ML. Neste m√©todo, voc√™ pode escolher um 'kernel' para decidir como agrupar os r√≥tulos. O par√¢metro 'C' refere-se √† 'regulariza√ß√£o' que regula a influ√™ncia dos par√¢metros. O kernel pode ser um de [v√°rios](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC); aqui, n√≥s o definimos como 'linear' para garantir impulsionar o classificador. O padr√£o de probabilidade √© 'false'; aqui, n√≥s o definimos como 'true' para reunir estimativas de probabilidade. Definimos random_state como '0' para embaralhar os dados e obter probabilidades.

### Exerc√≠cio - aplicando um SVC linear

Comece criando um array de classificadores. Voc√™ adicionar√° itens progressivamente a este array enquanto testamos.

1. Comece com um SVC linear:

    ```python
    C = 10
    # Create different classifiers.
    classifiers = {
        'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0)
    }
    ```

2. Treine seu modelo usando o SVC e imprima um relat√≥rio:

    ```python
    n_classifiers = len(classifiers)
    
    for index, (name, classifier) in enumerate(classifiers.items()):
        classifier.fit(X_train, np.ravel(y_train))
    
        y_pred = classifier.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print("Accuracy (train) for %s: %0.1f%% " % (name, accuracy * 100))
        print(classification_report(y_test,y_pred))
    ```

    O resultado √© bom:

    ```output
    Accuracy (train) for Linear SVC: 78.6% 
                  precision    recall  f1-score   support
    
         chinese       0.71      0.67      0.69       242
          indian       0.88      0.86      0.87       234
        japanese       0.79      0.74      0.76       254
          korean       0.85      0.81      0.83       242
            thai       0.71      0.86      0.78       227
    
        accuracy                           0.79      1199
       macro avg       0.79      0.79      0.79      1199
    weighted avg       0.79      0.79      0.79      1199
    ```

## Classificador K-Neighbors

K-Neighbors faz parte da fam√≠lia "neighbors" de m√©todos de ML, que podem ser usados para aprendizado supervisionado e n√£o supervisionado. Neste m√©todo, um n√∫mero predefinido de pontos √© criado e os dados s√£o reunidos em torno desses pontos de modo que r√≥tulos generalizados podem ser previstos para os dados.

### Exerc√≠cio - aplicando o classificador K-Neighbors

O classificador anterior era bom e funcionou bem com os dados, mas talvez possamos obter uma melhor acur√°cia. Experimente um classificador K-Neighbors.

1. Adicione uma linha ao seu array de classificadores (adicione uma v√≠rgula ap√≥s o item do SVC):

    ```python
    'KNN classifier': KNeighborsClassifier(C),
    ```

    O resultado √© um pouco pior:

    ```output
    Accuracy (train) for KNN classifier: 73.8% 
                  precision    recall  f1-score   support
    
         chinese       0.64      0.67      0.66       242
          indian       0.86      0.78      0.82       234
        japanese       0.66      0.83      0.74       254
          korean       0.94      0.58      0.72       242
            thai       0.71      0.82      0.76       227
    
        accuracy                           0.74      1199
       macro avg       0.76      0.74      0.74      1199
    weighted avg       0.76      0.74      0.74      1199
    ```

    ‚úÖ Aprenda mais sobre [K-Neighbors](https://scikit-learn.org/stable/modules/neighbors.html#neighbors)

## Classificador de Vetores de Suporte

Os Classificadores de Vetores de Suporte (SVM, ou no ingl√™s, Support-Vector Machine) fazem parte da fam√≠lia [Classificadores de Vetores de Suporte](https://wikipedia.org/wiki/Support-vector_machine) de m√©todos de ML que s√£o usados para tarefas de classifica√ß√£o e regress√£o. Os SVMs "mapeiam exemplos de treinamento para pontos no espa√ßo" para maximizar a dist√¢ncia entre duas categorias. Os dados subsequentes s√£o mapeados neste espa√ßo para que sua categoria possa ser prevista.

###  Exerc√≠cio - aplicando o Classificador de Vetores de Suporte

Vamos tentar aumentar a acur√°cia com um Classificador de Vetores de Suporte.

1. Adicione uma v√≠rgula ap√≥s o item K-Neighbors e, em seguida, adicione esta linha:

    ```python
    'SVC': SVC(),
    ```

    O resultado √© muito bom!

    ```output
    Accuracy (train) for SVC: 83.2% 
                  precision    recall  f1-score   support
    
         chinese       0.79      0.74      0.76       242
          indian       0.88      0.90      0.89       234
        japanese       0.87      0.81      0.84       254
          korean       0.91      0.82      0.86       242
            thai       0.74      0.90      0.81       227
    
        accuracy                           0.83      1199
       macro avg       0.84      0.83      0.83      1199
    weighted avg       0.84      0.83      0.83      1199
    ```

    ‚úÖ Aprenda mais sobre [Vetores de Suporte](https://scikit-learn.org/stable/modules/svm.html#svm)

## Classificadores de conjunto (ensemble)

Vamos seguir o caminho at√© o fim, embora o teste anterior tenha sido muito bom. Vamos tentar alguns 'Classificadores de conjunto, especificamente Random Forest (√Årvores Aleat√≥rias) e AdaBoost:

```python
'RFST': RandomForestClassifier(n_estimators=100),
  'ADA': AdaBoostClassifier(n_estimators=100)
```

O resultado √© muito bom, especialmente para Random Forest:

```output
Accuracy (train) for RFST: 84.5% 
              precision    recall  f1-score   support

     chinese       0.80      0.77      0.78       242
      indian       0.89      0.92      0.90       234
    japanese       0.86      0.84      0.85       254
      korean       0.88      0.83      0.85       242
        thai       0.80      0.87      0.83       227

    accuracy                           0.84      1199
   macro avg       0.85      0.85      0.84      1199
weighted avg       0.85      0.84      0.84      1199

Accuracy (train) for ADA: 72.4% 
              precision    recall  f1-score   support

     chinese       0.64      0.49      0.56       242
      indian       0.91      0.83      0.87       234
    japanese       0.68      0.69      0.69       254
      korean       0.73      0.79      0.76       242
        thai       0.67      0.83      0.74       227

    accuracy                           0.72      1199
   macro avg       0.73      0.73      0.72      1199
weighted avg       0.73      0.72      0.72      1199
```

‚úÖ Aprenda mais sobre [Classificadores de conjunto](https://scikit-learn.org/stable/modules/ensemble.html)

Este m√©todo de arendizado de m√°quina "combina as previs√µes de v√°rios estimadores de base" para melhorar a qualidade do modelo. Em nosso exemplo, usamos Random Forest e AdaBoost.

- [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest), um m√©todo de m√©dia, constr√≥i uma 'floresta' de '√°rvores de decis√£o' infundidas com aleatoriedade para evitar _overfitting_. O par√¢metro `n_estimators` define a quantidade de √°rvores.

- [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) ajusta um classificador a um _dataset_ e, em seguida, ajusta c√≥pias desse classificador ao mesmo _dataset_. Ele se concentra nos pesos dos itens classificados incorretamente e corrige o ajuste para o pr√≥ximo classificador.

---

## üöÄDesafio

Cada uma dessas t√©cnicas possui um grande n√∫mero de par√¢metros. Pesquise os par√¢metros padr√£o de cada um e pense no que o ajuste desses par√¢metros significaria para a qualidade do modelo.

## [Question√°rio para fixa√ß√£o](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/24?loc=ptbr)

## Revis√£o e Auto Aprendizagem

H√° muitos termos nessas li√ß√µes, ent√£o reserve um minuto para revisar [esta lista √∫til](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) sobre terminologias!

## Tarefa

[Brincando com par√¢metros](assignment.pt-br.md).
