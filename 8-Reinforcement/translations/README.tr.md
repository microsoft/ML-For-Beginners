# PekiÅŸtirmeli Ã–ÄŸrenmeye GiriÅŸ

PekiÅŸtirmeli Ã¶ÄŸrenme (reinforcement learning), RL, denetimli Ã¶ÄŸrenme ve denetimsiz Ã¶ÄŸrenme gibi temel makine Ã¶ÄŸrenmesi paradigmalarÄ±ndan biri olarak gÃ¶rÃ¼lÃ¼yor. RL tamamen kararlar ile ilgilidir: doÄŸru kararlarÄ± verebilmek veya en azÄ±ndan onlardan Ã¶ÄŸrenmektir.

SimÃ¼le edilmiÅŸ bir ortamÄ±nÄ±z olduÄŸunu hayal edin, borsa gibi. Belirli bir dÃ¼zenlemeyi(regÃ¼lasyon) uygularsanÄ±z ne olur? Pozitif mi negatif mi etki eder? EÄŸer negatif etki ettiyse bunu _negative reinforcement_ olarak almalÄ±, bundan birÅŸeyler Ã¶ÄŸrenmeli ve rotanÄ±zÄ± buna gÃ¶re deÄŸiÅŸtirmelisiniz. EÄŸer pozitif bir sonuÃ§ elde ederseniz,  _positive reinforcement_ olarak bunun Ã¼zerine birÅŸeyler inÅŸa etmelisiniz.

![peter and the wolf](../images/peter.png)

> Peter ve arkadaÅŸÄ± aÃ§ kurttan kaÃ§malÄ±! Image by [Jen Looper](https://twitter.com/jenlooper)
## BÃ¶lgesel Konu: Peter ve Kurt (Rusya)

[Peter ve Kurt](https://en.wikipedia.org/wiki/Peter_and_the_Wolf), Rus bir besteci[Sergei Prokofiev](https://en.wikipedia.org/wiki/Sergei_Prokofiev)  tarafÄ±ndan yazÄ±lmÄ±ÅŸ bir mÃ¼zikal peri masalÄ±dÄ±r. Kurdu kovalamak iÃ§in evinden cesurca ormana giden genÃ§ Peter hakkÄ±nda bir hikaye. Bu bÃ¶lÃ¼mde Peter'a yardÄ±mcÄ± olacak makine Ã¶ÄŸrenmesi algoritmalarÄ± eÄŸiteceÄŸiz:

- Ã‡evredeki alanÄ± **keÅŸfedin** ve yol gÃ¶sterici harita oluÅŸturun.
- Daha hÄ±zlÄ± hareket etmek iÃ§in kaykay kullanmayÄ± ve Ã¼zerinde dengede durmayÄ± **Ã¶ÄŸrenin**.

[![Peter and the Wolf](https://img.youtube.com/vi/Fmi5zHg4QSM/0.jpg)](https://www.youtube.com/watch?v=Fmi5zHg4QSM)

> ğŸ¥ Prokofiev'in Peter ve Kurt ÅŸarkÄ±sÄ±nÄ± dinlemek iÃ§in yukarÄ±daki resme tÄ±klayÄ±n.
## PekiÅŸtirmeli Ã–ÄŸrenme

Bir Ã¶nceki bÃ¶lÃ¼mde, iki Ã§eÅŸit makine Ã¶ÄŸrenmesi problemi Ã¶rneÄŸini gÃ¶rdÃ¼nÃ¼z:

- **Denetimli**, Ã§Ã¶zmek istediÄŸimiz soruna Ã¶rnek Ã§Ã¶zÃ¼mler Ã¶neren veri kÃ¼melerimiz var. [SÄ±nÄ±flandÄ±rma(Classification)](../../4-Classification/README.md) ve [regresyon(regression)](../2-Regression/README.md) denetimli Ã¶ÄŸrenme gÃ¶revlerindendir.
- **Denetimsiz**, etiketli eÄŸitim verisine sahip deÄŸiliz. Denetimsiz Ã¶ÄŸrenmenin baÅŸlÄ±ca Ã¶rneÄŸi [kÃ¼melemedir(Clustering)](../../5-Clustering/README.md).

Bu bÃ¶lÃ¼mde, etiketlenmiÅŸ eÄŸitim verileri ihtiyaÃ§ duymayan yeni bir Ã¶ÄŸrenme problemi tÃ¼rÃ¼nÃ¼ size tanÄ±tacaÄŸÄ±z. Bu tÃ¼r problemlerin birkaÃ§ tÃ¼rÃ¼ vardÄ±r:

- **[YarÄ±-denetimli Ã¶ÄŸrenme](https://wikipedia.org/wiki/Semi-supervised_learning)**, modeli Ã¶nceden eÄŸitmek iÃ§in kullanÄ±labilecek Ã§ok sayÄ±da etiketlenmemiÅŸ veriye sahip olduÄŸumuz yer.
- **[PekiÅŸtirmeli Ã¶ÄŸrenme](https://wikipedia.org/wiki/Reinforcement_learning)**, bir ajanÄ±n(agent, Ã¶ÄŸrenme iÅŸini yapacak olan), simÃ¼le edilmiÅŸ bir ortamda denemeler yaparak nasÄ±l davranacaÄŸÄ±nÄ± Ã¶ÄŸrendiÄŸi.

### Ã–rnek - bilgisayar oyunu

Bir bilgisayara satranÃ§ gibi bir oyun oynamayÄ± Ã¶ÄŸretmek istediÄŸinizi varsayalÄ±m, veya [Super Mario](https://wikipedia.org/wiki/Super_Mario). 
Bir bilgisayarÄ±n bir oyunu oynamasÄ± iÃ§in, oyun durumlarÄ±nÄ±n her birinde hangi hamleyi yapacaÄŸÄ±nÄ± tahmin etmemiz gerekir. Bu bir sÄ±nÄ±flandÄ±rma problemi gibi gÃ¶rÃ¼nse de, deÄŸil - Ã§Ã¼nkÃ¼ bu durumlarÄ± ve karÅŸÄ±lÄ±k gelen aksiyonlarÄ± iÃ§eren bir veri kÃ¼memiz yok. Mevcut satranÃ§ maÃ§larÄ± veya Super Mario oynayan oyuncularÄ±n kayÄ±tlarÄ± gibi bazÄ± verilere sahip olabiliriz, bu verilerin yeterince bÃ¼yÃ¼k sayÄ±da olmamasÄ± veya olasÄ± durumlarÄ± yeterince kapsamamasÄ± muhtemeldir.

**PekiÅŸtirmeli Ã¶ÄŸrenme** (RL) mevcut oyun verilerini aramak yerine, *bilgisayarÄ±n defalarca oynamasÄ±nÄ± saÄŸlama* ve sonucu gÃ¶zlemleme fikrine dayanÄ±r. Bu nedenle **pekiÅŸtirmeli Ã¶ÄŸrenmeyi** uygulamak iÃ§in iki ÅŸeye ihtiyacÄ±mÄ±z var:

- **Bir ortam** ve **bir similatÃ¶r** birÃ§ok kez oyun oynamamÄ±za imkan verecektir. Bu simÃ¼latÃ¶r, olasÄ± tÃ¼m durumlar ve tÃ¼m eylemlerin yanÄ± sÄ±ra tÃ¼m oyun kurallarÄ±nÄ± tanÄ±mlayacaktÄ±r.

- **Bir Ã¶dÃ¼l fonksiyonu**, bu bize her harekette veya oyunda ne kadar iyi ilerlediÄŸimizi sÃ¶yleyecektir.

DiÄŸer makine Ã¶ÄŸrenimi tÃ¼rleri ile RL arasÄ±ndaki temel fark, RL'de oyunu bitirene kadar kazanÄ±p kazanmadÄ±ÄŸÄ±mÄ±zÄ± genellikle bilemememizdir. Bu nedenle, belirli bir hareketin tek baÅŸÄ±na iyi olup olmadÄ±ÄŸÄ±nÄ± sÃ¶yleyemeyiz - sadece oyunun sonunda bir Ã¶dÃ¼l alÄ±rÄ±z. Ve hedefimiz ise belirsiz koÅŸullar altÄ±nda bir modeli eÄŸitmemizi saÄŸlayacak algoritmalar tasarlamak. **Q-learning** adÄ±nda ki bir RL algoritmasÄ±nÄ± Ã¶ÄŸreneceÄŸiz.

## Dersler

1. [Introduction to reinforcement learning and Q-Learning](../1-QLearning/README.md)
2. [Using a gym simulation environment](../2-Gym/README.md)

## KatkÄ±da bulunanlar

  "PekiÅŸtirmeli Ã–ÄŸrenmeye GiriÅŸ" â™¥ï¸ [Dmitry Soshnikov](http://soshnikov.com) tarafÄ±ndan yazÄ±ldÄ±.
