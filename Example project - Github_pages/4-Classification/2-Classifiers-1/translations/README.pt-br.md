# Classificadores de culin√°ria 1

Nesta li√ß√£o, voc√™ usar√° o _dataset_ balanceado e tratado que salvou da √∫ltima li√ß√£o cheio de dados sobre cozinhas diferentes.

Voc√™ usar√° este _dataset_ com uma variedade de classificadores para _prever uma determinada culin√°ria nacional com base em um grupo de ingredientes_. Enquanto isso, voc√™ aprender√° mais sobre algumas das maneiras como os algoritmos podem ser aproveitados para tarefas de classifica√ß√£o.

## [Question√°rio inicial](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/21?loc=ptbr)

# Prepara√ß√£o

Assumindo que voc√™ completou [li√ß√£o 1](../../1-Introduction/translations/README.pt-br.md), certifique-se de que existe o arquivo _cleaned_cuisines.csv_ na pasta `/data`, pois ser√° usado para todas as li√ß√µes de classifica√ß√£o.

## Exerc√≠cio - prevendo uma culin√°ria nacional

1. Usando o _notebook.ipynb_ que est√° na pasta desta li√ß√£o, importe a biblioteca Pandas:

    ```python
    import pandas as pd
    cuisines_df = pd.read_csv("../../data/cleaned_cuisines.csv")
    cuisines_df.head()
    ```

    Os dados estar√£o mais ou menos assim:

|     | Unnamed: 0 | cuisine | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood | yam | yeast | yogurt | zucchini |
| --- | ---------- | ------- | ------ | -------- | ----- | ---------- | ----- | ------------ | ------- | -------- | --- | ------- | ----------- | ---------- | ----------------------- | ---- | ---- | --- | ----- | ------ | -------- |
| 0   | 0          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 1   | 1          | indian  | 1      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 2   | 2          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 3   | 3          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 4   | 4          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 1      | 0        |
  

1. Agora importe algumas bibliotecas:

    ```python
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    from sklearn.svm import SVC
    import numpy as np
    ```

1. Divida as coordenadas X e y em dois _dataframes_ para treinamento. `cuisine` pode ser o r√≥tulo do _dataframe_:

    ```python
    cuisines_label_df = cuisines_df['cuisine']
    cuisines_label_df.head()
    ```

    O resultado ser√° mais ou menos assim:

    ```output
    0    indian
    1    indian
    2    indian
    3    indian
    4    indian
    Name: cuisine, dtype: object
    ```

1. Remova as colunas `Unnamed: 0` e `cuisine`, chamando o m√©todo `drop()`. Salve o restante dos dados como caracter√≠sticas trein√°veis:

    ```python
    cuisines_feature_df = cuisines_df.drop(['Unnamed: 0', 'cuisine'], axis=1)
    cuisines_feature_df.head()
    ```

    As caracter√≠sticas ser√£o mais ou menos assim:

|      | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | artemisia | artichoke |  ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood |  yam | yeast | yogurt | zucchini |
| ---: | -----: | -------: | ----: | ---------: | ----: | -----------: | ------: | -------: | --------: | --------: | ---: | ------: | ----------: | ---------: | ----------------------: | ---: | ---: | ---: | ----: | -----: | -------: |
|    0 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    1 |      1 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    2 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    3 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    4 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      1 |        0 | 0 |

J√° podemos treinar nosso modelo!

## Escolhendo um classificador

Agora que seus dados est√£o tratados e prontos para treinamento, voc√™ deve decidir qual algoritmo usar para o trabalho.

O Scikit-learn agrupa classifica√ß√£o em apredizagem supervisionada e, nessa categoria, voc√™ encontrar√° muitas maneiras de classificar. [A variedade](https://scikit-learn.org/stable/supervised_learning.html) √© bastante desconcertante √† primeira vista. Todos os m√©todos a seguir incluem t√©cnicas de classifica√ß√£o:

- Modelos Lineares
- M√°quinas de vetor de suporte (SVM)
- Descida do gradiente estoc√°stico (SGD)
- Vizinhos mais pr√≥ximos
- Processos Gaussianos
- √Årvores de decis√£o
- M√©todos de conjunto (classificador de vota√ß√£o, _ensemble_)
- Algoritmos de multiclasse e sa√≠da m√∫ltipla (classifica√ß√£o multiclasse e multilabel, classifica√ß√£o multiclasse-sa√≠da m√∫ltipla)

> Voc√™ tamb√©m pode usar [redes neurais para classificar dados](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#classification), mas isso est√° fora do escopo desta li√ß√£o.

### Qual classificador escolher?

Ent√£o, qual classificador voc√™ deve escolher? Freq√ºentemente, percorrer v√°rios e procurar um bom resultado √© uma forma de testar. Scikit-learn oferece uma [compara√ß√£o lado a lado](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) em um _dataset_ criado, comparando com KNeighbors, SVC de duas maneiras, GaussianProcessClassifier, DecisionTreeClassifier, RandomForestClassifier, MLPClassifier, AdaBoostClassifier, GaussianNB e QuadraticDiscrinationAnalysis, mostrando os resultados visualizados:

![compara√ß√£o de classificadores](../images/comparison.png)
> Plots gerados na documenta√ß√£o do Scikit-learn

> O AutoML resolve esse problema perfeitamente executando essas compara√ß√µes na nuvem, permitindo que voc√™ escolha o melhor algoritmo para seus dados. Teste-o [aqui](https://docs.microsoft.com/learn/modules/automate-model-selection-with-azure-automl/?WT.mc_id=academic-77952-leestott).

### Uma abordagem melhor

Melhor do que adivinhar, √© seguir as ideias nesta [planilha com dicas de ML](https://docs.microsoft.com/azure/machine-learning/algorithm-cheat-sheet?WT.mc_id=academic-77952-leestott). Aqui, descobrimos que para o nosso problema multiclasse, temos algumas op√ß√µes:

![planilha com dicas para problemas multiclasse](../images/cheatsheet.png)
> Uma planilha com dicas de algoritmo da Microsoft, detalhando as op√ß√µes de classifica√ß√£o multiclasse.

‚úÖ Baixe esta planilha, imprima e pendure na parede!

### Raciocinando

Vamos ver se podemos raciocinar atrav√©s de diferentes abordagens, dadas as restri√ß√µes que temos:

- **Redes neurais s√£o muito pesadas**. Dado que nosso _dataset_ est√° tratado mas √© pequeno, e o fato de estarmos executando o treinamento localmente por meio de _notebooks_, redes neurais s√£o muito pesadas para essa tarefa.
- **Nenhum classificador de duas classes**. N√£o usamos um classificador de duas classes, isso exclui o esquema um versus todos (one-vs-all).
- **√Årvore de decis√£o ou regress√£o log√≠stica podem funcionar**. √Årvore de decis√£o pode funcionar, ou regress√£o log√≠stica para dados multiclasse.
- **√Årvores de decis√£o impulsionadas √† multiclasse resolvem um problema diferente**. √Årvore de decis√£o impulsionada √† multiclasse √© mais adequada para tarefas n√£o param√©tricas, por exemplo, tarefas destinadas a construir _rankings_, por isso n√£o s√£o √∫teis para n√≥s.

### Usando Scikit-learn 

Usaremos o Scikit-learn para analisar nossos dados. No entanto, existem muitas maneiras de usar a regress√£o log√≠stica no Scikit-learn. D√™ uma olhada nos [poss√≠veis par√¢metros](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regressio#sklearn.linear_model.LogisticRegression). 

Essencialmente, existem dois par√¢metros importantes - `multi_class` e `solver` -, que precisamos especificar quando pedimos ao Scikit-learn para realizar uma regress√£o log√≠stica. O valor de `multi_class` aplica um certo comportamento. O valor de `solver` √© o algoritmo a ser usado. Nem todos os valores de `solver` podem ser combinados com os valores de `multi_class`.

De acordo com a documenta√ß√£o, no caso de multiclasse, o algoritmo de treinamento:

- **Usa o esquema one-vs-rest (OvR, ou "um contra o resto")**, se a op√ß√£o `multi_class` estiver definida como `ovr`.
- **Usa a perda de entropia cruzada**, se a op√ß√£o `multi_class` estiver definida como `multinomial` (atualmente, a op√ß√£o `multinomial` √© compat√≠vel apenas com os "_solvers_" (ou solucionadores): `lbfgs`, `sag`, `saga` e `newton-cg`).

> üéì O 'esquema' aqui pode ser 'ovr' ou 'multinomial'. Uma vez que a regress√£o log√≠stica √© realmente projetada para oferecer suporte √† classifica√ß√£o bin√°ria, esses esquemas permitem um melhor tratamento das tarefas de classifica√ß√£o multiclasse. [Fonte](https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/).

> üéì O 'solucionador' √© definido como "o algoritmo a ser usado no problema de otimiza√ß√£o". [Fonte](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regressio#sklearn.linear_model.LogisticRegression).

O Scikit-learn oferece esta tabela para explicar como os solucionadores lidam com diferentes desafios apresentados por diferentes tipos de estruturas de dados:

![Solucionadores](../images/solvers.png)

## Exerc√≠cio - dividindo os dados

Podemos nos concentrar na regress√£o log√≠stica para nosso primeiro teste de treinamento, uma vez que voc√™ aprendeu recentemente sobre o √∫ltimo em uma li√ß√£o anterior.
Divida seus dados em grupos de treinamento e teste chamando o m√©todo `train_test_split()`:

```python
X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)
```

## Exerc√≠cio - aplicando regress√£o log√≠stica

J√° que estamos usando um caso multiclasse, voc√™ precisa escolher qual _scheme_ usar e qual _solver_ definir. Use LogisticRegression com uma configura√ß√£o multiclasse e o solucionador **liblinear** para treinar.

1. Crie uma regress√£o log√≠stica com multi_class definido como `ovr` e solver definido como `liblinear`:

    ```python
    lr = LogisticRegression(multi_class='ovr',solver='liblinear')
    model = lr.fit(X_train, np.ravel(y_train))
    
    accuracy = model.score(X_test, y_test)
    print ("Accuracy is {}".format(accuracy))
    ```

    ‚úÖ Teste diferentes _solvers_ como o `lbfgs`, que j√° √© definido como padr√£o.

    > Use a fun√ß√£o Pandas chamada [`ravel`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.ravel.html) para nivelar seus dados quando necess√°rio.

    A acur√°cia est√° boa quando √© maior que **80%**!

1. Voc√™ pode ver este modelo em a√ß√£o testando dessa forma (linha #50):

    ```python
    print(f'ingredients: {X_test.iloc[50][X_test.iloc[50]!=0].keys()}')
    print(f'cuisine: {y_test.iloc[50]}')
    ```

    O resultado ser√°:

   ```output
   ingredients: Index(['cilantro', 'onion', 'pea', 'potato', 'tomato', 'vegetable_oil'], dtype='object')
   cuisine: indian
   ```

   ‚úÖ Tente um n√∫mero de linha diferente e verifique os resultados.

1. Indo mais fundo, voc√™ pode verificar a precis√£o desta previs√£o:

    ```python
    test= X_test.iloc[50].values.reshape(-1, 1).T
    proba = model.predict_proba(test)
    classes = model.classes_
    resultdf = pd.DataFrame(data=proba, columns=classes)
    
    topPrediction = resultdf.T.sort_values(by=[0], ascending = [False])
    topPrediction.head()
    ```

    A culin√°ria indiana √© seu melhor palpite, com boa probabilidade:

    |          |        0 |
    | -------: | -------: |
    |   indian | 0.715851 |
    |  chinese | 0.229475 |
    | japanese | 0.029763 |
    |   korean | 0.017277 |
    |     thai | 0.007634 |

    ‚úÖ Voc√™ pode explicar por que a modelo tem certeza de que se trata de uma culin√°ria indiana?

1. Obtenha mais detalhes imprimindo um relat√≥rio de classifica√ß√£o, como voc√™ fez nas aulas de regress√£o:

    ```python
    y_pred = model.predict(X_test)
    print(classification_report(y_test,y_pred))
    ```

    |              | precision | recall | f1-score | support |
    | ------------ | --------- | ------ | -------- | ------- |
    | chinese      | 0.73      | 0.71   | 0.72     | 229     |
    | indian       | 0.91      | 0.93   | 0.92     | 254     |
    | japanese     | 0.70      | 0.75   | 0.72     | 220     |
    | korean       | 0.86      | 0.76   | 0.81     | 242     |
    | thai         | 0.79      | 0.85   | 0.82     | 254     |
    | accuracy     | 0.80      | 1199   |          |         |
    | macro avg    | 0.80      | 0.80   | 0.80     | 1199    |
    | weighted avg | 0.80      | 0.80   | 0.80     | 1199    |

## üöÄDesafio

Nesta li√ß√£o, voc√™ usou seus dados para construir um modelo de aprendizado de m√°quina que pode prever uma culin√°ria nacional com base em uma s√©rie de ingredientes. Reserve algum tempo para ler as op√ß√µes que o Scikit-learn oferece para classificar dados. Aprofunde-se no conceito de 'solucionador' para entender o que acontece nos bastidores.

## [Question√°rio para fixa√ß√£o](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/22?loc=ptbr)

## Revis√£o e Auto Aprendizagem

Aprofunde-se um pouco mais na matem√°tica por tr√°s da regress√£o log√≠stica [nesta li√ß√£o](https://people.eecs.berkeley.edu/~russell/classes/cs194/f11/lectures/CS194%20Fall%202011%20Lecture%2006.pdf).

## Tarefa

[Estudando solucionadores](assignment.pt-br.md).
