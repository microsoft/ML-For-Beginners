# K-Means èšç±»

[![Andrew Ng explains Clustering](https://img.youtube.com/vi/hDmNF9JG3lo/0.jpg)](https://youtu.be/hDmNF9JG3lo "Andrew Ng explains Clustering")

> ğŸ¥ å•å‡»ä¸Šå›¾è§‚çœ‹è§†é¢‘ï¼šAndrew Ng è§£é‡Šèšç±»

## [è¯¾å‰æµ‹éªŒ](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/29/)

åœ¨æœ¬è¯¾ä¸­ï¼Œæ‚¨å°†å­¦ä¹ å¦‚ä½•ä½¿ç”¨ Scikit-learn å’Œæ‚¨ä¹‹å‰å¯¼å…¥çš„å°¼æ—¥åˆ©äºšéŸ³ä¹æ•°æ®é›†åˆ›å»ºèšç±»ã€‚æˆ‘ä»¬å°†ä»‹ç» K-Means èšç±» çš„åŸºç¡€çŸ¥è¯†ã€‚è¯·è®°ä½ï¼Œæ­£å¦‚æ‚¨åœ¨ä¸Šä¸€è¯¾ä¸­å­¦åˆ°çš„ï¼Œä½¿ç”¨èšç±»çš„æ–¹æ³•æœ‰å¾ˆå¤šç§ï¼Œæ‚¨ä½¿ç”¨çš„æ–¹æ³•å–å†³äºæ‚¨çš„æ•°æ®ã€‚æˆ‘ä»¬å°†å°è¯• K-Meansï¼Œå› ä¸ºå®ƒæ˜¯æœ€å¸¸è§çš„èšç±»æŠ€æœ¯ã€‚è®©æˆ‘ä»¬å¼€å§‹å§ï¼

æ‚¨å°†äº†è§£çš„æœ¯è¯­ï¼š

- è½®å»“æ‰“åˆ†
- æ‰‹è‚˜æ–¹æ³•
- æƒ¯æ€§
- æ–¹å·®

## ä»‹ç»

[K-Means Clustering](https://wikipedia.org/wiki/K-means_clustering) æ˜¯ä¸€ç§æºè‡ªä¿¡å·å¤„ç†é¢†åŸŸçš„æ–¹æ³•ã€‚å®ƒç”¨äºä½¿ç”¨ä¸€ç³»åˆ—è§‚å¯Ÿå°†æ•°æ®ç»„åˆ’åˆ†å’Œåˆ’åˆ†ä¸ºâ€œkâ€ä¸ªèšç±»ã€‚æ¯ä¸ªè§‚å¯Ÿéƒ½ç”¨äºå¯¹æœ€æ¥è¿‘å…¶æœ€è¿‘â€œå¹³å‡å€¼â€æˆ–èšç±»ä¸­å¿ƒç‚¹çš„ç»™å®šæ•°æ®ç‚¹è¿›è¡Œåˆ†ç»„ã€‚

èšç±»å¯ä»¥å¯è§†åŒ–ä¸º [Voronoi å›¾](https://wikipedia.org/wiki/Voronoi_diagram)ï¼Œå…¶ä¸­åŒ…æ‹¬ä¸€ä¸ªç‚¹ï¼ˆæˆ–â€œç§å­â€ï¼‰åŠå…¶ç›¸åº”çš„åŒºåŸŸã€‚

![voronoi diagram](../images/voronoi.png)

> [Jen Looper](https://twitter.com/jenlooper)ä½œå›¾

K-Means èšç±»è¿‡ç¨‹[åˆ†ä¸‰æ­¥æ‰§è¡Œ](https://scikit-learn.org/stable/modules/clustering.html#k-means)ï¼š

1. è¯¥ç®—æ³•é€šè¿‡ä»æ•°æ®é›†ä¸­é‡‡æ ·æ¥é€‰æ‹© k ä¸ªä¸­å¿ƒç‚¹ã€‚åœ¨æ­¤ä¹‹åï¼Œå®ƒå¾ªç¯ï¼š
   1. å®ƒå°†æ¯ä¸ªæ ·æœ¬åˆ†é…åˆ°æœ€è¿‘çš„è´¨å¿ƒã€‚
   2. å®ƒé€šè¿‡å–åˆ†é…ç»™å…ˆå‰è´¨å¿ƒçš„æ‰€æœ‰æ ·æœ¬çš„å¹³å‡å€¼æ¥åˆ›å»ºæ–°è´¨å¿ƒã€‚
   3. ç„¶åï¼Œå®ƒè®¡ç®—æ–°æ—§è´¨å¿ƒä¹‹é—´çš„å·®å¼‚å¹¶é‡å¤ç›´åˆ°è´¨å¿ƒç¨³å®šã€‚

ä½¿ç”¨ K-Means çš„ä¸€ä¸ªç¼ºç‚¹åŒ…æ‹¬æ‚¨éœ€è¦å»ºç«‹â€œkâ€ï¼Œå³è´¨å¿ƒçš„æ•°é‡ã€‚å¹¸è¿çš„æ˜¯ï¼Œâ€œè‚˜éƒ¨æ³•åˆ™â€æœ‰åŠ©äºä¼°è®¡â€œkâ€çš„è‰¯å¥½èµ·å§‹å€¼ã€‚è¯•ä¸€ä¸‹å§ã€‚

## å‰ç½®æ¡ä»¶

æ‚¨å°†ä½¿ç”¨æœ¬è¯¾çš„ *notebook.ipynb* æ–‡ä»¶ï¼Œå…¶ä¸­åŒ…å«æ‚¨åœ¨ä¸Šä¸€è¯¾ä¸­æ‰€åšçš„æ•°æ®å¯¼å…¥å’Œåˆæ­¥æ¸…ç†ã€‚

## ç»ƒä¹  - å‡†å¤‡

é¦–å…ˆå†çœ‹çœ‹æ­Œæ›²æ•°æ®ã€‚

1. åˆ›å»ºä¸€ä¸ªç®±çº¿å›¾ï¼Œ`boxplot()` ä¸ºæ¯ä¸€åˆ—è°ƒç”¨ï¼š

    ```python
    plt.figure(figsize=(20,20), dpi=200)
    
    plt.subplot(4,3,1)
    sns.boxplot(x = 'popularity', data = df)
    
    plt.subplot(4,3,2)
    sns.boxplot(x = 'acousticness', data = df)
    
    plt.subplot(4,3,3)
    sns.boxplot(x = 'energy', data = df)
    
    plt.subplot(4,3,4)
    sns.boxplot(x = 'instrumentalness', data = df)
    
    plt.subplot(4,3,5)
    sns.boxplot(x = 'liveness', data = df)
    
    plt.subplot(4,3,6)
    sns.boxplot(x = 'loudness', data = df)
    
    plt.subplot(4,3,7)
    sns.boxplot(x = 'speechiness', data = df)
    
    plt.subplot(4,3,8)
    sns.boxplot(x = 'tempo', data = df)
    
    plt.subplot(4,3,9)
    sns.boxplot(x = 'time_signature', data = df)
    
    plt.subplot(4,3,10)
    sns.boxplot(x = 'danceability', data = df)
    
    plt.subplot(4,3,11)
    sns.boxplot(x = 'length', data = df)
    
    plt.subplot(4,3,12)
    sns.boxplot(x = 'release_date', data = df)
    ```

    è¿™ä¸ªæ•°æ®æœ‰ç‚¹å˜ˆæ‚ï¼šé€šè¿‡è§‚å¯Ÿæ¯ä¸€åˆ—ä½œä¸ºç®±çº¿å›¾ï¼Œä½ å¯ä»¥çœ‹åˆ°å¼‚å¸¸å€¼ã€‚

    ![outliers](../images/boxplots.png)

æ‚¨å¯ä»¥æµè§ˆæ•°æ®é›†å¹¶åˆ é™¤è¿™äº›å¼‚å¸¸å€¼ï¼Œä½†è¿™ä¼šä½¿æ•°æ®éå¸¸å°‘ã€‚

1. ç°åœ¨ï¼Œé€‰æ‹©æ‚¨å°†ç”¨äºèšç±»ç»ƒä¹ çš„åˆ—ã€‚é€‰æ‹©å…·æœ‰ç›¸ä¼¼èŒƒå›´çš„é‚£äº›å¹¶å°† `artist_top_genre` åˆ—ç¼–ç ä¸ºæ•°å­—ç±»å‹çš„æ•°æ®ï¼š

    ```python
    from sklearn.preprocessing import LabelEncoder
    le = LabelEncoder()
    
    X = df.loc[:, ('artist_top_genre','popularity','danceability','acousticness','loudness','energy')]
    
    y = df['artist_top_genre']
    
    X['artist_top_genre'] = le.fit_transform(X['artist_top_genre'])
    
    y = le.transform(y)
    ```

1. ç°åœ¨æ‚¨éœ€è¦é€‰æ‹©è¦å®šä½çš„èšç±»æ•°é‡ã€‚æ‚¨çŸ¥é“æˆ‘ä»¬ä»æ•°æ®é›†ä¸­æŒ–æ˜å‡º 3 ç§æ­Œæ›²æµæ´¾ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬å°è¯• 3 ç§ï¼š

    ```python
    from sklearn.cluster import KMeans
    
    nclusters = 3 
    seed = 0
    
    km = KMeans(n_clusters=nclusters, random_state=seed)
    km.fit(X)
    
    # Predict the cluster for each data point
    
    y_cluster_kmeans = km.predict(X)
    y_cluster_kmeans
    ```

æ‚¨ä¼šçœ‹åˆ°æ‰“å°å‡ºçš„æ•°ç»„ï¼Œå…¶ä¸­åŒ…å«æ•°æ®å¸§æ¯ä¸€è¡Œçš„é¢„æµ‹èšç±»ï¼ˆ0ã€1 æˆ– 2ï¼‰ã€‚

1. ä½¿ç”¨æ­¤æ•°ç»„è®¡ç®—â€œè½®å»“åˆ†æ•°â€ï¼š

    ```python
    from sklearn import metrics
    score = metrics.silhouette_score(X, y_cluster_kmeans)
    score
    ```

## è½®å»“åˆ†æ•°

å¯»æ‰¾æ¥è¿‘ 1 çš„è½®å»“åˆ†æ•°ã€‚è¯¥åˆ†æ•°ä» -1 åˆ° 1 ä¸ç­‰ï¼Œå¦‚æœåˆ†æ•°ä¸º 1ï¼Œåˆ™è¯¥èšç±»å¯†é›†ä¸”ä¸å…¶ä»–èšç±»åˆ†ç¦»è‰¯å¥½ã€‚æ¥è¿‘ 0 çš„å€¼è¡¨ç¤ºé‡å èšç±»ï¼Œæ ·æœ¬éå¸¸æ¥è¿‘ç›¸é‚»èšç±»çš„å†³ç­–è¾¹ç•Œã€‚[æ¥æº](https://dzone.com/articles/kmeans-silhouette-score-explained-with-python-exam)ã€‚

æˆ‘ä»¬çš„åˆ†æ•°æ˜¯ **0.53**ï¼Œæ‰€ä»¥æ­£å¥½åœ¨ä¸­é—´ã€‚è¿™è¡¨æ˜æˆ‘ä»¬çš„æ•°æ®ä¸æ˜¯ç‰¹åˆ«é€‚åˆè¿™ç§ç±»å‹çš„èšç±»ï¼Œä½†è®©æˆ‘ä»¬ç»§ç»­ã€‚

### ç»ƒä¹  - å»ºç«‹æ¨¡å‹

1. å¯¼å…¥ `KMeans` å¹¶å¯åŠ¨èšç±»è¿‡ç¨‹ã€‚

    ```python
    from sklearn.cluster import KMeans
    wcss = []
    
    for i in range(1, 11):
        kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)
        kmeans.fit(X)
        wcss.append(kmeans.inertia_)
    
    ```

    è¿™é‡Œæœ‰å‡ ä¸ªéƒ¨åˆ†éœ€è¦è§£é‡Šã€‚

    > ğŸ“ rangeï¼šè¿™äº›æ˜¯èšç±»è¿‡ç¨‹çš„è¿­ä»£

    > ğŸ“ random_stateï¼šâ€œç¡®å®šè´¨å¿ƒåˆå§‹åŒ–çš„éšæœºæ•°ç”Ÿæˆã€‚â€ [æ¥æº](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)

    > ğŸ“ WCSSï¼šâ€œèšç±»å†…å¹³æ–¹å’Œâ€æµ‹é‡èšç±»å†…æ‰€æœ‰ç‚¹åˆ°èšç±»è´¨å¿ƒçš„å¹³æ–¹å¹³å‡è·ç¦»ã€‚[æ¥æº](https://medium.com/@ODSC/unsupervised-learning-evaluating-clusters-bd47eed175ce)ã€‚

    > ğŸ“ Inertiaï¼šK-Means ç®—æ³•å°è¯•é€‰æ‹©è´¨å¿ƒä»¥æœ€å°åŒ–â€œæƒ¯æ€§â€ï¼Œâ€œæƒ¯æ€§æ˜¯è¡¡é‡å†…éƒ¨ç›¸å¹²ç¨‹åº¦çš„ä¸€ç§æ–¹æ³•â€ã€‚[æ¥æº](https://scikit-learn.org/stable/modules/clustering.html)ã€‚è¯¥å€¼åœ¨æ¯æ¬¡è¿­ä»£æ—¶é™„åŠ åˆ° wcss å˜é‡ã€‚

    > ğŸ“ k-means++ï¼šåœ¨ [Scikit-learn ä¸­ï¼Œ](https://scikit-learn.org/stable/modules/clustering.html#k-means)æ‚¨å¯ä»¥ä½¿ç”¨â€œk-means++â€ä¼˜åŒ–ï¼Œå®ƒâ€œå°†è´¨å¿ƒåˆå§‹åŒ–ä¸ºï¼ˆé€šå¸¸ï¼‰å½¼æ­¤è¿œç¦»ï¼Œå¯¼è‡´å¯èƒ½æ¯”éšæœºåˆå§‹åŒ–æ›´å¥½çš„ç»“æœã€‚

### æ‰‹è‚˜æ–¹æ³•

ä¹‹å‰ï¼Œæ‚¨æ¨æµ‹ï¼Œå› ä¸ºæ‚¨å·²ç»å®šä½äº† 3 ä¸ªæ­Œæ›² genreï¼Œæ‰€ä»¥æ‚¨åº”è¯¥é€‰æ‹© 3 ä¸ªèšç±»ã€‚ä½†çœŸçš„æ˜¯è¿™æ ·å—ï¼Ÿ

1. ä½¿ç”¨æ‰‹è‚˜æ–¹æ³•æ¥ç¡®è®¤ã€‚

    ```python
    plt.figure(figsize=(10,5))
    sns.lineplot(range(1, 11), wcss,marker='o',color='red')
    plt.title('Elbow')
    plt.xlabel('Number of clusters')
    plt.ylabel('WCSS')
    plt.show()
    ```

    ä½¿ç”¨ `wcss` æ‚¨åœ¨ä¸Šä¸€æ­¥ä¸­æ„å»ºçš„å˜é‡åˆ›å»ºä¸€ä¸ªå›¾è¡¨ï¼Œæ˜¾ç¤ºè‚˜éƒ¨â€œå¼¯æ›²â€çš„ä½ç½®ï¼Œè¿™è¡¨ç¤ºæœ€ä½³èšç±»æ•°ã€‚ä¹Ÿè®¸**æ˜¯** 3ï¼

    ![elbow method](../images/elbow.png)

## ç»ƒä¹  - æ˜¾ç¤ºèšç±»

1. å†æ¬¡å°è¯•è¯¥è¿‡ç¨‹ï¼Œè¿™æ¬¡è®¾ç½®ä¸‰ä¸ªèšç±»ï¼Œå¹¶å°†èšç±»æ˜¾ç¤ºä¸ºæ•£ç‚¹å›¾ï¼š

    ```python
    from sklearn.cluster import KMeans
    kmeans = KMeans(n_clusters = 3)
    kmeans.fit(X)
    labels = kmeans.predict(X)
    plt.scatter(df['popularity'],df['danceability'],c = labels)
    plt.xlabel('popularity')
    plt.ylabel('danceability')
    plt.show()
    ```

1. æ£€æŸ¥æ¨¡å‹çš„å‡†ç¡®æ€§ï¼š

    ```python
    labels = kmeans.labels_
    
    correct_labels = sum(y == labels)
    
    print("Result: %d out of %d samples were correctly labeled." % (correct_labels, y.size))
    
    print('Accuracy score: {0:0.2f}'. format(correct_labels/float(y.size)))
    ```

    è¿™ä¸ªæ¨¡å‹çš„å‡†ç¡®æ€§ä¸æ˜¯å¾ˆå¥½ï¼Œèšç±»çš„å½¢çŠ¶ç»™äº†ä½ ä¸€ä¸ªæç¤ºã€‚

    ![clusters](../images/clusters.png)

    è¿™äº›æ•°æ®å¤ªä¸å¹³è¡¡ï¼Œç›¸å…³æ€§å¤ªä½ï¼Œåˆ—å€¼ä¹‹é—´çš„å·®å¼‚å¤ªå¤§ï¼Œæ— æ³•å¾ˆå¥½åœ°èšç±»ã€‚äº‹å®ä¸Šï¼Œå½¢æˆçš„èšç±»å¯èƒ½å—åˆ°æˆ‘ä»¬ä¸Šé¢å®šä¹‰çš„ä¸‰ä¸ªç±»å‹ç±»åˆ«çš„ä¸¥é‡å½±å“æˆ–æ‰­æ›²ã€‚é‚£æ˜¯ä¸€ä¸ªå­¦ä¹ çš„è¿‡ç¨‹ï¼

    åœ¨ Scikit-learn çš„æ–‡æ¡£ä¸­ï¼Œä½ å¯ä»¥çœ‹åˆ°åƒè¿™æ ·çš„æ¨¡å‹ï¼Œèšç±»åˆ’åˆ†ä¸æ˜¯å¾ˆå¥½ï¼Œæœ‰ä¸€ä¸ªâ€œæ–¹å·®â€é—®é¢˜ï¼š

    ![problem models](../images/problems.png)
    
    > å›¾æ¥è‡ª Scikit-learn

## æ–¹å·®

> æ–¹å·®è¢«å®šä¹‰ä¸ºâ€œæ¥è‡ªå‡å€¼çš„å¹³æ–¹å·®çš„å¹³å‡å€¼â€[æº](https://www.mathsisfun.com/data/standard-deviation.html)ã€‚åœ¨è¿™ä¸ªèšç±»é—®é¢˜çš„ä¸Šä¸‹æ–‡ä¸­ï¼Œå®ƒæŒ‡çš„æ˜¯æˆ‘ä»¬æ•°æ®é›†çš„æ•°é‡å¾€å¾€ä¸å¹³å‡å€¼ç›¸å·®å¤ªå¤šçš„æ•°æ®ã€‚
>
> âœ…è¿™æ˜¯è€ƒè™‘å¯ä»¥çº æ­£æ­¤é—®é¢˜çš„æ‰€æœ‰æ–¹æ³•çš„å¥½æ—¶æœºã€‚ç¨å¾®è°ƒæ•´ä¸€ä¸‹æ•°æ®ï¼Ÿä½¿ç”¨ä¸åŒçš„åˆ—ï¼Ÿä½¿ç”¨ä¸åŒçš„ç®—æ³•ï¼Ÿæç¤ºï¼šå°è¯•[ç¼©æ”¾æ•°æ®](https://www.mygreatlearning.com/blog/learning-data-science-with-k-means-clustering/)ä»¥å¯¹å…¶è¿›è¡Œæ ‡å‡†åŒ–å¹¶æµ‹è¯•å…¶ä»–åˆ—ã€‚
>
> > è¯•è¯•è¿™ä¸ªâ€œ[æ–¹å·®è®¡ç®—å™¨](https://www.calculatorsoup.com/calculators/statistics/variance-calculator.php)â€æ¥æ›´å¤šåœ°ç†è§£è¿™ä¸ªæ¦‚å¿µã€‚

---

## ğŸš€æŒ‘æˆ˜

èŠ±ä¸€äº›æ—¶é—´åœ¨è¿™ä¸ªç¬”è®°æœ¬ä¸Šï¼Œè°ƒæ•´å‚æ•°ã€‚æ‚¨èƒ½å¦é€šè¿‡æ›´å¤šåœ°æ¸…ç†æ•°æ®ï¼ˆä¾‹å¦‚ï¼Œå»é™¤å¼‚å¸¸å€¼ï¼‰æ¥æé«˜æ¨¡å‹çš„å‡†ç¡®æ€§ï¼Ÿæ‚¨å¯ä»¥ä½¿ç”¨æƒé‡ä¸ºç»™å®šçš„æ•°æ®æ ·æœ¬èµ‹äºˆæ›´å¤šæƒé‡ã€‚ä½ è¿˜èƒ½åšäº›ä»€ä¹ˆæ¥åˆ›å»ºæ›´å¥½çš„èšç±»ï¼Ÿ

æç¤ºï¼šå°è¯•ç¼©æ”¾æ‚¨çš„æ•°æ®ã€‚ç¬”è®°æœ¬ä¸­çš„æ³¨é‡Šä»£ç æ·»åŠ äº†æ ‡å‡†ç¼©æ”¾ï¼Œä½¿æ•°æ®åˆ—åœ¨èŒƒå›´æ–¹é¢æ›´åŠ ç›¸ä¼¼ã€‚æ‚¨ä¼šå‘ç°ï¼Œå½“è½®å»“åˆ†æ•°ä¸‹é™æ—¶ï¼Œè‚˜éƒ¨å›¾ä¸­çš„â€œæ‰­ç»“â€å˜å¾—å¹³æ»‘ã€‚è¿™æ˜¯å› ä¸ºä¸ç¼©æ”¾æ•°æ®å¯ä»¥è®©æ–¹å·®è¾ƒå°çš„æ•°æ®æ‰¿è½½æ›´å¤šçš„æƒé‡ã€‚åœ¨[è¿™é‡Œ](https://stats.stackexchange.com/questions/21222/are-mean-normalization-and-feature-scaling-needed-for-k-means-clustering/21226#21226)é˜…è¯»æ›´å¤šå…³äºè¿™ä¸ªé—®é¢˜çš„[ä¿¡æ¯](https://stats.stackexchange.com/questions/21222/are-mean-normalization-and-feature-scaling-needed-for-k-means-clustering/21226#21226)ã€‚

## [è¯¾åæµ‹éªŒ](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/30/)

## å¤ä¹ ä¸è‡ªå­¦

çœ‹çœ‹[åƒè¿™æ ·](https://user.ceng.metu.edu.tr/~akifakkus/courses/ceng574/k-means/)çš„ K-Means æ¨¡æ‹Ÿå™¨ã€‚æ‚¨å¯ä»¥ä½¿ç”¨æ­¤å·¥å…·æ¥å¯è§†åŒ–æ ·æœ¬æ•°æ®ç‚¹å¹¶ç¡®å®šå…¶è´¨å¿ƒã€‚æ‚¨å¯ä»¥ç¼–è¾‘æ•°æ®çš„éšæœºæ€§ã€èšç±»æ•°å’Œè´¨å¿ƒæ•°ã€‚è¿™æ˜¯å¦æœ‰åŠ©äºæ‚¨äº†è§£å¦‚ä½•å¯¹æ•°æ®è¿›è¡Œåˆ†ç»„ï¼Ÿ

å¦å¤–ï¼Œçœ‹çœ‹æ–¯å¦ç¦å¤§å­¦çš„ [K-Means è®²ä¹‰](https://stanford.edu/~cpiech/cs221/handouts/kmeans.html)ã€‚

## ä½œä¸š

[å°è¯•ä¸åŒçš„èšç±»æ–¹æ³•](./assignment.zh-cn.md)

