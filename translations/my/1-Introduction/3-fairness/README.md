<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "9a6b702d1437c0467e3c5c28d763dac2",
  "translation_date": "2025-09-05T12:40:56+00:00",
  "source_file": "1-Introduction/3-fairness/README.md",
  "language_code": "my"
}
-->
# တာဝန်ရှိသော AI ဖြင့် စက်မှုသင်ယူမှုဖြေရှင်းချက်များ တည်ဆောက်ခြင်း

![စက်မှုသင်ယူမှုတွင် တာဝန်ရှိသော AI အကြောင်းအရာကို ရှင်းပြထားသော ပုံ](../../../../sketchnotes/ml-fairness.png)
> ပုံရေးဆွဲသူ - [Tomomi Imura](https://www.twitter.com/girlie_mac)

## [မတိုင်မီ စစ်ဆေးမေးခွန်း](https://ff-quizzes.netlify.app/en/ml/)

## အကျဉ်းချုပ်

ဒီသင်ရိုးမှာ သင်သည် စက်မှုသင်ယူမှု (Machine Learning) က ဘယ်လိုနဲ့ ဘယ်လိုများ ကျွန်တော်တို့ရဲ့ နေ့စဉ်ဘဝတွေကို သက်ရောက်နေတယ်ဆိုတာကို စတင်လေ့လာသိရှိရမှာဖြစ်ပါတယ်။ ယနေ့တိုင် အချိန်မှာတောင် စနစ်များနဲ့ မော်ဒယ်များဟာ ကျွန်တော်တို့ရဲ့ နေ့စဉ်ဆုံးဖြတ်မှုလုပ်ငန်းစဉ်တွေမှာ ပါဝင်နေပါတယ်။ ဥပမာ - ကျန်းမာရေးစစ်ဆေးမှု၊ ချေးငွေခွင့်ပြုမှု သို့မဟုတ် လိမ်လည်မှုတွေကို ရှာဖွေခြင်းစသဖြင့်။ ဒါကြောင့် ဒီမော်ဒယ်တွေက ယုံကြည်စိတ်ချရတဲ့ ရလဒ်တွေကို ပေးနိုင်ဖို့ အရေးကြီးပါတယ်။ အခြားသော ဆော့ဖ်ဝဲလ်လျှောက်လွှာတစ်ခုလိုပဲ AI စနစ်တွေကလည်း မျှော်မှန်းချက်နဲ့ မကိုက်ညီတာတွေ သို့မဟုတ် မလိုလားအပ်တဲ့ ရလဒ်တွေကို ရရှိစေတတ်ပါတယ်။ ဒါကြောင့် AI မော်ဒယ်တစ်ခုရဲ့ အပြုအမူကို နားလည်နိုင်ဖို့နဲ့ ရှင်းပြနိုင်ဖို့ အရေးကြီးပါတယ်။

သင်တစ်ခါမှ မော်ဒယ်တည်ဆောက်ဖို့ သုံးတဲ့ ဒေတာတွေမှာ လူမျိုး၊ လိင်၊ နိုင်ငံရေးအမြင်၊ ဘာသာရေး စသဖြင့် အချို့သော လူမှုအုပ်စုတွေ မပါဝင်ဘူးဆိုရင် ဘာတွေဖြစ်နိုင်မလဲ စဉ်းစားကြည့်ပါ။ ဒါမှမဟုတ် မော်ဒယ်ရဲ့ ရလဒ်တွေက အချို့သော လူမှုအုပ်စုတွေကို အားပေးတဲ့အနေနဲ့ အဓိပ္ပာယ်ဖွင့်ဆိုရင်လည်း ဘာတွေဖြစ်နိုင်မလဲ။ ထို့အပြင် မော်ဒယ်ရဲ့ ရလဒ်တွေက လူတွေကို နစ်နာစေတဲ့အခါမှာလည်း ဘယ်သူက AI စနစ်ရဲ့ အပြုအမူအတွက် တာဝန်ရှိမလဲ။ ဒီသင်ရိုးမှာ ဒီလိုမေးခွန်းတွေကို လေ့လာသွားမှာဖြစ်ပါတယ်။

ဒီသင်ခန်းစာမှာ သင်သည် -

- စက်မှုသင်ယူမှုမှာ တရားမျှတမှုရဲ့ အရေးပါမှုနဲ့ ဆက်စပ်သော နစ်နာမှုများကို နားလည်သိရှိလာမယ်။
- ယုံကြည်စိတ်ချရမှုနဲ့ လုံခြုံမှုရှိစေရန် အထူးအခြေအနေတွေကို စူးစမ်းလေ့လာတဲ့ လေ့ကျင့်မှုနဲ့ ရင်းနှီးလာမယ်။
- လူတိုင်းကို အခွင့်အရေးပေးနိုင်ဖို့ အပါဝင်စနစ်တွေကို ဒီဇိုင်းဆွဲဖို့ လိုအပ်ချက်ကို နားလည်လာမယ်။
- ဒေတာနဲ့ လူတွေရဲ့ ကိုယ်ရေးအချက်အလက်ကို ကာကွယ်ဖို့ အရေးကြီးမှုကို လေ့လာမယ်။
- AI မော်ဒယ်ရဲ့ အပြုအမူကို ရှင်းပြနိုင်ဖို့ "ဖန်သားပုံး" လိုက်နာမှုရဲ့ အရေးကြီးမှုကို မြင်တွေ့မယ်။
- AI စနစ်တွေမှာ ယုံကြည်မှုတည်ဆောက်ဖို့ တာဝန်ရှိမှုရဲ့ အရေးကြီးမှုကို သတိပြုမယ်။

## ကြိုတင်လိုအပ်ချက်

ဒီသင်ခန်းစာကို စတင်မတိုင်မီ "တာဝန်ရှိသော AI မူဝါဒများ" သင်ခန်းစာကို လေ့လာပြီး အောက်ပါဗီဒီယိုကို ကြည့်ပါ။

[ဒီသင်ခန်းစာကို လေ့လာရန်](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77952-leestott)

[![Microsoft ရဲ့ တာဝန်ရှိသော AI မူဝါဒ](https://img.youtube.com/vi/dnC8-uUZXSc/0.jpg)](https://youtu.be/dnC8-uUZXSc "Microsoft ရဲ့ တာဝန်ရှိသော AI မူဝါဒ")

> 🎥 အထက်ပါပုံကို နှိပ်ပြီး Microsoft ရဲ့ တာဝန်ရှိသော AI မူဝါဒကို ကြည့်ပါ။

## တရားမျှတမှု

AI စနစ်တွေဟာ လူတိုင်းကို တရားမျှတစွာ ဆက်ဆံရမယ်။ နောက်ထပ် လူမှုအုပ်စုတွေကို မတူညီစွာ သက်ရောက်မှုမရှိစေရမယ်။ ဥပမာ - AI စနစ်တွေက ဆေးကုသမှုအကြံပြုမှု၊ ချေးငွေလျှောက်လွှာ သို့မဟုတ် အလုပ်ခန့်အပ်မှုအတွက် လမ်းညွှန်မှုပေးတဲ့အခါမှာ တူညီတဲ့ ရောဂါလက္ခဏာ၊ ငွေကြေးအခြေအနေ သို့မဟုတ် အလုပ်အတွေ့အကြုံရှိသူတိုင်းကို တူညီတဲ့ အကြံပြုချက်ပေးရမယ်။

လူတိုင်းမှာ မျိုးရိုးစဉ်ဆက်နဲ့ ရရှိလာတဲ့ အမြင်များရှိပြီး ဒါတွေက ကျွန်တော်တို့ရဲ့ဆုံးဖြတ်မှုနဲ့ လုပ်ဆောင်မှုတွေကို သက်ရောက်စေတတ်ပါတယ်။ ဒီလို အမြင်တွေဟာ AI စနစ်တွေကို သင်ကြားဖို့ သုံးတဲ့ ဒေတာထဲမှာပါဝင်လာတတ်ပါတယ်။ တစ်ခါတစ်ရံ ဒီလိုအခြေအနေတွေဟာ မတော်တဆ ဖြစ်တတ်ပါတယ်။ ဒေတာထဲမှာ ဘယ်အချိန်မှာ ဘာအမြင်တွေ ထည့်သွင်းနေတယ်ဆိုတာကို သိရှိဖို့ ခက်ခဲတတ်ပါတယ်။

**“မတရားမှု”** ဆိုတာ လူမျိုး၊ လိင်၊ အသက်အရွယ် သို့မဟုတ် မသန်စွမ်းမှုအခြေအနေ စသဖြင့် လူတစ်စုအပေါ် အနုတ်လက္ခဏာ သို့မဟုတ် “နစ်နာမှု” ဖြစ်စေတဲ့ သက်ရောက်မှုတွေကို ဆိုလိုပါတယ်။ မတရားမှုနဲ့ ဆက်စပ်တဲ့ နစ်နာမှုတွေကို အောက်ပါအတိုင်း ခွဲခြားနိုင်ပါတယ် -

- **ခွဲဝေမှု (Allocation)** - ဥပမာအားဖြင့် လိင် သို့မဟုတ် လူမျိုးတစ်ခုကို အခြားတစ်ခုထက် အားပေးခြင်း။
- **ဝန်ဆောင်မှုအရည်အသွေး (Quality of service)** - ဒေတာကို တစ်ခုတည်းသော အခြေအနေအတွက် သင်ကြားပြီး အမှန်တရားမှာ ပိုမိုရှုပ်ထွေးတဲ့အခါ၊ ဝန်ဆောင်မှုအရည်အသွေးကျဆင်းတတ်ပါတယ်။ ဥပမာအားဖြင့် အမဲရောင်အသားရည်ရှိသူတွေကို မသိနိုင်တဲ့ လက်ဆေးဆပ်ပြာထည့်စက်။
- **အပြစ်တင်မှု (Denigration)** - တစ်စုံတစ်ခု သို့မဟုတ် တစ်စုံတစ်ယောက်ကို မတရားစွာ အပြစ်တင်ခြင်း။
- **အလွန်အကျွံ သို့မဟုတ် အနည်းငယ်သာ ပါဝင်မှု (Over- or under-representation)** - လူတစ်စုကို သက်ဆိုင်ရာ အလုပ်အကိုင်မှာ မမြင်ရခြင်း။
- **စံနှုန်းသတ်မှတ်မှု (Stereotyping)** - လူတစ်စုကို သတ်မှတ်ထားတဲ့ အင်္ဂါရပ်တွေနဲ့ ဆက်စပ်ခြင်း။

![အင်္ဂလိပ်မှ တူရကီဘာသာပြန်](../../../../1-Introduction/3-fairness/images/gender-bias-translate-en-tr.png)
> အင်္ဂလိပ်မှ တူရကီဘာသာပြန်

![တူရကီမှ အင်္ဂလိပ်ပြန်](../../../../1-Introduction/3-fairness/images/gender-bias-translate-tr-en.png)
> တူရကီမှ အင်္ဂလိပ်ပြန်

AI စနစ်တွေကို ဒီဇိုင်းဆွဲပြီး စမ်းသပ်တဲ့အခါမှာ AI ဟာ မတရား သို့မဟုတ် ခွဲခြားဆက်ဆံမှု ဆုံးဖြတ်ချက်တွေ မလုပ်ဖို့ သေချာစေရမယ်။ AI နဲ့ စက်မှုသင်ယူမှုမှာ တရားမျှတမှုကို အာမခံဖို့ဟာ လူမှုနဲ့ နည်းပညာဆိုင်ရာ စိန်ခေါ်မှုတစ်ခုဖြစ်နေဆဲပါ။

### ယုံကြည်စိတ်ချမှုနှင့် လုံခြုံမှု

AI စနစ်တွေဟာ ယုံကြည်စိတ်ချရပြီး သာမန်အခြေအနေနဲ့ မထင်မှတ်ထားတဲ့ အခြေအနေတွေမှာ တိကျမှုရှိရမယ်။ AI စနစ်တွေဟာ အမျိုးမျိုးသော အခြေအနေတွေမှာ ဘယ်လို အပြုအမူပြုမယ်ဆိုတာ သိရှိထားဖို့ အရေးကြီးပါတယ်။ AI ဖြေရှင်းချက်တွေကို တည်ဆောက်တဲ့အခါမှာ AI ဖြေရှင်းချက်တွေ ကြုံတွေ့နိုင်တဲ့ အခြေအနေမျိုးစုံကို စဉ်းစားထားဖို့ အလေးပေးရမယ်။ 

ဥပမာအားဖြင့် ကိုယ်တိုင်မောင်းနှင်တဲ့ ကားတစ်စီးဟာ လူတွေ့လုံခြုံမှုကို အဓိကထားရမယ်။ AI ကားမောင်းစနစ်ဟာ ည၊ မိုးသီး၊ မိုးနှင်း၊ လမ်းပေါ်မှာ ကလေးတွေ သို့မဟုတ် တိရစ္ဆာန်တွေ ရုတ်တရက်ပေါ်လာတာ စသဖြင့် အခြေအနေမျိုးစုံကို စဉ်းစားထားရမယ်။

> [🎥 ဗီဒီယိုကြည့်ရန်](https://www.microsoft.com/videoplayer/embed/RE4vvIl)

### အပါဝင်မှု

AI စနစ်တွေဟာ လူတိုင်းကို ပါဝင်စေပြီး အခွင့်အရေးပေးနိုင်ဖို့ ဒီဇိုင်းဆွဲရမယ်။ AI စနစ်တွေကို ဒီဇိုင်းဆွဲပြီး အကောင်အထည်ဖော်တဲ့အခါ ဒေတာသိပ္ပံပညာရှင်တွေနဲ့ AI တီထွင်သူတွေဟာ စနစ်ထဲမှာ လူတွေကို မတော်တဆ ခွဲခြားမထားဖို့ အတားအဆီးတွေကို သတ်မှတ်ပြီး ဖြေရှင်းရမယ်။ 

ဥပမာအားဖြင့် ကမ္ဘာပေါ်မှာ မသန်စွမ်းသူ ၁ ဘီလီယံရှိပါတယ်။ AI ရဲ့ တိုးတက်မှုကြောင့် သူတို့ဟာ နေ့စဉ်ဘဝမှာ အချက်အလက်နဲ့ အခွင့်အရေးတွေကို ပိုမိုလွယ်ကူစွာ ရရှိနိုင်ပါတယ်။

> [🎥 ဗီဒီယိုကြည့်ရန်](https://www.microsoft.com/videoplayer/embed/RE4vl9v)

### လုံခြုံမှုနှင့် ကိုယ်ရေးအချက်အလက်

AI စနစ်တွေဟာ လုံခြုံပြီး လူတွေရဲ့ ကိုယ်ရေးအချက်အလက်ကို လေးစားရမယ်။ AI စနစ်တွေကို ယုံကြည်မှုရှိဖို့ လူတွေရဲ့ ကိုယ်ရေးအချက်အလက် သို့မဟုတ် ဘဝကို အန္တရာယ်မဖြစ်စေရမယ်။ 

> [🎥 ဗီဒီယိုကြည့်ရန်](https://www.microsoft.com/videoplayer/embed/RE4voJF)

### တာဝန်ရှိမှု

AI စနစ်တွေကို ဒီဇိုင်းဆွဲပြီး တည်ဆောက်သူတွေဟာ သူတို့ရဲ့ စနစ်တွေ ဘယ်လိုအလုပ်လုပ်တယ်ဆိုတာအတွက် တာဝန်ရှိရမယ်။ 

[![AI နဲ့ မျက်နှာသိရှိမှုနည်းပညာရဲ့ အန္တရာယ်](../../../../1-Introduction/3-fairness/images/accountability.png)](https://www.youtube.com/watch?v=Wldt8P5V6D0 "AI နဲ့ မျက်နှာသိရှိမှုနည်းပညာရဲ့ အန္တရာယ်")

> 🎥 ဗီဒီယိုကြည့်ရန်: မျက်နှာသိရှိမှုနည်းပညာရဲ့ အန္တရာယ်

## သက်ရောက်မှုအကဲဖြတ်မှု

မော်ဒယ်တစ်ခုကို သင်ကြားမတိုင်မီ AI စနစ်ရဲ့ ရည်ရွယ်ချက်၊ သုံးစွဲမည့်နေရာ၊ သက်ဆိုင်သူတွေကို နားလည်ဖို့ အရေးကြီးပါတယ်။

## တာဝန်ရှိသော AI ဖြင့် Debugging

AI စနစ်တွေကို Debugging လုပ်တဲ့အခါမှာ တာဝန်ရှိသော AI မူဝါဒတွေကို ထည့်သွင်းစဉ်းစားရမယ်။

## 🚀 စိန်ခေါ်မှု

နစ်နာမှုတွေ မဖြစ်ပေါ်စေရန် -

- အလုပ်လုပ်သူတွေမှာ အမျိုးမျိုးသော နောက်ခံနဲ့ အမြင်တွေ ပါဝင်စေရမယ်။
- လူမှုအဖွဲ့အစည်းရဲ့ အမျိုးမျိုးသော အချက်အလက်တွေကို အထောက်အပံ့ပေးမယ့် ဒေတာတွေကို ရင်းနှီးမြှုပ်နှံရမယ်။
- စက်မှုသင်ယူမှု လုပ်ငန်းစဉ်တစ်လျှောက်မှာ တာဝန်ရှိသော AI ကို ရှာဖွေပြီး ပြင်ဆင်နိုင်တဲ့ နည်းလမ်းတွေ တိုးတက်အောင်လုပ်ရမယ်။

## [သင်ခန်းစာပြီးနောက် စစ်ဆေးမေးခွန်း](https://ff-quizzes.netlify.app/en/ml/)

## ပြန်လည်သုံးသပ်ခြင်းနှင့် ကိုယ်တိုင်လေ့လာခြင်း

ဒီသင်ခန်းစာမှာ သင်သည် စက်မှုသင်ယူမှုမှာ တရားမျှတမှုနဲ့ မတရားမှုဆိုင်ရာ အခြေခံအယူအဆတွေကို လေ့လာသိရှိခဲ့ပါတယ်။
ဒီ workshop ကို ကြည့်ပြီး အကြောင်းအရာများကို ပိုမိုနက်ရှိုင်းစွာ လေ့လာပါ: 

- တာဝန်ရှိသော AI ရှာဖွေမှု: အခြေခံသဘောတရားများကို လက်တွေ့ကျအောင် ပြုလုပ်ခြင်း - Besmira Nushi, Mehrnoosh Sameki နှင့် Amit Sharma

[![Responsible AI Toolbox: တာဝန်ရှိသော AI ဖန်တီးရန်အတွက် အခမဲ့ framework](https://img.youtube.com/vi/tGgJCrA-MZU/0.jpg)](https://www.youtube.com/watch?v=tGgJCrA-MZU "RAI Toolbox: တာဝန်ရှိသော AI ဖန်တီးရန်အတွက် အခမဲ့ framework")

> 🎥 အထက်ပါပုံကို နှိပ်ပြီး ဗီဒီယိုကြည့်ပါ: RAI Toolbox: တာဝန်ရှိသော AI ဖန်တီးရန်အတွက် အခမဲ့ framework - Besmira Nushi, Mehrnoosh Sameki နှင့် Amit Sharma

ထို့အပြင် ဖတ်ရှုရန်: 

- Microsoft ရဲ့ RAI အရင်းအမြစ်စင်တာ: [Responsible AI Resources – Microsoft AI](https://www.microsoft.com/ai/responsible-ai-resources?activetab=pivot1%3aprimaryr4) 

- Microsoft ရဲ့ FATE သုတေသနအဖွဲ့: [FATE: Fairness, Accountability, Transparency, and Ethics in AI - Microsoft Research](https://www.microsoft.com/research/theme/fate/) 

RAI Toolbox: 

- [Responsible AI Toolbox GitHub repository](https://github.com/microsoft/responsible-ai-toolbox)

Azure Machine Learning ရဲ့ တရားမျှတမှုကို အာမခံရန် tools များအကြောင်း ဖတ်ရှုပါ: 

- [Azure Machine Learning](https://docs.microsoft.com/azure/machine-learning/concept-fairness-ml?WT.mc_id=academic-77952-leestott) 

## လုပ်ငန်း

[RAI Toolbox ကို လေ့လာပါ](assignment.md)

---

**အကြောင်းကြားချက်**:  
ဤစာရွက်စာတမ်းကို AI ဘာသာပြန်ဝန်ဆောင်မှု [Co-op Translator](https://github.com/Azure/co-op-translator) ကို အသုံးပြု၍ ဘာသာပြန်ထားပါသည်။ ကျွန်ုပ်တို့သည် တိကျမှုအတွက် ကြိုးစားနေသော်လည်း၊ အလိုအလျောက် ဘာသာပြန်မှုများတွင် အမှားများ သို့မဟုတ် မတိကျမှုများ ပါဝင်နိုင်သည်ကို သတိပြုပါ။ မူရင်းစာရွက်စာတမ်းကို ၎င်း၏ မူရင်းဘာသာစကားဖြင့် အာဏာတရားရှိသော အရင်းအမြစ်အဖြစ် သတ်မှတ်သင့်ပါသည်။ အရေးကြီးသော အချက်အလက်များအတွက် လူ့ဘာသာပြန်ပညာရှင်များမှ ပရော်ဖက်ရှင်နယ် ဘာသာပြန်မှုကို အကြံပြုပါသည်။ ဤဘာသာပြန်မှုကို အသုံးပြုခြင်းမှ ဖြစ်ပေါ်လာသော အလွဲအလွတ်များ သို့မဟုတ် အနားလွဲမှုများအတွက် ကျွန်ုပ်တို့သည် တာဝန်မယူပါ။