<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "917dbf890db71a322f306050cb284749",
  "translation_date": "2025-09-04T23:46:21+00:00",
  "source_file": "7-TimeSeries/2-ARIMA/README.md",
  "language_code": "da"
}
-->
# Tidsserieprognoser med ARIMA

I den forrige lektion l칝rte du lidt om tidsserieprognoser og indl칝ste et datas칝t, der viser udsving i elektrisk belastning over en tidsperiode.

[![Introduktion til ARIMA](https://img.youtube.com/vi/IUSk-YDau10/0.jpg)](https://youtu.be/IUSk-YDau10 "Introduktion til ARIMA")

> 游꿘 Klik p친 billedet ovenfor for en video: En kort introduktion til ARIMA-modeller. Eksemplet er lavet i R, men konceptet er universelt.

## [Quiz f칮r lektionen](https://ff-quizzes.netlify.app/en/ml/)

## Introduktion

I denne lektion vil du l칝re en specifik metode til at bygge modeller med [ARIMA: *A*uto*R*egressive *I*ntegrated *M*oving *A*verage](https://wikipedia.org/wiki/Autoregressive_integrated_moving_average). ARIMA-modeller er s칝rligt velegnede til at tilpasse data, der viser [ikke-stationaritet](https://wikipedia.org/wiki/Stationary_process).

## Generelle begreber

For at kunne arbejde med ARIMA er der nogle begreber, du skal kende til:

- 游꿉 **Stationaritet**. Fra et statistisk perspektiv refererer stationaritet til data, hvis fordeling ikke 칝ndrer sig, n친r den forskydes i tid. Ikke-station칝re data viser derimod udsving p친 grund af tendenser, som skal transformeres for at kunne analyseres. S칝sonvariationer kan for eksempel introducere udsving i data og kan fjernes ved en proces kaldet 's칝sonm칝ssig differencering'.

- 游꿉 **[Differencering](https://wikipedia.org/wiki/Autoregressive_integrated_moving_average#Differencing)**. Differencering af data, igen fra et statistisk perspektiv, refererer til processen med at transformere ikke-station칝re data for at g칮re dem station칝re ved at fjerne deres ikke-konstante tendens. "Differencering fjerner 칝ndringer i niveauet af en tidsserie, eliminerer tendens og s칝sonvariation og stabiliserer dermed gennemsnittet af tidsserien." [Papir af Shixiong et al](https://arxiv.org/abs/1904.07632)

## ARIMA i konteksten af tidsserier

Lad os pakke ARIMA's dele ud for bedre at forst친, hvordan det hj칝lper os med at modellere tidsserier og lave forudsigelser baseret p친 dem.

- **AR - for AutoRegressiv**. Autoregressive modeller ser, som navnet antyder, 'tilbage' i tiden for at analysere tidligere v칝rdier i dine data og lave antagelser om dem. Disse tidligere v칝rdier kaldes 'lags'. Et eksempel kunne v칝re data, der viser m친nedlige salg af blyanter. Hver m친neds salgstal ville blive betragtet som en 'udviklende variabel' i datas칝ttet. Denne model bygges ved, at "den udviklende variabel af interesse regresseres p친 sine egne forsinkede (dvs. tidligere) v칝rdier." [wikipedia](https://wikipedia.org/wiki/Autoregressive_integrated_moving_average)

- **I - for Integreret**. I mods칝tning til de lignende 'ARMA'-modeller refererer 'I' i ARIMA til dens *[integrerede](https://wikipedia.org/wiki/Order_of_integration)* aspekt. Dataene bliver 'integreret', n친r differenceringstrin anvendes for at eliminere ikke-stationaritet.

- **MA - for Glidende Gennemsnit**. Det [glidende gennemsnit](https://wikipedia.org/wiki/Moving-average_model)-aspekt af denne model refererer til outputvariablen, der bestemmes ved at observere de aktuelle og tidligere v칝rdier af lags.

Kort sagt: ARIMA bruges til at f친 en model til at passe s친 t칝t som muligt til den s칝rlige form for tidsseriedata.

## 칒velse - byg en ARIMA-model

칀bn [_/working_](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA/working)-mappen i denne lektion og find filen [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/7-TimeSeries/2-ARIMA/working/notebook.ipynb).

1. K칮r notebooken for at indl칝se Python-biblioteket `statsmodels`; du skal bruge dette til ARIMA-modeller.

1. Indl칝s n칮dvendige biblioteker.

1. Indl칝s nu flere biblioteker, der er nyttige til at plotte data:

    ```python
    import os
    import warnings
    import matplotlib.pyplot as plt
    import numpy as np
    import pandas as pd
    import datetime as dt
    import math

    from pandas.plotting import autocorrelation_plot
    from statsmodels.tsa.statespace.sarimax import SARIMAX
    from sklearn.preprocessing import MinMaxScaler
    from common.utils import load_data, mape
    from IPython.display import Image

    %matplotlib inline
    pd.options.display.float_format = '{:,.2f}'.format
    np.set_printoptions(precision=2)
    warnings.filterwarnings("ignore") # specify to ignore warning messages
    ```

1. Indl칝s data fra filen `/data/energy.csv` i en Pandas dataframe og kig p친 det:

    ```python
    energy = load_data('./data')[['load']]
    energy.head(10)
    ```

1. Plot alle tilg칝ngelige energidata fra januar 2012 til december 2014. Der b칮r ikke v칝re nogen overraskelser, da vi s친 disse data i den sidste lektion:

    ```python
    energy.plot(y='load', subplots=True, figsize=(15, 8), fontsize=12)
    plt.xlabel('timestamp', fontsize=12)
    plt.ylabel('load', fontsize=12)
    plt.show()
    ```

    Nu skal vi bygge en model!

### Opret tr칝nings- og testdatas칝t

Nu er dine data indl칝st, s친 du kan opdele dem i tr칝nings- og testdatas칝t. Du vil tr칝ne din model p친 tr칝ningss칝ttet. Som s칝dvanligt, efter at modellen er f칝rdig med at tr칝ne, vil du evaluere dens n칮jagtighed ved hj칝lp af testdatas칝ttet. Du skal sikre dig, at testdatas칝ttet d칝kker en senere periode end tr칝ningss칝ttet for at sikre, at modellen ikke f친r information fra fremtidige tidsperioder.

1. Tildel en to-m친neders periode fra 1. september til 31. oktober 2014 til tr칝ningss칝ttet. Testdatas칝ttet vil inkludere to-m친neders perioden fra 1. november til 31. december 2014:

    ```python
    train_start_dt = '2014-11-01 00:00:00'
    test_start_dt = '2014-12-30 00:00:00'
    ```

    Da disse data afspejler det daglige energiforbrug, er der et st칝rkt s칝sonm칮nster, men forbruget ligner mest forbruget i de mere nylige dage.

1. Visualiser forskellene:

    ```python
    energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)][['load']].rename(columns={'load':'train'}) \
        .join(energy[test_start_dt:][['load']].rename(columns={'load':'test'}), how='outer') \
        .plot(y=['train', 'test'], figsize=(15, 8), fontsize=12)
    plt.xlabel('timestamp', fontsize=12)
    plt.ylabel('load', fontsize=12)
    plt.show()
    ```

    ![tr칝nings- og testdata](../../../../7-TimeSeries/2-ARIMA/images/train-test.png)

    Derfor b칮r det v칝re tilstr칝kkeligt at bruge et relativt lille tidsvindue til at tr칝ne dataene.

    > Bem칝rk: Da den funktion, vi bruger til at tilpasse ARIMA-modellen, bruger in-sample validering under tilpasning, vil vi udelade valideringsdata.

### Forbered dataene til tr칝ning

Nu skal du forberede dataene til tr칝ning ved at udf칮re filtrering og skalering af dine data. Filtrer dit datas칝t, s친 det kun inkluderer de n칮dvendige tidsperioder og kolonner, og skaler dataene for at sikre, at de projiceres i intervallet 0,1.

1. Filtrer det originale datas칝t, s친 det kun inkluderer de n칝vnte tidsperioder pr. s칝t og kun inkluderer den n칮dvendige kolonne 'load' plus datoen:

    ```python
    train = energy.copy()[(energy.index >= train_start_dt) & (energy.index < test_start_dt)][['load']]
    test = energy.copy()[energy.index >= test_start_dt][['load']]

    print('Training data shape: ', train.shape)
    print('Test data shape: ', test.shape)
    ```

    Du kan se formen af dataene:

    ```output
    Training data shape:  (1416, 1)
    Test data shape:  (48, 1)
    ```

1. Skaler dataene til at v칝re i intervallet (0, 1).

    ```python
    scaler = MinMaxScaler()
    train['load'] = scaler.fit_transform(train)
    train.head(10)
    ```

1. Visualiser de originale vs. skalerede data:

    ```python
    energy[(energy.index >= train_start_dt) & (energy.index < test_start_dt)][['load']].rename(columns={'load':'original load'}).plot.hist(bins=100, fontsize=12)
    train.rename(columns={'load':'scaled load'}).plot.hist(bins=100, fontsize=12)
    plt.show()
    ```

    ![original](../../../../7-TimeSeries/2-ARIMA/images/original.png)

    > De originale data

    ![skaleret](../../../../7-TimeSeries/2-ARIMA/images/scaled.png)

    > De skalerede data

1. Nu hvor du har kalibreret de skalerede data, kan du skalere testdataene:

    ```python
    test['load'] = scaler.transform(test)
    test.head()
    ```

### Implementer ARIMA

Det er tid til at implementere ARIMA! Du vil nu bruge `statsmodels`-biblioteket, som du installerede tidligere.

Nu skal du f칮lge flere trin:

   1. Definer modellen ved at kalde `SARIMAX()` og angive modelparametrene: p-, d- og q-parametre samt P-, D- og Q-parametre.
   2. Forbered modellen til tr칝ningsdataene ved at kalde funktionen `fit()`.
   3. Lav forudsigelser ved at kalde funktionen `forecast()` og angive antallet af trin (horisonten), der skal forudsiges.

> 游꿉 Hvad er alle disse parametre til? I en ARIMA-model er der 3 parametre, der bruges til at hj칝lpe med at modellere de vigtigste aspekter af en tidsserie: s칝sonvariation, tendens og st칮j. Disse parametre er:

`p`: parameteren, der er forbundet med den autoregressive del af modellen, som inkorporerer *tidligere* v칝rdier.  
`d`: parameteren, der er forbundet med den integrerede del af modellen, som p친virker m칝ngden af *differencering* (游꿉 husk differencering 游녡?) der skal anvendes p친 en tidsserie.  
`q`: parameteren, der er forbundet med den glidende gennemsnitsdel af modellen.

> Bem칝rk: Hvis dine data har en s칝sonm칝ssig komponent - hvilket disse data har - bruger vi en s칝sonm칝ssig ARIMA-model (SARIMA). I s친 fald skal du bruge et andet s칝t parametre: `P`, `D` og `Q`, som beskriver de samme associationer som `p`, `d` og `q`, men svarer til de s칝sonm칝ssige komponenter i modellen.

1. Start med at indstille din foretrukne horisontv칝rdi. Lad os pr칮ve 3 timer:

    ```python
    # Specify the number of steps to forecast ahead
    HORIZON = 3
    print('Forecasting horizon:', HORIZON, 'hours')
    ```

    Det kan v칝re udfordrende at v칝lge de bedste v칝rdier for en ARIMA-models parametre, da det er noget subjektivt og tidskr칝vende. Du kan overveje at bruge en `auto_arima()`-funktion fra [`pyramid`-biblioteket](https://alkaline-ml.com/pmdarima/0.9.0/modules/generated/pyramid.arima.auto_arima.html).

1. Pr칮v for nu nogle manuelle valg for at finde en god model.

    ```python
    order = (4, 1, 0)
    seasonal_order = (1, 1, 0, 24)

    model = SARIMAX(endog=train, order=order, seasonal_order=seasonal_order)
    results = model.fit()

    print(results.summary())
    ```

    En tabel med resultater udskrives.

Du har bygget din f칮rste model! Nu skal vi finde en m친de at evaluere den p친.

### Evaluer din model

For at evaluere din model kan du udf칮re den s친kaldte `walk forward`-validering. I praksis bliver tidsseriemodeller gen-tr칝net hver gang nye data bliver tilg칝ngelige. Dette giver modellen mulighed for at lave den bedste forudsigelse p친 hvert tidspunkt.

Startende fra begyndelsen af tidsserien, tr칝ner du modellen p친 tr칝ningsdatas칝ttet. Derefter laver du en forudsigelse for det n칝ste tidspunkt. Forudsigelsen evalueres mod den kendte v칝rdi. Tr칝ningss칝ttet udvides derefter til at inkludere den kendte v칝rdi, og processen gentages.

> Bem칝rk: Du b칮r holde tr칝ningss칝ttets vindue fast for mere effektiv tr칝ning, s친 hver gang du tilf칮jer en ny observation til tr칝ningss칝ttet, fjerner du observationen fra begyndelsen af s칝ttet.

Denne proces giver en mere robust estimering af, hvordan modellen vil pr칝stere i praksis. Dog kommer det med den beregningsm칝ssige omkostning ved at skabe s친 mange modeller. Dette er acceptabelt, hvis dataene er sm친 eller modellen er simpel, men kan v칝re et problem i stor skala.

Walk-forward validering er guldstandarden for evaluering af tidsseriemodeller og anbefales til dine egne projekter.

1. F칮rst, opret et testdatapunkt for hvert HORIZON-trin.

    ```python
    test_shifted = test.copy()

    for t in range(1, HORIZON+1):
        test_shifted['load+'+str(t)] = test_shifted['load'].shift(-t, freq='H')

    test_shifted = test_shifted.dropna(how='any')
    test_shifted.head(5)
    ```

    |            |          | load | load+1 | load+2 |
    | ---------- | -------- | ---- | ------ | ------ |
    | 2014-12-30 | 00:00:00 | 0.33 | 0.29   | 0.27   |
    | 2014-12-30 | 01:00:00 | 0.29 | 0.27   | 0.27   |
    | 2014-12-30 | 02:00:00 | 0.27 | 0.27   | 0.30   |
    | 2014-12-30 | 03:00:00 | 0.27 | 0.30   | 0.41   |
    | 2014-12-30 | 04:00:00 | 0.30 | 0.41   | 0.57   |

    Dataene forskydes horisontalt i henhold til deres horisontpunkt.

1. Lav forudsigelser p친 dine testdata ved hj칝lp af denne glidende vinduesmetode i en l칮kke p친 st칮rrelse med testdatas칝ttets l칝ngde:

    ```python
    %%time
    training_window = 720 # dedicate 30 days (720 hours) for training

    train_ts = train['load']
    test_ts = test_shifted

    history = [x for x in train_ts]
    history = history[(-training_window):]

    predictions = list()

    order = (2, 1, 0)
    seasonal_order = (1, 1, 0, 24)

    for t in range(test_ts.shape[0]):
        model = SARIMAX(endog=history, order=order, seasonal_order=seasonal_order)
        model_fit = model.fit()
        yhat = model_fit.forecast(steps = HORIZON)
        predictions.append(yhat)
        obs = list(test_ts.iloc[t])
        # move the training window
        history.append(obs[0])
        history.pop(0)
        print(test_ts.index[t])
        print(t+1, ': predicted =', yhat, 'expected =', obs)
    ```

    Du kan se tr칝ningen foreg친:

    ```output
    2014-12-30 00:00:00
    1 : predicted = [0.32 0.29 0.28] expected = [0.32945389435989236, 0.2900626678603402, 0.2739480752014323]

    2014-12-30 01:00:00
    2 : predicted = [0.3  0.29 0.3 ] expected = [0.2900626678603402, 0.2739480752014323, 0.26812891674127126]

    2014-12-30 02:00:00
    3 : predicted = [0.27 0.28 0.32] expected = [0.2739480752014323, 0.26812891674127126, 0.3025962399283795]
    ```

1. Sammenlign forudsigelserne med den faktiske belastning:

    ```python
    eval_df = pd.DataFrame(predictions, columns=['t+'+str(t) for t in range(1, HORIZON+1)])
    eval_df['timestamp'] = test.index[0:len(test.index)-HORIZON+1]
    eval_df = pd.melt(eval_df, id_vars='timestamp', value_name='prediction', var_name='h')
    eval_df['actual'] = np.array(np.transpose(test_ts)).ravel()
    eval_df[['prediction', 'actual']] = scaler.inverse_transform(eval_df[['prediction', 'actual']])
    eval_df.head()
    ```

    Output  
    |     |            | timestamp | h   | prediction | actual   |
    | --- | ---------- | --------- | --- | ---------- | -------- |
    | 0   | 2014-12-30 | 00:00:00  | t+1 | 3,008.74   | 3,023.00 |
    | 1   | 2014-12-30 | 01:00:00  | t+1 | 2,955.53   | 2,935.00 |
    | 2   | 2014-12-30 | 02:00:00  | t+1 | 2,900.17   | 2,899.00 |
    | 3   | 2014-12-30 | 03:00:00  | t+1 | 2,917.69   | 2,886.00 |
    | 4   | 2014-12-30 | 04:00:00  | t+1 | 2,946.99   | 2,963.00 |

    Observer forudsigelsen af den timelige data sammenlignet med den faktiske belastning. Hvor n칮jagtig er den?

### Tjek modellens n칮jagtighed

Tjek n칮jagtigheden af din model ved at teste dens gennemsnitlige absolutte procentfejl (MAPE) over alle forudsigelserne.
> **游빑 Vis mig matematikken**
>
> ![MAPE](../../../../7-TimeSeries/2-ARIMA/images/mape.png)
>
> [MAPE](https://www.linkedin.com/pulse/what-mape-mad-msd-time-series-allameh-statistics/) bruges til at vise forudsigelsesn칮jagtighed som et forhold defineret af ovenst친ende formel. Forskellen mellem faktisk og forudsagt deles med den faktiske v칝rdi. "Den absolutte v칝rdi i denne beregning summeres for hvert forudsagt tidspunkt og deles med antallet af tilpassede punkter n." [wikipedia](https://wikipedia.org/wiki/Mean_absolute_percentage_error)
1. Udtryk ligningen i kode:

    ```python
    if(HORIZON > 1):
        eval_df['APE'] = (eval_df['prediction'] - eval_df['actual']).abs() / eval_df['actual']
        print(eval_df.groupby('h')['APE'].mean())
    ```

1. Beregn MAPE for 칠t trin:

    ```python
    print('One step forecast MAPE: ', (mape(eval_df[eval_df['h'] == 't+1']['prediction'], eval_df[eval_df['h'] == 't+1']['actual']))*100, '%')
    ```

    MAPE for 칠t trin:  0.5570581332313952 %

1. Udskriv MAPE for multi-trins prognose:

    ```python
    print('Multi-step forecast MAPE: ', mape(eval_df['prediction'], eval_df['actual'])*100, '%')
    ```

    ```output
    Multi-step forecast MAPE:  1.1460048657704118 %
    ```

    Et lavt tal er bedst: husk, at en prognose med en MAPE p친 10 er 10% ved siden af.

1. Men som altid er det nemmere at se denne type n칮jagtighedsm친ling visuelt, s친 lad os plotte det:

    ```python
     if(HORIZON == 1):
        ## Plotting single step forecast
        eval_df.plot(x='timestamp', y=['actual', 'prediction'], style=['r', 'b'], figsize=(15, 8))

    else:
        ## Plotting multi step forecast
        plot_df = eval_df[(eval_df.h=='t+1')][['timestamp', 'actual']]
        for t in range(1, HORIZON+1):
            plot_df['t+'+str(t)] = eval_df[(eval_df.h=='t+'+str(t))]['prediction'].values

        fig = plt.figure(figsize=(15, 8))
        ax = plt.plot(plot_df['timestamp'], plot_df['actual'], color='red', linewidth=4.0)
        ax = fig.add_subplot(111)
        for t in range(1, HORIZON+1):
            x = plot_df['timestamp'][(t-1):]
            y = plot_df['t+'+str(t)][0:len(x)]
            ax.plot(x, y, color='blue', linewidth=4*math.pow(.9,t), alpha=math.pow(0.8,t))

        ax.legend(loc='best')

    plt.xlabel('timestamp', fontsize=12)
    plt.ylabel('load', fontsize=12)
    plt.show()
    ```

    ![en tidsseriemodel](../../../../7-TimeSeries/2-ARIMA/images/accuracy.png)

游끥 Et rigtig flot plot, der viser en model med god n칮jagtighed. Godt arbejde!

---

## 游Udfordring

Unders칮g metoder til at teste n칮jagtigheden af en tidsseriemodel. Vi ber칮rer MAPE i denne lektion, men er der andre metoder, du kunne bruge? Unders칮g dem og annot칠r dem. Et nyttigt dokument kan findes [her](https://otexts.com/fpp2/accuracy.html)

## [Quiz efter lektionen](https://ff-quizzes.netlify.app/en/ml/)

## Gennemgang & Selvstudie

Denne lektion ber칮rer kun det grundl칝ggende i tidsserieprognoser med ARIMA. Brug lidt tid p친 at uddybe din viden ved at unders칮ge [dette repository](https://microsoft.github.io/forecasting/) og dets forskellige modeltyper for at l칝re andre m친der at bygge tidsseriemodeller p친.

## Opgave

[En ny ARIMA-model](assignment.md)

---

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj칝lp af AI-overs칝ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr칝ber os p친 n칮jagtighed, skal du v칝re opm칝rksom p친, at automatiserede overs칝ttelser kan indeholde fejl eller un칮jagtigheder. Det originale dokument p친 dets oprindelige sprog b칮r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs칝ttelse. Vi er ikke ansvarlige for eventuelle misforst친elser eller fejltolkninger, der opst친r som f칮lge af brugen af denne overs칝ttelse.