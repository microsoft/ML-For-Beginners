<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6534e145d52a3890590d27be75386e5d",
  "translation_date": "2025-08-29T22:20:03+00:00",
  "source_file": "6-NLP/2-Tasks/README.md",
  "language_code": "br"
}
-->
# Tarefas e t√©cnicas comuns de processamento de linguagem natural

Para a maioria das tarefas de *processamento de linguagem natural*, o texto a ser processado deve ser dividido, examinado e os resultados armazenados ou cruzados com regras e conjuntos de dados. Essas tarefas permitem ao programador derivar o _significado_, a _inten√ß√£o_ ou apenas a _frequ√™ncia_ de termos e palavras em um texto.

## [Quiz pr√©-aula](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/33/)

Vamos explorar t√©cnicas comuns usadas no processamento de texto. Combinadas com aprendizado de m√°quina, essas t√©cnicas ajudam a analisar grandes volumes de texto de forma eficiente. Antes de aplicar ML a essas tarefas, no entanto, vamos entender os problemas enfrentados por um especialista em PLN.

## Tarefas comuns em PLN

Existem diferentes maneiras de analisar um texto com o qual voc√™ est√° trabalhando. H√° tarefas que voc√™ pode realizar e, por meio delas, √© poss√≠vel compreender o texto e tirar conclus√µes. Normalmente, essas tarefas s√£o realizadas em sequ√™ncia.

### Tokeniza√ß√£o

Provavelmente, a primeira coisa que a maioria dos algoritmos de PLN precisa fazer √© dividir o texto em tokens ou palavras. Embora isso pare√ßa simples, lidar com pontua√ß√£o e delimitadores de palavras e frases em diferentes idiomas pode ser complicado. Pode ser necess√°rio usar v√°rios m√©todos para determinar as demarca√ß√µes.

![tokenization](../../../../translated_images/tokenization.1641a160c66cd2d93d4524e8114e93158a9ce0eba3ecf117bae318e8a6ad3487.br.png)
> Tokenizando uma frase de **Orgulho e Preconceito**. Infogr√°fico por [Jen Looper](https://twitter.com/jenlooper)

### Embeddings

[Word embeddings](https://wikipedia.org/wiki/Word_embedding) s√£o uma maneira de converter seus dados textuais em valores num√©ricos. Os embeddings s√£o feitos de forma que palavras com significados semelhantes ou usadas juntas fiquem agrupadas.

![word embeddings](../../../../translated_images/embedding.2cf8953c4b3101d188c2f61a5de5b6f53caaa5ad4ed99236d42bc3b6bd6a1fe2.br.png)
> "Tenho o maior respeito pelos seus nervos, eles s√£o meus velhos amigos." - Word embeddings para uma frase de **Orgulho e Preconceito**. Infogr√°fico por [Jen Looper](https://twitter.com/jenlooper)

‚úÖ Experimente [esta ferramenta interessante](https://projector.tensorflow.org/) para explorar word embeddings. Clicar em uma palavra mostra clusters de palavras semelhantes: 'brinquedo' agrupa-se com 'disney', 'lego', 'playstation' e 'console'.

### Parsing e Marca√ß√£o de Partes do Discurso

Cada palavra que foi tokenizada pode ser marcada como uma parte do discurso - um substantivo, verbo ou adjetivo. A frase `a r√°pida raposa vermelha pulou sobre o cachorro marrom pregui√ßoso` pode ser marcada como raposa = substantivo, pulou = verbo.

![parsing](../../../../translated_images/parse.d0c5bbe1106eae8fe7d60a183cd1736c8b6cec907f38000366535f84f3036101.br.png)

> Parsing de uma frase de **Orgulho e Preconceito**. Infogr√°fico por [Jen Looper](https://twitter.com/jenlooper)

Parsing √© reconhecer quais palavras est√£o relacionadas umas √†s outras em uma frase - por exemplo, `a r√°pida raposa vermelha pulou` √© uma sequ√™ncia de adjetivo-substantivo-verbo que √© separada da sequ√™ncia `cachorro marrom pregui√ßoso`.

### Frequ√™ncia de Palavras e Frases

Um procedimento √∫til ao analisar um grande corpo de texto √© construir um dicion√°rio de cada palavra ou frase de interesse e quantas vezes ela aparece. A frase `a r√°pida raposa vermelha pulou sobre o cachorro marrom pregui√ßoso` tem uma frequ√™ncia de 2 para a palavra "a".

Vamos observar um exemplo de texto onde contamos a frequ√™ncia das palavras. O poema The Winners de Rudyard Kipling cont√©m o seguinte verso:

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

Como as frequ√™ncias de frases podem ser sens√≠veis ou n√£o a mai√∫sculas, a frase `um amigo` tem uma frequ√™ncia de 2, `o` tem uma frequ√™ncia de 6 e `viaja` tem uma frequ√™ncia de 2.

### N-grams

Um texto pode ser dividido em sequ√™ncias de palavras de um comprimento definido, uma √∫nica palavra (unigrama), duas palavras (bigrama), tr√™s palavras (trigrama) ou qualquer n√∫mero de palavras (n-gramas).

Por exemplo, `a r√°pida raposa vermelha pulou sobre o cachorro marrom pregui√ßoso` com um n-grama de 2 produz os seguintes n-gramas:

1. a r√°pida  
2. r√°pida raposa  
3. raposa vermelha  
4. vermelha pulou  
5. pulou sobre  
6. sobre o  
7. o cachorro  
8. cachorro marrom  
9. marrom pregui√ßoso  

Pode ser mais f√°cil visualizar isso como uma janela deslizante sobre a frase. Aqui est√° para n-gramas de 3 palavras, o n-grama est√° em negrito em cada frase:

1.   <u>**a r√°pida raposa**</u> vermelha pulou sobre o cachorro marrom pregui√ßoso  
2.   a **<u>r√°pida raposa vermelha</u>** pulou sobre o cachorro marrom pregui√ßoso  
3.   a r√°pida **<u>raposa vermelha pulou</u>** sobre o cachorro marrom pregui√ßoso  
4.   a r√°pida raposa **<u>vermelha pulou sobre</u>** o cachorro marrom pregui√ßoso  
5.   a r√°pida raposa vermelha **<u>pulou sobre o</u>** cachorro marrom pregui√ßoso  
6.   a r√°pida raposa vermelha pulou **<u>sobre o cachorro</u>** marrom pregui√ßoso  
7.   a r√°pida raposa vermelha pulou sobre <u>**o cachorro marrom**</u> pregui√ßoso  
8.   a r√°pida raposa vermelha pulou sobre o **<u>cachorro marrom pregui√ßoso</u>**

![n-grams sliding window](../../../../6-NLP/2-Tasks/images/n-grams.gif)

> Valor de N-grama de 3: Infogr√°fico por [Jen Looper](https://twitter.com/jenlooper)

### Extra√ß√£o de Frases Nominais

Na maioria das frases, h√° um substantivo que √© o sujeito ou objeto da frase. Em ingl√™s, ele geralmente pode ser identificado por ter 'a', 'an' ou 'the' antes dele. Identificar o sujeito ou objeto de uma frase extraindo a 'frase nominal' √© uma tarefa comum em PLN ao tentar entender o significado de uma frase.

‚úÖ Na frase "N√£o consigo fixar a hora, ou o local, ou o olhar ou as palavras, que lan√ßaram a base. Faz muito tempo. Eu j√° estava no meio antes de perceber que tinha come√ßado.", voc√™ consegue identificar as frases nominais?

Na frase `a r√°pida raposa vermelha pulou sobre o cachorro marrom pregui√ßoso`, h√° 2 frases nominais: **r√°pida raposa vermelha** e **cachorro marrom pregui√ßoso**.

### An√°lise de Sentimento

Uma frase ou texto pode ser analisado para determinar o sentimento, ou qu√£o *positivo* ou *negativo* ele √©. O sentimento √© medido em *polaridade* e *objetividade/subjetividade*. A polaridade √© medida de -1.0 a 1.0 (negativo a positivo) e de 0.0 a 1.0 (mais objetivo a mais subjetivo).

‚úÖ Mais tarde, voc√™ aprender√° que existem diferentes maneiras de determinar o sentimento usando aprendizado de m√°quina, mas uma delas √© ter uma lista de palavras e frases categorizadas como positivas ou negativas por um especialista humano e aplicar esse modelo ao texto para calcular uma pontua√ß√£o de polaridade. Voc√™ consegue ver como isso funcionaria em algumas circunst√¢ncias e menos em outras?

### Flex√£o

A flex√£o permite que voc√™ pegue uma palavra e obtenha sua forma singular ou plural.

### Lematiza√ß√£o

Um *lema* √© a raiz ou palavra-base para um conjunto de palavras, por exemplo, *voou*, *voa*, *voando* t√™m como lema o verbo *voar*.

Tamb√©m existem bancos de dados √∫teis dispon√≠veis para pesquisadores de PLN, notavelmente:

### WordNet

[WordNet](https://wordnet.princeton.edu/) √© um banco de dados de palavras, sin√¥nimos, ant√¥nimos e muitos outros detalhes para cada palavra em v√°rios idiomas. √â incrivelmente √∫til ao tentar construir tradu√ß√µes, verificadores ortogr√°ficos ou ferramentas lingu√≠sticas de qualquer tipo.

## Bibliotecas de PLN

Felizmente, voc√™ n√£o precisa construir todas essas t√©cnicas sozinho, pois existem excelentes bibliotecas Python dispon√≠veis que tornam o processamento de linguagem natural muito mais acess√≠vel para desenvolvedores que n√£o s√£o especializados em PLN ou aprendizado de m√°quina. As pr√≥ximas li√ß√µes incluem mais exemplos dessas bibliotecas, mas aqui voc√™ aprender√° alguns exemplos √∫teis para ajud√°-lo na pr√≥xima tarefa.

### Exerc√≠cio - usando a biblioteca `TextBlob`

Vamos usar uma biblioteca chamada TextBlob, pois ela cont√©m APIs √∫teis para lidar com esses tipos de tarefas. TextBlob "se baseia nos ombros gigantes do [NLTK](https://nltk.org) e do [pattern](https://github.com/clips/pattern), e funciona bem com ambos." Ela possui uma quantidade consider√°vel de ML embutida em sua API.

> Nota: Um [Guia R√°pido](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart) √∫til est√° dispon√≠vel para TextBlob e √© recomendado para desenvolvedores Python experientes.

Ao tentar identificar *frases nominais*, o TextBlob oferece v√°rias op√ß√µes de extratores para encontr√°-las.

1. D√™ uma olhada no `ConllExtractor`.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > O que est√° acontecendo aqui? [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) √© "Um extrator de frases nominais que usa chunk parsing treinado com o corpus de treinamento ConLL-2000." ConLL-2000 refere-se √† Confer√™ncia de 2000 sobre Aprendizado Computacional de Linguagem Natural. Cada ano, a confer√™ncia hospedava um workshop para resolver um problema desafiador de PLN, e em 2000 foi o chunking de substantivos. Um modelo foi treinado no Wall Street Journal, com "as se√ß√µes 15-18 como dados de treinamento (211727 tokens) e a se√ß√£o 20 como dados de teste (47377 tokens)". Voc√™ pode conferir os procedimentos usados [aqui](https://www.clips.uantwerpen.be/conll2000/chunking/) e os [resultados](https://ifarm.nl/erikt/research/np-chunking.html).

### Desafio - melhorando seu bot com PLN

Na li√ß√£o anterior, voc√™ construiu um bot de perguntas e respostas muito simples. Agora, voc√™ tornar√° Marvin um pouco mais simp√°tico analisando sua entrada para detectar o sentimento e imprimindo uma resposta correspondente. Voc√™ tamb√©m precisar√° identificar uma `noun_phrase` e perguntar sobre ela.

Seus passos ao construir um bot conversacional melhor:

1. Imprima instru√ß√µes orientando o usu√°rio sobre como interagir com o bot.  
2. Inicie o loop:  
   1. Aceite a entrada do usu√°rio.  
   2. Se o usu√°rio pedir para sair, encerre.  
   3. Processe a entrada do usu√°rio e determine a resposta de sentimento apropriada.  
   4. Se uma frase nominal for detectada no sentimento, pluralize-a e pe√ßa mais informa√ß√µes sobre esse t√≥pico.  
   5. Imprima a resposta.  
3. Volte ao passo 2.

Aqui est√° o trecho de c√≥digo para determinar o sentimento usando TextBlob. Observe que h√° apenas quatro *gradientes* de resposta de sentimento (voc√™ pode adicionar mais, se quiser):

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

Aqui est√° um exemplo de sa√≠da para gui√°-lo (a entrada do usu√°rio est√° nas linhas que come√ßam com >):

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

Uma poss√≠vel solu√ß√£o para a tarefa est√° [aqui](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/2-Tasks/solution/bot.py).

‚úÖ Verifica√ß√£o de Conhecimento

1. Voc√™ acha que as respostas simp√°ticas poderiam 'enganar' algu√©m a pensar que o bot realmente os entende?  
2. Identificar a frase nominal torna o bot mais 'cr√≠vel'?  
3. Por que extrair uma 'frase nominal' de uma frase seria algo √∫til?  

---

Implemente o bot na verifica√ß√£o de conhecimento anterior e teste-o com um amigo. Ele consegue engan√°-lo? Voc√™ consegue tornar seu bot mais 'cr√≠vel'?

## üöÄDesafio

Escolha uma tarefa na verifica√ß√£o de conhecimento anterior e tente implement√°-la. Teste o bot com um amigo. Ele consegue engan√°-lo? Voc√™ consegue tornar seu bot mais 'cr√≠vel'?

## [Quiz p√≥s-aula](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/34/)

## Revis√£o e Autoestudo

Nas pr√≥ximas li√ß√µes, voc√™ aprender√° mais sobre an√°lise de sentimento. Pesquise essa t√©cnica interessante em artigos como os do [KDNuggets](https://www.kdnuggets.com/tag/nlp).

## Tarefa

[Fa√ßa um bot responder](assignment.md)

---

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes equivocadas decorrentes do uso desta tradu√ß√£o.