{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "anaconda-cloud": "",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  },
  "colab": {
   "name": "lesson_14.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "coopTranslator": {
   "original_hash": "ad65fb4aad0a156b42216e4929f490fc",
   "translation_date": "2025-08-29T23:39:22+00:00",
   "source_file": "5-Clustering/2-K-Means/solution/R/lesson_15-R.ipynb",
   "language_code": "br"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GULATlQXLXyR"
   },
   "source": [
    "## Explore o agrupamento K-Means usando R e os princ√≠pios de dados Tidy.\n",
    "\n",
    "### [**Question√°rio pr√©-aula**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/29/)\n",
    "\n",
    "Nesta li√ß√£o, voc√™ aprender√° como criar agrupamentos usando o pacote Tidymodels e outros pacotes do ecossistema R (vamos cham√°-los de amigos üßë‚Äçü§ù‚Äçüßë), al√©m do conjunto de dados de m√∫sica nigeriana que voc√™ importou anteriormente. Vamos abordar os fundamentos do K-Means para agrupamento. Lembre-se de que, como voc√™ aprendeu na li√ß√£o anterior, existem v√°rias maneiras de trabalhar com agrupamentos, e o m√©todo que voc√™ usa depende dos seus dados. Vamos experimentar o K-Means, pois √© a t√©cnica de agrupamento mais comum. Vamos come√ßar!\n",
    "\n",
    "Termos que voc√™ aprender√°:\n",
    "\n",
    "- Pontua√ß√£o Silhouette\n",
    "\n",
    "- M√©todo do Cotovelo\n",
    "\n",
    "- In√©rcia\n",
    "\n",
    "- Vari√¢ncia\n",
    "\n",
    "### **Introdu√ß√£o**\n",
    "\n",
    "O [agrupamento K-Means](https://wikipedia.org/wiki/K-means_clustering) √© um m√©todo derivado do dom√≠nio do processamento de sinais. Ele √© usado para dividir e particionar grupos de dados em `k agrupamentos` com base em semelhan√ßas em suas caracter√≠sticas.\n",
    "\n",
    "Os agrupamentos podem ser visualizados como [diagramas de Voronoi](https://wikipedia.org/wiki/Voronoi_diagram), que incluem um ponto (ou 'semente') e sua regi√£o correspondente.\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/voronoi.png\"\n",
    "   width=\"500\"/>\n",
    "   <figcaption>Infogr√°fico por Jen Looper</figcaption>\n",
    "\n",
    "O agrupamento K-Means segue os seguintes passos:\n",
    "\n",
    "1. O cientista de dados come√ßa especificando o n√∫mero desejado de agrupamentos a serem criados.\n",
    "\n",
    "2. Em seguida, o algoritmo seleciona aleatoriamente K observa√ß√µes do conjunto de dados para servir como os centros iniciais dos agrupamentos (ou seja, centr√≥ides).\n",
    "\n",
    "3. Depois, cada uma das observa√ß√µes restantes √© atribu√≠da ao centr√≥ide mais pr√≥ximo.\n",
    "\n",
    "4. Em seguida, as novas m√©dias de cada agrupamento s√£o calculadas e o centr√≥ide √© movido para a nova m√©dia.\n",
    "\n",
    "5. Agora que os centros foram recalculados, cada observa√ß√£o √© verificada novamente para ver se pode estar mais pr√≥xima de um agrupamento diferente. Todos os objetos s√£o realocados novamente usando as m√©dias atualizadas dos agrupamentos. As etapas de atribui√ß√£o de agrupamento e atualiza√ß√£o dos centr√≥ides s√£o repetidas iterativamente at√© que as atribui√ß√µes de agrupamento parem de mudar (ou seja, quando a converg√™ncia √© alcan√ßada). Normalmente, o algoritmo termina quando cada nova itera√ß√£o resulta em um movimento insignificante dos centr√≥ides e os agrupamentos se tornam est√°ticos.\n",
    "\n",
    "<div>\n",
    "\n",
    "> Observe que, devido √† randomiza√ß√£o das k observa√ß√µes iniciais usadas como centr√≥ides iniciais, podemos obter resultados ligeiramente diferentes a cada vez que aplicamos o procedimento. Por essa raz√£o, a maioria dos algoritmos utiliza v√°rios *in√≠cios aleat√≥rios* e escolhe a itera√ß√£o com o menor WCSS. Assim, √© altamente recomend√°vel sempre executar o K-Means com v√°rios valores de *nstart* para evitar um *√≥timo local indesejado.*\n",
    "\n",
    "</div>\n",
    "\n",
    "Esta breve anima√ß√£o usando a [arte](https://github.com/allisonhorst/stats-illustrations) de Allison Horst explica o processo de agrupamento:\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/kmeans.gif\"\n",
    "   width=\"550\"/>\n",
    "   <figcaption>Arte por @allison_horst</figcaption>\n",
    "\n",
    "Uma quest√£o fundamental que surge no agrupamento √©: como saber em quantos agrupamentos separar seus dados? Uma desvantagem do uso do K-Means √© o fato de que voc√™ precisar√° estabelecer `k`, ou seja, o n√∫mero de `centr√≥ides`. Felizmente, o `m√©todo do cotovelo` ajuda a estimar um bom valor inicial para `k`. Voc√™ experimentar√° isso em breve.\n",
    "\n",
    "### \n",
    "\n",
    "**Pr√©-requisito**\n",
    "\n",
    "Vamos continuar de onde paramos na [li√ß√£o anterior](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/1-Visualize/solution/R/lesson_14-R.ipynb), onde analisamos o conjunto de dados, criamos v√°rias visualiza√ß√µes e filtramos o conjunto de dados para observa√ß√µes de interesse. Certifique-se de conferir!\n",
    "\n",
    "Vamos precisar de alguns pacotes para concluir este m√≥dulo. Voc√™ pode instal√°-los com: `install.packages(c('tidyverse', 'tidymodels', 'cluster', 'summarytools', 'plotly', 'paletteer', 'factoextra', 'patchwork'))`\n",
    "\n",
    "Alternativamente, o script abaixo verifica se voc√™ possui os pacotes necess√°rios para completar este m√≥dulo e os instala para voc√™ caso algum esteja faltando.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ah_tBi58LXyi"
   },
   "source": [
    "suppressWarnings(if(!require(\"pacman\")) install.packages(\"pacman\"))\n",
    "\n",
    "pacman::p_load('tidyverse', 'tidymodels', 'cluster', 'summarytools', 'plotly', 'paletteer', 'factoextra', 'patchwork')\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e--UCUTLXym"
   },
   "source": [
    "Vamos come√ßar com tudo!\n",
    "\n",
    "## 1. Uma dan√ßa com dados: Reduza para os 3 g√™neros musicais mais populares\n",
    "\n",
    "Este √© um resumo do que fizemos na li√ß√£o anterior. Vamos explorar e analisar alguns dados!\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ycamx7GGLXyn"
   },
   "source": [
    "# Load the core tidyverse and make it available in your current R session\n",
    "library(tidyverse)\n",
    "\n",
    "# Import the data into a tibble\n",
    "df <- read_csv(file = \"https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/5-Clustering/data/nigerian-songs.csv\", show_col_types = FALSE)\n",
    "\n",
    "# Narrow down to top 3 popular genres\n",
    "nigerian_songs <- df %>% \n",
    "  # Concentrate on top 3 genres\n",
    "  filter(artist_top_genre %in% c(\"afro dancehall\", \"afropop\",\"nigerian pop\")) %>% \n",
    "  # Remove unclassified observations\n",
    "  filter(popularity != 0)\n",
    "\n",
    "\n",
    "\n",
    "# Visualize popular genres using bar plots\n",
    "theme_set(theme_light())\n",
    "nigerian_songs %>%\n",
    "  count(artist_top_genre) %>%\n",
    "  ggplot(mapping = aes(x = artist_top_genre, y = n,\n",
    "                       fill = artist_top_genre)) +\n",
    "  geom_col(alpha = 0.8) +\n",
    "  paletteer::scale_fill_paletteer_d(\"ggsci::category10_d3\") +\n",
    "  ggtitle(\"Top genres\") +\n",
    "  theme(plot.title = element_text(hjust = 0.5))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5h5zmkPLXyp"
   },
   "source": [
    "ü§© Isso foi √≥timo!\n",
    "\n",
    "## 2. Mais explora√ß√£o de dados.\n",
    "\n",
    "Qu√£o limpos est√£o esses dados? Vamos verificar a presen√ßa de outliers usando boxplots. Vamos nos concentrar em colunas num√©ricas com menos outliers (embora voc√™ possa limpar os outliers, se preferir). Boxplots podem mostrar o intervalo dos dados e ajudar a escolher quais colunas usar. Observe que os boxplots n√£o mostram a vari√¢ncia, um elemento importante para dados bem agrup√°veis. Por favor, veja [esta discuss√£o](https://stats.stackexchange.com/questions/91536/deduce-variance-from-boxplot) para leitura adicional.\n",
    "\n",
    "[Boxplots](https://en.wikipedia.org/wiki/Box_plot) s√£o usados para representar graficamente a distribui√ß√£o de dados `num√©ricos`, ent√£o vamos come√ßar *selecionando* todas as colunas num√©ricas junto com os g√™neros musicais populares.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HhNreJKLLXyq"
   },
   "source": [
    "# Select top genre column and all other numeric columns\n",
    "df_numeric <- nigerian_songs %>% \n",
    "  select(artist_top_genre, where(is.numeric)) \n",
    "\n",
    "# Display the data\n",
    "df_numeric %>% \n",
    "  slice_head(n = 5)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYXrwJRaLXyq"
   },
   "source": [
    "Veja como o seletor `where` facilita isso üíÅ? Explore outras fun√ß√µes semelhantes [aqui](https://tidyselect.r-lib.org/).\n",
    "\n",
    "Como vamos criar um boxplot para cada caracter√≠stica num√©rica e queremos evitar o uso de loops, vamos reformular nossos dados para um formato *mais longo*, o que nos permitir√° aproveitar os `facets` - subgr√°ficos que exibem cada um um subconjunto dos dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gd5bR3f8LXys"
   },
   "source": [
    "# Pivot data from wide to long\n",
    "df_numeric_long <- df_numeric %>% \n",
    "  pivot_longer(!artist_top_genre, names_to = \"feature_names\", values_to = \"values\") \n",
    "\n",
    "# Print out data\n",
    "df_numeric_long %>% \n",
    "  slice_head(n = 15)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7tE1swnLXyv"
   },
   "source": [
    "Muito mais longo! Agora √© hora de alguns `ggplots`! Ent√£o, qual `geom` usaremos?\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "r88bIsyuLXyy"
   },
   "source": [
    "# Make a box plot\n",
    "df_numeric_long %>% \n",
    "  ggplot(mapping = aes(x = feature_names, y = values, fill = feature_names)) +\n",
    "  geom_boxplot() +\n",
    "  facet_wrap(~ feature_names, ncol = 4, scales = \"free\") +\n",
    "  theme(legend.position = \"none\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYVyKIUELXyz"
   },
   "source": [
    "F√°cil-gg!\n",
    "\n",
    "Agora podemos ver que esses dados est√£o um pouco ruidosos: ao observar cada coluna como um boxplot, √© poss√≠vel identificar valores at√≠picos. Voc√™ poderia percorrer o conjunto de dados e remover esses valores at√≠picos, mas isso tornaria os dados bem reduzidos.\n",
    "\n",
    "Por enquanto, vamos escolher quais colunas usaremos para o nosso exerc√≠cio de agrupamento. Vamos selecionar as colunas num√©ricas com intervalos semelhantes. Poder√≠amos codificar o `artist_top_genre` como num√©rico, mas vamos descart√°-lo por enquanto.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-wkpINyZLXy0"
   },
   "source": [
    "# Select variables with similar ranges\n",
    "df_numeric_select <- df_numeric %>% \n",
    "  select(popularity, danceability, acousticness, loudness, energy) \n",
    "\n",
    "# Normalize data\n",
    "# df_numeric_select <- scale(df_numeric_select)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7dLzgpqLXy1"
   },
   "source": [
    "## 3. Computando agrupamento k-means em R\n",
    "\n",
    "Podemos calcular k-means em R usando a fun√ß√£o integrada `kmeans`, veja `help(\"kmeans()\")`. A fun√ß√£o `kmeans()` aceita um data frame com todas as colunas num√©ricas como seu argumento principal.\n",
    "\n",
    "O primeiro passo ao usar o agrupamento k-means √© especificar o n√∫mero de clusters (k) que ser√£o gerados na solu√ß√£o final. Sabemos que h√° 3 g√™neros musicais que extra√≠mos do conjunto de dados, ent√£o vamos tentar com 3:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uC4EQ5w7LXy5"
   },
   "source": [
    "set.seed(2056)\n",
    "# Kmeans clustering for 3 clusters\n",
    "kclust <- kmeans(\n",
    "  df_numeric_select,\n",
    "  # Specify the number of clusters\n",
    "  centers = 3,\n",
    "  # How many random initial configurations\n",
    "  nstart = 25\n",
    ")\n",
    "\n",
    "# Display clustering object\n",
    "kclust\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzfhscWrLXy-"
   },
   "source": [
    "O objeto kmeans cont√©m v√°rias informa√ß√µes que est√£o bem explicadas em `help(\"kmeans()\")`. Por enquanto, vamos nos concentrar em algumas delas. Podemos ver que os dados foram agrupados em 3 clusters com tamanhos de 65, 110 e 111. A sa√≠da tamb√©m cont√©m os centros dos clusters (m√©dias) para os 3 grupos em rela√ß√£o √†s 5 vari√°veis.\n",
    "\n",
    "O vetor de agrupamento √© a atribui√ß√£o de cluster para cada observa√ß√£o. Vamos usar a fun√ß√£o `augment` para adicionar a atribui√ß√£o de cluster ao conjunto de dados original.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0XwwpFGQLXy_"
   },
   "source": [
    "# Add predicted cluster assignment to data set\n",
    "augment(kclust, df_numeric_select) %>% \n",
    "  relocate(.cluster) %>% \n",
    "  slice_head(n = 10)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXIVXXACLXzA"
   },
   "source": [
    "Perfeito, acabamos de dividir nosso conjunto de dados em um conjunto de 3 grupos. Ent√£o, qu√£o boa √© nossa clusteriza√ß√£o ü§∑? Vamos dar uma olhada no `Silhouette score`.\n",
    "\n",
    "### **Silhouette score**\n",
    "\n",
    "[A an√°lise de Silhouette](https://en.wikipedia.org/wiki/Silhouette_(clustering)) pode ser usada para estudar a dist√¢ncia de separa√ß√£o entre os clusters resultantes. Esse score varia de -1 a 1, e se o score estiver pr√≥ximo de 1, o cluster √© denso e bem separado dos outros clusters. Um valor pr√≥ximo de 0 representa clusters sobrepostos com amostras muito pr√≥ximas da fronteira de decis√£o dos clusters vizinhos. [fonte](https://dzone.com/articles/kmeans-silhouette-score-explained-with-python-exam).\n",
    "\n",
    "O m√©todo de silhouette m√©dio calcula a m√©dia do silhouette das observa√ß√µes para diferentes valores de *k*. Um alto score m√©dio de silhouette indica uma boa clusteriza√ß√£o.\n",
    "\n",
    "A fun√ß√£o `silhouette` no pacote de cluster √© usada para calcular a largura m√©dia do silhouette.\n",
    "\n",
    "> O silhouette pode ser calculado com qualquer [m√©trica de dist√¢ncia](https://en.wikipedia.org/wiki/Distance \"Distance\"), como a [dist√¢ncia Euclidiana](https://en.wikipedia.org/wiki/Euclidean_distance \"Euclidean distance\") ou a [dist√¢ncia Manhattan](https://en.wikipedia.org/wiki/Manhattan_distance \"Manhattan distance\"), que discutimos na [li√ß√£o anterior](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/1-Visualize/solution/R/lesson_14-R.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Jn0McL28LXzB"
   },
   "source": [
    "# Load cluster package\n",
    "library(cluster)\n",
    "\n",
    "# Compute average silhouette score\n",
    "ss <- silhouette(kclust$cluster,\n",
    "                 # Compute euclidean distance\n",
    "                 dist = dist(df_numeric_select))\n",
    "mean(ss[, 3])\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyQRn97nLXzC"
   },
   "source": [
    "Nosso √≠ndice √© **0,549**, bem no meio. Isso indica que nossos dados n√£o s√£o particularmente adequados para este tipo de agrupamento. Vamos verificar se conseguimos confirmar essa suspeita visualmente. O [pacote factoextra](https://rpkgs.datanovia.com/factoextra/index.html) fornece fun√ß√µes (`fviz_cluster()`) para visualizar agrupamentos.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7a6Km1_FLXzD"
   },
   "source": [
    "library(factoextra)\n",
    "\n",
    "# Visualize clustering results\n",
    "fviz_cluster(kclust, df_numeric_select)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBwCWt-0LXzD"
   },
   "source": [
    "A sobreposi√ß√£o nos clusters indica que nossos dados n√£o s√£o particularmente adequados para esse tipo de agrupamento, mas vamos continuar.\n",
    "\n",
    "## 4. Determinando o n√∫mero ideal de clusters\n",
    "\n",
    "Uma pergunta fundamental que frequentemente surge no agrupamento K-Means √© esta: sem r√≥tulos de classe conhecidos, como voc√™ sabe em quantos clusters deve separar seus dados?\n",
    "\n",
    "Uma maneira de tentar descobrir √© usar uma amostra de dados para `criar uma s√©rie de modelos de agrupamento` com um n√∫mero crescente de clusters (por exemplo, de 1 a 10) e avaliar m√©tricas de agrupamento, como o **Silhouette score.**\n",
    "\n",
    "Vamos determinar o n√∫mero ideal de clusters calculando o algoritmo de agrupamento para diferentes valores de *k* e avaliando o **Within Cluster Sum of Squares** (WCSS). O total de soma de quadrados dentro dos clusters (WCSS) mede a compacidade do agrupamento, e queremos que ele seja o menor poss√≠vel, com valores mais baixos indicando que os pontos de dados est√£o mais pr√≥ximos.\n",
    "\n",
    "Vamos explorar o efeito de diferentes escolhas de `k`, de 1 a 10, nesse agrupamento.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hSeIiylDLXzE"
   },
   "source": [
    "# Create a series of clustering models\n",
    "kclusts <- tibble(k = 1:10) %>% \n",
    "  # Perform kmeans clustering for 1,2,3 ... ,10 clusters\n",
    "  mutate(model = map(k, ~ kmeans(df_numeric_select, centers = .x, nstart = 25)),\n",
    "  # Farm out clustering metrics eg WCSS\n",
    "         glanced = map(model, ~ glance(.x))) %>% \n",
    "  unnest(cols = glanced)\n",
    "  \n",
    "\n",
    "# View clustering rsulsts\n",
    "kclusts\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7rS2U1eLXzE"
   },
   "source": [
    "Agora que temos o total da soma dos quadrados dentro dos clusters (tot.withinss) para cada algoritmo de agrupamento com centro *k*, usamos o [m√©todo do cotovelo](https://en.wikipedia.org/wiki/Elbow_method_(clustering)) para encontrar o n√∫mero ideal de clusters. O m√©todo consiste em plotar o WCSS como uma fun√ß√£o do n√∫mero de clusters e escolher o [cotovelo da curva](https://en.wikipedia.org/wiki/Elbow_of_the_curve \"Elbow of the curve\") como o n√∫mero de clusters a ser utilizado.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o_DjHGItLXzF"
   },
   "source": [
    "set.seed(2056)\n",
    "# Use elbow method to determine optimum number of clusters\n",
    "kclusts %>% \n",
    "  ggplot(mapping = aes(x = k, y = tot.withinss)) +\n",
    "  geom_line(size = 1.2, alpha = 0.8, color = \"#FF7F0EFF\") +\n",
    "  geom_point(size = 2, color = \"#FF7F0EFF\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLYyt5XSLXzG"
   },
   "source": [
    "O gr√°fico mostra uma grande redu√ß√£o no WCSS (ou seja, maior *coer√™ncia*) √† medida que o n√∫mero de clusters aumenta de um para dois, e uma redu√ß√£o adicional percept√≠vel de dois para tr√™s clusters. Depois disso, a redu√ß√£o √© menos acentuada, resultando em um `cotovelo` üí™ no gr√°fico em torno de tr√™s clusters. Isso √© uma boa indica√ß√£o de que h√° dois a tr√™s clusters de pontos de dados razoavelmente bem separados.\n",
    "\n",
    "Agora podemos prosseguir e extrair o modelo de clustering onde `k = 3`:\n",
    "\n",
    "> `pull()`: usado para extrair uma √∫nica coluna\n",
    ">\n",
    "> `pluck()`: usado para indexar estruturas de dados como listas\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JP_JPKBILXzG"
   },
   "source": [
    "# Extract k = 3 clustering\n",
    "final_kmeans <- kclusts %>% \n",
    "  filter(k == 3) %>% \n",
    "  pull(model) %>% \n",
    "  pluck(1)\n",
    "\n",
    "\n",
    "final_kmeans\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_PDTu8tLXzI"
   },
   "source": [
    "√ìtimo! Vamos visualizar os clusters obtidos. Que tal adicionar um pouco de interatividade usando `plotly`?\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dNcleFe-LXzJ"
   },
   "source": [
    "# Add predicted cluster assignment to data set\n",
    "results <-  augment(final_kmeans, df_numeric_select) %>% \n",
    "  bind_cols(df_numeric %>% select(artist_top_genre)) \n",
    "\n",
    "# Plot cluster assignments\n",
    "clust_plt <- results %>% \n",
    "  ggplot(mapping = aes(x = popularity, y = danceability, color = .cluster, shape = artist_top_genre)) +\n",
    "  geom_point(size = 2, alpha = 0.8) +\n",
    "  paletteer::scale_color_paletteer_d(\"ggthemes::Tableau_10\")\n",
    "\n",
    "ggplotly(clust_plt)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JUM_51VLXzK"
   },
   "source": [
    "Talvez esper√°ssemos que cada cluster (representado por cores diferentes) tivesse g√™neros distintos (representados por formas diferentes).\n",
    "\n",
    "Vamos dar uma olhada na precis√£o do modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HdIMUGq7LXzL"
   },
   "source": [
    "# Assign genres to predefined integers\n",
    "label_count <- results %>% \n",
    "  group_by(artist_top_genre) %>% \n",
    "  mutate(id = cur_group_id()) %>% \n",
    "  ungroup() %>% \n",
    "  summarise(correct_labels = sum(.cluster == id))\n",
    "\n",
    "\n",
    "# Print results  \n",
    "cat(\"Result:\", label_count$correct_labels, \"out of\", nrow(results), \"samples were correctly labeled.\")\n",
    "\n",
    "cat(\"\\nAccuracy score:\", label_count$correct_labels/nrow(results))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C50wvaAOLXzM"
   },
   "source": [
    "A precis√£o deste modelo n√£o √© ruim, mas tamb√©m n√£o √© excelente. Pode ser que os dados n√£o sejam adequados para o agrupamento K-Means. Esses dados s√£o muito desequilibrados, pouco correlacionados e h√° muita vari√¢ncia entre os valores das colunas para formar bons clusters. Na verdade, os clusters que se formam provavelmente s√£o fortemente influenciados ou distorcidos pelas tr√™s categorias de g√™nero que definimos acima.\n",
    "\n",
    "Mesmo assim, foi um processo de aprendizado interessante!\n",
    "\n",
    "Na documenta√ß√£o do Scikit-learn, voc√™ pode ver que um modelo como este, com clusters n√£o muito bem definidos, apresenta um problema de 'vari√¢ncia':\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/problems.png\"\n",
    "   width=\"500\"/>\n",
    "   <figcaption>Infogr√°fico do Scikit-learn</figcaption>\n",
    "\n",
    "\n",
    "\n",
    "## **Vari√¢ncia**\n",
    "\n",
    "Vari√¢ncia √© definida como \"a m√©dia das diferen√ßas quadradas em rela√ß√£o √† m√©dia\" [fonte](https://www.mathsisfun.com/data/standard-deviation.html). No contexto deste problema de agrupamento, refere-se aos dados cujos n√∫meros do nosso conjunto tendem a divergir um pouco demais da m√©dia.\n",
    "\n",
    "‚úÖ Este √© um √≥timo momento para pensar em todas as maneiras de corrigir esse problema. Ajustar os dados um pouco mais? Usar colunas diferentes? Utilizar um algoritmo diferente? Dica: Experimente [escalar seus dados](https://www.mygreatlearning.com/blog/learning-data-science-with-k-means-clustering/) para normaliz√°-los e testar outras colunas.\n",
    "\n",
    "> Experimente este '[calculador de vari√¢ncia](https://www.calculatorsoup.com/calculators/statistics/variance-calculator.php)' para entender melhor o conceito.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## **üöÄDesafio**\n",
    "\n",
    "Dedique algum tempo a este notebook, ajustando os par√¢metros. Voc√™ consegue melhorar a precis√£o do modelo limpando mais os dados (removendo outliers, por exemplo)? Voc√™ pode usar pesos para dar mais import√¢ncia a determinadas amostras de dados. O que mais voc√™ pode fazer para criar clusters melhores?\n",
    "\n",
    "Dica: Experimente escalar seus dados. H√° c√≥digo comentado no notebook que adiciona escalonamento padr√£o para fazer com que as colunas de dados se assemelhem mais em termos de intervalo. Voc√™ ver√° que, embora a pontua√ß√£o de silhueta diminua, o 'cotovelo' no gr√°fico suaviza. Isso ocorre porque deixar os dados sem escala permite que dados com menos vari√¢ncia tenham mais peso. Leia mais sobre esse problema [aqui](https://stats.stackexchange.com/questions/21222/are-mean-normalization-and-feature-scaling-needed-for-k-means-clustering/21226#21226).\n",
    "\n",
    "## [**Quiz p√≥s-aula**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/30/)\n",
    "\n",
    "## **Revis√£o e Autoestudo**\n",
    "\n",
    "-   D√™ uma olhada em um simulador de K-Means [como este](https://user.ceng.metu.edu.tr/~akifakkus/courses/ceng574/k-means/). Voc√™ pode usar esta ferramenta para visualizar pontos de dados de amostra e determinar seus centr√≥ides. Voc√™ pode editar a aleatoriedade dos dados, o n√∫mero de clusters e o n√∫mero de centr√≥ides. Isso ajuda voc√™ a ter uma ideia de como os dados podem ser agrupados?\n",
    "\n",
    "-   Al√©m disso, confira [este material sobre K-Means](https://stanford.edu/~cpiech/cs221/handouts/kmeans.html) de Stanford.\n",
    "\n",
    "Quer testar suas habilidades rec√©m-adquiridas de agrupamento em conjuntos de dados que se adaptam bem ao K-Means? Veja:\n",
    "\n",
    "-   [Treine e avalie modelos de agrupamento](https://rpubs.com/eR_ic/clustering) usando Tidymodels e amigos\n",
    "\n",
    "-   [An√°lise de Cluster K-Means](https://uc-r.github.io/kmeans_clustering), Guia de Programa√ß√£o R para An√°lise de Neg√≥cios da UC\n",
    "\n",
    "- [Agrupamento K-Means com princ√≠pios de dados organizados](https://www.tidymodels.org/learn/statistics/k-means/)\n",
    "\n",
    "## **Tarefa**\n",
    "\n",
    "[Experimente diferentes m√©todos de agrupamento](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/2-K-Means/assignment.md)\n",
    "\n",
    "## AGRADECIMENTOS A:\n",
    "\n",
    "[Jen Looper](https://www.twitter.com/jenlooper) por criar a vers√£o original em Python deste m√≥dulo ‚ô•Ô∏è\n",
    "\n",
    "[`Allison Horst`](https://twitter.com/allison_horst/) por criar as ilustra√ß√µes incr√≠veis que tornam o R mais acolhedor e envolvente. Encontre mais ilustra√ß√µes em sua [galeria](https://www.google.com/url?q=https://github.com/allisonhorst/stats-illustrations&sa=D&source=editors&ust=1626380772530000&usg=AOvVaw3zcfyCizFQZpkSLzxiiQEM).\n",
    "\n",
    "Feliz aprendizado,\n",
    "\n",
    "[Eric](https://twitter.com/ericntay), Embaixador Estudante Gold da Microsoft Learn.\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/r_learners_sm.jpeg\"\n",
    "   width=\"500\"/>\n",
    "   <figcaption>Arte por @allison_horst</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Aviso Legal**:  \nEste documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte oficial. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes equivocadas decorrentes do uso desta tradu√ß√£o.\n"
   ]
  }
 ]
}