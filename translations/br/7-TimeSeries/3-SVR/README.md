<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "482bccabe1df958496ea71a3667995cd",
  "translation_date": "2025-09-04T21:28:28+00:00",
  "source_file": "7-TimeSeries/3-SVR/README.md",
  "language_code": "br"
}
-->
# Previs√£o de S√©ries Temporais com Support Vector Regressor

Na li√ß√£o anterior, voc√™ aprendeu como usar o modelo ARIMA para fazer previs√µes de s√©ries temporais. Agora, voc√™ ver√° o modelo Support Vector Regressor, que √© um modelo de regress√£o usado para prever dados cont√≠nuos.

## [Quiz pr√©-aula](https://ff-quizzes.netlify.app/en/ml/) 

## Introdu√ß√£o

Nesta li√ß√£o, voc√™ descobrir√° uma maneira espec√≠fica de construir modelos com [**SVM**: **S**upport **V**ector **M**achine](https://en.wikipedia.org/wiki/Support-vector_machine) para regress√£o, ou **SVR: Support Vector Regressor**.

### SVR no contexto de s√©ries temporais [^1]

Antes de entender a import√¢ncia do SVR na previs√£o de s√©ries temporais, aqui est√£o alguns conceitos importantes que voc√™ precisa saber:

- **Regress√£o:** T√©cnica de aprendizado supervisionado para prever valores cont√≠nuos a partir de um conjunto de entradas. A ideia √© ajustar uma curva (ou linha) no espa√ßo de caracter√≠sticas que tenha o maior n√∫mero de pontos de dados. [Clique aqui](https://en.wikipedia.org/wiki/Regression_analysis) para mais informa√ß√µes.
- **Support Vector Machine (SVM):** Um tipo de modelo de aprendizado de m√°quina supervisionado usado para classifica√ß√£o, regress√£o e detec√ß√£o de outliers. O modelo √© um hiperplano no espa√ßo de caracter√≠sticas, que no caso de classifica√ß√£o atua como um limite, e no caso de regress√£o atua como a linha de melhor ajuste. No SVM, uma fun√ß√£o Kernel geralmente √© usada para transformar o conjunto de dados em um espa√ßo de maior n√∫mero de dimens√µes, para que possam ser facilmente separ√°veis. [Clique aqui](https://en.wikipedia.org/wiki/Support-vector_machine) para mais informa√ß√µes sobre SVMs.
- **Support Vector Regressor (SVR):** Um tipo de SVM, usado para encontrar a linha de melhor ajuste (que no caso do SVM √© um hiperplano) que tenha o maior n√∫mero de pontos de dados.

### Por que SVR? [^1]

Na √∫ltima li√ß√£o, voc√™ aprendeu sobre o ARIMA, que √© um m√©todo estat√≠stico linear muito bem-sucedido para prever dados de s√©ries temporais. No entanto, em muitos casos, os dados de s√©ries temporais apresentam *n√£o-linearidade*, que n√£o pode ser mapeada por modelos lineares. Nesses casos, a capacidade do SVM de considerar a n√£o-linearidade nos dados para tarefas de regress√£o torna o SVR bem-sucedido na previs√£o de s√©ries temporais.

## Exerc√≠cio - construir um modelo SVR

Os primeiros passos para a prepara√ß√£o dos dados s√£o os mesmos da li√ß√£o anterior sobre [ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA).

Abra a pasta [_/working_](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/3-SVR/working) nesta li√ß√£o e encontre o arquivo [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/7-TimeSeries/3-SVR/working/notebook.ipynb). [^2]

1. Execute o notebook e importe as bibliotecas necess√°rias: [^2]

   ```python
   import sys
   sys.path.append('../../')
   ```

   ```python
   import os
   import warnings
   import matplotlib.pyplot as plt
   import numpy as np
   import pandas as pd
   import datetime as dt
   import math
   
   from sklearn.svm import SVR
   from sklearn.preprocessing import MinMaxScaler
   from common.utils import load_data, mape
   ```

2. Carregue os dados do arquivo `/data/energy.csv` em um dataframe do Pandas e d√™ uma olhada: [^2]

   ```python
   energy = load_data('../../data')[['load']]
   ```

3. Plote todos os dados de energia dispon√≠veis de janeiro de 2012 a dezembro de 2014: [^2]

   ```python
   energy.plot(y='load', subplots=True, figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![dados completos](../../../../7-TimeSeries/3-SVR/images/full-data.png)

   Agora, vamos construir nosso modelo SVR.

### Criar conjuntos de treinamento e teste

Agora que seus dados est√£o carregados, voc√™ pode separ√°-los em conjuntos de treinamento e teste. Em seguida, voc√™ remodelar√° os dados para criar um conjunto de dados baseado em etapas de tempo, que ser√° necess√°rio para o SVR. Voc√™ treinar√° seu modelo no conjunto de treinamento. Ap√≥s o t√©rmino do treinamento, voc√™ avaliar√° sua precis√£o no conjunto de treinamento, no conjunto de teste e, em seguida, no conjunto de dados completo para ver o desempenho geral. √â necess√°rio garantir que o conjunto de teste cubra um per√≠odo posterior ao conjunto de treinamento para garantir que o modelo n√£o obtenha informa√ß√µes de per√≠odos futuros [^2] (uma situa√ß√£o conhecida como *Overfitting*).

1. Alocar um per√≠odo de dois meses de 1¬∫ de setembro a 31 de outubro de 2014 para o conjunto de treinamento. O conjunto de teste incluir√° o per√≠odo de dois meses de 1¬∫ de novembro a 31 de dezembro de 2014: [^2]

   ```python
   train_start_dt = '2014-11-01 00:00:00'
   test_start_dt = '2014-12-30 00:00:00'
   ```

2. Visualizar as diferen√ßas: [^2]

   ```python
   energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)][['load']].rename(columns={'load':'train'}) \
       .join(energy[test_start_dt:][['load']].rename(columns={'load':'test'}), how='outer') \
       .plot(y=['train', 'test'], figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![dados de treinamento e teste](../../../../7-TimeSeries/3-SVR/images/train-test.png)

### Preparar os dados para treinamento

Agora, voc√™ precisa preparar os dados para treinamento, realizando filtragem e escalonamento dos dados. Filtre seu conjunto de dados para incluir apenas os per√≠odos de tempo e colunas necess√°rios, e escale para garantir que os dados sejam projetados no intervalo 0,1.

1. Filtrar o conjunto de dados original para incluir apenas os per√≠odos de tempo mencionados por conjunto e incluir apenas a coluna necess√°ria 'load' mais a data: [^2]

   ```python
   train = energy.copy()[(energy.index >= train_start_dt) & (energy.index < test_start_dt)][['load']]
   test = energy.copy()[energy.index >= test_start_dt][['load']]
   
   print('Training data shape: ', train.shape)
   print('Test data shape: ', test.shape)
   ```

   ```output
   Training data shape:  (1416, 1)
   Test data shape:  (48, 1)
   ```
   
2. Escalar os dados de treinamento para estar no intervalo (0, 1): [^2]

   ```python
   scaler = MinMaxScaler()
   train['load'] = scaler.fit_transform(train)
   ```
   
4. Agora, escale os dados de teste: [^2]

   ```python
   test['load'] = scaler.transform(test)
   ```

### Criar dados com etapas de tempo [^1]

Para o SVR, voc√™ transforma os dados de entrada para o formato `[batch, timesteps]`. Assim, voc√™ remodela os `train_data` e `test_data` existentes de forma que haja uma nova dimens√£o que se refira √†s etapas de tempo.

```python
# Converting to numpy arrays
train_data = train.values
test_data = test.values
```

Para este exemplo, usamos `timesteps = 5`. Assim, as entradas para o modelo s√£o os dados dos primeiros 4 timesteps, e a sa√≠da ser√° os dados do 5¬∫ timestep.

```python
timesteps=5
```

Convertendo os dados de treinamento para tensor 2D usando list comprehension aninhada:

```python
train_data_timesteps=np.array([[j for j in train_data[i:i+timesteps]] for i in range(0,len(train_data)-timesteps+1)])[:,:,0]
train_data_timesteps.shape
```

```output
(1412, 5)
```

Convertendo os dados de teste para tensor 2D:

```python
test_data_timesteps=np.array([[j for j in test_data[i:i+timesteps]] for i in range(0,len(test_data)-timesteps+1)])[:,:,0]
test_data_timesteps.shape
```

```output
(44, 5)
```

Selecionando entradas e sa√≠das dos dados de treinamento e teste:

```python
x_train, y_train = train_data_timesteps[:,:timesteps-1],train_data_timesteps[:,[timesteps-1]]
x_test, y_test = test_data_timesteps[:,:timesteps-1],test_data_timesteps[:,[timesteps-1]]

print(x_train.shape, y_train.shape)
print(x_test.shape, y_test.shape)
```

```output
(1412, 4) (1412, 1)
(44, 4) (44, 1)
```

### Implementar SVR [^1]

Agora, √© hora de implementar o SVR. Para ler mais sobre esta implementa√ß√£o, voc√™ pode consultar [esta documenta√ß√£o](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html). Para nossa implementa√ß√£o, seguimos estas etapas:

1. Definir o modelo chamando `SVR()` e passando os hiperpar√¢metros do modelo: kernel, gamma, c e epsilon
2. Preparar o modelo para os dados de treinamento chamando a fun√ß√£o `fit()`
3. Fazer previs√µes chamando a fun√ß√£o `predict()`

Agora criamos um modelo SVR. Aqui usamos o [kernel RBF](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel) e definimos os hiperpar√¢metros gamma, C e epsilon como 0.5, 10 e 0.05, respectivamente.

```python
model = SVR(kernel='rbf',gamma=0.5, C=10, epsilon = 0.05)
```

#### Ajustar o modelo nos dados de treinamento [^1]

```python
model.fit(x_train, y_train[:,0])
```

```output
SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.05, gamma=0.5,
    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)
```

#### Fazer previs√µes com o modelo [^1]

```python
y_train_pred = model.predict(x_train).reshape(-1,1)
y_test_pred = model.predict(x_test).reshape(-1,1)

print(y_train_pred.shape, y_test_pred.shape)
```

```output
(1412, 1) (44, 1)
```

Voc√™ construiu seu SVR! Agora precisamos avali√°-lo.

### Avaliar seu modelo [^1]

Para avalia√ß√£o, primeiro escalaremos os dados de volta para nossa escala original. Em seguida, para verificar o desempenho, plotaremos o gr√°fico de s√©ries temporais original e previsto, e tamb√©m imprimiremos o resultado do MAPE.

Escalar a sa√≠da prevista e original:

```python
# Scaling the predictions
y_train_pred = scaler.inverse_transform(y_train_pred)
y_test_pred = scaler.inverse_transform(y_test_pred)

print(len(y_train_pred), len(y_test_pred))
```

```python
# Scaling the original values
y_train = scaler.inverse_transform(y_train)
y_test = scaler.inverse_transform(y_test)

print(len(y_train), len(y_test))
```

#### Verificar desempenho do modelo nos dados de treinamento e teste [^1]

Extra√≠mos os timestamps do conjunto de dados para mostrar no eixo x do nosso gr√°fico. Note que estamos usando os primeiros ```timesteps-1``` valores como entrada para a primeira sa√≠da, ent√£o os timestamps para a sa√≠da come√ßar√£o depois disso.

```python
train_timestamps = energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)].index[timesteps-1:]
test_timestamps = energy[test_start_dt:].index[timesteps-1:]

print(len(train_timestamps), len(test_timestamps))
```

```output
1412 44
```

Plotar as previs√µes para os dados de treinamento:

```python
plt.figure(figsize=(25,6))
plt.plot(train_timestamps, y_train, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(train_timestamps, y_train_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.title("Training data prediction")
plt.show()
```

![previs√£o dos dados de treinamento](../../../../7-TimeSeries/3-SVR/images/train-data-predict.png)

Imprimir MAPE para os dados de treinamento

```python
print('MAPE for training data: ', mape(y_train_pred, y_train)*100, '%')
```

```output
MAPE for training data: 1.7195710200875551 %
```

Plotar as previs√µes para os dados de teste

```python
plt.figure(figsize=(10,3))
plt.plot(test_timestamps, y_test, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(test_timestamps, y_test_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![previs√£o dos dados de teste](../../../../7-TimeSeries/3-SVR/images/test-data-predict.png)

Imprimir MAPE para os dados de teste

```python
print('MAPE for testing data: ', mape(y_test_pred, y_test)*100, '%')
```

```output
MAPE for testing data:  1.2623790187854018 %
```

üèÜ Voc√™ obteve um resultado muito bom no conjunto de dados de teste!

### Verificar desempenho do modelo no conjunto de dados completo [^1]

```python
# Extracting load values as numpy array
data = energy.copy().values

# Scaling
data = scaler.transform(data)

# Transforming to 2D tensor as per model input requirement
data_timesteps=np.array([[j for j in data[i:i+timesteps]] for i in range(0,len(data)-timesteps+1)])[:,:,0]
print("Tensor shape: ", data_timesteps.shape)

# Selecting inputs and outputs from data
X, Y = data_timesteps[:,:timesteps-1],data_timesteps[:,[timesteps-1]]
print("X shape: ", X.shape,"\nY shape: ", Y.shape)
```

```output
Tensor shape:  (26300, 5)
X shape:  (26300, 4) 
Y shape:  (26300, 1)
```

```python
# Make model predictions
Y_pred = model.predict(X).reshape(-1,1)

# Inverse scale and reshape
Y_pred = scaler.inverse_transform(Y_pred)
Y = scaler.inverse_transform(Y)
```

```python
plt.figure(figsize=(30,8))
plt.plot(Y, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(Y_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![previs√£o dos dados completos](../../../../7-TimeSeries/3-SVR/images/full-data-predict.png)

```python
print('MAPE: ', mape(Y_pred, Y)*100, '%')
```

```output
MAPE:  2.0572089029888656 %
```

üèÜ Gr√°ficos muito bons, mostrando um modelo com boa precis√£o. Parab√©ns!

---

## üöÄDesafio

- Tente ajustar os hiperpar√¢metros (gamma, C, epsilon) ao criar o modelo e avalie os dados para ver qual conjunto de hiperpar√¢metros oferece os melhores resultados nos dados de teste. Para saber mais sobre esses hiperpar√¢metros, voc√™ pode consultar o documento [aqui](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel). 
- Tente usar diferentes fun√ß√µes kernel para o modelo e analise seus desempenhos no conjunto de dados. Um documento √∫til pode ser encontrado [aqui](https://scikit-learn.org/stable/modules/svm.html#kernel-functions).
- Tente usar diferentes valores para `timesteps` para que o modelo olhe para tr√°s e fa√ßa previs√µes.

## [Quiz p√≥s-aula](https://ff-quizzes.netlify.app/en/ml/)

## Revis√£o & Autoestudo

Esta li√ß√£o foi para introduzir a aplica√ß√£o do SVR na previs√£o de s√©ries temporais. Para ler mais sobre SVR, voc√™ pode consultar [este blog](https://www.analyticsvidhya.com/blog/2020/03/support-vector-regression-tutorial-for-machine-learning/). Esta [documenta√ß√£o sobre scikit-learn](https://scikit-learn.org/stable/modules/svm.html) fornece uma explica√ß√£o mais abrangente sobre SVMs em geral, [SVRs](https://scikit-learn.org/stable/modules/svm.html#regression) e tamb√©m outros detalhes de implementa√ß√£o, como as diferentes [fun√ß√µes kernel](https://scikit-learn.org/stable/modules/svm.html#kernel-functions) que podem ser usadas e seus par√¢metros.

## Tarefa

[Um novo modelo SVR](assignment.md)

## Cr√©ditos

[^1]: O texto, c√≥digo e sa√≠da nesta se√ß√£o foram contribu√≠dos por [@AnirbanMukherjeeXD](https://github.com/AnirbanMukherjeeXD)  
[^2]: O texto, c√≥digo e sa√≠da nesta se√ß√£o foram retirados de [ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA)

---

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes equivocadas decorrentes do uso desta tradu√ß√£o.