<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "abf86d845c84330bce205a46b382ec88",
  "translation_date": "2025-09-04T21:23:34+00:00",
  "source_file": "2-Regression/4-Logistic/README.md",
  "language_code": "br"
}
-->
# Regress√£o log√≠stica para prever categorias

![Infogr√°fico de regress√£o log√≠stica vs. regress√£o linear](../../../../2-Regression/4-Logistic/images/linear-vs-logistic.png)

## [Quiz pr√©-aula](https://ff-quizzes.netlify.app/en/ml/)

> ### [Esta aula est√° dispon√≠vel em R!](../../../../2-Regression/4-Logistic/solution/R/lesson_4.html)

## Introdu√ß√£o

Nesta √∫ltima aula sobre Regress√£o, uma das t√©cnicas b√°sicas _cl√°ssicas_ de ML, vamos explorar a Regress√£o Log√≠stica. Voc√™ usaria essa t√©cnica para descobrir padr√µes e prever categorias bin√°rias. Este doce √© chocolate ou n√£o? Esta doen√ßa √© contagiosa ou n√£o? Este cliente escolher√° este produto ou n√£o?

Nesta aula, voc√™ aprender√°:

- Uma nova biblioteca para visualiza√ß√£o de dados
- T√©cnicas de regress√£o log√≠stica

‚úÖ Aprofunde seu entendimento sobre como trabalhar com este tipo de regress√£o neste [m√≥dulo de aprendizado](https://docs.microsoft.com/learn/modules/train-evaluate-classification-models?WT.mc_id=academic-77952-leestott)

## Pr√©-requisito

Depois de trabalhar com os dados de ab√≥bora, j√° estamos suficientemente familiarizados para perceber que h√° uma categoria bin√°ria com a qual podemos trabalhar: `Color`.

Vamos construir um modelo de regress√£o log√≠stica para prever, com base em algumas vari√°veis, _qual √© a cor prov√°vel de uma determinada ab√≥bora_ (laranja üéÉ ou branca üëª).

> Por que estamos falando de classifica√ß√£o bin√°ria em uma aula sobre regress√£o? Apenas por conveni√™ncia lingu√≠stica, j√° que a regress√£o log√≠stica √© [na verdade um m√©todo de classifica√ß√£o](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression), embora baseado em linearidade. Aprenda sobre outras formas de classificar dados no pr√≥ximo grupo de aulas.

## Definir a pergunta

Para nossos prop√≥sitos, vamos expressar isso como um bin√°rio: 'Branca' ou 'N√£o Branca'. H√° tamb√©m uma categoria 'listrada' em nosso conjunto de dados, mas h√° poucas inst√¢ncias dela, ent√£o n√£o a utilizaremos. Ela desaparece quando removemos valores nulos do conjunto de dados, de qualquer forma.

> üéÉ Curiosidade: √†s vezes chamamos ab√≥boras brancas de ab√≥boras 'fantasma'. Elas n√£o s√£o muito f√°ceis de esculpir, ent√£o n√£o s√£o t√£o populares quanto as laranjas, mas t√™m uma apar√™ncia interessante! Assim, poder√≠amos reformular nossa pergunta como: 'Fantasma' ou 'N√£o Fantasma'. üëª

## Sobre regress√£o log√≠stica

A regress√£o log√≠stica difere da regress√£o linear, que voc√™ aprendeu anteriormente, em alguns aspectos importantes.

[![ML para iniciantes - Entendendo a Regress√£o Log√≠stica para Classifica√ß√£o de Machine Learning](https://img.youtube.com/vi/KpeCT6nEpBY/0.jpg)](https://youtu.be/KpeCT6nEpBY "ML para iniciantes - Entendendo a Regress√£o Log√≠stica para Classifica√ß√£o de Machine Learning")

> üé• Clique na imagem acima para um breve v√≠deo sobre regress√£o log√≠stica.

### Classifica√ß√£o bin√°ria

A regress√£o log√≠stica n√£o oferece os mesmos recursos que a regress√£o linear. A primeira oferece uma previs√£o sobre uma categoria bin√°ria ("branca ou n√£o branca"), enquanto a segunda √© capaz de prever valores cont√≠nuos, por exemplo, dado a origem de uma ab√≥bora e o tempo de colheita, _quanto seu pre√ßo aumentar√°_.

![Modelo de classifica√ß√£o de ab√≥bora](../../../../2-Regression/4-Logistic/images/pumpkin-classifier.png)
> Infogr√°fico por [Dasani Madipalli](https://twitter.com/dasani_decoded)

### Outras classifica√ß√µes

Existem outros tipos de regress√£o log√≠stica, incluindo multinomial e ordinal:

- **Multinomial**, que envolve mais de uma categoria - "Laranja, Branca e Listrada".
- **Ordinal**, que envolve categorias ordenadas, √∫til se quisermos ordenar nossos resultados logicamente, como nossas ab√≥boras que s√£o ordenadas por um n√∫mero finito de tamanhos (mini, pequeno, m√©dio, grande, extra grande, extra extra grande).

![Regress√£o multinomial vs ordinal](../../../../2-Regression/4-Logistic/images/multinomial-vs-ordinal.png)

### As vari√°veis N√ÉO precisam ser correlacionadas

Lembra como a regress√£o linear funcionava melhor com vari√°veis mais correlacionadas? A regress√£o log√≠stica √© o oposto - as vari√°veis n√£o precisam estar alinhadas. Isso funciona para este conjunto de dados, que tem correla√ß√µes relativamente fracas.

### Voc√™ precisa de muitos dados limpos

A regress√£o log√≠stica fornecer√° resultados mais precisos se voc√™ usar mais dados; nosso pequeno conjunto de dados n√£o √© ideal para esta tarefa, ent√£o tenha isso em mente.

[![ML para iniciantes - An√°lise e Prepara√ß√£o de Dados para Regress√£o Log√≠stica](https://img.youtube.com/vi/B2X4H9vcXTs/0.jpg)](https://youtu.be/B2X4H9vcXTs "ML para iniciantes - An√°lise e Prepara√ß√£o de Dados para Regress√£o Log√≠stica")

> üé• Clique na imagem acima para um breve v√≠deo sobre prepara√ß√£o de dados para regress√£o linear.

‚úÖ Pense nos tipos de dados que se adaptariam bem √† regress√£o log√≠stica.

## Exerc√≠cio - organizar os dados

Primeiro, limpe os dados, removendo valores nulos e selecionando apenas algumas colunas:

1. Adicione o seguinte c√≥digo:

    ```python
  
    columns_to_select = ['City Name','Package','Variety', 'Origin','Item Size', 'Color']
    pumpkins = full_pumpkins.loc[:, columns_to_select]

    pumpkins.dropna(inplace=True)
    ```

    Voc√™ sempre pode dar uma olhada no seu novo dataframe:

    ```python
    pumpkins.info
    ```

### Visualiza√ß√£o - gr√°fico categ√≥rico

Agora voc√™ carregou o [notebook inicial](../../../../2-Regression/4-Logistic/notebook.ipynb) com os dados de ab√≥bora novamente e os limpou para preservar um conjunto de dados contendo algumas vari√°veis, incluindo `Color`. Vamos visualizar o dataframe no notebook usando uma biblioteca diferente: [Seaborn](https://seaborn.pydata.org/index.html), que √© constru√≠da sobre o Matplotlib que usamos anteriormente.

Seaborn oferece algumas maneiras interessantes de visualizar seus dados. Por exemplo, voc√™ pode comparar distribui√ß√µes dos dados para cada `Variety` e `Color` em um gr√°fico categ√≥rico.

1. Crie tal gr√°fico usando a fun√ß√£o `catplot`, com os dados de ab√≥bora `pumpkins`, e especificando um mapeamento de cores para cada categoria de ab√≥bora (laranja ou branca):

    ```python
    import seaborn as sns
    
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }

    sns.catplot(
    data=pumpkins, y="Variety", hue="Color", kind="count",
    palette=palette, 
    )
    ```

    ![Uma grade de dados visualizados](../../../../2-Regression/4-Logistic/images/pumpkins_catplot_1.png)

    Observando os dados, voc√™ pode ver como os dados de `Color` se relacionam com `Variety`.

    ‚úÖ Dado este gr√°fico categ√≥rico, quais s√£o algumas explora√ß√µes interessantes que voc√™ pode imaginar?

### Pr√©-processamento de dados: codifica√ß√£o de caracter√≠sticas e r√≥tulos

Nosso conjunto de dados de ab√≥boras cont√©m valores de string para todas as suas colunas. Trabalhar com dados categ√≥ricos √© intuitivo para humanos, mas n√£o para m√°quinas. Algoritmos de aprendizado de m√°quina funcionam bem com n√∫meros. √â por isso que a codifica√ß√£o √© uma etapa muito importante na fase de pr√©-processamento de dados, pois nos permite transformar dados categ√≥ricos em dados num√©ricos, sem perder nenhuma informa√ß√£o. Uma boa codifica√ß√£o leva √† constru√ß√£o de um bom modelo.

Para codifica√ß√£o de caracter√≠sticas, existem dois tipos principais de codificadores:

1. Codificador ordinal: √© adequado para vari√°veis ordinais, que s√£o vari√°veis categ√≥ricas cujos dados seguem uma ordem l√≥gica, como a coluna `Item Size` em nosso conjunto de dados. Ele cria um mapeamento de forma que cada categoria seja representada por um n√∫mero, que √© a ordem da categoria na coluna.

    ```python
    from sklearn.preprocessing import OrdinalEncoder

    item_size_categories = [['sml', 'med', 'med-lge', 'lge', 'xlge', 'jbo', 'exjbo']]
    ordinal_features = ['Item Size']
    ordinal_encoder = OrdinalEncoder(categories=item_size_categories)
    ```

2. Codificador categ√≥rico: √© adequado para vari√°veis nominais, que s√£o vari√°veis categ√≥ricas cujos dados n√£o seguem uma ordem l√≥gica, como todas as caracter√≠sticas diferentes de `Item Size` em nosso conjunto de dados. √â uma codifica√ß√£o one-hot, o que significa que cada categoria √© representada por uma coluna bin√°ria: a vari√°vel codificada √© igual a 1 se a ab√≥bora pertence √†quela `Variety` e 0 caso contr√°rio.

    ```python
    from sklearn.preprocessing import OneHotEncoder

    categorical_features = ['City Name', 'Package', 'Variety', 'Origin']
    categorical_encoder = OneHotEncoder(sparse_output=False)
    ```

Ent√£o, `ColumnTransformer` √© usado para combinar m√∫ltiplos codificadores em uma √∫nica etapa e aplic√°-los √†s colunas apropriadas.

```python
    from sklearn.compose import ColumnTransformer
    
    ct = ColumnTransformer(transformers=[
        ('ord', ordinal_encoder, ordinal_features),
        ('cat', categorical_encoder, categorical_features)
        ])
    
    ct.set_output(transform='pandas')
    encoded_features = ct.fit_transform(pumpkins)
```

Por outro lado, para codificar o r√≥tulo, usamos a classe `LabelEncoder` do scikit-learn, que √© uma classe utilit√°ria para ajudar a normalizar r√≥tulos de forma que contenham apenas valores entre 0 e n_classes-1 (aqui, 0 e 1).

```python
    from sklearn.preprocessing import LabelEncoder

    label_encoder = LabelEncoder()
    encoded_label = label_encoder.fit_transform(pumpkins['Color'])
```

Depois de codificar as caracter√≠sticas e o r√≥tulo, podemos mescl√°-los em um novo dataframe `encoded_pumpkins`.

```python
    encoded_pumpkins = encoded_features.assign(Color=encoded_label)
```

‚úÖ Quais s√£o as vantagens de usar um codificador ordinal para a coluna `Item Size`?

### Analisar rela√ß√µes entre vari√°veis

Agora que pr√©-processamos nossos dados, podemos analisar as rela√ß√µes entre as caracter√≠sticas e o r√≥tulo para ter uma ideia de qu√£o bem o modelo ser√° capaz de prever o r√≥tulo com base nas caracter√≠sticas. 

A melhor maneira de realizar esse tipo de an√°lise √© plotando os dados. Usaremos novamente a fun√ß√£o `catplot` do Seaborn para visualizar as rela√ß√µes entre `Item Size`, `Variety` e `Color` em um gr√°fico categ√≥rico. Para melhor plotar os dados, usaremos a coluna codificada `Item Size` e a coluna n√£o codificada `Variety`.

```python
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }
    pumpkins['Item Size'] = encoded_pumpkins['ord__Item Size']

    g = sns.catplot(
        data=pumpkins,
        x="Item Size", y="Color", row='Variety',
        kind="box", orient="h",
        sharex=False, margin_titles=True,
        height=1.8, aspect=4, palette=palette,
    )
    g.set(xlabel="Item Size", ylabel="").set(xlim=(0,6))
    g.set_titles(row_template="{row_name}")
```

![Um gr√°fico categ√≥rico de dados visualizados](../../../../2-Regression/4-Logistic/images/pumpkins_catplot_2.png)

### Usar um gr√°fico de dispers√£o

Como `Color` √© uma categoria bin√°ria (Branca ou N√£o), ela precisa de '[uma abordagem especializada](https://seaborn.pydata.org/tutorial/categorical.html?highlight=bar) para visualiza√ß√£o'. Existem outras maneiras de visualizar a rela√ß√£o dessa categoria com outras vari√°veis.

Voc√™ pode visualizar vari√°veis lado a lado com gr√°ficos do Seaborn.

1. Experimente um gr√°fico de dispers√£o ('swarm plot') para mostrar a distribui√ß√£o de valores:

    ```python
    palette = {
    0: 'orange',
    1: 'wheat'
    }
    sns.swarmplot(x="Color", y="ord__Item Size", data=encoded_pumpkins, palette=palette)
    ```

    ![Um gr√°fico de dispers√£o de dados visualizados](../../../../2-Regression/4-Logistic/images/swarm_2.png)

**Aten√ß√£o**: o c√≥digo acima pode gerar um aviso, j√° que o Seaborn pode falhar ao representar uma quantidade t√£o grande de pontos de dados em um gr√°fico de dispers√£o. Uma solu√ß√£o poss√≠vel √© diminuir o tamanho do marcador, usando o par√¢metro 'size'. No entanto, esteja ciente de que isso afeta a legibilidade do gr√°fico.

> **üßÆ Mostre-me a Matem√°tica**
>
> A regress√£o log√≠stica se baseia no conceito de 'm√°xima verossimilhan√ßa' usando [fun√ß√µes sigmoides](https://wikipedia.org/wiki/Sigmoid_function). Uma 'Fun√ß√£o Sigmoide' em um gr√°fico tem a forma de um 'S'. Ela pega um valor e o mapeia para algo entre 0 e 1. Sua curva tamb√©m √© chamada de 'curva log√≠stica'. Sua f√≥rmula √© assim:
>
> ![fun√ß√£o log√≠stica](../../../../2-Regression/4-Logistic/images/sigmoid.png)
>
> onde o ponto m√©dio da sigmoide encontra-se no ponto 0 de x, L √© o valor m√°ximo da curva, e k √© a inclina√ß√£o da curva. Se o resultado da fun√ß√£o for maior que 0.5, o r√≥tulo em quest√£o ser√° atribu√≠do √† classe '1' da escolha bin√°ria. Caso contr√°rio, ser√° classificado como '0'.

## Construir seu modelo

Construir um modelo para encontrar essas classifica√ß√µes bin√°rias √© surpreendentemente simples no Scikit-learn.

[![ML para iniciantes - Regress√£o Log√≠stica para classifica√ß√£o de dados](https://img.youtube.com/vi/MmZS2otPrQ8/0.jpg)](https://youtu.be/MmZS2otPrQ8 "ML para iniciantes - Regress√£o Log√≠stica para classifica√ß√£o de dados")

> üé• Clique na imagem acima para um breve v√≠deo sobre constru√ß√£o de um modelo de regress√£o linear.

1. Selecione as vari√°veis que deseja usar em seu modelo de classifica√ß√£o e divida os conjuntos de treinamento e teste chamando `train_test_split()`:

    ```python
    from sklearn.model_selection import train_test_split
    
    X = encoded_pumpkins[encoded_pumpkins.columns.difference(['Color'])]
    y = encoded_pumpkins['Color']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
    
    ```

2. Agora voc√™ pode treinar seu modelo, chamando `fit()` com seus dados de treinamento, e imprimir o resultado:

    ```python
    from sklearn.metrics import f1_score, classification_report 
    from sklearn.linear_model import LogisticRegression

    model = LogisticRegression()
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)

    print(classification_report(y_test, predictions))
    print('Predicted labels: ', predictions)
    print('F1-score: ', f1_score(y_test, predictions))
    ```

    Veja o desempenho do seu modelo. N√£o est√° ruim, considerando que voc√™ tem apenas cerca de 1000 linhas de dados:

    ```output
                       precision    recall  f1-score   support
    
                    0       0.94      0.98      0.96       166
                    1       0.85      0.67      0.75        33
    
        accuracy                                0.92       199
        macro avg           0.89      0.82      0.85       199
        weighted avg        0.92      0.92      0.92       199
    
        Predicted labels:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0
        0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
        1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0
        0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0
        0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
        0 0 0 1 0 0 0 0 0 0 0 0 1 1]
        F1-score:  0.7457627118644068
    ```

## Melhor compreens√£o via uma matriz de confus√£o

Embora voc√™ possa obter um relat√≥rio de desempenho [termos](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html?highlight=classification_report#sklearn.metrics.classification_report) imprimindo os itens acima, talvez consiga entender seu modelo mais facilmente usando uma [matriz de confus√£o](https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix) para ajudar a entender como o modelo est√° se saindo.

> üéì Uma '[matriz de confus√£o](https://wikipedia.org/wiki/Confusion_matrix)' (ou 'matriz de erro') √© uma tabela que expressa os verdadeiros vs. falsos positivos e negativos do seu modelo, avaliando assim a precis√£o das previs√µes.

1. Para usar uma matriz de confus√£o, chame `confusion_matrix()`:

    ```python
    from sklearn.metrics import confusion_matrix
    confusion_matrix(y_test, predictions)
    ```

    Veja a matriz de confus√£o do seu modelo:

    ```output
    array([[162,   4],
           [ 11,  22]])
    ```

No Scikit-learn, as linhas (eixo 0) s√£o os r√≥tulos reais e as colunas (eixo 1) s√£o os r√≥tulos previstos.

|       |   0   |   1   |
| :---: | :---: | :---: |
|   0   |  TN   |  FP   |
|   1   |  FN   |  TP   |

O que est√° acontecendo aqui? Digamos que nosso modelo seja solicitado a classificar ab√≥boras entre duas categorias bin√°rias, categoria 'branca' e categoria 'n√£o branca'.

- Se seu modelo prev√™ uma ab√≥bora como n√£o branca e ela pertence √† categoria 'n√£o branca' na realidade, chamamos isso de verdadeiro negativo, mostrado pelo n√∫mero no canto superior esquerdo.
- Se seu modelo prev√™ uma ab√≥bora como branca e ela pertence √† categoria 'n√£o branca' na realidade, chamamos isso de falso negativo, mostrado pelo n√∫mero no canto inferior esquerdo.
- Se seu modelo prev√™ uma ab√≥bora como n√£o branca e ela pertence √† categoria 'branca' na realidade, chamamos isso de falso positivo, mostrado pelo n√∫mero no canto superior direito.
- Se seu modelo prev√™ uma ab√≥bora como branca e ela pertence √† categoria 'branca' na realidade, chamamos isso de verdadeiro positivo, mostrado pelo n√∫mero no canto inferior direito.

Como voc√™ deve ter imaginado, √© prefer√≠vel ter um n√∫mero maior de verdadeiros positivos e verdadeiros negativos e um n√∫mero menor de falsos positivos e falsos negativos, o que implica que o modelo est√° se saindo melhor.
Como a matriz de confus√£o se relaciona com precis√£o e recall? Lembre-se, o relat√≥rio de classifica√ß√£o mostrado acima indicou precis√£o (0,85) e recall (0,67).

Precis√£o = tp / (tp + fp) = 22 / (22 + 4) = 0,8461538461538461

Recall = tp / (tp + fn) = 22 / (22 + 11) = 0,6666666666666666

‚úÖ P: De acordo com a matriz de confus√£o, como o modelo se saiu? R: N√£o foi ruim; h√° um bom n√∫mero de verdadeiros negativos, mas tamb√©m alguns falsos negativos.

Vamos revisitar os termos que vimos anteriormente com a ajuda do mapeamento de TP/TN e FP/FN na matriz de confus√£o:

üéì Precis√£o: TP/(TP + FP) A fra√ß√£o de inst√¢ncias relevantes entre as inst√¢ncias recuperadas (ex.: quais r√≥tulos foram bem rotulados)

üéì Recall: TP/(TP + FN) A fra√ß√£o de inst√¢ncias relevantes que foram recuperadas, independentemente de estarem bem rotuladas ou n√£o

üéì f1-score: (2 * precis√£o * recall)/(precis√£o + recall) Uma m√©dia ponderada entre precis√£o e recall, sendo o melhor 1 e o pior 0

üéì Suporte: O n√∫mero de ocorr√™ncias de cada r√≥tulo recuperado

üéì Precis√£o geral: (TP + TN)/(TP + TN + FP + FN) A porcentagem de r√≥tulos previstos corretamente para uma amostra.

üéì M√©dia Macro: O c√°lculo das m√©tricas m√©dias n√£o ponderadas para cada r√≥tulo, sem levar em conta o desequil√≠brio entre os r√≥tulos.

üéì M√©dia Ponderada: O c√°lculo das m√©tricas m√©dias para cada r√≥tulo, levando em conta o desequil√≠brio entre os r√≥tulos ao ponder√°-los pelo suporte (o n√∫mero de inst√¢ncias verdadeiras para cada r√≥tulo).

‚úÖ Voc√™ consegue pensar em qual m√©trica deve observar se quiser que seu modelo reduza o n√∫mero de falsos negativos?

## Visualizar a curva ROC deste modelo

[![ML para iniciantes - Analisando o desempenho da regress√£o log√≠stica com curvas ROC](https://img.youtube.com/vi/GApO575jTA0/0.jpg)](https://youtu.be/GApO575jTA0 "ML para iniciantes - Analisando o desempenho da regress√£o log√≠stica com curvas ROC")

> üé• Clique na imagem acima para um breve v√≠deo sobre curvas ROC

Vamos fazer mais uma visualiza√ß√£o para ver a chamada curva 'ROC':

```python
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline

y_scores = model.predict_proba(X_test)
fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])

fig = plt.figure(figsize=(6, 6))
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.show()
```

Usando Matplotlib, plote a [Curva Caracter√≠stica de Opera√ß√£o do Receptor](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html?highlight=roc) ou ROC do modelo. As curvas ROC s√£o frequentemente usadas para visualizar o desempenho de um classificador em termos de seus verdadeiros positivos versus falsos positivos. "As curvas ROC geralmente apresentam a taxa de verdadeiros positivos no eixo Y e a taxa de falsos positivos no eixo X." Assim, a inclina√ß√£o da curva e o espa√ßo entre a linha do ponto m√©dio e a curva s√£o importantes: voc√™ quer uma curva que rapidamente suba e ultrapasse a linha. No nosso caso, h√° falsos positivos no in√≠cio, e ent√£o a linha sobe e ultrapassa adequadamente:

![ROC](../../../../2-Regression/4-Logistic/images/ROC_2.png)

Por fim, use a API [`roc_auc_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html?highlight=roc_auc#sklearn.metrics.roc_auc_score) do Scikit-learn para calcular a '√Årea Sob a Curva' (AUC):

```python
auc = roc_auc_score(y_test,y_scores[:,1])
print(auc)
```
O resultado √© `0.9749908725812341`. Dado que o AUC varia de 0 a 1, voc√™ quer um valor alto, j√° que um modelo que √© 100% correto em suas previs√µes ter√° um AUC de 1; neste caso, o modelo est√° _muito bom_.

Em futuras li√ß√µes sobre classifica√ß√µes, voc√™ aprender√° como iterar para melhorar os resultados do seu modelo. Mas, por enquanto, parab√©ns! Voc√™ concluiu estas li√ß√µes sobre regress√£o!

---
## üöÄDesafio

H√° muito mais para explorar sobre regress√£o log√≠stica! Mas a melhor maneira de aprender √© experimentando. Encontre um conjunto de dados que se preste a este tipo de an√°lise e construa um modelo com ele. O que voc√™ aprende? dica: experimente [Kaggle](https://www.kaggle.com/search?q=logistic+regression+datasets) para conjuntos de dados interessantes.

## [Quiz p√≥s-aula](https://ff-quizzes.netlify.app/en/ml/)

## Revis√£o & Autoestudo

Leia as primeiras p√°ginas [deste artigo de Stanford](https://web.stanford.edu/~jurafsky/slp3/5.pdf) sobre alguns usos pr√°ticos da regress√£o log√≠stica. Pense em tarefas que s√£o mais adequadas para um ou outro tipo de regress√£o entre as que estudamos at√© agora. O que funcionaria melhor?

## Tarefa 

[Repetindo esta regress√£o](assignment.md)

---

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes equivocadas decorrentes do uso desta tradu√ß√£o.