{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "lesson_12-R.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "ir",
   "display_name": "R"
  },
  "language_info": {
   "name": "R"
  },
  "coopTranslator": {
   "original_hash": "fab50046ca413a38939d579f8432274f",
   "translation_date": "2025-09-06T12:32:33+00:00",
   "source_file": "4-Classification/3-Classifiers-2/solution/R/lesson_12-R.ipynb",
   "language_code": "no"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsFutf_ygqSx"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HD54bEefgtNO"
   },
   "source": [
    "## Klassifisering av matretter 2\n",
    "\n",
    "I denne andre leksjonen om klassifisering skal vi utforske `flere m√•ter` √• klassifisere kategoriske data p√•. Vi skal ogs√• l√¶re om konsekvensene ved √• velge √©n klassifikator fremfor en annen.\n",
    "\n",
    "### [**Quiz f√∏r forelesning**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/23/)\n",
    "\n",
    "### **Forutsetninger**\n",
    "\n",
    "Vi antar at du har fullf√∏rt de tidligere leksjonene, siden vi vil bygge videre p√• noen konsepter vi l√¶rte tidligere.\n",
    "\n",
    "For denne leksjonen trenger vi f√∏lgende pakker:\n",
    "\n",
    "-   `tidyverse`: [tidyverse](https://www.tidyverse.org/) er en [samling av R-pakker](https://www.tidyverse.org/packages) som er designet for √• gj√∏re dataanalyse raskere, enklere og mer morsomt!\n",
    "\n",
    "-   `tidymodels`: [tidymodels](https://www.tidymodels.org/) er et [rammeverk med pakker](https://www.tidymodels.org/packages/) for modellering og maskinl√¶ring.\n",
    "\n",
    "-   `themis`: [themis-pakken](https://themis.tidymodels.org/) gir ekstra oppskritt for √• h√•ndtere ubalanserte data.\n",
    "\n",
    "Du kan installere dem slik:\n",
    "\n",
    "`install.packages(c(\"tidyverse\", \"tidymodels\", \"kernlab\", \"themis\", \"ranger\", \"xgboost\", \"kknn\"))`\n",
    "\n",
    "Alternativt kan skriptet nedenfor sjekke om du har de n√∏dvendige pakkene for √• fullf√∏re dette modulen, og installere dem for deg hvis de mangler.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vZ57IuUxgyQt"
   },
   "source": [
    "suppressWarnings(if (!require(\"pacman\"))install.packages(\"pacman\"))\n",
    "\n",
    "pacman::p_load(tidyverse, tidymodels, themis, kernlab, ranger, xgboost, kknn)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z22M-pj4g07x"
   },
   "source": [
    "## **1. Et klassifiseringskart**\n",
    "\n",
    "I v√•r [forrige leksjon](https://github.com/microsoft/ML-For-Beginners/tree/main/4-Classification/2-Classifiers-1) fors√∏kte vi √• besvare sp√∏rsm√•let: hvordan velger vi mellom flere modeller? I stor grad avhenger det av egenskapene til dataene og typen problem vi √∏nsker √• l√∏se (for eksempel klassifisering eller regresjon).\n",
    "\n",
    "Tidligere l√¶rte vi om de ulike alternativene du har n√•r du klassifiserer data ved hjelp av Microsofts jukselapp. Python sitt maskinl√¶ringsrammeverk, Scikit-learn, tilbyr en lignende, men mer detaljert jukselapp som kan hjelpe deg med √• snevre inn dine estimators (et annet begrep for klassifikatorer):\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/map.png\"\n",
    "   width=\"700\"/>\n",
    "   <figcaption></figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1i3xRIVg7vG"
   },
   "source": [
    "> Tips: [bes√∏k dette kartet online](https://scikit-learn.org/stable/tutorial/machine_learning_map/) og klikk langs stien for √• lese dokumentasjonen.\n",
    ">\n",
    "> Referansesiden for [Tidymodels](https://www.tidymodels.org/find/parsnip/#models) gir ogs√• utmerket dokumentasjon om ulike typer modeller.\n",
    "\n",
    "### **Planen** üó∫Ô∏è\n",
    "\n",
    "Dette kartet er veldig nyttig n√•r du har en klar forst√•else av dataene dine, da du kan 'g√•' langs stiene til en beslutning:\n",
    "\n",
    "-   Vi har \\>50 pr√∏ver\n",
    "\n",
    "-   Vi √∏nsker √• forutsi en kategori\n",
    "\n",
    "-   Vi har merket data\n",
    "\n",
    "-   Vi har f√¶rre enn 100K pr√∏ver\n",
    "\n",
    "-   ‚ú® Vi kan velge en Linear SVC\n",
    "\n",
    "-   Hvis det ikke fungerer, siden vi har numeriske data\n",
    "\n",
    "    -   Vi kan pr√∏ve en ‚ú® KNeighbors Classifier\n",
    "\n",
    "        -   Hvis det ikke fungerer, pr√∏v ‚ú® SVC og ‚ú® Ensemble Classifiers\n",
    "\n",
    "Dette er en veldig nyttig sti √• f√∏lge. N√•, la oss komme i gang med [tidymodels](https://www.tidymodels.org/) modelleringsrammeverket: en konsistent og fleksibel samling av R-pakker utviklet for √• oppmuntre til god statistisk praksis üòä.\n",
    "\n",
    "## 2. Del opp dataene og h√•ndter ubalanserte datasett.\n",
    "\n",
    "Fra v√•re tidligere leksjoner l√¶rte vi at det var et sett med vanlige ingredienser p√• tvers av v√•re kj√∏kken. Det var ogs√• en ganske ujevn fordeling i antall kj√∏kken.\n",
    "\n",
    "Vi vil h√•ndtere dette ved √•\n",
    "\n",
    "-   Fjerne de vanligste ingrediensene som skaper forvirring mellom ulike kj√∏kken, ved √• bruke `dplyr::select()`.\n",
    "\n",
    "-   Bruke en `recipe` som forh√•ndsprosesserer dataene for √• gj√∏re dem klare for modellering ved √• bruke en `over-sampling`-algoritme.\n",
    "\n",
    "Vi har allerede sett p√• dette i den forrige leksjonen, s√• dette b√∏r g√• som en lek ü•≥!\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6tj_rN00hClA"
   },
   "source": [
    "# Load the core Tidyverse and Tidymodels packages\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "\n",
    "# Load the original cuisines data\n",
    "df <- read_csv(file = \"https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/data/cuisines.csv\")\n",
    "\n",
    "# Drop id column, rice, garlic and ginger from our original data set\n",
    "df_select <- df %>% \n",
    "  select(-c(1, rice, garlic, ginger)) %>%\n",
    "  # Encode cuisine column as categorical\n",
    "  mutate(cuisine = factor(cuisine))\n",
    "\n",
    "\n",
    "# Create data split specification\n",
    "set.seed(2056)\n",
    "cuisines_split <- initial_split(data = df_select,\n",
    "                                strata = cuisine,\n",
    "                                prop = 0.7)\n",
    "\n",
    "# Extract the data in each split\n",
    "cuisines_train <- training(cuisines_split)\n",
    "cuisines_test <- testing(cuisines_split)\n",
    "\n",
    "# Display distribution of cuisines in the training set\n",
    "cuisines_train %>% \n",
    "  count(cuisine) %>% \n",
    "  arrange(desc(n))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFin5yw3hHb1"
   },
   "source": [
    "### H√•ndtering av ubalanserte data\n",
    "\n",
    "Ubalanserte data har ofte negative effekter p√• modellens ytelse. Mange modeller fungerer best n√•r antallet observasjoner er likt, og har derfor en tendens til √• slite med ubalanserte data.\n",
    "\n",
    "Det finnes hovedsakelig to m√•ter √• h√•ndtere ubalanserte datasett p√•:\n",
    "\n",
    "-   legge til observasjoner i minoritetsklassen: `Over-sampling`, for eksempel ved √• bruke en SMOTE-algoritme som syntetisk genererer nye eksempler av minoritetsklassen ved hjelp av n√¶rmeste naboer til disse tilfellene.\n",
    "\n",
    "-   fjerne observasjoner fra majoritetsklassen: `Under-sampling`\n",
    "\n",
    "I v√•r forrige leksjon demonstrerte vi hvordan man kan h√•ndtere ubalanserte datasett ved hjelp av en `recipe`. En recipe kan betraktes som en plan som beskriver hvilke steg som skal brukes p√• et datasett for √• gj√∏re det klart for dataanalyse. I v√•rt tilfelle √∏nsker vi √• ha en lik fordeling i antallet av v√•re matretter for v√•rt `training set`. La oss sette i gang.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cRzTnHolhLWd"
   },
   "source": [
    "# Load themis package for dealing with imbalanced data\n",
    "library(themis)\n",
    "\n",
    "# Create a recipe for preprocessing training data\n",
    "cuisines_recipe <- recipe(cuisine ~ ., data = cuisines_train) %>%\n",
    "  step_smote(cuisine) \n",
    "\n",
    "# Print recipe\n",
    "cuisines_recipe"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxOQ2ORhhO81"
   },
   "source": [
    "N√• er vi klare til √• trene modeller üë©‚Äçüíªüë®‚Äçüíª!\n",
    "\n",
    "## 3. Utover multinomiale regresjonsmodeller\n",
    "\n",
    "I v√•r forrige leksjon s√• vi p√• multinomiale regresjonsmodeller. La oss utforske noen mer fleksible modeller for klassifisering.\n",
    "\n",
    "### Support Vector Machines\n",
    "\n",
    "I sammenheng med klassifisering er `Support Vector Machines` en maskinl√¶ringsteknikk som pr√∏ver √• finne et *hyperplan* som \"best\" skiller klassene. La oss se p√• et enkelt eksempel:\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/svm.png\"\n",
    "   width=\"300\"/>\n",
    "   <figcaption>https://commons.wikimedia.org/w/index.php?curid=22877598</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4Wsd0vZhXYu"
   },
   "source": [
    "H1~ skiller ikke klassene. H2~ gj√∏r det, men bare med en liten margin. H3~ skiller dem med maksimal margin.\n",
    "\n",
    "#### Line√¶r Support Vector Classifier\n",
    "\n",
    "Support-Vector clustering (SVC) er en del av Support-Vector-maskiner-familien av ML-teknikker. I SVC velges hyperplanet for √• korrekt skille `de fleste` av treningsobservasjonene, men `kan feilkategorisere` noen observasjoner. Ved √• tillate at noen punkter er p√• feil side, blir SVM mer robust mot uteliggere og dermed bedre til √• generalisere til nye data. Parameteren som regulerer denne bruddgrensen kalles `cost`, som har en standardverdi p√• 1 (se `help(\"svm_poly\")`).\n",
    "\n",
    "La oss lage en line√¶r SVC ved √• sette `degree = 1` i en polynomisk SVM-modell.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vJpp6nuChlBz"
   },
   "source": [
    "# Make a linear SVC specification\n",
    "svc_linear_spec <- svm_poly(degree = 1) %>% \n",
    "  set_engine(\"kernlab\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle specification and recipe into a worklow\n",
    "svc_linear_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(svc_linear_spec)\n",
    "\n",
    "# Print out workflow\n",
    "svc_linear_wf"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDs8cWNkhoqu"
   },
   "source": [
    "N√• som vi har samlet forh√•ndsprosesseringsstegene og modellspesifikasjonen i en *arbeidsflyt*, kan vi g√• videre og trene den line√¶re SVC og evaluere resultatene samtidig. For ytelsesm√•linger, la oss lage et m√•lesett som vil evaluere: `accuracy`, `sensitivity`, `Positive Predicted Value` og `F Measure`.\n",
    "\n",
    "> `augment()` vil legge til kolonne(r) for prediksjoner til de gitte dataene.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "81wiqcwuhrnq"
   },
   "source": [
    "# Train a linear SVC model\n",
    "svc_linear_fit <- svc_linear_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "# Create a metric set\n",
    "eval_metrics <- metric_set(ppv, sens, accuracy, f_meas)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "svc_linear_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UFQvHf-huo3"
   },
   "source": [
    "#### St√∏ttevektormaskin\n",
    "\n",
    "St√∏ttevektormaskinen (SVM) er en utvidelse av st√∏ttevektor-klassifiseringen for √• kunne h√•ndtere en ikke-line√¶r grense mellom klassene. I hovedsak bruker SVM-er *kernel-trikset* for √• utvide funksjonsrommet og tilpasse seg ikke-line√¶re relasjoner mellom klassene. En popul√¶r og sv√¶rt fleksibel kjernefunksjon som brukes av SVM-er er *Radial basis function.* La oss se hvordan den vil prestere p√• v√•re data.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-KX4S8mzhzmp"
   },
   "source": [
    "set.seed(2056)\n",
    "\n",
    "# Make an RBF SVM specification\n",
    "svm_rbf_spec <- svm_rbf() %>% \n",
    "  set_engine(\"kernlab\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle specification and recipe into a worklow\n",
    "svm_rbf_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(svm_rbf_spec)\n",
    "\n",
    "\n",
    "# Train an RBF model\n",
    "svm_rbf_fit <- svm_rbf_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "svm_rbf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBFSa7WSh4HQ"
   },
   "source": [
    "Mye bedre ü§©!\n",
    "\n",
    "> ‚úÖ Vennligst se:\n",
    ">\n",
    "> -   [*Support Vector Machines*](https://bradleyboehmke.github.io/HOML/svm.html), Hands-on Machine Learning with R\n",
    ">\n",
    "> -   [*Support Vector Machines*](https://www.statlearning.com/), An Introduction to Statistical Learning with Applications in R\n",
    ">\n",
    "> for videre lesing.\n",
    "\n",
    "### Klassifisering med n√¶rmeste nabo\n",
    "\n",
    "*K*-n√¶rmeste nabo (KNN) er en algoritme der hver observasjon blir forutsagt basert p√• dens *likhet* med andre observasjoner.\n",
    "\n",
    "La oss tilpasse en til dataene v√•re.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k4BxxBcdh9Ka"
   },
   "source": [
    "# Make a KNN specification\n",
    "knn_spec <- nearest_neighbor() %>% \n",
    "  set_engine(\"kknn\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "knn_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(knn_spec)\n",
    "\n",
    "# Train a boosted tree model\n",
    "knn_wf_fit <- knn_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "knn_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaegQseriAcj"
   },
   "source": [
    "Det ser ut til at denne modellen ikke presterer s√• bra. Sannsynligvis vil det √• endre modellens argumenter (se `help(\"nearest_neighbor\")`) forbedre modellens ytelse. S√∏rg for √• teste det ut.\n",
    "\n",
    "> ‚úÖ Vennligst se:\n",
    ">\n",
    "> -   [Hands-on Machine Learning with R](https://bradleyboehmke.github.io/HOML/)\n",
    ">\n",
    "> -   [An Introduction to Statistical Learning with Applications in R](https://www.statlearning.com/)\n",
    ">\n",
    "> for √• l√¶re mer om *K*-Nearest Neighbors klassifikatorer.\n",
    "\n",
    "### Ensemble-klassifikatorer\n",
    "\n",
    "Ensemble-algoritmer fungerer ved √• kombinere flere grunnmodeller for √• produsere en optimal modell enten ved:\n",
    "\n",
    "`bagging`: √• bruke en *gjennomsnittsfunksjon* p√• en samling av grunnmodeller\n",
    "\n",
    "`boosting`: √• bygge en sekvens av modeller som bygger p√• hverandre for √• forbedre prediktiv ytelse.\n",
    "\n",
    "La oss starte med √• pr√∏ve ut en Random Forest-modell, som bygger en stor samling beslutningstr√¶r og deretter bruker en gjennomsnittsfunksjon for √• skape en bedre helhetlig modell.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "49DPoVs6iK1M"
   },
   "source": [
    "# Make a random forest specification\n",
    "rf_spec <- rand_forest() %>% \n",
    "  set_engine(\"ranger\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "rf_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(rf_spec)\n",
    "\n",
    "# Train a random forest model\n",
    "rf_wf_fit <- rf_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "rf_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGVYwC_aiUWc"
   },
   "source": [
    "Godt jobbet üëè!\n",
    "\n",
    "La oss ogs√• eksperimentere med en Boosted Tree-modell.\n",
    "\n",
    "Boosted Tree definerer en ensemblemetode som lager en serie av sekvensielle beslutningstr√¶r der hvert tre avhenger av resultatene fra tidligere tr√¶r i et fors√∏k p√• √• gradvis redusere feilen. Den fokuserer p√• vektene til feilklassifiserte elementer og justerer tilpasningen for neste klassifikator for √• rette opp.\n",
    "\n",
    "Det finnes forskjellige m√•ter √• tilpasse denne modellen p√• (se `help(\"boost_tree\")`). I dette eksempelet skal vi tilpasse Boosted trees via `xgboost`-motoren.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Py1YWo-micWs"
   },
   "source": [
    "# Make a boosted tree specification\n",
    "boost_spec <- boost_tree(trees = 200) %>% \n",
    "  set_engine(\"xgboost\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "boost_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(boost_spec)\n",
    "\n",
    "# Train a boosted tree model\n",
    "boost_wf_fit <- boost_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "boost_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNQnbuejigZM"
   },
   "source": [
    "> ‚úÖ Vennligst se:\n",
    ">\n",
    "> -   [Machine Learning for Social Scientists](https://cimentadaj.github.io/ml_socsci/tree-based-methods.html#random-forests)\n",
    ">\n",
    "> -   [Hands-on Machine Learning with R](https://bradleyboehmke.github.io/HOML/)\n",
    ">\n",
    "> -   [An Introduction to Statistical Learning with Applications in R](https://www.statlearning.com/)\n",
    ">\n",
    "> -   <https://algotech.netlify.app/blog/xgboost/> - Utforsker AdaBoost-modellen, som er et godt alternativ til xgboost.\n",
    ">\n",
    "> for √• l√¶re mer om Ensemble-klassifikatorer.\n",
    "\n",
    "## 4. Ekstra - sammenligne flere modeller\n",
    "\n",
    "Vi har tilpasset ganske mange modeller i denne labben üôå. Det kan bli tidkrevende eller tungvint √• lage mange arbeidsflyter fra ulike sett med forbehandlingsmetoder og/eller spesifikasjoner for modeller, og deretter beregne ytelsesm√•l √©n etter √©n.\n",
    "\n",
    "La oss se om vi kan l√∏se dette ved √• lage en funksjon som tilpasser en liste med arbeidsflyter p√• treningssettet og deretter returnerer ytelsesm√•l basert p√• testsettet. Vi skal bruke `map()` og `map_dfr()` fra [purrr](https://purrr.tidyverse.org/) pakken for √• anvende funksjoner p√• hvert element i en liste.\n",
    "\n",
    "> [`map()`](https://purrr.tidyverse.org/reference/map.html)-funksjoner lar deg erstatte mange for-l√∏kker med kode som b√•de er mer kortfattet og lettere √• lese. Det beste stedet √• l√¶re om [`map()`](https://purrr.tidyverse.org/reference/map.html)-funksjoner er [iterasjonskapitlet](http://r4ds.had.co.nz/iteration.html) i R for data science.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Qzb7LyZnimd2"
   },
   "source": [
    "set.seed(2056)\n",
    "\n",
    "# Create a metric set\n",
    "eval_metrics <- metric_set(ppv, sens, accuracy, f_meas)\n",
    "\n",
    "# Define a function that returns performance metrics\n",
    "compare_models <- function(workflow_list, train_set, test_set){\n",
    "  \n",
    "  suppressWarnings(\n",
    "    # Fit each model to the train_set\n",
    "    map(workflow_list, fit, data = train_set) %>% \n",
    "    # Make predictions on the test set\n",
    "      map_dfr(augment, new_data = test_set, .id = \"model\") %>%\n",
    "    # Select desired columns\n",
    "      select(model, cuisine, .pred_class) %>% \n",
    "    # Evaluate model performance\n",
    "      group_by(model) %>% \n",
    "      eval_metrics(truth = cuisine, estimate = .pred_class) %>% \n",
    "      ungroup()\n",
    "  )\n",
    "  \n",
    "} # End of function"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fwa712sNisDA"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3i4VJOi2iu-a"
   },
   "source": [
    "# Make a list of workflows\n",
    "workflow_list <- list(\n",
    "  \"svc\" = svc_linear_wf,\n",
    "  \"svm\" = svm_rbf_wf,\n",
    "  \"knn\" = knn_wf,\n",
    "  \"random_forest\" = rf_wf,\n",
    "  \"xgboost\" = boost_wf)\n",
    "\n",
    "# Call the function\n",
    "set.seed(2056)\n",
    "perf_metrics <- compare_models(workflow_list = workflow_list, train_set = cuisines_train, test_set = cuisines_test)\n",
    "\n",
    "# Print out performance metrics\n",
    "perf_metrics %>% \n",
    "  group_by(.metric) %>% \n",
    "  arrange(desc(.estimate)) %>% \n",
    "  slice_head(n=7)\n",
    "\n",
    "# Compare accuracy\n",
    "perf_metrics %>% \n",
    "  filter(.metric == \"accuracy\") %>% \n",
    "  arrange(desc(.estimate))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuWK_lEli4nW"
   },
   "source": [
    "[**workflowset**](https://workflowsets.tidymodels.org/) pakken lar brukere lage og enkelt tilpasse et stort antall modeller, men er hovedsakelig designet for √• fungere med resamplingsteknikker som `cross-validation`, en tiln√¶rming vi enn√• ikke har dekket.\n",
    "\n",
    "## **üöÄUtfordring**\n",
    "\n",
    "Hver av disse teknikkene har et stort antall parametere som du kan justere, for eksempel `cost` i SVMs, `neighbors` i KNN, `mtry` (Tilfeldig Valgte Prediktorer) i Random Forest.\n",
    "\n",
    "Unders√∏k standardparametrene for hver av dem og tenk over hva det √• justere disse parameterne vil bety for modellens kvalitet.\n",
    "\n",
    "For √• finne ut mer om en bestemt modell og dens parametere, bruk: `help(\"model\")` f.eks. `help(\"rand_forest\")`\n",
    "\n",
    "> I praksis *estimerer* vi vanligvis de *beste verdiene* for disse ved √• trene mange modeller p√• et `simulert datasett` og m√•le hvor godt alle disse modellene presterer. Denne prosessen kalles **tuning**.\n",
    "\n",
    "### [**Quiz etter forelesning**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/24/)\n",
    "\n",
    "### **Gjennomgang & Selvstudium**\n",
    "\n",
    "Det er mye fagterminologi i disse leksjonene, s√• ta et √∏yeblikk til √• g√• gjennom [denne listen](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) med nyttige begreper!\n",
    "\n",
    "#### TAKK TIL:\n",
    "\n",
    "[`Allison Horst`](https://twitter.com/allison_horst/) for √• lage de fantastiske illustrasjonene som gj√∏r R mer innbydende og engasjerende. Finn flere illustrasjoner i hennes [galleri](https://www.google.com/url?q=https://github.com/allisonhorst/stats-illustrations&sa=D&source=editors&ust=1626380772530000&usg=AOvVaw3zcfyCizFQZpkSLzxiiQEM).\n",
    "\n",
    "[Cassie Breviu](https://www.twitter.com/cassieview) og [Jen Looper](https://www.twitter.com/jenlooper) for √• lage den originale Python-versjonen av dette modulen ‚ô•Ô∏è\n",
    "\n",
    "Lykke til med l√¶ringen,\n",
    "\n",
    "[Eric](https://twitter.com/ericntay), Gold Microsoft Learn Student Ambassador.\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/r_learners_sm.jpeg\"\n",
    "   width=\"569\"/>\n",
    "   <figcaption>Kunstverk av @allison_horst</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Ansvarsfraskrivelse**:  \nDette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi tilstreber n√∏yaktighet, vennligst v√¶r oppmerksom p√• at automatiske oversettelser kan inneholde feil eller un√∏yaktigheter. Det originale dokumentet p√• sitt opprinnelige spr√•k b√∏r anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforst√•elser eller feiltolkninger som oppst√•r ved bruk av denne oversettelsen.\n"
   ]
  }
 ]
}