<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "917dbf890db71a322f306050cb284749",
  "translation_date": "2025-09-05T21:19:25+00:00",
  "source_file": "7-TimeSeries/2-ARIMA/README.md",
  "language_code": "no"
}
-->
# Tidsserieprognoser med ARIMA

I forrige leksjon l칝rte du litt om tidsserieprognoser og lastet inn et datasett som viser svingninger i elektrisk belastning over en tidsperiode.

[![Introduksjon til ARIMA](https://img.youtube.com/vi/IUSk-YDau10/0.jpg)](https://youtu.be/IUSk-YDau10 "Introduksjon til ARIMA")

> 游꿘 Klikk p친 bildet ovenfor for en video: En kort introduksjon til ARIMA-modeller. Eksempelet er gjort i R, men konseptene er universelle.

## [Quiz f칮r leksjonen](https://ff-quizzes.netlify.app/en/ml/)

## Introduksjon

I denne leksjonen vil du oppdage en spesifikk m친te 친 bygge modeller p친 med [ARIMA: *A*uto*R*egressive *I*ntegrated *M*oving *A*verage](https://wikipedia.org/wiki/Autoregressive_integrated_moving_average). ARIMA-modeller er spesielt godt egnet til 친 tilpasse data som viser [ikke-stasjonaritet](https://wikipedia.org/wiki/Stationary_process).

## Generelle konsepter

For 친 kunne jobbe med ARIMA, er det noen konsepter du m친 kjenne til:

- 游꿉 **Stasjonaritet**. Fra et statistisk perspektiv refererer stasjonaritet til data der distribusjonen ikke endres n친r den forskyves i tid. Ikke-stasjon칝re data viser derimot svingninger p친 grunn av trender som m친 transformeres for 친 kunne analyseres. Sesongvariasjoner, for eksempel, kan introdusere svingninger i data og kan elimineres ved en prosess kalt 'sesongdifferensiering'.

- 游꿉 **[Differensiering](https://wikipedia.org/wiki/Autoregressive_integrated_moving_average#Differencing)**. Differensiering av data, igjen fra et statistisk perspektiv, refererer til prosessen med 친 transformere ikke-stasjon칝re data for 친 gj칮re dem stasjon칝re ved 친 fjerne deres ikke-konstante trend. "Differensiering fjerner endringene i niv친et til en tidsserie, eliminerer trend og sesongvariasjoner og stabiliserer dermed gjennomsnittet av tidsserien." [Paper av Shixiong et al](https://arxiv.org/abs/1904.07632)

## ARIMA i konteksten av tidsserier

La oss pakke ut delene av ARIMA for bedre 친 forst친 hvordan det hjelper oss med 친 modellere tidsserier og lage prognoser basert p친 dem.

- **AR - for AutoRegressiv**. Autoregressive modeller, som navnet antyder, ser 'tilbake' i tid for 친 analysere tidligere verdier i dataene dine og gj칮re antakelser om dem. Disse tidligere verdiene kalles 'lags'. Et eksempel kan v칝re data som viser m친nedlige salg av blyanter. Hver m친neds salgssum vil bli betraktet som en 'utviklende variabel' i datasettet. Denne modellen bygges ved at "den utviklende variabelen av interesse regresseres p친 sine egne forsinkede (dvs. tidligere) verdier." [wikipedia](https://wikipedia.org/wiki/Autoregressive_integrated_moving_average)

- **I - for Integrert**. I motsetning til de lignende 'ARMA'-modellene, refererer 'I' i ARIMA til dens *[integrerte](https://wikipedia.org/wiki/Order_of_integration)* aspekt. Dataene blir 'integrert' n친r differensieringstrinn brukes for 친 eliminere ikke-stasjonaritet.

- **MA - for Glidende Gjennomsnitt**. Det [glidende gjennomsnittet](https://wikipedia.org/wiki/Moving-average_model) i denne modellen refererer til utgangsvariabelen som bestemmes ved 친 observere n친v칝rende og tidligere verdier av lags.

Kort oppsummert: ARIMA brukes til 친 lage en modell som passer s친 tett som mulig til den spesielle formen for tidsseriedata.

## 칒velse - bygg en ARIMA-modell

칀pne [_/working_](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA/working)-mappen i denne leksjonen og finn filen [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/7-TimeSeries/2-ARIMA/working/notebook.ipynb).

1. Kj칮r notebooken for 친 laste inn Python-biblioteket `statsmodels`; du trenger dette for ARIMA-modeller.

1. Last inn n칮dvendige biblioteker.

1. Deretter laster du inn flere biblioteker som er nyttige for 친 plotte data:

    ```python
    import os
    import warnings
    import matplotlib.pyplot as plt
    import numpy as np
    import pandas as pd
    import datetime as dt
    import math

    from pandas.plotting import autocorrelation_plot
    from statsmodels.tsa.statespace.sarimax import SARIMAX
    from sklearn.preprocessing import MinMaxScaler
    from common.utils import load_data, mape
    from IPython.display import Image

    %matplotlib inline
    pd.options.display.float_format = '{:,.2f}'.format
    np.set_printoptions(precision=2)
    warnings.filterwarnings("ignore") # specify to ignore warning messages
    ```

1. Last inn data fra `/data/energy.csv`-filen til en Pandas dataframe og ta en titt:

    ```python
    energy = load_data('./data')[['load']]
    energy.head(10)
    ```

1. Plot all tilgjengelig energidata fra januar 2012 til desember 2014. Det b칮r ikke v칝re noen overraskelser, da vi s친 disse dataene i forrige leksjon:

    ```python
    energy.plot(y='load', subplots=True, figsize=(15, 8), fontsize=12)
    plt.xlabel('timestamp', fontsize=12)
    plt.ylabel('load', fontsize=12)
    plt.show()
    ```

    N친, la oss bygge en modell!

### Opprett trenings- og testdatasett

N친 er dataene dine lastet inn, s친 du kan dele dem opp i trenings- og testsett. Du vil trene modellen din p친 treningssettet. Som vanlig, etter at modellen er ferdig trent, vil du evaluere n칮yaktigheten ved hjelp av testsettet. Du m친 s칮rge for at testsettet dekker en senere tidsperiode enn treningssettet for 친 sikre at modellen ikke f친r informasjon fra fremtidige tidsperioder.

1. Tildel en to-m친neders periode fra 1. september til 31. oktober 2014 til treningssettet. Testsettet vil inkludere to-m친neders perioden fra 1. november til 31. desember 2014:

    ```python
    train_start_dt = '2014-11-01 00:00:00'
    test_start_dt = '2014-12-30 00:00:00'
    ```

    Siden disse dataene reflekterer det daglige energiforbruket, er det et sterkt sesongm칮nster, men forbruket er mest likt forbruket i mer nylige dager.

1. Visualiser forskjellene:

    ```python
    energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)][['load']].rename(columns={'load':'train'}) \
        .join(energy[test_start_dt:][['load']].rename(columns={'load':'test'}), how='outer') \
        .plot(y=['train', 'test'], figsize=(15, 8), fontsize=12)
    plt.xlabel('timestamp', fontsize=12)
    plt.ylabel('load', fontsize=12)
    plt.show()
    ```

    ![trenings- og testdata](../../../../7-TimeSeries/2-ARIMA/images/train-test.png)

    Derfor b칮r det v칝re tilstrekkelig 친 bruke et relativt lite tidsvindu for 친 trene dataene.

    > Merk: Siden funksjonen vi bruker for 친 tilpasse ARIMA-modellen bruker in-sample validering under tilpasning, vil vi utelate valideringsdata.

### Forbered dataene for trening

N친 m친 du forberede dataene for trening ved 친 filtrere og skalere dem. Filtrer datasettet ditt for kun 친 inkludere de n칮dvendige tidsperiodene og kolonnene, og skaler dataene for 친 sikre at de projiseres i intervallet 0,1.

1. Filtrer det originale datasettet for kun 친 inkludere de nevnte tidsperiodene per sett og kun inkludere den n칮dvendige kolonnen 'load' pluss datoen:

    ```python
    train = energy.copy()[(energy.index >= train_start_dt) & (energy.index < test_start_dt)][['load']]
    test = energy.copy()[energy.index >= test_start_dt][['load']]

    print('Training data shape: ', train.shape)
    print('Test data shape: ', test.shape)
    ```

    Du kan se formen p친 dataene:

    ```output
    Training data shape:  (1416, 1)
    Test data shape:  (48, 1)
    ```

1. Skaler dataene til 친 v칝re i omr친det (0, 1).

    ```python
    scaler = MinMaxScaler()
    train['load'] = scaler.fit_transform(train)
    train.head(10)
    ```

1. Visualiser de originale vs. skalerte dataene:

    ```python
    energy[(energy.index >= train_start_dt) & (energy.index < test_start_dt)][['load']].rename(columns={'load':'original load'}).plot.hist(bins=100, fontsize=12)
    train.rename(columns={'load':'scaled load'}).plot.hist(bins=100, fontsize=12)
    plt.show()
    ```

    ![original](../../../../7-TimeSeries/2-ARIMA/images/original.png)

    > De originale dataene

    ![skalert](../../../../7-TimeSeries/2-ARIMA/images/scaled.png)

    > De skalerte dataene

1. N친 som du har kalibrert de skalerte dataene, kan du skalere testdataene:

    ```python
    test['load'] = scaler.transform(test)
    test.head()
    ```

### Implementer ARIMA

Det er p친 tide 친 implementere ARIMA! Du vil n친 bruke `statsmodels`-biblioteket som du installerte tidligere.

N친 m친 du f칮lge flere trinn:

   1. Definer modellen ved 친 kalle `SARIMAX()` og sende inn modellparametrene: p, d og q-parametere, samt P, D og Q-parametere.
   2. Forbered modellen for treningsdataene ved 친 kalle fit()-funksjonen.
   3. Lag prognoser ved 친 kalle `forecast()`-funksjonen og spesifisere antall steg (horisonten) som skal prognoseres.

> 游꿉 Hva er alle disse parameterne til? I en ARIMA-modell er det 3 parametere som brukes for 친 modellere de viktigste aspektene ved en tidsserie: sesongvariasjon, trend og st칮y. Disse parameterne er:

`p`: parameteren knyttet til den autoregressive delen av modellen, som inkorporerer *tidligere* verdier.  
`d`: parameteren knyttet til den integrerte delen av modellen, som p친virker mengden *differensiering* (游꿉 husk differensiering 游녡?) som skal brukes p친 en tidsserie.  
`q`: parameteren knyttet til den glidende gjennomsnittsdelen av modellen.

> Merk: Hvis dataene dine har en sesongmessig komponent - som disse dataene har - bruker vi en sesongmessig ARIMA-modell (SARIMA). I s친 fall m친 du bruke et annet sett med parametere: `P`, `D` og `Q`, som beskriver de samme assosiasjonene som `p`, `d` og `q`, men tilsvarer de sesongmessige komponentene i modellen.

1. Start med 친 sette din foretrukne horisontverdi. La oss pr칮ve 3 timer:

    ```python
    # Specify the number of steps to forecast ahead
    HORIZON = 3
    print('Forecasting horizon:', HORIZON, 'hours')
    ```

    칀 velge de beste verdiene for en ARIMA-modells parametere kan v칝re utfordrende, da det er noe subjektivt og tidkrevende. Du kan vurdere 친 bruke en `auto_arima()`-funksjon fra [`pyramid`-biblioteket](https://alkaline-ml.com/pmdarima/0.9.0/modules/generated/pyramid.arima.auto_arima.html).

1. For n친, pr칮v noen manuelle valg for 친 finne en god modell.

    ```python
    order = (4, 1, 0)
    seasonal_order = (1, 1, 0, 24)

    model = SARIMAX(endog=train, order=order, seasonal_order=seasonal_order)
    results = model.fit()

    print(results.summary())
    ```

    En tabell med resultater blir skrevet ut.

Du har bygget din f칮rste modell! N친 m친 vi finne en m친te 친 evaluere den p친.

### Evaluer modellen din

For 친 evaluere modellen din kan du utf칮re den s친kalte `walk forward`-valideringen. I praksis blir tidsseriemodeller re-trent hver gang nye data blir tilgjengelige. Dette lar modellen lage den beste prognosen ved hvert tidssteg.

Start ved begynnelsen av tidsserien med denne teknikken, tren modellen p친 treningsdatasettet. Deretter lager du en prognose for neste tidssteg. Prognosen evalueres mot den kjente verdien. Treningssettet utvides deretter til 친 inkludere den kjente verdien, og prosessen gjentas.

> Merk: Du b칮r holde treningssettets vindu fast for mer effektiv trening, slik at hver gang du legger til en ny observasjon i treningssettet, fjerner du observasjonen fra begynnelsen av settet.

Denne prosessen gir en mer robust estimering av hvordan modellen vil prestere i praksis. Imidlertid kommer det med beregningskostnaden ved 친 lage s친 mange modeller. Dette er akseptabelt hvis dataene er sm친 eller hvis modellen er enkel, men kan v칝re et problem i stor skala.

Walk-forward validering er gullstandarden for evaluering av tidsseriemodeller og anbefales for dine egne prosjekter.

1. F칮rst, opprett et testdatapunkt for hvert HORIZON-steg.

    ```python
    test_shifted = test.copy()

    for t in range(1, HORIZON+1):
        test_shifted['load+'+str(t)] = test_shifted['load'].shift(-t, freq='H')

    test_shifted = test_shifted.dropna(how='any')
    test_shifted.head(5)
    ```

    |            |          | load | load+1 | load+2 |
    | ---------- | -------- | ---- | ------ | ------ |
    | 2014-12-30 | 00:00:00 | 0.33 | 0.29   | 0.27   |
    | 2014-12-30 | 01:00:00 | 0.29 | 0.27   | 0.27   |
    | 2014-12-30 | 02:00:00 | 0.27 | 0.27   | 0.30   |
    | 2014-12-30 | 03:00:00 | 0.27 | 0.30   | 0.41   |
    | 2014-12-30 | 04:00:00 | 0.30 | 0.41   | 0.57   |

    Dataene forskyves horisontalt i henhold til horisontpunktet.

1. Lag prognoser for testdataene dine ved hjelp av denne glidende vindustiln칝rmingen i en l칮kke p친 st칮rrelse med testdatasettets lengde:

    ```python
    %%time
    training_window = 720 # dedicate 30 days (720 hours) for training

    train_ts = train['load']
    test_ts = test_shifted

    history = [x for x in train_ts]
    history = history[(-training_window):]

    predictions = list()

    order = (2, 1, 0)
    seasonal_order = (1, 1, 0, 24)

    for t in range(test_ts.shape[0]):
        model = SARIMAX(endog=history, order=order, seasonal_order=seasonal_order)
        model_fit = model.fit()
        yhat = model_fit.forecast(steps = HORIZON)
        predictions.append(yhat)
        obs = list(test_ts.iloc[t])
        # move the training window
        history.append(obs[0])
        history.pop(0)
        print(test_ts.index[t])
        print(t+1, ': predicted =', yhat, 'expected =', obs)
    ```

    Du kan se treningen foreg친:

    ```output
    2014-12-30 00:00:00
    1 : predicted = [0.32 0.29 0.28] expected = [0.32945389435989236, 0.2900626678603402, 0.2739480752014323]

    2014-12-30 01:00:00
    2 : predicted = [0.3  0.29 0.3 ] expected = [0.2900626678603402, 0.2739480752014323, 0.26812891674127126]

    2014-12-30 02:00:00
    3 : predicted = [0.27 0.28 0.32] expected = [0.2739480752014323, 0.26812891674127126, 0.3025962399283795]
    ```

1. Sammenlign prognosene med den faktiske belastningen:

    ```python
    eval_df = pd.DataFrame(predictions, columns=['t+'+str(t) for t in range(1, HORIZON+1)])
    eval_df['timestamp'] = test.index[0:len(test.index)-HORIZON+1]
    eval_df = pd.melt(eval_df, id_vars='timestamp', value_name='prediction', var_name='h')
    eval_df['actual'] = np.array(np.transpose(test_ts)).ravel()
    eval_df[['prediction', 'actual']] = scaler.inverse_transform(eval_df[['prediction', 'actual']])
    eval_df.head()
    ```

    Output  
    |     |            | timestamp | h   | prediction | actual   |
    | --- | ---------- | --------- | --- | ---------- | -------- |
    | 0   | 2014-12-30 | 00:00:00  | t+1 | 3,008.74   | 3,023.00 |
    | 1   | 2014-12-30 | 01:00:00  | t+1 | 2,955.53   | 2,935.00 |
    | 2   | 2014-12-30 | 02:00:00  | t+1 | 2,900.17   | 2,899.00 |
    | 3   | 2014-12-30 | 03:00:00  | t+1 | 2,917.69   | 2,886.00 |
    | 4   | 2014-12-30 | 04:00:00  | t+1 | 2,946.99   | 2,963.00 |

    Observer prognosen for timebaserte data sammenlignet med den faktiske belastningen. Hvor n칮yaktig er dette?

### Sjekk modellens n칮yaktighet

Sjekk n칮yaktigheten til modellen din ved 친 teste dens gjennomsnittlige absolutte prosentvise feil (MAPE) over alle prognosene.
> **游빑 Vis meg matematikken**
>
> ![MAPE](../../../../7-TimeSeries/2-ARIMA/images/mape.png)
>
> [MAPE](https://www.linkedin.com/pulse/what-mape-mad-msd-time-series-allameh-statistics/) brukes for 친 vise prediksjonsn칮yaktighet som et forhold definert av formelen ovenfor. Forskjellen mellom faktisk og forutsagt deles p친 det faktiske.
>
> "Den absolutte verdien i denne beregningen summeres for hvert prognosert tidspunkt og deles p친 antall tilpassede punkter n." [wikipedia](https://wikipedia.org/wiki/Mean_absolute_percentage_error)
1. Uttrykk ligningen i kode:

    ```python
    if(HORIZON > 1):
        eval_df['APE'] = (eval_df['prediction'] - eval_df['actual']).abs() / eval_df['actual']
        print(eval_df.groupby('h')['APE'].mean())
    ```

1. Beregn MAPE for ett steg:

    ```python
    print('One step forecast MAPE: ', (mape(eval_df[eval_df['h'] == 't+1']['prediction'], eval_df[eval_df['h'] == 't+1']['actual']))*100, '%')
    ```

    MAPE for ett steg:  0.5570581332313952 %

1. Skriv ut MAPE for flertrinnsprognosen:

    ```python
    print('Multi-step forecast MAPE: ', mape(eval_df['prediction'], eval_df['actual'])*100, '%')
    ```

    ```output
    Multi-step forecast MAPE:  1.1460048657704118 %
    ```

    Et lavt tall er best: husk at en prognose med en MAPE p친 10 er feil med 10%.

1. Men som alltid, det er enklere 친 se denne typen n칮yaktighetsm친ling visuelt, s친 la oss plotte det:

    ```python
     if(HORIZON == 1):
        ## Plotting single step forecast
        eval_df.plot(x='timestamp', y=['actual', 'prediction'], style=['r', 'b'], figsize=(15, 8))

    else:
        ## Plotting multi step forecast
        plot_df = eval_df[(eval_df.h=='t+1')][['timestamp', 'actual']]
        for t in range(1, HORIZON+1):
            plot_df['t+'+str(t)] = eval_df[(eval_df.h=='t+'+str(t))]['prediction'].values

        fig = plt.figure(figsize=(15, 8))
        ax = plt.plot(plot_df['timestamp'], plot_df['actual'], color='red', linewidth=4.0)
        ax = fig.add_subplot(111)
        for t in range(1, HORIZON+1):
            x = plot_df['timestamp'][(t-1):]
            y = plot_df['t+'+str(t)][0:len(x)]
            ax.plot(x, y, color='blue', linewidth=4*math.pow(.9,t), alpha=math.pow(0.8,t))

        ax.legend(loc='best')

    plt.xlabel('timestamp', fontsize=12)
    plt.ylabel('load', fontsize=12)
    plt.show()
    ```

    ![en tidsseriemodell](../../../../7-TimeSeries/2-ARIMA/images/accuracy.png)

游끥 Et veldig fint plot som viser en modell med god n칮yaktighet. Bra jobbet!

---

## 游Utfordring

Utforsk m친ter 친 teste n칮yaktigheten til en tidsseriemodell. Vi ber칮rer MAPE i denne leksjonen, men finnes det andre metoder du kan bruke? Unders칮k dem og kommenter dem. Et nyttig dokument kan finnes [her](https://otexts.com/fpp2/accuracy.html)

## [Quiz etter leksjonen](https://ff-quizzes.netlify.app/en/ml/)

## Gjennomgang & Selvstudium

Denne leksjonen ber칮rer kun det grunnleggende innen tidsserieprognoser med ARIMA. Ta deg tid til 친 utdype kunnskapen din ved 친 utforske [dette repositoriet](https://microsoft.github.io/forecasting/) og dets ulike modelltyper for 친 l칝re andre m친ter 친 bygge tidsseriemodeller p친.

## Oppgave

[En ny ARIMA-modell](assignment.md)

---

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi tilstreber n칮yaktighet, vennligst v칝r oppmerksom p친 at automatiske oversettelser kan inneholde feil eller un칮yaktigheter. Det originale dokumentet p친 sitt opprinnelige spr친k b칮r anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforst친elser eller feiltolkninger som oppst친r ved bruk av denne oversettelsen.