# í˜¸í…” ë¦¬ë·°ë¥¼ í†µí•œ ê°ì • ë¶„ì„ - ë°ì´í„° ì²˜ë¦¬

ì´ ì„¹ì…˜ì—ì„œëŠ” ì´ì „ ê°•ì˜ì—ì„œ ë°°ìš´ ê¸°ìˆ ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ëŒ€ê·œëª¨ ë°ì´í„°ì…‹ì„ íƒìƒ‰ì ìœ¼ë¡œ ë¶„ì„í•  ê²ƒì…ë‹ˆë‹¤. ë‹¤ì–‘í•œ ì—´ì˜ ìœ ìš©ì„±ì„ ì˜ ì´í•´í•œ í›„ì—ëŠ” ë‹¤ìŒì„ ë°°ìš°ê²Œ ë©ë‹ˆë‹¤:

- ë¶ˆí•„ìš”í•œ ì—´ì„ ì œê±°í•˜ëŠ” ë°©ë²•
- ê¸°ì¡´ ì—´ì„ ê¸°ë°˜ìœ¼ë¡œ ìƒˆë¡œìš´ ë°ì´í„°ë¥¼ ê³„ì‚°í•˜ëŠ” ë°©ë²•
- ìµœì¢… ë„ì „ì— ì‚¬ìš©í•  ê²°ê³¼ ë°ì´í„°ì…‹ì„ ì €ì¥í•˜ëŠ” ë°©ë²•

## [ê°•ì˜ ì „ í€´ì¦ˆ](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/37/)

### ì†Œê°œ

ì§€ê¸ˆê¹Œì§€ í…ìŠ¤íŠ¸ ë°ì´í„°ê°€ ìˆ«ì ë°ì´í„°ì™€ëŠ” ìƒë‹¹íˆ ë‹¤ë¥´ë‹¤ëŠ” ê²ƒì„ ë°°ì› ìŠµë‹ˆë‹¤. ì‚¬ëŒì´ ì‘ì„±í•˜ê±°ë‚˜ ë§í•œ í…ìŠ¤íŠ¸ëŠ” íŒ¨í„´ê³¼ ë¹ˆë„, ê°ì • ë° ì˜ë¯¸ë¥¼ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë²ˆ ê°•ì˜ì—ì„œëŠ” ì‹¤ì œ ë°ì´í„°ì…‹ê³¼ ì‹¤ì œ ë„ì „ì„ ë‹¤ë£¨ê²Œ ë©ë‹ˆë‹¤: **[ìœ ëŸ½ì˜ 515K í˜¸í…” ë¦¬ë·° ë°ì´í„°](https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe)** ë° [CC0: Public Domain ë¼ì´ì„ ìŠ¤](https://creativecommons.org/publicdomain/zero/1.0/)ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ ë°ì´í„°ëŠ” Booking.comì—ì„œ ê³µê°œ ì†ŒìŠ¤ë¥¼ í†µí•´ ìˆ˜ì§‘ë˜ì—ˆìŠµë‹ˆë‹¤. ë°ì´í„°ì…‹ì˜ ì‘ì„±ìëŠ” Jiashen Liuì…ë‹ˆë‹¤.

### ì¤€ë¹„

ë‹¤ìŒì´ í•„ìš”í•©ë‹ˆë‹¤:

* Python 3ì„ ì‚¬ìš©í•˜ì—¬ .ipynb ë…¸íŠ¸ë¶ì„ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ëŠ¥ë ¥
* pandas
* NLTK, [ë¡œì»¬ì— ì„¤ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤](https://www.nltk.org/install.html)
* Kaggleì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë°ì´í„°ì…‹ [ìœ ëŸ½ì˜ 515K í˜¸í…” ë¦¬ë·° ë°ì´í„°](https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe). ì••ì¶•ì„ í’€ë©´ ì•½ 230 MBì…ë‹ˆë‹¤. ì´ë¥¼ NLP ê°•ì˜ì™€ ê´€ë ¨ëœ ë£¨íŠ¸ `/data` í´ë”ì— ë‹¤ìš´ë¡œë“œí•˜ì‹­ì‹œì˜¤.

## íƒìƒ‰ì  ë°ì´í„° ë¶„ì„

ì´ ë„ì „ ê³¼ì œëŠ” ê°ì • ë¶„ì„ê³¼ ì†ë‹˜ ë¦¬ë·° ì ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í˜¸í…” ì¶”ì²œ ë´‡ì„ êµ¬ì¶•í•˜ëŠ” ê²ƒì„ ê°€ì •í•©ë‹ˆë‹¤. ì‚¬ìš©í•  ë°ì´í„°ì…‹ì—ëŠ” 6ê°œ ë„ì‹œì˜ 1493ê°œ í˜¸í…”ì— ëŒ€í•œ ë¦¬ë·°ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤.

Python, í˜¸í…” ë¦¬ë·° ë°ì´í„°ì…‹ ë° NLTKì˜ ê°ì • ë¶„ì„ì„ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒì„ ì•Œì•„ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤:

* ë¦¬ë·°ì—ì„œ ê°€ì¥ ìì£¼ ì‚¬ìš©ë˜ëŠ” ë‹¨ì–´ì™€ êµ¬ëŠ” ë¬´ì—‡ì¸ê°€?
* í˜¸í…”ì„ ì„¤ëª…í•˜ëŠ” ê³µì‹ *íƒœê·¸*ê°€ ë¦¬ë·° ì ìˆ˜ì™€ ìƒê´€ê´€ê³„ê°€ ìˆëŠ”ê°€? (ì˜ˆ: íŠ¹ì • í˜¸í…”ì— ëŒ€í•œ ë” ë¶€ì •ì ì¸ ë¦¬ë·°ê°€ *ì–´ë¦° ìë…€ë¥¼ ë‘” ê°€ì¡±*ë³´ë‹¤ *ì†”ë¡œ ì—¬í–‰ì*ì—ê²Œ ë” ë§ì€ê°€? ì´ëŠ” *ì†”ë¡œ ì—¬í–‰ì*ì—ê²Œ ë” ì í•©í•˜ë‹¤ëŠ” ê²ƒì„ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.)
* NLTK ê°ì • ì ìˆ˜ê°€ í˜¸í…” ë¦¬ë·°ì–´ì˜ ìˆ«ì ì ìˆ˜ì™€ 'ì¼ì¹˜'í•˜ëŠ”ê°€?

#### ë°ì´í„°ì…‹

ë‹¤ìš´ë¡œë“œí•˜ì—¬ ë¡œì»¬ì— ì €ì¥í•œ ë°ì´í„°ì…‹ì„ íƒìƒ‰í•´ ë´…ì‹œë‹¤. VS Codeë‚˜ Excelê³¼ ê°™ì€ í¸ì§‘ê¸°ì—ì„œ íŒŒì¼ì„ ì—´ì–´ë³´ì„¸ìš”.

ë°ì´í„°ì…‹ì˜ í—¤ë”ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

*Hotel_Address, Additional_Number_of_Scoring, Review_Date, Average_Score, Hotel_Name, Reviewer_Nationality, Negative_Review, Review_Total_Negative_Word_Counts, Total_Number_of_Reviews, Positive_Review, Review_Total_Positive_Word_Counts, Total_Number_of_Reviews_Reviewer_Has_Given, Reviewer_Score, Tags, days_since_review, lat, lng*

ì—¬ê¸°ì—ëŠ” ë” ì‰½ê²Œ ê²€í† í•  ìˆ˜ ìˆë„ë¡ ê·¸ë£¹í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤: 
##### í˜¸í…” ì—´

* `Hotel_Name`, `Hotel_Address`, `lat` (ìœ„ë„), `lng` (ê²½ë„)
  * *lat*ê³¼ *lng*ë¥¼ ì‚¬ìš©í•˜ì—¬ Pythonìœ¼ë¡œ í˜¸í…” ìœ„ì¹˜ë¥¼ ë³´ì—¬ì£¼ëŠ” ì§€ë„ë¥¼ ê·¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤ (ë¶€ì •ì  ë° ê¸ì •ì  ë¦¬ë·°ì— ë”°ë¼ ìƒ‰ìƒì„ êµ¬ë¶„í•  ìˆ˜ ìˆìŒ)
  * Hotel_AddressëŠ” ìš°ë¦¬ì—ê²Œ ëª…í™•íˆ ìœ ìš©í•˜ì§€ ì•Šìœ¼ë©°, ë” ì‰¬ìš´ ì •ë ¬ ë° ê²€ìƒ‰ì„ ìœ„í•´ êµ­ê°€ë¡œ ëŒ€ì²´í•  ê°€ëŠ¥ì„±ì´ í½ë‹ˆë‹¤.

**í˜¸í…” ë©”íƒ€ ë¦¬ë·° ì—´**

* `Average_Score`
  * ë°ì´í„°ì…‹ ì‘ì„±ìì— ë”°ë¥´ë©´, ì´ ì—´ì€ *ì§€ë‚œ 1ë…„ ë™ì•ˆì˜ ìµœì‹  ëŒ“ê¸€ì„ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°ëœ í˜¸í…”ì˜ í‰ê·  ì ìˆ˜*ì…ë‹ˆë‹¤. ì´ëŠ” ì ìˆ˜ë¥¼ ê³„ì‚°í•˜ëŠ” ë…íŠ¹í•œ ë°©ë²•ì²˜ëŸ¼ ë³´ì´ì§€ë§Œ, ì§€ê¸ˆì€ ë°ì´í„°ë¥¼ ì•¡ë©´ ê·¸ëŒ€ë¡œ ë°›ì•„ë“¤ì—¬ì•¼ í•©ë‹ˆë‹¤.
  
  âœ… ì´ ë°ì´í„°ì˜ ë‹¤ë¥¸ ì—´ì„ ê¸°ë°˜ìœ¼ë¡œ í‰ê·  ì ìˆ˜ë¥¼ ê³„ì‚°í•  ë‹¤ë¥¸ ë°©ë²•ì„ ìƒê°í•´ ë³¼ ìˆ˜ ìˆë‚˜ìš”?

* `Total_Number_of_Reviews`
  * ì´ í˜¸í…”ì´ ë°›ì€ ì´ ë¦¬ë·° ìˆ˜ - ì½”ë“œ ì‘ì„± ì—†ì´ ì´ ë°ì´í„°ì…‹ì˜ ë¦¬ë·°ë¥¼ ì˜ë¯¸í•˜ëŠ”ì§€ ëª…í™•í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
* `Additional_Number_of_Scoring`
  * ì´ëŠ” ë¦¬ë·°ì–´ê°€ ê¸ì •ì  ë˜ëŠ” ë¶€ì •ì  ë¦¬ë·°ë¥¼ ì‘ì„±í•˜ì§€ ì•Šì•˜ì§€ë§Œ ì ìˆ˜ë¥¼ ë¶€ì—¬í•œ ê²ƒì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

**ë¦¬ë·° ì—´**

- `Reviewer_Score`
  - ì´ëŠ” ìµœì†Œ 1ìë¦¬ ì†Œìˆ˜ì ìœ¼ë¡œ ëœ ìˆ«ì ê°’ì´ë©°, ìµœì†Œê°’ê³¼ ìµœëŒ€ê°’ì€ 2.5ì™€ 10 ì‚¬ì´ì…ë‹ˆë‹¤.
  - 2.5ê°€ ê°€ëŠ¥í•œ ìµœì € ì ìˆ˜ì¸ ì´ìœ ëŠ” ì„¤ëª…ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.
- `Negative_Review`
  - ë¦¬ë·°ì–´ê°€ ì•„ë¬´ê²ƒë„ ì‘ì„±í•˜ì§€ ì•Šì•˜ë‹¤ë©´, ì´ í•„ë“œëŠ” "**No Negative**"ë¡œ í‘œì‹œë©ë‹ˆë‹¤.
  - ë¦¬ë·°ì–´ê°€ ë¶€ì •ì  ë¦¬ë·° ì¹¸ì— ê¸ì •ì  ë¦¬ë·°ë¥¼ ì‘ì„±í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤ (ì˜ˆ: "ì´ í˜¸í…”ì— ë‚˜ìœ ì ì´ ì—†ìŠµë‹ˆë‹¤").
- `Review_Total_Negative_Word_Counts`
  - ë¶€ì •ì  ë‹¨ì–´ ìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ì ìˆ˜ê°€ ë‚®ì•„ì§‘ë‹ˆë‹¤ (ê°ì •ì„ í™•ì¸í•˜ì§€ ì•Šì€ ê²½ìš°).
- `Positive_Review`
  - ë¦¬ë·°ì–´ê°€ ì•„ë¬´ê²ƒë„ ì‘ì„±í•˜ì§€ ì•Šì•˜ë‹¤ë©´, ì´ í•„ë“œëŠ” "**No Positive**"ë¡œ í‘œì‹œë©ë‹ˆë‹¤.
  - ë¦¬ë·°ì–´ê°€ ê¸ì •ì  ë¦¬ë·° ì¹¸ì— ë¶€ì •ì  ë¦¬ë·°ë¥¼ ì‘ì„±í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤ (ì˜ˆ: "ì´ í˜¸í…”ì—ëŠ” ì¢‹ì€ ì ì´ ì „í˜€ ì—†ìŠµë‹ˆë‹¤").
- `Review_Total_Positive_Word_Counts`
  - ê¸ì •ì  ë‹¨ì–´ ìˆ˜ê°€ ë§ì„ìˆ˜ë¡ ì ìˆ˜ê°€ ë†’ì•„ì§‘ë‹ˆë‹¤ (ê°ì •ì„ í™•ì¸í•˜ì§€ ì•Šì€ ê²½ìš°).
- `Review_Date` ë° `days_since_review`
  - ì‹ ì„ ë„ ë˜ëŠ” ì˜¤ë˜ëœ ë¦¬ë·°ì— ëŒ€í•œ ì¸¡ì •ì„ ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤ (í˜¸í…” ê´€ë¦¬ê°€ ë³€ê²½ë˜ì—ˆê±°ë‚˜, ë¦¬ëª¨ë¸ë§ì´ ì´ë£¨ì–´ì¡Œê±°ë‚˜, ìˆ˜ì˜ì¥ì´ ì¶”ê°€ë˜ì—ˆê¸° ë•Œë¬¸ì— ì˜¤ë˜ëœ ë¦¬ë·°ëŠ” ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ).
- `Tags`
  - ì´ëŠ” ë¦¬ë·°ì–´ê°€ ìì‹ ì´ ì–´ë–¤ ìœ í˜•ì˜ ì†ë‹˜ì´ì—ˆëŠ”ì§€, ì–´ë–¤ ìœ í˜•ì˜ ë°©ì„ ê°€ì¡ŒëŠ”ì§€, ì²´ë¥˜ ê¸°ê°„, ë¦¬ë·°ë¥¼ ì œì¶œí•œ ë°©ë²• ë“±ì„ ì„¤ëª…í•˜ê¸° ìœ„í•´ ì„ íƒí•  ìˆ˜ ìˆëŠ” ì§§ì€ ì„¤ëª…ì…ë‹ˆë‹¤.
  - ë¶ˆí–‰íˆë„, ì´ëŸ¬í•œ íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì€ ë¬¸ì œê°€ ìˆìœ¼ë©°, ì•„ë˜ ì„¹ì…˜ì—ì„œ ê·¸ ìœ ìš©ì„±ì— ëŒ€í•´ ë…¼ì˜í•©ë‹ˆë‹¤.

**ë¦¬ë·°ì–´ ì—´**

- `Total_Number_of_Reviews_Reviewer_Has_Given`
  - ì´ëŠ” ì¶”ì²œ ëª¨ë¸ì—ì„œ ìš”ì¸ì´ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ìˆ˜ë°± ê°œì˜ ë¦¬ë·°ë¥¼ ì‘ì„±í•œ ë” ë§ì€ ë¦¬ë·°ì–´ê°€ ë¶€ì •ì  ë¦¬ë·°ë¥¼ ë‚¨ê¸¸ ê°€ëŠ¥ì„±ì´ ë” ë†’ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤ë©´ ìœ ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ íŠ¹ì • ë¦¬ë·°ì˜ ë¦¬ë·°ì–´ëŠ” ê³ ìœ  ì½”ë“œë¡œ ì‹ë³„ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ ë¦¬ë·° ì„¸íŠ¸ì™€ ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 100ê°œ ì´ìƒì˜ ë¦¬ë·°ë¥¼ ì‘ì„±í•œ ë¦¬ë·°ì–´ê°€ 30ëª… ìˆì§€ë§Œ, ì´ê²ƒì´ ì¶”ì²œ ëª¨ë¸ì— ì–´ë–»ê²Œ ë„ì›€ì´ ë˜ëŠ”ì§€ ë³´ê¸° ì–´ë µìŠµë‹ˆë‹¤.
- `Reviewer_Nationality`
  - ì¼ë¶€ ì‚¬ëŒë“¤ì€ íŠ¹ì • êµ­ì ì´ êµ­ê°€ì  ì„±í–¥ ë•Œë¬¸ì— ê¸ì •ì  ë˜ëŠ” ë¶€ì •ì  ë¦¬ë·°ë¥¼ ë‚¨ê¸¸ ê°€ëŠ¥ì„±ì´ ë” ë†’ë‹¤ê³  ìƒê°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŸ¬í•œ ì¼í™”ì  ê²¬í•´ë¥¼ ëª¨ë¸ì— í¬í•¨í•˜ëŠ” ë° ì£¼ì˜í•´ì•¼ í•©ë‹ˆë‹¤. ì´ëŠ” êµ­ê°€ì (ë•Œë¡œëŠ” ì¸ì¢…ì ) ê³ ì •ê´€ë…ì´ë©°, ê° ë¦¬ë·°ì–´ëŠ” ìì‹ ì˜ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ë¦¬ë·°ë¥¼ ì‘ì„±í•œ ê°œì¸ì…ë‹ˆë‹¤. ê·¸ë“¤ì˜ êµ­ì ì´ ë¦¬ë·° ì ìˆ˜ì˜ ì´ìœ ì˜€ë‹¤ê³  ìƒê°í•˜ëŠ” ê²ƒì€ ì •ë‹¹í™”í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤.

##### ì˜ˆì‹œ

| í‰ê·  ì ìˆ˜ | ì´ ë¦¬ë·° ìˆ˜ | ë¦¬ë·°ì–´ ì ìˆ˜ | ë¶€ì •ì  ë¦¬ë·°                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | ê¸ì •ì  ë¦¬ë·°                 | íƒœê·¸                                                                                      |
| -------------- | ---------------------- | ---------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------- | ----------------------------------------------------------------------------------------- |
| 7.8            | 1945                   | 2.5              | This is  currently not a hotel but a construction site I was terrorized from early  morning and all day with unacceptable building noise while resting after a  long trip and working in the room People were working all day i e with  jackhammers in the adjacent rooms I asked for a room change but no silent  room was available To make things worse I was overcharged I checked out in  the evening since I had to leave very early flight and received an appropriate  bill A day later the hotel made another charge without my consent in excess  of booked price It's a terrible place Don't punish yourself by booking  here | Nothing  Terrible place Stay away | Business trip                                Couple Standard Double  Room Stayed 2 nights |

ë³´ì‹œë‹¤ì‹œí”¼, ì´ ì†ë‹˜ì€ ì´ í˜¸í…”ì—ì„œ í–‰ë³µí•œ ì²´ë¥˜ë¥¼ í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì´ í˜¸í…”ì€ 7.8ì˜ ì¢‹ì€ í‰ê·  ì ìˆ˜ì™€ 1945ê°œì˜ ë¦¬ë·°ë¥¼ ê°€ì§€ê³  ìˆì§€ë§Œ, ì´ ë¦¬ë·°ì–´ëŠ” 2.5ë¥¼ ì£¼ê³  ê·¸ë“¤ì˜ ì²´ë¥˜ê°€ ì–¼ë§ˆë‚˜ ë¶€ì •ì ì´ì—ˆëŠ”ì§€ì— ëŒ€í•´ 115ë‹¨ì–´ë¥¼ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. ê¸ì •ì  ë¦¬ë·° ì¹¸ì— ì•„ë¬´ê²ƒë„ ì‘ì„±í•˜ì§€ ì•Šì•˜ë‹¤ë©´ ê¸ì •ì ì¸ ê²ƒì´ ì—†ë‹¤ê³  ì¶”ì¸¡í•  ìˆ˜ ìˆì§€ë§Œ, ê·¸ë“¤ì€ 7ë‹¨ì–´ë¡œ ê²½ê³ ë¥¼ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. ë‹¨ì–´ì˜ ì˜ë¯¸ë‚˜ ê°ì •ì„ ê³ ë ¤í•˜ì§€ ì•Šê³  ë‹¨ì–´ ìˆ˜ë§Œ ì„¼ë‹¤ë©´, ë¦¬ë·°ì–´ì˜ ì˜ë„ë¥¼ ì™œê³¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ìƒí•˜ê²Œë„, ê·¸ë“¤ì˜ ì ìˆ˜ 2.5ëŠ” í˜¼ë€ìŠ¤ëŸ½ìŠµë‹ˆë‹¤. í˜¸í…” ì²´ë¥˜ê°€ ê·¸ë ‡ê²Œ ë‚˜ë¹´ë‹¤ë©´ ì™œ ì ìˆ˜ë¥¼ ì£¼ì—ˆì„ê¹Œìš”? ë°ì´í„°ì…‹ì„ ìì„¸íˆ ì¡°ì‚¬í•˜ë©´ ê°€ëŠ¥í•œ ìµœì € ì ìˆ˜ê°€ 2.5ì´ë©°, 0ì´ ì•„ë‹ˆë¼ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œ ìµœê³  ì ìˆ˜ëŠ” 10ì…ë‹ˆë‹¤.

##### íƒœê·¸

ìœ„ì—ì„œ ì–¸ê¸‰í–ˆë“¯ì´, ì²˜ìŒì—ëŠ” `Tags`ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì•„ì´ë””ì–´ê°€ íƒ€ë‹¹í•´ ë³´ì…ë‹ˆë‹¤. ë¶ˆí–‰íˆë„ ì´ëŸ¬í•œ íƒœê·¸ëŠ” í‘œì¤€í™”ë˜ì–´ ìˆì§€ ì•Šì•„ì„œ, íŠ¹ì • í˜¸í…”ì—ì„œëŠ” *ì‹±ê¸€ë£¸*, *íŠ¸ìœˆë£¸*, *ë”ë¸”ë£¸* ì˜µì…˜ì´ ìˆì„ ìˆ˜ ìˆì§€ë§Œ, ë‹¤ìŒ í˜¸í…”ì—ì„œëŠ” *ë””ëŸ­ìŠ¤ ì‹±ê¸€ë£¸*, *í´ë˜ì‹ í€¸ë£¸*, *ì´ê·¸ì œíí‹°ë¸Œ í‚¹ë£¸* ì˜µì…˜ì´ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ë™ì¼í•œ ê²ƒì¼ ìˆ˜ ìˆì§€ë§Œ, ë„ˆë¬´ ë§ì€ ë³€í˜•ì´ ìˆì–´ ì„ íƒì´ ì–´ë ¤ì›Œì§‘ë‹ˆë‹¤:

1. ëª¨ë“  ìš©ì–´ë¥¼ ë‹¨ì¼ í‘œì¤€ìœ¼ë¡œ ë³€ê²½í•˜ë ¤ê³  ì‹œë„í•˜ëŠ” ê²ƒ, ì´ëŠ” ê° ê²½ìš°ì— ë³€í™˜ ê²½ë¡œê°€ ëª…í™•í•˜ì§€ ì•Šê¸° ë•Œë¬¸ì— ë§¤ìš° ì–´ë µìŠµë‹ˆë‹¤ (ì˜ˆ: *í´ë˜ì‹ ì‹±ê¸€ë£¸*ì„ *ì‹±ê¸€ë£¸*ìœ¼ë¡œ ë§¤í•‘í•˜ì§€ë§Œ *ì½”íŠ¸ì•¼ë“œ ê°€ë“  ë˜ëŠ” ì‹œí‹° ë·°ê°€ ìˆëŠ” ìŠˆí˜ë¦¬ì–´ í€¸ë£¸*ì€ ë§¤í•‘í•˜ê¸°ê°€ í›¨ì”¬ ì–´ë µìŠµë‹ˆë‹¤).

1. NLP ì ‘ê·¼ ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ ê° í˜¸í…”ì— ì ìš©ë˜ëŠ” *ì†”ë¡œ*, *ë¹„ì¦ˆë‹ˆìŠ¤ ì—¬í–‰ê°*, ë˜ëŠ” *ì–´ë¦° ì•„ì´ê°€ ìˆëŠ” ê°€ì¡±*ê³¼ ê°™ì€ íŠ¹ì • ìš©ì–´ì˜ ë¹ˆë„ë¥¼ ì¸¡ì •í•˜ê³  ì´ë¥¼ ì¶”ì²œì— ë°˜ì˜í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

íƒœê·¸ëŠ” ì¼ë°˜ì ìœ¼ë¡œ (í•­ìƒ ê·¸ë ‡ì§€ëŠ” ì•Šì§€ë§Œ) *ì—¬í–‰ ìœ í˜•*, *ì†ë‹˜ ìœ í˜•*, *ë°© ìœ í˜•*, *ìˆ™ë°• ê¸°ê°„*, ë° *ë¦¬ë·°ë¥¼ ì œì¶œí•œ ì¥ì¹˜ ìœ í˜•*ì— ë§ì¶”ì–´ì§„ 5~6ê°œì˜ ì‰¼í‘œë¡œ êµ¬ë¶„ëœ ê°’ì„ í¬í•¨í•˜ëŠ” ë‹¨ì¼ í•„ë“œì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì¼ë¶€ ë¦¬ë·°ì–´ê°€ ê° í•„ë“œë¥¼ ì±„ìš°ì§€ ì•ŠëŠ” ê²½ìš° (í•˜ë‚˜ë¥¼ ë¹„ì›Œë‘˜ ìˆ˜ ìˆìŒ), ê°’ì€ í•­ìƒ ê°™ì€ ìˆœì„œë¡œ ì œê³µë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

ì˜ˆë¥¼ ë“¤ì–´ *ê·¸ë£¹ ìœ í˜•*ì„ ë³´ì„¸ìš”. `Tags` ì—´ì—ì„œ ì´ í•„ë“œì—ëŠ” 1025ê°œì˜ ê³ ìœ  ê°€ëŠ¥ì„±ì´ ìˆìœ¼ë©°, ë¶ˆí–‰íˆë„ ê·¸ ì¤‘ ì¼ë¶€ë§Œ ê·¸ë£¹ì„ ì°¸ì¡°í•©ë‹ˆë‹¤ (ì¼ë¶€ëŠ” ë°© ìœ í˜• ë“±ì…ë‹ˆë‹¤). ê°€ì¡±ì„ ì–¸ê¸‰í•˜ëŠ” ê²ƒë§Œ í•„í„°ë§í•˜ë©´ ë§ì€ *ê°€ì¡± ë°©* ìœ í˜•ì˜ ê²°ê³¼ê°€ í¬í•¨ë©ë‹ˆë‹¤. *with* ìš©ì–´ë¥¼ í¬í•¨í•˜ë©´, ì¦‰ *ê°€ì¡±ê³¼ í•¨ê»˜* ê°’ì„ ê³„ì‚°í•˜ë©´, "ì–´ë¦° ìë…€ë¥¼ ë‘” ê°€ì¡±" ë˜ëŠ” "ë‚˜ì´ ë“  ìë…€ë¥¼ ë‘” ê°€ì¡±" ë¬¸êµ¬ê°€ í¬í•¨ëœ 80,000ê°œ ì´ìƒì˜ 515,000ê°œ ê²°ê³¼ê°€ ë‚˜ì˜µë‹ˆë‹¤.

ì´ê²ƒì€ íƒœê·¸ ì—´ì´ ì™„ì „íˆ ì“¸ëª¨ì—†ì§€ëŠ” ì•Šì§€ë§Œ, ìœ ìš©í•˜ê²Œ ë§Œë“¤ê¸° ìœ„í•´ì„œëŠ” ì•½ê°„ì˜ ì‘ì—…ì´ í•„ìš”í•¨ì„ ì˜ë¯¸í•©ë‹ˆë‹¤.

##### í˜¸í…” í‰ê·  ì ìˆ˜

ë°ì´í„°ì…‹ì—ëŠ” ì´í•´í•˜ê¸° ì–´ë µì§€ë§Œ ëª¨ë¸ì„ êµ¬ì¶•í•  ë•Œ ì¸ì‹í•´ì•¼ í•˜ëŠ” ëª‡ ê°€ì§€ ì´ìƒ í˜„ìƒ ë˜ëŠ” ë¶ˆì¼ì¹˜ê°€ ìˆìŠµë‹ˆë‹¤. ì´í•´í•˜ê²Œ ë˜ë©´ í† ë¡  ì„¹ì…˜ì—ì„œ ì•Œë ¤ì£¼ì„¸ìš”!

ë°ì´í„°ì…‹ì—ëŠ” í‰ê·  ì ìˆ˜ ë° ë¦¬ë·° ìˆ˜ì™€ ê´€ë ¨ëœ ë‹¤ìŒ ì—´ì´ ìˆìŠµë‹ˆë‹¤:

1. Hotel_Name
2. Additional_Number_of_Scoring
3. Average_Score
4. Total_Number_of_Reviews
5. Reviewer_Score  

ì´ ë°ì´í„°ì…‹ì—ì„œ ê°€ì¥ ë§ì€ ë¦¬ë·°ë¥¼ ê°€ì§„ ë‹¨ì¼ í˜¸í…”ì€ *Britannia International Hotel Canary Wharf*ë¡œ 515,000ê°œì˜ ë¦¬ë·° ì¤‘ 4789ê°œì˜ ë¦¬ë·°ë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ `Total_Number_of_Reviews` ê°’ì´ 9086ì¸ ì´ í˜¸í…”ì„ ë³´ë©´, ë¦¬ë·° ì—†ì´ ì ìˆ˜ë§Œ ìˆëŠ” ê²½ìš°ê°€ ë§ì´ ìˆì„ ìˆ˜ ìˆë‹¤ê³  ì¶”ì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `Additional_Number_of_Scoring` ì—´ ê°’ì„ ì¶”ê°€í•´ì•¼ í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ê·¸ ê°’ì€ 2682ì´ë©°, 4789ì— ì¶”ê°€í•˜ë©´ 7471ì´ ë˜ì–´ `Total_Number_of_Reviews`ì—ì„œ ì—¬ì „íˆ 1615 ë¶€ì¡±í•©ë‹ˆë‹¤.

`Average_Score` ì—´ì„ ë³´ë©´, ë°ì´í„°ì…‹ì˜ ë¦¬ë·° í‰ê· ì¼ ìˆ˜ ìˆë‹¤ê³  ì¶”ì¸¡í•  ìˆ˜ ìˆì§€ë§Œ, Kaggleì˜ ì„¤ëª…ì€ "*ì§€ë‚œ 1ë…„ ë™ì•ˆì˜ ìµœì‹  ëŒ“ê¸€ì„ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°ëœ í˜¸í…”ì˜ í‰ê·  ì ìˆ˜*"ì…ë‹ˆë‹¤. ì´ëŠ” ê·¸ë‹¤ì§€ ìœ ìš©í•´ ë³´ì´ì§€ ì•Šì§€ë§Œ, ë°ì´í„°ì…‹ì˜ ë¦¬ë·° ì ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìì²´ í‰ê· ì„ ê³„ì‚°í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë™ì¼í•œ í˜¸í…”ì„ ì˜ˆë¡œ ë“¤ë©´, í˜¸í…” í‰ê·  ì ìˆ˜ëŠ” 7.1ë¡œ ì£¼ì–´ì¡Œì§€ë§Œ, ë°ì´í„°ì…‹ì—ì„œ ê³„ì‚°ëœ ì ìˆ˜ (ë¦¬ë·°ì–´ ì ìˆ˜ì˜ í‰ê· )ëŠ” 6.8ì…ë‹ˆë‹¤. ì´ëŠ” ë¹„ìŠ·í•˜ì§€ë§Œ ë™ì¼í•œ ê°’ì€ ì•„ë‹ˆë©°, `Additional_Number_of_Scoring` ë¦¬ë·°ì—ì„œ ì œê³µëœ ì ìˆ˜ê°€ í‰ê· ì„ 7.1ë¡œ ì˜¬ë ¸ë‹¤ê³  ì¶”ì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì´ë¥¼ í…ŒìŠ¤íŠ¸í•˜ê±°ë‚˜ ì¦ëª…í•  ë°©ë²•ì´ ì—†ìœ¼ë¯€ë¡œ, `Average_Score`, `Additional_Number_of_Scoring` ë° `Total_Number_of_Reviews`ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ì–´ë µìŠµë‹ˆë‹¤.

ë” ë³µì¡í•˜ê²Œë„, ë‘ ë²ˆì§¸ë¡œ ë§ì€ ë¦¬ë·°ë¥¼ ê°€ì§„ í˜¸í…”ì˜ ê³„ì‚°ëœ í‰ê·  ì ìˆ˜ëŠ” 8.12ì´ê³ , ë°ì´í„°ì…‹ `Average_Score`ëŠ” 8.1ì…ë‹ˆë‹¤. ì´ ì •í™•í•œ ì ìˆ˜ëŠ” ìš°ì—°ì˜ ì¼ì¹˜ì¸ê°€ìš”, ì•„ë‹ˆë©´ ì²« ë²ˆì§¸ í˜¸í…”ì˜ ë¶ˆì¼ì¹˜ì¸ê°€ìš”?

ì´ í˜¸í…”ì´ íŠ¹ì´ì¹˜ì¼ ê°€ëŠ¥ì„±ì„ ê³ ë ¤í•˜ì—¬, ëŒ€ë¶€ë¶„ì˜ ê°’ì´ ì¼ì¹˜í•  ìˆ˜ë„ ìˆì§€ë§Œ (ì–´ë–¤ ì´ìœ ë¡œ ì¼ë¶€ëŠ” ê·¸ë ‡ì§€ ì•ŠìŒ) ë‹¤ìŒìœ¼ë¡œ ë°ì´í„°ì…‹ì˜ ê°’ì„ íƒìƒ‰í•˜ê³  ê°’ì˜ ì˜¬ë°”ë¥¸ ì‚¬ìš© (ë˜ëŠ” ë¹„ì‚¬ìš©)ì„ ê²°ì •í•˜ëŠ” ì§§ì€ í”„ë¡œê·¸ë¨ì„ ì‘ì„±í•  ê²ƒì…ë‹ˆë‹¤.

> ğŸš¨ ì£¼ì˜ ì‚¬í•­
>
> ì´ ë°ì´í„°ì…‹ì„ ì‘ì—…í•  ë•Œ í…ìŠ¤íŠ¸ë¥¼ ì½ê±°ë‚˜ ë¶„ì„í•˜ì§€ ì•Šê³ ë„ í…ìŠ¤íŠ¸ì—ì„œ ë¬´ì–¸ê°€ë¥¼ ê³„ì‚°í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ê²Œ ë  ê²ƒì…ë‹ˆë‹¤. ì´ëŠ” NLPì˜ ë³¸ì§ˆë¡œ, ì‚¬ëŒì´ í•˜ì§€ ì•Šê³ ë„ ì˜ë¯¸ë‚˜ ê°ì •ì„ í•´ì„í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ë¶€ì •ì  ë¦¬ë·°ë¥¼ ì½ì„ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤. ê·¸ë ‡ê²Œ í•˜ì§€ ì•Šê¸°ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤. ì¼ë¶€ëŠ” ì–´ë¦¬ì„ê±°ë‚˜, í˜¸í…”ì˜ í†µì œ ë°–ì˜ ê²ƒë“¤ì— ëŒ€í•œ ë¶€ì ì ˆí•œ ë¶€ì •ì  ë¦¬ë·°ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´ "ë‚ ì”¨ê°€ ì¢‹ì§€ ì•Šì•˜ë‹¤"ëŠ” í˜¸í…”ì´ë‚˜ ê·¸ ëˆ„êµ¬ë„ í†µì œí•  ìˆ˜ ì—†ëŠ” ê²ƒì— ëŒ€í•œ ë¦¬ë·°ì…ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ì¼ë¶€ ë¦¬ë·°ëŠ” ì¸ì¢…ì°¨ë³„ì , ì„±ì°¨ë³„ì , ì—°ë ¹ì°¨ë³„ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ëŠ” ë¶ˆí–‰í•˜ì§€ë§Œ ê³µê°œ ì›¹ì‚¬ì´íŠ¸ì—ì„œ ìˆ˜ì§‘ëœ ë°ì´í„°ì…‹ì—ì„œ ì˜ˆìƒí•  ìˆ˜ ìˆëŠ” ì¼ì…ë‹ˆë‹¤. ì¼ë¶€ ë¦¬ë·°ì–´ëŠ” ë¶ˆì¾Œí•˜ê±°ë‚˜ ë¶ˆí¸í•˜ê±°ë‚˜ í™”ë‚˜ê²Œ í•  ìˆ˜ ìˆëŠ” ë¦¬ë·°ë¥¼ ë‚¨ê¹ë‹ˆë‹¤. ì½”ë“œë¥¼ í†µí•´ ê°ì •ì„ ì¸¡ì •í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. ë‹¤ë§Œ, ì†Œìˆ˜ì˜ ì‚¬ëŒë“¤ì´ ê·¸ëŸ¬í•œ ë¦¬ë·°ë¥¼ ë‚¨ê¸°ì§€ë§Œ, ì—¬ì „íˆ ì¡´ì¬í•©ë‹ˆë‹¤.

## ì—°ìŠµ - ë°ì´í„° íƒìƒ‰
### ë°ì´í„° ë¡œë“œ

ë°ì´í„°ë¥¼ ì‹œê°ì ìœ¼ë¡œ ì¶©ë¶„íˆ ì‚´í´ë³´ì•˜ìœ¼ë‹ˆ ì´ì œ ì½”ë“œë¥¼ ì‘ì„±í•˜ì—¬ ëª‡ ê°€ì§€ ë‹µì„ ì–»ì–´ë´…ì‹œë‹¤! ì´ ì„¹ì…˜ì—ì„œëŠ” pandas ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì²« ë²ˆì§¸ ì‘ì—…ì€ CSV ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì½ì„ ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. pandas ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” ë¹ ë¥¸ CSV ë¡œë”ë¥¼ ê°€ì§€ê³  ìˆìœ¼ë©°, ê²°ê³¼ëŠ” ì´ì „ ê°•ì˜ì—ì„œì™€ ê°™ì´ ë°ì´í„°í”„ë ˆì„ì— ë°°ì¹˜ë©ë‹ˆë‹¤. ë¡œë“œí•  CSVëŠ” 50ë§Œ ê°œ ì´ìƒì˜ í–‰ì´ ìˆì§€ë§Œ, ì—´ì€ 17ê°œë¿ì…ë‹ˆë‹¤. pandasëŠ” ë°ì´í„°í”„ë ˆì„ê³¼ ìƒí˜¸ ì‘ìš©í•  ìˆ˜ ìˆëŠ” ê°•ë ¥í•œ ë°©ë²•ì„ ë§ì´ ì œê³µí•©ë‹ˆë‹¤. ì—¬ê¸°ì—ëŠ” ëª¨ë“  í–‰ì— ëŒ€í•´ ì—°ì‚°ì„ ìˆ˜í–‰í•˜ëŠ” ê¸°ëŠ¥ë„ í¬í•¨ë©ë‹ˆë‹¤.

ì´ ê°•ì˜ì˜ ì´í›„ ë¶€ë¶„ì—ì„œëŠ” ì½”ë“œ ìŠ¤ë‹ˆí«ê³¼ ì½”ë“œ ì„¤ëª…, ê²°ê³¼ì— ëŒ€í•œ ë…¼ì˜ê°€ í¬í•¨ë©ë‹ˆë‹¤. ì½”ë“œ ì‘ì„±ì—ëŠ” _notebook.ipynb_ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.

ë‹¤ìŒì€ ì‚¬ìš©í•  ë°ì´í„° íŒŒì¼ì„ ë¡œë“œí•˜ëŠ” ì½”ë“œì…ë‹ˆë‹¤:

```python
# Load the hotel reviews from CSV
import pandas as pd
import time
# importing time so the start and end time can be used to calculate file loading time
print("Loading data file now, this could take a while depending on file size")
start = time.time()
# df is 'DataFrame' - make sure you downloaded the file to the data folder
df = pd.read_csv('../../data/Hotel_Reviews.csv')
end = time.time()
print("Loading took " + str(round(end - start, 2)) + " seconds")
```

ì´ì œ ë°ì´í„°ê°€ ë¡œë“œë˜ì—ˆìœ¼ë‹ˆ ëª‡ ê°€ì§€ ì—°ì‚°ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì½”ë“œë¥¼ í”„ë¡œê·¸ë¨ì˜ ìƒë‹¨ì— ìœ ì§€í•˜ì„¸ìš”.

## ë°ì´í„° íƒìƒ‰

ì´ ê²½ìš° ë°ì´í„°ëŠ” ì´ë¯¸ *ê¹¨ë—*í•©ë‹ˆë‹¤. ì¦‰, ì‘ì—…í•  ì¤€ë¹„ê°€ ë˜ì–´ ìˆìœ¼ë©°, ì•Œê³ ë¦¬ì¦˜ì´ ì˜ì–´ ë¬¸ìë§Œ ê¸°ëŒ€í•˜ëŠ” ë‹¤ë¥¸ ì–¸ì–´ì˜ ë¬¸ìê°€ í¬í•¨ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.

âœ… NLP ê¸°ìˆ ì„ ì ìš©í•˜ê¸° ì „ì— ë°ì´í„°ë¥¼ í˜•ì‹í™”í•˜ê¸° ìœ„í•œ ì´ˆê¸° ì²˜ë¦¬ê°€ í•„ìš”í•œ ë°ì´í„°ë¥¼ ë‹¤ë£° ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ ë¹„ì˜ì–´ ë¬¸ìë¥¼ ì–´ë–»ê²Œ ì²˜ë¦¬í•˜ì‹œê² ìŠµë‹ˆê¹Œ?

ë°ì´í„°ê°€ ë¡œë“œëœ í›„ ì½”ë“œë¥¼ ì‚¬ìš©í•˜ì—¬ íƒìƒ‰í•  ìˆ˜ ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”. `Negative_Review` ë° `Positive_Review` ì—´ì— ì§‘ì¤‘í•˜ê³  ì‹¶ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ ì—´ë“¤ì€ NLP ì•Œê³ ë¦¬ì¦˜ì´ ì²˜ë¦¬í•  ìì—°ì–´ í…ìŠ¤íŠ¸ë¡œ ê°€ë“ ì°¨ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜ ê¸°ë‹¤ë¦¬ì„¸ìš”! NLPì™€ ê°ì • ë¶„ì„ì— ë›°ì–´ë“¤ê¸° ì „ì—, ì•„ë˜ ì½”ë“œë¥¼ ë”°ë¼ ë°ì´í„°ì…‹ì— ì£¼ì–´ì§„ ê°’ì´ pandasë¡œ ê³„ì‚°í•œ ê°’ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.

## ë°ì´í„°í”„ë ˆì„ ì—°ì‚°

ì´ ê°•ì˜ì˜ ì²« ë²ˆì§¸ ì‘ì—…ì€ ë°ì´í„° í”„ë ˆì„ì„ ë³€ê²½í•˜ì§€ ì•Šê³  ë°ì´í„°ë¥¼ ê²€ì‚¬í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•˜ì—¬ ë‹¤ìŒ ì£¼ì¥ì´ ì˜¬ë°”ë¥¸ì§€ í™•ì¸í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

> ë§ì€ í”„ë¡œê·¸ë˜ë° ì‘ì—…ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ, ì´ë¥¼ ì™„ë£Œí•˜ëŠ” ì—¬ëŸ¬ ê°€ì§€ ë°©ë²•ì´ ìˆì§€ë§Œ, ê°€ì¥ ê°„ë‹¨í•˜ê³  ì‰¬ìš´ ë°©ë²•ìœ¼ë¡œ í•˜ëŠ” ê²ƒì´ ì¢‹ìŠµë‹ˆë‹¤. íŠ¹íˆ ë‚˜ì¤‘ì— ì´ ì½”ë“œë¥¼
rows have column `Positive_Review` values of "No Positive" 9. Calculate and print out how many rows have column `Positive_Review` values of "No Positive" **and** `Negative_Review` values of "No Negative" ### Code answers 1. Print out the *shape* of the data frame you have just loaded (the shape is the number of rows and columns) ```python
   print("The shape of the data (rows, cols) is " + str(df.shape))
   > The shape of the data (rows, cols) is (515738, 17)
   ``` 2. Calculate the frequency count for reviewer nationalities: 1. How many distinct values are there for the column `Reviewer_Nationality` and what are they? 2. What reviewer nationality is the most common in the dataset (print country and number of reviews)? ```python
   # value_counts() creates a Series object that has index and values in this case, the country and the frequency they occur in reviewer nationality
   nationality_freq = df["Reviewer_Nationality"].value_counts()
   print("There are " + str(nationality_freq.size) + " different nationalities")
   # print first and last rows of the Series. Change to nationality_freq.to_string() to print all of the data
   print(nationality_freq) 
   
   There are 227 different nationalities
    United Kingdom               245246
    United States of America      35437
    Australia                     21686
    Ireland                       14827
    United Arab Emirates          10235
                                  ...  
    Comoros                           1
    Palau                             1
    Northern Mariana Islands          1
    Cape Verde                        1
    Guinea                            1
   Name: Reviewer_Nationality, Length: 227, dtype: int64
   ``` 3. What are the next top 10 most frequently found nationalities, and their frequency count? ```python
      print("The highest frequency reviewer nationality is " + str(nationality_freq.index[0]).strip() + " with " + str(nationality_freq[0]) + " reviews.")
      # Notice there is a leading space on the values, strip() removes that for printing
      # What is the top 10 most common nationalities and their frequencies?
      print("The next 10 highest frequency reviewer nationalities are:")
      print(nationality_freq[1:11].to_string())
      
      The highest frequency reviewer nationality is United Kingdom with 245246 reviews.
      The next 10 highest frequency reviewer nationalities are:
       United States of America     35437
       Australia                    21686
       Ireland                      14827
       United Arab Emirates         10235
       Saudi Arabia                  8951
       Netherlands                   8772
       Switzerland                   8678
       Germany                       7941
       Canada                        7894
       France                        7296
      ``` 3. What was the most frequently reviewed hotel for each of the top 10 most reviewer nationalities? ```python
   # What was the most frequently reviewed hotel for the top 10 nationalities
   # Normally with pandas you will avoid an explicit loop, but wanted to show creating a new dataframe using criteria (don't do this with large amounts of data because it could be very slow)
   for nat in nationality_freq[:10].index:
      # First, extract all the rows that match the criteria into a new dataframe
      nat_df = df[df["Reviewer_Nationality"] == nat]   
      # Now get the hotel freq
      freq = nat_df["Hotel_Name"].value_counts()
      print("The most reviewed hotel for " + str(nat).strip() + " was " + str(freq.index[0]) + " with " + str(freq[0]) + " reviews.") 
      
   The most reviewed hotel for United Kingdom was Britannia International Hotel Canary Wharf with 3833 reviews.
   The most reviewed hotel for United States of America was Hotel Esther a with 423 reviews.
   The most reviewed hotel for Australia was Park Plaza Westminster Bridge London with 167 reviews.
   The most reviewed hotel for Ireland was Copthorne Tara Hotel London Kensington with 239 reviews.
   The most reviewed hotel for United Arab Emirates was Millennium Hotel London Knightsbridge with 129 reviews.
   The most reviewed hotel for Saudi Arabia was The Cumberland A Guoman Hotel with 142 reviews.
   The most reviewed hotel for Netherlands was Jaz Amsterdam with 97 reviews.
   The most reviewed hotel for Switzerland was Hotel Da Vinci with 97 reviews.
   The most reviewed hotel for Germany was Hotel Da Vinci with 86 reviews.
   The most reviewed hotel for Canada was St James Court A Taj Hotel London with 61 reviews.
   ``` 4. How many reviews are there per hotel (frequency count of hotel) in the dataset? ```python
   # First create a new dataframe based on the old one, removing the uneeded columns
   hotel_freq_df = df.drop(["Hotel_Address", "Additional_Number_of_Scoring", "Review_Date", "Average_Score", "Reviewer_Nationality", "Negative_Review", "Review_Total_Negative_Word_Counts", "Positive_Review", "Review_Total_Positive_Word_Counts", "Total_Number_of_Reviews_Reviewer_Has_Given", "Reviewer_Score", "Tags", "days_since_review", "lat", "lng"], axis = 1)
   
   # Group the rows by Hotel_Name, count them and put the result in a new column Total_Reviews_Found
   hotel_freq_df['Total_Reviews_Found'] = hotel_freq_df.groupby('Hotel_Name').transform('count')
   
   # Get rid of all the duplicated rows
   hotel_freq_df = hotel_freq_df.drop_duplicates(subset = ["Hotel_Name"])
   display(hotel_freq_df) 
   ``` | Hotel_Name | Total_Number_of_Reviews | Total_Reviews_Found | | :----------------------------------------: | :---------------------: | :-----------------: | | Britannia International Hotel Canary Wharf | 9086 | 4789 | | Park Plaza Westminster Bridge London | 12158 | 4169 | | Copthorne Tara Hotel London Kensington | 7105 | 3578 | | ... | ... | ... | | Mercure Paris Porte d Orleans | 110 | 10 | | Hotel Wagner | 135 | 10 | | Hotel Gallitzinberg | 173 | 8 | You may notice that the *counted in the dataset* results do not match the value in `Total_Number_of_Reviews`. It is unclear if this value in the dataset represented the total number of reviews the hotel had, but not all were scraped, or some other calculation. `Total_Number_of_Reviews` is not used in the model because of this unclarity. 5. While there is an `Average_Score` column for each hotel in the dataset, you can also calculate an average score (getting the average of all reviewer scores in the dataset for each hotel). Add a new column to your dataframe with the column header `Calc_Average_Score` that contains that calculated average. Print out the columns `Hotel_Name`, `Average_Score`, and `Calc_Average_Score`. ```python
   # define a function that takes a row and performs some calculation with it
   def get_difference_review_avg(row):
     return row["Average_Score"] - row["Calc_Average_Score"]
   
   # 'mean' is mathematical word for 'average'
   df['Calc_Average_Score'] = round(df.groupby('Hotel_Name').Reviewer_Score.transform('mean'), 1)
   
   # Add a new column with the difference between the two average scores
   df["Average_Score_Difference"] = df.apply(get_difference_review_avg, axis = 1)
   
   # Create a df without all the duplicates of Hotel_Name (so only 1 row per hotel)
   review_scores_df = df.drop_duplicates(subset = ["Hotel_Name"])
   
   # Sort the dataframe to find the lowest and highest average score difference
   review_scores_df = review_scores_df.sort_values(by=["Average_Score_Difference"])
   
   display(review_scores_df[["Average_Score_Difference", "Average_Score", "Calc_Average_Score", "Hotel_Name"]])
   ``` You may also wonder about the `Average_Score` value and why it is sometimes different from the calculated average score. As we can't know why some of the values match, but others have a difference, it's safest in this case to use the review scores that we have to calculate the average ourselves. That said, the differences are usually very small, here are the hotels with the greatest deviation from the dataset average and the calculated average: | Average_Score_Difference | Average_Score | Calc_Average_Score | Hotel_Name | | :----------------------: | :-----------: | :----------------: | ------------------------------------------: | | -0.8 | 7.7 | 8.5 | Best Western Hotel Astoria | | -0.7 | 8.8 | 9.5 | Hotel Stendhal Place Vend me Paris MGallery | | -0.7 | 7.5 | 8.2 | Mercure Paris Porte d Orleans | | -0.7 | 7.9 | 8.6 | Renaissance Paris Vendome Hotel | | -0.5 | 7.0 | 7.5 | Hotel Royal Elys es | | ... | ... | ... | ... | | 0.7 | 7.5 | 6.8 | Mercure Paris Op ra Faubourg Montmartre | | 0.8 | 7.1 | 6.3 | Holiday Inn Paris Montparnasse Pasteur | | 0.9 | 6.8 | 5.9 | Villa Eugenie | | 0.9 | 8.6 | 7.7 | MARQUIS Faubourg St Honor Relais Ch teaux | | 1.3 | 7.2 | 5.9 | Kube Hotel Ice Bar | With only 1 hotel having a difference of score greater than 1, it means we can probably ignore the difference and use the calculated average score. 6. Calculate and print out how many rows have column `Negative_Review` values of "No Negative" 7. Calculate and print out how many rows have column `Positive_Review` values of "No Positive" 8. Calculate and print out how many rows have column `Positive_Review` values of "No Positive" **and** `Negative_Review` values of "No Negative" ```python
   # with lambdas:
   start = time.time()
   no_negative_reviews = df.apply(lambda x: True if x['Negative_Review'] == "No Negative" else False , axis=1)
   print("Number of No Negative reviews: " + str(len(no_negative_reviews[no_negative_reviews == True].index)))
   
   no_positive_reviews = df.apply(lambda x: True if x['Positive_Review'] == "No Positive" else False , axis=1)
   print("Number of No Positive reviews: " + str(len(no_positive_reviews[no_positive_reviews == True].index)))
   
   both_no_reviews = df.apply(lambda x: True if x['Negative_Review'] == "No Negative" and x['Positive_Review'] == "No Positive" else False , axis=1)
   print("Number of both No Negative and No Positive reviews: " + str(len(both_no_reviews[both_no_reviews == True].index)))
   end = time.time()
   print("Lambdas took " + str(round(end - start, 2)) + " seconds")
   
   Number of No Negative reviews: 127890
   Number of No Positive reviews: 35946
   Number of both No Negative and No Positive reviews: 127
   Lambdas took 9.64 seconds
   ``` ## Another way Another way count items without Lambdas, and use sum to count the rows: ```python
   # without lambdas (using a mixture of notations to show you can use both)
   start = time.time()
   no_negative_reviews = sum(df.Negative_Review == "No Negative")
   print("Number of No Negative reviews: " + str(no_negative_reviews))
   
   no_positive_reviews = sum(df["Positive_Review"] == "No Positive")
   print("Number of No Positive reviews: " + str(no_positive_reviews))
   
   both_no_reviews = sum((df.Negative_Review == "No Negative") & (df.Positive_Review == "No Positive"))
   print("Number of both No Negative and No Positive reviews: " + str(both_no_reviews))
   
   end = time.time()
   print("Sum took " + str(round(end - start, 2)) + " seconds")
   
   Number of No Negative reviews: 127890
   Number of No Positive reviews: 35946
   Number of both No Negative and No Positive reviews: 127
   Sum took 0.19 seconds
   ``` You may have noticed that there are 127 rows that have both "No Negative" and "No Positive" values for the columns `Negative_Review` and `Positive_Review` respectively. That means that the reviewer gave the hotel a numerical score, but declined to write either a positive or negative review. Luckily this is a small amount of rows (127 out of 515738, or 0.02%), so it probably won't skew our model or results in any particular direction, but you might not have expected a data set of reviews to have rows with no reviews, so it's worth exploring the data to discover rows like this. Now that you have explored the dataset, in the next lesson you will filter the data and add some sentiment analysis. --- ## ğŸš€Challenge This lesson demonstrates, as we saw in previous lessons, how critically important it is to understand your data and its foibles before performing operations on it. Text-based data, in particular, bears careful scrutiny. Dig through various text-heavy datasets and see if you can discover areas that could introduce bias or skewed sentiment into a model. ## [Post-lecture quiz](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/38/) ## Review & Self Study Take [this Learning Path on NLP](https://docs.microsoft.com/learn/paths/explore-natural-language-processing/?WT.mc_id=academic-77952-leestott) to discover tools to try when building speech and text-heavy models. ## Assignment [NLTK](assignment.md)

**ë©´ì±… ì¡°í•­**:
ì´ ë¬¸ì„œëŠ” ê¸°ê³„ ê¸°ë°˜ AI ë²ˆì—­ ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ë²ˆì—­ë˜ì—ˆìŠµë‹ˆë‹¤. ì •í™•ì„±ì„ ìœ„í•´ ë…¸ë ¥í•˜ê³  ìˆì§€ë§Œ, ìë™ ë²ˆì—­ì—ëŠ” ì˜¤ë¥˜ë‚˜ ë¶€ì •í™•ì„±ì´ ìˆì„ ìˆ˜ ìˆìŒì„ ìœ ì˜í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤. ì›ì–´ë¡œ ì‘ì„±ëœ ì›ë³¸ ë¬¸ì„œë¥¼ ê¶Œìœ„ ìˆëŠ” ì¶œì²˜ë¡œ ê°„ì£¼í•´ì•¼ í•©ë‹ˆë‹¤. ì¤‘ìš”í•œ ì •ë³´ì˜ ê²½ìš°, ì „ë¬¸ì ì¸ ì¸ê°„ ë²ˆì—­ì„ ê¶Œì¥í•©ë‹ˆë‹¤. ì´ ë²ˆì—­ ì‚¬ìš©ìœ¼ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ì˜¤í•´ë‚˜ ì˜ëª»ëœ í•´ì„ì— ëŒ€í•´ì„œëŠ” ì±…ì„ì§€ì§€ ì•ŠìŠµë‹ˆë‹¤.