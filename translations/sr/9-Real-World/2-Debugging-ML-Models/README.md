<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "df2b538e8fbb3e91cf0419ae2f858675",
  "translation_date": "2025-09-05T12:29:09+00:00",
  "source_file": "9-Real-World/2-Debugging-ML-Models/README.md",
  "language_code": "sr"
}
-->
# Постскриптум: Отклањање грешака у моделима машинског учења помоћу компоненти одговорног AI контролне табле

## [Квиз пре предавања](https://ff-quizzes.netlify.app/en/ml/)

## Увод

Машинско учење утиче на наше свакодневне животе. Вештачка интелигенција (AI) налази своје место у неким од најважнијих система који утичу на нас као појединце и на наше друштво, од здравства, финансија, образовања до запошљавања. На пример, системи и модели се користе у задацима доношења одлука, као што су дијагнозе у здравству или откривање превара. Као последица тога, напредак у AI, заједно са убрзаним усвајањем, праћен је еволуирајућим друштвеним очекивањима и све већом регулацијом. Често видимо области у којима AI системи не испуњавају очекивања; откривају нове изазове; а владе почињу да регулишу AI решења. Због тога је важно да се ови модели анализирају како би се обезбедили правични, поуздани, инклузивни, транспарентни и одговорни резултати за све.

У овом курикулуму ћемо истражити практичне алате који се могу користити за процену да ли модел има проблеме са одговорним AI. Традиционалне технике отклањања грешака у машинском учењу обично се заснивају на квантитативним прорачунима као што су агрегирана тачност или просечан губитак грешке. Замислите шта се може догодити када подаци које користите за изградњу ових модела недостају одређеним демографским групама, као што су раса, пол, политички став, религија, или су непропорционално заступљени. Шта ако се излаз модела тумачи тако да фаворизује неку демографску групу? Ово може довести до претеране или недовољне заступљености ових осетљивих група карактеристика, што резултира проблемима правичности, инклузивности или поузданости модела. Још један фактор је то што се модели машинског учења често сматрају "црним кутијама", што отежава разумевање и објашњење шта покреће предвиђања модела. Сви ови изазови су са којима се суочавају научници података и AI програмери када немају адекватне алате за отклањање грешака и процену правичности или поузданости модела.

У овој лекцији ћете научити како да отклањате грешке у својим моделима користећи:

- **Анализу грешака**: идентификацију делова у расподели података где модел има високе стопе грешака.
- **Преглед модела**: спровођење компаративне анализе између различитих кохорти података како би се откриле разлике у метрикама перформанси модела.
- **Анализу података**: истраживање где може постојати претерана или недовољна заступљеност података која може искривити модел да фаворизује једну демографску групу у односу на другу.
- **Важност карактеристика**: разумевање које карактеристике покрећу предвиђања вашег модела на глобалном или локалном нивоу.

## Предуслов

Као предуслов, молимо вас да прегледате [алате за одговорни AI за програмере](https://www.microsoft.com/ai/ai-lab-responsible-ai-dashboard)

> ![Гиф о алатима за одговорни AI](../../../../9-Real-World/2-Debugging-ML-Models/images/rai-overview.gif)

## Анализа грешака

Традиционалне метрике перформанси модела које се користе за мерење тачности углавном су прорачуни засновани на исправним и неисправним предвиђањима. На пример, утврђивање да је модел тачан 89% времена са губитком грешке од 0.001 може се сматрати добрим перформансама. Међутим, грешке често нису равномерно распоређене у вашем основном скупу података. Можете добити резултат тачности модела од 89%, али открити да постоје различити региони ваших података у којима модел греши 42% времена. Последице ових образаца грешака у одређеним групама података могу довести до проблема правичности или поузданости. Важно је разумети области у којима модел добро ради или не. Региони података где постоји велики број нетачности у вашем моделу могу се испоставити као важна демографска група података.

![Анализа и отклањање грешака модела](../../../../9-Real-World/2-Debugging-ML-Models/images/ea-error-distribution.png)

Компонента Анализа грешака на RAI контролној табли илуструје како су грешке модела распоређене кроз различите кохорте помоћу визуализације стабла. Ово је корисно за идентификовање карактеристика или области где постоји висока стопа грешака у вашем скупу података. Гледајући где долази већина нетачности модела, можете почети да истражујете основни узрок. Такође можете креирати кохорте података за спровођење анализе. Ове кохорте података помажу у процесу отклањања грешака како би се утврдило зашто је перформанса модела добра у једној кохорти, али погрешна у другој.

![Анализа грешака](../../../../9-Real-World/2-Debugging-ML-Models/images/ea-error-cohort.png)

Визуелни индикатори на мапи стабла помажу у бржем лоцирању проблематичних области. На пример, тамнија нијанса црвене боје чвора стабла указује на већу стопу грешака.

Топлотна мапа је још једна функционалност визуализације коју корисници могу користити за истраживање стопе грешака користећи једну или две карактеристике како би пронашли узрок грешака модела у целом скупу података или кохортама.

![Топлотна мапа анализе грешака](../../../../9-Real-World/2-Debugging-ML-Models/images/ea-heatmap.png)

Користите анализу грешака када треба да:

* Добијете дубоко разумевање како су грешке модела распоређене у скупу података и кроз више улазних и димензија карактеристика.
* Разложите агрегатне метрике перформанси како бисте аутоматски открили погрешне кохорте и информисали своје циљане кораке за ублажавање.

## Преглед модела

Евалуација перформанси модела машинског учења захтева добијање свеобухватног разумевања његовог понашања. Ово се може постићи прегледом више од једне метрике, као што су стопа грешке, тачност, опозив, прецизност или MAE (просечна апсолутна грешка), како би се пронашле разлике међу метрикама перформанси. Једна метрика перформанси може изгледати одлично, али нетачности могу бити откривене у другој метрици. Поред тога, упоређивање метрика ради откривања разлика у целом скупу података или кохортама помаже у осветљавању области где модел добро ради или не. Ово је посебно важно за уочавање перформанси модела међу осетљивим и неосетљивим карактеристикама (нпр. раса пацијента, пол или старост) како би се открила потенцијална неправичност модела. На пример, откривање да је модел више погрешан у кохорти која има осетљиве карактеристике може указати на потенцијалну неправичност модела.

Компонента Преглед модела на RAI контролној табли помаже не само у анализи метрика перформанси репрезентације података у кохорти, већ корисницима пружа могућност да упореде понашање модела у различитим кохортама.

![Кохорте скупа података - преглед модела на RAI контролној табли](../../../../9-Real-World/2-Debugging-ML-Models/images/model-overview-dataset-cohorts.png)

Функционалност анализе засноване на карактеристикама компоненте омогућава корисницима да сузе подгрупе података унутар одређене карактеристике како би идентификовали аномалије на грануларном нивоу. На пример, контролна табла има уграђену интелигенцију за аутоматско генерисање кохорти за кориснички изабрану карактеристику (нпр. *"time_in_hospital < 3"* или *"time_in_hospital >= 7"*). Ово омогућава кориснику да изолује одређену карактеристику из веће групе података како би видео да ли је она кључни утицајни фактор на погрешне исходе модела.

![Кохорте карактеристика - преглед модела на RAI контролној табли](../../../../9-Real-World/2-Debugging-ML-Models/images/model-overview-feature-cohorts.png)

Компонента Преглед модела подржава две класе метрика разлика:

**Разлике у перформансама модела**: Ови скупови метрика израчунавају разлику у вредностима изабране метрике перформанси између подгрупа података. Ево неколико примера:

* Разлика у стопи тачности
* Разлика у стопи грешке
* Разлика у прецизности
* Разлика у опозиву
* Разлика у просечној апсолутној грешци (MAE)

**Разлике у стопи селекције**: Ова метрика садржи разлику у стопи селекције (пожељно предвиђање) међу подгрупама. Пример овога је разлика у стопама одобрења кредита. Стопа селекције означава фракцију тачака података у свакој класи класификованих као 1 (у бинарној класификацији) или расподелу вредности предвиђања (у регресији).

## Анализа података

> "Ако довољно мучите податке, они ће признати било шта" - Роналд Коуз

Ова изјава звучи екстремно, али је истина да се подаци могу манипулисати како би подржали било који закључак. Таква манипулација понекад може бити ненамерна. Као људи, сви имамо пристрасности, и често је тешко свесно знати када уносите пристрасност у податке. Обезбеђивање правичности у AI и машинском учењу остаје сложен изазов.

Подаци су велика слепа тачка за традиционалне метрике перформанси модела. Можете имати високе резултате тачности, али то не одражава увек основну пристрасност података која може постојати у вашем скупу података. На пример, ако скуп података запослених има 27% жена на извршним позицијама у компанији и 73% мушкараца на истом нивоу, модел за оглашавање послова обучен на овим подацима може углавном циљати мушку публику за позиције на вишем нивоу. Ова неравнотежа у подацима искривила је предвиђање модела да фаворизује један пол. Ово открива проблем правичности где постоји родна пристрасност у AI моделу.

Компонента Анализа података на RAI контролној табли помаже у идентификовању области где постоји претерана или недовољна заступљеност у скупу података. Она помаже корисницима да дијагностикују основни узрок грешака и проблема правичности који су уведени због неравнотеже података или недостатка репрезентације одређене групе података. Ово корисницима пружа могућност да визуализују скупове података на основу предвиђених и стварних исхода, група грешака и специфичних карактеристика. Понекад откривање недовољно заступљене групе података такође може открити да модел не учи добро, што доводи до високих нетачности. Модел који има пристрасност у подацима није само проблем правичности већ показује да модел није инклузиван или поуздан.

![Компонента Анализа података на RAI контролној табли](../../../../9-Real-World/2-Debugging-ML-Models/images/dataanalysis-cover.png)

Користите анализу података када треба да:

* Истражите статистику вашег скупа података одабиром различитих филтера за сегментирање података у различите димензије (познате и као кохорте).
* Разумете расподелу вашег скупа података кроз различите кохорте и групе карактеристика.
* Утврдите да ли су ваша открића у вези са правичношћу, анализом грешака и узрочношћу (изведена из других компоненти контролне табле) резултат расподеле вашег скупа података.
* Одлучите у којим областима треба прикупити више података како бисте ублажили грешке које произилазе из проблема репрезентације, буке у ознакама, буке у карактеристикама, пристрасности у ознакама и сличних фактора.

## Интерпретабилност модела

Модели машинског учења често се сматрају "црним кутијама". Разумевање које кључне карактеристике података покрећу предвиђање модела може бити изазовно. Важно је пружити транспарентност у вези са тим зашто модел доноси одређено предвиђање. На пример, ако AI систем предвиђа да је пацијент са дијабетесом у ризику од поновног пријема у болницу у року од мање од 30 дана, требало би да буде у стању да пружи податке који подржавају његово предвиђање. Имање података који подржавају предвиђање доноси транспарентност која помаже клиничарима или болницама да доносе добро информисане одлуке. Поред тога, могућност објашњења зашто је модел донео предвиђање за појединачног пацијента омогућава одговорност у складу са здравственим прописима. Када користите моделе машинског учења на начине који утичу на животе људи, кључно је разумети и објаснити шта утиче на понашање модела. Интерпретабилност и објашњивост модела помажу у одговарању на питања у сценаријима као што су:

* Отклањање грешака у моделу: Зашто је мој модел направио ову грешку? Како могу побољшати свој модел?
* Сарадња човека и AI: Како могу разумети и веровати одлукама модела?
* Регулаторна усклађеност: Да ли мој модел задовољава законске захтеве?

Компонента Важност карактеристика на RAI контролној табли помаже вам да отклоните грешке и стекнете свеобухватно разумевање како модел доноси предвиђања. Такође је користан алат за професионалце у машинском учењу и доносиоце одлука да објасне и покажу доказе о карактеристикама које утичу на понашање модела ради регулаторне усклађености. Корисници могу истраживати и глобална и локална објашњења како би потврдили које карактеристике покрећу предвиђања модела. Глобална објашњења наводе најважније карактеристике које су утицале на укуп
- **Превелика или премала заступљеност**. Идеја је да одређена група није заступљена у одређеној професији, а свака услуга или функција која наставља да промовише то доприноси штети.

### Azure RAI контролна табла

[Azure RAI контролна табла](https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai-dashboard?WT.mc_id=aiml-90525-ruyakubu) је изграђена на алатима отвореног кода које су развиле водеће академске институције и организације, укључујући Microsoft, и представљају кључне алате за научнике који се баве подацима и AI програмере да боље разумеју понашање модела, открију и ублаже непожељне проблеме у AI моделима.

- Сазнајте како да користите различите компоненте тако што ћете погледати [документацију RAI контролне табле.](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-responsible-ai-dashboard?WT.mc_id=aiml-90525-ruyakubu)

- Погледајте неке [примере нотебука RAI контролне табле](https://github.com/Azure/RAI-vNext-Preview/tree/main/examples/notebooks) за отклањање проблема у сценаријима одговорног AI у Azure Machine Learning.

---
## 🚀 Изазов

Да бисмо спречили увођење статистичких или податковних пристрасности, требало би:

- имати разноврсност у позадинама и перспективама међу људима који раде на системима
- улагати у скупове података који одражавају разноврсност нашег друштва
- развијати боље методе за откривање и исправљање пристрасности када се она појави

Размислите о стварним животним сценаријима где је неправедност очигледна у изградњи и коришћењу модела. Шта још треба узети у обзир?

## [Квиз након предавања](https://ff-quizzes.netlify.app/en/ml/)
## Преглед и самостално учење

У овом часу сте научили неке практичне алате за укључивање одговорног AI у машинско учење.

Погледајте овај радионицу за дубље разумевање тема:

- Одговорна AI контролна табла: Централно место за оперативну примену RAI у пракси, од Besmira Nushi и Mehrnoosh Sameki

[![Одговорна AI контролна табла: Централно место за оперативну примену RAI у пракси](https://img.youtube.com/vi/f1oaDNl3djg/0.jpg)](https://www.youtube.com/watch?v=f1oaDNl3djg "Одговорна AI контролна табла: Централно место за оперативну примену RAI у пракси")


> 🎥 Кликните на слику изнад за видео: Одговорна AI контролна табла: Централно место за оперативну примену RAI у пракси, од Besmira Nushi и Mehrnoosh Sameki

Реферишите следеће материјале да бисте сазнали више о одговорном AI и како изградити поузданије моделе:

- Microsoft-ови алати RAI контролне табле за отклањање проблема у ML моделима: [Ресурси алата за одговорни AI](https://aka.ms/rai-dashboard)

- Истражите алатке за одговорни AI: [Github](https://github.com/microsoft/responsible-ai-toolbox)

- Microsoft-ов центар ресурса за RAI: [Ресурси за одговорни AI – Microsoft AI](https://www.microsoft.com/ai/responsible-ai-resources?activetab=pivot1%3aprimaryr4)

- Microsoft-ова истраживачка група FATE: [FATE: Праведност, Одговорност, Транспарентност и Етика у AI - Microsoft Research](https://www.microsoft.com/research/theme/fate/)

## Задатак

[Истражите RAI контролну таблу](assignment.md)

---

**Одрицање од одговорности**:  
Овај документ је преведен коришћењем услуге за превођење помоћу вештачке интелигенције [Co-op Translator](https://github.com/Azure/co-op-translator). Иако се трудимо да обезбедимо тачност, молимо вас да имате у виду да аутоматски преводи могу садржати грешке или нетачности. Оригинални документ на његовом изворном језику треба сматрати ауторитативним извором. За критичне информације препоручује се професионални превод од стране људи. Не преузимамо одговорност за било каква погрешна тумачења или неспоразуме који могу настати услед коришћења овог превода.