<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "5f3cb462e3122e1afe7ab0050ccf2bd3",
  "translation_date": "2025-09-05T13:53:33+00:00",
  "source_file": "6-NLP/2-Tasks/README.md",
  "language_code": "sr"
}
-->
# Уобичајени задаци и технике обраде природног језика

За већину задатака обраде *природног језика*, текст који се обрађује мора бити разложен, анализиран, а резултати сачувани или упоређени са правилима и скуповима података. Ови задаци омогућавају програмеру да изведе _значење_, _намеру_ или само _учесталост_ термина и речи у тексту.

## [Квиз пре предавања](https://ff-quizzes.netlify.app/en/ml/)

Хајде да откријемо уобичајене технике које се користе у обради текста. У комбинацији са машинским учењем, ове технике вам помажу да ефикасно анализирате велике количине текста. Међутим, пре него што примените машинско учење на ове задатке, важно је разумети проблеме са којима се сусреће специјалиста за обраду природног језика.

## Уобичајени задаци у обради природног језика

Постоје различити начини за анализу текста на којем радите. Постоје задаци које можете извршити, а кроз те задатке можете стећи разумевање текста и извући закључке. Ове задатке обично извршавате у одређеном редоследу.

### Токенизација

Вероватно прва ствар коју већина алгоритама за обраду природног језика мора да уради јесте да подели текст на токене, или речи. Иако ово звучи једноставно, узимање у обзир интерпункције и различитих језичких разграничења речи и реченица може бити компликовано. Можда ћете морати да користите различите методе за одређивање граница.

![токенизација](../../../../6-NLP/2-Tasks/images/tokenization.png)
> Токенизација реченице из **Гордости и предрасуда**. Инфографика од [Jen Looper](https://twitter.com/jenlooper)

### Ембединг

[Ембединг речи](https://wikipedia.org/wiki/Word_embedding) је начин да се ваш текстуални подаци конвертују у нумерички облик. Ембединг се ради тако да речи са сличним значењем или речи које се често користе заједно буду груписане.

![ембединг речи](../../../../6-NLP/2-Tasks/images/embedding.png)
> "Имам највеће поштовање према вашим нервима, они су моји стари пријатељи." - Ембединг речи за реченицу из **Гордости и предрасуда**. Инфографика од [Jen Looper](https://twitter.com/jenlooper)

✅ Испробајте [овај занимљив алат](https://projector.tensorflow.org/) за експериментисање са ембедингом речи. Кликом на једну реч приказују се групе сличних речи: 'toy' је груписан са 'disney', 'lego', 'playstation' и 'console'.

### Парсирање и означавање делова говора

Свака реч која је токенизована може бити означена као део говора - именица, глагол или придев. Реченица `the quick red fox jumped over the lazy brown dog` може бити означена као fox = именица, jumped = глагол.

![парсирање](../../../../6-NLP/2-Tasks/images/parse.png)

> Парсирање реченице из **Гордости и предрасуда**. Инфографика од [Jen Looper](https://twitter.com/jenlooper)

Парсирање подразумева препознавање које речи су међусобно повезане у реченици - на пример, `the quick red fox jumped` је секвенца придев-именица-глагол која је одвојена од секвенце `lazy brown dog`.

### Учесталост речи и фраза

Корисна процедура при анализи великог текста је изградња речника сваке речи или фразе од интереса и учесталости њиховог појављивања. Фраза `the quick red fox jumped over the lazy brown dog` има учесталост речи 2 за the.

Хајде да погледамо пример текста где бројимо учесталост речи. Песма Редијарда Киплинга "The Winners" садржи следећи стих:

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

Како учесталост фраза може бити осетљива или неосетљива на велика и мала слова, фраза `a friend` има учесталост 2, `the` има учесталост 6, а `travels` је 2.

### N-грамови

Текст се може поделити на секвенце речи одређене дужине, једна реч (униграм), две речи (биграм), три речи (триграм) или било који број речи (n-грам).

На пример, `the quick red fox jumped over the lazy brown dog` са n-грам оценом 2 производи следеће n-грамове:

1. the quick 
2. quick red 
3. red fox
4. fox jumped 
5. jumped over 
6. over the 
7. the lazy 
8. lazy brown 
9. brown dog

Можда је лакше визуализовати то као клизну кутију преко реченице. Ево како изгледа за n-грамове од 3 речи, n-грам је означен у свакој реченици:

1.   <u>**the quick red**</u> fox jumped over the lazy brown dog
2.   the **<u>quick red fox</u>** jumped over the lazy brown dog
3.   the quick **<u>red fox jumped</u>** over the lazy brown dog
4.   the quick red **<u>fox jumped over</u>** the lazy brown dog
5.   the quick red fox **<u>jumped over the</u>** lazy brown dog
6.   the quick red fox jumped **<u>over the lazy</u>** brown dog
7.   the quick red fox jumped over <u>**the lazy brown**</u> dog
8.   the quick red fox jumped over the **<u>lazy brown dog</u>**

![клизни прозор n-грамова](../../../../6-NLP/2-Tasks/images/n-grams.gif)

> Вредност n-грама 3: Инфографика од [Jen Looper](https://twitter.com/jenlooper)

### Екстракција именичких фраза

У већини реченица постоји именица која је субјекат или објекат реченице. У енглеском језику често се може идентификовати као реч која има 'a', 'an' или 'the' испред себе. Идентификовање субјекта или објекта реченице кроз 'екстракцију именичке фразе' је уобичајен задатак у обради природног језика када се покушава разумети значење реченице.

✅ У реченици "I cannot fix on the hour, or the spot, or the look or the words, which laid the foundation. It is too long ago. I was in the middle before I knew that I had begun.", можете ли идентификовати именичке фразе?

У реченици `the quick red fox jumped over the lazy brown dog` постоје 2 именичке фразе: **quick red fox** и **lazy brown dog**.

### Анализа сентимента

Реченица или текст могу се анализирати за сентимент, односно колико су *позитивни* или *негативни*. Сентимент се мери кроз *поларитет* и *објективност/субјективност*. Поларитет се мери од -1.0 до 1.0 (негативно до позитивно) и 0.0 до 1.0 (најобјективније до најсубјективније).

✅ Касније ћете научити да постоје различити начини за одређивање сентимента користећи машинско учење, али један начин је да имате листу речи и фраза које су категорисане као позитивне или негативне од стране људског експерта и примените тај модел на текст да бисте израчунали оцену поларитета. Можете ли видети како би ово функционисало у неким околностима, а мање добро у другим?

### Инфлексија

Инфлексија вам омогућава да узмете реч и добијете њен једнину или множину.

### Лематизација

*Лема* је корен или основна реч за скуп речи, на пример *flew*, *flies*, *flying* имају лему глагола *fly*.

Такође постоје корисне базе података доступне истраживачима обраде природног језика, нарочито:

### WordNet

[WordNet](https://wordnet.princeton.edu/) је база података речи, синонима, антонима и многих других детаља за сваку реч на многим различитим језицима. Изузетно је корисна када се покушавају изградити преводи, провере правописа или алати за језик било које врсте.

## Библиотеке за обраду природног језика

Срећом, не морате сами да градите све ове технике, јер постоје одличне Python библиотеке које чине обраду природног језика много приступачнијом за програмере који нису специјализовани за обраду природног језика или машинско учење. У наредним лекцијама биће више примера ових библиотека, али овде ћете научити неке корисне примере који ће вам помоћи у следећем задатку.

### Вежба - коришћење библиотеке `TextBlob`

Хајде да користимо библиотеку TextBlob јер садржи корисне API-је за решавање ових типова задатака. TextBlob "се ослања на гигантска рамена [NLTK](https://nltk.org) и [pattern](https://github.com/clips/pattern), и лепо сарађује са оба." Има значајну количину машинског учења уграђену у свој API.

> Напомена: Корисни [Quick Start](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart) водич је доступан за TextBlob и препоручује се искусним Python програмерима.

Када покушавате да идентификујете *именичке фразе*, TextBlob нуди неколико опција екстрактора за проналажење именица.

1. Погледајте `ConllExtractor`.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > Шта се овде дешава? [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) је "Екстрактор именица који користи chunk парсирање обучено са ConLL-2000 корпусом за обуку." ConLL-2000 се односи на Конференцију о рачунарском учењу природног језика из 2000. године. Сваке године конференција је организовала радионицу за решавање сложеног проблема обраде природног језика, а 2000. године то је било chunking именица. Модел је обучен на Wall Street Journal-у, са "секцијама 15-18 као подаци за обуку (211727 токена) и секцијом 20 као тест подаци (47377 токена)". Можете погледати процедуре коришћене [овде](https://www.clips.uantwerpen.be/conll2000/chunking/) и [резултате](https://ifarm.nl/erikt/research/np-chunking.html).

### Изазов - побољшање вашег бота уз обраду природног језика

У претходној лекцији направили сте веома једноставан Q&A бот. Сада ћете учинити Марвина мало симпатичнијим анализирајући ваш унос за сентимент и штампајући одговор који одговара сентименту. Такође ћете морати да идентификујете `noun_phrase` и поставите питање о њој.

Ваши кораци при изградњи бољег конверзационог бота:

1. Штампајте упутства која саветују корисника како да комуницира са ботом
2. Покрените петљу 
   1. Прихватите унос корисника
   2. Ако корисник затражи излаз, изађите
   3. Обрадите унос корисника и одредите одговарајући сентимент одговор
   4. Ако је именица детектована у сентименту, множите је и поставите додатно питање о тој теми
   5. Штампајте одговор
3. Вратите се на корак 2

Ево исечка кода за одређивање сентимента користећи TextBlob. Напомена: постоје само четири *градијента* сентимент одговора (можете додати више ако желите):

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

Ево примера излазног резултата који вас може водити (кориснички унос је на линијама које почињу са >):

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

Једно могуће решење задатка је [овде](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/2-Tasks/solution/bot.py)

✅ Провера знања

1. Мислите ли да би симпатични одговори могли 'преварити' некога да помисли да бот заиста разуме њих?
2. Да ли идентификовање именице чини бота 'веродостојнијим'?
3. Зашто би екстракција 'именице' из реченице била корисна ствар?

---

Имплементирајте бота из претходне провере знања и тестирајте га на пријатељу. Може ли их преварити? Можете ли учинити вашег бота 'веродостојнијим'?

## 🚀Изазов

Узмите задатак из претходне провере знања и покушајте да га имплементирате. Тестирајте бота на пријатељу. Може ли их преварити? Можете ли учинити вашег бота 'веродостојнијим'?

## [Квиз после предавања](https://ff-quizzes.netlify.app/en/ml/)

## Преглед и самостално учење

У наредним лекцијама ћете научити више о анализи сентимента. Истражите ову занимљиву технику у чланцима као што су они на [KDNuggets](https://www.kdnuggets.com/tag/nlp)

## Задатак 

[Учини да бот одговара](assignment.md)

---

**Одрицање од одговорности**:  
Овај документ је преведен коришћењем услуге за превођење помоћу вештачке интелигенције [Co-op Translator](https://github.com/Azure/co-op-translator). Иако се трудимо да обезбедимо тачност, молимо вас да имате у виду да аутоматизовани преводи могу садржати грешке или нетачности. Оригинални документ на његовом изворном језику треба сматрати меродавним извором. За критичне информације, препоручује се професионални превод од стране људског преводиоца. Не преузимамо одговорност за било каква погрешна тумачења или неспоразуме који могу произаћи из коришћења овог превода.