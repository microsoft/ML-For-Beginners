{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "lesson_12-R.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "ir",
   "display_name": "R"
  },
  "language_info": {
   "name": "R"
  },
  "coopTranslator": {
   "original_hash": "fab50046ca413a38939d579f8432274f",
   "translation_date": "2025-08-29T15:28:33+00:00",
   "source_file": "4-Classification/3-Classifiers-2/solution/R/lesson_12-R.ipynb",
   "language_code": "ur"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsFutf_ygqSx"
   },
   "source": [
    "ایک درجہ بندی ماڈل بنائیں: مزیدار ایشیائی اور بھارتی کھانے\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HD54bEefgtNO"
   },
   "source": [
    "## کھانوں کی درجہ بندی کرنے والے 2\n",
    "\n",
    "اس دوسرے درجہ بندی کے سبق میں، ہم زمرہ وار ڈیٹا کو درجہ بندی کرنے کے مزید طریقے دریافت کریں گے۔ ہم یہ بھی سیکھیں گے کہ ایک درجہ بندی کرنے والے کو دوسرے پر منتخب کرنے کے کیا اثرات ہو سکتے ہیں۔\n",
    "\n",
    "### [**لیکچر سے پہلے کا کوئز**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/23/)\n",
    "\n",
    "### **پیشگی شرط**\n",
    "\n",
    "ہم فرض کرتے ہیں کہ آپ نے پچھلے اسباق مکمل کر لیے ہیں کیونکہ ہم ان تصورات کو آگے بڑھائیں گے جو ہم نے پہلے سیکھے تھے۔\n",
    "\n",
    "اس سبق کے لیے، ہمیں درج ذیل پیکجز کی ضرورت ہوگی:\n",
    "\n",
    "-   `tidyverse`: [tidyverse](https://www.tidyverse.org/) ایک [R پیکجز کا مجموعہ](https://www.tidyverse.org/packages) ہے جو ڈیٹا سائنس کو تیز، آسان اور مزید دلچسپ بناتا ہے!\n",
    "\n",
    "-   `tidymodels`: [tidymodels](https://www.tidymodels.org/) فریم ورک ایک [پیکجز کا مجموعہ](https://www.tidymodels.org/packages/) ہے جو ماڈلنگ اور مشین لرننگ کے لیے استعمال ہوتا ہے۔\n",
    "\n",
    "-   `themis`: [themis پیکج](https://themis.tidymodels.org/) غیر متوازن ڈیٹا سے نمٹنے کے لیے اضافی ترکیبیں فراہم کرتا ہے۔\n",
    "\n",
    "آپ انہیں اس طرح انسٹال کر سکتے ہیں:\n",
    "\n",
    "`install.packages(c(\"tidyverse\", \"tidymodels\", \"kernlab\", \"themis\", \"ranger\", \"xgboost\", \"kknn\"))`\n",
    "\n",
    "متبادل طور پر، نیچے دیا گیا اسکرپٹ چیک کرتا ہے کہ آیا آپ کے پاس اس ماڈیول کو مکمل کرنے کے لیے درکار پیکجز موجود ہیں، اور اگر وہ غائب ہوں تو انہیں آپ کے لیے انسٹال کر دیتا ہے۔\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vZ57IuUxgyQt"
   },
   "source": [
    "suppressWarnings(if (!require(\"pacman\"))install.packages(\"pacman\"))\n",
    "\n",
    "pacman::p_load(tidyverse, tidymodels, themis, kernlab, ranger, xgboost, kknn)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z22M-pj4g07x"
   },
   "source": [
    "## **1. ایک درجہ بندی کا نقشہ**\n",
    "\n",
    "ہم نے [پچھلے سبق](https://github.com/microsoft/ML-For-Beginners/tree/main/4-Classification/2-Classifiers-1) میں یہ سوال حل کرنے کی کوشش کی: ہم مختلف ماڈلز میں سے کیسے انتخاب کریں؟ بڑی حد تک، یہ ڈیٹا کی خصوصیات اور اس مسئلے کی نوعیت پر منحصر ہے جسے ہم حل کرنا چاہتے ہیں (مثال کے طور پر، درجہ بندی یا رجریشن؟)\n",
    "\n",
    "پہلے، ہم نے مائیکروسافٹ کے چیٹ شیٹ کا استعمال کرتے ہوئے ڈیٹا کو درجہ بندی کرنے کے مختلف اختیارات کے بارے میں سیکھا۔ پائتھون کے مشین لرننگ فریم ورک، Scikit-learn، ایک اسی طرح کا لیکن زیادہ تفصیلی چیٹ شیٹ پیش کرتا ہے جو آپ کے تخمینے (جسے classifiers بھی کہا جاتا ہے) کو مزید محدود کرنے میں مدد دے سکتا ہے:\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/map.png\"\n",
    "   width=\"700\"/>\n",
    "   <figcaption></figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1i3xRIVg7vG"
   },
   "source": [
    "> مشورہ: [اس نقشے کو آن لائن دیکھیں](https://scikit-learn.org/stable/tutorial/machine_learning_map/) اور راستے پر کلک کریں تاکہ دستاویزات پڑھ سکیں۔\n",
    ">\n",
    "> [Tidymodels حوالہ سائٹ](https://www.tidymodels.org/find/parsnip/#models) بھی مختلف قسم کے ماڈلز کے بارے میں بہترین دستاویزات فراہم کرتی ہے۔\n",
    "\n",
    "### **منصوبہ** 🗺️\n",
    "\n",
    "یہ نقشہ تب بہت مددگار ثابت ہوتا ہے جب آپ اپنے ڈیٹا کو اچھی طرح سمجھ چکے ہوں، کیونکہ آپ اس کے راستوں پر چل کر فیصلہ کر سکتے ہیں:\n",
    "\n",
    "-   ہمارے پاس \\>50 نمونے ہیں\n",
    "\n",
    "-   ہم ایک زمرہ کی پیش گوئی کرنا چاہتے ہیں\n",
    "\n",
    "-   ہمارے پاس لیبل شدہ ڈیٹا موجود ہے\n",
    "\n",
    "-   ہمارے پاس 100K سے کم نمونے ہیں\n",
    "\n",
    "-   ✨ ہم ایک Linear SVC منتخب کر سکتے ہیں\n",
    "\n",
    "-   اگر یہ کام نہ کرے، چونکہ ہمارے پاس عددی ڈیٹا ہے\n",
    "\n",
    "    -   ہم ✨ KNeighbors Classifier آزما سکتے ہیں\n",
    "\n",
    "        -   اگر یہ بھی کام نہ کرے، تو ✨ SVC اور ✨ Ensemble Classifiers آزما لیں\n",
    "\n",
    "یہ ایک بہت مددگار راستہ ہے جس پر چلنا آسان ہے۔ اب، آئیے [tidymodels](https://www.tidymodels.org/) ماڈلنگ فریم ورک استعمال کرتے ہوئے شروع کرتے ہیں: R پیکجز کا ایک مستقل اور لچکدار مجموعہ جو اچھے شماریاتی طریقوں کو فروغ دینے کے لیے تیار کیا گیا ہے 😊۔\n",
    "\n",
    "## 2. ڈیٹا کو تقسیم کریں اور غیر متوازن ڈیٹا سیٹ سے نمٹیں۔\n",
    "\n",
    "پچھلے اسباق میں، ہم نے سیکھا کہ ہمارے کھانوں میں کچھ عام اجزاء موجود تھے۔ اس کے علاوہ، کھانوں کی تعداد میں کافی غیر مساوی تقسیم تھی۔\n",
    "\n",
    "ہم ان سے نمٹیں گے:\n",
    "\n",
    "-   ان سب سے عام اجزاء کو ہٹا کر جو مختلف کھانوں کے درمیان الجھن پیدا کرتے ہیں، `dplyr::select()` استعمال کرتے ہوئے۔\n",
    "\n",
    "-   ایک `recipe` استعمال کریں جو ڈیٹا کو ماڈلنگ کے لیے تیار کرنے کے لیے پہلے سے پروسیس کرتا ہے، اور ایک `over-sampling` الگورتھم لگاتا ہے۔\n",
    "\n",
    "ہم نے یہ سب پچھلے سبق میں دیکھا تھا، لہذا یہ کام آسان ہونا چاہیے 🥳!\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6tj_rN00hClA"
   },
   "source": [
    "# Load the core Tidyverse and Tidymodels packages\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "\n",
    "# Load the original cuisines data\n",
    "df <- read_csv(file = \"https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/data/cuisines.csv\")\n",
    "\n",
    "# Drop id column, rice, garlic and ginger from our original data set\n",
    "df_select <- df %>% \n",
    "  select(-c(1, rice, garlic, ginger)) %>%\n",
    "  # Encode cuisine column as categorical\n",
    "  mutate(cuisine = factor(cuisine))\n",
    "\n",
    "\n",
    "# Create data split specification\n",
    "set.seed(2056)\n",
    "cuisines_split <- initial_split(data = df_select,\n",
    "                                strata = cuisine,\n",
    "                                prop = 0.7)\n",
    "\n",
    "# Extract the data in each split\n",
    "cuisines_train <- training(cuisines_split)\n",
    "cuisines_test <- testing(cuisines_split)\n",
    "\n",
    "# Display distribution of cuisines in the training set\n",
    "cuisines_train %>% \n",
    "  count(cuisine) %>% \n",
    "  arrange(desc(n))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFin5yw3hHb1"
   },
   "source": [
    "### غیر متوازن ڈیٹا سے نمٹنا\n",
    "\n",
    "غیر متوازن ڈیٹا اکثر ماڈل کی کارکردگی پر منفی اثر ڈالتا ہے۔ بہت سے ماڈلز بہترین کارکردگی تب دکھاتے ہیں جب مشاہدات کی تعداد برابر ہو، اور اسی وجہ سے غیر متوازن ڈیٹا کے ساتھ جدوجہد کرتے ہیں۔\n",
    "\n",
    "غیر متوازن ڈیٹا سیٹس سے نمٹنے کے دو اہم طریقے ہیں:\n",
    "\n",
    "-   اقلیت کلاس میں مشاہدات کا اضافہ کرنا: `اوور سیمپلنگ` جیسے SMOTE الگورتھم کا استعمال، جو اقلیت کلاس کے نئے مثالیں مصنوعی طور پر ان کیسز کے قریبی ہمسایوں کی بنیاد پر پیدا کرتا ہے۔\n",
    "\n",
    "-   اکثریت کلاس سے مشاہدات کو ہٹانا: `انڈر سیمپلنگ`\n",
    "\n",
    "پچھلے سبق میں، ہم نے دکھایا کہ کس طرح غیر متوازن ڈیٹا سیٹس سے نمٹنے کے لیے `recipe` کا استعمال کیا جا سکتا ہے۔ ایک recipe کو ایک خاکہ سمجھا جا سکتا ہے جو بیان کرتا ہے کہ ڈیٹا سیٹ پر تجزیہ کے لیے تیار کرنے کے لیے کون سے اقدامات کیے جانے چاہئیں۔ ہمارے معاملے میں، ہم اپنے `training set` کے لیے کھانوں کی تعداد میں مساوی تقسیم چاہتے ہیں۔ آئیے شروع کرتے ہیں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cRzTnHolhLWd"
   },
   "source": [
    "# Load themis package for dealing with imbalanced data\n",
    "library(themis)\n",
    "\n",
    "# Create a recipe for preprocessing training data\n",
    "cuisines_recipe <- recipe(cuisine ~ ., data = cuisines_train) %>%\n",
    "  step_smote(cuisine) \n",
    "\n",
    "# Print recipe\n",
    "cuisines_recipe"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxOQ2ORhhO81"
   },
   "source": [
    "اب ہم ماڈلز کی تربیت کے لیے تیار ہیں 👩‍💻👨‍💻!\n",
    "\n",
    "## 3. ملٹی نومیئل ریگریشن ماڈلز سے آگے\n",
    "\n",
    "پچھلے سبق میں، ہم نے ملٹی نومیئل ریگریشن ماڈلز کا جائزہ لیا تھا۔ آئیے کچھ زیادہ لچکدار ماڈلز کو کلاسفیکیشن کے لیے دریافت کرتے ہیں۔\n",
    "\n",
    "### سپورٹ ویکٹر مشینز\n",
    "\n",
    "کلاسفیکیشن کے تناظر میں، `Support Vector Machines` ایک مشین لرننگ تکنیک ہے جو ایک *ہائپرپلین* تلاش کرنے کی کوشش کرتی ہے جو کلاسز کو \"بہترین\" طریقے سے الگ کرے۔ آئیے ایک سادہ مثال دیکھتے ہیں:\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/svm.png\"\n",
    "   width=\"300\"/>\n",
    "   <figcaption>https://commons.wikimedia.org/w/index.php?curid=22877598</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4Wsd0vZhXYu"
   },
   "source": [
    "### کلاسز کو الگ کرنے کے اصول\n",
    "\n",
    "H1~ کلاسز کو الگ نہیں کرتا۔ H2~ الگ کرتا ہے، لیکن صرف ایک چھوٹے مارجن کے ساتھ۔ H3~ انہیں زیادہ سے زیادہ مارجن کے ساتھ الگ کرتا ہے۔\n",
    "\n",
    "#### لینیئر سپورٹ ویکٹر کلاسیفائر\n",
    "\n",
    "سپورٹ-ویکٹر کلسٹرنگ (SVC) مشین لرننگ تکنیکوں کے سپورٹ-ویکٹر مشینز خاندان کا حصہ ہے۔ SVC میں، ہائپرپلین کو اس طرح منتخب کیا جاتا ہے کہ وہ `زیادہ تر` ٹریننگ آبزرویشنز کو درست طریقے سے الگ کرے، لیکن `کچھ آبزرویشنز کو غلط` بھی کلاسیفائی کر سکتا ہے۔ کچھ پوائنٹس کو غلط طرف رکھنے کی اجازت دے کر، SVM آؤٹ لائرز کے لیے زیادہ مضبوط ہو جاتا ہے اور اس طرح نئے ڈیٹا کے لیے بہتر جنرلائزیشن فراہم کرتا ہے۔ اس خلاف ورزی کو کنٹرول کرنے والے پیرامیٹر کو `کاسٹ` کہا جاتا ہے، جس کی ڈیفالٹ ویلیو 1 ہے (دیکھیں `help(\"svm_poly\")`)۔\n",
    "\n",
    "آئیے ایک لینیئر SVC بناتے ہیں، جس کے لیے پولینومیل SVM ماڈل میں `degree = 1` سیٹ کریں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vJpp6nuChlBz"
   },
   "source": [
    "# Make a linear SVC specification\n",
    "svc_linear_spec <- svm_poly(degree = 1) %>% \n",
    "  set_engine(\"kernlab\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle specification and recipe into a worklow\n",
    "svc_linear_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(svc_linear_spec)\n",
    "\n",
    "# Print out workflow\n",
    "svc_linear_wf"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDs8cWNkhoqu"
   },
   "source": [
    "اب جب کہ ہم نے پری پروسیسنگ کے مراحل اور ماڈل کی وضاحت کو *workflow* میں شامل کر لیا ہے، ہم آگے بڑھ کر linear SVC کو تربیت دے سکتے ہیں اور اس کے ساتھ ہی نتائج کا جائزہ لے سکتے ہیں۔ کارکردگی کے پیمانوں کے لیے، آئیے ایک میٹرک سیٹ بناتے ہیں جو درج ذیل کا جائزہ لے گا: `accuracy`, `sensitivity`, `Positive Predicted Value` اور `F Measure`\n",
    "\n",
    "> `augment()` دیے گئے ڈیٹا میں پیش گوئیوں کے لیے کالم شامل کرے گا۔\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "81wiqcwuhrnq"
   },
   "source": [
    "# Train a linear SVC model\n",
    "svc_linear_fit <- svc_linear_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "# Create a metric set\n",
    "eval_metrics <- metric_set(ppv, sens, accuracy, f_meas)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "svc_linear_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UFQvHf-huo3"
   },
   "source": [
    "#### سپورٹ ویکٹر مشین\n",
    "\n",
    "سپورٹ ویکٹر مشین (SVM) سپورٹ ویکٹر کلاسیفائر کی توسیع ہے تاکہ کلاسز کے درمیان غیر خطی حد کو ایڈجسٹ کیا جا سکے۔ بنیادی طور پر، SVMs *کرنل ٹرک* کا استعمال کرتے ہیں تاکہ فیچر اسپیس کو بڑھایا جا سکے اور کلاسز کے درمیان غیر خطی تعلقات کے مطابق ڈھالا جا سکے۔ SVMs کے ذریعے استعمال ہونے والا ایک مشہور اور انتہائی لچکدار کرنل فنکشن *ریڈیل بیسز فنکشن* ہے۔ آئیے دیکھتے ہیں کہ یہ ہمارے ڈیٹا پر کیسا کارکردگی دکھائے گا۔\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-KX4S8mzhzmp"
   },
   "source": [
    "set.seed(2056)\n",
    "\n",
    "# Make an RBF SVM specification\n",
    "svm_rbf_spec <- svm_rbf() %>% \n",
    "  set_engine(\"kernlab\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle specification and recipe into a worklow\n",
    "svm_rbf_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(svm_rbf_spec)\n",
    "\n",
    "\n",
    "# Train an RBF model\n",
    "svm_rbf_fit <- svm_rbf_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "svm_rbf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBFSa7WSh4HQ"
   },
   "source": [
    "بہت بہتر 🤩!\n",
    "\n",
    "> ✅ براہ کرم دیکھیں:\n",
    ">\n",
    "> -   [*سپورٹ ویکٹر مشینز*](https://bradleyboehmke.github.io/HOML/svm.html)، ہینڈز آن مشین لرننگ ود آر\n",
    ">\n",
    "> -   [*سپورٹ ویکٹر مشینز*](https://www.statlearning.com/)، شماریاتی لرننگ کا تعارف آر کے ساتھ ایپلیکیشنز میں\n",
    ">\n",
    "> مزید مطالعے کے لیے۔\n",
    "\n",
    "### قریب ترین ہمسایہ درجہ بندی کرنے والے\n",
    "\n",
    "*K*-قریب ترین ہمسایہ (KNN) ایک ایسا الگورتھم ہے جس میں ہر مشاہدہ اس کی *مشابہت* کی بنیاد پر دیگر مشاہدات کے ساتھ پیش گوئی کیا جاتا ہے۔\n",
    "\n",
    "آئیے اسے اپنے ڈیٹا پر فٹ کرتے ہیں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k4BxxBcdh9Ka"
   },
   "source": [
    "# Make a KNN specification\n",
    "knn_spec <- nearest_neighbor() %>% \n",
    "  set_engine(\"kknn\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "knn_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(knn_spec)\n",
    "\n",
    "# Train a boosted tree model\n",
    "knn_wf_fit <- knn_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "knn_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaegQseriAcj"
   },
   "source": [
    "ایسا لگتا ہے کہ یہ ماڈل اتنا اچھا کام نہیں کر رہا۔ شاید ماڈل کے دلائل کو تبدیل کرنا (دیکھیں `help(\"nearest_neighbor\")`) ماڈل کی کارکردگی کو بہتر بنا سکتا ہے۔ ضرور اسے آزما کر دیکھیں۔\n",
    "\n",
    "> ✅ براہ کرم دیکھیں:\n",
    ">\n",
    "> -   [Hands-on Machine Learning with R](https://bradleyboehmke.github.io/HOML/)\n",
    ">\n",
    "> -   [An Introduction to Statistical Learning with Applications in R](https://www.statlearning.com/)\n",
    ">\n",
    "> مزید جاننے کے لیے کہ *K*-Nearest Neighbors classifiers کیسے کام کرتے ہیں۔\n",
    "\n",
    "### Ensemble classifiers\n",
    "\n",
    "Ensemble الگورتھمز کئی بنیادی تخمینوں کو یکجا کر کے ایک بہترین ماڈل تیار کرتے ہیں، یا تو:\n",
    "\n",
    "`bagging`: ایک *اوسط فنکشن* کو بنیادی ماڈلز کے مجموعے پر لاگو کرنا\n",
    "\n",
    "`boosting`: ماڈلز کی ایک ترتیب بنانا جو ایک دوسرے پر تعمیر کرتے ہیں تاکہ پیش گوئی کی کارکردگی کو بہتر بنایا جا سکے۔\n",
    "\n",
    "چلیں ایک Random Forest ماڈل آزما کر شروع کرتے ہیں، جو فیصلہ سازی کے درختوں کا ایک بڑا مجموعہ بناتا ہے اور پھر ایک اوسط فنکشن لاگو کرتا ہے تاکہ مجموعی طور پر ایک بہتر ماڈل تیار ہو۔\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "49DPoVs6iK1M"
   },
   "source": [
    "# Make a random forest specification\n",
    "rf_spec <- rand_forest() %>% \n",
    "  set_engine(\"ranger\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "rf_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(rf_spec)\n",
    "\n",
    "# Train a random forest model\n",
    "rf_wf_fit <- rf_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "rf_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGVYwC_aiUWc"
   },
   "source": [
    "شاندار کام 👏!\n",
    "\n",
    "آئیے ایک بوسٹڈ ٹری ماڈل کے ساتھ بھی تجربہ کریں۔\n",
    "\n",
    "بوسٹڈ ٹری ایک مجموعی طریقہ کار کی وضاحت کرتا ہے جو ایک سلسلہ وار فیصلہ درختوں کا ایک سلسلہ بناتا ہے، جہاں ہر درخت پچھلے درختوں کے نتائج پر منحصر ہوتا ہے تاکہ بتدریج غلطی کو کم کیا جا سکے۔ یہ غلط طور پر درجہ بند اشیاء کے وزن پر توجہ مرکوز کرتا ہے اور اگلے کلاسیفائر کے لیے فٹ کو ایڈجسٹ کرتا ہے تاکہ درستگی کی جا سکے۔\n",
    "\n",
    "اس ماڈل کو فٹ کرنے کے مختلف طریقے ہیں (دیکھیں `help(\"boost_tree\")`)۔ اس مثال میں، ہم بوسٹڈ ٹری کو `xgboost` انجن کے ذریعے فٹ کریں گے۔\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Py1YWo-micWs"
   },
   "source": [
    "# Make a boosted tree specification\n",
    "boost_spec <- boost_tree(trees = 200) %>% \n",
    "  set_engine(\"xgboost\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "boost_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(boost_spec)\n",
    "\n",
    "# Train a boosted tree model\n",
    "boost_wf_fit <- boost_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "boost_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNQnbuejigZM"
   },
   "source": [
    "✅ براہ کرم دیکھیں:\n",
    "\n",
    "-   [مشین لرننگ برائے سماجی سائنسدان](https://cimentadaj.github.io/ml_socsci/tree-based-methods.html#random-forests)\n",
    "\n",
    "-   [ہینڈز آن مشین لرننگ ود آر](https://bradleyboehmke.github.io/HOML/)\n",
    "\n",
    "-   [شماریاتی لرننگ کا تعارف آر کے ساتھ](https://www.statlearning.com/)\n",
    "\n",
    "-   <https://algotech.netlify.app/blog/xgboost/> - ایڈابوسٹ ماڈل کی تحقیق کرتا ہے جو xgboost کا ایک اچھا متبادل ہے۔\n",
    "\n",
    "تاکہ اینسمبل کلاسیفائرز کے بارے میں مزید جان سکیں۔\n",
    "\n",
    "## 4. اضافی - متعدد ماڈلز کا موازنہ\n",
    "\n",
    "ہم نے اس لیب میں کافی تعداد میں ماڈلز فٹ کیے ہیں 🙌۔ مختلف سیٹوں کے پری پروسیسرز اور/یا ماڈل کی وضاحتوں سے بہت سے ورک فلو بنانا اور پھر کارکردگی کے میٹرکس کو ایک ایک کرکے حساب لگانا تھکا دینے والا یا مشکل ہو سکتا ہے۔\n",
    "\n",
    "آئیے دیکھتے ہیں کہ کیا ہم اس مسئلے کو حل کر سکتے ہیں۔ ہم ایک فنکشن بنائیں گے جو ٹریننگ سیٹ پر ورک فلو کی فہرست فٹ کرے اور پھر ٹیسٹ سیٹ کی بنیاد پر کارکردگی کے میٹرکس واپس کرے۔ ہم [purrr](https://purrr.tidyverse.org/) پیکیج سے `map()` اور `map_dfr()` استعمال کریں گے تاکہ فہرست میں موجود ہر عنصر پر فنکشنز لاگو کریں۔\n",
    "\n",
    "> [`map()`](https://purrr.tidyverse.org/reference/map.html) فنکشنز آپ کو بہت سے فور لوپس کو ایسے کوڈ سے بدلنے کی اجازت دیتے ہیں جو زیادہ مختصر اور پڑھنے میں آسان ہو۔ [`map()`](https://purrr.tidyverse.org/reference/map.html) فنکشنز کے بارے میں سیکھنے کے لیے بہترین جگہ آر فار ڈیٹا سائنس میں [iteration chapter](http://r4ds.had.co.nz/iteration.html) ہے۔\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Qzb7LyZnimd2"
   },
   "source": [
    "set.seed(2056)\n",
    "\n",
    "# Create a metric set\n",
    "eval_metrics <- metric_set(ppv, sens, accuracy, f_meas)\n",
    "\n",
    "# Define a function that returns performance metrics\n",
    "compare_models <- function(workflow_list, train_set, test_set){\n",
    "  \n",
    "  suppressWarnings(\n",
    "    # Fit each model to the train_set\n",
    "    map(workflow_list, fit, data = train_set) %>% \n",
    "    # Make predictions on the test set\n",
    "      map_dfr(augment, new_data = test_set, .id = \"model\") %>%\n",
    "    # Select desired columns\n",
    "      select(model, cuisine, .pred_class) %>% \n",
    "    # Evaluate model performance\n",
    "      group_by(model) %>% \n",
    "      eval_metrics(truth = cuisine, estimate = .pred_class) %>% \n",
    "      ungroup()\n",
    "  )\n",
    "  \n",
    "} # End of function"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fwa712sNisDA"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3i4VJOi2iu-a"
   },
   "source": [
    "# Make a list of workflows\n",
    "workflow_list <- list(\n",
    "  \"svc\" = svc_linear_wf,\n",
    "  \"svm\" = svm_rbf_wf,\n",
    "  \"knn\" = knn_wf,\n",
    "  \"random_forest\" = rf_wf,\n",
    "  \"xgboost\" = boost_wf)\n",
    "\n",
    "# Call the function\n",
    "set.seed(2056)\n",
    "perf_metrics <- compare_models(workflow_list = workflow_list, train_set = cuisines_train, test_set = cuisines_test)\n",
    "\n",
    "# Print out performance metrics\n",
    "perf_metrics %>% \n",
    "  group_by(.metric) %>% \n",
    "  arrange(desc(.estimate)) %>% \n",
    "  slice_head(n=7)\n",
    "\n",
    "# Compare accuracy\n",
    "perf_metrics %>% \n",
    "  filter(.metric == \"accuracy\") %>% \n",
    "  arrange(desc(.estimate))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuWK_lEli4nW"
   },
   "source": [
    "[**workflowset**](https://workflowsets.tidymodels.org/) پیکیج صارفین کو بڑی تعداد میں ماڈلز بنانے اور آسانی سے فٹ کرنے کی اجازت دیتا ہے، لیکن یہ زیادہ تر `cross-validation` جیسی ریسمپلنگ تکنیکوں کے ساتھ کام کرنے کے لیے ڈیزائن کیا گیا ہے، جس پر ہم ابھی بات نہیں کر رہے ہیں۔\n",
    "\n",
    "## **🚀چیلنج**\n",
    "\n",
    "ان تکنیکوں میں سے ہر ایک کے پاس کئی پیرامیٹرز ہوتے ہیں جنہیں آپ تبدیل کر سکتے ہیں، جیسے کہ SVMs میں `cost`، KNN میں `neighbors`، اور رینڈم فورسٹ میں `mtry` (رینڈم طور پر منتخب کردہ پیش گوئی کرنے والے)۔\n",
    "\n",
    "ہر ماڈل کے ڈیفالٹ پیرامیٹرز پر تحقیق کریں اور سوچیں کہ ان پیرامیٹرز کو تبدیل کرنے سے ماڈل کے معیار پر کیا اثر پڑے گا۔\n",
    "\n",
    "کسی خاص ماڈل اور اس کے پیرامیٹرز کے بارے میں مزید جاننے کے لیے، یہ استعمال کریں: `help(\"model\")` مثلاً `help(\"rand_forest\")`\n",
    "\n",
    "> عملی طور پر، ہم عام طور پر ان کے *بہترین اقدار* کا *اندازہ* لگاتے ہیں، کئی ماڈلز کو `simulated data set` پر ٹرین کر کے اور یہ جانچ کر کے کہ یہ ماڈلز کتنے اچھے کام کرتے ہیں۔ اس عمل کو **tuning** کہا جاتا ہے۔\n",
    "\n",
    "### [**لیکچر کے بعد کا کوئز**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/24/)\n",
    "\n",
    "### **جائزہ اور خود مطالعہ**\n",
    "\n",
    "ان اسباق میں بہت زیادہ تکنیکی اصطلاحات ہیں، اس لیے ایک لمحہ نکال کر [اس فہرست](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) کا جائزہ لیں جو مفید اصطلاحات پر مشتمل ہے!\n",
    "\n",
    "#### شکریہ:\n",
    "\n",
    "[`ایلیسن ہورسٹ`](https://twitter.com/allison_horst/) کا شکریہ کہ انہوں نے شاندار تصاویر بنائیں جو R کو زیادہ خوش آئند اور دلچسپ بناتی ہیں۔ مزید تصاویر ان کے [گیلری](https://www.google.com/url?q=https://github.com/allisonhorst/stats-illustrations&sa=D&source=editors&ust=1626380772530000&usg=AOvVaw3zcfyCizFQZpkSLzxiiQEM) میں دیکھیں۔\n",
    "\n",
    "[Cassie Breviu](https://www.twitter.com/cassieview) اور [Jen Looper](https://www.twitter.com/jenlooper) کا شکریہ کہ انہوں نے اس ماڈیول کا اصل Python ورژن تخلیق کیا ♥️\n",
    "\n",
    "خوش رہیں اور سیکھتے رہیں،\n",
    "\n",
    "[Eric](https://twitter.com/ericntay)، گولڈ مائیکروسافٹ لرن اسٹوڈنٹ ایمبیسیڈر۔\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/r_learners_sm.jpeg\"\n",
    "   width=\"569\"/>\n",
    "   <figcaption>تصویر: @allison_horst</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**ڈسکلیمر**:  \nیہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا عدم درستگی ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے لیے ہم ذمہ دار نہیں ہیں۔\n"
   ]
  }
 ]
}