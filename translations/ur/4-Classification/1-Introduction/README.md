<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "aaf391d922bd6de5efba871d514c6d47",
  "translation_date": "2025-09-06T08:56:19+00:00",
  "source_file": "4-Classification/1-Introduction/README.md",
  "language_code": "ur"
}
-->
# تعارف برائے کلاسیفکیشن

ان چار اسباق میں، آپ مشین لرننگ کے ایک بنیادی پہلو - _کلاسیفکیشن_ - کو دریافت کریں گے۔ ہم مختلف کلاسیفکیشن الگورتھمز کا استعمال کریں گے ایک ڈیٹاسیٹ کے ساتھ جو ایشیا اور بھارت کے شاندار کھانوں کے بارے میں ہے۔ امید ہے کہ آپ بھوکے ہیں!

![صرف ایک چٹکی!](../../../../4-Classification/1-Introduction/images/pinch.png)

> ان اسباق میں پین-ایشیائی کھانوں کا جشن منائیں! تصویر: [Jen Looper](https://twitter.com/jenlooper)

کلاسیفکیشن [سپر وائزڈ لرننگ](https://wikipedia.org/wiki/Supervised_learning) کی ایک قسم ہے جو ریگریشن تکنیکوں سے کافی مشابہت رکھتی ہے۔ اگر مشین لرننگ کا مقصد ڈیٹاسیٹس کا استعمال کرتے ہوئے چیزوں کے نام یا قدریں پیش گوئی کرنا ہے، تو کلاسیفکیشن عام طور پر دو گروپوں میں تقسیم ہوتی ہے: _بائنری کلاسیفکیشن_ اور _ملٹی کلاس کلاسیفکیشن_۔

[![کلاسیفکیشن کا تعارف](https://img.youtube.com/vi/eg8DJYwdMyg/0.jpg)](https://youtu.be/eg8DJYwdMyg "کلاسیفکیشن کا تعارف")

> 🎥 اوپر دی گئی تصویر پر کلک کریں ویڈیو کے لیے: MIT کے جان گٹٹیگ کلاسیفکیشن کا تعارف کروا رہے ہیں

یاد رکھیں:

- **لینیئر ریگریشن** نے آپ کو متغیرات کے درمیان تعلقات کی پیش گوئی کرنے اور یہ اندازہ لگانے میں مدد دی کہ ایک نیا ڈیٹا پوائنٹ اس لائن کے ساتھ کہاں گرے گا۔ مثال کے طور پر، آپ پیش گوئی کر سکتے ہیں کہ _ستمبر کے مقابلے میں دسمبر میں کدو کی قیمت کیا ہوگی_۔
- **لاجسٹک ریگریشن** نے آپ کو "بائنری کیٹیگریز" دریافت کرنے میں مدد دی: اس قیمت پر، _کیا یہ کدو نارنجی ہے یا غیر نارنجی؟_

کلاسیفکیشن مختلف الگورتھمز کا استعمال کرتی ہے تاکہ یہ تعین کیا جا سکے کہ کسی ڈیٹا پوائنٹ کا لیبل یا کلاس کیا ہو سکتا ہے۔ آئیے اس کھانے کے ڈیٹاسیٹ کے ساتھ کام کریں تاکہ یہ دیکھ سکیں کہ اجزاء کے ایک گروپ کو دیکھ کر ہم اس کے کھانے کی اصل کا تعین کر سکتے ہیں یا نہیں۔

## [لیکچر سے پہلے کا کوئز](https://ff-quizzes.netlify.app/en/ml/)

> ### [یہ سبق R میں بھی دستیاب ہے!](../../../../4-Classification/1-Introduction/solution/R/lesson_10.html)

### تعارف

کلاسیفکیشن مشین لرننگ کے محقق اور ڈیٹا سائنسدان کی بنیادی سرگرمیوں میں سے ایک ہے۔ چاہے یہ کسی بائنری ویلیو کی بنیادی کلاسیفکیشن ہو ("کیا یہ ای میل اسپیم ہے یا نہیں؟") یا کمپیوٹر وژن کا استعمال کرتے ہوئے پیچیدہ امیج کلاسیفکیشن اور سیگمنٹیشن، ڈیٹا کو کلاسز میں ترتیب دینا اور اس سے سوالات پوچھنا ہمیشہ مفید ہوتا ہے۔

اگر اس عمل کو زیادہ سائنسی انداز میں بیان کیا جائے، تو آپ کا کلاسیفکیشن طریقہ ایک پیش گوئی ماڈل بناتا ہے جو ان پٹ متغیرات اور آؤٹ پٹ متغیرات کے درمیان تعلق کو نقشہ بنانے کے قابل بناتا ہے۔

![بائنری بمقابلہ ملٹی کلاس کلاسیفکیشن](../../../../4-Classification/1-Introduction/images/binary-multiclass.png)

> بائنری بمقابلہ ملٹی کلاس مسائل جنہیں کلاسیفکیشن الگورتھمز ہینڈل کرتے ہیں۔ انفوگرافک: [Jen Looper](https://twitter.com/jenlooper)

اپنے ڈیٹا کو صاف کرنے، اسے بصری بنانے، اور مشین لرننگ کے کاموں کے لیے تیار کرنے کے عمل کو شروع کرنے سے پہلے، آئیے یہ سیکھیں کہ مشین لرننگ کو ڈیٹا کی کلاسیفکیشن کے لیے کس طرح استعمال کیا جا سکتا ہے۔

[شماریات](https://wikipedia.org/wiki/Statistical_classification) سے ماخوذ، کلاسیکی مشین لرننگ کا استعمال کرتے ہوئے کلاسیفکیشن خصوصیات جیسے `smoker`، `weight`، اور `age` کا استعمال کرتی ہے تاکہ _کسی بیماری کے ہونے کے امکان_ کا تعین کیا جا سکے۔ جیسا کہ آپ نے پہلے ریگریشن مشقوں میں کیا، یہ ایک سپر وائزڈ لرننگ تکنیک ہے، جہاں آپ کا ڈیٹا لیبل شدہ ہوتا ہے اور مشین لرننگ الگورتھمز ان لیبلز کا استعمال کرتے ہوئے ڈیٹاسیٹ کی کلاسز (یا 'خصوصیات') کی پیش گوئی کرتے ہیں اور انہیں کسی گروپ یا نتیجے میں تفویض کرتے ہیں۔

✅ ایک لمحہ نکال کر کھانوں کے بارے میں ایک ڈیٹاسیٹ کا تصور کریں۔ ایک ملٹی کلاس ماڈل کیا جواب دے سکتا ہے؟ ایک بائنری ماڈل کیا جواب دے سکتا ہے؟ اگر آپ یہ تعین کرنا چاہتے ہیں کہ آیا کسی خاص کھانے میں میتھی استعمال ہوتی ہے یا نہیں؟ یا اگر آپ یہ دیکھنا چاہتے ہیں کہ، اگر آپ کو ستارے کی سونف، آرٹچوک، گوبھی، اور ہارسریڈش سے بھرا ہوا ایک گروسری بیگ دیا جائے، تو کیا آپ ایک عام بھارتی ڈش بنا سکتے ہیں؟

[![پراسرار باسکٹ](https://img.youtube.com/vi/GuTeDbaNoEU/0.jpg)](https://youtu.be/GuTeDbaNoEU "پراسرار باسکٹ")

> 🎥 اوپر دی گئی تصویر پر کلک کریں ویڈیو کے لیے۔ شو 'چاپڈ' کا پورا مقصد 'مستری باسکٹ' ہے، جہاں شیفس کو اجزاء کے ایک بے ترتیب انتخاب سے کوئی ڈش بنانی ہوتی ہے۔ یقیناً ایک مشین لرننگ ماڈل مددگار ثابت ہوتا!

## ہیلو 'کلاسیفائر'

ہم اس کھانے کے ڈیٹاسیٹ سے جو سوال پوچھنا چاہتے ہیں وہ دراصل ایک **ملٹی کلاس سوال** ہے، کیونکہ ہمارے پاس کام کرنے کے لیے کئی ممکنہ قومی کھانے ہیں۔ اجزاء کے ایک بیچ کو دیکھتے ہوئے، ان میں سے کون سی کلاسز ڈیٹا کے مطابق ہوں گی؟

Scikit-learn مختلف الگورتھمز پیش کرتا ہے جو آپ کے مسئلے کی نوعیت کے مطابق ڈیٹا کو کلاسیفائی کرنے کے لیے استعمال کیے جا سکتے ہیں۔ اگلے دو اسباق میں، آپ ان الگورتھمز کے بارے میں سیکھیں گے۔

## مشق - اپنے ڈیٹا کو صاف کریں اور متوازن بنائیں

پہلا کام، اس پروجیکٹ کو شروع کرنے سے پہلے، یہ ہے کہ آپ اپنے ڈیٹا کو صاف کریں اور **متوازن** بنائیں تاکہ بہتر نتائج حاصل ہو سکیں۔ اس فولڈر کی جڑ میں موجود _notebook.ipynb_ فائل سے شروع کریں۔

پہلی چیز جو انسٹال کرنی ہے وہ ہے [imblearn](https://imbalanced-learn.org/stable/)، جو Scikit-learn کا ایک پیکیج ہے جو آپ کو ڈیٹا کو بہتر طریقے سے متوازن بنانے کی اجازت دے گا (آپ اس کام کے بارے میں مزید سیکھیں گے)۔

1. `imblearn` انسٹال کرنے کے لیے، `pip install` چلائیں، اس طرح:

    ```python
    pip install imblearn
    ```

1. وہ پیکیجز درآمد کریں جن کی آپ کو اپنے ڈیٹا کو درآمد کرنے اور بصری بنانے کے لیے ضرورت ہے، اور `SMOTE` کو `imblearn` سے درآمد کریں۔

    ```python
    import pandas as pd
    import matplotlib.pyplot as plt
    import matplotlib as mpl
    import numpy as np
    from imblearn.over_sampling import SMOTE
    ```

    اب آپ اگلے مرحلے میں ڈیٹا درآمد کرنے کے لیے تیار ہیں۔

1. اگلا کام ڈیٹا کو درآمد کرنا ہوگا:

    ```python
    df  = pd.read_csv('../data/cuisines.csv')
    ```

   `read_csv()` کا استعمال کرتے ہوئے، _cusines.csv_ فائل کے مواد کو پڑھا جائے گا اور اسے متغیر `df` میں رکھا جائے گا۔

1. ڈیٹا کی شکل چیک کریں:

    ```python
    df.head()
    ```

   پہلے پانچ قطاریں اس طرح نظر آتی ہیں:

    ```output
    |     | Unnamed: 0 | cuisine | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood | yam | yeast | yogurt | zucchini |
    | --- | ---------- | ------- | ------ | -------- | ----- | ---------- | ----- | ------------ | ------- | -------- | --- | ------- | ----------- | ---------- | ----------------------- | ---- | ---- | --- | ----- | ------ | -------- |
    | 0   | 65         | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
    | 1   | 66         | indian  | 1      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
    | 2   | 67         | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
    | 3   | 68         | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
    | 4   | 69         | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 1      | 0        |
    ```

1. اس ڈیٹا کے بارے میں معلومات حاصل کریں `info()` کو کال کرکے:

    ```python
    df.info()
    ```

    آپ کا آؤٹ پٹ اس طرح نظر آتا ہے:

    ```output
    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 2448 entries, 0 to 2447
    Columns: 385 entries, Unnamed: 0 to zucchini
    dtypes: int64(384), object(1)
    memory usage: 7.2+ MB
    ```

## مشق - کھانوں کے بارے میں سیکھنا

اب کام زیادہ دلچسپ ہونا شروع ہو جاتا ہے۔ آئیے ڈیٹا کی تقسیم کو دریافت کریں، ہر کھانے کے لحاظ سے۔

1. ڈیٹا کو بارز کے طور پر `barh()` کو کال کرکے پلاٹ کریں:

    ```python
    df.cuisine.value_counts().plot.barh()
    ```

    ![کھانے کے ڈیٹا کی تقسیم](../../../../4-Classification/1-Introduction/images/cuisine-dist.png)

    کھانوں کی ایک محدود تعداد ہے، لیکن ڈیٹا کی تقسیم غیر متوازن ہے۔ آپ اسے ٹھیک کر سکتے ہیں! ایسا کرنے سے پہلے، تھوڑا اور دریافت کریں۔

1. معلوم کریں کہ ہر کھانے کے لیے کتنا ڈیٹا دستیاب ہے اور اسے پرنٹ کریں:

    ```python
    thai_df = df[(df.cuisine == "thai")]
    japanese_df = df[(df.cuisine == "japanese")]
    chinese_df = df[(df.cuisine == "chinese")]
    indian_df = df[(df.cuisine == "indian")]
    korean_df = df[(df.cuisine == "korean")]
    
    print(f'thai df: {thai_df.shape}')
    print(f'japanese df: {japanese_df.shape}')
    print(f'chinese df: {chinese_df.shape}')
    print(f'indian df: {indian_df.shape}')
    print(f'korean df: {korean_df.shape}')
    ```

    آؤٹ پٹ اس طرح نظر آتا ہے:

    ```output
    thai df: (289, 385)
    japanese df: (320, 385)
    chinese df: (442, 385)
    indian df: (598, 385)
    korean df: (799, 385)
    ```

## اجزاء دریافت کرنا

اب آپ ڈیٹا میں مزید گہرائی میں جا سکتے ہیں اور یہ جان سکتے ہیں کہ ہر کھانے کے لیے عام اجزاء کیا ہیں۔ آپ کو بار بار آنے والے ڈیٹا کو صاف کرنا چاہیے جو کھانوں کے درمیان الجھن پیدا کرتا ہے، تو آئیے اس مسئلے کے بارے میں سیکھیں۔

1. Python میں ایک فنکشن `create_ingredient()` بنائیں تاکہ ایک اجزاء کا ڈیٹافریم بنایا جا سکے۔ یہ فنکشن ایک غیر مددگار کالم کو ہٹا کر اور اجزاء کو ان کی گنتی کے لحاظ سے ترتیب دے کر شروع کرے گا:

    ```python
    def create_ingredient_df(df):
        ingredient_df = df.T.drop(['cuisine','Unnamed: 0']).sum(axis=1).to_frame('value')
        ingredient_df = ingredient_df[(ingredient_df.T != 0).any()]
        ingredient_df = ingredient_df.sort_values(by='value', ascending=False,
        inplace=False)
        return ingredient_df
    ```

   اب آپ اس فنکشن کا استعمال کرکے ہر کھانے کے لیے سب سے زیادہ مقبول دس اجزاء کا اندازہ لگا سکتے ہیں۔

1. `create_ingredient()` کو کال کریں اور اسے `barh()` کو کال کرکے پلاٹ کریں:

    ```python
    thai_ingredient_df = create_ingredient_df(thai_df)
    thai_ingredient_df.head(10).plot.barh()
    ```

    ![تھائی](../../../../4-Classification/1-Introduction/images/thai.png)

1. جاپانی ڈیٹا کے لیے بھی ایسا ہی کریں:

    ```python
    japanese_ingredient_df = create_ingredient_df(japanese_df)
    japanese_ingredient_df.head(10).plot.barh()
    ```

    ![جاپانی](../../../../4-Classification/1-Introduction/images/japanese.png)

1. اب چینی اجزاء کے لیے:

    ```python
    chinese_ingredient_df = create_ingredient_df(chinese_df)
    chinese_ingredient_df.head(10).plot.barh()
    ```

    ![چینی](../../../../4-Classification/1-Introduction/images/chinese.png)

1. بھارتی اجزاء کو پلاٹ کریں:

    ```python
    indian_ingredient_df = create_ingredient_df(indian_df)
    indian_ingredient_df.head(10).plot.barh()
    ```

    ![بھارتی](../../../../4-Classification/1-Introduction/images/indian.png)

1. آخر میں، کوریائی اجزاء کو پلاٹ کریں:

    ```python
    korean_ingredient_df = create_ingredient_df(korean_df)
    korean_ingredient_df.head(10).plot.barh()
    ```

    ![کوریائی](../../../../4-Classification/1-Introduction/images/korean.png)

1. اب، ان سب سے عام اجزاء کو ہٹا دیں جو مختلف کھانوں کے درمیان الجھن پیدا کرتے ہیں، `drop()` کو کال کرکے:

   ہر کوئی چاول، لہسن، اور ادرک پسند کرتا ہے!

    ```python
    feature_df= df.drop(['cuisine','Unnamed: 0','rice','garlic','ginger'], axis=1)
    labels_df = df.cuisine #.unique()
    feature_df.head()
    ```

## ڈیٹاسیٹ کو متوازن بنائیں

اب جب کہ آپ نے ڈیٹا کو صاف کر لیا ہے، [SMOTE](https://imbalanced-learn.org/dev/references/generated/imblearn.over_sampling.SMOTE.html) - "Synthetic Minority Over-sampling Technique" - کا استعمال کریں تاکہ اسے متوازن بنایا جا سکے۔

1. `fit_resample()` کو کال کریں، یہ حکمت عملی انٹرپولیشن کے ذریعے نئے نمونے تیار کرتی ہے۔

    ```python
    oversample = SMOTE()
    transformed_feature_df, transformed_label_df = oversample.fit_resample(feature_df, labels_df)
    ```

    اپنے ڈیٹا کو متوازن بنا کر، آپ کلاسیفکیشن کرتے وقت بہتر نتائج حاصل کریں گے۔ بائنری کلاسیفکیشن کے بارے میں سوچیں۔ اگر آپ کے زیادہ تر ڈیٹا کا تعلق ایک کلاس سے ہے، تو ایک مشین لرننگ ماڈل اس کلاس کی زیادہ پیش گوئی کرے گا، صرف اس لیے کہ اس کے لیے زیادہ ڈیٹا موجود ہے۔ ڈیٹا کو متوازن بنانا کسی بھی غیر متوازن ڈیٹا کو درست کرنے میں مدد کرتا ہے۔

1. اب آپ اجزاء کے لحاظ سے لیبلز کی تعداد چیک کر سکتے ہیں:

    ```python
    print(f'new label count: {transformed_label_df.value_counts()}')
    print(f'old label count: {df.cuisine.value_counts()}')
    ```

    آپ کا آؤٹ پٹ اس طرح نظر آتا ہے:

    ```output
    new label count: korean      799
    chinese     799
    indian      799
    japanese    799
    thai        799
    Name: cuisine, dtype: int64
    old label count: korean      799
    indian      598
    chinese     442
    japanese    320
    thai        289
    Name: cuisine, dtype: int64
    ```

    ڈیٹا صاف، متوازن، اور بہت مزیدار ہے!

1. آخری مرحلہ یہ ہے کہ اپنے متوازن ڈیٹا کو، بشمول لیبلز اور خصوصیات، ایک نئے ڈیٹافریم میں محفوظ کریں جسے فائل میں برآمد کیا جا سکے:

    ```python
    transformed_df = pd.concat([transformed_label_df,transformed_feature_df],axis=1, join='outer')
    ```

1. آپ `transformed_df.head()` اور `transformed_df.info()` کا استعمال کرکے ڈیٹا پر ایک اور نظر ڈال سکتے ہیں۔ اس ڈیٹا کی ایک کاپی مستقبل کے اسباق کے لیے محفوظ کریں:

    ```python
    transformed_df.head()
    transformed_df.info()
    transformed_df.to_csv("../data/cleaned_cuisines.csv")
    ```

    یہ تازہ CSV اب روٹ ڈیٹا فولڈر میں پایا جا سکتا ہے۔

---

## 🚀چیلنج

اس نصاب میں کئی دلچسپ ڈیٹاسیٹس شامل ہیں۔ `data` فولڈرز کو کھنگالیں اور دیکھیں کہ کیا ان میں سے کوئی ڈیٹاسیٹ بائنری یا ملٹی کلاس کلاسیفکیشن کے لیے موزوں ہے؟ آپ اس ڈیٹاسیٹ سے کیا سوالات پوچھیں گے؟

## [لیکچر کے بعد کا کوئز](https://ff-quizzes.netlify.app/en/ml/)

## جائزہ اور خود مطالعہ

SMOTE کے API کو دریافت کریں۔ یہ کن استعمالات کے لیے بہترین ہے؟ یہ کن مسائل کو حل کرتا ہے؟

## اسائنمنٹ

[کلاسیفکیشن کے طریقے دریافت کریں](assignment.md)

---

**ڈسکلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا غیر درستیاں ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ ہم اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ذمہ دار نہیں ہیں۔