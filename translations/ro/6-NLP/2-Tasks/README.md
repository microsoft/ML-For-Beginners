<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "5f3cb462e3122e1afe7ab0050ccf2bd3",
  "translation_date": "2025-09-05T16:51:49+00:00",
  "source_file": "6-NLP/2-Tasks/README.md",
  "language_code": "ro"
}
-->
# Sarcini È™i tehnici comune de procesare a limbajului natural

Pentru majoritatea sarcinilor de *procesare a limbajului natural*, textul care trebuie procesat trebuie sÄƒ fie descompus, examinat, iar rezultatele stocate sau corelate cu reguli È™i seturi de date. Aceste sarcini permit programatorului sÄƒ derive _semnificaÈ›ia_ sau _intenÈ›ia_ sau doar _frecvenÈ›a_ termenilor È™i cuvintelor dintr-un text.

## [Chestionar Ã®nainte de lecÈ›ie](https://ff-quizzes.netlify.app/en/ml/)

SÄƒ descoperim tehnicile comune utilizate Ã®n procesarea textului. Combinate cu Ã®nvÄƒÈ›area automatÄƒ, aceste tehnici te ajutÄƒ sÄƒ analizezi eficient cantitÄƒÈ›i mari de text. TotuÈ™i, Ã®nainte de a aplica ML acestor sarcini, sÄƒ Ã®nÈ›elegem problemele Ã®ntÃ¢mpinate de un specialist NLP.

## Sarcini comune Ã®n NLP

ExistÄƒ diferite moduri de a analiza un text pe care lucrezi. ExistÄƒ sarcini pe care le poÈ›i efectua È™i, prin aceste sarcini, poÈ›i Ã®nÈ›elege textul È™i trage concluzii. De obicei, aceste sarcini sunt realizate Ã®ntr-o anumitÄƒ ordine.

### Tokenizare

Probabil primul lucru pe care majoritatea algoritmilor NLP trebuie sÄƒ-l facÄƒ este sÄƒ Ã®mpartÄƒ textul Ã®n tokeni sau cuvinte. DeÈ™i pare simplu, luarea Ã®n considerare a punctuaÈ›iei È™i a delimitatorilor de cuvinte È™i propoziÈ›ii din diferite limbi poate fi complicatÄƒ. Este posibil sÄƒ fie nevoie sÄƒ foloseÈ™ti diverse metode pentru a determina delimitÄƒrile.

![tokenizare](../../../../6-NLP/2-Tasks/images/tokenization.png)
> Tokenizarea unei propoziÈ›ii din **MÃ¢ndrie È™i PrejudecatÄƒ**. Infografic de [Jen Looper](https://twitter.com/jenlooper)

### Embedding-uri

[Embedding-urile de cuvinte](https://wikipedia.org/wiki/Word_embedding) sunt o modalitate de a converti datele text Ã®n format numeric. Embedding-urile sunt realizate astfel Ã®ncÃ¢t cuvintele cu semnificaÈ›ii similare sau cuvintele utilizate Ã®mpreunÄƒ sÄƒ se grupeze.

![embedding-uri de cuvinte](../../../../6-NLP/2-Tasks/images/embedding.png)
> "Am cel mai mare respect pentru nervii tÄƒi, sunt prietenii mei vechi." - Embedding-uri de cuvinte pentru o propoziÈ›ie din **MÃ¢ndrie È™i PrejudecatÄƒ**. Infografic de [Jen Looper](https://twitter.com/jenlooper)

âœ… ÃncearcÄƒ [acest instrument interesant](https://projector.tensorflow.org/) pentru a experimenta cu embedding-uri de cuvinte. Clic pe un cuvÃ¢nt aratÄƒ grupuri de cuvinte similare: 'jucÄƒrie' se grupeazÄƒ cu 'disney', 'lego', 'playstation' È™i 'consolÄƒ'.

### Parsing È™i Etichetarea pÄƒrÈ›ilor de vorbire

Fiecare cuvÃ¢nt care a fost tokenizat poate fi etichetat ca parte de vorbire - substantiv, verb sau adjectiv. PropoziÈ›ia `vulpea roÈ™ie rapidÄƒ a sÄƒrit peste cÃ¢inele maro leneÈ™` ar putea fi etichetatÄƒ POS astfel: vulpea = substantiv, sÄƒrit = verb.

![parsing](../../../../6-NLP/2-Tasks/images/parse.png)

> Parsing-ul unei propoziÈ›ii din **MÃ¢ndrie È™i PrejudecatÄƒ**. Infografic de [Jen Looper](https://twitter.com/jenlooper)

Parsing-ul Ã®nseamnÄƒ recunoaÈ™terea cuvintelor care sunt legate Ã®ntre ele Ã®ntr-o propoziÈ›ie - de exemplu, `vulpea roÈ™ie rapidÄƒ a sÄƒrit` este o secvenÈ›Äƒ adjectiv-substantiv-verb care este separatÄƒ de secvenÈ›a `cÃ¢inele maro leneÈ™`.

### FrecvenÈ›a cuvintelor È™i expresiilor

O procedurÄƒ utilÄƒ atunci cÃ¢nd analizezi un corp mare de text este sÄƒ construieÈ™ti un dicÈ›ionar al fiecÄƒrui cuvÃ¢nt sau expresie de interes È™i cÃ¢t de des apare. Expresia `vulpea roÈ™ie rapidÄƒ a sÄƒrit peste cÃ¢inele maro leneÈ™` are o frecvenÈ›Äƒ de 2 pentru cuvÃ¢ntul "the".

SÄƒ analizÄƒm un exemplu de text Ã®n care numÄƒrÄƒm frecvenÈ›a cuvintelor. Poemul lui Rudyard Kipling, The Winners, conÈ›ine urmÄƒtorul vers:

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

Deoarece frecvenÈ›ele expresiilor pot fi insensibile sau sensibile la majuscule, expresia `un prieten` are o frecvenÈ›Äƒ de 2, `the` are o frecvenÈ›Äƒ de 6, iar `travels` are o frecvenÈ›Äƒ de 2.

### N-gramuri

Un text poate fi Ã®mpÄƒrÈ›it Ã®n secvenÈ›e de cuvinte de o lungime setatÄƒ, un singur cuvÃ¢nt (unigram), douÄƒ cuvinte (bigram), trei cuvinte (trigram) sau orice numÄƒr de cuvinte (n-gramuri).

De exemplu, `vulpea roÈ™ie rapidÄƒ a sÄƒrit peste cÃ¢inele maro leneÈ™` cu un scor n-gram de 2 produce urmÄƒtoarele n-gramuri:

1. vulpea roÈ™ie  
2. roÈ™ie rapidÄƒ  
3. rapidÄƒ a  
4. a sÄƒrit  
5. sÄƒrit peste  
6. peste cÃ¢inele  
7. cÃ¢inele maro  
8. maro leneÈ™  

Ar putea fi mai uÈ™or sÄƒ vizualizezi acest lucru ca o fereastrÄƒ glisantÄƒ peste propoziÈ›ie. IatÄƒ cum aratÄƒ pentru n-gramuri de 3 cuvinte, n-gramul fiind evidenÈ›iat Ã®n fiecare propoziÈ›ie:

1.   <u>**vulpea roÈ™ie rapidÄƒ**</u> a sÄƒrit peste cÃ¢inele maro leneÈ™  
2.   vulpea **<u>roÈ™ie rapidÄƒ a</u>** sÄƒrit peste cÃ¢inele maro leneÈ™  
3.   vulpea roÈ™ie **<u>rapidÄƒ a sÄƒrit</u>** peste cÃ¢inele maro leneÈ™  
4.   vulpea roÈ™ie rapidÄƒ **<u>a sÄƒrit peste</u>** cÃ¢inele maro leneÈ™  
5.   vulpea roÈ™ie rapidÄƒ a **<u>sÄƒrit peste cÃ¢inele</u>** maro leneÈ™  
6.   vulpea roÈ™ie rapidÄƒ a sÄƒrit **<u>peste cÃ¢inele maro</u>** leneÈ™  
7.   vulpea roÈ™ie rapidÄƒ a sÄƒrit peste <u>**cÃ¢inele maro leneÈ™**</u>  

![fereastrÄƒ glisantÄƒ n-gramuri](../../../../6-NLP/2-Tasks/images/n-grams.gif)

> Valoare n-gram de 3: Infografic de [Jen Looper](https://twitter.com/jenlooper)

### ExtracÈ›ia expresiilor nominale

Ãn majoritatea propoziÈ›iilor, existÄƒ un substantiv care este subiectul sau obiectul propoziÈ›iei. Ãn englezÄƒ, acesta poate fi identificat adesea prin prezenÈ›a cuvintelor 'a', 'an' sau 'the' Ã®naintea sa. Identificarea subiectului sau obiectului unei propoziÈ›ii prin 'extracÈ›ia expresiei nominale' este o sarcinÄƒ comunÄƒ Ã®n NLP atunci cÃ¢nd se Ã®ncearcÄƒ Ã®nÈ›elegerea semnificaÈ›iei unei propoziÈ›ii.

âœ… Ãn propoziÈ›ia "Nu pot fixa ora, sau locul, sau privirea sau cuvintele, care au pus bazele. Este prea demult. Eram Ã®n mijloc Ã®nainte sÄƒ È™tiu cÄƒ am Ã®nceput.", poÈ›i identifica expresiile nominale?

Ãn propoziÈ›ia `vulpea roÈ™ie rapidÄƒ a sÄƒrit peste cÃ¢inele maro leneÈ™` existÄƒ 2 expresii nominale: **vulpea roÈ™ie rapidÄƒ** È™i **cÃ¢inele maro leneÈ™**.

### Analiza sentimentului

O propoziÈ›ie sau un text poate fi analizat pentru sentiment, sau cÃ¢t de *pozitiv* sau *negativ* este. Sentimentul este mÄƒsurat Ã®n *polaritate* È™i *obiectivitate/subiectivitate*. Polaritatea este mÄƒsuratÄƒ de la -1.0 la 1.0 (negativ la pozitiv) È™i de la 0.0 la 1.0 (cel mai obiectiv la cel mai subiectiv).

âœ… Mai tÃ¢rziu vei Ã®nvÄƒÈ›a cÄƒ existÄƒ diferite moduri de a determina sentimentul folosind Ã®nvÄƒÈ›area automatÄƒ, dar un mod este sÄƒ ai o listÄƒ de cuvinte È™i expresii care sunt categorisite ca pozitive sau negative de un expert uman È™i sÄƒ aplici acel model textului pentru a calcula un scor de polaritate. PoÈ›i vedea cum ar funcÈ›iona acest lucru Ã®n unele circumstanÈ›e È™i mai puÈ›in bine Ã®n altele?

### Flexiune

Flexiunea Ã®È›i permite sÄƒ iei un cuvÃ¢nt È™i sÄƒ obÈ›ii forma singularÄƒ sau pluralÄƒ a acestuia.

### Lemmatizare

Un *lemma* este rÄƒdÄƒcina sau cuvÃ¢ntul principal pentru un set de cuvinte, de exemplu *zburat*, *zboarÄƒ*, *zburÃ¢nd* au ca lemma verbul *a zbura*.

ExistÄƒ, de asemenea, baze de date utile disponibile pentru cercetÄƒtorii NLP, Ã®n special:

### WordNet

[WordNet](https://wordnet.princeton.edu/) este o bazÄƒ de date de cuvinte, sinonime, antonime È™i multe alte detalii pentru fiecare cuvÃ¢nt Ã®n multe limbi diferite. Este incredibil de utilÄƒ atunci cÃ¢nd se Ã®ncearcÄƒ construirea de traduceri, verificatoare ortografice sau instrumente lingvistice de orice tip.

## Biblioteci NLP

Din fericire, nu trebuie sÄƒ construieÈ™ti toate aceste tehnici singur, deoarece existÄƒ biblioteci excelente de Python disponibile care le fac mult mai accesibile pentru dezvoltatorii care nu sunt specializaÈ›i Ã®n procesarea limbajului natural sau Ã®nvÄƒÈ›area automatÄƒ. LecÈ›iile urmÄƒtoare includ mai multe exemple despre acestea, dar aici vei Ã®nvÄƒÈ›a cÃ¢teva exemple utile pentru a te ajuta cu urmÄƒtoarea sarcinÄƒ.

### ExerciÈ›iu - utilizarea bibliotecii `TextBlob`

SÄƒ folosim o bibliotecÄƒ numitÄƒ TextBlob, deoarece conÈ›ine API-uri utile pentru abordarea acestor tipuri de sarcini. TextBlob "se bazeazÄƒ pe umerii giganÈ›ilor [NLTK](https://nltk.org) È™i [pattern](https://github.com/clips/pattern), È™i funcÈ›ioneazÄƒ bine cu ambele." Are o cantitate considerabilÄƒ de ML integratÄƒ Ã®n API-ul sÄƒu.

> NotÄƒ: Un [Ghid de Start Rapid](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart) util este disponibil pentru TextBlob È™i este recomandat pentru dezvoltatorii Python experimentaÈ›i.

CÃ¢nd Ã®ncerci sÄƒ identifici *expresii nominale*, TextBlob oferÄƒ mai multe opÈ›iuni de extractoare pentru a gÄƒsi expresii nominale.

1. AruncÄƒ o privire la `ConllExtractor`.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > Ce se Ã®ntÃ¢mplÄƒ aici? [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) este "Un extractor de expresii nominale care foloseÈ™te parsing-ul de fragmente antrenat cu corpusul de antrenament ConLL-2000." ConLL-2000 se referÄƒ la ConferinÈ›a din 2000 despre ÃnvÄƒÈ›area ComputaÈ›ionalÄƒ a Limbajului Natural. Fiecare an, conferinÈ›a a gÄƒzduit un workshop pentru a aborda o problemÄƒ dificilÄƒ NLP, iar Ã®n 2000 aceasta a fost fragmentarea expresiilor nominale. Un model a fost antrenat pe Wall Street Journal, cu "secÈ›iunile 15-18 ca date de antrenament (211727 tokeni) È™i secÈ›iunea 20 ca date de testare (47377 tokeni)". PoÈ›i consulta procedurile utilizate [aici](https://www.clips.uantwerpen.be/conll2000/chunking/) È™i [rezultatele](https://ifarm.nl/erikt/research/np-chunking.html).

### Provocare - Ã®mbunÄƒtÄƒÈ›irea botului tÄƒu cu NLP

Ãn lecÈ›ia anterioarÄƒ ai construit un bot foarte simplu de Ã®ntrebÄƒri È™i rÄƒspunsuri. Acum, vei face ca Marvin sÄƒ fie puÈ›in mai empatic analizÃ¢nd inputul tÄƒu pentru sentiment È™i afiÈ™Ã¢nd un rÄƒspuns care sÄƒ se potriveascÄƒ sentimentului. De asemenea, va trebui sÄƒ identifici o `expresie nominalÄƒ` È™i sÄƒ Ã®ntrebi despre aceasta.

PaÈ™ii tÄƒi pentru construirea unui bot conversaÈ›ional mai bun:

1. AfiÈ™eazÄƒ instrucÈ›iuni care sfÄƒtuiesc utilizatorul cum sÄƒ interacÈ›ioneze cu botul  
2. PorneÈ™te bucla  
   1. AcceptÄƒ inputul utilizatorului  
   2. DacÄƒ utilizatorul a cerut sÄƒ iasÄƒ, atunci ieÈ™i  
   3. ProceseazÄƒ inputul utilizatorului È™i determinÄƒ rÄƒspunsul adecvat pentru sentiment  
   4. DacÄƒ se detecteazÄƒ o expresie nominalÄƒ Ã®n sentiment, pluralizeaz-o È™i cere mai multe informaÈ›ii despre acel subiect  
   5. AfiÈ™eazÄƒ rÄƒspunsul  
3. Revino la pasul 2  

IatÄƒ fragmentul de cod pentru determinarea sentimentului folosind TextBlob. ObservÄƒ cÄƒ existÄƒ doar patru *grade* de rÄƒspunsuri la sentiment (poÈ›i avea mai multe dacÄƒ doreÈ™ti):

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

IatÄƒ un exemplu de output pentru a te ghida (inputul utilizatorului este pe liniile care Ã®ncep cu >):

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

O soluÈ›ie posibilÄƒ pentru sarcinÄƒ este [aici](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/2-Tasks/solution/bot.py)

âœ… Verificare cunoÈ™tinÈ›e

1. Crezi cÄƒ rÄƒspunsurile empatice ar putea 'pÄƒcÄƒli' pe cineva sÄƒ creadÄƒ cÄƒ botul chiar Ã®i Ã®nÈ›elege?  
2. Face identificarea expresiei nominale botul mai 'credibil'?  
3. De ce ar fi utilÄƒ extragerea unei 'expresii nominale' dintr-o propoziÈ›ie?  

---

ImplementeazÄƒ botul din verificarea cunoÈ™tinÈ›elor anterioare È™i testeazÄƒ-l pe un prieten. Poate sÄƒ-l pÄƒcÄƒleascÄƒ? PoÈ›i face botul tÄƒu mai 'credibil'?

## ğŸš€Provocare

Ia o sarcinÄƒ din verificarea cunoÈ™tinÈ›elor anterioare È™i Ã®ncearcÄƒ sÄƒ o implementezi. TesteazÄƒ botul pe un prieten. Poate sÄƒ-l pÄƒcÄƒleascÄƒ? PoÈ›i face botul tÄƒu mai 'credibil'?

## [Chestionar dupÄƒ lecÈ›ie](https://ff-quizzes.netlify.app/en/ml/)

## Recapitulare È™i Studiu Individual

Ãn urmÄƒtoarele cÃ¢teva lecÈ›ii vei Ã®nvÄƒÈ›a mai multe despre analiza sentimentului. CerceteazÄƒ aceastÄƒ tehnicÄƒ interesantÄƒ Ã®n articole precum cele de pe [KDNuggets](https://www.kdnuggets.com/tag/nlp)

## TemÄƒ

[FÄƒ un bot sÄƒ rÄƒspundÄƒ](assignment.md)

---

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). DeÈ™i ne strÄƒduim sÄƒ asigurÄƒm acurateÈ›ea, vÄƒ rugÄƒm sÄƒ fiÈ›i conÈ™tienÈ›i cÄƒ traducerile automate pot conÈ›ine erori sau inexactitÄƒÈ›i. Documentul original Ã®n limba sa natalÄƒ ar trebui considerat sursa autoritarÄƒ. Pentru informaÈ›ii critice, se recomandÄƒ traducerea profesionalÄƒ realizatÄƒ de un specialist uman. Nu ne asumÄƒm responsabilitatea pentru eventualele neÃ®nÈ›elegeri sau interpretÄƒri greÈ™ite care pot apÄƒrea din utilizarea acestei traduceri.