<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "482bccabe1df958496ea71a3667995cd",
  "translation_date": "2025-09-05T15:38:01+00:00",
  "source_file": "7-TimeSeries/3-SVR/README.md",
  "language_code": "ro"
}
-->
# Predic탵ia seriilor temporale cu Support Vector Regressor

칉n lec탵ia anterioar캒, ai 칥nv캒탵at cum s캒 folose탳ti modelul ARIMA pentru a face predic탵ii ale seriilor temporale. Acum vei explora modelul Support Vector Regressor, un model de regresie utilizat pentru a prezice date continue.

## [Chestionar 칥nainte de lec탵ie](https://ff-quizzes.netlify.app/en/ml/) 

## Introducere

칉n aceast캒 lec탵ie, vei descoperi o metod캒 specific캒 de a construi modele cu [**SVM**: **S**upport **V**ector **M**achine](https://en.wikipedia.org/wiki/Support-vector_machine) pentru regresie, sau **SVR: Support Vector Regressor**. 

### SVR 칥n contextul seriilor temporale [^1]

칉nainte de a 칥n탵elege importan탵a SVR 칥n predic탵ia seriilor temporale, iat캒 c칙teva concepte importante pe care trebuie s캒 le cuno탳ti:

- **Regresie:** Tehnic캒 de 칥nv캒탵are supravegheat캒 pentru a prezice valori continue dintr-un set dat de intr캒ri. Ideea este de a ajusta o curb캒 (sau o linie) 칥n spa탵iul caracteristicilor care s캒 includ캒 c칙t mai multe puncte de date. [Click aici](https://en.wikipedia.org/wiki/Regression_analysis) pentru mai multe informa탵ii.
- **Support Vector Machine (SVM):** Un tip de model de 칥nv캒탵are automat캒 supravegheat utilizat pentru clasificare, regresie 탳i detectarea anomaliilor. Modelul este un hiperplan 칥n spa탵iul caracteristicilor, care, 칥n cazul clasific캒rii, ac탵ioneaz캒 ca o grani탵캒, iar 칥n cazul regresiei, ac탵ioneaz캒 ca linia de ajustare optim캒. 칉n SVM, o func탵ie Kernel este utilizat캒 칥n general pentru a transforma setul de date 칥ntr-un spa탵iu cu un num캒r mai mare de dimensiuni, astfel 칥nc칙t s캒 fie mai u탳or separabil. [Click aici](https://en.wikipedia.org/wiki/Support-vector_machine) pentru mai multe informa탵ii despre SVM.
- **Support Vector Regressor (SVR):** Un tip de SVM, utilizat pentru a g캒si linia de ajustare optim캒 (care, 칥n cazul SVM, este un hiperplan) ce include c칙t mai multe puncte de date.

### De ce SVR? [^1]

칉n lec탵ia anterioar캒 ai 칥nv캒탵at despre ARIMA, care este o metod캒 statistic캒 liniar캒 foarte eficient캒 pentru a prezice datele seriilor temporale. Totu탳i, 칥n multe cazuri, datele seriilor temporale prezint캒 *non-liniaritate*, care nu poate fi modelat캒 de metodele liniare. 칉n astfel de cazuri, abilitatea SVM de a considera non-liniaritatea datelor pentru sarcinile de regresie face ca SVR s캒 fie eficient 칥n predic탵ia seriilor temporale.

## Exerci탵iu - construirea unui model SVR

Primele c칙teva etape pentru preg캒tirea datelor sunt acelea탳i ca 칥n lec탵ia anterioar캒 despre [ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA). 

Deschide folderul [_/working_](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/3-SVR/working) din aceast캒 lec탵ie 탳i g캒se탳te fi탳ierul [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/7-TimeSeries/3-SVR/working/notebook.ipynb). [^2]

1. Ruleaz캒 notebook-ul 탳i import캒 bibliotecile necesare: [^2]

   ```python
   import sys
   sys.path.append('../../')
   ```

   ```python
   import os
   import warnings
   import matplotlib.pyplot as plt
   import numpy as np
   import pandas as pd
   import datetime as dt
   import math
   
   from sklearn.svm import SVR
   from sklearn.preprocessing import MinMaxScaler
   from common.utils import load_data, mape
   ```

2. 칉ncarc캒 datele din fi탳ierul `/data/energy.csv` 칥ntr-un dataframe Pandas 탳i analizeaz캒-le: [^2]

   ```python
   energy = load_data('../../data')[['load']]
   ```

3. Ploteaz캒 toate datele disponibile despre energie din ianuarie 2012 p칙n캒 칥n decembrie 2014: [^2]

   ```python
   energy.plot(y='load', subplots=True, figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![date complete](../../../../7-TimeSeries/3-SVR/images/full-data.png)

   Acum, s캒 construim modelul SVR.

### Crearea seturilor de date pentru antrenare 탳i testare

Acum datele tale sunt 칥nc캒rcate, a탳a c캒 le po탵i separa 칥n seturi de antrenare 탳i testare. Apoi vei rearanja datele pentru a crea un set de date bazat pe pa탳i de timp, necesar pentru SVR. Vei antrena modelul pe setul de antrenare. Dup캒 ce modelul a terminat antrenarea, 칥i vei evalua acurate탵ea pe setul de antrenare, setul de testare 탳i apoi pe 칥ntregul set de date pentru a vedea performan탵a general캒. Trebuie s캒 te asiguri c캒 setul de testare acoper캒 o perioad캒 ulterioar캒 칥n timp fa탵캒 de setul de antrenare pentru a te asigura c캒 modelul nu ob탵ine informa탵ii din perioadele viitoare [^2] (o situa탵ie cunoscut캒 sub numele de *Overfitting*).

1. Aloc캒 o perioad캒 de dou캒 luni, de la 1 septembrie p칙n캒 la 31 octombrie 2014, pentru setul de antrenare. Setul de testare va include perioada de dou캒 luni de la 1 noiembrie p칙n캒 la 31 decembrie 2014: [^2]

   ```python
   train_start_dt = '2014-11-01 00:00:00'
   test_start_dt = '2014-12-30 00:00:00'
   ```

2. Vizualizeaz캒 diferen탵ele: [^2]

   ```python
   energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)][['load']].rename(columns={'load':'train'}) \
       .join(energy[test_start_dt:][['load']].rename(columns={'load':'test'}), how='outer') \
       .plot(y=['train', 'test'], figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![date de antrenare 탳i testare](../../../../7-TimeSeries/3-SVR/images/train-test.png)

### Preg캒tirea datelor pentru antrenare

Acum trebuie s캒 preg캒te탳ti datele pentru antrenare prin filtrarea 탳i scalarea acestora. Filtreaz캒 setul de date pentru a include doar perioadele de timp 탳i coloanele necesare, 탳i scaleaz캒 datele pentru a te asigura c캒 sunt proiectate 칥n intervalul 0,1.

1. Filtreaz캒 setul de date original pentru a include doar perioadele de timp men탵ionate anterior pentru fiecare set 탳i doar coloana necesar캒 'load' plus data: [^2]

   ```python
   train = energy.copy()[(energy.index >= train_start_dt) & (energy.index < test_start_dt)][['load']]
   test = energy.copy()[energy.index >= test_start_dt][['load']]
   
   print('Training data shape: ', train.shape)
   print('Test data shape: ', test.shape)
   ```

   ```output
   Training data shape:  (1416, 1)
   Test data shape:  (48, 1)
   ```
   
2. Scaleaz캒 datele de antrenare pentru a fi 칥n intervalul (0, 1): [^2]

   ```python
   scaler = MinMaxScaler()
   train['load'] = scaler.fit_transform(train)
   ```
   
4. Acum scaleaz캒 datele de testare: [^2]

   ```python
   test['load'] = scaler.transform(test)
   ```

### Crearea datelor cu pa탳i de timp [^1]

Pentru SVR, transformi datele de intrare 칥n forma `[batch, timesteps]`. A탳adar, rearanjezi `train_data` 탳i `test_data` existente astfel 칥nc칙t s캒 existe o nou캒 dimensiune care se refer캒 la pa탳ii de timp. 

```python
# Converting to numpy arrays
train_data = train.values
test_data = test.values
```

Pentru acest exemplu, lu캒m `timesteps = 5`. A탳adar, intr캒rile modelului sunt datele pentru primii 4 pa탳i de timp, iar ie탳irea va fi datele pentru al 5-lea pas de timp.

```python
timesteps=5
```

Conversia datelor de antrenare 칥ntr-un tensor 2D folosind list comprehension:

```python
train_data_timesteps=np.array([[j for j in train_data[i:i+timesteps]] for i in range(0,len(train_data)-timesteps+1)])[:,:,0]
train_data_timesteps.shape
```

```output
(1412, 5)
```

Conversia datelor de testare 칥ntr-un tensor 2D:

```python
test_data_timesteps=np.array([[j for j in test_data[i:i+timesteps]] for i in range(0,len(test_data)-timesteps+1)])[:,:,0]
test_data_timesteps.shape
```

```output
(44, 5)
```

Selectarea intr캒rilor 탳i ie탳irilor din datele de antrenare 탳i testare:

```python
x_train, y_train = train_data_timesteps[:,:timesteps-1],train_data_timesteps[:,[timesteps-1]]
x_test, y_test = test_data_timesteps[:,:timesteps-1],test_data_timesteps[:,[timesteps-1]]

print(x_train.shape, y_train.shape)
print(x_test.shape, y_test.shape)
```

```output
(1412, 4) (1412, 1)
(44, 4) (44, 1)
```

### Implementarea SVR [^1]

Acum este momentul s캒 implementezi SVR. Pentru a citi mai multe despre aceast캒 implementare, po탵i consulta [aceast캒 documenta탵ie](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html). Pentru implementarea noastr캒, urm캒m ace탳ti pa탳i:

  1. Definim modelul apel칙nd `SVR()` 탳i trec칙nd hiperparametrii modelului: kernel, gamma, c 탳i epsilon
  2. Preg캒tim modelul pentru datele de antrenare apel칙nd func탵ia `fit()`
  3. Facem predic탵ii apel칙nd func탵ia `predict()`

Acum cre캒m un model SVR. Aici folosim [kernelul RBF](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel) 탳i set캒m hiperparametrii gamma, C 탳i epsilon la 0.5, 10 탳i 0.05 respectiv.

```python
model = SVR(kernel='rbf',gamma=0.5, C=10, epsilon = 0.05)
```

#### Antreneaz캒 modelul pe datele de antrenare [^1]

```python
model.fit(x_train, y_train[:,0])
```

```output
SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.05, gamma=0.5,
    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)
```

#### Realizeaz캒 predic탵ii cu modelul [^1]

```python
y_train_pred = model.predict(x_train).reshape(-1,1)
y_test_pred = model.predict(x_test).reshape(-1,1)

print(y_train_pred.shape, y_test_pred.shape)
```

```output
(1412, 1) (44, 1)
```

Ai construit modelul SVR! Acum trebuie s캒-l evalu캒m.

### Evalueaz캒 modelul [^1]

Pentru evaluare, mai 칥nt칙i vom scala 칥napoi datele la scara original캒. Apoi, pentru a verifica performan탵a, vom plota graficul seriei temporale originale 탳i prezise 탳i vom afi탳a rezultatul MAPE.

Scaleaz캒 ie탳irea prezis캒 탳i cea original캒:

```python
# Scaling the predictions
y_train_pred = scaler.inverse_transform(y_train_pred)
y_test_pred = scaler.inverse_transform(y_test_pred)

print(len(y_train_pred), len(y_test_pred))
```

```python
# Scaling the original values
y_train = scaler.inverse_transform(y_train)
y_test = scaler.inverse_transform(y_test)

print(len(y_train), len(y_test))
```

#### Verific캒 performan탵a modelului pe datele de antrenare 탳i testare [^1]

Extragem marcajele temporale din setul de date pentru a le afi탳a pe axa x a graficului nostru. Observ캒 c캒 folosim primele ```timesteps-1``` valori ca intrare pentru prima ie탳ire, astfel 칥nc칙t marcajele temporale pentru ie탳ire vor 칥ncepe dup캒 aceea.

```python
train_timestamps = energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)].index[timesteps-1:]
test_timestamps = energy[test_start_dt:].index[timesteps-1:]

print(len(train_timestamps), len(test_timestamps))
```

```output
1412 44
```

Ploteaz캒 predic탵iile pentru datele de antrenare:

```python
plt.figure(figsize=(25,6))
plt.plot(train_timestamps, y_train, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(train_timestamps, y_train_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.title("Training data prediction")
plt.show()
```

![predic탵ia datelor de antrenare](../../../../7-TimeSeries/3-SVR/images/train-data-predict.png)

Afi탳eaz캒 MAPE pentru datele de antrenare

```python
print('MAPE for training data: ', mape(y_train_pred, y_train)*100, '%')
```

```output
MAPE for training data: 1.7195710200875551 %
```

Ploteaz캒 predic탵iile pentru datele de testare

```python
plt.figure(figsize=(10,3))
plt.plot(test_timestamps, y_test, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(test_timestamps, y_test_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![predic탵ia datelor de testare](../../../../7-TimeSeries/3-SVR/images/test-data-predict.png)

Afi탳eaz캒 MAPE pentru datele de testare

```python
print('MAPE for testing data: ', mape(y_test_pred, y_test)*100, '%')
```

```output
MAPE for testing data:  1.2623790187854018 %
```

游끥 Ai ob탵inut un rezultat foarte bun pe setul de date de testare!

### Verific캒 performan탵a modelului pe 칥ntregul set de date [^1]

```python
# Extracting load values as numpy array
data = energy.copy().values

# Scaling
data = scaler.transform(data)

# Transforming to 2D tensor as per model input requirement
data_timesteps=np.array([[j for j in data[i:i+timesteps]] for i in range(0,len(data)-timesteps+1)])[:,:,0]
print("Tensor shape: ", data_timesteps.shape)

# Selecting inputs and outputs from data
X, Y = data_timesteps[:,:timesteps-1],data_timesteps[:,[timesteps-1]]
print("X shape: ", X.shape,"\nY shape: ", Y.shape)
```

```output
Tensor shape:  (26300, 5)
X shape:  (26300, 4) 
Y shape:  (26300, 1)
```

```python
# Make model predictions
Y_pred = model.predict(X).reshape(-1,1)

# Inverse scale and reshape
Y_pred = scaler.inverse_transform(Y_pred)
Y = scaler.inverse_transform(Y)
```

```python
plt.figure(figsize=(30,8))
plt.plot(Y, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(Y_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![predic탵ia datelor complete](../../../../7-TimeSeries/3-SVR/images/full-data-predict.png)

```python
print('MAPE: ', mape(Y_pred, Y)*100, '%')
```

```output
MAPE:  2.0572089029888656 %
```

游끥 Grafice foarte frumoase, care arat캒 un model cu o acurate탵e bun캒. Felicit캒ri!

---

## 游Provocare

- 칉ncearc캒 s캒 ajustezi hiperparametrii (gamma, C, epsilon) 칥n timp ce creezi modelul 탳i evalueaz캒-l pe date pentru a vedea care set de hiperparametri ofer캒 cele mai bune rezultate pe datele de testare. Pentru a afla mai multe despre ace탳ti hiperparametri, po탵i consulta documentul [aici](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel). 
- 칉ncearc캒 s캒 folose탳ti func탵ii kernel diferite pentru model 탳i analizeaz캒 performan탵ele acestora pe setul de date. Un document util poate fi g캒sit [aici](https://scikit-learn.org/stable/modules/svm.html#kernel-functions).
- 칉ncearc캒 s캒 folose탳ti valori diferite pentru `timesteps` pentru ca modelul s캒 priveasc캒 칥napoi pentru a face predic탵ii.

## [Chestionar dup캒 lec탵ie](https://ff-quizzes.netlify.app/en/ml/)

## Recapitulare 탳i studiu individual

Aceast캒 lec탵ie a fost pentru a introduce aplica탵ia SVR pentru predic탵ia seriilor temporale. Pentru a citi mai multe despre SVR, po탵i consulta [acest blog](https://www.analyticsvidhya.com/blog/2020/03/support-vector-regression-tutorial-for-machine-learning/). Aceast캒 [documenta탵ie despre scikit-learn](https://scikit-learn.org/stable/modules/svm.html) ofer캒 o explica탵ie mai cuprinz캒toare despre SVM-uri 칥n general, [SVR-uri](https://scikit-learn.org/stable/modules/svm.html#regression) 탳i, de asemenea, alte detalii de implementare, cum ar fi diferitele [func탵ii kernel](https://scikit-learn.org/stable/modules/svm.html#kernel-functions) care pot fi utilizate 탳i parametrii acestora.

## Tem캒

[Un nou model SVR](assignment.md)

## Credite

[^1]: Textul, codul 탳i rezultatele din aceast캒 sec탵iune au fost contribuite de [@AnirbanMukherjeeXD](https://github.com/AnirbanMukherjeeXD)
[^2]: Textul, codul 탳i rezultatele din aceast캒 sec탵iune au fost preluate din [ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA)

---

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). De탳i ne str캒duim s캒 asigur캒m acurate탵ea, v캒 rug캒m s캒 fi탵i con탳tien탵i c캒 traducerile automate pot con탵ine erori sau inexactit캒탵i. Documentul original 칥n limba sa natal캒 ar trebui considerat sursa autoritar캒. Pentru informa탵ii critice, se recomand캒 traducerea profesional캒 realizat캒 de un specialist uman. Nu ne asum캒m responsabilitatea pentru eventualele ne칥n탵elegeri sau interpret캒ri gre탳ite care pot ap캒rea din utilizarea acestei traduceri.