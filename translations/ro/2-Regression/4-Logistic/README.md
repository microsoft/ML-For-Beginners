<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "abf86d845c84330bce205a46b382ec88",
  "translation_date": "2025-09-05T15:18:34+00:00",
  "source_file": "2-Regression/4-Logistic/README.md",
  "language_code": "ro"
}
-->
# Regresie logisticÄƒ pentru a prezice categorii

![Infografic despre regresia logisticÄƒ vs. regresia liniarÄƒ](../../../../2-Regression/4-Logistic/images/linear-vs-logistic.png)

## [Chestionar Ã®nainte de lecÈ›ie](https://ff-quizzes.netlify.app/en/ml/)

> ### [AceastÄƒ lecÈ›ie este disponibilÄƒ È™i Ã®n R!](../../../../2-Regression/4-Logistic/solution/R/lesson_4.html)

## Introducere

Ãn aceastÄƒ ultimÄƒ lecÈ›ie despre regresie, una dintre tehnicile clasice de bazÄƒ ale ML, vom analiza regresia logisticÄƒ. AceastÄƒ tehnicÄƒ este utilizatÄƒ pentru a descoperi modele care prezic categorii binare. Este aceastÄƒ bomboanÄƒ ciocolatÄƒ sau nu? Este aceastÄƒ boalÄƒ contagioasÄƒ sau nu? Va alege acest client produsul sau nu?

Ãn aceastÄƒ lecÈ›ie, vei Ã®nvÄƒÈ›a:

- O nouÄƒ bibliotecÄƒ pentru vizualizarea datelor
- Tehnici pentru regresia logisticÄƒ

âœ… AprofundeazÄƒ Ã®nÈ›elegerea lucrului cu acest tip de regresie Ã®n acest [modul de Ã®nvÄƒÈ›are](https://docs.microsoft.com/learn/modules/train-evaluate-classification-models?WT.mc_id=academic-77952-leestott)

## Prerechizite

DupÄƒ ce am lucrat cu datele despre dovleci, suntem suficient de familiarizaÈ›i cu ele pentru a realiza cÄƒ existÄƒ o categorie binarÄƒ cu care putem lucra: `Color`.

SÄƒ construim un model de regresie logisticÄƒ pentru a prezice, pe baza unor variabile, _ce culoare este probabil sÄƒ aibÄƒ un dovleac_ (portocaliu ğŸƒ sau alb ğŸ‘»).

> De ce discutÄƒm despre clasificarea binarÄƒ Ã®ntr-o lecÈ›ie despre regresie? Doar din comoditate lingvisticÄƒ, deoarece regresia logisticÄƒ este [de fapt o metodÄƒ de clasificare](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression), deÈ™i bazatÄƒ pe regresie liniarÄƒ. ÃnvaÈ›Äƒ despre alte metode de clasificare a datelor Ã®n urmÄƒtorul grup de lecÈ›ii.

## Definirea Ã®ntrebÄƒrii

Pentru scopurile noastre, vom exprima aceasta ca o binarÄƒ: 'Alb' sau 'Nu Alb'. ExistÄƒ È™i o categorie 'dungat' Ã®n setul nostru de date, dar existÄƒ puÈ›ine instanÈ›e ale acesteia, aÈ™a cÄƒ nu o vom folosi. Oricum dispare odatÄƒ ce eliminÄƒm valorile nule din setul de date.

> ğŸƒ Fapt amuzant: uneori numim dovlecii albi 'dovleci fantomÄƒ'. Nu sunt foarte uÈ™or de sculptat, aÈ™a cÄƒ nu sunt la fel de populari ca cei portocalii, dar aratÄƒ interesant! AÈ™adar, am putea reformula Ã®ntrebarea noastrÄƒ astfel: 'Fantoma' sau 'Nu Fantoma'. ğŸ‘»

## Despre regresia logisticÄƒ

Regresia logisticÄƒ diferÄƒ de regresia liniarÄƒ, pe care ai Ã®nvÄƒÈ›at-o anterior, Ã®n cÃ¢teva moduri importante.

[![ML pentru Ã®ncepÄƒtori - ÃnÈ›elegerea regresiei logistice pentru clasificarea Ã®n Ã®nvÄƒÈ›area automatÄƒ](https://img.youtube.com/vi/KpeCT6nEpBY/0.jpg)](https://youtu.be/KpeCT6nEpBY "ML pentru Ã®ncepÄƒtori - ÃnÈ›elegerea regresiei logistice pentru clasificarea Ã®n Ã®nvÄƒÈ›area automatÄƒ")

> ğŸ¥ FÄƒ clic pe imaginea de mai sus pentru un scurt videoclip despre regresia logisticÄƒ.

### Clasificare binarÄƒ

Regresia logisticÄƒ nu oferÄƒ aceleaÈ™i caracteristici ca regresia liniarÄƒ. Prima oferÄƒ o predicÈ›ie despre o categorie binarÄƒ ("alb sau nu alb"), Ã®n timp ce cea de-a doua este capabilÄƒ sÄƒ prezicÄƒ valori continue, de exemplu, avÃ¢nd Ã®n vedere originea unui dovleac È™i momentul recoltÄƒrii, _cÃ¢t de mult va creÈ™te preÈ›ul sÄƒu_.

![Model de clasificare a dovlecilor](../../../../2-Regression/4-Logistic/images/pumpkin-classifier.png)
> Infografic de [Dasani Madipalli](https://twitter.com/dasani_decoded)

### Alte clasificÄƒri

ExistÄƒ alte tipuri de regresie logisticÄƒ, inclusiv multinomialÄƒ È™i ordonatÄƒ:

- **MultinomialÄƒ**, care implicÄƒ mai multe categorii - "Portocaliu, Alb È™i Dungat".
- **OrdonatÄƒ**, care implicÄƒ categorii ordonate, utilÄƒ dacÄƒ dorim sÄƒ ordonÄƒm rezultatele logic, cum ar fi dovlecii noÈ™tri care sunt ordonaÈ›i dupÄƒ un numÄƒr finit de dimensiuni (mini, mic, mediu, mare, XL, XXL).

![Regresie multinomialÄƒ vs ordonatÄƒ](../../../../2-Regression/4-Logistic/images/multinomial-vs-ordinal.png)

### Variabilele NU trebuie sÄƒ fie corelate

ÃÈ›i aminteÈ™ti cum regresia liniarÄƒ funcÈ›iona mai bine cu variabile mai corelate? Regresia logisticÄƒ este opusul - variabilele nu trebuie sÄƒ fie aliniate. Acest lucru funcÈ›ioneazÄƒ pentru aceste date care au corelaÈ›ii destul de slabe.

### Ai nevoie de multe date curate

Regresia logisticÄƒ va oferi rezultate mai precise dacÄƒ foloseÈ™ti mai multe date; setul nostru mic de date nu este optim pentru aceastÄƒ sarcinÄƒ, aÈ™a cÄƒ È›ine cont de acest lucru.

[![ML pentru Ã®ncepÄƒtori - Analiza È™i pregÄƒtirea datelor pentru regresia logisticÄƒ](https://img.youtube.com/vi/B2X4H9vcXTs/0.jpg)](https://youtu.be/B2X4H9vcXTs "ML pentru Ã®ncepÄƒtori - Analiza È™i pregÄƒtirea datelor pentru regresia logisticÄƒ")

âœ… GÃ¢ndeÈ™te-te la tipurile de date care s-ar potrivi bine regresiei logistice.

## ExerciÈ›iu - curÄƒÈ›area datelor

Mai Ã®ntÃ¢i, curÄƒÈ›Äƒ puÈ›in datele, eliminÃ¢nd valorile nule È™i selectÃ¢nd doar cÃ¢teva coloane:

1. AdaugÄƒ urmÄƒtorul cod:

    ```python
  
    columns_to_select = ['City Name','Package','Variety', 'Origin','Item Size', 'Color']
    pumpkins = full_pumpkins.loc[:, columns_to_select]

    pumpkins.dropna(inplace=True)
    ```

    PoÈ›i oricÃ¢nd sÄƒ arunci o privire asupra noului tÄƒu dataframe:

    ```python
    pumpkins.info
    ```

### Vizualizare - grafic categorial

PÃ¢nÄƒ acum ai Ã®ncÄƒrcat [notebook-ul de Ã®nceput](../../../../2-Regression/4-Logistic/notebook.ipynb) cu datele despre dovleci din nou È™i le-ai curÄƒÈ›at astfel Ã®ncÃ¢t sÄƒ pÄƒstrezi un set de date care conÈ›ine cÃ¢teva variabile, inclusiv `Color`. SÄƒ vizualizÄƒm dataframe-ul Ã®n notebook folosind o bibliotecÄƒ diferitÄƒ: [Seaborn](https://seaborn.pydata.org/index.html), care este construitÄƒ pe Matplotlib pe care l-am folosit anterior.

Seaborn oferÄƒ cÃ¢teva modalitÄƒÈ›i interesante de a vizualiza datele tale. De exemplu, poÈ›i compara distribuÈ›iile datelor pentru fiecare `Variety` È™i `Color` Ã®ntr-un grafic categorial.

1. CreeazÄƒ un astfel de grafic folosind funcÈ›ia `catplot`, utilizÃ¢nd datele noastre despre dovleci `pumpkins` È™i specificÃ¢nd o mapare de culori pentru fiecare categorie de dovleci (portocaliu sau alb):

    ```python
    import seaborn as sns
    
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }

    sns.catplot(
    data=pumpkins, y="Variety", hue="Color", kind="count",
    palette=palette, 
    )
    ```

    ![O grilÄƒ de date vizualizate](../../../../2-Regression/4-Logistic/images/pumpkins_catplot_1.png)

    ObservÃ¢nd datele, poÈ›i vedea cum datele despre culoare se raporteazÄƒ la varietate.

    âœ… AvÃ¢nd acest grafic categorial, ce explorÄƒri interesante poÈ›i imagina?

### Pre-procesarea datelor: codificarea caracteristicilor È™i etichetelor

Setul nostru de date despre dovleci conÈ›ine valori de tip string pentru toate coloanele sale. Lucrul cu date categoriale este intuitiv pentru oameni, dar nu pentru maÈ™ini. Algoritmii de Ã®nvÄƒÈ›are automatÄƒ funcÈ›ioneazÄƒ bine cu numere. De aceea, codificarea este un pas foarte important Ã®n faza de pre-procesare a datelor, deoarece ne permite sÄƒ transformÄƒm datele categoriale Ã®n date numerice, fÄƒrÄƒ a pierde informaÈ›ii. O codificare bunÄƒ duce la construirea unui model bun.

Pentru codificarea caracteristicilor existÄƒ douÄƒ tipuri principale de codificatori:

1. Codificator ordinal: se potriveÈ™te bine pentru variabile ordinale, care sunt variabile categoriale unde datele lor urmeazÄƒ o ordine logicÄƒ, cum ar fi coloana `Item Size` din setul nostru de date. CreeazÄƒ o mapare astfel Ã®ncÃ¢t fiecare categorie sÄƒ fie reprezentatÄƒ de un numÄƒr, care este ordinea categoriei Ã®n coloanÄƒ.

    ```python
    from sklearn.preprocessing import OrdinalEncoder

    item_size_categories = [['sml', 'med', 'med-lge', 'lge', 'xlge', 'jbo', 'exjbo']]
    ordinal_features = ['Item Size']
    ordinal_encoder = OrdinalEncoder(categories=item_size_categories)
    ```

2. Codificator categorial: se potriveÈ™te bine pentru variabile nominale, care sunt variabile categoriale unde datele lor nu urmeazÄƒ o ordine logicÄƒ, cum ar fi toate caracteristicile diferite de `Item Size` din setul nostru de date. Este o codificare one-hot, ceea ce Ã®nseamnÄƒ cÄƒ fiecare categorie este reprezentatÄƒ de o coloanÄƒ binarÄƒ: variabila codificatÄƒ este egalÄƒ cu 1 dacÄƒ dovleacul aparÈ›ine acelei varietÄƒÈ›i È™i 0 altfel.

    ```python
    from sklearn.preprocessing import OneHotEncoder

    categorical_features = ['City Name', 'Package', 'Variety', 'Origin']
    categorical_encoder = OneHotEncoder(sparse_output=False)
    ```

Apoi, `ColumnTransformer` este utilizat pentru a combina mai mulÈ›i codificatori Ã®ntr-un singur pas È™i a-i aplica coloanelor corespunzÄƒtoare.

```python
    from sklearn.compose import ColumnTransformer
    
    ct = ColumnTransformer(transformers=[
        ('ord', ordinal_encoder, ordinal_features),
        ('cat', categorical_encoder, categorical_features)
        ])
    
    ct.set_output(transform='pandas')
    encoded_features = ct.fit_transform(pumpkins)
```

Pe de altÄƒ parte, pentru a codifica eticheta, folosim clasa `LabelEncoder` din scikit-learn, care este o clasÄƒ utilitarÄƒ pentru a normaliza etichetele astfel Ã®ncÃ¢t sÄƒ conÈ›inÄƒ doar valori Ã®ntre 0 È™i n_classes-1 (aici, 0 È™i 1).

```python
    from sklearn.preprocessing import LabelEncoder

    label_encoder = LabelEncoder()
    encoded_label = label_encoder.fit_transform(pumpkins['Color'])
```

DupÄƒ ce am codificat caracteristicile È™i eticheta, le putem Ã®mbina Ã®ntr-un nou dataframe `encoded_pumpkins`.

```python
    encoded_pumpkins = encoded_features.assign(Color=encoded_label)
```

âœ… Care sunt avantajele utilizÄƒrii unui codificator ordinal pentru coloana `Item Size`?

### Analiza relaÈ›iilor dintre variabile

Acum cÄƒ am pre-procesat datele, putem analiza relaÈ›iile dintre caracteristici È™i etichetÄƒ pentru a Ã®nÈ›elege cÃ¢t de bine va putea modelul sÄƒ prezicÄƒ eticheta pe baza caracteristicilor. 

Cea mai bunÄƒ modalitate de a efectua acest tip de analizÄƒ este sÄƒ plotÄƒm datele. Vom folosi din nou funcÈ›ia `catplot` din Seaborn pentru a vizualiza relaÈ›iile dintre `Item Size`, `Variety` È™i `Color` Ã®ntr-un grafic categorial. Pentru a plota mai bine datele, vom folosi coloana codificatÄƒ `Item Size` È™i coloana necodificatÄƒ `Variety`.

```python
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }
    pumpkins['Item Size'] = encoded_pumpkins['ord__Item Size']

    g = sns.catplot(
        data=pumpkins,
        x="Item Size", y="Color", row='Variety',
        kind="box", orient="h",
        sharex=False, margin_titles=True,
        height=1.8, aspect=4, palette=palette,
    )
    g.set(xlabel="Item Size", ylabel="").set(xlim=(0,6))
    g.set_titles(row_template="{row_name}")
```

![Un grafic categorial al datelor vizualizate](../../../../2-Regression/4-Logistic/images/pumpkins_catplot_2.png)

### Utilizarea unui grafic swarm

Deoarece `Color` este o categorie binarÄƒ (Alb sau Nu), necesitÄƒ 'o [abordare specializatÄƒ](https://seaborn.pydata.org/tutorial/categorical.html?highlight=bar) pentru vizualizare'. ExistÄƒ alte modalitÄƒÈ›i de a vizualiza relaÈ›ia acestei categorii cu alte variabile.

PoÈ›i vizualiza variabilele una lÃ¢ngÄƒ alta cu grafice Seaborn.

1. ÃncearcÄƒ un grafic 'swarm' pentru a arÄƒta distribuÈ›ia valorilor:

    ```python
    palette = {
    0: 'orange',
    1: 'wheat'
    }
    sns.swarmplot(x="Color", y="ord__Item Size", data=encoded_pumpkins, palette=palette)
    ```

    ![Un grafic swarm al datelor vizualizate](../../../../2-Regression/4-Logistic/images/swarm_2.png)

**AtenÈ›ie**: codul de mai sus poate genera un avertisment, deoarece Seaborn nu reuÈ™eÈ™te sÄƒ reprezinte o cantitate atÃ¢t de mare de puncte de date Ã®ntr-un grafic swarm. O soluÈ›ie posibilÄƒ este reducerea dimensiunii markerului, utilizÃ¢nd parametrul 'size'. TotuÈ™i, fii conÈ™tient cÄƒ acest lucru afecteazÄƒ lizibilitatea graficului.

> **ğŸ§® AratÄƒ-mi matematica**
>
> Regresia logisticÄƒ se bazeazÄƒ pe conceptul de 'maximum likelihood' folosind [funcÈ›ii sigmoid](https://wikipedia.org/wiki/Sigmoid_function). O 'FuncÈ›ie Sigmoid' pe un grafic aratÄƒ ca o formÄƒ de 'S'. Aceasta ia o valoare È™i o mapeazÄƒ undeva Ã®ntre 0 È™i 1. Curba sa este numitÄƒ È™i 'curbÄƒ logisticÄƒ'. Formula sa aratÄƒ astfel:
>
> ![funcÈ›ia logisticÄƒ](../../../../2-Regression/4-Logistic/images/sigmoid.png)
>
> unde punctul de mijloc al sigmoidului se aflÄƒ la punctul 0 al lui x, L este valoarea maximÄƒ a curbei, iar k este panta curbei. DacÄƒ rezultatul funcÈ›iei este mai mare de 0.5, eticheta Ã®n cauzÄƒ va fi atribuitÄƒ clasei '1' din alegerea binarÄƒ. DacÄƒ nu, va fi clasificatÄƒ ca '0'.

## ConstruieÈ™te modelul tÄƒu

Construirea unui model pentru a gÄƒsi aceste clasificÄƒri binare este surprinzÄƒtor de simplÄƒ Ã®n Scikit-learn.

[![ML pentru Ã®ncepÄƒtori - Regresia logisticÄƒ pentru clasificarea datelor](https://img.youtube.com/vi/MmZS2otPrQ8/0.jpg)](https://youtu.be/MmZS2otPrQ8 "ML pentru Ã®ncepÄƒtori - Regresia logisticÄƒ pentru clasificarea datelor")

> ğŸ¥ FÄƒ clic pe imaginea de mai sus pentru un scurt videoclip despre construirea unui model de regresie liniarÄƒ.

1. SelecteazÄƒ variabilele pe care vrei sÄƒ le foloseÈ™ti Ã®n modelul tÄƒu de clasificare È™i Ã®mparte seturile de antrenament È™i testare apelÃ¢nd `train_test_split()`:

    ```python
    from sklearn.model_selection import train_test_split
    
    X = encoded_pumpkins[encoded_pumpkins.columns.difference(['Color'])]
    y = encoded_pumpkins['Color']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
    
    ```

2. Acum poÈ›i antrena modelul tÄƒu, apelÃ¢nd `fit()` cu datele de antrenament È™i afiÈ™Ã¢nd rezultatul:

    ```python
    from sklearn.metrics import f1_score, classification_report 
    from sklearn.linear_model import LogisticRegression

    model = LogisticRegression()
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)

    print(classification_report(y_test, predictions))
    print('Predicted labels: ', predictions)
    print('F1-score: ', f1_score(y_test, predictions))
    ```

    AruncÄƒ o privire asupra scorului modelului tÄƒu. Nu este rÄƒu, avÃ¢nd Ã®n vedere cÄƒ ai doar aproximativ 1000 de rÃ¢nduri de date:

    ```output
                       precision    recall  f1-score   support
    
                    0       0.94      0.98      0.96       166
                    1       0.85      0.67      0.75        33
    
        accuracy                                0.92       199
        macro avg           0.89      0.82      0.85       199
        weighted avg        0.92      0.92      0.92       199
    
        Predicted labels:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0
        0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
        1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0
        0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0
        0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
        0 0 0 1 0 0 0 0 0 0 0 0 1 1]
        F1-score:  0.7457627118644068
    ```

## ÃnÈ›elegere mai bunÄƒ printr-o matrice de confuzie

DeÈ™i poÈ›i obÈ›ine un raport de scor [termeni](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html?highlight=classification_report#sklearn.metrics.classification_report) prin imprimarea elementelor de mai sus, s-ar putea sÄƒ Ã®nÈ›elegi modelul mai uÈ™or utilizÃ¢nd o [matrice de confuzie](https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix) pentru a ne ajuta sÄƒ Ã®nÈ›elegem cum performeazÄƒ modelul.

> ğŸ“ O '[matrice de confuzie](https://wikipedia.org/wiki/Confusion_matrix)' (sau 'matrice de eroare') este un tabel care exprimÄƒ pozitivele È™i negativele adevÄƒrate vs. false ale modelului tÄƒu, evaluÃ¢nd astfel acurateÈ›ea predicÈ›iilor.

1. Pentru a utiliza o matrice de confuzie, apeleazÄƒ `confusion_matrix()`:

    ```python
    from sklearn.metrics import confusion_matrix
    confusion_matrix(y_test, predictions)
    ```

    AruncÄƒ o privire asupra matricei de confuzie a modelului tÄƒu:

    ```output
    array([[162,   4],
           [ 11,  22]])
    ```

Ãn Scikit-learn, rÃ¢ndurile (axa 0) sunt etichetele reale, iar coloanele (axa 1) sunt etichetele prezise.

|       |   0   |   1   |
| :---: | :---: | :---: |
|   0   |  TN   |  FP   |
|   1   |  FN   |  TP   |

Ce se Ã®ntÃ¢mplÄƒ aici? SÄƒ presupunem cÄƒ modelul nostru este solicitat sÄƒ clasifice dovlecii Ã®ntre douÄƒ categorii binare, categoria 'alb' È™i categoria 'nu alb'.

- DacÄƒ modelul tÄƒu prezice un dovleac ca fiind nu alb È™i acesta aparÈ›ine categoriei 'nu alb' Ã®n realitate, Ã®l numim negativ adevÄƒrat, indicat de numÄƒrul din stÃ¢nga sus.
- DacÄƒ modelul tÄƒu prezice un dovleac ca fiind alb È™i acesta aparÈ›ine categoriei 'nu alb' Ã®n realitate, Ã®l numim negativ fals, indicat de numÄƒrul din stÃ¢nga jos.
- DacÄƒ modelul tÄƒu prezice un dovleac ca fiind nu alb È™i acesta aparÈ›ine categoriei 'alb' Ã®n realitate, Ã®l numim pozitiv fals, indicat de numÄƒrul din dreapta sus.
- DacÄƒ modelul tÄƒu prezice un dovleac ca fiind alb È™i acesta aparÈ›ine categoriei 'alb' Ã®n realitate, Ã®l numim pozitiv adevÄƒrat, indicat de numÄƒrul din dreapta jos.

DupÄƒ cum probabil ai ghicit, este preferabil sÄƒ ai un numÄƒr mai mare de pozitive adevÄƒrate È™i negative adevÄƒrate È™i un numÄƒr mai mic de pozitive false È™i negative false, ceea ce implicÄƒ faptul cÄƒ modelul performeazÄƒ mai bine.
Cum se leagÄƒ matricea de confuzie de precizie È™i recall? Èšine minte, raportul de clasificare afiÈ™at mai sus a arÄƒtat o precizie de 0.85 È™i un recall de 0.67.

Precizie = tp / (tp + fp) = 22 / (22 + 4) = 0.8461538461538461

Recall = tp / (tp + fn) = 22 / (22 + 11) = 0.6666666666666666

âœ… Ã: Conform matricei de confuzie, cum s-a descurcat modelul? R: Nu rÄƒu; existÄƒ un numÄƒr bun de true negatives, dar È™i cÃ¢teva false negatives.

SÄƒ revenim la termenii pe care i-am vÄƒzut mai devreme, cu ajutorul mapÄƒrii TP/TN È™i FP/FN din matricea de confuzie:

ğŸ“ Precizie: TP/(TP + FP) ProporÈ›ia instanÈ›elor relevante dintre cele recuperate (de exemplu, etichetele care au fost bine etichetate)

ğŸ“ Recall: TP/(TP + FN) ProporÈ›ia instanÈ›elor relevante care au fost recuperate, indiferent dacÄƒ au fost bine etichetate sau nu

ğŸ“ f1-score: (2 * precizie * recall)/(precizie + recall) O medie ponderatÄƒ a preciziei È™i recall-ului, cu cel mai bun scor fiind 1 È™i cel mai slab fiind 0

ğŸ“ Support: NumÄƒrul de apariÈ›ii ale fiecÄƒrei etichete recuperate

ğŸ“ AcurateÈ›e: (TP + TN)/(TP + TN + FP + FN) Procentul de etichete prezise corect pentru un eÈ™antion.

ğŸ“ Macro Avg: Calculul mediei neponderate a metricilor pentru fiecare etichetÄƒ, fÄƒrÄƒ a È›ine cont de dezechilibrul etichetelor.

ğŸ“ Weighted Avg: Calculul mediei metricilor pentru fiecare etichetÄƒ, È›inÃ¢nd cont de dezechilibrul etichetelor prin ponderarea lor Ã®n funcÈ›ie de support (numÄƒrul de instanÈ›e reale pentru fiecare etichetÄƒ).

âœ… Te poÈ›i gÃ¢ndi la ce metricÄƒ ar trebui sÄƒ fii atent dacÄƒ vrei ca modelul tÄƒu sÄƒ reducÄƒ numÄƒrul de false negatives?

## VizualizeazÄƒ curba ROC a acestui model

[![ML pentru Ã®ncepÄƒtori - Analiza performanÈ›ei regresiei logistice cu curbe ROC](https://img.youtube.com/vi/GApO575jTA0/0.jpg)](https://youtu.be/GApO575jTA0 "ML pentru Ã®ncepÄƒtori - Analiza performanÈ›ei regresiei logistice cu curbe ROC")

> ğŸ¥ FÄƒ clic pe imaginea de mai sus pentru o prezentare video scurtÄƒ despre curbele ROC

SÄƒ facem o vizualizare suplimentarÄƒ pentru a vedea aÈ™a-numita 'curbÄƒ ROC':

```python
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline

y_scores = model.predict_proba(X_test)
fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])

fig = plt.figure(figsize=(6, 6))
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.show()
```

Folosind Matplotlib, ploteazÄƒ [Receiving Operating Characteristic](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html?highlight=roc) sau ROC-ul modelului. Curbele ROC sunt adesea utilizate pentru a obÈ›ine o imagine de ansamblu asupra ieÈ™irii unui clasificator Ã®n termeni de true positives vs. false positives. "Curbele ROC prezintÄƒ de obicei rata de true positives pe axa Y È™i rata de false positives pe axa X." Astfel, abruptul curbei È™i spaÈ›iul dintre linia de mijloc È™i curbÄƒ conteazÄƒ: vrei o curbÄƒ care urcÄƒ rapid È™i depÄƒÈ™eÈ™te linia. Ãn cazul nostru, existÄƒ false positives la Ã®nceput, iar apoi linia urcÄƒ È™i depÄƒÈ™eÈ™te corect:

![ROC](../../../../2-Regression/4-Logistic/images/ROC_2.png)

Ãn final, foloseÈ™te API-ul [`roc_auc_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html?highlight=roc_auc#sklearn.metrics.roc_auc_score) din Scikit-learn pentru a calcula efectiv 'Aria Sub CurbÄƒ' (AUC):

```python
auc = roc_auc_score(y_test,y_scores[:,1])
print(auc)
```
Rezultatul este `0.9749908725812341`. AvÃ¢nd Ã®n vedere cÄƒ AUC variazÄƒ Ã®ntre 0 È™i 1, vrei un scor mare, deoarece un model care este 100% corect Ã®n predicÈ›iile sale va avea un AUC de 1; Ã®n acest caz, modelul este _destul de bun_.

Ãn lecÈ›iile viitoare despre clasificÄƒri, vei Ã®nvÄƒÈ›a cum sÄƒ iterezi pentru a Ã®mbunÄƒtÄƒÈ›i scorurile modelului tÄƒu. Dar pentru moment, felicitÄƒri! Ai finalizat aceste lecÈ›ii despre regresie!

---
## ğŸš€Provocare

ExistÄƒ mult mai multe de explorat Ã®n ceea ce priveÈ™te regresia logisticÄƒ! Dar cel mai bun mod de a Ã®nvÄƒÈ›a este sÄƒ experimentezi. GÄƒseÈ™te un set de date care se preteazÄƒ acestui tip de analizÄƒ È™i construieÈ™te un model cu el. Ce ai Ã®nvÄƒÈ›at? sugestie: Ã®ncearcÄƒ [Kaggle](https://www.kaggle.com/search?q=logistic+regression+datasets) pentru seturi de date interesante.

## [Quiz dupÄƒ lecÈ›ie](https://ff-quizzes.netlify.app/en/ml/)

## Recapitulare & Studiu individual

CiteÈ™te primele cÃ¢teva pagini din [acest articol de la Stanford](https://web.stanford.edu/~jurafsky/slp3/5.pdf) despre cÃ¢teva utilizÄƒri practice ale regresiei logistice. GÃ¢ndeÈ™te-te la sarcini care sunt mai potrivite pentru unul sau altul dintre tipurile de regresie pe care le-am studiat pÃ¢nÄƒ acum. Ce ar funcÈ›iona cel mai bine?

## TemÄƒ

[Reia aceastÄƒ regresie](assignment.md)

---

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). DeÈ™i ne strÄƒduim sÄƒ asigurÄƒm acurateÈ›ea, vÄƒ rugÄƒm sÄƒ fiÈ›i conÈ™tienÈ›i cÄƒ traducerile automate pot conÈ›ine erori sau inexactitÄƒÈ›i. Documentul original Ã®n limba sa natalÄƒ ar trebui considerat sursa autoritarÄƒ. Pentru informaÈ›ii critice, se recomandÄƒ traducerea profesionalÄƒ realizatÄƒ de un specialist uman. Nu ne asumÄƒm responsabilitatea pentru eventualele neÃ®nÈ›elegeri sau interpretÄƒri greÈ™ite care pot apÄƒrea din utilizarea acestei traduceri.