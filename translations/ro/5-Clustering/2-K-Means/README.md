<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7cdd17338d9bbd7e2171c2cd462eb081",
  "translation_date": "2025-09-05T15:46:59+00:00",
  "source_file": "5-Clustering/2-K-Means/README.md",
  "language_code": "ro"
}
-->
# Gruparea K-Means

## [Chestionar Ã®nainte de lecÈ›ie](https://ff-quizzes.netlify.app/en/ml/)

Ãn aceastÄƒ lecÈ›ie, vei Ã®nvÄƒÈ›a cum sÄƒ creezi grupuri folosind Scikit-learn È™i setul de date despre muzica nigerianÄƒ pe care l-ai importat anterior. Vom acoperi elementele de bazÄƒ ale K-Means pentru grupare. Èšine minte cÄƒ, aÈ™a cum ai Ã®nvÄƒÈ›at Ã®n lecÈ›ia anterioarÄƒ, existÄƒ multe moduri de a lucra cu grupuri, iar metoda pe care o alegi depinde de datele tale. Vom Ã®ncerca K-Means, deoarece este cea mai comunÄƒ tehnicÄƒ de grupare. SÄƒ Ã®ncepem!

Termeni pe care Ã®i vei Ã®nvÄƒÈ›a:

- Scorul siluetei
- Metoda cotului
- InerÈ›ie
- VariaÈ›ie

## Introducere

[Gruparea K-Means](https://wikipedia.org/wiki/K-means_clustering) este o metodÄƒ derivatÄƒ din domeniul procesÄƒrii semnalelor. Este utilizatÄƒ pentru a Ã®mpÄƒrÈ›i È™i partitiona grupuri de date Ã®n 'k' grupuri folosind o serie de observaÈ›ii. Fiecare observaÈ›ie funcÈ›ioneazÄƒ pentru a grupa un punct de date dat cÃ¢t mai aproape de 'media' sa cea mai apropiatÄƒ, sau punctul central al unui grup.

Grupurile pot fi vizualizate ca [diagrame Voronoi](https://wikipedia.org/wiki/Voronoi_diagram), care includ un punct (sau 'sÄƒmÃ¢nÈ›Äƒ') È™i regiunea corespunzÄƒtoare acestuia.

![voronoi diagram](../../../../5-Clustering/2-K-Means/images/voronoi.png)

> infografic de [Jen Looper](https://twitter.com/jenlooper)

Procesul de grupare K-Means [se executÄƒ Ã®n trei paÈ™i](https://scikit-learn.org/stable/modules/clustering.html#k-means):

1. Algoritmul selecteazÄƒ un numÄƒr k de puncte centrale prin eÈ™antionare din setul de date. DupÄƒ aceasta, se repetÄƒ:
    1. Atribuie fiecare eÈ™antion celui mai apropiat centroid.
    2. CreeazÄƒ noi centroizi calculÃ¢nd valoarea medie a tuturor eÈ™antioanelor atribuite centroidelor anterioare.
    3. Apoi, calculeazÄƒ diferenÈ›a dintre noii È™i vechii centroizi È™i repetÄƒ pÃ¢nÄƒ cÃ¢nd centroizii se stabilizeazÄƒ.

Un dezavantaj al utilizÄƒrii K-Means este faptul cÄƒ trebuie sÄƒ stabileÈ™ti 'k', adicÄƒ numÄƒrul de centroizi. Din fericire, 'metoda cotului' ajutÄƒ la estimarea unei valori bune de Ã®nceput pentru 'k'. Vei Ã®ncerca acest lucru Ã®n curÃ¢nd.

## Prerechizite

Vei lucra Ã®n fiÈ™ierul [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/2-K-Means/notebook.ipynb) al acestei lecÈ›ii, care include importul de date È™i curÄƒÈ›area preliminarÄƒ pe care ai fÄƒcut-o Ã®n lecÈ›ia anterioarÄƒ.

## ExerciÈ›iu - pregÄƒtire

Ãncepe prin a analiza din nou datele despre melodii.

1. CreeazÄƒ un boxplot, apelÃ¢nd `boxplot()` pentru fiecare coloanÄƒ:

    ```python
    plt.figure(figsize=(20,20), dpi=200)
    
    plt.subplot(4,3,1)
    sns.boxplot(x = 'popularity', data = df)
    
    plt.subplot(4,3,2)
    sns.boxplot(x = 'acousticness', data = df)
    
    plt.subplot(4,3,3)
    sns.boxplot(x = 'energy', data = df)
    
    plt.subplot(4,3,4)
    sns.boxplot(x = 'instrumentalness', data = df)
    
    plt.subplot(4,3,5)
    sns.boxplot(x = 'liveness', data = df)
    
    plt.subplot(4,3,6)
    sns.boxplot(x = 'loudness', data = df)
    
    plt.subplot(4,3,7)
    sns.boxplot(x = 'speechiness', data = df)
    
    plt.subplot(4,3,8)
    sns.boxplot(x = 'tempo', data = df)
    
    plt.subplot(4,3,9)
    sns.boxplot(x = 'time_signature', data = df)
    
    plt.subplot(4,3,10)
    sns.boxplot(x = 'danceability', data = df)
    
    plt.subplot(4,3,11)
    sns.boxplot(x = 'length', data = df)
    
    plt.subplot(4,3,12)
    sns.boxplot(x = 'release_date', data = df)
    ```

    Aceste date sunt puÈ›in zgomotoase: observÃ¢nd fiecare coloanÄƒ ca boxplot, poÈ›i vedea valori extreme.

    ![outliers](../../../../5-Clustering/2-K-Means/images/boxplots.png)

Ai putea parcurge setul de date È™i elimina aceste valori extreme, dar acest lucru ar face datele destul de minimale.

1. DeocamdatÄƒ, alege coloanele pe care le vei folosi pentru exerciÈ›iul de grupare. SelecteazÄƒ coloane cu intervale similare È™i codificÄƒ coloana `artist_top_genre` ca date numerice:

    ```python
    from sklearn.preprocessing import LabelEncoder
    le = LabelEncoder()
    
    X = df.loc[:, ('artist_top_genre','popularity','danceability','acousticness','loudness','energy')]
    
    y = df['artist_top_genre']
    
    X['artist_top_genre'] = le.fit_transform(X['artist_top_genre'])
    
    y = le.transform(y)
    ```

1. Acum trebuie sÄƒ alegi cÃ¢te grupuri sÄƒ vizezi. È˜tii cÄƒ existÄƒ 3 genuri muzicale pe care le-am extras din setul de date, aÈ™a cÄƒ sÄƒ Ã®ncercÄƒm cu 3:

    ```python
    from sklearn.cluster import KMeans
    
    nclusters = 3 
    seed = 0
    
    km = KMeans(n_clusters=nclusters, random_state=seed)
    km.fit(X)
    
    # Predict the cluster for each data point
    
    y_cluster_kmeans = km.predict(X)
    y_cluster_kmeans
    ```

Vei vedea un array afiÈ™at cu grupurile prezise (0, 1 sau 2) pentru fiecare rÃ¢nd din dataframe.

1. FoloseÈ™te acest array pentru a calcula un 'scor al siluetei':

    ```python
    from sklearn import metrics
    score = metrics.silhouette_score(X, y_cluster_kmeans)
    score
    ```

## Scorul siluetei

CautÄƒ un scor al siluetei mai aproape de 1. Acest scor variazÄƒ de la -1 la 1, iar dacÄƒ scorul este 1, grupul este dens È™i bine separat de celelalte grupuri. O valoare apropiatÄƒ de 0 reprezintÄƒ grupuri suprapuse, cu eÈ™antioane foarte apropiate de limita de decizie a grupurilor vecine. [(SursÄƒ)](https://dzone.com/articles/kmeans-silhouette-score-explained-with-python-exam)

Scorul nostru este **.53**, deci chiar la mijloc. Acest lucru indicÄƒ faptul cÄƒ datele noastre nu sunt deosebit de potrivite pentru acest tip de grupare, dar sÄƒ continuÄƒm.

### ExerciÈ›iu - construieÈ™te un model

1. ImportÄƒ `KMeans` È™i Ã®ncepe procesul de grupare.

    ```python
    from sklearn.cluster import KMeans
    wcss = []
    
    for i in range(1, 11):
        kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)
        kmeans.fit(X)
        wcss.append(kmeans.inertia_)
    
    ```

    ExistÄƒ cÃ¢teva pÄƒrÈ›i aici care meritÄƒ explicate.

    > ğŸ“ range: Acestea sunt iteraÈ›iile procesului de grupare.

    > ğŸ“ random_state: "DeterminÄƒ generarea de numere aleatoare pentru iniÈ›ializarea centroizilor." [SursÄƒ](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)

    > ğŸ“ WCSS: "suma pÄƒtratelor din interiorul grupurilor" mÄƒsoarÄƒ distanÈ›a medie pÄƒtratÄƒ a tuturor punctelor dintr-un grup faÈ›Äƒ de centrul grupului. [SursÄƒ](https://medium.com/@ODSC/unsupervised-learning-evaluating-clusters-bd47eed175ce).

    > ğŸ“ InerÈ›ie: Algoritmii K-Means Ã®ncearcÄƒ sÄƒ aleagÄƒ centroizi pentru a minimiza 'inerÈ›ia', "o mÄƒsurÄƒ a cÃ¢t de coerente sunt grupurile intern." [SursÄƒ](https://scikit-learn.org/stable/modules/clustering.html). Valoarea este adÄƒugatÄƒ la variabila wcss la fiecare iteraÈ›ie.

    > ğŸ“ k-means++: Ãn [Scikit-learn](https://scikit-learn.org/stable/modules/clustering.html#k-means) poÈ›i folosi optimizarea 'k-means++', care "iniÈ›ializeazÄƒ centroizii pentru a fi (Ã®n general) distanÈ›aÈ›i unul de celÄƒlalt, conducÃ¢nd probabil la rezultate mai bune decÃ¢t iniÈ›ializarea aleatorie."

### Metoda cotului

Anterior, ai presupus cÄƒ, deoarece ai vizat 3 genuri muzicale, ar trebui sÄƒ alegi 3 grupuri. Dar este acesta cazul?

1. FoloseÈ™te 'metoda cotului' pentru a te asigura.

    ```python
    plt.figure(figsize=(10,5))
    sns.lineplot(x=range(1, 11), y=wcss, marker='o', color='red')
    plt.title('Elbow')
    plt.xlabel('Number of clusters')
    plt.ylabel('WCSS')
    plt.show()
    ```

    FoloseÈ™te variabila `wcss` pe care ai construit-o Ã®n pasul anterior pentru a crea un grafic care aratÄƒ unde este 'cotul', ceea ce indicÄƒ numÄƒrul optim de grupuri. Poate chiar **este** 3!

    ![elbow method](../../../../5-Clustering/2-K-Means/images/elbow.png)

## ExerciÈ›iu - afiÈ™eazÄƒ grupurile

1. ÃncearcÄƒ procesul din nou, de data aceasta setÃ¢nd trei grupuri È™i afiÈ™eazÄƒ grupurile ca un scatterplot:

    ```python
    from sklearn.cluster import KMeans
    kmeans = KMeans(n_clusters = 3)
    kmeans.fit(X)
    labels = kmeans.predict(X)
    plt.scatter(df['popularity'],df['danceability'],c = labels)
    plt.xlabel('popularity')
    plt.ylabel('danceability')
    plt.show()
    ```

1. VerificÄƒ acurateÈ›ea modelului:

    ```python
    labels = kmeans.labels_
    
    correct_labels = sum(y == labels)
    
    print("Result: %d out of %d samples were correctly labeled." % (correct_labels, y.size))
    
    print('Accuracy score: {0:0.2f}'. format(correct_labels/float(y.size)))
    ```

    AcurateÈ›ea acestui model nu este foarte bunÄƒ, iar forma grupurilor Ã®È›i oferÄƒ un indiciu de ce.

    ![clusters](../../../../5-Clustering/2-K-Means/images/clusters.png)

    Aceste date sunt prea dezechilibrate, prea puÈ›in corelate È™i existÄƒ prea multÄƒ variaÈ›ie Ã®ntre valorile coloanelor pentru a grupa bine. De fapt, grupurile care se formeazÄƒ sunt probabil influenÈ›ate sau distorsionate puternic de cele trei categorii de genuri pe care le-am definit mai sus. A fost un proces de Ã®nvÄƒÈ›are!

    Ãn documentaÈ›ia Scikit-learn, poÈ›i vedea cÄƒ un model ca acesta, cu grupuri care nu sunt foarte bine delimitate, are o problemÄƒ de 'variaÈ›ie':

    ![problem models](../../../../5-Clustering/2-K-Means/images/problems.png)
    > Infografic din Scikit-learn

## VariaÈ›ie

VariaÈ›ia este definitÄƒ ca "media diferenÈ›elor pÄƒtrate faÈ›Äƒ de medie" [(SursÄƒ)](https://www.mathsisfun.com/data/standard-deviation.html). Ãn contextul acestei probleme de grupare, se referÄƒ la datele ale cÄƒror valori tind sÄƒ se abatÄƒ prea mult de la medie.

âœ… Acesta este un moment excelent pentru a te gÃ¢ndi la toate modurile Ã®n care ai putea corecta aceastÄƒ problemÄƒ. Ajustezi datele puÈ›in mai mult? FoloseÈ™ti alte coloane? Utilizezi un alt algoritm? Sugestie: ÃncearcÄƒ [scalarea datelor](https://www.mygreatlearning.com/blog/learning-data-science-with-k-means-clustering/) pentru a le normaliza È™i testeazÄƒ alte coloane.

> ÃncearcÄƒ acest '[calculator de variaÈ›ie](https://www.calculatorsoup.com/calculators/statistics/variance-calculator.php)' pentru a Ã®nÈ›elege mai bine conceptul.

---

## ğŸš€Provocare

Petrece ceva timp cu acest notebook, ajustÃ¢nd parametrii. PoÈ›i Ã®mbunÄƒtÄƒÈ›i acurateÈ›ea modelului prin curÄƒÈ›area mai bunÄƒ a datelor (eliminÃ¢nd valorile extreme, de exemplu)? PoÈ›i folosi ponderi pentru a acorda mai multÄƒ greutate anumitor eÈ™antioane de date. Ce altceva poÈ›i face pentru a crea grupuri mai bune?

Sugestie: ÃncearcÄƒ sÄƒ scalezi datele. ExistÄƒ cod comentat Ã®n notebook care adaugÄƒ scalarea standard pentru a face ca valorile coloanelor sÄƒ semene mai mult Ã®ntre ele Ã®n termeni de interval. Vei descoperi cÄƒ, deÈ™i scorul siluetei scade, 'cotul' din graficul cotului se netezeÈ™te. Acest lucru se Ã®ntÃ¢mplÄƒ deoarece lÄƒsarea datelor nescalate permite datelor cu mai puÈ›inÄƒ variaÈ›ie sÄƒ aibÄƒ mai multÄƒ greutate. CiteÈ™te mai multe despre aceastÄƒ problemÄƒ [aici](https://stats.stackexchange.com/questions/21222/are-mean-normalization-and-feature-scaling-needed-for-k-means-clustering/21226#21226).

## [Chestionar dupÄƒ lecÈ›ie](https://ff-quizzes.netlify.app/en/ml/)

## Recapitulare È™i studiu individual

AruncÄƒ o privire la un simulator K-Means [cum ar fi acesta](https://user.ceng.metu.edu.tr/~akifakkus/courses/ceng574/k-means/). PoÈ›i folosi acest instrument pentru a vizualiza punctele de date eÈ™antion È™i pentru a determina centroizii acestora. PoÈ›i edita aleatoritatea datelor, numÄƒrul de grupuri È™i numÄƒrul de centroizi. Te ajutÄƒ acest lucru sÄƒ Ã®È›i faci o idee despre cum pot fi grupate datele?

De asemenea, aruncÄƒ o privire la [acest material despre K-Means](https://stanford.edu/~cpiech/cs221/handouts/kmeans.html) de la Stanford.

## TemÄƒ

[ÃncearcÄƒ metode diferite de grupare](assignment.md)

---

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). DeÈ™i ne strÄƒduim sÄƒ asigurÄƒm acurateÈ›ea, vÄƒ rugÄƒm sÄƒ reÈ›ineÈ›i cÄƒ traducerile automate pot conÈ›ine erori sau inexactitÄƒÈ›i. Documentul original Ã®n limba sa natalÄƒ ar trebui considerat sursa autoritarÄƒ. Pentru informaÈ›ii critice, se recomandÄƒ traducerea profesionalÄƒ realizatÄƒ de un specialist uman. Nu ne asumÄƒm responsabilitatea pentru eventualele neÃ®nÈ›elegeri sau interpretÄƒri greÈ™ite care pot apÄƒrea din utilizarea acestei traduceri.