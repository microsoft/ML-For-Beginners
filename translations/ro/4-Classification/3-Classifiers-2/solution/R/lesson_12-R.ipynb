{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "lesson_12-R.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "ir",
   "display_name": "R"
  },
  "language_info": {
   "name": "R"
  },
  "coopTranslator": {
   "original_hash": "fab50046ca413a38939d579f8432274f",
   "translation_date": "2025-09-06T12:33:31+00:00",
   "source_file": "4-Classification/3-Classifiers-2/solution/R/lesson_12-R.ipynb",
   "language_code": "ro"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsFutf_ygqSx"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HD54bEefgtNO"
   },
   "source": [
    "## Clasificatori de bucătărie 2\n",
    "\n",
    "În această a doua lecție despre clasificare, vom explora `mai multe modalități` de a clasifica datele categorice. De asemenea, vom învăța despre implicațiile alegerii unui clasificator în detrimentul altuia.\n",
    "\n",
    "### [**Chestionar înainte de lecție**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/23/)\n",
    "\n",
    "### **Prerechizite**\n",
    "\n",
    "Presupunem că ați finalizat lecțiile anterioare, deoarece vom continua să folosim unele concepte pe care le-am învățat anterior.\n",
    "\n",
    "Pentru această lecție, vom avea nevoie de următoarele pachete:\n",
    "\n",
    "-   `tidyverse`: [tidyverse](https://www.tidyverse.org/) este o [colecție de pachete R](https://www.tidyverse.org/packages) concepută pentru a face știința datelor mai rapidă, mai ușoară și mai distractivă!\n",
    "\n",
    "-   `tidymodels`: [tidymodels](https://www.tidymodels.org/) este un [cadru de lucru](https://www.tidymodels.org/packages/) format din pachete pentru modelare și învățare automată.\n",
    "\n",
    "-   `themis`: Pachetul [themis](https://themis.tidymodels.org/) oferă pași suplimentari pentru rețete, utili în gestionarea datelor dezechilibrate.\n",
    "\n",
    "Le puteți instala astfel:\n",
    "\n",
    "`install.packages(c(\"tidyverse\", \"tidymodels\", \"kernlab\", \"themis\", \"ranger\", \"xgboost\", \"kknn\"))`\n",
    "\n",
    "Alternativ, scriptul de mai jos verifică dacă aveți pachetele necesare pentru a finaliza acest modul și le instalează pentru dvs. în cazul în care lipsesc.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vZ57IuUxgyQt"
   },
   "source": [
    "suppressWarnings(if (!require(\"pacman\"))install.packages(\"pacman\"))\n",
    "\n",
    "pacman::p_load(tidyverse, tidymodels, themis, kernlab, ranger, xgboost, kknn)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z22M-pj4g07x"
   },
   "source": [
    "## **1. O hartă de clasificare**\n",
    "\n",
    "În [lecția anterioară](https://github.com/microsoft/ML-For-Beginners/tree/main/4-Classification/2-Classifiers-1), am încercat să răspundem la întrebarea: cum alegem între mai multe modele? În mare măsură, acest lucru depinde de caracteristicile datelor și de tipul de problemă pe care dorim să o rezolvăm (de exemplu, clasificare sau regresie?).\n",
    "\n",
    "Anterior, am învățat despre diversele opțiuni pe care le aveți atunci când clasificați date folosind fișa de ajutor de la Microsoft. Framework-ul de Machine Learning al Python, Scikit-learn, oferă o fișă de ajutor similară, dar mai detaliată, care poate ajuta în continuare la restrângerea alegerii estimatoarelor (un alt termen pentru clasificatori):\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/map.png\"\n",
    "   width=\"700\"/>\n",
    "   <figcaption></figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1i3xRIVg7vG"
   },
   "source": [
    "> Sfat: [vizitează această hartă online](https://scikit-learn.org/stable/tutorial/machine_learning_map/) și navighează pe traseu pentru a citi documentația.\n",
    ">\n",
    "> [Site-ul de referință Tidymodels](https://www.tidymodels.org/find/parsnip/#models) oferă, de asemenea, o documentație excelentă despre diferite tipuri de modele.\n",
    "\n",
    "### **Planul** 🗺️\n",
    "\n",
    "Această hartă este foarte utilă odată ce ai o înțelegere clară a datelor tale, deoarece poți 'merge' pe traseele ei pentru a lua o decizie:\n",
    "\n",
    "-   Avem \\>50 mostre\n",
    "\n",
    "-   Vrem să prezicem o categorie\n",
    "\n",
    "-   Avem date etichetate\n",
    "\n",
    "-   Avem mai puțin de 100K mostre\n",
    "\n",
    "-   ✨ Putem alege un Linear SVC\n",
    "\n",
    "-   Dacă asta nu funcționează, deoarece avem date numerice\n",
    "\n",
    "    -   Putem încerca un ✨ KNeighbors Classifier\n",
    "\n",
    "        -   Dacă nici asta nu funcționează, încercăm ✨ SVC și ✨ Ensemble Classifiers\n",
    "\n",
    "Acesta este un traseu foarte util de urmat. Acum, să trecem direct la treabă folosind cadrul de modelare [tidymodels](https://www.tidymodels.org/): o colecție consistentă și flexibilă de pachete R dezvoltate pentru a încuraja bunele practici statistice 😊.\n",
    "\n",
    "## 2. Împărțirea datelor și gestionarea setului de date dezechilibrat.\n",
    "\n",
    "Din lecțiile anterioare, am învățat că există un set de ingrediente comune în bucătăriile noastre. De asemenea, am observat o distribuție destul de inegală în numărul de bucătării.\n",
    "\n",
    "Vom gestiona aceste aspecte prin:\n",
    "\n",
    "-   Eliminarea celor mai comune ingrediente care creează confuzie între bucătării distincte, folosind `dplyr::select()`.\n",
    "\n",
    "-   Utilizarea unui `recipe` care preprocesează datele pentru a le pregăti pentru modelare prin aplicarea unui algoritm de `over-sampling`.\n",
    "\n",
    "Am discutat deja despre cele de mai sus în lecția anterioară, așa că ar trebui să fie o joacă de copii 🥳!\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6tj_rN00hClA"
   },
   "source": [
    "# Load the core Tidyverse and Tidymodels packages\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "\n",
    "# Load the original cuisines data\n",
    "df <- read_csv(file = \"https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/data/cuisines.csv\")\n",
    "\n",
    "# Drop id column, rice, garlic and ginger from our original data set\n",
    "df_select <- df %>% \n",
    "  select(-c(1, rice, garlic, ginger)) %>%\n",
    "  # Encode cuisine column as categorical\n",
    "  mutate(cuisine = factor(cuisine))\n",
    "\n",
    "\n",
    "# Create data split specification\n",
    "set.seed(2056)\n",
    "cuisines_split <- initial_split(data = df_select,\n",
    "                                strata = cuisine,\n",
    "                                prop = 0.7)\n",
    "\n",
    "# Extract the data in each split\n",
    "cuisines_train <- training(cuisines_split)\n",
    "cuisines_test <- testing(cuisines_split)\n",
    "\n",
    "# Display distribution of cuisines in the training set\n",
    "cuisines_train %>% \n",
    "  count(cuisine) %>% \n",
    "  arrange(desc(n))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFin5yw3hHb1"
   },
   "source": [
    "### Gestionarea datelor dezechilibrate\n",
    "\n",
    "Datele dezechilibrate au adesea efecte negative asupra performanței modelului. Multe modele funcționează cel mai bine atunci când numărul de observații este egal și, prin urmare, tind să întâmpine dificultăți cu datele dezechilibrate.\n",
    "\n",
    "Există în principal două modalități de a gestiona seturile de date dezechilibrate:\n",
    "\n",
    "-   adăugarea de observații la clasa minoritară: `Supraselectare` (Over-sampling), de exemplu, utilizând un algoritm SMOTE care generează sintetic noi exemple ale clasei minoritare folosind cei mai apropiați vecini ai acestor cazuri.\n",
    "\n",
    "-   eliminarea observațiilor din clasa majoritară: `Subselectare` (Under-sampling)\n",
    "\n",
    "În lecția noastră anterioară, am demonstrat cum să gestionăm seturile de date dezechilibrate folosind un `recipe`. Un recipe poate fi considerat ca un plan care descrie ce pași ar trebui aplicați unui set de date pentru a-l pregăti pentru analiza datelor. În cazul nostru, ne dorim să avem o distribuție egală a numărului de bucătării pentru `setul nostru de antrenament`. Haideți să trecem direct la subiect.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cRzTnHolhLWd"
   },
   "source": [
    "# Load themis package for dealing with imbalanced data\n",
    "library(themis)\n",
    "\n",
    "# Create a recipe for preprocessing training data\n",
    "cuisines_recipe <- recipe(cuisine ~ ., data = cuisines_train) %>%\n",
    "  step_smote(cuisine) \n",
    "\n",
    "# Print recipe\n",
    "cuisines_recipe"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxOQ2ORhhO81"
   },
   "source": [
    "Acum suntem gata să antrenăm modele 👩‍💻👨‍💻!\n",
    "\n",
    "## 3. Dincolo de modelele de regresie multinomială\n",
    "\n",
    "În lecția anterioară, am analizat modelele de regresie multinomială. Haideți să explorăm câteva modele mai flexibile pentru clasificare.\n",
    "\n",
    "### Mașini cu Vectori de Suport\n",
    "\n",
    "În contextul clasificării, `Mașinile cu Vectori de Suport` reprezintă o tehnică de învățare automată care încearcă să găsească un *hiperplan* care separă \"cel mai bine\" clasele. Să analizăm un exemplu simplu:\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/svm.png\"\n",
    "   width=\"300\"/>\n",
    "   <figcaption>https://commons.wikimedia.org/w/index.php?curid=22877598</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4Wsd0vZhXYu"
   },
   "source": [
    "H1~ nu separă clasele. H2~ le separă, dar doar cu o marjă mică. H3~ le separă cu o marjă maximă.\n",
    "\n",
    "#### Clasificator Linear cu Vectori de Suport\n",
    "\n",
    "Clusteringul cu Vectori de Suport (SVC) face parte din familia de tehnici ML bazate pe mașini cu vectori de suport. În SVC, hiperplanul este ales astfel încât să separe corect `majoritatea` observațiilor de antrenament, dar `poate clasifica greșit` câteva observații. Prin permiterea unor puncte să fie pe partea greșită, SVM devine mai robust la valori extreme, ceea ce duce la o generalizare mai bună pentru datele noi. Parametrul care reglează această abatere este denumit `cost`, având o valoare implicită de 1 (vezi `help(\"svm_poly\")`).\n",
    "\n",
    "Să creăm un SVC liniar setând `degree = 1` într-un model SVM polinomial.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vJpp6nuChlBz"
   },
   "source": [
    "# Make a linear SVC specification\n",
    "svc_linear_spec <- svm_poly(degree = 1) %>% \n",
    "  set_engine(\"kernlab\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle specification and recipe into a worklow\n",
    "svc_linear_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(svc_linear_spec)\n",
    "\n",
    "# Print out workflow\n",
    "svc_linear_wf"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDs8cWNkhoqu"
   },
   "source": [
    "Acum că am capturat pașii de preprocesare și specificațiile modelului într-un *workflow*, putem continua cu antrenarea SVC liniar și evaluarea rezultatelor în același timp. Pentru măsurile de performanță, să creăm un set de metrici care va evalua: `acuratețea`, `sensibilitatea`, `Valoarea Predictivă Pozitivă` și `F Measure`.\n",
    "\n",
    "> `augment()` va adăuga coloane pentru predicții la datele furnizate.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "81wiqcwuhrnq"
   },
   "source": [
    "# Train a linear SVC model\n",
    "svc_linear_fit <- svc_linear_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "# Create a metric set\n",
    "eval_metrics <- metric_set(ppv, sens, accuracy, f_meas)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "svc_linear_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UFQvHf-huo3"
   },
   "source": [
    "#### Mașina cu Vectori de Suport\n",
    "\n",
    "Mașina cu vectori de suport (SVM) este o extensie a clasificatorului cu vectori de suport pentru a permite o delimitare non-lineară între clase. În esență, SVM-urile folosesc *trucul kernel* pentru a extinde spațiul caracteristicilor, adaptându-se astfel la relațiile non-lineare dintre clase. O funcție kernel populară și extrem de flexibilă utilizată de SVM-uri este *funcția de bază radială.* Haideți să vedem cum se va descurca pe datele noastre.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-KX4S8mzhzmp"
   },
   "source": [
    "set.seed(2056)\n",
    "\n",
    "# Make an RBF SVM specification\n",
    "svm_rbf_spec <- svm_rbf() %>% \n",
    "  set_engine(\"kernlab\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle specification and recipe into a worklow\n",
    "svm_rbf_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(svm_rbf_spec)\n",
    "\n",
    "\n",
    "# Train an RBF model\n",
    "svm_rbf_fit <- svm_rbf_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "svm_rbf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBFSa7WSh4HQ"
   },
   "source": [
    "Mult mai bine 🤩!\n",
    "\n",
    "> ✅ Vă rugăm să consultați:\n",
    ">\n",
    "> -   [*Support Vector Machines*](https://bradleyboehmke.github.io/HOML/svm.html), Hands-on Machine Learning with R\n",
    ">\n",
    "> -   [*Support Vector Machines*](https://www.statlearning.com/), An Introduction to Statistical Learning with Applications in R\n",
    ">\n",
    "> pentru lecturi suplimentare.\n",
    "\n",
    "### Clasificatori Nearest Neighbor\n",
    "\n",
    "Algoritmul *K*-nearest neighbor (KNN) este o metodă în care fiecare observație este prezisă pe baza *similarității* sale cu alte observații.\n",
    "\n",
    "Haideți să aplicăm unul pe datele noastre.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k4BxxBcdh9Ka"
   },
   "source": [
    "# Make a KNN specification\n",
    "knn_spec <- nearest_neighbor() %>% \n",
    "  set_engine(\"kknn\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "knn_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(knn_spec)\n",
    "\n",
    "# Train a boosted tree model\n",
    "knn_wf_fit <- knn_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "knn_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaegQseriAcj"
   },
   "source": [
    "Se pare că acest model nu funcționează prea bine. Probabil că modificarea argumentelor modelului (vezi `help(\"nearest_neighbor\")`) va îmbunătăți performanța modelului. Asigură-te că încerci acest lucru.\n",
    "\n",
    "> ✅ Te rog să consulți:\n",
    ">\n",
    "> -   [Hands-on Machine Learning with R](https://bradleyboehmke.github.io/HOML/)\n",
    ">\n",
    "> -   [An Introduction to Statistical Learning with Applications in R](https://www.statlearning.com/)\n",
    ">\n",
    "> pentru a afla mai multe despre clasificatorii *K*-Nearest Neighbors.\n",
    "\n",
    "### Clasificatori de tip ensemble\n",
    "\n",
    "Algoritmii de tip ensemble funcționează prin combinarea mai multor estimatori de bază pentru a produce un model optim, fie prin:\n",
    "\n",
    "`bagging`: aplicarea unei *funcții de mediere* asupra unei colecții de modele de bază\n",
    "\n",
    "`boosting`: construirea unei secvențe de modele care se bazează unul pe altul pentru a îmbunătăți performanța predictivă.\n",
    "\n",
    "Să începem prin testarea unui model Random Forest, care construiește o colecție mare de arbori de decizie și apoi aplică o funcție de mediere pentru a obține un model general mai bun.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "49DPoVs6iK1M"
   },
   "source": [
    "# Make a random forest specification\n",
    "rf_spec <- rand_forest() %>% \n",
    "  set_engine(\"ranger\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "rf_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(rf_spec)\n",
    "\n",
    "# Train a random forest model\n",
    "rf_wf_fit <- rf_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "rf_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGVYwC_aiUWc"
   },
   "source": [
    "Bravo 👏!\n",
    "\n",
    "Haide să experimentăm și cu un model Boosted Tree.\n",
    "\n",
    "Boosted Tree define o metodă de ansamblu care creează o serie de arbori decizionali secvențiali, unde fiecare arbore depinde de rezultatele arborilor anteriori, încercând să reducă treptat eroarea. Se concentrează pe greutățile elementelor clasificate incorect și ajustează potrivirea pentru următorul clasificator pentru a corecta.\n",
    "\n",
    "Există diferite moduri de a potrivi acest model (vezi `help(\"boost_tree\")`). În acest exemplu, vom potrivi arborii Boosted prin motorul `xgboost`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Py1YWo-micWs"
   },
   "source": [
    "# Make a boosted tree specification\n",
    "boost_spec <- boost_tree(trees = 200) %>% \n",
    "  set_engine(\"xgboost\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "boost_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(boost_spec)\n",
    "\n",
    "# Train a boosted tree model\n",
    "boost_wf_fit <- boost_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "boost_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNQnbuejigZM"
   },
   "source": [
    "> ✅ Vă rugăm să consultați:\n",
    ">\n",
    "> -   [Machine Learning for Social Scientists](https://cimentadaj.github.io/ml_socsci/tree-based-methods.html#random-forests)\n",
    ">\n",
    "> -   [Hands-on Machine Learning with R](https://bradleyboehmke.github.io/HOML/)\n",
    ">\n",
    "> -   [An Introduction to Statistical Learning with Applications in R](https://www.statlearning.com/)\n",
    ">\n",
    "> -   <https://algotech.netlify.app/blog/xgboost/> - Explorează modelul AdaBoost, care este o alternativă bună la xgboost.\n",
    ">\n",
    "> pentru a afla mai multe despre clasificatorii Ensemble.\n",
    "\n",
    "## 4. Extra - compararea mai multor modele\n",
    "\n",
    "Am ajustat destul de multe modele în acest laborator 🙌. Poate deveni obositor sau dificil să creezi o mulțime de fluxuri de lucru din diferite seturi de preprocesare și/sau specificații de model și apoi să calculezi metricele de performanță una câte una.\n",
    "\n",
    "Haideți să vedem dacă putem aborda această problemă prin crearea unei funcții care ajustează o listă de fluxuri de lucru pe setul de antrenament și apoi returnează metricele de performanță bazate pe setul de testare. Vom folosi `map()` și `map_dfr()` din pachetul [purrr](https://purrr.tidyverse.org/) pentru a aplica funcții fiecărui element din listă.\n",
    "\n",
    "> Funcțiile [`map()`](https://purrr.tidyverse.org/reference/map.html) vă permit să înlocuiți multe bucle for cu un cod care este atât mai concis, cât și mai ușor de citit. Cel mai bun loc pentru a învăța despre funcțiile [`map()`](https://purrr.tidyverse.org/reference/map.html) este capitolul [iteration](http://r4ds.had.co.nz/iteration.html) din R pentru data science.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Qzb7LyZnimd2"
   },
   "source": [
    "set.seed(2056)\n",
    "\n",
    "# Create a metric set\n",
    "eval_metrics <- metric_set(ppv, sens, accuracy, f_meas)\n",
    "\n",
    "# Define a function that returns performance metrics\n",
    "compare_models <- function(workflow_list, train_set, test_set){\n",
    "  \n",
    "  suppressWarnings(\n",
    "    # Fit each model to the train_set\n",
    "    map(workflow_list, fit, data = train_set) %>% \n",
    "    # Make predictions on the test set\n",
    "      map_dfr(augment, new_data = test_set, .id = \"model\") %>%\n",
    "    # Select desired columns\n",
    "      select(model, cuisine, .pred_class) %>% \n",
    "    # Evaluate model performance\n",
    "      group_by(model) %>% \n",
    "      eval_metrics(truth = cuisine, estimate = .pred_class) %>% \n",
    "      ungroup()\n",
    "  )\n",
    "  \n",
    "} # End of function"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fwa712sNisDA"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3i4VJOi2iu-a"
   },
   "source": [
    "# Make a list of workflows\n",
    "workflow_list <- list(\n",
    "  \"svc\" = svc_linear_wf,\n",
    "  \"svm\" = svm_rbf_wf,\n",
    "  \"knn\" = knn_wf,\n",
    "  \"random_forest\" = rf_wf,\n",
    "  \"xgboost\" = boost_wf)\n",
    "\n",
    "# Call the function\n",
    "set.seed(2056)\n",
    "perf_metrics <- compare_models(workflow_list = workflow_list, train_set = cuisines_train, test_set = cuisines_test)\n",
    "\n",
    "# Print out performance metrics\n",
    "perf_metrics %>% \n",
    "  group_by(.metric) %>% \n",
    "  arrange(desc(.estimate)) %>% \n",
    "  slice_head(n=7)\n",
    "\n",
    "# Compare accuracy\n",
    "perf_metrics %>% \n",
    "  filter(.metric == \"accuracy\") %>% \n",
    "  arrange(desc(.estimate))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuWK_lEli4nW"
   },
   "source": [
    "[**workflowset**](https://workflowsets.tidymodels.org/) permite utilizatorilor să creeze și să ajusteze cu ușurință un număr mare de modele, dar este conceput în principal pentru a funcționa cu tehnici de resampling, cum ar fi `cross-validation`, o abordare pe care încă nu am acoperit-o.\n",
    "\n",
    "## **🚀Provocare**\n",
    "\n",
    "Fiecare dintre aceste tehnici are un număr mare de parametri pe care îi poți ajusta, de exemplu, `cost` în SVM-uri, `neighbors` în KNN, `mtry` (Predictori Selectați Aleatoriu) în Random Forest.\n",
    "\n",
    "Cercetează parametrii impliciți ai fiecăruia și gândește-te ce ar însemna ajustarea acestor parametri pentru calitatea modelului.\n",
    "\n",
    "Pentru a afla mai multe despre un model anume și parametrii săi, folosește: `help(\"model\")`, de exemplu, `help(\"rand_forest\")`.\n",
    "\n",
    "> În practică, de obicei *estimăm* *cele mai bune valori* pentru acești parametri antrenând mai multe modele pe un `set de date simulat` și măsurând cât de bine performează toate aceste modele. Acest proces se numește **tuning**.\n",
    "\n",
    "### [**Chestionar post-lectură**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/24/)\n",
    "\n",
    "### **Revizuire & Studiu Individual**\n",
    "\n",
    "Există mulți termeni specifici în aceste lecții, așa că ia-ți un moment pentru a revizui [această listă](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) de terminologie utilă!\n",
    "\n",
    "#### MULȚUMIRI SPECIALE:\n",
    "\n",
    "[`Allison Horst`](https://twitter.com/allison_horst/) pentru crearea ilustrațiilor uimitoare care fac R mai prietenos și mai captivant. Găsește mai multe ilustrații în [galeria ei](https://www.google.com/url?q=https://github.com/allisonhorst/stats-illustrations&sa=D&source=editors&ust=1626380772530000&usg=AOvVaw3zcfyCizFQZpkSLzxiiQEM).\n",
    "\n",
    "[Cassie Breviu](https://www.twitter.com/cassieview) și [Jen Looper](https://www.twitter.com/jenlooper) pentru crearea versiunii originale în Python a acestui modul ♥️\n",
    "\n",
    "Învățare plăcută,\n",
    "\n",
    "[Eric](https://twitter.com/ericntay), Ambasador Gold Microsoft Learn Student.\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/r_learners_sm.jpeg\"\n",
    "   width=\"569\"/>\n",
    "   <figcaption>Ilustrație de @allison_horst</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Declinarea responsabilității**:  \nAcest document a fost tradus utilizând serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). Deși depunem eforturi pentru a asigura acuratețea, vă rugăm să aveți în vedere că traducerile automate pot conține erori sau inexactități. Documentul original în limba sa nativă ar trebui considerat sursa autoritară. Pentru informații critice, se recomandă traducerea profesională realizată de un specialist. Nu ne asumăm răspunderea pentru eventualele neînțelegeri sau interpretări greșite care pot apărea din utilizarea acestei traduceri.\n"
   ]
  }
 ]
}