<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "482bccabe1df958496ea71a3667995cd",
  "translation_date": "2025-09-05T19:08:01+00:00",
  "source_file": "7-TimeSeries/3-SVR/README.md",
  "language_code": "vi"
}
-->
# Dá»± Ä‘oÃ¡n chuá»—i thá»i gian vá»›i Support Vector Regressor

Trong bÃ i há»c trÆ°á»›c, báº¡n Ä‘Ã£ há»c cÃ¡ch sá»­ dá»¥ng mÃ´ hÃ¬nh ARIMA Ä‘á»ƒ dá»± Ä‘oÃ¡n chuá»—i thá»i gian. BÃ¢y giá», báº¡n sáº½ tÃ¬m hiá»ƒu vá» mÃ´ hÃ¬nh Support Vector Regressor, má»™t mÃ´ hÃ¬nh há»“i quy Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ dá»± Ä‘oÃ¡n dá»¯ liá»‡u liÃªn tá»¥c.

## [CÃ¢u há»i trÆ°á»›c bÃ i há»c](https://ff-quizzes.netlify.app/en/ml/) 

## Giá»›i thiá»‡u

Trong bÃ i há»c nÃ y, báº¡n sáº½ khÃ¡m phÃ¡ má»™t cÃ¡ch cá»¥ thá»ƒ Ä‘á»ƒ xÃ¢y dá»±ng mÃ´ hÃ¬nh vá»›i [**SVM**: **S**upport **V**ector **M**achine](https://en.wikipedia.org/wiki/Support-vector_machine) cho há»“i quy, hay **SVR: Support Vector Regressor**.

### SVR trong bá»‘i cáº£nh chuá»—i thá»i gian [^1]

TrÆ°á»›c khi hiá»ƒu Ä‘Æ°á»£c táº§m quan trá»ng cá»§a SVR trong dá»± Ä‘oÃ¡n chuá»—i thá»i gian, Ä‘Ã¢y lÃ  má»™t sá»‘ khÃ¡i niá»‡m quan trá»ng mÃ  báº¡n cáº§n biáº¿t:

- **Há»“i quy:** Ká»¹ thuáº­t há»c cÃ³ giÃ¡m sÃ¡t Ä‘á»ƒ dá»± Ä‘oÃ¡n giÃ¡ trá»‹ liÃªn tá»¥c tá»« má»™t táº­p há»£p Ä‘áº§u vÃ o. Ã tÆ°á»Ÿng lÃ  tÃ¬m má»™t Ä‘Æ°á»ng cong (hoáº·c Ä‘Æ°á»ng tháº³ng) trong khÃ´ng gian Ä‘áº·c trÆ°ng cÃ³ sá»‘ lÆ°á»£ng Ä‘iá»ƒm dá»¯ liá»‡u tá»‘i Ä‘a. [Nháº¥n vÃ o Ä‘Ã¢y](https://en.wikipedia.org/wiki/Regression_analysis) Ä‘á»ƒ biáº¿t thÃªm thÃ´ng tin.
- **Support Vector Machine (SVM):** Má»™t loáº¡i mÃ´ hÃ¬nh há»c mÃ¡y cÃ³ giÃ¡m sÃ¡t Ä‘Æ°á»£c sá»­ dá»¥ng cho phÃ¢n loáº¡i, há»“i quy vÃ  phÃ¡t hiá»‡n Ä‘iá»ƒm báº¥t thÆ°á»ng. MÃ´ hÃ¬nh lÃ  má»™t siÃªu pháº³ng trong khÃ´ng gian Ä‘áº·c trÆ°ng, trong trÆ°á»ng há»£p phÃ¢n loáº¡i nÃ³ hoáº¡t Ä‘á»™ng nhÆ° má»™t ranh giá»›i, vÃ  trong trÆ°á»ng há»£p há»“i quy nÃ³ hoáº¡t Ä‘á»™ng nhÆ° Ä‘Æ°á»ng tháº³ng phÃ¹ há»£p nháº¥t. Trong SVM, má»™t hÃ m Kernel thÆ°á»ng Ä‘Æ°á»£c sá»­ dá»¥ng Ä‘á»ƒ chuyá»ƒn Ä‘á»•i táº­p dá»¯ liá»‡u sang khÃ´ng gian cÃ³ sá»‘ chiá»u cao hÆ¡n, Ä‘á»ƒ chÃºng cÃ³ thá»ƒ dá»… dÃ ng phÃ¢n tÃ¡ch. [Nháº¥n vÃ o Ä‘Ã¢y](https://en.wikipedia.org/wiki/Support-vector_machine) Ä‘á»ƒ biáº¿t thÃªm thÃ´ng tin vá» SVM.
- **Support Vector Regressor (SVR):** Má»™t loáº¡i SVM, Ä‘á»ƒ tÃ¬m Ä‘Æ°á»ng tháº³ng phÃ¹ há»£p nháº¥t (trong trÆ°á»ng há»£p cá»§a SVM lÃ  siÃªu pháº³ng) cÃ³ sá»‘ lÆ°á»£ng Ä‘iá»ƒm dá»¯ liá»‡u tá»‘i Ä‘a.

### Táº¡i sao láº¡i lÃ  SVR? [^1]

Trong bÃ i há»c trÆ°á»›c, báº¡n Ä‘Ã£ há»c vá» ARIMA, má»™t phÆ°Æ¡ng phÃ¡p thá»‘ng kÃª tuyáº¿n tÃ­nh ráº¥t thÃ nh cÃ´ng Ä‘á»ƒ dá»± Ä‘oÃ¡n dá»¯ liá»‡u chuá»—i thá»i gian. Tuy nhiÃªn, trong nhiá»u trÆ°á»ng há»£p, dá»¯ liá»‡u chuá»—i thá»i gian cÃ³ tÃ­nh *phi tuyáº¿n*, Ä‘iá»u mÃ  cÃ¡c mÃ´ hÃ¬nh tuyáº¿n tÃ­nh khÃ´ng thá»ƒ Ã¡nh xáº¡ Ä‘Æ°á»£c. Trong nhá»¯ng trÆ°á»ng há»£p nhÆ° váº­y, kháº£ nÄƒng cá»§a SVM trong viá»‡c xem xÃ©t tÃ­nh phi tuyáº¿n cá»§a dá»¯ liá»‡u cho cÃ¡c nhiá»‡m vá»¥ há»“i quy khiáº¿n SVR trá»Ÿ nÃªn thÃ nh cÃ´ng trong dá»± Ä‘oÃ¡n chuá»—i thá»i gian.

## BÃ i táº­p - xÃ¢y dá»±ng mÃ´ hÃ¬nh SVR

CÃ¡c bÆ°á»›c Ä‘áº§u tiÃªn Ä‘á»ƒ chuáº©n bá»‹ dá»¯ liá»‡u giá»‘ng nhÆ° bÃ i há»c trÆ°á»›c vá» [ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA). 

Má»Ÿ thÆ° má»¥c [_/working_](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/3-SVR/working) trong bÃ i há»c nÃ y vÃ  tÃ¬m tá»‡p [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/7-TimeSeries/3-SVR/working/notebook.ipynb). [^2]

1. Cháº¡y notebook vÃ  nháº­p cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t: [^2]

   ```python
   import sys
   sys.path.append('../../')
   ```

   ```python
   import os
   import warnings
   import matplotlib.pyplot as plt
   import numpy as np
   import pandas as pd
   import datetime as dt
   import math
   
   from sklearn.svm import SVR
   from sklearn.preprocessing import MinMaxScaler
   from common.utils import load_data, mape
   ```

2. Táº£i dá»¯ liá»‡u tá»« tá»‡p `/data/energy.csv` vÃ o má»™t dataframe cá»§a Pandas vÃ  xem qua: [^2]

   ```python
   energy = load_data('../../data')[['load']]
   ```

3. Váº½ biá»ƒu Ä‘á»“ táº¥t cáº£ dá»¯ liá»‡u nÄƒng lÆ°á»£ng cÃ³ sáºµn tá»« thÃ¡ng 1 nÄƒm 2012 Ä‘áº¿n thÃ¡ng 12 nÄƒm 2014: [^2]

   ```python
   energy.plot(y='load', subplots=True, figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![full data](../../../../7-TimeSeries/3-SVR/images/full-data.png)

   BÃ¢y giá», hÃ£y xÃ¢y dá»±ng mÃ´ hÃ¬nh SVR cá»§a chÃºng ta.

### Táº¡o táº­p dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  kiá»ƒm tra

BÃ¢y giá» dá»¯ liá»‡u cá»§a báº¡n Ä‘Ã£ Ä‘Æ°á»£c táº£i, báº¡n cÃ³ thá»ƒ tÃ¡ch nÃ³ thÃ nh táº­p huáº¥n luyá»‡n vÃ  kiá»ƒm tra. Sau Ä‘Ã³, báº¡n sáº½ Ä‘á»‹nh hÃ¬nh láº¡i dá»¯ liá»‡u Ä‘á»ƒ táº¡o má»™t táº­p dá»¯ liá»‡u dá»±a trÃªn bÆ°á»›c thá»i gian, Ä‘iá»u nÃ y sáº½ cáº§n thiáº¿t cho SVR. Báº¡n sáº½ huáº¥n luyá»‡n mÃ´ hÃ¬nh cá»§a mÃ¬nh trÃªn táº­p huáº¥n luyá»‡n. Sau khi mÃ´ hÃ¬nh hoÃ n thÃ nh viá»‡c huáº¥n luyá»‡n, báº¡n sáº½ Ä‘Ã¡nh giÃ¡ Ä‘á»™ chÃ­nh xÃ¡c cá»§a nÃ³ trÃªn táº­p huáº¥n luyá»‡n, táº­p kiá»ƒm tra vÃ  sau Ä‘Ã³ lÃ  toÃ n bá»™ táº­p dá»¯ liá»‡u Ä‘á»ƒ xem hiá»‡u suáº¥t tá»•ng thá»ƒ. Báº¡n cáº§n Ä‘áº£m báº£o ráº±ng táº­p kiá»ƒm tra bao gá»“m má»™t khoáº£ng thá»i gian sau táº­p huáº¥n luyá»‡n Ä‘á»ƒ Ä‘áº£m báº£o ráº±ng mÃ´ hÃ¬nh khÃ´ng thu tháº­p thÃ´ng tin tá»« cÃ¡c khoáº£ng thá»i gian trong tÆ°Æ¡ng lai [^2] (má»™t tÃ¬nh huá»‘ng Ä‘Æ°á»£c gá»i lÃ  *Overfitting*).

1. PhÃ¢n bá»• khoáº£ng thá»i gian hai thÃ¡ng tá»« ngÃ y 1 thÃ¡ng 9 Ä‘áº¿n ngÃ y 31 thÃ¡ng 10 nÄƒm 2014 cho táº­p huáº¥n luyá»‡n. Táº­p kiá»ƒm tra sáº½ bao gá»“m khoáº£ng thá»i gian hai thÃ¡ng tá»« ngÃ y 1 thÃ¡ng 11 Ä‘áº¿n ngÃ y 31 thÃ¡ng 12 nÄƒm 2014: [^2]

   ```python
   train_start_dt = '2014-11-01 00:00:00'
   test_start_dt = '2014-12-30 00:00:00'
   ```

2. Hiá»ƒn thá»‹ sá»± khÃ¡c biá»‡t: [^2]

   ```python
   energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)][['load']].rename(columns={'load':'train'}) \
       .join(energy[test_start_dt:][['load']].rename(columns={'load':'test'}), how='outer') \
       .plot(y=['train', 'test'], figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![training and testing data](../../../../7-TimeSeries/3-SVR/images/train-test.png)

### Chuáº©n bá»‹ dá»¯ liá»‡u Ä‘á»ƒ huáº¥n luyá»‡n

BÃ¢y giá», báº¡n cáº§n chuáº©n bá»‹ dá»¯ liá»‡u Ä‘á»ƒ huáº¥n luyá»‡n báº±ng cÃ¡ch lá»c vÃ  chuáº©n hÃ³a dá»¯ liá»‡u cá»§a mÃ¬nh. Lá»c táº­p dá»¯ liá»‡u Ä‘á»ƒ chá»‰ bao gá»“m cÃ¡c khoáº£ng thá»i gian vÃ  cá»™t cáº§n thiáº¿t, vÃ  chuáº©n hÃ³a Ä‘á»ƒ Ä‘áº£m báº£o dá»¯ liá»‡u Ä‘Æ°á»£c chiáº¿u trong khoáº£ng 0,1.

1. Lá»c táº­p dá»¯ liá»‡u gá»‘c Ä‘á»ƒ chá»‰ bao gá»“m cÃ¡c khoáº£ng thá»i gian Ä‘Ã£ Ä‘á» cáº­p á»Ÿ trÃªn cho má»—i táº­p vÃ  chá»‰ bao gá»“m cá»™t 'load' cáº§n thiáº¿t cÃ¹ng vá»›i ngÃ y thÃ¡ng: [^2]

   ```python
   train = energy.copy()[(energy.index >= train_start_dt) & (energy.index < test_start_dt)][['load']]
   test = energy.copy()[energy.index >= test_start_dt][['load']]
   
   print('Training data shape: ', train.shape)
   print('Test data shape: ', test.shape)
   ```

   ```output
   Training data shape:  (1416, 1)
   Test data shape:  (48, 1)
   ```
   
2. Chuáº©n hÃ³a dá»¯ liá»‡u huáº¥n luyá»‡n Ä‘á»ƒ náº±m trong khoáº£ng (0, 1): [^2]

   ```python
   scaler = MinMaxScaler()
   train['load'] = scaler.fit_transform(train)
   ```
   
4. BÃ¢y giá», báº¡n chuáº©n hÃ³a dá»¯ liá»‡u kiá»ƒm tra: [^2]

   ```python
   test['load'] = scaler.transform(test)
   ```

### Táº¡o dá»¯ liá»‡u vá»›i bÆ°á»›c thá»i gian [^1]

Äá»‘i vá»›i SVR, báº¡n chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u Ä‘áº§u vÃ o thÃ nh dáº¡ng `[batch, timesteps]`. VÃ¬ váº­y, báº¡n Ä‘á»‹nh hÃ¬nh láº¡i `train_data` vÃ  `test_data` hiá»‡n táº¡i sao cho cÃ³ má»™t chiá»u má»›i Ä‘á» cáº­p Ä‘áº¿n cÃ¡c bÆ°á»›c thá»i gian.

```python
# Converting to numpy arrays
train_data = train.values
test_data = test.values
```

Trong vÃ­ dá»¥ nÃ y, chÃºng ta láº¥y `timesteps = 5`. VÃ¬ váº­y, Ä‘áº§u vÃ o cho mÃ´ hÃ¬nh lÃ  dá»¯ liá»‡u cá»§a 4 bÆ°á»›c thá»i gian Ä‘áº§u tiÃªn, vÃ  Ä‘áº§u ra sáº½ lÃ  dá»¯ liá»‡u cá»§a bÆ°á»›c thá»i gian thá»© 5.

```python
timesteps=5
```

Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u huáº¥n luyá»‡n thÃ nh tensor 2D báº±ng cÃ¡ch sá»­ dá»¥ng list comprehension lá»“ng nhau:

```python
train_data_timesteps=np.array([[j for j in train_data[i:i+timesteps]] for i in range(0,len(train_data)-timesteps+1)])[:,:,0]
train_data_timesteps.shape
```

```output
(1412, 5)
```

Chuyá»ƒn Ä‘á»•i dá»¯ liá»‡u kiá»ƒm tra thÃ nh tensor 2D:

```python
test_data_timesteps=np.array([[j for j in test_data[i:i+timesteps]] for i in range(0,len(test_data)-timesteps+1)])[:,:,0]
test_data_timesteps.shape
```

```output
(44, 5)
```

Chá»n Ä‘áº§u vÃ o vÃ  Ä‘áº§u ra tá»« dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  kiá»ƒm tra:

```python
x_train, y_train = train_data_timesteps[:,:timesteps-1],train_data_timesteps[:,[timesteps-1]]
x_test, y_test = test_data_timesteps[:,:timesteps-1],test_data_timesteps[:,[timesteps-1]]

print(x_train.shape, y_train.shape)
print(x_test.shape, y_test.shape)
```

```output
(1412, 4) (1412, 1)
(44, 4) (44, 1)
```

### Triá»ƒn khai SVR [^1]

BÃ¢y giá», Ä‘Ã£ Ä‘áº¿n lÃºc triá»ƒn khai SVR. Äá»ƒ Ä‘á»c thÃªm vá» triá»ƒn khai nÃ y, báº¡n cÃ³ thá»ƒ tham kháº£o [tÃ i liá»‡u nÃ y](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html). Äá»‘i vá»›i triá»ƒn khai cá»§a chÃºng ta, chÃºng ta thá»±c hiá»‡n cÃ¡c bÆ°á»›c sau:

  1. Äá»‹nh nghÄ©a mÃ´ hÃ¬nh báº±ng cÃ¡ch gá»i `SVR()` vÃ  truyá»n vÃ o cÃ¡c siÃªu tham sá»‘ cá»§a mÃ´ hÃ¬nh: kernel, gamma, c vÃ  epsilon
  2. Chuáº©n bá»‹ mÃ´ hÃ¬nh cho dá»¯ liá»‡u huáº¥n luyá»‡n báº±ng cÃ¡ch gá»i hÃ m `fit()`
  3. Thá»±c hiá»‡n dá»± Ä‘oÃ¡n báº±ng cÃ¡ch gá»i hÃ m `predict()`

BÃ¢y giá» chÃºng ta táº¡o má»™t mÃ´ hÃ¬nh SVR. á» Ä‘Ã¢y chÃºng ta sá»­ dá»¥ng [kernel RBF](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel), vÃ  Ä‘áº·t cÃ¡c siÃªu tham sá»‘ gamma, C vÃ  epsilon láº§n lÆ°á»£t lÃ  0.5, 10 vÃ  0.05.

```python
model = SVR(kernel='rbf',gamma=0.5, C=10, epsilon = 0.05)
```

#### Huáº¥n luyá»‡n mÃ´ hÃ¬nh trÃªn dá»¯ liá»‡u huáº¥n luyá»‡n [^1]

```python
model.fit(x_train, y_train[:,0])
```

```output
SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.05, gamma=0.5,
    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)
```

#### Thá»±c hiá»‡n dá»± Ä‘oÃ¡n cá»§a mÃ´ hÃ¬nh [^1]

```python
y_train_pred = model.predict(x_train).reshape(-1,1)
y_test_pred = model.predict(x_test).reshape(-1,1)

print(y_train_pred.shape, y_test_pred.shape)
```

```output
(1412, 1) (44, 1)
```

Báº¡n Ä‘Ã£ xÃ¢y dá»±ng SVR cá»§a mÃ¬nh! BÃ¢y giá» chÃºng ta cáº§n Ä‘Ã¡nh giÃ¡ nÃ³.

### ÄÃ¡nh giÃ¡ mÃ´ hÃ¬nh cá»§a báº¡n [^1]

Äá»ƒ Ä‘Ã¡nh giÃ¡, trÆ°á»›c tiÃªn chÃºng ta sáº½ chuáº©n hÃ³a láº¡i dá»¯ liá»‡u vá» thang Ä‘o ban Ä‘áº§u. Sau Ä‘Ã³, Ä‘á»ƒ kiá»ƒm tra hiá»‡u suáº¥t, chÃºng ta sáº½ váº½ biá»ƒu Ä‘á»“ chuá»—i thá»i gian gá»‘c vÃ  dá»± Ä‘oÃ¡n, vÃ  cÅ©ng in káº¿t quáº£ MAPE.

Chuáº©n hÃ³a láº¡i dá»¯ liá»‡u dá»± Ä‘oÃ¡n vÃ  Ä‘áº§u ra gá»‘c:

```python
# Scaling the predictions
y_train_pred = scaler.inverse_transform(y_train_pred)
y_test_pred = scaler.inverse_transform(y_test_pred)

print(len(y_train_pred), len(y_test_pred))
```

```python
# Scaling the original values
y_train = scaler.inverse_transform(y_train)
y_test = scaler.inverse_transform(y_test)

print(len(y_train), len(y_test))
```

#### Kiá»ƒm tra hiá»‡u suáº¥t mÃ´ hÃ¬nh trÃªn dá»¯ liá»‡u huáº¥n luyá»‡n vÃ  kiá»ƒm tra [^1]

ChÃºng ta trÃ­ch xuáº¥t cÃ¡c dáº¥u thá»i gian tá»« táº­p dá»¯ liá»‡u Ä‘á»ƒ hiá»ƒn thá»‹ trÃªn trá»¥c x cá»§a biá»ƒu Ä‘á»“. LÆ°u Ã½ ráº±ng chÃºng ta Ä‘ang sá»­ dá»¥ng ```timesteps-1``` giÃ¡ trá»‹ Ä‘áº§u tiÃªn lÃ m Ä‘áº§u vÃ o cho Ä‘áº§u ra Ä‘áº§u tiÃªn, vÃ¬ váº­y cÃ¡c dáº¥u thá»i gian cho Ä‘áº§u ra sáº½ báº¯t Ä‘áº§u sau Ä‘Ã³.

```python
train_timestamps = energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)].index[timesteps-1:]
test_timestamps = energy[test_start_dt:].index[timesteps-1:]

print(len(train_timestamps), len(test_timestamps))
```

```output
1412 44
```

Váº½ biá»ƒu Ä‘á»“ dá»± Ä‘oÃ¡n cho dá»¯ liá»‡u huáº¥n luyá»‡n:

```python
plt.figure(figsize=(25,6))
plt.plot(train_timestamps, y_train, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(train_timestamps, y_train_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.title("Training data prediction")
plt.show()
```

![training data prediction](../../../../7-TimeSeries/3-SVR/images/train-data-predict.png)

In MAPE cho dá»¯ liá»‡u huáº¥n luyá»‡n

```python
print('MAPE for training data: ', mape(y_train_pred, y_train)*100, '%')
```

```output
MAPE for training data: 1.7195710200875551 %
```

Váº½ biá»ƒu Ä‘á»“ dá»± Ä‘oÃ¡n cho dá»¯ liá»‡u kiá»ƒm tra

```python
plt.figure(figsize=(10,3))
plt.plot(test_timestamps, y_test, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(test_timestamps, y_test_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![testing data prediction](../../../../7-TimeSeries/3-SVR/images/test-data-predict.png)

In MAPE cho dá»¯ liá»‡u kiá»ƒm tra

```python
print('MAPE for testing data: ', mape(y_test_pred, y_test)*100, '%')
```

```output
MAPE for testing data:  1.2623790187854018 %
```

ğŸ† Báº¡n Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ ráº¥t tá»‘t trÃªn táº­p dá»¯ liá»‡u kiá»ƒm tra!

### Kiá»ƒm tra hiá»‡u suáº¥t mÃ´ hÃ¬nh trÃªn toÃ n bá»™ táº­p dá»¯ liá»‡u [^1]

```python
# Extracting load values as numpy array
data = energy.copy().values

# Scaling
data = scaler.transform(data)

# Transforming to 2D tensor as per model input requirement
data_timesteps=np.array([[j for j in data[i:i+timesteps]] for i in range(0,len(data)-timesteps+1)])[:,:,0]
print("Tensor shape: ", data_timesteps.shape)

# Selecting inputs and outputs from data
X, Y = data_timesteps[:,:timesteps-1],data_timesteps[:,[timesteps-1]]
print("X shape: ", X.shape,"\nY shape: ", Y.shape)
```

```output
Tensor shape:  (26300, 5)
X shape:  (26300, 4) 
Y shape:  (26300, 1)
```

```python
# Make model predictions
Y_pred = model.predict(X).reshape(-1,1)

# Inverse scale and reshape
Y_pred = scaler.inverse_transform(Y_pred)
Y = scaler.inverse_transform(Y)
```

```python
plt.figure(figsize=(30,8))
plt.plot(Y, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(Y_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![full data prediction](../../../../7-TimeSeries/3-SVR/images/full-data-predict.png)

```python
print('MAPE: ', mape(Y_pred, Y)*100, '%')
```

```output
MAPE:  2.0572089029888656 %
```

ğŸ† Biá»ƒu Ä‘á»“ ráº¥t Ä‘áº¹p, cho tháº¥y má»™t mÃ´ hÃ¬nh vá»›i Ä‘á»™ chÃ­nh xÃ¡c tá»‘t. LÃ m tá»‘t láº¯m!

---

## ğŸš€Thá»­ thÃ¡ch

- Thá»­ Ä‘iá»u chá»‰nh cÃ¡c siÃªu tham sá»‘ (gamma, C, epsilon) khi táº¡o mÃ´ hÃ¬nh vÃ  Ä‘Ã¡nh giÃ¡ trÃªn dá»¯ liá»‡u Ä‘á»ƒ xem bá»™ siÃªu tham sá»‘ nÃ o cho káº¿t quáº£ tá»‘t nháº¥t trÃªn dá»¯ liá»‡u kiá»ƒm tra. Äá»ƒ biáº¿t thÃªm vá» cÃ¡c siÃªu tham sá»‘ nÃ y, báº¡n cÃ³ thá»ƒ tham kháº£o tÃ i liá»‡u [táº¡i Ä‘Ã¢y](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel). 
- Thá»­ sá»­ dá»¥ng cÃ¡c hÃ m kernel khÃ¡c nhau cho mÃ´ hÃ¬nh vÃ  phÃ¢n tÃ­ch hiá»‡u suáº¥t cá»§a chÃºng trÃªn táº­p dá»¯ liá»‡u. Má»™t tÃ i liá»‡u há»¯u Ã­ch cÃ³ thá»ƒ Ä‘Æ°á»£c tÃ¬m tháº¥y [táº¡i Ä‘Ã¢y](https://scikit-learn.org/stable/modules/svm.html#kernel-functions).
- Thá»­ sá»­ dá»¥ng cÃ¡c giÃ¡ trá»‹ khÃ¡c nhau cho `timesteps` Ä‘á»ƒ mÃ´ hÃ¬nh nhÃ¬n láº¡i vÃ  thá»±c hiá»‡n dá»± Ä‘oÃ¡n.

## [CÃ¢u há»i sau bÃ i há»c](https://ff-quizzes.netlify.app/en/ml/)

## Ã”n táº­p & Tá»± há»c

BÃ i há»c nÃ y nháº±m giá»›i thiá»‡u á»©ng dá»¥ng cá»§a SVR trong dá»± Ä‘oÃ¡n chuá»—i thá»i gian. Äá»ƒ Ä‘á»c thÃªm vá» SVR, báº¡n cÃ³ thá»ƒ tham kháº£o [blog nÃ y](https://www.analyticsvidhya.com/blog/2020/03/support-vector-regression-tutorial-for-machine-learning/). TÃ i liá»‡u [scikit-learn nÃ y](https://scikit-learn.org/stable/modules/svm.html) cung cáº¥p má»™t giáº£i thÃ­ch toÃ n diá»‡n hÆ¡n vá» SVM nÃ³i chung, [SVRs](https://scikit-learn.org/stable/modules/svm.html#regression) vÃ  cÅ©ng cÃ¡c chi tiáº¿t triá»ƒn khai khÃ¡c nhÆ° cÃ¡c [hÃ m kernel](https://scikit-learn.org/stable/modules/svm.html#kernel-functions) khÃ¡c nhau cÃ³ thá»ƒ Ä‘Æ°á»£c sá»­ dá»¥ng, vÃ  cÃ¡c tham sá»‘ cá»§a chÃºng.

## BÃ i táº­p

[Má»™t mÃ´ hÃ¬nh SVR má»›i](assignment.md)

## TÃ­n dá»¥ng

[^1]: VÄƒn báº£n, mÃ£ vÃ  káº¿t quáº£ trong pháº§n nÃ y Ä‘Æ°á»£c Ä‘Ã³ng gÃ³p bá»Ÿi [@AnirbanMukherjeeXD](https://github.com/AnirbanMukherjeeXD)
[^2]: VÄƒn báº£n, mÃ£ vÃ  káº¿t quáº£ trong pháº§n nÃ y Ä‘Æ°á»£c láº¥y tá»« [ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA)

---

**TuyÃªn bá»‘ miá»…n trá»« trÃ¡ch nhiá»‡m**:  
TÃ i liá»‡u nÃ y Ä‘Ã£ Ä‘Æ°á»£c dá»‹ch báº±ng dá»‹ch vá»¥ dá»‹ch thuáº­t AI [Co-op Translator](https://github.com/Azure/co-op-translator). Máº·c dÃ¹ chÃºng tÃ´i cá»‘ gáº¯ng Ä‘áº£m báº£o Ä‘á»™ chÃ­nh xÃ¡c, xin lÆ°u Ã½ ráº±ng cÃ¡c báº£n dá»‹ch tá»± Ä‘á»™ng cÃ³ thá»ƒ chá»©a lá»—i hoáº·c khÃ´ng chÃ­nh xÃ¡c. TÃ i liá»‡u gá»‘c báº±ng ngÃ´n ngá»¯ báº£n Ä‘á»‹a nÃªn Ä‘Æ°á»£c coi lÃ  nguá»“n thÃ´ng tin chÃ­nh thá»©c. Äá»‘i vá»›i cÃ¡c thÃ´ng tin quan trá»ng, khuyáº¿n nghá»‹ sá»­ dá»¥ng dá»‹ch vá»¥ dá»‹ch thuáº­t chuyÃªn nghiá»‡p bá»Ÿi con ngÆ°á»i. ChÃºng tÃ´i khÃ´ng chá»‹u trÃ¡ch nhiá»‡m cho báº¥t ká»³ sá»± hiá»ƒu láº§m hoáº·c diá»…n giáº£i sai nÃ o phÃ¡t sinh tá»« viá»‡c sá»­ dá»¥ng báº£n dá»‹ch nÃ y.