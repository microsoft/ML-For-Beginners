<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "107d5bb29da8a562e7ae72262d251a75",
  "translation_date": "2025-09-05T20:20:38+00:00",
  "source_file": "8-Reinforcement/2-Gym/README.md",
  "language_code": "vi"
}
-->
# TrÆ°á»£t vÃ¡n CartPole

BÃ i toÃ¡n mÃ  chÃºng ta Ä‘Ã£ giáº£i trong bÃ i há»c trÆ°á»›c cÃ³ váº» nhÆ° lÃ  má»™t váº¥n Ä‘á» Ä‘Æ¡n giáº£n, khÃ´ng thá»±c sá»± Ã¡p dá»¥ng Ä‘Æ°á»£c vÃ o cÃ¡c tÃ¬nh huá»‘ng thá»±c táº¿. NhÆ°ng thá»±c táº¿ khÃ´ng pháº£i váº­y, vÃ¬ nhiá»u váº¥n Ä‘á» trong tháº¿ giá»›i thá»±c cÅ©ng cÃ³ ká»‹ch báº£n tÆ°Æ¡ng tá»± - bao gá»“m chÆ¡i cá» vua hoáº·c cá» vÃ¢y. ChÃºng tÆ°Æ¡ng tá»± nhau vÃ¬ chÃºng ta cÅ©ng cÃ³ má»™t bÃ n cá» vá»›i cÃ¡c quy táº¯c nháº¥t Ä‘á»‹nh vÃ  má»™t **tráº¡ng thÃ¡i rá»i ráº¡c**.

## [CÃ¢u há»i trÆ°á»›c bÃ i há»c](https://ff-quizzes.netlify.app/en/ml/)

## Giá»›i thiá»‡u

Trong bÃ i há»c nÃ y, chÃºng ta sáº½ Ã¡p dá»¥ng cÃ¡c nguyÃªn táº¯c cá»§a Q-Learning vÃ o má»™t bÃ i toÃ¡n vá»›i **tráº¡ng thÃ¡i liÃªn tá»¥c**, tá»©c lÃ  tráº¡ng thÃ¡i Ä‘Æ°á»£c biá»ƒu diá»…n báº±ng má»™t hoáº·c nhiá»u sá»‘ thá»±c. ChÃºng ta sáº½ giáº£i quyáº¿t bÃ i toÃ¡n sau:

> **BÃ i toÃ¡n**: Náº¿u Peter muá»‘n thoÃ¡t khá»i con sÃ³i, cáº­u áº¥y cáº§n pháº£i di chuyá»ƒn nhanh hÆ¡n. ChÃºng ta sáº½ xem cÃ¡ch Peter há»c cÃ¡ch trÆ°á»£t vÃ¡n, Ä‘áº·c biá»‡t lÃ  giá»¯ thÄƒng báº±ng, báº±ng cÃ¡ch sá»­ dá»¥ng Q-Learning.

![Cuá»™c cháº¡y trá»‘n vÄ© Ä‘áº¡i!](../../../../8-Reinforcement/2-Gym/images/escape.png)

> Peter vÃ  cÃ¡c báº¡n cá»§a cáº­u áº¥y sÃ¡ng táº¡o Ä‘á»ƒ thoÃ¡t khá»i con sÃ³i! HÃ¬nh áº£nh bá»Ÿi [Jen Looper](https://twitter.com/jenlooper)

ChÃºng ta sáº½ sá»­ dá»¥ng má»™t phiÃªn báº£n Ä‘Æ¡n giáº£n cá»§a viá»‡c giá»¯ thÄƒng báº±ng Ä‘Æ°á»£c gá»i lÃ  bÃ i toÃ¡n **CartPole**. Trong tháº¿ giá»›i CartPole, chÃºng ta cÃ³ má»™t thanh trÆ°á»£t ngang cÃ³ thá»ƒ di chuyá»ƒn sang trÃ¡i hoáº·c pháº£i, vÃ  má»¥c tiÃªu lÃ  giá»¯ thÄƒng báº±ng má»™t cÃ¢y cá»™t tháº³ng Ä‘á»©ng trÃªn thanh trÆ°á»£t.

## YÃªu cáº§u trÆ°á»›c

Trong bÃ i há»c nÃ y, chÃºng ta sáº½ sá»­ dá»¥ng má»™t thÆ° viá»‡n gá»i lÃ  **OpenAI Gym** Ä‘á»ƒ mÃ´ phá»ng cÃ¡c **mÃ´i trÆ°á»ng** khÃ¡c nhau. Báº¡n cÃ³ thá»ƒ cháº¡y mÃ£ cá»§a bÃ i há»c nÃ y trÃªn mÃ¡y tÃ­nh cÃ¡ nhÃ¢n (vÃ­ dá»¥: tá»« Visual Studio Code), trong trÆ°á»ng há»£p Ä‘Ã³, mÃ´ phá»ng sáº½ má»Ÿ trong má»™t cá»­a sá»• má»›i. Khi cháº¡y mÃ£ trá»±c tuyáº¿n, báº¡n cÃ³ thá»ƒ cáº§n thá»±c hiá»‡n má»™t sá»‘ Ä‘iá»u chá»‰nh, nhÆ° Ä‘Æ°á»£c mÃ´ táº£ [á»Ÿ Ä‘Ã¢y](https://towardsdatascience.com/rendering-openai-gym-envs-on-binder-and-google-colab-536f99391cc7).

## OpenAI Gym

Trong bÃ i há»c trÆ°á»›c, cÃ¡c quy táº¯c cá»§a trÃ² chÆ¡i vÃ  tráº¡ng thÃ¡i Ä‘Æ°á»£c cung cáº¥p bá»Ÿi lá»›p `Board` mÃ  chÃºng ta tá»± Ä‘á»‹nh nghÄ©a. á» Ä‘Ã¢y, chÃºng ta sáº½ sá»­ dá»¥ng má»™t **mÃ´i trÆ°á»ng mÃ´ phá»ng** Ä‘áº·c biá»‡t, mÃ´ phá»ng váº­t lÃ½ Ä‘áº±ng sau cÃ¢y cá»™t giá»¯ thÄƒng báº±ng. Má»™t trong nhá»¯ng mÃ´i trÆ°á»ng mÃ´ phá»ng phá»• biáº¿n nháº¥t Ä‘á»ƒ huáº¥n luyá»‡n cÃ¡c thuáº­t toÃ¡n há»c tÄƒng cÆ°á»ng Ä‘Æ°á»£c gá»i lÃ  [Gym](https://gym.openai.com/), Ä‘Æ°á»£c duy trÃ¬ bá»Ÿi [OpenAI](https://openai.com/). Báº±ng cÃ¡ch sá»­ dá»¥ng Gym nÃ y, chÃºng ta cÃ³ thá»ƒ táº¡o ra cÃ¡c **mÃ´i trÆ°á»ng** khÃ¡c nhau tá»« mÃ´ phá»ng CartPole Ä‘áº¿n cÃ¡c trÃ² chÆ¡i Atari.

> **LÆ°u Ã½**: Báº¡n cÃ³ thá»ƒ xem cÃ¡c mÃ´i trÆ°á»ng khÃ¡c cÃ³ sáºµn tá»« OpenAI Gym [táº¡i Ä‘Ã¢y](https://gym.openai.com/envs/#classic_control).

Äáº§u tiÃªn, hÃ£y cÃ i Ä‘áº·t Gym vÃ  nháº­p cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t (mÃ£ khá»‘i 1):

```python
import sys
!{sys.executable} -m pip install gym 

import gym
import matplotlib.pyplot as plt
import numpy as np
import random
```

## BÃ i táº­p - khá»Ÿi táº¡o mÃ´i trÆ°á»ng CartPole

Äá»ƒ lÃ m viá»‡c vá»›i bÃ i toÃ¡n giá»¯ thÄƒng báº±ng CartPole, chÃºng ta cáº§n khá»Ÿi táº¡o mÃ´i trÆ°á»ng tÆ°Æ¡ng á»©ng. Má»—i mÃ´i trÆ°á»ng Ä‘Æ°á»£c liÃªn káº¿t vá»›i:

- **KhÃ´ng gian quan sÃ¡t** Ä‘á»‹nh nghÄ©a cáº¥u trÃºc thÃ´ng tin mÃ  chÃºng ta nháº­n Ä‘Æ°á»£c tá»« mÃ´i trÆ°á»ng. Äá»‘i vá»›i bÃ i toÃ¡n CartPole, chÃºng ta nháº­n Ä‘Æ°á»£c vá»‹ trÃ­ cá»§a cÃ¢y cá»™t, váº­n tá»‘c vÃ  má»™t sá»‘ giÃ¡ trá»‹ khÃ¡c.

- **KhÃ´ng gian hÃ nh Ä‘á»™ng** Ä‘á»‹nh nghÄ©a cÃ¡c hÃ nh Ä‘á»™ng cÃ³ thá»ƒ thá»±c hiá»‡n. Trong trÆ°á»ng há»£p cá»§a chÃºng ta, khÃ´ng gian hÃ nh Ä‘á»™ng lÃ  rá»i ráº¡c vÃ  bao gá»“m hai hÃ nh Ä‘á»™ng - **trÃ¡i** vÃ  **pháº£i**. (mÃ£ khá»‘i 2)

1. Äá»ƒ khá»Ÿi táº¡o, hÃ£y nháº­p mÃ£ sau:

    ```python
    env = gym.make("CartPole-v1")
    print(env.action_space)
    print(env.observation_space)
    print(env.action_space.sample())
    ```

Äá»ƒ xem cÃ¡ch mÃ´i trÆ°á»ng hoáº¡t Ä‘á»™ng, hÃ£y cháº¡y má»™t mÃ´ phá»ng ngáº¯n trong 100 bÆ°á»›c. Táº¡i má»—i bÆ°á»›c, chÃºng ta cung cáº¥p má»™t hÃ nh Ä‘á»™ng Ä‘á»ƒ thá»±c hiá»‡n - trong mÃ´ phá»ng nÃ y, chÃºng ta chá»‰ chá»n ngáº«u nhiÃªn má»™t hÃ nh Ä‘á»™ng tá»« `action_space`.

1. Cháº¡y mÃ£ dÆ°á»›i Ä‘Ã¢y vÃ  xem káº¿t quáº£.

    âœ… Nhá»› ráº±ng nÃªn cháº¡y mÃ£ nÃ y trÃªn cÃ i Ä‘áº·t Python cá»¥c bá»™! (mÃ£ khá»‘i 3)

    ```python
    env.reset()
    
    for i in range(100):
       env.render()
       env.step(env.action_space.sample())
    env.close()
    ```

    Báº¡n sáº½ tháº¥y má»™t hÃ¬nh áº£nh tÆ°Æ¡ng tá»± nhÆ° hÃ¬nh nÃ y:

    ![CartPole khÃ´ng giá»¯ thÄƒng báº±ng](../../../../8-Reinforcement/2-Gym/images/cartpole-nobalance.gif)

1. Trong quÃ¡ trÃ¬nh mÃ´ phá»ng, chÃºng ta cáº§n nháº­n cÃ¡c quan sÃ¡t Ä‘á»ƒ quyáº¿t Ä‘á»‹nh cÃ¡ch hÃ nh Ä‘á»™ng. Thá»±c táº¿, hÃ m bÆ°á»›c tráº£ vá» cÃ¡c quan sÃ¡t hiá»‡n táº¡i, má»™t hÃ m thÆ°á»Ÿng, vÃ  cá» `done` cho biáº¿t liá»‡u cÃ³ nÃªn tiáº¿p tá»¥c mÃ´ phá»ng hay khÃ´ng: (mÃ£ khá»‘i 4)

    ```python
    env.reset()
    
    done = False
    while not done:
       env.render()
       obs, rew, done, info = env.step(env.action_space.sample())
       print(f"{obs} -> {rew}")
    env.close()
    ```

    Báº¡n sáº½ tháº¥y káº¿t quáº£ tÆ°Æ¡ng tá»± nhÆ° tháº¿ nÃ y trong Ä‘áº§u ra cá»§a notebook:

    ```text
    [ 0.03403272 -0.24301182  0.02669811  0.2895829 ] -> 1.0
    [ 0.02917248 -0.04828055  0.03248977  0.00543839] -> 1.0
    [ 0.02820687  0.14636075  0.03259854 -0.27681916] -> 1.0
    [ 0.03113408  0.34100283  0.02706215 -0.55904489] -> 1.0
    [ 0.03795414  0.53573468  0.01588125 -0.84308041] -> 1.0
    ...
    [ 0.17299878  0.15868546 -0.20754175 -0.55975453] -> 1.0
    [ 0.17617249  0.35602306 -0.21873684 -0.90998894] -> 1.0
    ```

    Vector quan sÃ¡t Ä‘Æ°á»£c tráº£ vá» táº¡i má»—i bÆ°á»›c cá»§a mÃ´ phá»ng chá»©a cÃ¡c giÃ¡ trá»‹ sau:
    - Vá»‹ trÃ­ cá»§a xe Ä‘áº©y
    - Váº­n tá»‘c cá»§a xe Ä‘áº©y
    - GÃ³c cá»§a cÃ¢y cá»™t
    - Tá»‘c Ä‘á»™ quay cá»§a cÃ¢y cá»™t

1. Láº¥y giÃ¡ trá»‹ nhá» nháº¥t vÃ  lá»›n nháº¥t cá»§a cÃ¡c sá»‘ nÃ y: (mÃ£ khá»‘i 5)

    ```python
    print(env.observation_space.low)
    print(env.observation_space.high)
    ```

    Báº¡n cÅ©ng cÃ³ thá»ƒ nháº­n tháº¥y ráº±ng giÃ¡ trá»‹ thÆ°á»Ÿng táº¡i má»—i bÆ°á»›c mÃ´ phá»ng luÃ´n lÃ  1. Äiá»u nÃ y lÃ  vÃ¬ má»¥c tiÃªu cá»§a chÃºng ta lÃ  tá»“n táº¡i lÃ¢u nháº¥t cÃ³ thá»ƒ, tá»©c lÃ  giá»¯ cÃ¢y cá»™t á»Ÿ vá»‹ trÃ­ tháº³ng Ä‘á»©ng há»£p lÃ½ trong thá»i gian dÃ i nháº¥t.

    âœ… Thá»±c táº¿, mÃ´ phá»ng CartPole Ä‘Æ°á»£c coi lÃ  Ä‘Ã£ giáº£i quyáº¿t náº¿u chÃºng ta Ä‘áº¡t Ä‘Æ°á»£c pháº§n thÆ°á»Ÿng trung bÃ¬nh lÃ  195 trong 100 láº§n thá»­ liÃªn tiáº¿p.

## Rá»i ráº¡c hÃ³a tráº¡ng thÃ¡i

Trong Q-Learning, chÃºng ta cáº§n xÃ¢y dá»±ng Q-Table Ä‘á»ƒ xÃ¡c Ä‘á»‹nh hÃ nh Ä‘á»™ng táº¡i má»—i tráº¡ng thÃ¡i. Äá»ƒ lÃ m Ä‘Æ°á»£c Ä‘iá»u nÃ y, tráº¡ng thÃ¡i cáº§n pháº£i **rá»i ráº¡c**, cá»¥ thá»ƒ hÆ¡n, nÃ³ pháº£i chá»©a má»™t sá»‘ lÆ°á»£ng há»¯u háº¡n cÃ¡c giÃ¡ trá»‹ rá»i ráº¡c. VÃ¬ váº­y, chÃºng ta cáº§n **rá»i ráº¡c hÃ³a** cÃ¡c quan sÃ¡t, Ã¡nh xáº¡ chÃºng thÃ nh má»™t táº­p há»£p há»¯u háº¡n cÃ¡c tráº¡ng thÃ¡i.

CÃ³ má»™t vÃ i cÃ¡ch Ä‘á»ƒ lÃ m Ä‘iá»u nÃ y:

- **Chia thÃ nh cÃ¡c khoáº£ng**. Náº¿u chÃºng ta biáº¿t khoáº£ng cá»§a má»™t giÃ¡ trá»‹ nháº¥t Ä‘á»‹nh, chÃºng ta cÃ³ thá»ƒ chia khoáº£ng nÃ y thÃ nh má»™t sá»‘ **khoáº£ng nhá»**, vÃ  sau Ä‘Ã³ thay tháº¿ giÃ¡ trá»‹ báº±ng sá»‘ thá»© tá»± cá»§a khoáº£ng mÃ  nÃ³ thuá»™c vá». Äiá»u nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c thá»±c hiá»‡n báº±ng phÆ°Æ¡ng phÃ¡p [`digitize`](https://numpy.org/doc/stable/reference/generated/numpy.digitize.html) cá»§a numpy. Trong trÆ°á»ng há»£p nÃ y, chÃºng ta sáº½ biáº¿t chÃ­nh xÃ¡c kÃ­ch thÆ°á»›c tráº¡ng thÃ¡i, vÃ¬ nÃ³ sáº½ phá»¥ thuá»™c vÃ o sá»‘ lÆ°á»£ng khoáº£ng mÃ  chÃºng ta chá»n Ä‘á»ƒ sá»‘ hÃ³a.

âœ… ChÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng ná»™i suy tuyáº¿n tÃ­nh Ä‘á»ƒ Ä‘Æ°a cÃ¡c giÃ¡ trá»‹ vá» má»™t khoáº£ng há»¯u háº¡n (vÃ­ dá»¥, tá»« -20 Ä‘áº¿n 20), vÃ  sau Ä‘Ã³ chuyá»ƒn Ä‘á»•i cÃ¡c sá»‘ thÃ nh sá»‘ nguyÃªn báº±ng cÃ¡ch lÃ m trÃ²n. Äiá»u nÃ y cho chÃºng ta Ã­t kiá»ƒm soÃ¡t hÆ¡n vá» kÃ­ch thÆ°á»›c cá»§a tráº¡ng thÃ¡i, Ä‘áº·c biá»‡t náº¿u chÃºng ta khÃ´ng biáº¿t chÃ­nh xÃ¡c pháº¡m vi cá»§a cÃ¡c giÃ¡ trá»‹ Ä‘áº§u vÃ o. VÃ­ dá»¥, trong trÆ°á»ng há»£p cá»§a chÃºng ta, 2 trong sá»‘ 4 giÃ¡ trá»‹ khÃ´ng cÃ³ giá»›i háº¡n trÃªn/dÆ°á»›i, Ä‘iá»u nÃ y cÃ³ thá»ƒ dáº«n Ä‘áº¿n sá»‘ lÆ°á»£ng tráº¡ng thÃ¡i vÃ´ háº¡n.

Trong vÃ­ dá»¥ cá»§a chÃºng ta, chÃºng ta sáº½ sá»­ dá»¥ng cÃ¡ch tiáº¿p cáº­n thá»© hai. NhÆ° báº¡n cÃ³ thá»ƒ nháº­n tháº¥y sau nÃ y, máº·c dÃ¹ khÃ´ng cÃ³ giá»›i háº¡n trÃªn/dÆ°á»›i, nhá»¯ng giÃ¡ trá»‹ nÃ y hiáº¿m khi vÆ°á»£t ra ngoÃ i má»™t khoáº£ng há»¯u háº¡n nháº¥t Ä‘á»‹nh, do Ä‘Ã³ nhá»¯ng tráº¡ng thÃ¡i vá»›i giÃ¡ trá»‹ cá»±c Ä‘oan sáº½ ráº¥t hiáº¿m.

1. ÄÃ¢y lÃ  hÃ m sáº½ láº¥y quan sÃ¡t tá»« mÃ´ hÃ¬nh cá»§a chÃºng ta vÃ  táº¡o ra má»™t bá»™ giÃ¡ trá»‹ nguyÃªn gá»“m 4 giÃ¡ trá»‹: (mÃ£ khá»‘i 6)

    ```python
    def discretize(x):
        return tuple((x/np.array([0.25, 0.25, 0.01, 0.1])).astype(np.int))
    ```

1. HÃ£y khÃ¡m phÃ¡ má»™t phÆ°Æ¡ng phÃ¡p rá»i ráº¡c hÃ³a khÃ¡c sá»­ dá»¥ng cÃ¡c khoáº£ng: (mÃ£ khá»‘i 7)

    ```python
    def create_bins(i,num):
        return np.arange(num+1)*(i[1]-i[0])/num+i[0]
    
    print("Sample bins for interval (-5,5) with 10 bins\n",create_bins((-5,5),10))
    
    ints = [(-5,5),(-2,2),(-0.5,0.5),(-2,2)] # intervals of values for each parameter
    nbins = [20,20,10,10] # number of bins for each parameter
    bins = [create_bins(ints[i],nbins[i]) for i in range(4)]
    
    def discretize_bins(x):
        return tuple(np.digitize(x[i],bins[i]) for i in range(4))
    ```

1. BÃ¢y giá» hÃ£y cháº¡y má»™t mÃ´ phá»ng ngáº¯n vÃ  quan sÃ¡t cÃ¡c giÃ¡ trá»‹ mÃ´i trÆ°á»ng rá»i ráº¡c. HÃ£y thá»­ cáº£ `discretize` vÃ  `discretize_bins` Ä‘á»ƒ xem cÃ³ sá»± khÃ¡c biá»‡t nÃ o khÃ´ng.

    âœ… `discretize_bins` tráº£ vá» sá»‘ thá»© tá»± cá»§a khoáº£ng, báº¯t Ä‘áº§u tá»« 0. VÃ¬ váº­y, Ä‘á»‘i vá»›i cÃ¡c giÃ¡ trá»‹ cá»§a biáº¿n Ä‘áº§u vÃ o xung quanh 0, nÃ³ tráº£ vá» sá»‘ tá»« giá»¯a khoáº£ng (10). Trong `discretize`, chÃºng ta khÃ´ng quan tÃ¢m Ä‘áº¿n pháº¡m vi cá»§a cÃ¡c giÃ¡ trá»‹ Ä‘áº§u ra, cho phÃ©p chÃºng lÃ  sá»‘ Ã¢m, do Ä‘Ã³ cÃ¡c giÃ¡ trá»‹ tráº¡ng thÃ¡i khÃ´ng bá»‹ dá»‹ch chuyá»ƒn, vÃ  0 tÆ°Æ¡ng á»©ng vá»›i 0. (mÃ£ khá»‘i 8)

    ```python
    env.reset()
    
    done = False
    while not done:
       #env.render()
       obs, rew, done, info = env.step(env.action_space.sample())
       #print(discretize_bins(obs))
       print(discretize(obs))
    env.close()
    ```

    âœ… Bá» chÃº thÃ­ch dÃ²ng báº¯t Ä‘áº§u báº±ng `env.render` náº¿u báº¡n muá»‘n xem cÃ¡ch mÃ´i trÆ°á»ng thá»±c thi. Náº¿u khÃ´ng, báº¡n cÃ³ thá»ƒ thá»±c thi nÃ³ trong ná»n, Ä‘iá»u nÃ y nhanh hÆ¡n. ChÃºng ta sáº½ sá»­ dá»¥ng cÃ¡ch thá»±c thi "áº©n" nÃ y trong quÃ¡ trÃ¬nh Q-Learning.

## Cáº¥u trÃºc Q-Table

Trong bÃ i há»c trÆ°á»›c, tráº¡ng thÃ¡i lÃ  má»™t cáº·p sá»‘ Ä‘Æ¡n giáº£n tá»« 0 Ä‘áº¿n 8, vÃ  do Ä‘Ã³ ráº¥t tiá»‡n lá»£i Ä‘á»ƒ biá»ƒu diá»…n Q-Table báº±ng má»™t tensor numpy vá»›i kÃ­ch thÆ°á»›c 8x8x2. Náº¿u chÃºng ta sá»­ dá»¥ng rá»i ráº¡c hÃ³a báº±ng khoáº£ng, kÃ­ch thÆ°á»›c cá»§a vector tráº¡ng thÃ¡i cÅ©ng Ä‘Æ°á»£c biáº¿t, vÃ¬ váº­y chÃºng ta cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡ch tiáº¿p cáº­n tÆ°Æ¡ng tá»± vÃ  biá»ƒu diá»…n tráº¡ng thÃ¡i báº±ng má»™t máº£ng cÃ³ kÃ­ch thÆ°á»›c 20x20x10x10x2 (á»Ÿ Ä‘Ã¢y 2 lÃ  kÃ­ch thÆ°á»›c cá»§a khÃ´ng gian hÃ nh Ä‘á»™ng, vÃ  cÃ¡c kÃ­ch thÆ°á»›c Ä‘áº§u tiÃªn tÆ°Æ¡ng á»©ng vá»›i sá»‘ lÆ°á»£ng khoáº£ng mÃ  chÃºng ta Ä‘Ã£ chá»n Ä‘á»ƒ sá»­ dá»¥ng cho má»—i tham sá»‘ trong khÃ´ng gian quan sÃ¡t).

Tuy nhiÃªn, Ä‘Ã´i khi kÃ­ch thÆ°á»›c chÃ­nh xÃ¡c cá»§a khÃ´ng gian quan sÃ¡t khÃ´ng Ä‘Æ°á»£c biáº¿t. Trong trÆ°á»ng há»£p cá»§a hÃ m `discretize`, chÃºng ta cÃ³ thá»ƒ khÃ´ng bao giá» cháº¯c cháº¯n ráº±ng tráº¡ng thÃ¡i cá»§a chÃºng ta náº±m trong má»™t giá»›i háº¡n nháº¥t Ä‘á»‹nh, vÃ¬ má»™t sá»‘ giÃ¡ trá»‹ ban Ä‘áº§u khÃ´ng bá»‹ giá»›i háº¡n. Do Ä‘Ã³, chÃºng ta sáº½ sá»­ dá»¥ng má»™t cÃ¡ch tiáº¿p cáº­n hÆ¡i khÃ¡c vÃ  biá»ƒu diá»…n Q-Table báº±ng má»™t tá»« Ä‘iá»ƒn.

1. Sá»­ dá»¥ng cáº·p *(state,action)* lÃ m khÃ³a cá»§a tá»« Ä‘iá»ƒn, vÃ  giÃ¡ trá»‹ sáº½ tÆ°Æ¡ng á»©ng vá»›i giÃ¡ trá»‹ cá»§a má»¥c trong Q-Table. (mÃ£ khá»‘i 9)

    ```python
    Q = {}
    actions = (0,1)
    
    def qvalues(state):
        return [Q.get((state,a),0) for a in actions]
    ```

    á» Ä‘Ã¢y chÃºng ta cÅ©ng Ä‘á»‹nh nghÄ©a má»™t hÃ m `qvalues()`, tráº£ vá» danh sÃ¡ch cÃ¡c giÃ¡ trá»‹ Q-Table cho má»™t tráº¡ng thÃ¡i nháº¥t Ä‘á»‹nh tÆ°Æ¡ng á»©ng vá»›i táº¥t cáº£ cÃ¡c hÃ nh Ä‘á»™ng cÃ³ thá»ƒ. Náº¿u má»¥c khÃ´ng cÃ³ trong Q-Table, chÃºng ta sáº½ tráº£ vá» 0 lÃ m giÃ¡ trá»‹ máº·c Ä‘á»‹nh.

## Báº¯t Ä‘áº§u Q-Learning

BÃ¢y giá» chÃºng ta Ä‘Ã£ sáºµn sÃ ng Ä‘á»ƒ dáº¡y Peter cÃ¡ch giá»¯ thÄƒng báº±ng!

1. Äáº§u tiÃªn, hÃ£y Ä‘áº·t má»™t sá»‘ siÃªu tham sá»‘: (mÃ£ khá»‘i 10)

    ```python
    # hyperparameters
    alpha = 0.3
    gamma = 0.9
    epsilon = 0.90
    ```

    á» Ä‘Ã¢y, `alpha` lÃ  **tá»‘c Ä‘á»™ há»c** xÃ¡c Ä‘á»‹nh má»©c Ä‘á»™ chÃºng ta nÃªn Ä‘iá»u chá»‰nh cÃ¡c giÃ¡ trá»‹ hiá»‡n táº¡i cá»§a Q-Table táº¡i má»—i bÆ°á»›c. Trong bÃ i há»c trÆ°á»›c, chÃºng ta báº¯t Ä‘áº§u vá»›i giÃ¡ trá»‹ 1, vÃ  sau Ä‘Ã³ giáº£m `alpha` xuá»‘ng cÃ¡c giÃ¡ trá»‹ tháº¥p hÆ¡n trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n. Trong vÃ­ dá»¥ nÃ y, chÃºng ta sáº½ giá»¯ nÃ³ cá»‘ Ä‘á»‹nh chá»‰ Ä‘á»ƒ Ä‘Æ¡n giáº£n, vÃ  báº¡n cÃ³ thá»ƒ thá»­ nghiá»‡m vá»›i viá»‡c Ä‘iá»u chá»‰nh giÃ¡ trá»‹ `alpha` sau.

    `gamma` lÃ  **há»‡ sá»‘ chiáº¿t kháº¥u** cho biáº¿t má»©c Ä‘á»™ chÃºng ta nÃªn Æ°u tiÃªn pháº§n thÆ°á»Ÿng trong tÆ°Æ¡ng lai so vá»›i pháº§n thÆ°á»Ÿng hiá»‡n táº¡i.

    `epsilon` lÃ  **yáº¿u tá»‘ khÃ¡m phÃ¡/khai thÃ¡c** xÃ¡c Ä‘á»‹nh liá»‡u chÃºng ta nÃªn Æ°u tiÃªn khÃ¡m phÃ¡ hay khai thÃ¡c. Trong thuáº­t toÃ¡n cá»§a chÃºng ta, chÃºng ta sáº½ chá»n hÃ nh Ä‘á»™ng tiáº¿p theo theo giÃ¡ trá»‹ Q-Table trong `epsilon` pháº§n trÄƒm trÆ°á»ng há»£p, vÃ  trong sá»‘ trÆ°á»ng há»£p cÃ²n láº¡i, chÃºng ta sáº½ thá»±c hiá»‡n má»™t hÃ nh Ä‘á»™ng ngáº«u nhiÃªn. Äiá»u nÃ y sáº½ cho phÃ©p chÃºng ta khÃ¡m phÃ¡ cÃ¡c khu vá»±c cá»§a khÃ´ng gian tÃ¬m kiáº¿m mÃ  chÃºng ta chÆ°a tá»«ng tháº¥y trÆ°á»›c Ä‘Ã¢y.

    âœ… Vá» máº·t giá»¯ thÄƒng báº±ng - chá»n hÃ nh Ä‘á»™ng ngáº«u nhiÃªn (khÃ¡m phÃ¡) sáº½ giá»‘ng nhÆ° má»™t cÃº Ä‘áº©y ngáº«u nhiÃªn sai hÆ°á»›ng, vÃ  cÃ¢y cá»™t sáº½ pháº£i há»c cÃ¡ch phá»¥c há»“i thÄƒng báº±ng tá»« nhá»¯ng "sai láº§m" Ä‘Ã³.

### Cáº£i thiá»‡n thuáº­t toÃ¡n

ChÃºng ta cÅ©ng cÃ³ thá»ƒ thá»±c hiá»‡n hai cáº£i tiáº¿n cho thuáº­t toÃ¡n tá»« bÃ i há»c trÆ°á»›c:

- **TÃ­nh pháº§n thÆ°á»Ÿng tÃ­ch lÅ©y trung bÃ¬nh**, qua má»™t sá»‘ láº§n mÃ´ phá»ng. ChÃºng ta sáº½ in tiáº¿n trÃ¬nh má»—i 5000 láº§n láº·p, vÃ  chÃºng ta sáº½ tÃ­nh trung bÃ¬nh pháº§n thÆ°á»Ÿng tÃ­ch lÅ©y qua khoáº£ng thá»i gian Ä‘Ã³. Äiá»u nÃ y cÃ³ nghÄ©a lÃ  náº¿u chÃºng ta Ä‘áº¡t Ä‘Æ°á»£c hÆ¡n 195 Ä‘iá»ƒm - chÃºng ta cÃ³ thá»ƒ coi bÃ i toÃ¡n Ä‘Ã£ Ä‘Æ°á»£c giáº£i quyáº¿t, vá»›i cháº¥t lÆ°á»£ng tháº­m chÃ­ cao hÆ¡n yÃªu cáº§u.

- **TÃ­nh káº¿t quáº£ tÃ­ch lÅ©y trung bÃ¬nh tá»‘i Ä‘a**, `Qmax`, vÃ  chÃºng ta sáº½ lÆ°u trá»¯ Q-Table tÆ°Æ¡ng á»©ng vá»›i káº¿t quáº£ Ä‘Ã³. Khi báº¡n cháº¡y quÃ¡ trÃ¬nh huáº¥n luyá»‡n, báº¡n sáº½ nháº­n tháº¥y ráº±ng Ä‘Ã´i khi káº¿t quáº£ tÃ­ch lÅ©y trung bÃ¬nh báº¯t Ä‘áº§u giáº£m, vÃ  chÃºng ta muá»‘n giá»¯ láº¡i cÃ¡c giÃ¡ trá»‹ cá»§a Q-Table tÆ°Æ¡ng á»©ng vá»›i mÃ´ hÃ¬nh tá»‘t nháº¥t Ä‘Æ°á»£c quan sÃ¡t trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n.

1. Thu tháº­p táº¥t cáº£ pháº§n thÆ°á»Ÿng tÃ­ch lÅ©y táº¡i má»—i láº§n mÃ´ phá»ng vÃ o vector `rewards` Ä‘á»ƒ váº½ biá»ƒu Ä‘á»“ sau nÃ y. (mÃ£ khá»‘i 11)

    ```python
    def probs(v,eps=1e-4):
        v = v-v.min()+eps
        v = v/v.sum()
        return v
    
    Qmax = 0
    cum_rewards = []
    rewards = []
    for epoch in range(100000):
        obs = env.reset()
        done = False
        cum_reward=0
        # == do the simulation ==
        while not done:
            s = discretize(obs)
            if random.random()<epsilon:
                # exploitation - chose the action according to Q-Table probabilities
                v = probs(np.array(qvalues(s)))
                a = random.choices(actions,weights=v)[0]
            else:
                # exploration - randomly chose the action
                a = np.random.randint(env.action_space.n)
    
            obs, rew, done, info = env.step(a)
            cum_reward+=rew
            ns = discretize(obs)
            Q[(s,a)] = (1 - alpha) * Q.get((s,a),0) + alpha * (rew + gamma * max(qvalues(ns)))
        cum_rewards.append(cum_reward)
        rewards.append(cum_reward)
        # == Periodically print results and calculate average reward ==
        if epoch%5000==0:
            print(f"{epoch}: {np.average(cum_rewards)}, alpha={alpha}, epsilon={epsilon}")
            if np.average(cum_rewards) > Qmax:
                Qmax = np.average(cum_rewards)
                Qbest = Q
            cum_rewards=[]
    ```

Nhá»¯ng gÃ¬ báº¡n cÃ³ thá»ƒ nháº­n tháº¥y tá»« cÃ¡c káº¿t quáº£ nÃ y:

- **Gáº§n Ä‘áº¡t má»¥c tiÃªu**. ChÃºng ta ráº¥t gáº§n Ä‘áº¡t Ä‘Æ°á»£c má»¥c tiÃªu lÃ  Ä‘áº¡t 195 pháº§n thÆ°á»Ÿng tÃ­ch lÅ©y qua hÆ¡n 100 láº§n cháº¡y liÃªn tiáº¿p cá»§a mÃ´ phá»ng, hoáº·c chÃºng ta cÃ³ thá»ƒ Ä‘Ã£ Ä‘áº¡t Ä‘Æ°á»£c nÃ³! Ngay cáº£ khi chÃºng ta Ä‘áº¡t Ä‘Æ°á»£c cÃ¡c sá»‘ nhá» hÆ¡n, chÃºng ta váº«n khÃ´ng biáº¿t, vÃ¬ chÃºng ta tÃ­nh trung bÃ¬nh qua 5000 láº§n cháº¡y, vÃ  chá»‰ cáº§n 100 láº§n cháº¡y lÃ  Ä‘á»§ theo tiÃªu chÃ­ chÃ­nh thá»©c.

- **Pháº§n thÆ°á»Ÿng báº¯t Ä‘áº§u giáº£m**. ÄÃ´i khi pháº§n thÆ°á»Ÿng báº¯t Ä‘áº§u giáº£m, Ä‘iá»u nÃ y cÃ³ nghÄ©a lÃ  chÃºng ta cÃ³ thá»ƒ "phÃ¡ há»§y" cÃ¡c giÃ¡ trá»‹ Ä‘Ã£ há»c trong Q-Table báº±ng cÃ¡c giÃ¡ trá»‹ lÃ m tÃ¬nh hÃ¬nh trá»Ÿ nÃªn tá»‡ hÆ¡n.

Quan sÃ¡t nÃ y rÃµ rÃ ng hÆ¡n náº¿u chÃºng ta váº½ biá»ƒu Ä‘á»“ tiáº¿n trÃ¬nh huáº¥n luyá»‡n.

## Váº½ biá»ƒu Ä‘á»“ tiáº¿n trÃ¬nh huáº¥n luyá»‡n

Trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, chÃºng ta Ä‘Ã£ thu tháº­p giÃ¡ trá»‹ pháº§n thÆ°á»Ÿng tÃ­ch lÅ©y táº¡i má»—i láº§n láº·p vÃ o vector `rewards`. ÄÃ¢y lÃ  cÃ¡ch nÃ³ trÃ´ng khi chÃºng ta váº½ biá»ƒu Ä‘á»“ so vá»›i sá»‘ láº§n láº·p:

```python
plt.plot(rewards)
```

![Tiáº¿n trÃ¬nh thÃ´](../../../../8-Reinforcement/2-Gym/images/train_progress_raw.png)

Tá»« biá»ƒu Ä‘á»“ nÃ y, khÃ´ng thá»ƒ nÃ³i Ä‘Æ°á»£c Ä‘iá»u gÃ¬, vÃ¬ do báº£n cháº¥t cá»§a quÃ¡ trÃ¬nh huáº¥n luyá»‡n ngáº«u nhiÃªn, Ä‘á»™ dÃ i cá»§a cÃ¡c phiÃªn huáº¥n luyá»‡n thay Ä‘á»•i ráº¥t nhiá»u. Äá»ƒ lÃ m cho biá»ƒu Ä‘á»“ nÃ y cÃ³ Ã½ nghÄ©a hÆ¡n, chÃºng ta cÃ³ thá»ƒ tÃ­nh **trung bÃ¬nh cháº¡y** qua má»™t loáº¡t cÃ¡c thÃ­ nghiá»‡m, giáº£ sá»­ lÃ  100. Äiá»u nÃ y cÃ³ thá»ƒ Ä‘Æ°á»£c thá»±c hiá»‡n má»™t cÃ¡ch thuáº­n tiá»‡n báº±ng cÃ¡ch sá»­ dá»¥ng `np.convolve`: (mÃ£ khá»‘i 12)

```python
def running_average(x,window):
    return np.convolve(x,np.ones(window)/window,mode='valid')

plt.plot(running_average(rewards,100))
```

![Tiáº¿n trÃ¬nh huáº¥n luyá»‡n](../../../../8-Reinforcement/2-Gym/images/train_progress_runav.png)

## Thay Ä‘á»•i siÃªu tham sá»‘

Äá»ƒ lÃ m cho viá»‡c há»c á»•n Ä‘á»‹nh hÆ¡n, cÃ³ Ã½ nghÄ©a khi Ä‘iá»u chá»‰nh má»™t sá»‘ siÃªu tham sá»‘ cá»§a chÃºng ta trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n. Cá»¥ thá»ƒ:

- **Äá»‘i vá»›i tá»‘c Ä‘á»™ há»c**, `alpha`, chÃºng ta cÃ³ thá»ƒ báº¯t Ä‘áº§u vá»›i cÃ¡c giÃ¡ trá»‹ gáº§n 1, vÃ  sau Ä‘Ã³ tiáº¿p tá»¥c giáº£m tham sá»‘ nÃ y. Theo thá»i gian, chÃºng ta sáº½ nháº­n Ä‘Æ°á»£c cÃ¡c giÃ¡ trá»‹ xÃ¡c suáº¥t tá»‘t trong Q-Table, vÃ  do Ä‘Ã³ chÃºng ta nÃªn Ä‘iá»u chá»‰nh chÃºng má»™t cÃ¡ch nháº¹ nhÃ ng, thay vÃ¬ ghi Ä‘Ã¨ hoÃ n toÃ n báº±ng cÃ¡c giÃ¡ trá»‹ má»›i.

- **TÄƒng epsilon**. ChÃºng ta cÃ³ thá»ƒ muá»‘n tÄƒng `epsilon` tá»« tá»«, Ä‘á»ƒ khÃ¡m phÃ¡ Ã­t hÆ¡n vÃ  khai thÃ¡c nhiá»u hÆ¡n. CÃ³ láº½ há»£p lÃ½ khi báº¯t Ä‘áº§u vá»›i giÃ¡ trá»‹ tháº¥p cá»§a `epsilon`, vÃ  tÄƒng lÃªn gáº§n 1.
> **Nhiá»‡m vá»¥ 1**: Thá»­ thay Ä‘á»•i cÃ¡c giÃ¡ trá»‹ siÃªu tham sá»‘ vÃ  xem liá»‡u báº¡n cÃ³ thá»ƒ Ä‘áº¡t Ä‘Æ°á»£c tá»•ng pháº§n thÆ°á»Ÿng cao hÆ¡n khÃ´ng. Báº¡n cÃ³ Ä‘áº¡t trÃªn 195 khÃ´ng?
> **Nhiá»‡m vá»¥ 2**: Äá»ƒ giáº£i quyáº¿t váº¥n Ä‘á» má»™t cÃ¡ch chÃ­nh thá»©c, báº¡n cáº§n Ä‘áº¡t Ä‘Æ°á»£c má»©c thÆ°á»Ÿng trung bÃ¬nh 195 qua 100 láº§n cháº¡y liÃªn tiáº¿p. Äo lÆ°á»ng Ä‘iá»u nÃ y trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n vÃ  Ä‘áº£m báº£o ráº±ng báº¡n Ä‘Ã£ giáº£i quyáº¿t váº¥n Ä‘á» má»™t cÃ¡ch chÃ­nh thá»©c!

## Xem káº¿t quáº£ hoáº¡t Ä‘á»™ng

Sáº½ ráº¥t thÃº vá»‹ khi thá»±c sá»± tháº¥y mÃ´ hÃ¬nh Ä‘Ã£ huáº¥n luyá»‡n hoáº¡t Ä‘á»™ng nhÆ° tháº¿ nÃ o. HÃ£y cháº¡y mÃ´ phá»ng vÃ  Ã¡p dá»¥ng chiáº¿n lÆ°á»£c chá»n hÃ nh Ä‘á»™ng giá»‘ng nhÆ° trong quÃ¡ trÃ¬nh huáº¥n luyá»‡n, báº±ng cÃ¡ch láº¥y máº«u theo phÃ¢n phá»‘i xÃ¡c suáº¥t trong Q-Table: (khá»‘i mÃ£ 13)

```python
obs = env.reset()
done = False
while not done:
   s = discretize(obs)
   env.render()
   v = probs(np.array(qvalues(s)))
   a = random.choices(actions,weights=v)[0]
   obs,_,done,_ = env.step(a)
env.close()
```

Báº¡n sáº½ tháº¥y Ä‘iá»u gÃ¬ Ä‘Ã³ nhÆ° tháº¿ nÃ y:

![a balancing cartpole](../../../../8-Reinforcement/2-Gym/images/cartpole-balance.gif)

---

## ğŸš€Thá»­ thÃ¡ch

> **Nhiá»‡m vá»¥ 3**: á» Ä‘Ã¢y, chÃºng ta Ä‘ang sá»­ dá»¥ng báº£n sao cuá»‘i cÃ¹ng cá»§a Q-Table, nhÆ°ng cÃ³ thá»ƒ nÃ³ khÃ´ng pháº£i lÃ  báº£n tá»‘t nháº¥t. HÃ£y nhá»› ráº±ng chÃºng ta Ä‘Ã£ lÆ°u Q-Table cÃ³ hiá»‡u suáº¥t tá»‘t nháº¥t vÃ o biáº¿n `Qbest`! Thá»­ vÃ­ dá»¥ tÆ°Æ¡ng tá»± vá»›i Q-Table cÃ³ hiá»‡u suáº¥t tá»‘t nháº¥t báº±ng cÃ¡ch sao chÃ©p `Qbest` sang `Q` vÃ  xem liá»‡u báº¡n cÃ³ nháº­n tháº¥y sá»± khÃ¡c biá»‡t khÃ´ng.

> **Nhiá»‡m vá»¥ 4**: á» Ä‘Ã¢y chÃºng ta khÃ´ng chá»n hÃ nh Ä‘á»™ng tá»‘t nháº¥t á»Ÿ má»—i bÆ°á»›c, mÃ  thay vÃ o Ä‘Ã³ láº¥y máº«u theo phÃ¢n phá»‘i xÃ¡c suáº¥t tÆ°Æ¡ng á»©ng. Liá»‡u cÃ³ há»£p lÃ½ hÆ¡n khÃ´ng náº¿u luÃ´n chá»n hÃ nh Ä‘á»™ng tá»‘t nháº¥t, vá»›i giÃ¡ trá»‹ cao nháº¥t trong Q-Table? Äiá»u nÃ y cÃ³ thá»ƒ thá»±c hiá»‡n báº±ng cÃ¡ch sá»­ dá»¥ng hÃ m `np.argmax` Ä‘á»ƒ tÃ¬m sá»‘ hÃ nh Ä‘á»™ng tÆ°Æ¡ng á»©ng vá»›i giÃ¡ trá»‹ cao nháº¥t trong Q-Table. HÃ£y triá»ƒn khai chiáº¿n lÆ°á»£c nÃ y vÃ  xem liá»‡u nÃ³ cÃ³ cáº£i thiá»‡n kháº£ nÄƒng cÃ¢n báº±ng khÃ´ng.

## [CÃ¢u há»i sau bÃ i giáº£ng](https://ff-quizzes.netlify.app/en/ml/)

## BÃ i táº­p
[Huáº¥n luyá»‡n Mountain Car](assignment.md)

## Káº¿t luáº­n

ChÃºng ta Ä‘Ã£ há»c cÃ¡ch huáº¥n luyá»‡n cÃ¡c tÃ¡c nhÃ¢n Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ tá»‘t chá»‰ báº±ng cÃ¡ch cung cáº¥p cho chÃºng má»™t hÃ m thÆ°á»Ÿng Ä‘á»‹nh nghÄ©a tráº¡ng thÃ¡i mong muá»‘n cá»§a trÃ² chÆ¡i, vÃ  cho chÃºng cÆ¡ há»™i khÃ¡m phÃ¡ khÃ´ng gian tÃ¬m kiáº¿m má»™t cÃ¡ch thÃ´ng minh. ChÃºng ta Ä‘Ã£ Ã¡p dá»¥ng thÃ nh cÃ´ng thuáº­t toÃ¡n Q-Learning trong cÃ¡c trÆ°á»ng há»£p mÃ´i trÆ°á»ng rá»i ráº¡c vÃ  liÃªn tá»¥c, nhÆ°ng vá»›i cÃ¡c hÃ nh Ä‘á»™ng rá»i ráº¡c.

Äiá»u quan trá»ng lÃ  cÅ©ng cáº§n nghiÃªn cá»©u cÃ¡c tÃ¬nh huá»‘ng mÃ  tráº¡ng thÃ¡i hÃ nh Ä‘á»™ng cÅ©ng liÃªn tá»¥c, vÃ  khi khÃ´ng gian quan sÃ¡t phá»©c táº¡p hÆ¡n nhiá»u, cháº³ng háº¡n nhÆ° hÃ¬nh áº£nh tá»« mÃ n hÃ¬nh trÃ² chÆ¡i Atari. Trong nhá»¯ng váº¥n Ä‘á» nÃ y, chÃºng ta thÆ°á»ng cáº§n sá»­ dá»¥ng cÃ¡c ká»¹ thuáº­t há»c mÃ¡y máº¡nh máº½ hÆ¡n, cháº³ng háº¡n nhÆ° máº¡ng nÆ¡-ron, Ä‘á»ƒ Ä‘áº¡t Ä‘Æ°á»£c káº¿t quáº£ tá»‘t. Nhá»¯ng chá»§ Ä‘á» nÃ¢ng cao nÃ y sáº½ lÃ  ná»™i dung cá»§a khÃ³a há»c AI nÃ¢ng cao sáº¯p tá»›i cá»§a chÃºng ta.

---

**TuyÃªn bá»‘ miá»…n trá»« trÃ¡ch nhiá»‡m**:  
TÃ i liá»‡u nÃ y Ä‘Ã£ Ä‘Æ°á»£c dá»‹ch báº±ng dá»‹ch vá»¥ dá»‹ch thuáº­t AI [Co-op Translator](https://github.com/Azure/co-op-translator). Máº·c dÃ¹ chÃºng tÃ´i cá»‘ gáº¯ng Ä‘áº£m báº£o Ä‘á»™ chÃ­nh xÃ¡c, xin lÆ°u Ã½ ráº±ng cÃ¡c báº£n dá»‹ch tá»± Ä‘á»™ng cÃ³ thá»ƒ chá»©a lá»—i hoáº·c khÃ´ng chÃ­nh xÃ¡c. TÃ i liá»‡u gá»‘c báº±ng ngÃ´n ngá»¯ báº£n Ä‘á»‹a nÃªn Ä‘Æ°á»£c coi lÃ  nguá»“n thÃ´ng tin chÃ­nh thá»©c. Äá»‘i vá»›i cÃ¡c thÃ´ng tin quan trá»ng, nÃªn sá»­ dá»¥ng dá»‹ch vá»¥ dá»‹ch thuáº­t chuyÃªn nghiá»‡p tá»« con ngÆ°á»i. ChÃºng tÃ´i khÃ´ng chá»‹u trÃ¡ch nhiá»‡m cho báº¥t ká»³ sá»± hiá»ƒu láº§m hoáº·c diá»…n giáº£i sai nÃ o phÃ¡t sinh tá»« viá»‡c sá»­ dá»¥ng báº£n dá»‹ch nÃ y.