<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7cdd17338d9bbd7e2171c2cd462eb081",
  "translation_date": "2025-09-05T15:46:29+00:00",
  "source_file": "5-Clustering/2-K-Means/README.md",
  "language_code": "sk"
}
-->
# K-Means zhlukovanie

## [KvÃ­z pred prednÃ¡Å¡kou](https://ff-quizzes.netlify.app/en/ml/)

V tejto lekcii sa nauÄÃ­te, ako vytvÃ¡raÅ¥ zhluky pomocou Scikit-learn a datasetu nigÃ©rijskej hudby, ktorÃ½ ste importovali skÃ´r. Pokryjeme zÃ¡klady K-Means pre zhlukovanie. PamÃ¤tajte, Å¾e ako ste sa nauÄili v predchÃ¡dzajÃºcej lekcii, existuje mnoho spÃ´sobov, ako pracovaÅ¥ so zhlukmi, a metÃ³da, ktorÃº pouÅ¾ijete, zÃ¡visÃ­ od vaÅ¡ich dÃ¡t. SkÃºsime K-Means, pretoÅ¾e je to najbeÅ¾nejÅ¡ia technika zhlukovania. PoÄme na to!

Pojmy, o ktorÃ½ch sa dozviete:

- Silhouette skÃ³re
- MetÃ³da lakÅ¥a
- Inercia
- Variancia

## Ãšvod

[K-Means zhlukovanie](https://wikipedia.org/wiki/K-means_clustering) je metÃ³da odvodenÃ¡ z oblasti spracovania signÃ¡lov. PouÅ¾Ã­va sa na rozdelenie a rozÄlenenie skupÃ­n dÃ¡t do 'k' zhlukov pomocou sÃ©rie pozorovanÃ­. KaÅ¾dÃ© pozorovanie pracuje na zoskupenÃ­ danÃ©ho dÃ¡tovÃ©ho bodu najbliÅ¾Å¡ie k jeho najbliÅ¾Å¡iemu 'priemeru', alebo stredovÃ©mu bodu zhluku.

Zhluky je moÅ¾nÃ© vizualizovaÅ¥ ako [Voronoi diagramy](https://wikipedia.org/wiki/Voronoi_diagram), ktorÃ© zahÅ•ÅˆajÃº bod (alebo 'semienko') a jeho zodpovedajÃºcu oblasÅ¥.

![voronoi diagram](../../../../5-Clustering/2-K-Means/images/voronoi.png)

> Infografika od [Jen Looper](https://twitter.com/jenlooper)

Proces K-Means zhlukovania [prebieha v trojstupÅˆovom procese](https://scikit-learn.org/stable/modules/clustering.html#k-means):

1. Algoritmus vyberie k-poÄet stredovÃ½ch bodov vzorkovanÃ­m z datasetu. Potom cykluje:
    1. PriradÃ­ kaÅ¾dÃº vzorku k najbliÅ¾Å¡iemu centroidu.
    2. VytvorÃ­ novÃ© centroidy vypoÄÃ­tanÃ­m priemernej hodnoty vÅ¡etkÃ½ch vzoriek priradenÃ½ch k predchÃ¡dzajÃºcim centroidom.
    3. Potom vypoÄÃ­ta rozdiel medzi novÃ½mi a starÃ½mi centroidmi a opakuje, kÃ½m sa centroidy nestabilizujÃº.

Jednou nevÃ½hodou pouÅ¾Ã­vania K-Means je fakt, Å¾e budete musieÅ¥ urÄiÅ¥ 'k', teda poÄet centroidov. NaÅ¡Å¥astie metÃ³da 'lakÅ¥a' pomÃ¡ha odhadnÃºÅ¥ dobrÃº poÄiatoÄnÃº hodnotu pre 'k'. HneÄ si to vyskÃºÅ¡ate.

## Predpoklad

Budete pracovaÅ¥ v sÃºbore [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/2-K-Means/notebook.ipynb), ktorÃ½ obsahuje import dÃ¡t a predbeÅ¾nÃ© Äistenie, ktorÃ© ste vykonali v poslednej lekcii.

## CviÄenie - prÃ­prava

ZaÄnite tÃ½m, Å¾e sa znova pozriete na dÃ¡ta piesnÃ­.

1. Vytvorte boxplot, zavolanÃ­m `boxplot()` pre kaÅ¾dÃ½ stÄºpec:

    ```python
    plt.figure(figsize=(20,20), dpi=200)
    
    plt.subplot(4,3,1)
    sns.boxplot(x = 'popularity', data = df)
    
    plt.subplot(4,3,2)
    sns.boxplot(x = 'acousticness', data = df)
    
    plt.subplot(4,3,3)
    sns.boxplot(x = 'energy', data = df)
    
    plt.subplot(4,3,4)
    sns.boxplot(x = 'instrumentalness', data = df)
    
    plt.subplot(4,3,5)
    sns.boxplot(x = 'liveness', data = df)
    
    plt.subplot(4,3,6)
    sns.boxplot(x = 'loudness', data = df)
    
    plt.subplot(4,3,7)
    sns.boxplot(x = 'speechiness', data = df)
    
    plt.subplot(4,3,8)
    sns.boxplot(x = 'tempo', data = df)
    
    plt.subplot(4,3,9)
    sns.boxplot(x = 'time_signature', data = df)
    
    plt.subplot(4,3,10)
    sns.boxplot(x = 'danceability', data = df)
    
    plt.subplot(4,3,11)
    sns.boxplot(x = 'length', data = df)
    
    plt.subplot(4,3,12)
    sns.boxplot(x = 'release_date', data = df)
    ```

    Tieto dÃ¡ta sÃº trochu hluÄnÃ©: pozorovanÃ­m kaÅ¾dÃ©ho stÄºpca ako boxplotu mÃ´Å¾ete vidieÅ¥ odÄ¾ahlÃ© hodnoty.

    ![odÄ¾ahlÃ© hodnoty](../../../../5-Clustering/2-K-Means/images/boxplots.png)

MÃ´Å¾ete prejsÅ¥ dataset a odstrÃ¡niÅ¥ tieto odÄ¾ahlÃ© hodnoty, ale to by spravilo dÃ¡ta dosÅ¥ minimÃ¡lne.

1. ZatiaÄ¾ si vyberte, ktorÃ© stÄºpce pouÅ¾ijete pre vaÅ¡e cviÄenie zhlukovania. Vyberte tie s podobnÃ½mi rozsahmi a zakÃ³dujte stÄºpec `artist_top_genre` ako numerickÃ© dÃ¡ta:

    ```python
    from sklearn.preprocessing import LabelEncoder
    le = LabelEncoder()
    
    X = df.loc[:, ('artist_top_genre','popularity','danceability','acousticness','loudness','energy')]
    
    y = df['artist_top_genre']
    
    X['artist_top_genre'] = le.fit_transform(X['artist_top_genre'])
    
    y = le.transform(y)
    ```

1. Teraz musÃ­te vybraÅ¥, koÄ¾ko zhlukov chcete cieliÅ¥. Viete, Å¾e existujÃº 3 hudobnÃ© Å¾Ã¡nre, ktorÃ© sme vyÄlenili z datasetu, takÅ¾e skÃºsme 3:

    ```python
    from sklearn.cluster import KMeans
    
    nclusters = 3 
    seed = 0
    
    km = KMeans(n_clusters=nclusters, random_state=seed)
    km.fit(X)
    
    # Predict the cluster for each data point
    
    y_cluster_kmeans = km.predict(X)
    y_cluster_kmeans
    ```

VidÃ­te vytlaÄenÃ© pole s predpovedanÃ½mi zhlukmi (0, 1 alebo 2) pre kaÅ¾dÃ½ riadok dataframe.

1. PouÅ¾ite toto pole na vÃ½poÄet 'silhouette skÃ³re':

    ```python
    from sklearn import metrics
    score = metrics.silhouette_score(X, y_cluster_kmeans)
    score
    ```

## Silhouette skÃ³re

HÄ¾adajte silhouette skÃ³re bliÅ¾Å¡ie k 1. Toto skÃ³re sa pohybuje od -1 do 1, a ak je skÃ³re 1, zhluk je hustÃ½ a dobre oddelenÃ½ od ostatnÃ½ch zhlukov. Hodnota blÃ­zka 0 predstavuje prekrÃ½vajÃºce sa zhluky so vzorkami veÄ¾mi blÃ­zko rozhodovacej hranice susednÃ½ch zhlukov. [(Zdroj)](https://dzone.com/articles/kmeans-silhouette-score-explained-with-python-exam)

NaÅ¡e skÃ³re je **.53**, takÅ¾e je presne v strede. To naznaÄuje, Å¾e naÅ¡e dÃ¡ta nie sÃº obzvlÃ¡Å¡Å¥ vhodnÃ© pre tento typ zhlukovania, ale pokraÄujme.

### CviÄenie - vytvorte model

1. Importujte `KMeans` a zaÄnite proces zhlukovania.

    ```python
    from sklearn.cluster import KMeans
    wcss = []
    
    for i in range(1, 11):
        kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)
        kmeans.fit(X)
        wcss.append(kmeans.inertia_)
    
    ```

    Tu je niekoÄ¾ko ÄastÃ­, ktorÃ© si zaslÃºÅ¾ia vysvetlenie.

    > ğŸ“ range: Toto sÃº iterÃ¡cie procesu zhlukovania.

    > ğŸ“ random_state: "UrÄuje generovanie nÃ¡hodnÃ½ch ÄÃ­sel pre inicializÃ¡ciu centroidov." [Zdroj](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)

    > ğŸ“ WCSS: "sÃºÄet Å¡tvorcov v rÃ¡mci zhluku" meria Å¡tvorcovÃº priemernÃº vzdialenosÅ¥ vÅ¡etkÃ½ch bodov v rÃ¡mci zhluku od centroidu zhluku. [Zdroj](https://medium.com/@ODSC/unsupervised-learning-evaluating-clusters-bd47eed175ce).

    > ğŸ“ Inercia: Algoritmy K-Means sa snaÅ¾ia vybraÅ¥ centroidy tak, aby minimalizovali 'inerciu', "mieru toho, ako sÃº zhluky vnÃºtorne koherentnÃ©." [Zdroj](https://scikit-learn.org/stable/modules/clustering.html). Hodnota sa pridÃ¡va do premennej wcss pri kaÅ¾dej iterÃ¡cii.

    > ğŸ“ k-means++: V [Scikit-learn](https://scikit-learn.org/stable/modules/clustering.html#k-means) mÃ´Å¾ete pouÅ¾iÅ¥ optimalizÃ¡ciu 'k-means++', ktorÃ¡ "inicializuje centroidy tak, aby boli (zvyÄajne) vzdialenÃ© od seba, Äo vedie k pravdepodobne lepÅ¡Ã­m vÃ½sledkom ako nÃ¡hodnÃ¡ inicializÃ¡cia."

### MetÃ³da lakÅ¥a

PredtÃ½m ste predpokladali, Å¾e keÄÅ¾e ste cielili 3 hudobnÃ© Å¾Ã¡nre, mali by ste zvoliÅ¥ 3 zhluky. Ale je to tak?

1. PouÅ¾ite metÃ³du 'lakÅ¥a', aby ste si boli istÃ­.

    ```python
    plt.figure(figsize=(10,5))
    sns.lineplot(x=range(1, 11), y=wcss, marker='o', color='red')
    plt.title('Elbow')
    plt.xlabel('Number of clusters')
    plt.ylabel('WCSS')
    plt.show()
    ```

    PouÅ¾ite premennÃº `wcss`, ktorÃº ste vytvorili v predchÃ¡dzajÃºcom kroku, na vytvorenie grafu, ktorÃ½ ukazuje, kde je 'ohyb' v lakti, Äo naznaÄuje optimÃ¡lny poÄet zhlukov. MoÅ¾no je to **naozaj** 3!

    ![metÃ³da lakÅ¥a](../../../../5-Clustering/2-K-Means/images/elbow.png)

## CviÄenie - zobrazte zhluky

1. SkÃºste proces znova, tentoraz nastavte tri zhluky a zobrazte zhluky ako scatterplot:

    ```python
    from sklearn.cluster import KMeans
    kmeans = KMeans(n_clusters = 3)
    kmeans.fit(X)
    labels = kmeans.predict(X)
    plt.scatter(df['popularity'],df['danceability'],c = labels)
    plt.xlabel('popularity')
    plt.ylabel('danceability')
    plt.show()
    ```

1. Skontrolujte presnosÅ¥ modelu:

    ```python
    labels = kmeans.labels_
    
    correct_labels = sum(y == labels)
    
    print("Result: %d out of %d samples were correctly labeled." % (correct_labels, y.size))
    
    print('Accuracy score: {0:0.2f}'. format(correct_labels/float(y.size)))
    ```

    PresnosÅ¥ tohto modelu nie je veÄ¾mi dobrÃ¡ a tvar zhlukov vÃ¡m dÃ¡va nÃ¡znak preÄo.

    ![zhluky](../../../../5-Clustering/2-K-Means/images/clusters.png)

    Tieto dÃ¡ta sÃº prÃ­liÅ¡ nevyvÃ¡Å¾enÃ©, mÃ¡lo korelovanÃ© a medzi hodnotami stÄºpcov je prÃ­liÅ¡ veÄ¾kÃ¡ variancia na to, aby sa dobre zhlukovali. V skutoÄnosti sÃº zhluky, ktorÃ© sa tvoria, pravdepodobne silne ovplyvnenÃ© alebo skreslenÃ© tromi kategÃ³riami Å¾Ã¡nrov, ktorÃ© sme definovali vyÅ¡Å¡ie. To bol proces uÄenia!

    V dokumentÃ¡cii Scikit-learn mÃ´Å¾ete vidieÅ¥, Å¾e model ako tento, s nie veÄ¾mi dobre vyznaÄenÃ½mi zhlukmi, mÃ¡ problÃ©m s 'varianciou':

    ![problÃ©movÃ© modely](../../../../5-Clustering/2-K-Means/images/problems.png)
    > Infografika zo Scikit-learn

## Variancia

Variancia je definovanÃ¡ ako "priemer Å¡tvorcovÃ½ch rozdielov od priemeru" [(Zdroj)](https://www.mathsisfun.com/data/standard-deviation.html). V kontexte tohto problÃ©mu zhlukovania sa vzÅ¥ahuje na dÃ¡ta, kde ÄÃ­sla nÃ¡Å¡ho datasetu majÃº tendenciu odchÃ½liÅ¥ sa trochu prÃ­liÅ¡ od priemeru.

âœ… Toto je skvelÃ½ moment na zamyslenie sa nad vÅ¡etkÃ½mi spÃ´sobmi, ako by ste mohli tento problÃ©m opraviÅ¥. UpraviÅ¥ dÃ¡ta trochu viac? PouÅ¾iÅ¥ inÃ© stÄºpce? PouÅ¾iÅ¥ inÃ½ algoritmus? Tip: SkÃºste [Å¡kÃ¡lovaÅ¥ vaÅ¡e dÃ¡ta](https://www.mygreatlearning.com/blog/learning-data-science-with-k-means-clustering/) na ich normalizÃ¡ciu a otestovaÅ¥ inÃ© stÄºpce.

> SkÃºste tento '[kalkulÃ¡tor variancie](https://www.calculatorsoup.com/calculators/statistics/variance-calculator.php)', aby ste lepÅ¡ie pochopili tento koncept.

---

## ğŸš€VÃ½zva

StrÃ¡vte nejakÃ½ Äas s tÃ½mto notebookom, upravujte parametre. DokÃ¡Å¾ete zlepÅ¡iÅ¥ presnosÅ¥ modelu ÄistenÃ­m dÃ¡t (naprÃ­klad odstrÃ¡nenÃ­m odÄ¾ahlÃ½ch hodnÃ´t)? MÃ´Å¾ete pouÅ¾iÅ¥ vÃ¡hy na pridanie vÃ¤ÄÅ¡ej vÃ¡hy urÄitÃ½m vzorkÃ¡m dÃ¡t. ÄŒo eÅ¡te mÃ´Å¾ete urobiÅ¥ na vytvorenie lepÅ¡Ã­ch zhlukov?

Tip: SkÃºste Å¡kÃ¡lovaÅ¥ vaÅ¡e dÃ¡ta. V notebooku je komentovanÃ½ kÃ³d, ktorÃ½ pridÃ¡va Å¡tandardnÃ© Å¡kÃ¡lovanie, aby sa stÄºpce dÃ¡t viac podobali z hÄ¾adiska rozsahu. ZistÃ­te, Å¾e zatiaÄ¾ Äo silhouette skÃ³re klesÃ¡, 'ohyb' v grafe lakÅ¥a sa vyhladzuje. Je to preto, Å¾e ponechanie dÃ¡t neÅ¡kÃ¡lovanÃ½ch umoÅ¾Åˆuje dÃ¡tam s menÅ¡ou varianciou niesÅ¥ vÃ¤ÄÅ¡iu vÃ¡hu. PreÄÃ­tajte si o tomto problÃ©me [tu](https://stats.stackexchange.com/questions/21222/are-mean-normalization-and-feature-scaling-needed-for-k-means-clustering/21226#21226).

## [KvÃ­z po prednÃ¡Å¡ke](https://ff-quizzes.netlify.app/en/ml/)

## PrehÄ¾ad a samostatnÃ© Å¡tÃºdium

Pozrite sa na simulÃ¡tor K-Means [ako je tento](https://user.ceng.metu.edu.tr/~akifakkus/courses/ceng574/k-means/). MÃ´Å¾ete pouÅ¾iÅ¥ tento nÃ¡stroj na vizualizÃ¡ciu vzoriek dÃ¡tovÃ½ch bodov a urÄenie ich centroidov. MÃ´Å¾ete upraviÅ¥ nÃ¡hodnosÅ¥ dÃ¡t, poÄet zhlukov a poÄet centroidov. PomÃ¡ha vÃ¡m to zÃ­skaÅ¥ predstavu o tom, ako mÃ´Å¾u byÅ¥ dÃ¡ta zoskupenÃ©?

TieÅ¾ sa pozrite na [tento materiÃ¡l o K-Means](https://stanford.edu/~cpiech/cs221/handouts/kmeans.html) zo Stanfordu.

## Zadanie

[VyskÃºÅ¡ajte rÃ´zne metÃ³dy zhlukovania](assignment.md)

---

**Upozornenie**:  
Tento dokument bol preloÅ¾enÃ½ pomocou sluÅ¾by AI prekladu [Co-op Translator](https://github.com/Azure/co-op-translator). Hoci sa snaÅ¾Ã­me o presnosÅ¥, prosÃ­m, berte na vedomie, Å¾e automatizovanÃ© preklady mÃ´Å¾u obsahovaÅ¥ chyby alebo nepresnosti. PÃ´vodnÃ½ dokument v jeho pÃ´vodnom jazyku by mal byÅ¥ povaÅ¾ovanÃ½ za autoritatÃ­vny zdroj. Pre kritickÃ© informÃ¡cie sa odporÃºÄa profesionÃ¡lny Ä¾udskÃ½ preklad. Nie sme zodpovednÃ­ za akÃ©koÄ¾vek nedorozumenia alebo nesprÃ¡vne interpretÃ¡cie vyplÃ½vajÃºce z pouÅ¾itia tohto prekladu.