<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "482bccabe1df958496ea71a3667995cd",
  "translation_date": "2025-09-05T15:37:17+00:00",
  "source_file": "7-TimeSeries/3-SVR/README.md",
  "language_code": "sk"
}
-->
# Predpovedanie ƒçasov√Ωch radov pomocou Support Vector Regressor

V predch√°dzaj√∫cej lekcii ste sa nauƒçili pou≈æ√≠va≈• model ARIMA na predpovedanie ƒçasov√Ωch radov. Teraz sa pozrieme na model Support Vector Regressor, ktor√Ω je regresn√Ω model pou≈æ√≠van√Ω na predpovedanie spojit√Ωch √∫dajov.

## [Kv√≠z pred predn√°≈°kou](https://ff-quizzes.netlify.app/en/ml/) 

## √övod

V tejto lekcii objav√≠te ≈°pecifick√Ω sp√¥sob budovania modelov pomocou [**SVM**: **S**upport **V**ector **M**achine](https://en.wikipedia.org/wiki/Support-vector_machine) pre regresiu, alebo **SVR: Support Vector Regressor**. 

### SVR v kontexte ƒçasov√Ωch radov [^1]

Predt√Ωm, ne≈æ pochop√≠te v√Ωznam SVR pri predpovedan√≠ ƒçasov√Ωch radov, je d√¥le≈æit√© pozna≈• nasleduj√∫ce koncepty:

- **Regresia:** Technika uƒçenia s uƒçiteƒæom na predpovedanie spojit√Ωch hodn√¥t z dan√©ho s√∫boru vstupov. Ide o prisp√¥sobenie krivky (alebo ƒçiary) v priestore vlastnost√≠, ktor√° obsahuje maxim√°lny poƒçet d√°tov√Ωch bodov. [Kliknite sem](https://en.wikipedia.org/wiki/Regression_analysis) pre viac inform√°ci√≠.
- **Support Vector Machine (SVM):** Typ modelu strojov√©ho uƒçenia s uƒçiteƒæom pou≈æ√≠van√Ω na klasifik√°ciu, regresiu a detekciu odƒæahl√Ωch hodn√¥t. Model je hyperplocha v priestore vlastnost√≠, ktor√° v pr√≠pade klasifik√°cie funguje ako hranica a v pr√≠pade regresie ako najlep≈°ie prisp√¥soben√° ƒçiara. V SVM sa zvyƒçajne pou≈æ√≠va funkcia Kernel na transform√°ciu d√°tov√©ho s√∫boru do priestoru s vy≈°≈°√≠m poƒçtom dimenzi√≠, aby boli ƒæah≈°ie oddeliteƒæn√©. [Kliknite sem](https://en.wikipedia.org/wiki/Support-vector_machine) pre viac inform√°ci√≠ o SVM.
- **Support Vector Regressor (SVR):** Typ SVM, ktor√Ω hƒæad√° najlep≈°ie prisp√¥soben√∫ ƒçiaru (ktor√° je v pr√≠pade SVM hyperplocha) obsahuj√∫cu maxim√°lny poƒçet d√°tov√Ωch bodov.

### Preƒço SVR? [^1]

V poslednej lekcii ste sa nauƒçili o ARIMA, ƒço je veƒæmi √∫spe≈°n√° ≈°tatistick√° line√°rna met√≥da na predpovedanie ƒçasov√Ωch radov. Av≈°ak v mnoh√Ωch pr√≠padoch maj√∫ ƒçasov√© rady *nelinearitu*, ktor√∫ line√°rne modely nedok√°≈æu zachyti≈•. V tak√Ωchto pr√≠padoch schopnos≈• SVM zohƒæadni≈• nelinearitu v √∫dajoch pri regresn√Ωch √∫loh√°ch rob√≠ SVR √∫spe≈°n√Ωm pri predpovedan√≠ ƒçasov√Ωch radov.

## Cviƒçenie - vytvorenie modelu SVR

Prv√© kroky na pr√≠pravu √∫dajov s√∫ rovnak√© ako v predch√°dzaj√∫cej lekcii o [ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA). 

Otvorte prieƒçinok [_/working_](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/3-SVR/working) v tejto lekcii a n√°jdite s√∫bor [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/7-TimeSeries/3-SVR/working/notebook.ipynb). [^2]

1. Spustite notebook a importujte potrebn√© kni≈ænice: [^2]

   ```python
   import sys
   sys.path.append('../../')
   ```

   ```python
   import os
   import warnings
   import matplotlib.pyplot as plt
   import numpy as np
   import pandas as pd
   import datetime as dt
   import math
   
   from sklearn.svm import SVR
   from sklearn.preprocessing import MinMaxScaler
   from common.utils import load_data, mape
   ```

2. Naƒç√≠tajte √∫daje zo s√∫boru `/data/energy.csv` do Pandas dataframe a pozrite sa na ne: [^2]

   ```python
   energy = load_data('../../data')[['load']]
   ```

3. Vykreslite v≈°etky dostupn√© √∫daje o energii od janu√°ra 2012 do decembra 2014: [^2]

   ```python
   energy.plot(y='load', subplots=True, figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![√∫pln√© √∫daje](../../../../7-TimeSeries/3-SVR/images/full-data.png)

   Teraz vytvor√≠me n√°≈° model SVR.

### Vytvorenie tr√©ningov√Ωch a testovac√≠ch d√°tov√Ωch s√∫borov

Keƒè s√∫ va≈°e √∫daje naƒç√≠tan√©, m√¥≈æete ich rozdeli≈• na tr√©ningov√∫ a testovaciu mno≈æinu. Potom √∫daje uprav√≠te tak, aby vytvorili dataset zalo≈æen√Ω na ƒçasov√Ωch krokoch, ktor√Ω bude potrebn√Ω pre SVR. Model budete tr√©nova≈• na tr√©ningovej mno≈æine. Po dokonƒçen√≠ tr√©ningu modelu vyhodnot√≠te jeho presnos≈• na tr√©ningovej mno≈æine, testovacej mno≈æine a potom na celom datasete, aby ste videli celkov√Ω v√Ωkon. Mus√≠te zabezpeƒçi≈•, ≈æe testovacia mno≈æina pokr√Ωva neskor≈°ie obdobie v ƒçase oproti tr√©ningovej mno≈æine, aby ste zabezpeƒçili, ≈æe model nez√≠ska inform√°cie z bud√∫cich ƒçasov√Ωch obdob√≠ [^2] (situ√°cia zn√°ma ako *Overfitting*).

1. Priraƒète dvojmesaƒçn√© obdobie od 1. septembra do 31. okt√≥bra 2014 tr√©ningovej mno≈æine. Testovacia mno≈æina bude zah≈ï≈àa≈• dvojmesaƒçn√© obdobie od 1. novembra do 31. decembra 2014: [^2]

   ```python
   train_start_dt = '2014-11-01 00:00:00'
   test_start_dt = '2014-12-30 00:00:00'
   ```

2. Vizualizujte rozdiely: [^2]

   ```python
   energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)][['load']].rename(columns={'load':'train'}) \
       .join(energy[test_start_dt:][['load']].rename(columns={'load':'test'}), how='outer') \
       .plot(y=['train', 'test'], figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![tr√©ningov√© a testovacie √∫daje](../../../../7-TimeSeries/3-SVR/images/train-test.png)

### Pr√≠prava √∫dajov na tr√©ning

Teraz mus√≠te pripravi≈• √∫daje na tr√©ning vykonan√≠m filtrovania a ≈°k√°lovania √∫dajov. Filtrovanie datasetu zah≈ï≈àa iba ƒçasov√© obdobia a stƒ∫pce, ktor√© potrebujete, a ≈°k√°lovanie zabezpeƒç√≠, ≈æe √∫daje bud√∫ premietnut√© do intervalu 0,1.

1. Filtrovanie p√¥vodn√©ho datasetu tak, aby zah≈ï≈àal iba uveden√© ƒçasov√© obdobia na mno≈æinu a iba potrebn√Ω stƒ∫pec 'load' plus d√°tum: [^2]

   ```python
   train = energy.copy()[(energy.index >= train_start_dt) & (energy.index < test_start_dt)][['load']]
   test = energy.copy()[energy.index >= test_start_dt][['load']]
   
   print('Training data shape: ', train.shape)
   print('Test data shape: ', test.shape)
   ```

   ```output
   Training data shape:  (1416, 1)
   Test data shape:  (48, 1)
   ```
   
2. ≈†k√°lovanie tr√©ningov√Ωch √∫dajov do rozsahu (0, 1): [^2]

   ```python
   scaler = MinMaxScaler()
   train['load'] = scaler.fit_transform(train)
   ```
   
4. Teraz ≈°k√°lujte testovacie √∫daje: [^2]

   ```python
   test['load'] = scaler.transform(test)
   ```

### Vytvorenie √∫dajov s ƒçasov√Ωmi krokmi [^1]

Pre SVR transformujete vstupn√© √∫daje do formy `[batch, timesteps]`. Tak≈æe existuj√∫ce `train_data` a `test_data` uprav√≠te tak, aby obsahovali nov√Ω rozmer, ktor√Ω sa t√Ωka ƒçasov√Ωch krokov. 

```python
# Converting to numpy arrays
train_data = train.values
test_data = test.values
```

Pre tento pr√≠klad berieme `timesteps = 5`. Tak≈æe vstupy do modelu s√∫ √∫daje za prv√© 4 ƒçasov√© kroky a v√Ωstup bud√∫ √∫daje za 5. ƒçasov√Ω krok.

```python
timesteps=5
```

Konverzia tr√©ningov√Ωch √∫dajov na 2D tensor pomocou vnoren√©ho zoznamov√©ho porozumenia:

```python
train_data_timesteps=np.array([[j for j in train_data[i:i+timesteps]] for i in range(0,len(train_data)-timesteps+1)])[:,:,0]
train_data_timesteps.shape
```

```output
(1412, 5)
```

Konverzia testovac√≠ch √∫dajov na 2D tensor:

```python
test_data_timesteps=np.array([[j for j in test_data[i:i+timesteps]] for i in range(0,len(test_data)-timesteps+1)])[:,:,0]
test_data_timesteps.shape
```

```output
(44, 5)
```

V√Ωber vstupov a v√Ωstupov z tr√©ningov√Ωch a testovac√≠ch √∫dajov:

```python
x_train, y_train = train_data_timesteps[:,:timesteps-1],train_data_timesteps[:,[timesteps-1]]
x_test, y_test = test_data_timesteps[:,:timesteps-1],test_data_timesteps[:,[timesteps-1]]

print(x_train.shape, y_train.shape)
print(x_test.shape, y_test.shape)
```

```output
(1412, 4) (1412, 1)
(44, 4) (44, 1)
```

### Implement√°cia SVR [^1]

Teraz je ƒças implementova≈• SVR. Preƒç√≠tajte si viac o tejto implement√°cii v [dokument√°cii](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html). Pre na≈°u implement√°ciu postupujeme podƒæa t√Ωchto krokov:

  1. Definujte model volan√≠m `SVR()` a zadan√≠m hyperparametrov modelu: kernel, gamma, c a epsilon
  2. Pripravte model na tr√©ningov√© √∫daje volan√≠m funkcie `fit()`
  3. Vytvorte predpovede volan√≠m funkcie `predict()`

Teraz vytvor√≠me model SVR. Pou≈æijeme [RBF kernel](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel) a nastav√≠me hyperparametre gamma, C a epsilon na hodnoty 0.5, 10 a 0.05.

```python
model = SVR(kernel='rbf',gamma=0.5, C=10, epsilon = 0.05)
```

#### Tr√©ning modelu na tr√©ningov√Ωch √∫dajoch [^1]

```python
model.fit(x_train, y_train[:,0])
```

```output
SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.05, gamma=0.5,
    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)
```

#### Vytvorenie predpoved√≠ modelu [^1]

```python
y_train_pred = model.predict(x_train).reshape(-1,1)
y_test_pred = model.predict(x_test).reshape(-1,1)

print(y_train_pred.shape, y_test_pred.shape)
```

```output
(1412, 1) (44, 1)
```

Postavili ste svoj SVR! Teraz ho mus√≠me vyhodnoti≈•.

### Vyhodnotenie modelu [^1]

Na vyhodnotenie najsk√¥r ≈°k√°lujeme √∫daje sp√§≈• na p√¥vodn√∫ ≈°k√°lu. Potom, aby sme skontrolovali v√Ωkon, vykresl√≠me p√¥vodn√Ω a predpovedan√Ω ƒçasov√Ω rad a tie≈æ vytlaƒç√≠me v√Ωsledok MAPE.

≈†k√°lovanie predpovedan√©ho a p√¥vodn√©ho v√Ωstupu:

```python
# Scaling the predictions
y_train_pred = scaler.inverse_transform(y_train_pred)
y_test_pred = scaler.inverse_transform(y_test_pred)

print(len(y_train_pred), len(y_test_pred))
```

```python
# Scaling the original values
y_train = scaler.inverse_transform(y_train)
y_test = scaler.inverse_transform(y_test)

print(len(y_train), len(y_test))
```

#### Kontrola v√Ωkonu modelu na tr√©ningov√Ωch a testovac√≠ch √∫dajoch [^1]

Z datasetu extrahujeme ƒçasov√© znaƒçky, aby sme ich zobrazili na osi x n√°≈°ho grafu. V≈°imnite si, ≈æe pou≈æ√≠vame prv√Ωch ```timesteps-1``` hodn√¥t ako vstup pre prv√Ω v√Ωstup, tak≈æe ƒçasov√© znaƒçky pre v√Ωstup zaƒçn√∫ a≈æ po tom.

```python
train_timestamps = energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)].index[timesteps-1:]
test_timestamps = energy[test_start_dt:].index[timesteps-1:]

print(len(train_timestamps), len(test_timestamps))
```

```output
1412 44
```

Vykreslenie predpoved√≠ pre tr√©ningov√© √∫daje:

```python
plt.figure(figsize=(25,6))
plt.plot(train_timestamps, y_train, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(train_timestamps, y_train_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.title("Training data prediction")
plt.show()
```

![predpoveƒè tr√©ningov√Ωch √∫dajov](../../../../7-TimeSeries/3-SVR/images/train-data-predict.png)

Tlaƒç MAPE pre tr√©ningov√© √∫daje

```python
print('MAPE for training data: ', mape(y_train_pred, y_train)*100, '%')
```

```output
MAPE for training data: 1.7195710200875551 %
```

Vykreslenie predpoved√≠ pre testovacie √∫daje

```python
plt.figure(figsize=(10,3))
plt.plot(test_timestamps, y_test, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(test_timestamps, y_test_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![predpoveƒè testovac√≠ch √∫dajov](../../../../7-TimeSeries/3-SVR/images/test-data-predict.png)

Tlaƒç MAPE pre testovacie √∫daje

```python
print('MAPE for testing data: ', mape(y_test_pred, y_test)*100, '%')
```

```output
MAPE for testing data:  1.2623790187854018 %
```

üèÜ Dosiahli ste veƒæmi dobr√Ω v√Ωsledok na testovacom datasete!

### Kontrola v√Ωkonu modelu na celom datasete [^1]

```python
# Extracting load values as numpy array
data = energy.copy().values

# Scaling
data = scaler.transform(data)

# Transforming to 2D tensor as per model input requirement
data_timesteps=np.array([[j for j in data[i:i+timesteps]] for i in range(0,len(data)-timesteps+1)])[:,:,0]
print("Tensor shape: ", data_timesteps.shape)

# Selecting inputs and outputs from data
X, Y = data_timesteps[:,:timesteps-1],data_timesteps[:,[timesteps-1]]
print("X shape: ", X.shape,"\nY shape: ", Y.shape)
```

```output
Tensor shape:  (26300, 5)
X shape:  (26300, 4) 
Y shape:  (26300, 1)
```

```python
# Make model predictions
Y_pred = model.predict(X).reshape(-1,1)

# Inverse scale and reshape
Y_pred = scaler.inverse_transform(Y_pred)
Y = scaler.inverse_transform(Y)
```

```python
plt.figure(figsize=(30,8))
plt.plot(Y, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(Y_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![predpoveƒè cel√Ωch √∫dajov](../../../../7-TimeSeries/3-SVR/images/full-data-predict.png)

```python
print('MAPE: ', mape(Y_pred, Y)*100, '%')
```

```output
MAPE:  2.0572089029888656 %
```

üèÜ Veƒæmi pekn√© grafy, ktor√© ukazuj√∫ model s dobrou presnos≈•ou. Skvel√° pr√°ca!

---

## üöÄV√Ωzva

- Sk√∫ste upravi≈• hyperparametre (gamma, C, epsilon) pri vytv√°ran√≠ modelu a vyhodno≈•te √∫daje, aby ste zistili, ktor√° sada hyperparametrov poskytuje najlep≈°ie v√Ωsledky na testovac√≠ch √∫dajoch. Viac o t√Ωchto hyperparametroch sa dozviete v [dokumente](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel). 
- Sk√∫ste pou≈æi≈• r√¥zne funkcie kernelu pre model a analyzujte ich v√Ωkonnos≈• na datasete. U≈æitoƒçn√Ω dokument n√°jdete [tu](https://scikit-learn.org/stable/modules/svm.html#kernel-functions).
- Sk√∫ste pou≈æi≈• r√¥zne hodnoty pre `timesteps`, aby model mohol pozera≈• sp√§≈• na predpoveƒè.

## [Kv√≠z po predn√°≈°ke](https://ff-quizzes.netlify.app/en/ml/)

## Prehƒæad a samostatn√© ≈°t√∫dium

T√°to lekcia bola zameran√° na predstavenie aplik√°cie SVR pre predpovedanie ƒçasov√Ωch radov. Viac o SVR si m√¥≈æete preƒç√≠ta≈• v [tomto blogu](https://www.analyticsvidhya.com/blog/2020/03/support-vector-regression-tutorial-for-machine-learning/). T√°to [dokument√°cia na scikit-learn](https://scikit-learn.org/stable/modules/svm.html) poskytuje komplexnej≈°ie vysvetlenie o SVM v≈°eobecne, [SVR](https://scikit-learn.org/stable/modules/svm.html#regression) a tie≈æ ƒèal≈°ie detaily implement√°cie, ako s√∫ r√¥zne [funkcie kernelu](https://scikit-learn.org/stable/modules/svm.html#kernel-functions), ktor√© je mo≈æn√© pou≈æi≈•, a ich parametre.

## Zadanie

[Nov√Ω model SVR](assignment.md)

## Kredity

[^1]: Text, k√≥d a v√Ωstup v tejto sekcii prispel [@AnirbanMukherjeeXD](https://github.com/AnirbanMukherjeeXD)
[^2]: Text, k√≥d a v√Ωstup v tejto sekcii bol prevzat√Ω z [ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA)

---

**Upozornenie**:  
Tento dokument bol prelo≈æen√Ω pomocou slu≈æby AI prekladu [Co-op Translator](https://github.com/Azure/co-op-translator). Hoci sa sna≈æ√≠me o presnos≈•, pros√≠m, berte na vedomie, ≈æe automatizovan√© preklady m√¥≈æu obsahova≈• chyby alebo nepresnosti. P√¥vodn√Ω dokument v jeho p√¥vodnom jazyku by mal by≈• pova≈æovan√Ω za autoritat√≠vny zdroj. Pre kritick√© inform√°cie sa odpor√∫ƒça profesion√°lny ƒæudsk√Ω preklad. Nie sme zodpovedn√≠ za ak√©koƒævek nedorozumenia alebo nespr√°vne interpret√°cie vypl√Ωvaj√∫ce z pou≈æitia tohto prekladu.