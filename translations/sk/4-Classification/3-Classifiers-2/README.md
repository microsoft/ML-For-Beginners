<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "49047911108adc49d605cddfb455749c",
  "translation_date": "2025-09-05T16:23:53+00:00",
  "source_file": "4-Classification/3-Classifiers-2/README.md",
  "language_code": "sk"
}
-->
# Klasifik√°tory kuch√Ω≈à 2

V tejto druhej lekcii o klasifik√°cii presk√∫mate ƒèal≈°ie sp√¥soby klasifik√°cie ƒç√≠seln√Ωch √∫dajov. Tie≈æ sa dozviete o d√¥sledkoch v√Ωberu jedn√©ho klasifik√°tora oproti druh√©mu.

## [Kv√≠z pred predn√°≈°kou](https://ff-quizzes.netlify.app/en/ml/)

### Predpoklady

Predpoklad√°me, ≈æe ste dokonƒçili predch√°dzaj√∫ce lekcie a m√°te vyƒçisten√Ω dataset vo va≈°om prieƒçinku `data` s n√°zvom _cleaned_cuisines.csv_ v kore≈àovom adres√°ri tejto 4-lekciovej zlo≈æky.

### Pr√≠prava

Naƒç√≠tali sme v√°≈° s√∫bor _notebook.ipynb_ s vyƒçisten√Ωm datasetom a rozdelili ho na d√°tov√© r√°mce X a y, pripraven√© na proces vytv√°rania modelu.

## Mapa klasifik√°cie

Predt√Ωm ste sa nauƒçili o r√¥znych mo≈ænostiach klasifik√°cie √∫dajov pomocou cheat sheetu od Microsoftu. Scikit-learn pon√∫ka podobn√Ω, ale podrobnej≈°√≠ cheat sheet, ktor√Ω v√°m m√¥≈æe pom√¥c≈• e≈°te viac z√∫≈æi≈• v√Ωber odhadovaƒçov (in√Ω term√≠n pre klasifik√°tory):

![ML Map from Scikit-learn](../../../../4-Classification/3-Classifiers-2/images/map.png)
> Tip: [nav≈°t√≠vte t√∫to mapu online](https://scikit-learn.org/stable/tutorial/machine_learning_map/) a kliknite na cesty, aby ste si preƒç√≠tali dokument√°ciu.

### Pl√°n

T√°to mapa je veƒæmi u≈æitoƒçn√°, keƒè m√°te jasn√Ω prehƒæad o svojich √∫dajoch, preto≈æe sa m√¥≈æete ‚Äûprejs≈•‚Äú po jej cest√°ch k rozhodnutiu:

- M√°me >50 vzoriek
- Chceme predpoveda≈• kateg√≥riu
- M√°me oznaƒçen√© √∫daje
- M√°me menej ako 100K vzoriek
- ‚ú® M√¥≈æeme zvoli≈• Linear SVC
- Ak to nefunguje, keƒè≈æe m√°me ƒç√≠seln√© √∫daje
    - M√¥≈æeme sk√∫si≈• ‚ú® KNeighbors Classifier 
      - Ak to nefunguje, sk√∫ste ‚ú® SVC a ‚ú® Ensemble Classifiers

Toto je veƒæmi u≈æitoƒçn√° cesta, ktor√∫ treba sledova≈•.

## Cviƒçenie - rozdelenie √∫dajov

Podƒæa tejto cesty by sme mali zaƒça≈• importovan√≠m niektor√Ωch kni≈æn√≠c na pou≈æitie.

1. Importujte potrebn√© kni≈ænice:

    ```python
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    import numpy as np
    ```

1. Rozdeƒæte svoje tr√©ningov√© a testovacie √∫daje:

    ```python
    X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)
    ```

## Linear SVC klasifik√°tor

Support-Vector clustering (SVC) je s√∫ƒças≈•ou rodiny techn√≠k strojov√©ho uƒçenia Support-Vector Machines (viac o nich ni≈æ≈°ie). V tejto met√≥de si m√¥≈æete vybra≈• ‚Äûkernel‚Äú, ktor√Ω rozhoduje o tom, ako sa bud√∫ oznaƒçenia zoskupova≈•. Parameter 'C' sa t√Ωka 'regulariz√°cie', ktor√° reguluje vplyv parametrov. Kernel m√¥≈æe by≈• jeden z [niekoƒæk√Ωch](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC); tu ho nastav√≠me na 'linear', aby sme vyu≈æili Linear SVC. Pravdepodobnos≈• je predvolene nastaven√° na 'false'; tu ju nastav√≠me na 'true', aby sme z√≠skali odhady pravdepodobnosti. Random state nastav√≠me na '0', aby sme premie≈°ali √∫daje na z√≠skanie pravdepodobnost√≠.

### Cviƒçenie - aplik√°cia Linear SVC

Zaƒçnite vytvoren√≠m poƒæa klasifik√°torov. Postupne budete prid√°va≈• do tohto poƒæa, ako budeme testova≈•.

1. Zaƒçnite s Linear SVC:

    ```python
    C = 10
    # Create different classifiers.
    classifiers = {
        'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0)
    }
    ```

2. Natr√©nujte svoj model pomocou Linear SVC a vytlaƒçte spr√°vu:

    ```python
    n_classifiers = len(classifiers)
    
    for index, (name, classifier) in enumerate(classifiers.items()):
        classifier.fit(X_train, np.ravel(y_train))
    
        y_pred = classifier.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print("Accuracy (train) for %s: %0.1f%% " % (name, accuracy * 100))
        print(classification_report(y_test,y_pred))
    ```

    V√Ωsledok je celkom dobr√Ω:

    ```output
    Accuracy (train) for Linear SVC: 78.6% 
                  precision    recall  f1-score   support
    
         chinese       0.71      0.67      0.69       242
          indian       0.88      0.86      0.87       234
        japanese       0.79      0.74      0.76       254
          korean       0.85      0.81      0.83       242
            thai       0.71      0.86      0.78       227
    
        accuracy                           0.79      1199
       macro avg       0.79      0.79      0.79      1199
    weighted avg       0.79      0.79      0.79      1199
    ```

## K-Neighbors klasifik√°tor

K-Neighbors je s√∫ƒças≈•ou rodiny met√≥d strojov√©ho uƒçenia ‚Äûneighbors‚Äú, ktor√© sa daj√∫ pou≈æi≈• na riaden√© aj neriaden√© uƒçenie. V tejto met√≥de sa vytvor√≠ preddefinovan√Ω poƒçet bodov a √∫daje sa zhroma≈æƒèuj√∫ okolo t√Ωchto bodov tak, aby sa dali predpoveda≈• v≈°eobecn√© oznaƒçenia pre √∫daje.

### Cviƒçenie - aplik√°cia K-Neighbors klasifik√°tora

Predch√°dzaj√∫ci klasifik√°tor bol dobr√Ω a fungoval dobre s √∫dajmi, ale mo≈æno m√¥≈æeme dosiahnu≈• lep≈°iu presnos≈•. Sk√∫ste K-Neighbors klasifik√°tor.

1. Pridajte riadok do svojho poƒæa klasifik√°torov (pridajte ƒçiarku za polo≈æku Linear SVC):

    ```python
    'KNN classifier': KNeighborsClassifier(C),
    ```

    V√Ωsledok je o nieƒço hor≈°√≠:

    ```output
    Accuracy (train) for KNN classifier: 73.8% 
                  precision    recall  f1-score   support
    
         chinese       0.64      0.67      0.66       242
          indian       0.86      0.78      0.82       234
        japanese       0.66      0.83      0.74       254
          korean       0.94      0.58      0.72       242
            thai       0.71      0.82      0.76       227
    
        accuracy                           0.74      1199
       macro avg       0.76      0.74      0.74      1199
    weighted avg       0.76      0.74      0.74      1199
    ```

    ‚úÖ Zistite viac o [K-Neighbors](https://scikit-learn.org/stable/modules/neighbors.html#neighbors)

## Support Vector klasifik√°tor

Support-Vector klasifik√°tory s√∫ s√∫ƒças≈•ou rodiny met√≥d strojov√©ho uƒçenia [Support-Vector Machine](https://wikipedia.org/wiki/Support-vector_machine), ktor√© sa pou≈æ√≠vaj√∫ na klasifikaƒçn√© a regresn√© √∫lohy. SVM ‚Äûmapuj√∫ tr√©ningov√© pr√≠klady na body v priestore‚Äú, aby maximalizovali vzdialenos≈• medzi dvoma kateg√≥riami. N√°sledn√© √∫daje sa mapuj√∫ do tohto priestoru, aby sa dala predpoveda≈• ich kateg√≥ria.

### Cviƒçenie - aplik√°cia Support Vector klasifik√°tora

Sk√∫sme dosiahnu≈• o nieƒço lep≈°iu presnos≈• pomocou Support Vector klasifik√°tora.

1. Pridajte ƒçiarku za polo≈æku K-Neighbors a potom pridajte tento riadok:

    ```python
    'SVC': SVC(),
    ```

    V√Ωsledok je veƒæmi dobr√Ω!

    ```output
    Accuracy (train) for SVC: 83.2% 
                  precision    recall  f1-score   support
    
         chinese       0.79      0.74      0.76       242
          indian       0.88      0.90      0.89       234
        japanese       0.87      0.81      0.84       254
          korean       0.91      0.82      0.86       242
            thai       0.74      0.90      0.81       227
    
        accuracy                           0.83      1199
       macro avg       0.84      0.83      0.83      1199
    weighted avg       0.84      0.83      0.83      1199
    ```

    ‚úÖ Zistite viac o [Support-Vectors](https://scikit-learn.org/stable/modules/svm.html#svm)

## Ensemble klasifik√°tory

Poƒème sledova≈• cestu a≈æ do konca, aj keƒè predch√°dzaj√∫ci test bol veƒæmi dobr√Ω. Sk√∫sme niektor√© 'Ensemble Classifiers', konkr√©tne Random Forest a AdaBoost:

```python
  'RFST': RandomForestClassifier(n_estimators=100),
  'ADA': AdaBoostClassifier(n_estimators=100)
```

V√Ωsledok je veƒæmi dobr√Ω, najm√§ pre Random Forest:

```output
Accuracy (train) for RFST: 84.5% 
              precision    recall  f1-score   support

     chinese       0.80      0.77      0.78       242
      indian       0.89      0.92      0.90       234
    japanese       0.86      0.84      0.85       254
      korean       0.88      0.83      0.85       242
        thai       0.80      0.87      0.83       227

    accuracy                           0.84      1199
   macro avg       0.85      0.85      0.84      1199
weighted avg       0.85      0.84      0.84      1199

Accuracy (train) for ADA: 72.4% 
              precision    recall  f1-score   support

     chinese       0.64      0.49      0.56       242
      indian       0.91      0.83      0.87       234
    japanese       0.68      0.69      0.69       254
      korean       0.73      0.79      0.76       242
        thai       0.67      0.83      0.74       227

    accuracy                           0.72      1199
   macro avg       0.73      0.73      0.72      1199
weighted avg       0.73      0.72      0.72      1199
```

‚úÖ Zistite viac o [Ensemble Classifiers](https://scikit-learn.org/stable/modules/ensemble.html)

T√°to met√≥da strojov√©ho uƒçenia ‚Äûkombinuje predpovede niekoƒæk√Ωch z√°kladn√Ωch odhadovaƒçov‚Äú, aby zlep≈°ila kvalitu modelu. V na≈°om pr√≠klade sme pou≈æili Random Trees a AdaBoost. 

- [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest), met√≥da priemerovania, vytv√°ra ‚Äûles‚Äú z ‚Äûrozhodovac√≠ch stromov‚Äú naplnen√Ωch n√°hodnos≈•ou, aby sa zabr√°nilo pretr√©novaniu. Parameter n_estimators je nastaven√Ω na poƒçet stromov.

- [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) prisp√¥sob√≠ klasifik√°tor datasetu a potom prisp√¥sob√≠ k√≥pie tohto klasifik√°tora rovnak√©mu datasetu. Zameriava sa na v√°hy nespr√°vne klasifikovan√Ωch polo≈æiek a upravuje fit pre ƒèal≈°√≠ klasifik√°tor, aby ich opravil.

---

## üöÄV√Ωzva

Ka≈æd√° z t√Ωchto techn√≠k m√° veƒæk√© mno≈æstvo parametrov, ktor√© m√¥≈æete upravi≈•. Presk√∫majte predvolen√© parametre ka≈æd√©ho z nich a prem√Ω≈°ƒæajte o tom, ƒço by znamenalo upravenie t√Ωchto parametrov pre kvalitu modelu.

## [Kv√≠z po predn√°≈°ke](https://ff-quizzes.netlify.app/en/ml/)

## Prehƒæad a samostatn√© ≈°t√∫dium

V t√Ωchto lekci√°ch je veƒæa odborn√Ωch v√Ωrazov, tak≈æe si chv√≠ƒæu pre≈°tudujte [tento zoznam](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) u≈æitoƒçnej terminol√≥gie!

## Zadanie 

[Parameter play](assignment.md)

---

**Upozornenie**:  
Tento dokument bol prelo≈æen√Ω pomocou slu≈æby AI prekladu [Co-op Translator](https://github.com/Azure/co-op-translator). Hoci sa sna≈æ√≠me o presnos≈•, pros√≠m, berte na vedomie, ≈æe automatizovan√© preklady m√¥≈æu obsahova≈• chyby alebo nepresnosti. P√¥vodn√Ω dokument v jeho rodnom jazyku by mal by≈• pova≈æovan√Ω za autoritat√≠vny zdroj. Pre kritick√© inform√°cie sa odpor√∫ƒça profesion√°lny ƒæudsk√Ω preklad. Nie sme zodpovedn√≠ za ≈æiadne nedorozumenia alebo nespr√°vne interpret√°cie vypl√Ωvaj√∫ce z pou≈æitia tohto prekladu.