<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "df2b538e8fbb3e91cf0419ae2f858675",
  "translation_date": "2025-09-05T15:55:18+00:00",
  "source_file": "9-Real-World/2-Debugging-ML-Models/README.md",
  "language_code": "sk"
}
-->
# Postscript: Ladenie modelov v strojovom uƒçen√≠ pomocou komponentov zodpovedn√©ho AI dashboardu

## [Kv√≠z pred predn√°≈°kou](https://ff-quizzes.netlify.app/en/ml/)

## √övod

Strojov√© uƒçenie ovplyv≈àuje na≈°e ka≈ædodenn√© ≈æivoty. AI si nach√°dza cestu do niektor√Ωch z najd√¥le≈æitej≈°√≠ch syst√©mov, ktor√© ovplyv≈àuj√∫ n√°s ako jednotlivcov aj na≈°u spoloƒçnos≈•, od zdravotn√≠ctva, financi√≠, vzdel√°vania a≈æ po zamestnanie. Napr√≠klad syst√©my a modely sa podieƒæaj√∫ na ka≈ædodenn√Ωch rozhodovac√≠ch √∫loh√°ch, ako s√∫ diagnostiky v zdravotn√≠ctve alebo odhaƒæovanie podvodov. V d√¥sledku toho s√∫ pokroky v AI spolu s zr√Ωchlen√Ωm prij√≠man√≠m sprev√°dzan√© vyv√≠jaj√∫cimi sa spoloƒçensk√Ωmi oƒçak√°vaniami a rast√∫cou regul√°ciou. Neust√°le vid√≠me oblasti, kde syst√©my AI nespl≈àuj√∫ oƒçak√°vania; odhaƒæuj√∫ nov√© v√Ωzvy; a vl√°dy zaƒç√≠naj√∫ regulova≈• AI rie≈°enia. Preto je d√¥le≈æit√©, aby boli tieto modely analyzovan√© s cieƒæom poskytova≈• spravodliv√©, spoƒæahliv√©, inkluz√≠vne, transparentn√© a zodpovedn√© v√Ωsledky pre v≈°etk√Ωch.

V tomto kurze sa pozrieme na praktick√© n√°stroje, ktor√© m√¥≈æu by≈• pou≈æit√© na pos√∫denie, ƒçi m√° model probl√©my so zodpovedn√Ωm AI. Tradiƒçn√© techniky ladenia strojov√©ho uƒçenia maj√∫ tendenciu by≈• zalo≈æen√© na kvantitat√≠vnych v√Ωpoƒçtoch, ako je agregovan√° presnos≈• alebo priemern√° strata ch√Ωb. Predstavte si, ƒço sa m√¥≈æe sta≈•, keƒè √∫daje, ktor√© pou≈æ√≠vate na vytvorenie t√Ωchto modelov, postr√°daj√∫ urƒçit√© demografick√© skupiny, ako s√∫ rasa, pohlavie, politick√© n√°zory, n√°bo≈æenstvo, alebo neprimerane zastupuj√∫ tak√©to demografick√© skupiny. ƒåo ak je v√Ωstup modelu interpretovan√Ω tak, ≈æe uprednost≈àuje urƒçit√∫ demografick√∫ skupinu? To m√¥≈æe vies≈• k nadmernej alebo nedostatoƒçnej reprezent√°cii t√Ωchto citliv√Ωch skup√≠n, ƒço sp√¥sobuje probl√©my so spravodlivos≈•ou, inkluz√≠vnos≈•ou alebo spoƒæahlivos≈•ou modelu. ƒéal≈°√≠m faktorom je, ≈æe modely strojov√©ho uƒçenia s√∫ pova≈æovan√© za ƒçierne skrinky, ƒço s≈•a≈æuje pochopenie a vysvetlenie toho, ƒço ovplyv≈àuje predikciu modelu. Toto s√∫ v√Ωzvy, ktor√Ωm ƒçelia d√°tov√≠ vedci a v√Ωvoj√°ri AI, keƒè nemaj√∫ dostatoƒçn√© n√°stroje na ladenie a pos√∫denie spravodlivosti alebo d√¥veryhodnosti modelu.

V tejto lekcii sa nauƒç√≠te, ako ladi≈• svoje modely pomocou:

- **Anal√Ωzy ch√Ωb**: identifik√°cia oblast√≠ v distrib√∫cii √∫dajov, kde m√° model vysok√© miery ch√Ωb.
- **Prehƒæadu modelu**: vykonanie porovn√°vacej anal√Ωzy medzi r√¥znymi kohortami √∫dajov na odhalenie rozdielov vo v√Ωkonnostn√Ωch metrik√°ch modelu.
- **Anal√Ωzy √∫dajov**: sk√∫manie, kde m√¥≈æe by≈• nadmern√° alebo nedostatoƒçn√° reprezent√°cia √∫dajov, ktor√° m√¥≈æe skresli≈• model tak, aby uprednost≈àoval jednu demografick√∫ skupinu pred druhou.
- **D√¥le≈æitosti vlastnost√≠**: pochopenie, ktor√© vlastnosti ovplyv≈àuj√∫ predikcie modelu na glob√°lnej alebo lok√°lnej √∫rovni.

## Predpoklady

Ako predpoklad si pros√≠m pre≈°tudujte [N√°stroje zodpovedn√©ho AI pre v√Ωvoj√°rov](https://www.microsoft.com/ai/ai-lab-responsible-ai-dashboard)

> ![Gif o n√°strojoch zodpovedn√©ho AI](../../../../9-Real-World/2-Debugging-ML-Models/images/rai-overview.gif)

## Anal√Ωza ch√Ωb

Tradiƒçn√© metriky v√Ωkonnosti modelu pou≈æ√≠van√© na meranie presnosti s√∫ v√§ƒç≈°inou v√Ωpoƒçty zalo≈æen√© na spr√°vnych vs nespr√°vnych predikci√°ch. Napr√≠klad urƒçenie, ≈æe model je presn√Ω na 89 % s chybovou stratou 0,001, m√¥≈æe by≈• pova≈æovan√© za dobr√Ω v√Ωkon. Chyby v≈°ak nie s√∫ rovnomerne rozlo≈æen√© v podkladovom s√∫bore √∫dajov. M√¥≈æete dosiahnu≈• sk√≥re presnosti modelu 89 %, ale zisti≈•, ≈æe existuj√∫ r√¥zne oblasti va≈°ich √∫dajov, v ktor√Ωch model zlyh√°va na 42 %. D√¥sledky t√Ωchto vzorcov zlyhania s urƒçit√Ωmi skupinami √∫dajov m√¥≈æu vies≈• k probl√©mom so spravodlivos≈•ou alebo spoƒæahlivos≈•ou. Je nevyhnutn√© pochopi≈• oblasti, kde model funguje dobre alebo nie. Oblasti √∫dajov, kde m√° v√°≈° model vysok√Ω poƒçet nepresnost√≠, sa m√¥≈æu uk√°za≈• ako d√¥le≈æit√° demografick√° skupina √∫dajov.

![Analyzujte a ladte chyby modelu](../../../../9-Real-World/2-Debugging-ML-Models/images/ea-error-distribution.png)

Komponent Anal√Ωza ch√Ωb na RAI dashboarde ilustruje, ako s√∫ zlyhania modelu rozlo≈æen√© medzi r√¥znymi kohortami pomocou vizualiz√°cie stromu. To je u≈æitoƒçn√© pri identifik√°cii vlastnost√≠ alebo oblast√≠, kde je vysok√° miera ch√Ωb vo va≈°om s√∫bore √∫dajov. T√Ωm, ≈æe vid√≠te, odkiaƒæ poch√°dza v√§ƒç≈°ina nepresnost√≠ modelu, m√¥≈æete zaƒça≈• sk√∫ma≈• pr√≠ƒçinu. M√¥≈æete tie≈æ vytv√°ra≈• kohorty √∫dajov na vykonanie anal√Ωzy. Tieto kohorty √∫dajov pom√°haj√∫ v procese ladenia urƒçi≈•, preƒço je v√Ωkon modelu dobr√Ω v jednej kohorte, ale chybn√Ω v inej.

![Anal√Ωza ch√Ωb](../../../../9-Real-World/2-Debugging-ML-Models/images/ea-error-cohort.png)

Vizualizaƒçn√© indik√°tory na mape stromu pom√°haj√∫ r√Ωchlej≈°ie lokalizova≈• probl√©mov√© oblasti. Napr√≠klad tmav≈°√≠ odtie≈à ƒçervenej farby na uzle stromu znamen√° vy≈°≈°iu mieru ch√Ωb.

Heatmapa je ƒèal≈°ou vizualizaƒçnou funkciou, ktor√∫ m√¥≈æu pou≈æ√≠vatelia pou≈æi≈• na sk√∫manie miery ch√Ωb pomocou jednej alebo dvoch vlastnost√≠ na n√°jdenie prispievateƒæa k chyb√°m modelu v celom s√∫bore √∫dajov alebo kohort√°ch.

![Heatmapa anal√Ωzy ch√Ωb](../../../../9-Real-World/2-Debugging-ML-Models/images/ea-heatmap.png)

Pou≈æite anal√Ωzu ch√Ωb, keƒè potrebujete:

* Z√≠ska≈• hlbok√© pochopenie toho, ako s√∫ zlyhania modelu rozlo≈æen√© v s√∫bore √∫dajov a medzi viacer√Ωmi vstupn√Ωmi a vlastnostn√Ωmi dimenziami.
* Rozlo≈æi≈• agregovan√© metriky v√Ωkonnosti na automatick√© objavenie chybn√Ωch kohort na informovanie o va≈°ich cielen√Ωch krokoch na zmiernenie probl√©mov.

## Prehƒæad modelu

Hodnotenie v√Ωkonnosti modelu strojov√©ho uƒçenia si vy≈æaduje z√≠skanie holistick√©ho pochopenia jeho spr√°vania. To mo≈æno dosiahnu≈• presk√∫man√≠m viacer√Ωch metr√≠k, ako s√∫ miera ch√Ωb, presnos≈•, recall, precision alebo MAE (Mean Absolute Error), na odhalenie rozdielov medzi v√Ωkonnostn√Ωmi metrikami. Jedna metrika v√Ωkonnosti m√¥≈æe vyzera≈• skvele, ale nepresnosti m√¥≈æu by≈• odhalen√© v inej metrike. Okrem toho porovn√°vanie metr√≠k na odhalenie rozdielov v celom s√∫bore √∫dajov alebo kohort√°ch pom√°ha objasni≈•, kde model funguje dobre alebo nie. To je obzvl√°≈°≈• d√¥le≈æit√© pri sledovan√≠ v√Ωkonu modelu medzi citliv√Ωmi vs necitliv√Ωmi vlastnos≈•ami (napr. rasa pacienta, pohlavie alebo vek), aby sa odhalila potenci√°lna nespravodlivos≈• modelu. Napr√≠klad zistenie, ≈æe model je viac chybn√Ω v kohorte, ktor√° m√° citliv√© vlastnosti, m√¥≈æe odhali≈• potenci√°lnu nespravodlivos≈• modelu.

Komponent Prehƒæad modelu na RAI dashboarde pom√°ha nielen pri anal√Ωze v√Ωkonnostn√Ωch metr√≠k reprezent√°cie √∫dajov v kohorte, ale d√°va pou≈æ√≠vateƒæom mo≈ænos≈• porovn√°va≈• spr√°vanie modelu medzi r√¥znymi kohortami.

![Datasetov√© kohorty - prehƒæad modelu na RAI dashboarde](../../../../9-Real-World/2-Debugging-ML-Models/images/model-overview-dataset-cohorts.png)

Funkcia anal√Ωzy zalo≈æen√° na vlastnostiach komponentu umo≈æ≈àuje pou≈æ√≠vateƒæom z√∫≈æi≈• podskupiny √∫dajov v r√°mci konkr√©tnej vlastnosti na identifik√°ciu anom√°li√≠ na granul√°rnej √∫rovni. Napr√≠klad dashboard m√° zabudovan√∫ inteligenciu na automatick√© generovanie kohort pre pou≈æ√≠vateƒæom vybran√∫ vlastnos≈• (napr. *"time_in_hospital < 3"* alebo *"time_in_hospital >= 7"*). To umo≈æ≈àuje pou≈æ√≠vateƒæovi izolova≈• konkr√©tnu vlastnos≈• z v√§ƒç≈°ej skupiny √∫dajov, aby zistil, ƒçi je kƒæ√∫ƒçov√Ωm ovplyv≈àovateƒæom chybn√Ωch v√Ωsledkov modelu.

![Kohorty vlastnost√≠ - prehƒæad modelu na RAI dashboarde](../../../../9-Real-World/2-Debugging-ML-Models/images/model-overview-feature-cohorts.png)

Komponent Prehƒæad modelu podporuje dve triedy metr√≠k rozdielov:

**Rozdiely vo v√Ωkonnosti modelu**: Tieto sady metr√≠k vypoƒç√≠tavaj√∫ rozdiely (disparity) v hodnot√°ch vybranej metriky v√Ωkonnosti medzi podskupinami √∫dajov. Tu je niekoƒæko pr√≠kladov:

* Rozdiely v miere presnosti
* Rozdiely v miere ch√Ωb
* Rozdiely v precision
* Rozdiely v recall
* Rozdiely v Mean Absolute Error (MAE)

**Rozdiely v miere v√Ωberu**: T√°to metrika obsahuje rozdiely v miere v√Ωberu (priazniv√° predikcia) medzi podskupinami. Pr√≠kladom je rozdiel v miere schvaƒæovania √∫verov. Miera v√Ωberu znamen√° podiel d√°tov√Ωch bodov v ka≈ædej triede klasifikovan√Ωch ako 1 (v bin√°rnej klasifik√°cii) alebo distrib√∫ciu predikƒçn√Ωch hodn√¥t (v regresii).

## Anal√Ωza √∫dajov

> "Ak budete √∫daje muƒçi≈• dostatoƒçne dlho, priznaj√∫ sa k ƒçomukoƒævek" - Ronald Coase

Toto tvrdenie znie extr√©mne, ale je pravda, ≈æe √∫daje m√¥≈æu by≈• manipulovan√© na podporu ak√©hokoƒævek z√°veru. Tak√°to manipul√°cia sa niekedy m√¥≈æe sta≈• ne√∫myselne. Ako ƒæudia m√°me v≈°etci predsudky a ƒçasto je ≈•a≈æk√© vedome vedie≈•, kedy zav√°dzame predsudky do √∫dajov. Zaruƒçenie spravodlivosti v AI a strojovom uƒçen√≠ zost√°va komplexnou v√Ωzvou.

√ödaje s√∫ veƒæk√Ωm slep√Ωm miestom pre tradiƒçn√© metriky v√Ωkonnosti modelu. M√¥≈æete ma≈• vysok√© sk√≥re presnosti, ale to nemus√≠ v≈ædy odr√°≈æa≈• podkladov√© predsudky v √∫dajoch, ktor√© by mohli by≈• vo va≈°om s√∫bore √∫dajov. Napr√≠klad, ak m√° s√∫bor √∫dajov zamestnancov 27 % ≈æien na v√Ωkonn√Ωch poz√≠ci√°ch v spoloƒçnosti a 73 % mu≈æov na rovnakej √∫rovni, model AI na inzerciu pracovn√Ωch miest tr√©novan√Ω na t√Ωchto √∫dajoch m√¥≈æe cieli≈• preva≈æne na mu≈æsk√© publikum pre seniorn√© pracovn√© poz√≠cie. T√°to nerovnov√°ha v √∫dajoch skreslila predikciu modelu tak, aby uprednost≈àovala jedno pohlavie. To odhaƒæuje probl√©m spravodlivosti, kde je v AI modeli predsudok voƒçi pohlaviu.

Komponent Anal√Ωza √∫dajov na RAI dashboarde pom√°ha identifikova≈• oblasti, kde je nadmern√° alebo nedostatoƒçn√° reprezent√°cia v s√∫bore √∫dajov. Pom√°ha pou≈æ√≠vateƒæom diagnostikova≈• pr√≠ƒçinu ch√Ωb a probl√©mov so spravodlivos≈•ou, ktor√© s√∫ sp√¥soben√© nerovnov√°hou √∫dajov alebo nedostatkom reprezent√°cie urƒçitej skupiny √∫dajov. To d√°va pou≈æ√≠vateƒæom mo≈ænos≈• vizualizova≈• s√∫bory √∫dajov na z√°klade predikovan√Ωch a skutoƒçn√Ωch v√Ωsledkov, skup√≠n ch√Ωb a konkr√©tnych vlastnost√≠. Niekedy objavenie nedostatoƒçne zast√∫penej skupiny √∫dajov m√¥≈æe tie≈æ odhali≈•, ≈æe model sa neuƒç√≠ dobre, a preto m√° vysok√© nepresnosti. Model s predsudkami v √∫dajoch nie je len probl√©mom spravodlivosti, ale ukazuje, ≈æe model nie je inkluz√≠vny ani spoƒæahliv√Ω.

![Komponent Anal√Ωza √∫dajov na RAI dashboarde](../../../../9-Real-World/2-Debugging-ML-Models/images/dataanalysis-cover.png)

Pou≈æite anal√Ωzu √∫dajov, keƒè potrebujete:

* Presk√∫ma≈• ≈°tatistiky v√°≈°ho s√∫boru √∫dajov v√Ωberom r√¥znych filtrov na rozdelenie √∫dajov do r√¥znych dimenzi√≠ (zn√°mych ako kohorty).
* Pochopi≈• distrib√∫ciu v√°≈°ho s√∫boru √∫dajov medzi r√¥znymi kohortami a skupinami vlastnost√≠.
* Urƒçi≈•, ƒçi va≈°e zistenia t√Ωkaj√∫ce sa spravodlivosti, anal√Ωzy ch√Ωb a kauzality (odvoden√© z in√Ωch komponentov dashboardu) s√∫ v√Ωsledkom distrib√∫cie v√°≈°ho s√∫boru √∫dajov.
* Rozhodn√∫≈•, v ktor√Ωch oblastiach zbiera≈• viac √∫dajov na zmiernenie ch√Ωb sp√¥soben√Ωch probl√©mami s reprezent√°ciou, ≈°umom v oznaƒçen√≠, ≈°umom vo vlastnostiach, predsudkami v oznaƒçen√≠ a podobn√Ωmi faktormi.

## Interpret√°cia modelu

Modely strojov√©ho uƒçenia maj√∫ tendenciu by≈• ƒçiernymi skrinkami. Pochopenie, ktor√© kƒæ√∫ƒçov√© vlastnosti √∫dajov ovplyv≈àuj√∫ predikciu modelu, m√¥≈æe by≈• n√°roƒçn√©. Je d√¥le≈æit√© poskytn√∫≈• transparentnos≈•, preƒço model rob√≠ urƒçit√∫ predikciu. Napr√≠klad, ak AI syst√©m predikuje, ≈æe diabetick√Ω pacient je ohrozen√Ω op√§tovn√Ωm prijat√≠m do nemocnice do 30 dn√≠, mal by by≈• schopn√Ω poskytn√∫≈• podporn√© √∫daje, ktor√© viedli k jeho predikcii. Ma≈• podporn√© indik√°tory √∫dajov prin√°≈°a transparentnos≈•, ktor√° pom√°ha klinik√°m alebo nemocniciam robi≈• dobre informovan√© rozhodnutia. Okrem toho schopnos≈• vysvetli≈•, preƒço model urobil predikciu pre konkr√©tneho pacienta, umo≈æ≈àuje zodpovednos≈• voƒçi zdravotn√Ωm regul√°ci√°m. Keƒè pou≈æ√≠vate modely strojov√©ho uƒçenia sp√¥sobmi, ktor√© ovplyv≈àuj√∫ ≈æivoty ƒæud√≠, je nevyhnutn√© pochopi≈• a vysvetli≈•, ƒço ovplyv≈àuje spr√°vanie modelu. Vysvetliteƒænos≈• a interpret√°cia modelu pom√°ha odpoveda≈• na ot√°zky v scen√°roch, ako s√∫:

* Ladenie modelu: Preƒço m√¥j model urobil t√∫to chybu? Ako m√¥≈æem zlep≈°i≈• svoj model?
* Spolupr√°ca ƒçlovek-AI: Ako m√¥≈æem pochopi≈• a d√¥verova≈• rozhodnutiam modelu?
* Regul√°cia: Spƒ∫≈àa m√¥j model pr√°vne po≈æiadavky?

Komponent D√¥le≈æitos≈• vlastnost√≠ na RAI dashboarde v√°m pom√°ha ladi≈• a z√≠ska≈• komplexn√© pochopenie toho, ako model rob√≠ predikcie. Je to tie≈æ u≈æitoƒçn√Ω n√°stroj pre profesion√°lov v oblasti strojov√©ho uƒçenia a rozhodovac√≠ch ƒçiniteƒæov na vysvetlenie a uk√°zanie d√¥kazov vlastnost√≠ ovplyv≈àuj√∫cich spr√°vanie modelu pre regul√°ciu. Pou≈æ√≠vatelia m√¥≈æu ƒèalej sk√∫ma≈• glob√°lne aj lok√°lne vysvetlenia na valid√°ciu, ktor√© vlastnosti ovplyv≈àuj√∫ predikciu modelu. Glob√°lne vysvetlenia uv√°dzaj√∫ najd√¥le≈æitej≈°ie vlastnosti, ktor√© ovplyvnili celkov√∫ predikciu modelu. Lok√°lne vysvetlenia zobrazuj√∫, ktor√© vlastnosti viedli k predikcii modelu pre konkr√©tny pr√≠pad. Schopnos≈• hodnoti≈• lok√°lne vysvetlenia je tie≈æ u≈æitoƒçn√° pri laden√≠ alebo audite konkr√©tneho pr√≠padu na lep≈°ie pochopenie a interpret√°ciu, preƒço model urobil presn√∫ alebo nepresn√∫ predikciu.

![Komponent D√¥le≈æitos≈• vlastnost√≠ na RAI dashboarde](../../../../9-Real-World/2-Debugging-ML-Models/images/9-feature-importance.png)

* Glob√°lne vysvetlenia: Napr√≠klad, ktor√© vlastnosti ovplyv≈àuj√∫ celkov√© spr√°vanie modelu na op√§tovn√© prijatie diabetick√Ωch pacientov do nemocnice?
* Lok√°lne vysvetlenia: Napr√≠klad, preƒço bol diabetick√Ω pacient nad 60 rokov s predch√°dzaj√∫cimi hospitaliz√°ciami predikovan√Ω na op√§tovn√© prijatie alebo neprijatie do nemocnice do 30 dn√≠?

V procese ladenia v√Ωkonu modelu medzi r√¥znymi kohortami D√¥le≈æitos≈• vlastnost√≠ ukazuje, ak√Ω vplyv m√° vlastnos≈• na kohorty. Pom√°ha odhali≈• anom√°lie pri porovn√°van√≠ √∫rovne vplyvu vlastnosti na chybn√∫ predikciu modelu. Komponent D√¥le≈æitos≈• vlastnost√≠ m√¥≈æe uk√°za≈•, ktor√©
- **Nadmern√© alebo nedostatoƒçn√© zast√∫penie**. Ide o to, ≈æe urƒçit√° skupina nie je viditeƒæn√° v urƒçitej profesii, a ak√°koƒævek slu≈æba alebo funkcia, ktor√° to naƒèalej podporuje, prispieva k ≈°kod√°m.

### Azure RAI dashboard

[Azure RAI dashboard](https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai-dashboard?WT.mc_id=aiml-90525-ruyakubu) je postaven√Ω na open-source n√°strojoch vyvinut√Ωch popredn√Ωmi akademick√Ωmi in≈°tit√∫ciami a organiz√°ciami vr√°tane Microsoftu, ktor√© s√∫ nevyhnutn√© pre d√°tov√Ωch vedcov a v√Ωvoj√°rov AI na lep≈°ie pochopenie spr√°vania modelov, objavovanie a zmier≈àovanie ne≈æiaducich probl√©mov z AI modelov.

- Nauƒçte sa, ako pou≈æ√≠va≈• r√¥zne komponenty, preƒç√≠tan√≠m dokument√°cie k RAI dashboardu [docs.](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-responsible-ai-dashboard?WT.mc_id=aiml-90525-ruyakubu)

- Pozrite si niektor√© [uk√°≈ækov√© notebooky RAI dashboardu](https://github.com/Azure/RAI-vNext-Preview/tree/main/examples/notebooks) na ladenie zodpovednej≈°√≠ch AI scen√°rov v Azure Machine Learning.

---
## üöÄ V√Ωzva

Aby sme zabr√°nili zav√°dzaniu ≈°tatistick√Ωch alebo d√°tov√Ωch predsudkov u≈æ na zaƒçiatku, mali by sme:

- zabezpeƒçi≈• rozmanitos≈• pozad√≠ a perspekt√≠v medzi ƒæuƒèmi pracuj√∫cimi na syst√©moch
- investova≈• do datasetov, ktor√© odr√°≈æaj√∫ rozmanitos≈• na≈°ej spoloƒçnosti
- vyv√≠ja≈• lep≈°ie met√≥dy na detekciu a opravu predsudkov, keƒè sa objavia

Prem√Ω≈°ƒæajte o re√°lnych situ√°ci√°ch, kde je nespravodlivos≈• evidentn√° pri budovan√≠ a pou≈æ√≠van√≠ modelov. ƒåo ƒèal≈°ie by sme mali zv√°≈æi≈•?

## [Kv√≠z po predn√°≈°ke](https://ff-quizzes.netlify.app/en/ml/)
## Prehƒæad a samostatn√© ≈°t√∫dium

V tejto lekcii ste sa nauƒçili niektor√© praktick√© n√°stroje na zaƒçlenenie zodpovednej AI do strojov√©ho uƒçenia.

Pozrite si tento workshop, aby ste sa hlb≈°ie ponorili do t√©m:

- Responsible AI Dashboard: Jednotn√© miesto na operacionaliz√°ciu RAI v praxi od Besmiry Nushi a Mehrnoosh Sameki

[![Responsible AI Dashboard: Jednotn√© miesto na operacionaliz√°ciu RAI v praxi](https://img.youtube.com/vi/f1oaDNl3djg/0.jpg)](https://www.youtube.com/watch?v=f1oaDNl3djg "Responsible AI Dashboard: Jednotn√© miesto na operacionaliz√°ciu RAI v praxi")

> üé• Kliknite na obr√°zok vy≈°≈°ie pre video: Responsible AI Dashboard: Jednotn√© miesto na operacionaliz√°ciu RAI v praxi od Besmiry Nushi a Mehrnoosh Sameki

Odk√°≈æte na nasleduj√∫ce materi√°ly, aby ste sa dozvedeli viac o zodpovednej AI a o tom, ako budova≈• d√¥veryhodnej≈°ie modely:

- Microsoftove n√°stroje RAI dashboardu na ladenie ML modelov: [Responsible AI tools resources](https://aka.ms/rai-dashboard)

- Presk√∫majte Responsible AI toolkit: [Github](https://github.com/microsoft/responsible-ai-toolbox)

- Microsoftove centrum zdrojov RAI: [Responsible AI Resources ‚Äì Microsoft AI](https://www.microsoft.com/ai/responsible-ai-resources?activetab=pivot1%3aprimaryr4)

- Microsoftova v√Ωskumn√° skupina FATE: [FATE: Fairness, Accountability, Transparency, and Ethics in AI - Microsoft Research](https://www.microsoft.com/research/theme/fate/)

## Zadanie

[Presk√∫majte RAI dashboard](assignment.md)

---

**Upozornenie**:  
Tento dokument bol prelo≈æen√Ω pomocou slu≈æby na automatick√Ω preklad [Co-op Translator](https://github.com/Azure/co-op-translator). Aj keƒè sa sna≈æ√≠me o presnos≈•, upozor≈àujeme, ≈æe automatick√© preklady m√¥≈æu obsahova≈• chyby alebo nepresnosti. P√¥vodn√Ω dokument v jeho p√¥vodnom jazyku by mal by≈• pova≈æovan√Ω za autoritat√≠vny zdroj. Pre d√¥le≈æit√© inform√°cie sa odpor√∫ƒça profesion√°lny ƒæudsk√Ω preklad. Nezodpoved√°me za ak√©koƒævek nedorozumenia alebo nespr√°vne interpret√°cie vypl√Ωvaj√∫ce z pou≈æitia tohto prekladu.