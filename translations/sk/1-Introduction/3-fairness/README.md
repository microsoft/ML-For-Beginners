<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "9a6b702d1437c0467e3c5c28d763dac2",
  "translation_date": "2025-09-05T16:00:41+00:00",
  "source_file": "1-Introduction/3-fairness/README.md",
  "language_code": "sk"
}
-->
# Budovanie rie≈°en√≠ strojov√©ho uƒçenia s d√¥razom na zodpovedn√∫ AI

![Zhrnutie zodpovednej AI v strojovom uƒçen√≠ v sketchnote](../../../../sketchnotes/ml-fairness.png)
> Sketchnote od [Tomomi Imura](https://www.twitter.com/girlie_mac)

## [Kv√≠z pred predn√°≈°kou](https://ff-quizzes.netlify.app/en/ml/)

## √övod

V tomto kurze zaƒçnete objavova≈•, ako strojov√© uƒçenie ovplyv≈àuje na≈°e ka≈ædodenn√© ≈æivoty. U≈æ teraz s√∫ syst√©my a modely zapojen√© do rozhodovac√≠ch √∫loh, ako s√∫ diagnostika v zdravotn√≠ctve, schvaƒæovanie √∫verov alebo odhaƒæovanie podvodov. Preto je d√¥le≈æit√©, aby tieto modely fungovali spoƒæahlivo a poskytovali d√¥veryhodn√© v√Ωsledky. Rovnako ako ak√°koƒævek softv√©rov√° aplik√°cia, aj syst√©my AI m√¥≈æu zlyha≈• alebo ma≈• ne≈æiaduci v√Ωsledok. Preto je nevyhnutn√© rozumie≈• a vedie≈• vysvetli≈• spr√°vanie modelu AI.

Predstavte si, ƒço sa m√¥≈æe sta≈•, keƒè √∫daje, ktor√© pou≈æ√≠vate na vytvorenie t√Ωchto modelov, neobsahuj√∫ urƒçit√© demografick√© skupiny, ako s√∫ rasa, pohlavie, politick√© n√°zory, n√°bo≈æenstvo, alebo ich neprimerane zastupuj√∫. ƒåo ak je v√Ωstup modelu interpretovan√Ω tak, ≈æe uprednost≈àuje urƒçit√∫ demografick√∫ skupinu? Ak√© s√∫ d√¥sledky pre aplik√°ciu? A ƒço sa stane, keƒè model m√° nepriazniv√Ω v√Ωsledok a je ≈°kodliv√Ω pre ƒæud√≠? Kto je zodpovedn√Ω za spr√°vanie syst√©mu AI? Toto s√∫ niektor√© ot√°zky, ktor√© budeme sk√∫ma≈• v tomto kurze.

V tejto lekcii sa nauƒç√≠te:

- Zv√Ω≈°i≈• povedomie o d√¥le≈æitosti spravodlivosti v strojovom uƒçen√≠ a o ≈°kod√°ch s√∫visiacich so spravodlivos≈•ou.
- Obozn√°mi≈• sa s praxou sk√∫mania odch√Ωlok a neobvykl√Ωch scen√°rov na zabezpeƒçenie spoƒæahlivosti a bezpeƒçnosti.
- Z√≠ska≈• pochopenie potreby posilni≈• v≈°etk√Ωch prostredn√≠ctvom navrhovania inkluz√≠vnych syst√©mov.
- Presk√∫ma≈•, ak√© d√¥le≈æit√© je chr√°ni≈• s√∫kromie a bezpeƒçnos≈• √∫dajov a ƒæud√≠.
- Vidie≈• v√Ωznam pr√≠stupu ‚Äûsklenen√° krabica‚Äú na vysvetlenie spr√°vania modelov AI.
- By≈• si vedom√Ω toho, ako je zodpovednos≈• kƒæ√∫ƒçov√° pre budovanie d√¥very v syst√©my AI.

## Predpoklad

Ako predpoklad si pros√≠m pre≈°tudujte ‚ÄûZ√°sady zodpovednej AI‚Äú v r√°mci uƒçebnej cesty a pozrite si nasleduj√∫ce video na t√∫to t√©mu:

Viac o zodpovednej AI sa dozviete na tejto [uƒçebnej ceste](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77952-leestott).

[![Pr√≠stup Microsoftu k zodpovednej AI](https://img.youtube.com/vi/dnC8-uUZXSc/0.jpg)](https://youtu.be/dnC8-uUZXSc "Pr√≠stup Microsoftu k zodpovednej AI")

> üé• Kliknite na obr√°zok vy≈°≈°ie pre video: Pr√≠stup Microsoftu k zodpovednej AI

## Spravodlivos≈•

Syst√©my AI by mali zaobch√°dza≈• so v≈°etk√Ωmi spravodlivo a vyhn√∫≈• sa tomu, aby ovplyv≈àovali podobn√© skupiny ƒæud√≠ r√¥znymi sp√¥sobmi. Napr√≠klad, keƒè syst√©my AI poskytuj√∫ odpor√∫ƒçania t√Ωkaj√∫ce sa lek√°rskej lieƒçby, ≈æiadost√≠ o √∫ver alebo zamestnania, mali by robi≈• rovnak√© odpor√∫ƒçania v≈°etk√Ωm s podobn√Ωmi sympt√≥mami, finanƒçn√Ωmi okolnos≈•ami alebo odborn√Ωmi kvalifik√°ciami. Ka≈æd√Ω z n√°s ako ƒçlovek nesie vroden√© predsudky, ktor√© ovplyv≈àuj√∫ na≈°e rozhodnutia a ƒçiny. Tieto predsudky m√¥≈æu by≈• zjavn√© v √∫dajoch, ktor√© pou≈æ√≠vame na tr√©novanie syst√©mov AI. Tak√°to manipul√°cia sa niekedy m√¥≈æe sta≈• ne√∫myselne. ƒåasto je ≈•a≈æk√© vedome rozpozna≈•, kedy do √∫dajov zav√°dzame predsudky.

**‚ÄûNespravodlivos≈•‚Äú** zah≈ï≈àa negat√≠vne dopady alebo ‚Äû≈°kody‚Äú na skupinu ƒæud√≠, ako s√∫ t√≠ definovan√≠ podƒæa rasy, pohlavia, veku alebo zdravotn√©ho postihnutia. Hlavn√© ≈°kody s√∫visiace so spravodlivos≈•ou mo≈æno klasifikova≈• ako:

- **Alok√°cia**, ak je napr√≠klad uprednostnen√© jedno pohlavie alebo etnick√° skupina pred druhou.
- **Kvalita slu≈æby**. Ak tr√©nujete √∫daje pre jeden konkr√©tny scen√°r, ale realita je oveƒæa zlo≈æitej≈°ia, vedie to k zle funguj√∫cej slu≈æbe. Napr√≠klad d√°vkovaƒç mydla, ktor√Ω nedok√°zal rozpozna≈• ƒæud√≠ s tmavou poko≈ækou. [Referencie](https://gizmodo.com/why-cant-this-soap-dispenser-identify-dark-skin-1797931773)
- **Oƒçier≈àovanie**. Nespravodliv√© kritizovanie a oznaƒçovanie nieƒçoho alebo niekoho. Napr√≠klad technol√≥gia oznaƒçovania obr√°zkov nesl√°vne oznaƒçila obr√°zky ƒæud√≠ s tmavou poko≈ækou ako gorily.
- **Nadmern√© alebo nedostatoƒçn√© zast√∫penie**. My≈°lienka, ≈æe urƒçit√° skupina nie je viditeƒæn√° v urƒçitom povolan√≠, a ak√°koƒævek slu≈æba alebo funkcia, ktor√° to naƒèalej podporuje, prispieva k ≈°kode.
- **Stereotypiz√°cia**. Priraƒèovanie preddefinovan√Ωch atrib√∫tov urƒçitej skupine. Napr√≠klad syst√©m prekladu medzi angliƒçtinou a tureƒçtinou m√¥≈æe ma≈• nepresnosti kv√¥li slov√°m so stereotypn√Ωmi asoci√°ciami k pohlaviu.

![preklad do tureƒçtiny](../../../../1-Introduction/3-fairness/images/gender-bias-translate-en-tr.png)
> preklad do tureƒçtiny

![preklad sp√§≈• do angliƒçtiny](../../../../1-Introduction/3-fairness/images/gender-bias-translate-tr-en.png)
> preklad sp√§≈• do angliƒçtiny

Pri navrhovan√≠ a testovan√≠ syst√©mov AI mus√≠me zabezpeƒçi≈•, ≈æe AI je spravodliv√° a nie je naprogramovan√° na prij√≠manie zaujat√Ωch alebo diskriminaƒçn√Ωch rozhodnut√≠, ktor√© s√∫ zak√°zan√© aj pre ƒæud√≠. Zaruƒçenie spravodlivosti v AI a strojovom uƒçen√≠ zost√°va komplexnou sociotechnickou v√Ωzvou.

### Spoƒæahlivos≈• a bezpeƒçnos≈•

Na budovanie d√¥very musia by≈• syst√©my AI spoƒæahliv√©, bezpeƒçn√© a konzistentn√© za norm√°lnych aj neoƒçak√°van√Ωch podmienok. Je d√¥le≈æit√© vedie≈•, ako sa syst√©my AI bud√∫ spr√°va≈• v r√¥znych situ√°ci√°ch, najm√§ keƒè ide o odch√Ωlky. Pri budovan√≠ rie≈°en√≠ AI je potrebn√© venova≈• znaƒçn√∫ pozornos≈• tomu, ako zvl√°dnu≈• ≈°irok√∫ ≈°k√°lu okolnost√≠, s ktor√Ωmi sa rie≈°enia AI m√¥≈æu stretn√∫≈•. Napr√≠klad auton√≥mne auto mus√≠ kl√°s≈• bezpeƒçnos≈• ƒæud√≠ na prv√© miesto. V√Ωsledkom je, ≈æe AI poh√°≈àaj√∫ca auto mus√≠ zohƒæadni≈• v≈°etky mo≈æn√© scen√°re, s ktor√Ωmi sa auto m√¥≈æe stretn√∫≈•, ako s√∫ noc, b√∫rky alebo snehov√© b√∫rky, deti be≈æiace cez ulicu, dom√°ce zvierat√°, cestn√© pr√°ce atƒè. To, ako dobre syst√©m AI dok√°≈æe spoƒæahlivo a bezpeƒçne zvl√°dnu≈• ≈°irok√∫ ≈°k√°lu podmienok, odr√°≈æa √∫rove≈à predv√≠davosti, ktor√∫ d√°tov√Ω vedec alebo v√Ωvoj√°r AI zohƒæadnil poƒças n√°vrhu alebo testovania syst√©mu.

> [üé• Kliknite sem pre video: ](https://www.microsoft.com/videoplayer/embed/RE4vvIl)

### Inkluz√≠vnos≈•

Syst√©my AI by mali by≈• navrhnut√© tak, aby zap√°jali a posil≈àovali ka≈æd√©ho. Pri navrhovan√≠ a implement√°cii syst√©mov AI d√°tov√≠ vedci a v√Ωvoj√°ri AI identifikuj√∫ a rie≈°ia potenci√°lne bari√©ry v syst√©me, ktor√© by mohli ne√∫myselne vyl√∫ƒçi≈• ƒæud√≠. Napr√≠klad na svete je 1 miliarda ƒæud√≠ so zdravotn√Ωm postihnut√≠m. Vƒèaka pokroku v AI m√¥≈æu ƒæah≈°ie pristupova≈• k ≈°irok√©mu spektru inform√°ci√≠ a pr√≠le≈æitost√≠ vo svojom ka≈ædodennom ≈æivote. Rie≈°en√≠m bari√©r sa vytv√°raj√∫ pr√≠le≈æitosti na inov√°cie a v√Ωvoj produktov AI s lep≈°√≠mi sk√∫senos≈•ami, ktor√© prospievaj√∫ v≈°etk√Ωm.

> [üé• Kliknite sem pre video: inkluz√≠vnos≈• v AI](https://www.microsoft.com/videoplayer/embed/RE4vl9v)

### Bezpeƒçnos≈• a s√∫kromie

Syst√©my AI by mali by≈• bezpeƒçn√© a re≈°pektova≈• s√∫kromie ƒæud√≠. ƒΩudia maj√∫ men≈°iu d√¥veru v syst√©my, ktor√© ohrozuj√∫ ich s√∫kromie, inform√°cie alebo ≈æivoty. Pri tr√©novan√≠ modelov strojov√©ho uƒçenia sa spoliehame na √∫daje, aby sme dosiahli ƒço najlep≈°ie v√Ωsledky. Pri tom je potrebn√© zv√°≈æi≈• p√¥vod √∫dajov a ich integritu. Napr√≠klad, boli √∫daje poskytnut√© pou≈æ√≠vateƒæom alebo verejne dostupn√©? ƒéalej, pri pr√°ci s √∫dajmi je nevyhnutn√© vyv√≠ja≈• syst√©my AI, ktor√© dok√°≈æu chr√°ni≈• d√¥vern√© inform√°cie a odol√°va≈• √∫tokom. Ako sa AI st√°va roz≈°√≠renej≈°ou, ochrana s√∫kromia a zabezpeƒçenie d√¥le≈æit√Ωch osobn√Ωch a obchodn√Ωch inform√°ci√≠ sa st√°va ƒçoraz kritickej≈°ou a zlo≈æitej≈°ou. Probl√©my so s√∫krom√≠m a bezpeƒçnos≈•ou √∫dajov si vy≈æaduj√∫ obzvl√°≈°≈• d√¥kladn√∫ pozornos≈• pri AI, preto≈æe pr√≠stup k √∫dajom je nevyhnutn√Ω na to, aby syst√©my AI mohli robi≈• presn√© a informovan√© predpovede a rozhodnutia o ƒæuƒèoch.

> [üé• Kliknite sem pre video: bezpeƒçnos≈• v AI](https://www.microsoft.com/videoplayer/embed/RE4voJF)

- Ako odvetvie sme dosiahli v√Ωznamn√Ω pokrok v oblasti s√∫kromia a bezpeƒçnosti, v√Ωrazne podporen√Ω regul√°ciami, ako je GDPR (V≈°eobecn√© nariadenie o ochrane √∫dajov).
- Napriek tomu mus√≠me pri syst√©moch AI uzna≈• nap√§tie medzi potrebou viac osobn√Ωch √∫dajov na zlep≈°enie syst√©mov a ochranou s√∫kromia.
- Rovnako ako pri vzniku pripojen√Ωch poƒç√≠taƒçov s internetom, zaznamen√°vame aj v√Ωrazn√Ω n√°rast poƒçtu bezpeƒçnostn√Ωch probl√©mov s√∫visiacich s AI.
- Z√°rove≈à sme videli, ≈æe AI sa pou≈æ√≠va na zlep≈°enie bezpeƒçnosti. Napr√≠klad v√§ƒç≈°ina modern√Ωch antiv√≠rusov√Ωch skenerov je dnes poh√°≈àan√° heuristikou AI.
- Mus√≠me zabezpeƒçi≈•, aby na≈°e procesy d√°tovej vedy harmonicky ladili s najnov≈°√≠mi praktikami v oblasti s√∫kromia a bezpeƒçnosti.

### Transparentnos≈•

Syst√©my AI by mali by≈• zrozumiteƒæn√©. Kƒæ√∫ƒçovou s√∫ƒças≈•ou transparentnosti je vysvetlenie spr√°vania syst√©mov AI a ich komponentov. Zlep≈°enie porozumenia syst√©mom AI si vy≈æaduje, aby zainteresovan√© strany pochopili, ako a preƒço funguj√∫, aby mohli identifikova≈• potenci√°lne probl√©my s v√Ωkonom, obavy o bezpeƒçnos≈• a s√∫kromie, predsudky, vyluƒçuj√∫ce praktiky alebo ne√∫myseln√© v√Ωsledky. Ver√≠me tie≈æ, ≈æe t√≠, ktor√≠ pou≈æ√≠vaj√∫ syst√©my AI, by mali by≈• √∫primn√≠ a otvoren√≠ o tom, kedy, preƒço a ako sa rozhodn√∫ ich nasadi≈•. Rovnako ako o obmedzeniach syst√©mov, ktor√© pou≈æ√≠vaj√∫. Napr√≠klad, ak banka pou≈æ√≠va syst√©m AI na podporu svojich rozhodnut√≠ o poskytovan√≠ √∫verov, je d√¥le≈æit√© presk√∫ma≈• v√Ωsledky a pochopi≈•, ktor√© √∫daje ovplyv≈àuj√∫ odpor√∫ƒçania syst√©mu. Vl√°dy zaƒç√≠naj√∫ regulova≈• AI naprieƒç odvetviami, tak≈æe d√°tov√≠ vedci a organiz√°cie musia vysvetli≈•, ƒçi syst√©m AI spƒ∫≈àa regulaƒçn√© po≈æiadavky, najm√§ keƒè d√¥jde k ne≈æiaducemu v√Ωsledku.

> [üé• Kliknite sem pre video: transparentnos≈• v AI](https://www.microsoft.com/videoplayer/embed/RE4voJF)

- Keƒè≈æe syst√©my AI s√∫ veƒæmi komplexn√©, je ≈•a≈æk√© pochopi≈•, ako funguj√∫ a interpretova≈• v√Ωsledky.
- Tento nedostatok porozumenia ovplyv≈àuje sp√¥sob, ak√Ωm s√∫ tieto syst√©my spravovan√©, prev√°dzkovan√© a dokumentovan√©.
- Tento nedostatok porozumenia e≈°te d√¥le≈æitej≈°ie ovplyv≈àuje rozhodnutia prijat√© na z√°klade v√Ωsledkov, ktor√© tieto syst√©my produkuj√∫.

### Zodpovednos≈•

ƒΩudia, ktor√≠ navrhuj√∫ a nasadzuj√∫ syst√©my AI, musia by≈• zodpovedn√≠ za to, ako ich syst√©my funguj√∫. Potreba zodpovednosti je obzvl√°≈°≈• d√¥le≈æit√° pri technol√≥gi√°ch citliv√©ho pou≈æitia, ako je rozpozn√°vanie tv√°re. V poslednej dobe rastie dopyt po technol√≥gii rozpozn√°vania tv√°re, najm√§ zo strany org√°nov ƒçinn√Ωch v trestnom konan√≠, ktor√© vidia potenci√°l tejto technol√≥gie v aplik√°ci√°ch, ako je hƒæadanie nezvestn√Ωch det√≠. Tieto technol√≥gie v≈°ak m√¥≈æu by≈• potenci√°lne pou≈æit√© vl√°dou na ohrozenie z√°kladn√Ωch slob√¥d obƒçanov, napr√≠klad umo≈ænen√≠m nepretr≈æit√©ho sledovania konkr√©tnych jednotlivcov. Preto musia by≈• d√°tov√≠ vedci a organiz√°cie zodpovedn√≠ za to, ako ich syst√©m AI ovplyv≈àuje jednotlivcov alebo spoloƒçnos≈•.

[![Ved√∫ci v√Ωskumn√≠k AI varuje pred masov√Ωm sledovan√≠m prostredn√≠ctvom rozpozn√°vania tv√°re](../../../../1-Introduction/3-fairness/images/accountability.png)](https://www.youtube.com/watch?v=Wldt8P5V6D0 "Pr√≠stup Microsoftu k zodpovednej AI")

> üé• Kliknite na obr√°zok vy≈°≈°ie pre video: Varovania pred masov√Ωm sledovan√≠m prostredn√≠ctvom rozpozn√°vania tv√°re

Nakoniec jednou z najv√§ƒç≈°√≠ch ot√°zok na≈°ej gener√°cie, ako prvej gener√°cie, ktor√° prin√°≈°a AI do spoloƒçnosti, je, ako zabezpeƒçi≈•, aby poƒç√≠taƒçe zostali zodpovedn√© voƒçi ƒæuƒèom a ako zabezpeƒçi≈•, aby ƒæudia, ktor√≠ navrhuj√∫ poƒç√≠taƒçe, zostali zodpovedn√≠ voƒçi v≈°etk√Ωm ostatn√Ωm.

## Hodnotenie dopadu

Pred tr√©novan√≠m modelu strojov√©ho uƒçenia je d√¥le≈æit√© vykona≈• hodnotenie dopadu, aby ste pochopili √∫ƒçel syst√©mu AI; ak√© je jeho zam√Ω≈°ƒæan√© pou≈æitie; kde bude nasaden√Ω; a kto bude so syst√©mom interagova≈•. Tieto inform√°cie s√∫ u≈æitoƒçn√© pre recenzentov alebo testerov, ktor√≠ hodnotia syst√©m, aby vedeli, ak√© faktory treba zohƒæadni≈• pri identifik√°cii potenci√°lnych riz√≠k a oƒçak√°van√Ωch d√¥sledkov.

Nasleduj√∫ oblasti zamerania pri vykon√°van√≠ hodnotenia dopadu:

* **Nepriazniv√Ω dopad na jednotlivcov**. By≈• si vedom√Ω ak√Ωchkoƒævek obmedzen√≠ alebo po≈æiadaviek, nepodporovan√©ho pou≈æitia alebo ak√Ωchkoƒævek zn√°mych obmedzen√≠, ktor√© br√°nia v√Ωkonu syst√©mu, je z√°sadn√© na zabezpeƒçenie toho, aby syst√©m nebol pou≈æ√≠van√Ω sp√¥sobom, ktor√Ω by mohol sp√¥sobi≈• ≈°kodu jednotlivcom.
* **Po≈æiadavky na √∫daje**. Z√≠skanie pochopenia toho, ako a kde syst√©m bude pou≈æ√≠va≈• √∫daje, umo≈æ≈àuje recenzentom presk√∫ma≈• ak√©koƒævek po≈æiadavky na √∫daje, na ktor√© by ste mali by≈• pozorn√≠ (napr. GDPR alebo HIPPA regul√°cie √∫dajov). Okrem toho presk√∫majte, ƒçi je zdroj alebo mno≈æstvo √∫dajov dostatoƒçn√© na tr√©novanie.
* **Zhrnutie dopadu**. Zozbierajte zoznam potenci√°lnych ≈°k√¥d, ktor√© by mohli vznikn√∫≈• z pou≈æ√≠vania syst√©mu. Poƒças ≈æivotn√©ho cyklu ML presk√∫majte, ƒçi s√∫ identifikovan√© probl√©my zmiernen√© alebo rie≈°en√©.
* **Platn√© ciele** pre ka≈æd√∫ zo ≈°iestich z√°kladn√Ωch z√°sad. Pos√∫ƒète, ƒçi s√∫ ciele z ka≈ædej z√°sady splnen√© a ƒçi existuj√∫ nejak√© medzery.

## Ladenie so zodpovednou AI

Podobne ako ladenie softv√©rovej aplik√°cie, ladenie syst√©mu AI je nevyhnutn√Ω proces identifik√°cie a rie≈°enia probl√©mov v syst√©me. Existuje mnoho faktorov, ktor√© m√¥≈æu ovplyvni≈•, ≈æe model nefunguje podƒæa oƒçak√°van√≠ alebo zodpovedne. V√§ƒç≈°ina tradiƒçn√Ωch metr√≠k v√Ωkonu modelu s√∫ kvantitat√≠vne agreg√°ty v√Ωkonu modelu, ktor√© nie s√∫ dostatoƒçn√©
Pozrite si tento workshop, aby ste sa hlb≈°ie ponorili do t√©m:

- Na ceste k zodpovednej AI: Uplatnenie princ√≠pov v praxi od Besmiry Nushi, Mehrnoosh Sameki a Amita Sharmu

[![Responsible AI Toolbox: Open-source framework na budovanie zodpovednej AI](https://img.youtube.com/vi/tGgJCrA-MZU/0.jpg)](https://www.youtube.com/watch?v=tGgJCrA-MZU "RAI Toolbox: Open-source framework na budovanie zodpovednej AI")

> üé• Kliknite na obr√°zok vy≈°≈°ie pre video: RAI Toolbox: Open-source framework na budovanie zodpovednej AI od Besmiry Nushi, Mehrnoosh Sameki a Amita Sharmu

Preƒç√≠tajte si tie≈æ:

- Microsoftov zdrojov√Ω centrum pre zodpovedn√∫ AI: [Responsible AI Resources ‚Äì Microsoft AI](https://www.microsoft.com/ai/responsible-ai-resources?activetab=pivot1%3aprimaryr4)

- Microsoftova v√Ωskumn√° skupina FATE: [FATE: Fairness, Accountability, Transparency, and Ethics in AI - Microsoft Research](https://www.microsoft.com/research/theme/fate/)

RAI Toolbox:

- [GitHub repozit√°r Responsible AI Toolbox](https://github.com/microsoft/responsible-ai-toolbox)

Preƒç√≠tajte si o n√°strojoch Azure Machine Learning na zabezpeƒçenie spravodlivosti:

- [Azure Machine Learning](https://docs.microsoft.com/azure/machine-learning/concept-fairness-ml?WT.mc_id=academic-77952-leestott)

## Zadanie

[Presk√∫majte RAI Toolbox](assignment.md)

---

**Zrieknutie sa zodpovednosti**:  
Tento dokument bol prelo≈æen√Ω pomocou slu≈æby AI prekladu [Co-op Translator](https://github.com/Azure/co-op-translator). Aj keƒè sa sna≈æ√≠me o presnos≈•, pros√≠m, berte na vedomie, ≈æe automatizovan√© preklady m√¥≈æu obsahova≈• chyby alebo nepresnosti. P√¥vodn√Ω dokument v jeho rodnom jazyku by mal by≈• pova≈æovan√Ω za autoritat√≠vny zdroj. Pre kritick√© inform√°cie sa odpor√∫ƒça profesion√°lny ƒæudsk√Ω preklad. Nenesieme zodpovednos≈• za ak√©koƒævek nedorozumenia alebo nespr√°vne interpret√°cie vypl√Ωvaj√∫ce z pou≈æitia tohto prekladu.