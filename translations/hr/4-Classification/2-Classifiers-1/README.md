<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1a6e9e46b34a2e559fbbfc1f95397c7b",
  "translation_date": "2025-09-05T13:04:51+00:00",
  "source_file": "4-Classification/2-Classifiers-1/README.md",
  "language_code": "hr"
}
-->
# Klasifikatori kuhinja 1

U ovoj lekciji koristit Ä‡ete skup podataka koji ste spremili iz prethodne lekcije, pun uravnoteÅ¾enih i oÄiÅ¡Ä‡enih podataka o kuhinjama.

Koristit Ä‡ete ovaj skup podataka s raznim klasifikatorima kako biste _predvidjeli odreÄ‘enu nacionalnu kuhinju na temelju grupe sastojaka_. Dok to radite, nauÄit Ä‡ete viÅ¡e o naÄinima na koje se algoritmi mogu koristiti za zadatke klasifikacije.

## [Kviz prije predavanja](https://ff-quizzes.netlify.app/en/ml/)
# Priprema

Pod pretpostavkom da ste zavrÅ¡ili [Lekciju 1](../1-Introduction/README.md), provjerite postoji li datoteka _cleaned_cuisines.csv_ u korijenskoj mapi `/data` za ove Äetiri lekcije.

## VjeÅ¾ba - predviÄ‘anje nacionalne kuhinje

1. Radite u mapi _notebook.ipynb_ ove lekcije i uvezite tu datoteku zajedno s Pandas bibliotekom:

    ```python
    import pandas as pd
    cuisines_df = pd.read_csv("../data/cleaned_cuisines.csv")
    cuisines_df.head()
    ```

    Podaci izgledaju ovako:

|     | Unnamed: 0 | cuisine | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood | yam | yeast | yogurt | zucchini |
| --- | ---------- | ------- | ------ | -------- | ----- | ---------- | ----- | ------------ | ------- | -------- | --- | ------- | ----------- | ---------- | ----------------------- | ---- | ---- | --- | ----- | ------ | -------- |
| 0   | 0          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 1   | 1          | indian  | 1      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 2   | 2          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 3   | 3          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 4   | 4          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 1      | 0        |
  

1. Sada uvezite joÅ¡ nekoliko biblioteka:

    ```python
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    from sklearn.svm import SVC
    import numpy as np
    ```

1. Podijelite X i y koordinate u dva dataframea za treniranje. `cuisine` moÅ¾e biti dataframe s oznakama:

    ```python
    cuisines_label_df = cuisines_df['cuisine']
    cuisines_label_df.head()
    ```

    Izgledat Ä‡e ovako:

    ```output
    0    indian
    1    indian
    2    indian
    3    indian
    4    indian
    Name: cuisine, dtype: object
    ```

1. Izbacite stupce `Unnamed: 0` i `cuisine` koristeÄ‡i `drop()`. Ostatak podataka spremite kao znaÄajke za treniranje:

    ```python
    cuisines_feature_df = cuisines_df.drop(['Unnamed: 0', 'cuisine'], axis=1)
    cuisines_feature_df.head()
    ```

    VaÅ¡e znaÄajke izgledaju ovako:

|      | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | artemisia | artichoke |  ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood |  yam | yeast | yogurt | zucchini |
| ---: | -----: | -------: | ----: | ---------: | ----: | -----------: | ------: | -------: | --------: | --------: | ---: | ------: | ----------: | ---------: | ----------------------: | ---: | ---: | ---: | ----: | -----: | -------: |
|    0 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    1 |      1 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    2 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    3 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    4 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      1 |        0 | 0 |

Sada ste spremni za treniranje modela!

## Odabir klasifikatora

Sada kada su vaÅ¡i podaci oÄiÅ¡Ä‡eni i spremni za treniranje, morate odluÄiti koji algoritam koristiti za zadatak.

Scikit-learn grupira klasifikaciju pod Nadzirano uÄenje, a u toj kategoriji postoji mnogo naÄina za klasifikaciju. [Raznolikost](https://scikit-learn.org/stable/supervised_learning.html) moÅ¾e na prvi pogled djelovati zbunjujuÄ‡e. SljedeÄ‡e metode ukljuÄuju tehnike klasifikacije:

- Linearni modeli
- Strojevi za potporne vektore (SVM)
- StohastiÄki gradijentni spust
- NajbliÅ¾i susjedi
- Gaussovi procesi
- Stabla odluke
- Metode ansambla (glasajuÄ‡i klasifikator)
- ViÅ¡eklasni i viÅ¡erezultatski algoritmi (viÅ¡eklasna i viÅ¡eznaÄna klasifikacija, viÅ¡eklasna-viÅ¡erezultatska klasifikacija)

> TakoÄ‘er moÅ¾ete koristiti [neuronske mreÅ¾e za klasifikaciju podataka](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#classification), ali to je izvan opsega ove lekcije.

### Koji klasifikator odabrati?

Dakle, koji klasifikator odabrati? ÄŒesto je korisno isprobati nekoliko njih i traÅ¾iti dobar rezultat. Scikit-learn nudi [usporedbu](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) na stvorenom skupu podataka, usporeÄ‘ujuÄ‡i KNeighbors, SVC na dva naÄina, GaussianProcessClassifier, DecisionTreeClassifier, RandomForestClassifier, MLPClassifier, AdaBoostClassifier, GaussianNB i QuadraticDiscriminationAnalysis, prikazujuÄ‡i rezultate vizualno:

![usporedba klasifikatora](../../../../4-Classification/2-Classifiers-1/images/comparison.png)
> Grafovi generirani u dokumentaciji Scikit-learn-a

> AutoML rjeÅ¡ava ovaj problem jednostavno pokretanjem ovih usporedbi u oblaku, omoguÄ‡ujuÄ‡i vam odabir najboljeg algoritma za vaÅ¡e podatke. Isprobajte [ovdje](https://docs.microsoft.com/learn/modules/automate-model-selection-with-azure-automl/?WT.mc_id=academic-77952-leestott)

### Bolji pristup

Bolji naÄin od nasumiÄnog pogaÄ‘anja je slijediti ideje iz ovog preuzimljivog [ML Cheat Sheeta](https://docs.microsoft.com/azure/machine-learning/algorithm-cheat-sheet?WT.mc_id=academic-77952-leestott). Ovdje otkrivamo da za naÅ¡ viÅ¡eklasni problem imamo nekoliko izbora:

![cheatsheet za viÅ¡eklasne probleme](../../../../4-Classification/2-Classifiers-1/images/cheatsheet.png)
> Dio Microsoftovog Algorithm Cheat Sheeta, koji detaljno opisuje opcije za viÅ¡eklasnu klasifikaciju

âœ… Preuzmite ovaj cheat sheet, isprintajte ga i objesite na zid!

### RazmiÅ¡ljanje

PokuÅ¡ajmo razmotriti razliÄite pristupe s obzirom na ograniÄenja koja imamo:

- **Neuronske mreÅ¾e su preteÅ¡ke**. S obzirom na naÅ¡ oÄiÅ¡Ä‡eni, ali minimalni skup podataka i Äinjenicu da treniranje provodimo lokalno putem biljeÅ¾nica, neuronske mreÅ¾e su preteÅ¡ke za ovaj zadatak.
- **Nema klasifikatora za dvije klase**. Ne koristimo klasifikator za dvije klase, Å¡to iskljuÄuje one-vs-all.
- **Stablo odluke ili logistiÄka regresija mogli bi raditi**. Stablo odluke moglo bi raditi, kao i logistiÄka regresija za viÅ¡eklasne podatke.
- **ViÅ¡eklasna Boosted Decision Trees rjeÅ¡ava drugi problem**. ViÅ¡eklasno pojaÄano stablo odluke najprikladnije je za neparametarske zadatke, npr. zadatke dizajnirane za izradu rangiranja, pa nam nije korisno.

### KoriÅ¡tenje Scikit-learn-a

Koristit Ä‡emo Scikit-learn za analizu naÅ¡ih podataka. MeÄ‘utim, postoji mnogo naÄina za koriÅ¡tenje logistiÄke regresije u Scikit-learn-u. Pogledajte [parametre za prosljeÄ‘ivanje](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regressio#sklearn.linear_model.LogisticRegression).  

U osnovi, postoje dva vaÅ¾na parametra - `multi_class` i `solver` - koje trebamo specificirati kada traÅ¾imo od Scikit-learn-a da izvede logistiÄku regresiju. Vrijednost `multi_class` primjenjuje odreÄ‘eno ponaÅ¡anje. Vrijednost solvera odreÄ‘uje koji algoritam koristiti. Nisu svi solveri kompatibilni sa svim vrijednostima `multi_class`.

Prema dokumentaciji, u sluÄaju viÅ¡eklasne klasifikacije, algoritam treniranja:

- **Koristi shemu one-vs-rest (OvR)**, ako je opcija `multi_class` postavljena na `ovr`
- **Koristi gubitak unakrsne entropije**, ako je opcija `multi_class` postavljena na `multinomial`. (Trenutno opciju `multinomial` podrÅ¾avaju samo solveri â€˜lbfgsâ€™, â€˜sagâ€™, â€˜sagaâ€™ i â€˜newton-cgâ€™.)

> ğŸ“ 'Shema' ovdje moÅ¾e biti 'ovr' (one-vs-rest) ili 'multinomial'. BuduÄ‡i da je logistiÄka regresija zapravo dizajnirana za podrÅ¡ku binarnoj klasifikaciji, ove sheme omoguÄ‡uju joj bolje rukovanje zadacima viÅ¡eklasne klasifikacije. [izvor](https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/)

> ğŸ“ 'Solver' je definiran kao "algoritam koji se koristi u problemu optimizacije". [izvor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regressio#sklearn.linear_model.LogisticRegression).

Scikit-learn nudi ovu tablicu kako bi objasnio kako solveri rjeÅ¡avaju razliÄite izazove koje predstavljaju razliÄite vrste struktura podataka:

![solvers](../../../../4-Classification/2-Classifiers-1/images/solvers.png)

## VjeÅ¾ba - podjela podataka

MoÅ¾emo se usredotoÄiti na logistiÄku regresiju za naÅ¡ prvi pokuÅ¡aj treniranja jer ste nedavno nauÄili o njoj u prethodnoj lekciji.
Podijelite svoje podatke u grupe za treniranje i testiranje pozivom `train_test_split()`:

```python
X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)
```

## VjeÅ¾ba - primjena logistiÄke regresije

BuduÄ‡i da koristite sluÄaj viÅ¡eklasne klasifikacije, trebate odabrati koju _shemu_ koristiti i koji _solver_ postaviti. Koristite LogisticRegression s viÅ¡eklasnim postavkama i **liblinear** solverom za treniranje.

1. Kreirajte logistiÄku regresiju s multi_class postavljenim na `ovr` i solverom postavljenim na `liblinear`:

    ```python
    lr = LogisticRegression(multi_class='ovr',solver='liblinear')
    model = lr.fit(X_train, np.ravel(y_train))
    
    accuracy = model.score(X_test, y_test)
    print ("Accuracy is {}".format(accuracy))
    ```

    âœ… Isprobajte drugi solver poput `lbfgs`, koji je Äesto postavljen kao zadani
> Napomena, koristite Pandasovu funkciju [`ravel`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.ravel.html) za izravnavanje podataka kada je to potrebno.
ToÄnost je dobra, preko **80%**!

1. MoÅ¾ete vidjeti ovaj model u akciji testiranjem jednog retka podataka (#50):

    ```python
    print(f'ingredients: {X_test.iloc[50][X_test.iloc[50]!=0].keys()}')
    print(f'cuisine: {y_test.iloc[50]}')
    ```

    Rezultat se ispisuje:

   ```output
   ingredients: Index(['cilantro', 'onion', 'pea', 'potato', 'tomato', 'vegetable_oil'], dtype='object')
   cuisine: indian
   ```

   âœ… Isprobajte drugi broj retka i provjerite rezultate.

1. Ako Å¾elite dublje istraÅ¾iti, moÅ¾ete provjeriti toÄnost ove predikcije:

    ```python
    test= X_test.iloc[50].values.reshape(-1, 1).T
    proba = model.predict_proba(test)
    classes = model.classes_
    resultdf = pd.DataFrame(data=proba, columns=classes)
    
    topPrediction = resultdf.T.sort_values(by=[0], ascending = [False])
    topPrediction.head()
    ```

    Rezultat se ispisuje - Indijska kuhinja je najbolja pretpostavka, s dobrom vjerojatnoÅ¡Ä‡u:

    |          |        0 |
    | -------: | -------: |
    |   indian | 0.715851 |
    |  chinese | 0.229475 |
    | japanese | 0.029763 |
    |   korean | 0.017277 |
    |     thai | 0.007634 |

    âœ… MoÅ¾ete li objasniti zaÅ¡to je model priliÄno siguran da se radi o indijskoj kuhinji?

1. Dobijte viÅ¡e detalja ispisivanjem izvjeÅ¡taja o klasifikaciji, kao Å¡to ste radili u lekcijama o regresiji:

    ```python
    y_pred = model.predict(X_test)
    print(classification_report(y_test,y_pred))
    ```

    |              | preciznost | odziv | f1-rezultat | podrÅ¡ka |
    | ------------ | ---------- | ----- | ----------- | ------- |
    | chinese      | 0.73       | 0.71  | 0.72        | 229     |
    | indian       | 0.91       | 0.93  | 0.92        | 254     |
    | japanese     | 0.70       | 0.75  | 0.72        | 220     |
    | korean       | 0.86       | 0.76  | 0.81        | 242     |
    | thai         | 0.79       | 0.85  | 0.82        | 254     |
    | toÄnost      | 0.80       | 1199  |             |         |
    | prosjek makro| 0.80       | 0.80  | 0.80        | 1199    |
    | prosjek teÅ¾. | 0.80       | 0.80  | 0.80        | 1199    |

## ğŸš€Izazov

U ovoj lekciji koristili ste oÄiÅ¡Ä‡ene podatke za izradu modela strojnog uÄenja koji moÅ¾e predvidjeti nacionalnu kuhinju na temelju niza sastojaka. Odvojite malo vremena da prouÄite mnoge opcije koje Scikit-learn nudi za klasifikaciju podataka. Dublje istraÅ¾ite koncept 'solver' kako biste razumjeli Å¡to se dogaÄ‘a iza kulisa.

## [Kviz nakon predavanja](https://ff-quizzes.netlify.app/en/ml/)

## Pregled i samostalno uÄenje

Dublje istraÅ¾ite matematiku iza logistiÄke regresije u [ovoj lekciji](https://people.eecs.berkeley.edu/~russell/classes/cs194/f11/lectures/CS194%20Fall%202011%20Lecture%2006.pdf)
## Zadatak 

[ProuÄite solvere](assignment.md)

---

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden koriÅ¡tenjem AI usluge za prevoÄ‘enje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati toÄnost, imajte na umu da automatski prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati mjerodavnim izvorom. Za kljuÄne informacije preporuÄuje se profesionalni prijevod od strane struÄnjaka. Ne preuzimamo odgovornost za bilo kakva nesporazuma ili pogreÅ¡na tumaÄenja koja proizlaze iz koriÅ¡tenja ovog prijevoda.