<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20ca019012b1725de956681d036d8b18",
  "translation_date": "2025-09-05T13:31:55+00:00",
  "source_file": "8-Reinforcement/README.md",
  "language_code": "hr"
}
-->
# Uvod u uÄenje pojaÄanjem

UÄenje pojaÄanjem, RL, smatra se jednim od osnovnih paradigmi strojnog uÄenja, uz nadzirano i nenadzirano uÄenje. RL se bavi donoÅ¡enjem odluka: donoÅ¡enjem ispravnih odluka ili barem uÄenjem iz njih.

Zamislite da imate simulirano okruÅ¾enje poput burze. Å to se dogaÄ‘a ako uvedete odreÄ‘enu regulaciju? Ima li to pozitivan ili negativan uÄinak? Ako se dogodi neÅ¡to negativno, trebate uzeti tu _negativnu povratnu informaciju_, uÄiti iz nje i promijeniti smjer. Ako je ishod pozitivan, trebate graditi na toj _pozitivnoj povratnoj informaciji_.

![peter i vuk](../../../8-Reinforcement/images/peter.png)

> Peter i njegovi prijatelji moraju pobjeÄ‡i od gladnog vuka! Slika: [Jen Looper](https://twitter.com/jenlooper)

## Regionalna tema: Peter i vuk (Rusija)

[Peter i vuk](https://en.wikipedia.org/wiki/Peter_and_the_Wolf) je glazbena bajka koju je napisao ruski skladatelj [Sergej Prokofjev](https://en.wikipedia.org/wiki/Sergei_Prokofiev). To je priÄa o mladom pioniru Peteru, koji hrabro izlazi iz svoje kuÄ‡e na Å¡umsku Äistinu kako bi ulovio vuka. U ovom dijelu Ä‡emo trenirati algoritme strojnog uÄenja koji Ä‡e pomoÄ‡i Peteru:

- **IstraÅ¾iti** okolno podruÄje i izgraditi optimalnu kartu navigacije
- **NauÄiti** kako koristiti skateboard i odrÅ¾avati ravnoteÅ¾u na njemu kako bi se brÅ¾e kretao.

[![Peter i vuk](https://img.youtube.com/vi/Fmi5zHg4QSM/0.jpg)](https://www.youtube.com/watch?v=Fmi5zHg4QSM)

> ğŸ¥ Kliknite na sliku iznad kako biste posluÅ¡ali "Peter i vuk" od Prokofjeva

## UÄenje pojaÄanjem

U prethodnim dijelovima vidjeli ste dva primjera problema strojnog uÄenja:

- **Nadzirano uÄenje**, gdje imamo skupove podataka koji sugeriraju primjere rjeÅ¡enja problema koji Å¾elimo rijeÅ¡iti. [Klasifikacija](../4-Classification/README.md) i [regresija](../2-Regression/README.md) su zadaci nadziranog uÄenja.
- **Nadzirano uÄenje**, u kojem nemamo oznaÄene podatke za treniranje. Glavni primjer nenadziranog uÄenja je [Grupiranje](../5-Clustering/README.md).

U ovom dijelu Ä‡emo vas upoznati s novom vrstom problema uÄenja koji ne zahtijeva oznaÄene podatke za treniranje. Postoji nekoliko vrsta takvih problema:

- **[Polunadzirano uÄenje](https://wikipedia.org/wiki/Semi-supervised_learning)**, gdje imamo puno neoznaÄenih podataka koji se mogu koristiti za predtreniranje modela.
- **[UÄenje pojaÄanjem](https://wikipedia.org/wiki/Reinforcement_learning)**, u kojem agent uÄi kako se ponaÅ¡ati izvoÄ‘enjem eksperimenata u nekom simuliranom okruÅ¾enju.

### Primjer - raÄunalna igra

Pretpostavimo da Å¾elite nauÄiti raÄunalo kako igrati igru, poput Å¡aha ili [Super Maria](https://wikipedia.org/wiki/Super_Mario). Da bi raÄunalo moglo igrati igru, potrebno je predvidjeti koji potez napraviti u svakom stanju igre. Iako se to moÅ¾e Äiniti kao problem klasifikacije, nije - jer nemamo skup podataka sa stanjima i odgovarajuÄ‡im akcijama. Iako moÅ¾da imamo neke podatke poput postojeÄ‡ih Å¡ahovskih partija ili snimki igraÄa koji igraju Super Maria, vjerojatno ti podaci neÄ‡e dovoljno pokriti veliki broj moguÄ‡ih stanja.

Umjesto traÅ¾enja postojeÄ‡ih podataka o igri, **uÄenje pojaÄanjem** (RL) temelji se na ideji da *raÄunalo igra* mnogo puta i promatra rezultat. Dakle, za primjenu uÄenja pojaÄanjem potrebne su nam dvije stvari:

- **OkruÅ¾enje** i **simulator** koji nam omoguÄ‡uju da igru igramo mnogo puta. Ovaj simulator bi definirao sva pravila igre, kao i moguÄ‡a stanja i akcije.

- **Funkcija nagrade**, koja bi nam govorila koliko smo dobro igrali tijekom svakog poteza ili igre.

Glavna razlika izmeÄ‘u drugih vrsta strojnog uÄenja i RL-a je ta Å¡to u RL-u obiÄno ne znamo hoÄ‡emo li pobijediti ili izgubiti dok ne zavrÅ¡imo igru. Dakle, ne moÅ¾emo reÄ‡i je li odreÄ‘eni potez sam po sebi dobar ili ne - nagradu dobivamo tek na kraju igre. NaÅ¡ cilj je osmisliti algoritme koji Ä‡e nam omoguÄ‡iti treniranje modela u uvjetima nesigurnosti. NauÄit Ä‡emo o jednom RL algoritmu zvanom **Q-uÄenje**.

## Lekcije

1. [Uvod u uÄenje pojaÄanjem i Q-uÄenje](1-QLearning/README.md)
2. [KoriÅ¡tenje simulacijskog okruÅ¾enja Gym](2-Gym/README.md)

## Zasluge

"Uvod u uÄenje pojaÄanjem" napisano je s â™¥ï¸ od strane [Dmitry Soshnikov](http://soshnikov.com)

---

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden pomoÄ‡u AI usluge za prevoÄ‘enje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati toÄnost, imajte na umu da automatski prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za kljuÄne informacije preporuÄuje se profesionalni prijevod od strane Äovjeka. Ne preuzimamo odgovornost za bilo kakva nesporazuma ili pogreÅ¡na tumaÄenja koja proizlaze iz koriÅ¡tenja ovog prijevoda.