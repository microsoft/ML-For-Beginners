<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "5f3cb462e3122e1afe7ab0050ccf2bd3",
  "translation_date": "2025-09-05T13:54:13+00:00",
  "source_file": "6-NLP/2-Tasks/README.md",
  "language_code": "hr"
}
-->
# UobiÄajeni zadaci i tehnike obrade prirodnog jezika

Za veÄ‡inu zadataka obrade prirodnog jezika (*natural language processing*), tekst koji se obraÄ‘uje mora se razloÅ¾iti, analizirati i rezultati pohraniti ili usporediti s pravilima i skupovima podataka. Ovi zadaci omoguÄ‡uju programeru da izvuÄe _znaÄenje_, _namjeru_ ili samo _uÄestalost_ pojmova i rijeÄi u tekstu.

## [Kviz prije predavanja](https://ff-quizzes.netlify.app/en/ml/)

Otkrijmo uobiÄajene tehnike koje se koriste u obradi teksta. U kombinaciji sa strojnim uÄenjem, ove tehnike pomaÅ¾u vam da uÄinkovito analizirate velike koliÄine teksta. MeÄ‘utim, prije nego Å¡to primijenimo strojno uÄenje na ove zadatke, prvo razumijmo probleme s kojima se susreÄ‡e struÄnjak za obradu prirodnog jezika.

## UobiÄajeni zadaci u obradi prirodnog jezika

Postoje razliÄiti naÄini za analizu teksta na kojem radite. Postoje zadaci koje moÅ¾ete izvrÅ¡iti, a kroz njih moÅ¾ete steÄ‡i razumijevanje teksta i donijeti zakljuÄke. ObiÄno se ovi zadaci izvode u nizu.

### Tokenizacija

Vjerojatno prva stvar koju veÄ‡ina algoritama za obradu prirodnog jezika mora uÄiniti jest podijeliti tekst na tokene ili rijeÄi. Iako to zvuÄi jednostavno, uzimanje u obzir interpunkcije i razliÄitih jeziÄnih granica rijeÄi i reÄenica moÅ¾e biti izazovno. MoÅ¾da Ä‡ete morati koristiti razliÄite metode za odreÄ‘ivanje granica.

![tokenizacija](../../../../6-NLP/2-Tasks/images/tokenization.png)
> Tokenizacija reÄenice iz **Ponosa i predrasuda**. Infografika autorice [Jen Looper](https://twitter.com/jenlooper)

### UgraÄ‘ivanja

[UgraÄ‘ivanja rijeÄi](https://wikipedia.org/wiki/Word_embedding) su naÄin pretvaranja vaÅ¡ih tekstualnih podataka u numeriÄki oblik. UgraÄ‘ivanja se rade na naÄin da rijeÄi sa sliÄnim znaÄenjem ili rijeÄi koje se Äesto koriste zajedno budu grupirane.

![ugraÄ‘ivanja rijeÄi](../../../../6-NLP/2-Tasks/images/embedding.png)
> "Imam najveÄ‡e poÅ¡tovanje prema vaÅ¡im Å¾ivcima, oni su moji stari prijatelji." - UgraÄ‘ivanja rijeÄi za reÄenicu iz **Ponosa i predrasuda**. Infografika autorice [Jen Looper](https://twitter.com/jenlooper)

âœ… Isprobajte [ovaj zanimljiv alat](https://projector.tensorflow.org/) za eksperimentiranje s ugraÄ‘ivanjima rijeÄi. Klikom na jednu rijeÄ prikazuju se skupine sliÄnih rijeÄi: 'toy' je grupiran s 'disney', 'lego', 'playstation' i 'console'.

### Parsiranje i oznaÄavanje dijelova govora

Svaka rijeÄ koja je tokenizirana moÅ¾e se oznaÄiti kao dio govora - imenica, glagol ili pridjev. ReÄenica `brza crvena lisica skoÄila je preko lijenog smeÄ‘eg psa` mogla bi biti oznaÄena kao lisica = imenica, skoÄila = glagol.

![parsiranje](../../../../6-NLP/2-Tasks/images/parse.png)

> Parsiranje reÄenice iz **Ponosa i predrasuda**. Infografika autorice [Jen Looper](https://twitter.com/jenlooper)

Parsiranje prepoznaje koje su rijeÄi povezane u reÄenici - na primjer, `brza crvena lisica skoÄila` je slijed pridjev-imenica-glagol koji je odvojen od slijeda `lijeni smeÄ‘i pas`.

### UÄestalost rijeÄi i fraza

Korisna procedura pri analizi velikog teksta je izgradnja rjeÄnika svake rijeÄi ili fraze od interesa i koliko se Äesto pojavljuje. Fraza `brza crvena lisica skoÄila je preko lijenog smeÄ‘eg psa` ima uÄestalost rijeÄi 2 za rijeÄ "the".

Pogledajmo primjer teksta u kojem brojimo uÄestalost rijeÄi. Pjesma The Winners autora Rudyarda Kiplinga sadrÅ¾i sljedeÄ‡e stihove:

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

Kako uÄestalost fraza moÅ¾e biti osjetljiva ili neosjetljiva na velika i mala slova, fraza `a friend` ima uÄestalost 2, `the` ima uÄestalost 6, a `travels` ima uÄestalost 2.

### N-grami

Tekst se moÅ¾e podijeliti na sekvence rijeÄi odreÄ‘ene duljine: jedna rijeÄ (unigram), dvije rijeÄi (bigrami), tri rijeÄi (trigrami) ili bilo koji broj rijeÄi (n-grami).

Na primjer, `brza crvena lisica skoÄila je preko lijenog smeÄ‘eg psa` s n-gramom duljine 2 daje sljedeÄ‡e n-grame:

1. brza crvena  
2. crvena lisica  
3. lisica skoÄila  
4. skoÄila preko  
5. preko lijenog  
6. lijenog smeÄ‘eg  
7. smeÄ‘eg psa  

MoÅ¾da Ä‡e biti lakÅ¡e vizualizirati to kao klizni okvir preko reÄenice. Evo kako to izgleda za n-grame od 3 rijeÄi, gdje je n-gram podebljan u svakoj reÄenici:

1.   <u>**brza crvena lisica**</u> skoÄila je preko lijenog smeÄ‘eg psa  
2.   brza **<u>crvena lisica skoÄila</u>** je preko lijenog smeÄ‘eg psa  
3.   brza crvena **<u>lisica skoÄila preko</u>** lijenog smeÄ‘eg psa  
4.   brza crvena lisica **<u>skoÄila preko lijenog</u>** smeÄ‘eg psa  
5.   brza crvena lisica skoÄila **<u>preko lijenog smeÄ‘eg</u>** psa  
6.   brza crvena lisica skoÄila preko <u>**lijenog smeÄ‘eg psa**</u>  

![klizni prozor n-grama](../../../../6-NLP/2-Tasks/images/n-grams.gif)

> Vrijednost n-grama 3: Infografika autorice [Jen Looper](https://twitter.com/jenlooper)

### Ekstrakcija imenskih fraza

U veÄ‡ini reÄenica postoji imenica koja je subjekt ili objekt reÄenice. U engleskom jeziku Äesto se moÅ¾e prepoznati po tome Å¡to joj prethodi 'a', 'an' ili 'the'. Identificiranje subjekta ili objekta reÄenice pomoÄ‡u 'ekstrakcije imenske fraze' uobiÄajen je zadatak u obradi prirodnog jezika kada se pokuÅ¡ava razumjeti znaÄenje reÄenice.

âœ… U reÄenici "Ne mogu odrediti sat, ni mjesto, ni pogled ni rijeÄi, koje su postavile temelje. To je bilo davno. Bio sam usred toga prije nego Å¡to sam shvatio da sam poÄeo.", moÅ¾ete li identificirati imenske fraze?

U reÄenici `brza crvena lisica skoÄila je preko lijenog smeÄ‘eg psa` postoje 2 imenske fraze: **brza crvena lisica** i **lijeni smeÄ‘i pas**.

### Analiza sentimenta

ReÄenica ili tekst mogu se analizirati prema sentimentu, odnosno koliko su *pozitivni* ili *negativni*. Sentiment se mjeri prema *polaritetu* i *objektivnosti/subjektivnosti*. Polaritet se mjeri od -1.0 do 1.0 (negativno do pozitivno), a objektivnost od 0.0 do 1.0 (najobjektivnije do najsubjektivnije).

âœ… Kasnije Ä‡ete nauÄiti da postoje razliÄiti naÄini za odreÄ‘ivanje sentimenta pomoÄ‡u strojnog uÄenja, ali jedan od naÄina je imati popis rijeÄi i fraza koje su kategorizirane kao pozitivne ili negativne od strane ljudskog struÄnjaka i primijeniti taj model na tekst kako biste izraÄunali polaritet. MoÅ¾ete li vidjeti kako bi ovo funkcioniralo u nekim okolnostima, a u drugima ne?

### Infleksija

Infleksija vam omoguÄ‡uje da uzmete rijeÄ i dobijete njezin jedninski ili mnoÅ¾inski oblik.

### Lemmatizacija

*Lema* je korijen ili osnovna rijeÄ za skup rijeÄi, na primjer *letio*, *leti*, *leteÄ‡i* imaju lemu glagola *letjeti*.

TakoÄ‘er postoje korisne baze podataka dostupne istraÅ¾ivaÄima obrade prirodnog jezika, a posebno:

### WordNet

[WordNet](https://wordnet.princeton.edu/) je baza podataka rijeÄi, sinonima, antonima i mnogih drugih detalja za svaku rijeÄ na mnogim razliÄitim jezicima. Nevjerojatno je korisna pri pokuÅ¡aju izrade prijevoda, provjere pravopisa ili alata za jezik bilo koje vrste.

## Biblioteke za obradu prirodnog jezika

SreÄ‡om, ne morate sami graditi sve ove tehnike jer postoje izvrsne Python biblioteke koje ih Äine mnogo pristupaÄnijima za programere koji nisu specijalizirani za obradu prirodnog jezika ili strojno uÄenje. SljedeÄ‡e lekcije ukljuÄuju viÅ¡e primjera ovih biblioteka, ali ovdje Ä‡ete nauÄiti nekoliko korisnih primjera koji Ä‡e vam pomoÄ‡i u sljedeÄ‡em zadatku.

### VjeÅ¾ba - koriÅ¡tenje biblioteke `TextBlob`

Koristimo biblioteku pod nazivom TextBlob jer sadrÅ¾i korisne API-je za rjeÅ¡avanje ovakvih zadataka. TextBlob "stoji na ramenima divova [NLTK](https://nltk.org) i [pattern](https://github.com/clips/pattern), i lijepo suraÄ‘uje s oboje." Ima znaÄajnu koliÄinu strojnog uÄenja ugraÄ‘enu u svoj API.

> Napomena: Koristan [VodiÄ za brzi poÄetak](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart) dostupan je za TextBlob i preporuÄuje se iskusnim Python programerima.

Kada pokuÅ¡avate identificirati *imenske fraze*, TextBlob nudi nekoliko opcija ekstraktora za pronalaÅ¾enje imenskih fraza.

1. Pogledajte `ConllExtractor`.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > Å to se ovdje dogaÄ‘a? [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) je "Ekstraktor imenskih fraza koji koristi parsiranje segmenata trenirano na ConLL-2000 korpusu za treniranje." ConLL-2000 odnosi se na Konferenciju o raÄunalnom uÄenju jezika iz 2000. godine. Svake godine konferencija je organizirala radionicu za rjeÅ¡avanje sloÅ¾enog problema obrade prirodnog jezika, a 2000. godine to je bilo segmentiranje imenskih fraza. Model je treniran na Wall Street Journalu, s "odjeljcima 15-18 kao podacima za treniranje (211727 tokena) i odjeljkom 20 kao testnim podacima (47377 tokena)". MoÅ¾ete pogledati postupke koriÅ¡tene [ovdje](https://www.clips.uantwerpen.be/conll2000/chunking/) i [rezultate](https://ifarm.nl/erikt/research/np-chunking.html).

### Izazov - poboljÅ¡ajte svog bota pomoÄ‡u obrade prirodnog jezika

U prethodnoj lekciji izradili ste vrlo jednostavnog Q&A bota. Sada Ä‡ete uÄiniti Marvina malo suosjeÄ‡ajnijim analizirajuÄ‡i vaÅ¡ unos za sentiment i ispisujuÄ‡i odgovor koji odgovara sentimentu. TakoÄ‘er Ä‡ete morati identificirati `imensku frazu` i postaviti pitanje o njoj.

VaÅ¡i koraci pri izradi boljeg konverzacijskog bota:

1. IspiÅ¡ite upute koje savjetuju korisnika kako komunicirati s botom  
2. Pokrenite petlju  
   1. Prihvatite korisnikov unos  
   2. Ako korisnik zatraÅ¾i izlaz, izaÄ‘ite  
   3. Obradite korisnikov unos i odredite odgovarajuÄ‡i odgovor na temelju sentimenta  
   4. Ako se u sentimentu otkrije imenska fraza, mnoÅ¾ite je i zatraÅ¾ite dodatni unos o toj temi  
   5. IspiÅ¡ite odgovor  
3. Vratite se na korak 2  

Evo isjeÄka koda za odreÄ‘ivanje sentimenta pomoÄ‡u TextBlob-a. Imajte na umu da postoje samo Äetiri *gradijenta* odgovora na sentiment (moÅ¾ete ih imati viÅ¡e ako Å¾elite):

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

Evo primjera izlaza koji Ä‡e vas voditi (korisnikov unos je na linijama koje poÄinju s >):

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

Jedno moguÄ‡e rjeÅ¡enje zadatka nalazi se [ovdje](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/2-Tasks/solution/bot.py)

âœ… Provjera znanja

1. Mislite li da bi suosjeÄ‡ajni odgovori mogli 'zavarati' nekoga da pomisli da bot zapravo razumije?  
2. ÄŒini li identificiranje imenske fraze bota 'uvjerljivijim'?  
3. ZaÅ¡to bi ekstrakcija 'imenske fraze' iz reÄenice bila korisna stvar?  

---

Implementirajte bota iz prethodne provjere znanja i testirajte ga na prijatelju. MoÅ¾e li ih zavarati? MoÅ¾ete li uÄiniti svog bota 'uvjerljivijim'?

## ğŸš€Izazov

Uzmite zadatak iz prethodne provjere znanja i pokuÅ¡ajte ga implementirati. Testirajte bota na prijatelju. MoÅ¾e li ih zavarati? MoÅ¾ete li uÄiniti svog bota 'uvjerljivijim'?

## [Kviz nakon predavanja](https://ff-quizzes.netlify.app/en/ml/)

## Pregled i samostalno uÄenje

U sljedeÄ‡ih nekoliko lekcija nauÄit Ä‡ete viÅ¡e o analizi sentimenta. IstraÅ¾ite ovu zanimljivu tehniku u Älancima poput ovih na [KDNuggets](https://www.kdnuggets.com/tag/nlp)

## Zadatak 

[Natjerajte bota da odgovara](assignment.md)

---

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden koristeÄ‡i AI uslugu za prevoÄ‘enje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati toÄnost, imajte na umu da automatski prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati mjerodavnim izvorom. Za kljuÄne informacije preporuÄuje se profesionalni prijevod od strane struÄnjaka. Ne preuzimamo odgovornost za bilo kakve nesporazume ili pogreÅ¡ne interpretacije proizaÅ¡le iz koriÅ¡tenja ovog prijevoda.