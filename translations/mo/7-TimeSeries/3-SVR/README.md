<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f80e513b3279869e7661e3190cc83076",
  "translation_date": "2025-08-29T20:49:52+00:00",
  "source_file": "7-TimeSeries/3-SVR/README.md",
  "language_code": "mo"
}
-->
# ä½¿ç”¨æ”¯æŒå‘é‡å›æ­¸é€²è¡Œæ™‚é–“åºåˆ—é æ¸¬

åœ¨ä¸Šä¸€èª²ä¸­ï¼Œä½ å­¸ç¿’äº†å¦‚ä½•ä½¿ç”¨ ARIMA æ¨¡å‹é€²è¡Œæ™‚é–“åºåˆ—é æ¸¬ã€‚ç¾åœ¨ï¼Œæˆ‘å€‘å°‡æ¢è¨æ”¯æŒå‘é‡å›æ­¸ï¼ˆSupport Vector Regressorï¼ŒSVRï¼‰æ¨¡å‹ï¼Œå®ƒæ˜¯ä¸€ç¨®ç”¨æ–¼é æ¸¬é€£çºŒæ•¸æ“šçš„å›æ­¸æ¨¡å‹ã€‚

## [èª²å‰æ¸¬é©—](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/51/) 

## ç°¡ä»‹

åœ¨æœ¬èª²ä¸­ï¼Œä½ å°‡å­¸ç¿’å¦‚ä½•ä½¿ç”¨ [**SVM**ï¼š**æ”¯æŒå‘é‡æ©Ÿ**](https://en.wikipedia.org/wiki/Support-vector_machine) ä¾†é€²è¡Œå›æ­¸ï¼Œæˆ–ç¨± **SVRï¼šæ”¯æŒå‘é‡å›æ­¸**ã€‚

### SVR åœ¨æ™‚é–“åºåˆ—ä¸­çš„æ‡‰ç”¨ [^1]

åœ¨äº†è§£ SVR åœ¨æ™‚é–“åºåˆ—é æ¸¬ä¸­çš„é‡è¦æ€§ä¹‹å‰ï¼Œä»¥ä¸‹æ˜¯ä¸€äº›ä½ éœ€è¦äº†è§£çš„é‡è¦æ¦‚å¿µï¼š

- **å›æ­¸ï¼š** ä¸€ç¨®ç›£ç£å¼å­¸ç¿’æŠ€è¡“ï¼Œç”¨æ–¼æ ¹æ“šçµ¦å®šçš„è¼¸å…¥é›†é æ¸¬é€£çºŒå€¼ã€‚å…¶æ ¸å¿ƒæ€æƒ³æ˜¯æ‰¾åˆ°ç‰¹å¾µç©ºé–“ä¸­åŒ…å«æœ€å¤šæ•¸æ“šé»çš„æ›²ç·šï¼ˆæˆ–ç›´ç·šï¼‰ã€‚[é»æ“Šæ­¤è™•](https://en.wikipedia.org/wiki/Regression_analysis)äº†è§£æ›´å¤šè³‡è¨Šã€‚
- **æ”¯æŒå‘é‡æ©Ÿï¼ˆSVMï¼‰ï¼š** ä¸€ç¨®ç›£ç£å¼æ©Ÿå™¨å­¸ç¿’æ¨¡å‹ï¼Œç”¨æ–¼åˆ†é¡ã€å›æ­¸å’Œç•°å¸¸æª¢æ¸¬ã€‚è©²æ¨¡å‹åœ¨ç‰¹å¾µç©ºé–“ä¸­æ˜¯ä¸€å€‹è¶…å¹³é¢ï¼Œåˆ†é¡æ™‚ä½œç‚ºé‚Šç•Œï¼Œå›æ­¸æ™‚ä½œç‚ºæœ€ä½³æ“¬åˆç·šã€‚åœ¨ SVM ä¸­ï¼Œé€šå¸¸ä½¿ç”¨æ ¸å‡½æ•¸å°‡æ•¸æ“šé›†è½‰æ›åˆ°æ›´é«˜ç¶­åº¦çš„ç©ºé–“ï¼Œä»¥ä¾¿æ›´å®¹æ˜“åˆ†é›¢ã€‚[é»æ“Šæ­¤è™•](https://en.wikipedia.org/wiki/Support-vector_machine)äº†è§£æ›´å¤šé—œæ–¼ SVM çš„è³‡è¨Šã€‚
- **æ”¯æŒå‘é‡å›æ­¸ï¼ˆSVRï¼‰ï¼š** SVM çš„ä¸€ç¨®ï¼Œç”¨æ–¼æ‰¾åˆ°æœ€ä½³æ“¬åˆç·šï¼ˆåœ¨ SVM ä¸­æ˜¯è¶…å¹³é¢ï¼‰ï¼Œä»¥åŒ…å«æœ€å¤šæ•¸æ“šé»ã€‚

### ç‚ºä»€éº¼é¸æ“‡ SVRï¼Ÿ [^1]

åœ¨ä¸Šä¸€èª²ä¸­ï¼Œä½ å­¸ç¿’äº† ARIMAï¼Œå®ƒæ˜¯ä¸€ç¨®éå¸¸æˆåŠŸçš„çµ±è¨ˆç·šæ€§æ–¹æ³•ï¼Œç”¨æ–¼é æ¸¬æ™‚é–“åºåˆ—æ•¸æ“šã€‚ç„¶è€Œï¼Œåœ¨è¨±å¤šæƒ…æ³ä¸‹ï¼Œæ™‚é–“åºåˆ—æ•¸æ“šå…·æœ‰*éç·šæ€§*ç‰¹æ€§ï¼Œé€™äº›ç‰¹æ€§ç„¡æ³•é€šéç·šæ€§æ¨¡å‹æ˜ å°„ã€‚åœ¨é€™ç¨®æƒ…æ³ä¸‹ï¼ŒSVM èƒ½å¤ è€ƒæ…®æ•¸æ“šä¸­çš„éç·šæ€§ç‰¹æ€§ï¼Œä½¿å¾— SVR åœ¨æ™‚é–“åºåˆ—é æ¸¬ä¸­éå¸¸æˆåŠŸã€‚

## ç·´ç¿’ - å»ºç«‹ SVR æ¨¡å‹

æ•¸æ“šæº–å‚™çš„å‰å¹¾æ­¥èˆ‡ä¸Šä¸€èª² [ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA) çš„æ­¥é©Ÿç›¸åŒã€‚

æ‰“é–‹æœ¬èª²çš„ [_/working_](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/3-SVR/working) è³‡æ–™å¤¾ï¼Œæ‰¾åˆ° [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/7-TimeSeries/3-SVR/working/notebook.ipynb) æ–‡ä»¶ã€‚[^2]

1. åŸ·è¡Œ notebook ä¸¦å°å…¥å¿…è¦çš„åº«ï¼š[^2]

   ```python
   import sys
   sys.path.append('../../')
   ```

   ```python
   import os
   import warnings
   import matplotlib.pyplot as plt
   import numpy as np
   import pandas as pd
   import datetime as dt
   import math
   
   from sklearn.svm import SVR
   from sklearn.preprocessing import MinMaxScaler
   from common.utils import load_data, mape
   ```

2. å¾ `/data/energy.csv` æ–‡ä»¶ä¸­è¼‰å…¥æ•¸æ“šåˆ° Pandas dataframeï¼Œä¸¦æŸ¥çœ‹æ•¸æ“šï¼š[^2]

   ```python
   energy = load_data('../../data')[['load']]
   ```

3. ç¹ªè£½ 2012 å¹´ 1 æœˆè‡³ 2014 å¹´ 12 æœˆçš„æ‰€æœ‰èƒ½æºæ•¸æ“šï¼š[^2]

   ```python
   energy.plot(y='load', subplots=True, figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![å®Œæ•´æ•¸æ“š](../../../../translated_images/full-data.a82ec9957e580e976f651a4fc38f280b9229c6efdbe3cfe7c60abaa9486d2cbe.mo.png)

   ç¾åœ¨ï¼Œè®“æˆ‘å€‘å»ºç«‹ SVR æ¨¡å‹ã€‚

### å‰µå»ºè¨“ç·´å’Œæ¸¬è©¦æ•¸æ“šé›†

ç¾åœ¨æ•¸æ“šå·²è¼‰å…¥ï¼Œä½ å¯ä»¥å°‡å…¶åˆ†ç‚ºè¨“ç·´é›†å’Œæ¸¬è©¦é›†ã€‚æ¥è‘—ï¼Œä½ éœ€è¦é‡å¡‘æ•¸æ“šä»¥å‰µå»ºåŸºæ–¼æ™‚é–“æ­¥é•·çš„æ•¸æ“šé›†ï¼Œé€™æ˜¯ SVR æ‰€éœ€çš„æ ¼å¼ã€‚ä½ å°‡åœ¨è¨“ç·´é›†ä¸Šè¨“ç·´æ¨¡å‹ã€‚æ¨¡å‹è¨“ç·´å®Œæˆå¾Œï¼Œä½ å°‡åœ¨è¨“ç·´é›†ã€æ¸¬è©¦é›†ä»¥åŠå®Œæ•´æ•¸æ“šé›†ä¸Šè©•ä¼°å…¶æº–ç¢ºæ€§ï¼Œä»¥æŸ¥çœ‹æ•´é«”è¡¨ç¾ã€‚éœ€è¦ç¢ºä¿æ¸¬è©¦é›†æ¶µè“‹è¨“ç·´é›†ä¹‹å¾Œçš„æ™‚é–“æ®µï¼Œä»¥é¿å…æ¨¡å‹å¾æœªä¾†æ™‚é–“æ®µä¸­ç²å–è³‡è¨Š [^2]ï¼ˆé€™ç¨®æƒ…æ³ç¨±ç‚º*éæ“¬åˆ*ï¼‰ã€‚

1. å°‡ 2014 å¹´ 9 æœˆ 1 æ—¥è‡³ 10 æœˆ 31 æ—¥çš„å…©å€‹æœˆåˆ†é…çµ¦è¨“ç·´é›†ã€‚æ¸¬è©¦é›†å°‡åŒ…æ‹¬ 2014 å¹´ 11 æœˆ 1 æ—¥è‡³ 12 æœˆ 31 æ—¥çš„å…©å€‹æœˆï¼š[^2]

   ```python
   train_start_dt = '2014-11-01 00:00:00'
   test_start_dt = '2014-12-30 00:00:00'
   ```

2. å¯è¦–åŒ–å·®ç•°ï¼š[^2]

   ```python
   energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)][['load']].rename(columns={'load':'train'}) \
       .join(energy[test_start_dt:][['load']].rename(columns={'load':'test'}), how='outer') \
       .plot(y=['train', 'test'], figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![è¨“ç·´å’Œæ¸¬è©¦æ•¸æ“š](../../../../translated_images/train-test.ead0cecbfc341921d4875eccf25fed5eefbb860cdbb69cabcc2276c49e4b33e5.mo.png)

### ç‚ºè¨“ç·´æº–å‚™æ•¸æ“š

ç¾åœ¨ï¼Œä½ éœ€è¦é€šéç¯©é¸å’Œç¸®æ”¾æ•¸æ“šä¾†æº–å‚™è¨“ç·´æ•¸æ“šã€‚ç¯©é¸æ•¸æ“šé›†ä»¥åƒ…åŒ…å«æ‰€éœ€çš„æ™‚é–“æ®µå’Œåˆ—ï¼Œä¸¦ç¸®æ”¾æ•¸æ“šä»¥ç¢ºä¿å…¶æŠ•å°„åˆ° 0 å’Œ 1 çš„å€é–“å…§ã€‚

1. ç¯©é¸åŸå§‹æ•¸æ“šé›†ä»¥åƒ…åŒ…å«ä¸Šè¿°æ™‚é–“æ®µçš„æ•¸æ“šé›†ï¼Œä»¥åŠåƒ…åŒ…å«æ‰€éœ€çš„åˆ— 'load' å’Œæ—¥æœŸï¼š[^2]

   ```python
   train = energy.copy()[(energy.index >= train_start_dt) & (energy.index < test_start_dt)][['load']]
   test = energy.copy()[energy.index >= test_start_dt][['load']]
   
   print('Training data shape: ', train.shape)
   print('Test data shape: ', test.shape)
   ```

   ```output
   Training data shape:  (1416, 1)
   Test data shape:  (48, 1)
   ```
   
2. å°‡è¨“ç·´æ•¸æ“šç¸®æ”¾åˆ°ç¯„åœ (0, 1)ï¼š[^2]

   ```python
   scaler = MinMaxScaler()
   train['load'] = scaler.fit_transform(train)
   ```
   
4. ç¾åœ¨ï¼Œç¸®æ”¾æ¸¬è©¦æ•¸æ“šï¼š[^2]

   ```python
   test['load'] = scaler.transform(test)
   ```

### å‰µå»ºå…·æœ‰æ™‚é–“æ­¥é•·çš„æ•¸æ“š [^1]

å°æ–¼ SVRï¼Œä½ éœ€è¦å°‡è¼¸å…¥æ•¸æ“šè½‰æ›ç‚º `[batch, timesteps]` çš„å½¢å¼ã€‚å› æ­¤ï¼Œä½ éœ€è¦é‡å¡‘ç¾æœ‰çš„ `train_data` å’Œ `test_data`ï¼Œä»¥ä¾¿æ–°å¢ä¸€å€‹ç¶­åº¦è¡¨ç¤ºæ™‚é–“æ­¥é•·ã€‚

```python
# Converting to numpy arrays
train_data = train.values
test_data = test.values
```

åœ¨æ­¤ç¯„ä¾‹ä¸­ï¼Œæˆ‘å€‘è¨­å®š `timesteps = 5`ã€‚å› æ­¤ï¼Œæ¨¡å‹çš„è¼¸å…¥æ˜¯å‰ 4 å€‹æ™‚é–“æ­¥é•·çš„æ•¸æ“šï¼Œè¼¸å‡ºæ˜¯ç¬¬ 5 å€‹æ™‚é–“æ­¥é•·çš„æ•¸æ“šã€‚

```python
timesteps=5
```

ä½¿ç”¨åµŒå¥—åˆ—è¡¨æ¨å°å¼å°‡è¨“ç·´æ•¸æ“šè½‰æ›ç‚º 2D å¼µé‡ï¼š

```python
train_data_timesteps=np.array([[j for j in train_data[i:i+timesteps]] for i in range(0,len(train_data)-timesteps+1)])[:,:,0]
train_data_timesteps.shape
```

```output
(1412, 5)
```

å°‡æ¸¬è©¦æ•¸æ“šè½‰æ›ç‚º 2D å¼µé‡ï¼š

```python
test_data_timesteps=np.array([[j for j in test_data[i:i+timesteps]] for i in range(0,len(test_data)-timesteps+1)])[:,:,0]
test_data_timesteps.shape
```

```output
(44, 5)
```

é¸æ“‡è¨“ç·´å’Œæ¸¬è©¦æ•¸æ“šçš„è¼¸å…¥å’Œè¼¸å‡ºï¼š

```python
x_train, y_train = train_data_timesteps[:,:timesteps-1],train_data_timesteps[:,[timesteps-1]]
x_test, y_test = test_data_timesteps[:,:timesteps-1],test_data_timesteps[:,[timesteps-1]]

print(x_train.shape, y_train.shape)
print(x_test.shape, y_test.shape)
```

```output
(1412, 4) (1412, 1)
(44, 4) (44, 1)
```

### å¯¦ç¾ SVR [^1]

ç¾åœ¨æ˜¯å¯¦ç¾ SVR çš„æ™‚å€™äº†ã€‚è¦äº†è§£æ›´å¤šé—œæ–¼æ­¤å¯¦ç¾çš„è³‡è¨Šï¼Œä½ å¯ä»¥åƒè€ƒ [æ­¤æ–‡ä»¶](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html)ã€‚ä»¥ä¸‹æ˜¯æˆ‘å€‘çš„å¯¦ç¾æ­¥é©Ÿï¼š

1. é€šéèª¿ç”¨ `SVR()` ä¸¦å‚³å…¥æ¨¡å‹è¶…åƒæ•¸ï¼škernelã€gammaã€c å’Œ epsilon ä¾†å®šç¾©æ¨¡å‹
2. é€šéèª¿ç”¨ `fit()` å‡½æ•¸æº–å‚™è¨“ç·´æ•¸æ“šçš„æ¨¡å‹
3. é€šéèª¿ç”¨ `predict()` å‡½æ•¸é€²è¡Œé æ¸¬

ç¾åœ¨æˆ‘å€‘å‰µå»ºä¸€å€‹ SVR æ¨¡å‹ã€‚åœ¨æ­¤ï¼Œæˆ‘å€‘ä½¿ç”¨ [RBF æ ¸å‡½æ•¸](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel)ï¼Œä¸¦å°‡è¶…åƒæ•¸ gammaã€C å’Œ epsilon åˆ†åˆ¥è¨­ç½®ç‚º 0.5ã€10 å’Œ 0.05ã€‚

```python
model = SVR(kernel='rbf',gamma=0.5, C=10, epsilon = 0.05)
```

#### åœ¨è¨“ç·´æ•¸æ“šä¸Šæ“¬åˆæ¨¡å‹ [^1]

```python
model.fit(x_train, y_train[:,0])
```

```output
SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.05, gamma=0.5,
    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)
```

#### é€²è¡Œæ¨¡å‹é æ¸¬ [^1]

```python
y_train_pred = model.predict(x_train).reshape(-1,1)
y_test_pred = model.predict(x_test).reshape(-1,1)

print(y_train_pred.shape, y_test_pred.shape)
```

```output
(1412, 1) (44, 1)
```

ä½ å·²ç¶“å»ºç«‹äº† SVRï¼ç¾åœ¨æˆ‘å€‘éœ€è¦è©•ä¼°å®ƒã€‚

### è©•ä¼°ä½ çš„æ¨¡å‹ [^1]

ç‚ºäº†è©•ä¼°ï¼Œé¦–å…ˆæˆ‘å€‘éœ€è¦å°‡æ•¸æ“šç¸®æ”¾å›åŸå§‹æ¯”ä¾‹ã€‚æ¥è‘—ï¼Œç‚ºäº†æª¢æŸ¥æ€§èƒ½ï¼Œæˆ‘å€‘å°‡ç¹ªè£½åŸå§‹å’Œé æ¸¬çš„æ™‚é–“åºåˆ—åœ–ï¼Œä¸¦æ‰“å° MAPE çµæœã€‚

å°‡é æ¸¬å’ŒåŸå§‹è¼¸å‡ºç¸®æ”¾å›åŸå§‹æ¯”ä¾‹ï¼š

```python
# Scaling the predictions
y_train_pred = scaler.inverse_transform(y_train_pred)
y_test_pred = scaler.inverse_transform(y_test_pred)

print(len(y_train_pred), len(y_test_pred))
```

```python
# Scaling the original values
y_train = scaler.inverse_transform(y_train)
y_test = scaler.inverse_transform(y_test)

print(len(y_train), len(y_test))
```

#### æª¢æŸ¥æ¨¡å‹åœ¨è¨“ç·´å’Œæ¸¬è©¦æ•¸æ“šä¸Šçš„æ€§èƒ½ [^1]

æˆ‘å€‘å¾æ•¸æ“šé›†ä¸­æå–æ™‚é–“æˆ³ï¼Œä»¥é¡¯ç¤ºåœ¨åœ–è¡¨çš„ x è»¸ä¸Šã€‚æ³¨æ„ï¼Œæˆ‘å€‘ä½¿ç”¨å‰ ```timesteps-1``` å€‹å€¼ä½œç‚ºç¬¬ä¸€å€‹è¼¸å‡ºçš„è¼¸å…¥ï¼Œå› æ­¤è¼¸å‡ºçš„æ™‚é–“æˆ³å°‡å¾é‚£ä¹‹å¾Œé–‹å§‹ã€‚

```python
train_timestamps = energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)].index[timesteps-1:]
test_timestamps = energy[test_start_dt:].index[timesteps-1:]

print(len(train_timestamps), len(test_timestamps))
```

```output
1412 44
```

ç¹ªè£½è¨“ç·´æ•¸æ“šçš„é æ¸¬ï¼š

```python
plt.figure(figsize=(25,6))
plt.plot(train_timestamps, y_train, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(train_timestamps, y_train_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.title("Training data prediction")
plt.show()
```

![è¨“ç·´æ•¸æ“šé æ¸¬](../../../../translated_images/train-data-predict.3c4ef4e78553104ffdd53d47a4c06414007947ea328e9261ddf48d3eafdefbbf.mo.png)

æ‰“å°è¨“ç·´æ•¸æ“šçš„ MAPEï¼š

```python
print('MAPE for training data: ', mape(y_train_pred, y_train)*100, '%')
```

```output
MAPE for training data: 1.7195710200875551 %
```

ç¹ªè£½æ¸¬è©¦æ•¸æ“šçš„é æ¸¬ï¼š

```python
plt.figure(figsize=(10,3))
plt.plot(test_timestamps, y_test, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(test_timestamps, y_test_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![æ¸¬è©¦æ•¸æ“šé æ¸¬](../../../../translated_images/test-data-predict.8afc47ee7e52874f514ebdda4a798647e9ecf44a97cc927c535246fcf7a28aa9.mo.png)

æ‰“å°æ¸¬è©¦æ•¸æ“šçš„ MAPEï¼š

```python
print('MAPE for testing data: ', mape(y_test_pred, y_test)*100, '%')
```

```output
MAPE for testing data:  1.2623790187854018 %
```

ğŸ† ä½ åœ¨æ¸¬è©¦æ•¸æ“šé›†ä¸Šå–å¾—äº†éå¸¸å¥½çš„çµæœï¼

### æª¢æŸ¥æ¨¡å‹åœ¨å®Œæ•´æ•¸æ“šé›†ä¸Šçš„æ€§èƒ½ [^1]

```python
# Extracting load values as numpy array
data = energy.copy().values

# Scaling
data = scaler.transform(data)

# Transforming to 2D tensor as per model input requirement
data_timesteps=np.array([[j for j in data[i:i+timesteps]] for i in range(0,len(data)-timesteps+1)])[:,:,0]
print("Tensor shape: ", data_timesteps.shape)

# Selecting inputs and outputs from data
X, Y = data_timesteps[:,:timesteps-1],data_timesteps[:,[timesteps-1]]
print("X shape: ", X.shape,"\nY shape: ", Y.shape)
```

```output
Tensor shape:  (26300, 5)
X shape:  (26300, 4) 
Y shape:  (26300, 1)
```

```python
# Make model predictions
Y_pred = model.predict(X).reshape(-1,1)

# Inverse scale and reshape
Y_pred = scaler.inverse_transform(Y_pred)
Y = scaler.inverse_transform(Y)
```

```python
plt.figure(figsize=(30,8))
plt.plot(Y, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(Y_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![å®Œæ•´æ•¸æ“šé æ¸¬](../../../../translated_images/full-data-predict.4f0fed16a131c8f3bcc57a3060039dc7f2f714a05b07b68c513e0fe7fb3d8964.mo.png)

```python
print('MAPE: ', mape(Y_pred, Y)*100, '%')
```

```output
MAPE:  2.0572089029888656 %
```

ğŸ† éå¸¸æ£’çš„åœ–è¡¨ï¼Œé¡¯ç¤ºå‡ºæ¨¡å‹å…·æœ‰è‰¯å¥½çš„æº–ç¢ºæ€§ã€‚åšå¾—å¥½ï¼

---

## ğŸš€æŒ‘æˆ°

- å˜—è©¦åœ¨å‰µå»ºæ¨¡å‹æ™‚èª¿æ•´è¶…åƒæ•¸ï¼ˆgammaã€Cã€epsilonï¼‰ï¼Œä¸¦åœ¨æ•¸æ“šä¸Šé€²è¡Œè©•ä¼°ï¼Œä»¥æŸ¥çœ‹å“ªçµ„è¶…åƒæ•¸åœ¨æ¸¬è©¦æ•¸æ“šä¸Šè¡¨ç¾æœ€ä½³ã€‚è¦äº†è§£æ›´å¤šé—œæ–¼é€™äº›è¶…åƒæ•¸çš„è³‡è¨Šï¼Œä½ å¯ä»¥åƒè€ƒ [æ­¤æ–‡ä»¶](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel)ã€‚ 
- å˜—è©¦ä½¿ç”¨ä¸åŒçš„æ ¸å‡½æ•¸é€²è¡Œæ¨¡å‹è¨“ç·´ï¼Œä¸¦åˆ†æå®ƒå€‘åœ¨æ•¸æ“šé›†ä¸Šçš„è¡¨ç¾ã€‚ç›¸é—œæ–‡ä»¶å¯åƒè€ƒ [æ­¤è™•](https://scikit-learn.org/stable/modules/svm.html#kernel-functions)ã€‚
- å˜—è©¦ç‚ºæ¨¡å‹ä½¿ç”¨ä¸åŒçš„ `timesteps` å€¼ï¼Œè§€å¯Ÿå…¶å›æº¯é æ¸¬çš„æ•ˆæœã€‚

## [èª²å¾Œæ¸¬é©—](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/52/)

## å›é¡§èˆ‡è‡ªå­¸

æœ¬èª²æ—¨åœ¨ä»‹ç´¹ SVR åœ¨æ™‚é–“åºåˆ—é æ¸¬ä¸­çš„æ‡‰ç”¨ã€‚è¦äº†è§£æ›´å¤šé—œæ–¼ SVR çš„è³‡è¨Šï¼Œä½ å¯ä»¥åƒè€ƒ [é€™ç¯‡åšå®¢](https://www.analyticsvidhya.com/blog/2020/03/support-vector-regression-tutorial-for-machine-learning/)ã€‚[scikit-learn çš„æ–‡ä»¶](https://scikit-learn.org/stable/modules/svm.html) æä¾›äº†æ›´å…¨é¢çš„è§£é‡‹ï¼ŒåŒ…æ‹¬ SVM çš„ä¸€èˆ¬æ¦‚å¿µã€[SVR](https://scikit-learn.org/stable/modules/svm.html#regression)ï¼Œä»¥åŠå…¶ä»–å¯¦ç¾ç´°ç¯€ï¼Œä¾‹å¦‚å¯ç”¨çš„ä¸åŒ [æ ¸å‡½æ•¸](https://scikit-learn.org/stable/modules/svm.html#kernel-functions) å’Œå®ƒå€‘çš„åƒæ•¸ã€‚

## ä½œæ¥­

[ä¸€å€‹æ–°çš„ SVR æ¨¡å‹](assignment.md)

## è‡´è¬

[^1]: æœ¬ç¯€çš„æ–‡å­—ã€ä»£ç¢¼å’Œè¼¸å‡ºç”± [@AnirbanMukherjeeXD](https://github.com/AnirbanMukherjeeXD) è²¢ç»
[^2]: æœ¬ç¯€çš„æ–‡å­—ã€ä»£ç¢¼å’Œè¼¸å‡ºå–è‡ª [ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA)

---

**å…è²¬è²æ˜**ï¼š  
æœ¬æ–‡ä»¶å·²ä½¿ç”¨ AI ç¿»è­¯æœå‹™ [Co-op Translator](https://github.com/Azure/co-op-translator) é€²è¡Œç¿»è­¯ã€‚å„˜ç®¡æˆ‘å€‘åŠªåŠ›ç¢ºä¿ç¿»è­¯çš„æº–ç¢ºæ€§ï¼Œä½†è«‹æ³¨æ„ï¼Œè‡ªå‹•ç¿»è­¯å¯èƒ½åŒ…å«éŒ¯èª¤æˆ–ä¸æº–ç¢ºä¹‹è™•ã€‚åŸå§‹æ–‡ä»¶çš„æ¯èªç‰ˆæœ¬æ‡‰è¢«è¦–ç‚ºæ¬Šå¨ä¾†æºã€‚å°æ–¼é—œéµä¿¡æ¯ï¼Œå»ºè­°ä½¿ç”¨å°ˆæ¥­äººå·¥ç¿»è­¯ã€‚æˆ‘å€‘å°å› ä½¿ç”¨æ­¤ç¿»è­¯è€Œå¼•èµ·çš„ä»»ä½•èª¤è§£æˆ–éŒ¯èª¤è§£é‡‹ä¸æ‰¿æ“”è²¬ä»»ã€‚