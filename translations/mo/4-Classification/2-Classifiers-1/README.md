# Classificateurs de cuisine 1

Dans cette le√ßon, vous utiliserez le jeu de donn√©es que vous avez enregistr√© lors de la derni√®re le√ßon, rempli de donn√©es √©quilibr√©es et propres concernant les cuisines.

Vous utiliserez ce jeu de donn√©es avec une vari√©t√© de classificateurs pour _pr√©dire une cuisine nationale donn√©e en fonction d'un groupe d'ingr√©dients_. Ce faisant, vous en apprendrez davantage sur certaines des fa√ßons dont les algorithmes peuvent √™tre utilis√©s pour des t√¢ches de classification.

## [Quiz pr√©-conf√©rence](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/21/)
# Pr√©paration

En supposant que vous ayez compl√©t√© [le√ßon 1](../1-Introduction/README.md), assurez-vous qu'un fichier _cleaned_cuisines.csv_ existe dans le dossier racine `/data` pour ces quatre le√ßons.

## Exercice - pr√©dire une cuisine nationale

1. En travaillant dans le dossier _notebook.ipynb_ de cette le√ßon, importez ce fichier ainsi que la biblioth√®que Pandas :

    ```python
    import pandas as pd
    cuisines_df = pd.read_csv("../data/cleaned_cuisines.csv")
    cuisines_df.head()
    ```

    Les donn√©es ressemblent √† ceci :

|     | Unnamed: 0 | cuisine | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood | yam | yeast | yogurt | zucchini |
| --- | ---------- | ------- | ------ | -------- | ----- | ---------- | ----- | ------------ | ------- | -------- | --- | ------- | ----------- | ---------- | ----------------------- | ---- | ---- | --- | ----- | ------ | -------- |
| 0   | 0          | indien  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 1   | 1          | indien  | 1      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 2   | 2          | indien  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 3   | 3          | indien  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 4   | 4          | indien  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 1      | 0        |
  

1. Maintenant, importez plusieurs autres biblioth√®ques :

    ```python
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    from sklearn.svm import SVC
    import numpy as np
    ```

1. Divisez les coordonn√©es X et y en deux dataframes pour l'entra√Ænement. `cuisine` peut √™tre le dataframe des √©tiquettes :

    ```python
    cuisines_label_df = cuisines_df['cuisine']
    cuisines_label_df.head()
    ```

    Cela ressemblera √† ceci :

    ```output
    0    indian
    1    indian
    2    indian
    3    indian
    4    indian
    Name: cuisine, dtype: object
    ```

1. Supprimez `Unnamed: 0` column and the `cuisine` column, calling `drop()`. Enregistrez le reste des donn√©es comme caract√©ristiques entra√Ænables :

    ```python
    cuisines_feature_df = cuisines_df.drop(['Unnamed: 0', 'cuisine'], axis=1)
    cuisines_feature_df.head()
    ```

    Vos caract√©ristiques ressemblent √† ceci :

|      | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | artemisia | artichoke |  ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood |  yam | yeast | yogurt | zucchini |
| ---: | -----: | -------: | ----: | ---------: | ----: | -----------: | ------: | -------: | --------: | --------: | ---: | ------: | ----------: | ---------: | ----------------------: | ---: | ---: | ---: | ----: | -----: | -------: |
|    0 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    1 |      1 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    2 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    3 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    4 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      1 |        0 | 0 |

Maintenant, vous √™tes pr√™t √† entra√Æner votre mod√®le !

## Choisir votre classificateur

Maintenant que vos donn√©es sont propres et pr√™tes pour l'entra√Ænement, vous devez d√©cider quel algorithme utiliser pour la t√¢che. 

Scikit-learn regroupe la classification sous l'apprentissage supervis√©, et dans cette cat√©gorie, vous trouverez de nombreuses fa√ßons de classer. [La vari√©t√©](https://scikit-learn.org/stable/supervised_learning.html) est assez d√©routante √† premi√®re vue. Les m√©thodes suivantes incluent toutes des techniques de classification :

- Mod√®les lin√©aires
- Machines √† vecteurs de support
- Descente de gradient stochastique
- Voisins les plus proches
- Processus gaussiens
- Arbres de d√©cision
- M√©thodes d'ensemble (classificateur par vote)
- Algorithmes multiclasses et multi-sorties (classification multiclasses et multi-√©tiquettes, classification multiclasses-multi-sorties)

> Vous pouvez √©galement utiliser [des r√©seaux neuronaux pour classer des donn√©es](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#classification), mais cela d√©passe le cadre de cette le√ßon.

### Quel classificateur choisir ?

Alors, quel classificateur devriez-vous choisir ? Souvent, passer par plusieurs et chercher un bon r√©sultat est une mani√®re de tester. Scikit-learn propose une [comparaison c√¥te √† c√¥te](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) sur un ensemble de donn√©es cr√©√©, comparant KNeighbors, SVC de deux mani√®res, GaussianProcessClassifier, DecisionTreeClassifier, RandomForestClassifier, MLPClassifier, AdaBoostClassifier, GaussianNB et QuadraticDiscriminantAnalysis, montrant les r√©sultats visualis√©s : 

![comparaison des classificateurs](../../../../translated_images/comparison.edfab56193a85e7fdecbeaa1b1f8c99e94adbf7178bed0de902090cf93d6734f.mo.png)
> Graphiques g√©n√©r√©s dans la documentation de Scikit-learn

> AutoML r√©sout ce probl√®me de mani√®re √©l√©gante en ex√©cutant ces comparaisons dans le cloud, vous permettant de choisir le meilleur algorithme pour vos donn√©es. Essayez-le [ici](https://docs.microsoft.com/learn/modules/automate-model-selection-with-azure-automl/?WT.mc_id=academic-77952-leestott)

### Une meilleure approche

Une meilleure fa√ßon que de deviner √† l'aveugle, cependant, est de suivre les id√©es sur cette [fiche de triche ML](https://docs.microsoft.com/azure/machine-learning/algorithm-cheat-sheet?WT.mc_id=academic-77952-leestott) t√©l√©chargeable. Ici, nous d√©couvrons que, pour notre probl√®me multiclass, nous avons plusieurs choix :

![fiche de triche pour les probl√®mes multiclasses](../../../../translated_images/cheatsheet.07a475ea444d22234cb8907a3826df5bdd1953efec94bd18e4496f36ff60624a.mo.png)
> Une section de la fiche de triche d'algorithme de Microsoft, d√©taillant les options de classification multiclasses

‚úÖ T√©l√©chargez cette fiche de triche, imprimez-la et accrochez-la sur votre mur !

### Raisonnement

Voyons si nous pouvons raisonner √† travers diff√©rentes approches compte tenu des contraintes que nous avons :

- **Les r√©seaux neuronaux sont trop lourds**. √âtant donn√© notre jeu de donn√©es propre, mais minimal, et le fait que nous ex√©cutons l'entra√Ænement localement via des notebooks, les r√©seaux neuronaux sont trop lourds pour cette t√¢che.
- **Pas de classificateur √† deux classes**. Nous n'utilisons pas de classificateur √† deux classes, donc cela √©limine one-vs-all. 
- **Un arbre de d√©cision ou une r√©gression logistique pourraient fonctionner**. Un arbre de d√©cision pourrait fonctionner, ou une r√©gression logistique pour des donn√©es multiclasses. 
- **Les arbres de d√©cision boost√©s multiclasses r√©solvent un probl√®me diff√©rent**. L'arbre de d√©cision boost√© multiclasses est le plus adapt√© aux t√¢ches non param√©triques, par exemple, les t√¢ches con√ßues pour √©tablir des classements, donc il n'est pas utile pour nous.

### Utilisation de Scikit-learn 

Nous utiliserons Scikit-learn pour analyser nos donn√©es. Cependant, il existe de nombreuses fa√ßons d'utiliser la r√©gression logistique dans Scikit-learn. Jetez un ≈ìil aux [param√®tres √† passer](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regressio#sklearn.linear_model.LogisticRegression).  

Essentiellement, il y a deux param√®tres importants - `multi_class` and `solver` - that we need to specify, when we ask Scikit-learn to perform a logistic regression. The `multi_class` value applies a certain behavior. The value of the solver is what algorithm to use. Not all solvers can be paired with all `multi_class` values.

According to the docs, in the multiclass case, the training algorithm:

- **Uses the one-vs-rest (OvR) scheme**, if the `multi_class` option is set to `ovr`
- **Uses the cross-entropy loss**, if the `multi_class` option is set to `multinomial`. (Currently the `multinomial` option is supported only by the ‚Äòlbfgs‚Äô, ‚Äòsag‚Äô, ‚Äòsaga‚Äô and ‚Äònewton-cg‚Äô solvers.)"

> üéì The 'scheme' here can either be 'ovr' (one-vs-rest) or 'multinomial'. Since logistic regression is really designed to support binary classification, these schemes allow it to better handle multiclass classification tasks. [source](https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/)

> üéì The 'solver' is defined as "the algorithm to use in the optimization problem". [source](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regressio#sklearn.linear_model.LogisticRegression).

Scikit-learn offers this table to explain how solvers handle different challenges presented by different kinds of data structures:

![solvers](../../../../translated_images/solvers.5fc648618529e627dfac29b917b3ccabda4b45ee8ed41b0acb1ce1441e8d1ef1.mo.png)

## Exercise - split the data

We can focus on logistic regression for our first training trial since you recently learned about the latter in a previous lesson.
Split your data into training and testing groups by calling `train_test_split()`:

```python
X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)
```

## Exercice - appliquer la r√©gression logistique

Puisque vous utilisez le cas multiclasses, vous devez choisir quel _sch√©ma_ utiliser et quel _solveur_ d√©finir. Utilisez LogisticRegression avec un param√®tre multiclass et le solveur **liblinear** pour l'entra√Ænement.

1. Cr√©ez une r√©gression logistique avec multi_class d√©fini sur `ovr` and the solver set to `liblinear` :

    ```python
    lr = LogisticRegression(multi_class='ovr',solver='liblinear')
    model = lr.fit(X_train, np.ravel(y_train))
    
    accuracy = model.score(X_test, y_test)
    print ("Accuracy is {}".format(accuracy))
    ```

    ‚úÖ Essayez un autre solveur comme `lbfgs`, which is often set as default

    > Note, use Pandas [`ravel`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.ravel.html) pour aplatir vos donn√©es si n√©cessaire.

    L'exactitude est bonne √† plus de **80%** !

1. Vous pouvez voir ce mod√®le en action en testant une ligne de donn√©es (#50) :

    ```python
    print(f'ingredients: {X_test.iloc[50][X_test.iloc[50]!=0].keys()}')
    print(f'cuisine: {y_test.iloc[50]}')
    ```

    Le r√©sultat est imprim√© :

   ```output
   ingredients: Index(['cilantro', 'onion', 'pea', 'potato', 'tomato', 'vegetable_oil'], dtype='object')
   cuisine: indian
   ```

   ‚úÖ Essayez un num√©ro de ligne diff√©rent et v√©rifiez les r√©sultats

1. En creusant plus profond√©ment, vous pouvez v√©rifier l'exactitude de cette pr√©diction :

    ```python
    test= X_test.iloc[50].values.reshape(-1, 1).T
    proba = model.predict_proba(test)
    classes = model.classes_
    resultdf = pd.DataFrame(data=proba, columns=classes)
    
    topPrediction = resultdf.T.sort_values(by=[0], ascending = [False])
    topPrediction.head()
    ```

    Le r√©sultat est imprim√© - la cuisine indienne est sa meilleure supposition, avec une bonne probabilit√© :

    |          |        0 |
    | -------: | -------: |
    |   indien | 0.715851 |
    |  chinois | 0.229475 |
    | japonais | 0.029763 |
    |   cor√©en | 0.017277 |
    |     tha√Ø | 0.007634 |

    ‚úÖ Pouvez-vous expliquer pourquoi le mod√®le est assez s√ªr qu'il s'agit d'une cuisine indienne ?

1. Obtenez plus de d√©tails en imprimant un rapport de classification, comme vous l'avez fait dans les le√ßons de r√©gression :

    ```python
    y_pred = model.predict(X_test)
    print(classification_report(y_test,y_pred))
    ```

    |              | pr√©cision | rappel | f1-score | support |
    | ------------ | --------- | ------ | -------- | ------- |
    | chinois      | 0.73      | 0.71   | 0.72     | 229     |
    | indien       | 0.91      | 0.93   | 0.92     | 254     |
    | japonais     | 0.70      | 0.75   | 0.72     | 220     |
    | cor√©en       | 0.86      | 0.76   | 0.81     | 242     |
    | tha√Ø         | 0.79      | 0.85   | 0.82     | 254     |
    | exactitude   | 0.80      | 1199   |          |         |
    | moyenne macro| 0.80      | 0.80   | 0.80     | 1199    |
    | moyenne pond√©r√©e | 0.80  | 0.80   | 0.80     | 1199    |

## üöÄD√©fi

Dans cette le√ßon, vous avez utilis√© vos donn√©es nettoy√©es pour construire un mod√®le d'apprentissage automatique capable de pr√©dire une cuisine nationale en fonction d'une s√©rie d'ingr√©dients. Prenez le temps de parcourir les nombreuses options que Scikit-learn offre pour classer des donn√©es. Plongez plus profond√©ment dans le concept de 'solveur' pour comprendre ce qui se passe en coulisses.

## [Quiz post-conf√©rence](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/22/)

## Revue & Auto-√©tude

Explorez un peu plus les math√©matiques derri√®re la r√©gression logistique dans [cette le√ßon](https://people.eecs.berkeley.edu/~russell/classes/cs194/f11/lectures/CS194%20Fall%202011%20Lecture%2006.pdf)
## Devoir 

[√âtudiez les solveurs](assignment.md)

I'm sorry, but I can't provide a translation to "mo" as it is not clear which language you are referring to. If you mean "Moldovan" (which is essentially Romanian), I can help with that. Please confirm or specify the language you want the text translated into.