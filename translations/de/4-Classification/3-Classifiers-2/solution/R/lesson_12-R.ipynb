{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "lesson_12-R.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "ir",
   "display_name": "R"
  },
  "language_info": {
   "name": "R"
  },
  "coopTranslator": {
   "original_hash": "fab50046ca413a38939d579f8432274f",
   "translation_date": "2025-09-04T02:37:39+00:00",
   "source_file": "4-Classification/3-Classifiers-2/solution/R/lesson_12-R.ipynb",
   "language_code": "de"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsFutf_ygqSx"
   },
   "source": [
    "# Erstellen Sie ein Klassifikationsmodell: K√∂stliche asiatische und indische K√ºchen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HD54bEefgtNO"
   },
   "source": [
    "## K√ºchenklassifikatoren 2\n",
    "\n",
    "In dieser zweiten Lektion zur Klassifikation werden wir `weitere M√∂glichkeiten` zur Klassifikation von kategorialen Daten erkunden. Au√üerdem werden wir die Auswirkungen der Wahl eines Klassifikators gegen√ºber einem anderen kennenlernen.\n",
    "\n",
    "### [**Quiz vor der Vorlesung**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/23/)\n",
    "\n",
    "### **Voraussetzungen**\n",
    "\n",
    "Wir gehen davon aus, dass Sie die vorherigen Lektionen abgeschlossen haben, da wir einige zuvor erlernte Konzepte weiterf√ºhren werden.\n",
    "\n",
    "F√ºr diese Lektion ben√∂tigen wir die folgenden Pakete:\n",
    "\n",
    "-   `tidyverse`: Das [tidyverse](https://www.tidyverse.org/) ist eine [Sammlung von R-Paketen](https://www.tidyverse.org/packages), die darauf abzielt, Datenwissenschaft schneller, einfacher und unterhaltsamer zu machen!\n",
    "\n",
    "-   `tidymodels`: Das [tidymodels](https://www.tidymodels.org/) Framework ist eine [Sammlung von Paketen](https://www.tidymodels.org/packages/) f√ºr Modellierung und maschinelles Lernen.\n",
    "\n",
    "-   `themis`: Das [themis-Paket](https://themis.tidymodels.org/) bietet zus√§tzliche Rezeptschritte f√ºr den Umgang mit unausgewogenen Daten.\n",
    "\n",
    "Sie k√∂nnen diese Pakete wie folgt installieren:\n",
    "\n",
    "`install.packages(c(\"tidyverse\", \"tidymodels\", \"kernlab\", \"themis\", \"ranger\", \"xgboost\", \"kknn\"))`\n",
    "\n",
    "Alternativ √ºberpr√ºft das untenstehende Skript, ob Sie die f√ºr dieses Modul ben√∂tigten Pakete installiert haben, und installiert sie f√ºr Sie, falls sie fehlen.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vZ57IuUxgyQt"
   },
   "source": [
    "suppressWarnings(if (!require(\"pacman\"))install.packages(\"pacman\"))\n",
    "\n",
    "pacman::p_load(tidyverse, tidymodels, themis, kernlab, ranger, xgboost, kknn)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z22M-pj4g07x"
   },
   "source": [
    "## **1. Eine Klassifikations√ºbersicht**\n",
    "\n",
    "In unserer [vorherigen Lektion](https://github.com/microsoft/ML-For-Beginners/tree/main/4-Classification/2-Classifiers-1) haben wir versucht, die Frage zu beantworten: Wie w√§hlt man zwischen mehreren Modellen aus? In hohem Ma√üe h√§ngt dies von den Eigenschaften der Daten und der Art des Problems ab, das wir l√∂sen m√∂chten (zum Beispiel Klassifikation oder Regression?).\n",
    "\n",
    "Zuvor haben wir die verschiedenen M√∂glichkeiten kennengelernt, die Ihnen zur Verf√ºgung stehen, wenn Sie Daten mithilfe von Microsofts Spickzettel klassifizieren. Das Machine-Learning-Framework von Python, Scikit-learn, bietet einen √§hnlichen, aber detaillierteren Spickzettel, der Ihnen dabei helfen kann, Ihre Auswahl an Sch√§tzern (ein anderer Begriff f√ºr Klassifikatoren) weiter einzugrenzen:\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/map.png\"\n",
    "   width=\"700\"/>\n",
    "   <figcaption></figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1i3xRIVg7vG"
   },
   "source": [
    "> Tipp: [Besuchen Sie diese Karte online](https://scikit-learn.org/stable/tutorial/machine_learning_map/) und klicken Sie entlang des Pfads, um die Dokumentation zu lesen.\n",
    ">\n",
    "> Die [Tidymodels-Referenzseite](https://www.tidymodels.org/find/parsnip/#models) bietet ebenfalls eine hervorragende Dokumentation √ºber verschiedene Modelltypen.\n",
    "\n",
    "### **Der Plan** üó∫Ô∏è\n",
    "\n",
    "Diese Karte ist sehr hilfreich, sobald Sie ein klares Verst√§ndnis Ihrer Daten haben, da Sie entlang ihrer Pfade zu einer Entscheidung ‚Äûgehen‚Äú k√∂nnen:\n",
    "\n",
    "-   Wir haben \\>50 Proben\n",
    "\n",
    "-   Wir m√∂chten eine Kategorie vorhersagen\n",
    "\n",
    "-   Wir haben beschriftete Daten\n",
    "\n",
    "-   Wir haben weniger als 100.000 Proben\n",
    "\n",
    "-   ‚ú® Wir k√∂nnen einen Linear SVC w√§hlen\n",
    "\n",
    "-   Wenn das nicht funktioniert, da wir numerische Daten haben\n",
    "\n",
    "    -   K√∂nnen wir einen ‚ú® KNeighbors Classifier ausprobieren\n",
    "\n",
    "        -   Wenn das nicht funktioniert, probieren Sie ‚ú® SVC und ‚ú® Ensemble Classifiers\n",
    "\n",
    "Dies ist ein sehr hilfreicher Pfad, dem man folgen kann. Jetzt legen wir direkt los und nutzen das [tidymodels](https://www.tidymodels.org/) Modellierungs-Framework: eine konsistente und flexible Sammlung von R-Paketen, die entwickelt wurden, um gute statistische Praktiken zu f√∂rdern üòä.\n",
    "\n",
    "## 2. Daten aufteilen und mit unausgewogenen Datens√§tzen umgehen.\n",
    "\n",
    "Aus unseren vorherigen Lektionen haben wir gelernt, dass es eine Reihe von gemeinsamen Zutaten in unseren K√ºchen gab. Au√üerdem gab es eine ziemlich ungleiche Verteilung in der Anzahl der K√ºchen.\n",
    "\n",
    "Wir werden damit umgehen, indem wir:\n",
    "\n",
    "-   Die h√§ufigsten Zutaten, die Verwirrung zwischen verschiedenen K√ºchen schaffen, mit `dplyr::select()` entfernen.\n",
    "\n",
    "-   Ein `recipe` verwenden, das die Daten vorverarbeitet, um sie f√ºr die Modellierung vorzubereiten, indem ein `over-sampling`-Algorithmus angewendet wird.\n",
    "\n",
    "Wir haben das oben bereits in der vorherigen Lektion behandelt, daher sollte das ein Kinderspiel sein ü•≥!\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6tj_rN00hClA"
   },
   "source": [
    "# Load the core Tidyverse and Tidymodels packages\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "\n",
    "# Load the original cuisines data\n",
    "df <- read_csv(file = \"https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/data/cuisines.csv\")\n",
    "\n",
    "# Drop id column, rice, garlic and ginger from our original data set\n",
    "df_select <- df %>% \n",
    "  select(-c(1, rice, garlic, ginger)) %>%\n",
    "  # Encode cuisine column as categorical\n",
    "  mutate(cuisine = factor(cuisine))\n",
    "\n",
    "\n",
    "# Create data split specification\n",
    "set.seed(2056)\n",
    "cuisines_split <- initial_split(data = df_select,\n",
    "                                strata = cuisine,\n",
    "                                prop = 0.7)\n",
    "\n",
    "# Extract the data in each split\n",
    "cuisines_train <- training(cuisines_split)\n",
    "cuisines_test <- testing(cuisines_split)\n",
    "\n",
    "# Display distribution of cuisines in the training set\n",
    "cuisines_train %>% \n",
    "  count(cuisine) %>% \n",
    "  arrange(desc(n))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFin5yw3hHb1"
   },
   "source": [
    "### Umgang mit unausgeglichenen Daten\n",
    "\n",
    "Unausgeglichene Daten haben oft negative Auswirkungen auf die Modellleistung. Viele Modelle erzielen die besten Ergebnisse, wenn die Anzahl der Beobachtungen gleich ist, und haben daher Schwierigkeiten mit unausgeglichenen Daten.\n",
    "\n",
    "Es gibt im Wesentlichen zwei Ans√§tze, um mit unausgeglichenen Datens√§tzen umzugehen:\n",
    "\n",
    "-   Hinzuf√ºgen von Beobachtungen zur Minderheitsklasse: `Over-sampling`, z. B. mit einem SMOTE-Algorithmus, der synthetisch neue Beispiele der Minderheitsklasse generiert, indem er die n√§chsten Nachbarn dieser F√§lle verwendet.\n",
    "\n",
    "-   Entfernen von Beobachtungen aus der Mehrheitsklasse: `Under-sampling`\n",
    "\n",
    "In unserer vorherigen Lektion haben wir demonstriert, wie man mit unausgeglichenen Datens√§tzen mithilfe eines `recipe` umgeht. Ein Recipe kann als eine Art Blaupause betrachtet werden, die beschreibt, welche Schritte auf einen Datensatz angewendet werden sollten, um ihn f√ºr die Datenanalyse vorzubereiten. In unserem Fall m√∂chten wir eine gleichm√§√üige Verteilung der Anzahl unserer K√ºchenstile im `training set` erreichen. Legen wir los.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cRzTnHolhLWd"
   },
   "source": [
    "# Load themis package for dealing with imbalanced data\n",
    "library(themis)\n",
    "\n",
    "# Create a recipe for preprocessing training data\n",
    "cuisines_recipe <- recipe(cuisine ~ ., data = cuisines_train) %>%\n",
    "  step_smote(cuisine) \n",
    "\n",
    "# Print recipe\n",
    "cuisines_recipe"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxOQ2ORhhO81"
   },
   "source": [
    "Jetzt sind wir bereit, Modelle zu trainieren üë©‚Äçüíªüë®‚Äçüíª!\n",
    "\n",
    "## 3. √úber multinomiale Regressionsmodelle hinaus\n",
    "\n",
    "In unserer vorherigen Lektion haben wir uns mit multinomialen Regressionsmodellen besch√§ftigt. Lassen Sie uns einige flexiblere Modelle f√ºr die Klassifikation erkunden.\n",
    "\n",
    "### Support Vector Machines\n",
    "\n",
    "Im Kontext der Klassifikation ist `Support Vector Machines` eine Technik des maschinellen Lernens, die versucht, eine *Hyperebene* zu finden, die die Klassen \"optimal\" trennt. Schauen wir uns ein einfaches Beispiel an:\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/svm.png\"\n",
    "   width=\"300\"/>\n",
    "   <figcaption>https://commons.wikimedia.org/w/index.php?curid=22877598</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4Wsd0vZhXYu"
   },
   "source": [
    "H1~ trennt die Klassen nicht. H2~ trennt sie, aber nur mit einem kleinen Abstand. H3~ trennt sie mit dem maximalen Abstand.\n",
    "\n",
    "#### Linearer Support-Vector-Klassifikator\n",
    "\n",
    "Support-Vector-Clustering (SVC) ist ein Mitglied der Familie der Support-Vector-Maschinen (SVM), einer Technik des maschinellen Lernens. Beim SVC wird die Hyperebene so gew√§hlt, dass sie `die meisten` Trainingsbeobachtungen korrekt trennt, aber `einige` Beobachtungen m√∂glicherweise falsch klassifiziert. Indem einige Punkte auf der falschen Seite erlaubt werden, wird die SVM robuster gegen√ºber Ausrei√üern und erzielt dadurch eine bessere Generalisierung auf neue Daten. Der Parameter, der diese Abweichung reguliert, wird als `cost` bezeichnet und hat standardm√§√üig den Wert 1 (siehe `help(\"svm_poly\")`).\n",
    "\n",
    "Lassen Sie uns einen linearen SVC erstellen, indem wir `degree = 1` in einem polynomialen SVM-Modell setzen.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vJpp6nuChlBz"
   },
   "source": [
    "# Make a linear SVC specification\n",
    "svc_linear_spec <- svm_poly(degree = 1) %>% \n",
    "  set_engine(\"kernlab\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle specification and recipe into a worklow\n",
    "svc_linear_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(svc_linear_spec)\n",
    "\n",
    "# Print out workflow\n",
    "svc_linear_wf"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDs8cWNkhoqu"
   },
   "source": [
    "Nun, da wir die Vorverarbeitungsschritte und die Modellspezifikation in einem *Workflow* erfasst haben, k√∂nnen wir fortfahren, den linearen SVC zu trainieren und die Ergebnisse dabei auszuwerten. F√ºr die Leistungskennzahlen erstellen wir ein Metrik-Set, das folgende Werte bewertet: `accuracy`, `sensitivity`, `Positive Predicted Value` und `F Measure`.\n",
    "\n",
    "> `augment()` f√ºgt der angegebenen Datenmenge Spalte(n) f√ºr Vorhersagen hinzu.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "81wiqcwuhrnq"
   },
   "source": [
    "# Train a linear SVC model\n",
    "svc_linear_fit <- svc_linear_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "# Create a metric set\n",
    "eval_metrics <- metric_set(ppv, sens, accuracy, f_meas)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "svc_linear_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UFQvHf-huo3"
   },
   "source": [
    "#### Support Vector Machine\n",
    "\n",
    "Die Support Vector Machine (SVM) ist eine Erweiterung des Support Vector Classifiers, um eine nicht-lineare Grenze zwischen den Klassen zu erm√∂glichen. Im Wesentlichen nutzen SVMs den *Kernel-Trick*, um den Merkmalsraum zu erweitern und sich an nichtlineare Beziehungen zwischen den Klassen anzupassen. Eine beliebte und √§u√üerst flexible Kernel-Funktion, die von SVMs verwendet wird, ist die *Radial Basis Function.* Schauen wir uns an, wie sie sich auf unseren Daten schl√§gt.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-KX4S8mzhzmp"
   },
   "source": [
    "set.seed(2056)\n",
    "\n",
    "# Make an RBF SVM specification\n",
    "svm_rbf_spec <- svm_rbf() %>% \n",
    "  set_engine(\"kernlab\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle specification and recipe into a worklow\n",
    "svm_rbf_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(svm_rbf_spec)\n",
    "\n",
    "\n",
    "# Train an RBF model\n",
    "svm_rbf_fit <- svm_rbf_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "svm_rbf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBFSa7WSh4HQ"
   },
   "source": [
    "Viel besser ü§©!\n",
    "\n",
    "> ‚úÖ Bitte siehe:\n",
    ">\n",
    "> -   [*Support Vector Machines*](https://bradleyboehmke.github.io/HOML/svm.html), Hands-on Machine Learning mit R\n",
    ">\n",
    "> -   [*Support Vector Machines*](https://www.statlearning.com/), Eine Einf√ºhrung in Statistisches Lernen mit Anwendungen in R\n",
    ">\n",
    "> f√ºr weiterf√ºhrende Lekt√ºre.\n",
    "\n",
    "### N√§chster-Nachbar-Klassifikatoren\n",
    "\n",
    "Der *k*-n√§chste Nachbar (KNN) ist ein Algorithmus, bei dem jede Beobachtung basierend auf ihrer *√Ñhnlichkeit* zu anderen Beobachtungen vorhergesagt wird.\n",
    "\n",
    "Lass uns einen auf unsere Daten anwenden.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k4BxxBcdh9Ka"
   },
   "source": [
    "# Make a KNN specification\n",
    "knn_spec <- nearest_neighbor() %>% \n",
    "  set_engine(\"kknn\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "knn_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(knn_spec)\n",
    "\n",
    "# Train a boosted tree model\n",
    "knn_wf_fit <- knn_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "knn_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaegQseriAcj"
   },
   "source": [
    "Es scheint, dass dieses Modell nicht besonders gut abschneidet. Wahrscheinlich wird eine Anpassung der Modellparameter (siehe `help(\"nearest_neighbor\")`) die Leistung verbessern. Probieren Sie es unbedingt aus.\n",
    "\n",
    "> ‚úÖ Weitere Informationen finden Sie unter:\n",
    ">\n",
    "> -   [Hands-on Machine Learning with R](https://bradleyboehmke.github.io/HOML/)\n",
    ">\n",
    "> -   [An Introduction to Statistical Learning with Applications in R](https://www.statlearning.com/)\n",
    ">\n",
    "> um mehr √ºber *K*-Nearest Neighbors-Klassifikatoren zu erfahren.\n",
    "\n",
    "### Ensemble-Klassifikatoren\n",
    "\n",
    "Ensemble-Algorithmen funktionieren, indem sie mehrere Basis-Estimatoren kombinieren, um ein optimales Modell zu erstellen, entweder durch:\n",
    "\n",
    "`bagging`: Anwenden einer *Mittelungsfunktion* auf eine Sammlung von Basismodellen\n",
    "\n",
    "`boosting`: Erstellen einer Sequenz von Modellen, die aufeinander aufbauen, um die Vorhersageleistung zu verbessern.\n",
    "\n",
    "Beginnen wir mit einem Random-Forest-Modell, das eine gro√üe Sammlung von Entscheidungsb√§umen erstellt und dann eine Mittelungsfunktion anwendet, um ein besseres Gesamtmodell zu erhalten.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "49DPoVs6iK1M"
   },
   "source": [
    "# Make a random forest specification\n",
    "rf_spec <- rand_forest() %>% \n",
    "  set_engine(\"ranger\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "rf_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(rf_spec)\n",
    "\n",
    "# Train a random forest model\n",
    "rf_wf_fit <- rf_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "rf_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGVYwC_aiUWc"
   },
   "source": [
    "Gute Arbeit üëè!\n",
    "\n",
    "Lass uns auch ein Boosted-Tree-Modell ausprobieren.\n",
    "\n",
    "Boosted Tree definiert eine Ensemble-Methode, die eine Reihe von sequentiellen Entscheidungsb√§umen erstellt, bei denen jeder Baum von den Ergebnissen der vorherigen B√§ume abh√§ngt, um den Fehler schrittweise zu reduzieren. Der Fokus liegt auf den Gewichten der falsch klassifizierten Elemente, und die Anpassung f√ºr den n√§chsten Klassifikator wird entsprechend korrigiert.\n",
    "\n",
    "Es gibt verschiedene M√∂glichkeiten, dieses Modell anzupassen (siehe `help(\"boost_tree\")`). In diesem Beispiel passen wir Boosted Trees √ºber die `xgboost`-Engine an.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Py1YWo-micWs"
   },
   "source": [
    "# Make a boosted tree specification\n",
    "boost_spec <- boost_tree(trees = 200) %>% \n",
    "  set_engine(\"xgboost\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "boost_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(boost_spec)\n",
    "\n",
    "# Train a boosted tree model\n",
    "boost_wf_fit <- boost_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "boost_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNQnbuejigZM"
   },
   "source": [
    "> ‚úÖ Bitte sehen Sie:\n",
    ">\n",
    "> -   [Machine Learning for Social Scientists](https://cimentadaj.github.io/ml_socsci/tree-based-methods.html#random-forests)\n",
    ">\n",
    "> -   [Hands-on Machine Learning with R](https://bradleyboehmke.github.io/HOML/)\n",
    ">\n",
    "> -   [An Introduction to Statistical Learning with Applications in R](https://www.statlearning.com/)\n",
    ">\n",
    "> -   <https://algotech.netlify.app/blog/xgboost/> - Untersucht das AdaBoost-Modell, das eine gute Alternative zu xgboost darstellt.\n",
    ">\n",
    "> um mehr √ºber Ensemble-Klassifikatoren zu erfahren.\n",
    "\n",
    "## 4. Extra - Vergleich mehrerer Modelle\n",
    "\n",
    "Wir haben in diesem Lab eine ganze Reihe von Modellen angepasst üôå. Es kann m√ºhsam oder aufwendig werden, viele Workflows aus verschiedenen Sets von Preprozessoren und/oder Modellspezifikationen zu erstellen und dann die Leistungskennzahlen einzeln zu berechnen.\n",
    "\n",
    "Schauen wir, ob wir das vereinfachen k√∂nnen, indem wir eine Funktion erstellen, die eine Liste von Workflows auf den Trainingssatz anpasst und dann die Leistungskennzahlen basierend auf dem Testsatz zur√ºckgibt. Wir werden `map()` und `map_dfr()` aus dem [purrr](https://purrr.tidyverse.org/) Paket verwenden, um Funktionen auf jedes Element in einer Liste anzuwenden.\n",
    "\n",
    "> [`map()`](https://purrr.tidyverse.org/reference/map.html)-Funktionen erm√∂glichen es, viele for-Schleifen durch Code zu ersetzen, der sowohl k√ºrzer als auch leichter lesbar ist. Der beste Ort, um mehr √ºber die [`map()`](https://purrr.tidyverse.org/reference/map.html)-Funktionen zu lernen, ist das [Kapitel √ºber Iteration](http://r4ds.had.co.nz/iteration.html) in \"R for Data Science\".\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Qzb7LyZnimd2"
   },
   "source": [
    "set.seed(2056)\n",
    "\n",
    "# Create a metric set\n",
    "eval_metrics <- metric_set(ppv, sens, accuracy, f_meas)\n",
    "\n",
    "# Define a function that returns performance metrics\n",
    "compare_models <- function(workflow_list, train_set, test_set){\n",
    "  \n",
    "  suppressWarnings(\n",
    "    # Fit each model to the train_set\n",
    "    map(workflow_list, fit, data = train_set) %>% \n",
    "    # Make predictions on the test set\n",
    "      map_dfr(augment, new_data = test_set, .id = \"model\") %>%\n",
    "    # Select desired columns\n",
    "      select(model, cuisine, .pred_class) %>% \n",
    "    # Evaluate model performance\n",
    "      group_by(model) %>% \n",
    "      eval_metrics(truth = cuisine, estimate = .pred_class) %>% \n",
    "      ungroup()\n",
    "  )\n",
    "  \n",
    "} # End of function"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fwa712sNisDA"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3i4VJOi2iu-a"
   },
   "source": [
    "# Make a list of workflows\n",
    "workflow_list <- list(\n",
    "  \"svc\" = svc_linear_wf,\n",
    "  \"svm\" = svm_rbf_wf,\n",
    "  \"knn\" = knn_wf,\n",
    "  \"random_forest\" = rf_wf,\n",
    "  \"xgboost\" = boost_wf)\n",
    "\n",
    "# Call the function\n",
    "set.seed(2056)\n",
    "perf_metrics <- compare_models(workflow_list = workflow_list, train_set = cuisines_train, test_set = cuisines_test)\n",
    "\n",
    "# Print out performance metrics\n",
    "perf_metrics %>% \n",
    "  group_by(.metric) %>% \n",
    "  arrange(desc(.estimate)) %>% \n",
    "  slice_head(n=7)\n",
    "\n",
    "# Compare accuracy\n",
    "perf_metrics %>% \n",
    "  filter(.metric == \"accuracy\") %>% \n",
    "  arrange(desc(.estimate))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuWK_lEli4nW"
   },
   "source": [
    "[**workflowset**](https://workflowsets.tidymodels.org/) Paket erm√∂glicht es Nutzern, eine gro√üe Anzahl von Modellen zu erstellen und einfach anzupassen. Es ist jedoch haupts√§chlich darauf ausgelegt, mit Resampling-Techniken wie `cross-validation` zu arbeiten, eine Methode, die wir noch behandeln werden.\n",
    "\n",
    "## **üöÄHerausforderung**\n",
    "\n",
    "Jede dieser Techniken hat eine Vielzahl von Parametern, die Sie anpassen k√∂nnen, wie zum Beispiel `cost` bei SVMs, `neighbors` bei KNN, `mtry` (zuf√§llig ausgew√§hlte Pr√§diktoren) bei Random Forest.\n",
    "\n",
    "Recherchieren Sie die Standardparameter jedes Modells und √ºberlegen Sie, was das Anpassen dieser Parameter f√ºr die Qualit√§t des Modells bedeuten w√ºrde.\n",
    "\n",
    "Um mehr √ºber ein bestimmtes Modell und seine Parameter zu erfahren, verwenden Sie: `help(\"model\")`, z. B. `help(\"rand_forest\")`.\n",
    "\n",
    "> In der Praxis *sch√§tzen* wir normalerweise die *besten Werte* f√ºr diese Parameter, indem wir viele Modelle auf einem `simulierten Datensatz` trainieren und messen, wie gut diese Modelle abschneiden. Dieser Prozess wird **Tuning** genannt.\n",
    "\n",
    "### [**Quiz nach der Vorlesung**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/24/)\n",
    "\n",
    "### **√úberblick & Selbststudium**\n",
    "\n",
    "Es gibt viele Fachbegriffe in diesen Lektionen, nehmen Sie sich daher einen Moment Zeit, um [diese Liste](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) n√ºtzlicher Begriffe zu √ºberpr√ºfen!\n",
    "\n",
    "#### EIN DANKESCH√ñN AN:\n",
    "\n",
    "[`Allison Horst`](https://twitter.com/allison_horst/) f√ºr die gro√üartigen Illustrationen, die R einladender und ansprechender machen. Weitere Illustrationen finden Sie in ihrer [Galerie](https://www.google.com/url?q=https://github.com/allisonhorst/stats-illustrations&sa=D&source=editors&ust=1626380772530000&usg=AOvVaw3zcfyCizFQZpkSLzxiiQEM).\n",
    "\n",
    "[Cassie Breviu](https://www.twitter.com/cassieview) und [Jen Looper](https://www.twitter.com/jenlooper) f√ºr die Erstellung der urspr√ºnglichen Python-Version dieses Moduls ‚ô•Ô∏è\n",
    "\n",
    "Viel Spa√ü beim Lernen,\n",
    "\n",
    "[Eric](https://twitter.com/ericntay), Gold Microsoft Learn Student Ambassador.\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/r_learners_sm.jpeg\"\n",
    "   width=\"569\"/>\n",
    "   <figcaption>Kunstwerk von @allison_horst</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Haftungsausschluss**:  \nDieses Dokument wurde mit dem KI-√úbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, weisen wir darauf hin, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache sollte als ma√ügebliche Quelle betrachtet werden. F√ºr kritische Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die aus der Nutzung dieser √úbersetzung entstehen.\n"
   ]
  }
 ]
}