# Einf√ºhrung in das Clustering

Clustering ist eine Art von [Unsupervised Learning](https://wikipedia.org/wiki/Unsupervised_learning), die davon ausgeht, dass ein Datensatz unbeschriftet ist oder dass seine Eingaben nicht mit vordefinierten Ausgaben √ºbereinstimmen. Es verwendet verschiedene Algorithmen, um unbeschriftete Daten zu durchsuchen und Gruppierungen gem√§√ü den Mustern, die es in den Daten erkennt, bereitzustellen.

[![No One Like You von PSquare](https://img.youtube.com/vi/ty2advRiWJM/0.jpg)](https://youtu.be/ty2advRiWJM "No One Like You von PSquare")

> üé• Klicken Sie auf das obige Bild f√ºr ein Video. W√§hrend Sie das maschinelle Lernen mit Clustering studieren, genie√üen Sie einige Nigerian Dance Hall-Tracks ‚Äì dies ist ein hochbewertetes Lied aus dem Jahr 2014 von PSquare.

## [Vorlesungsquiz](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/27/)

### Einf√ºhrung

[Clustering](https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-30164-8_124) ist sehr n√ºtzlich f√ºr die Datenexploration. Lassen Sie uns sehen, ob es helfen kann, Trends und Muster in der Art und Weise zu entdecken, wie nigerianische Zuschauer Musik konsumieren.

‚úÖ Nehmen Sie sich einen Moment Zeit, um √ºber die Anwendungen des Clustering nachzudenken. Im wirklichen Leben passiert Clustering immer dann, wenn Sie einen W√§scheberg haben und die Kleidung Ihrer Familienmitglieder sortieren m√ºssen üß¶üëïüëñü©≤. In der Datenwissenschaft tritt Clustering auf, wenn versucht wird, die Vorlieben eines Benutzers zu analysieren oder die Merkmale eines unbeschrifteten Datensatzes zu bestimmen. Clustering hilft auf eine Weise, Chaos zu ordnen, wie eine Sockenschublade.

[![Einf√ºhrung in ML](https://img.youtube.com/vi/esmzYhuFnds/0.jpg)](https://youtu.be/esmzYhuFnds "Einf√ºhrung in das Clustering")

> üé• Klicken Sie auf das obige Bild f√ºr ein Video: MITs John Guttag f√ºhrt in das Clustering ein.

In einem professionellen Umfeld kann Clustering verwendet werden, um Dinge wie Marktsegmentierung zu bestimmen, um herauszufinden, welche Altersgruppen welche Artikel kaufen. Eine andere Anwendung k√∂nnte die Anomalieerkennung sein, um m√∂glicherweise Betrug aus einem Datensatz von Kreditkartentransaktionen zu erkennen. Oder Sie k√∂nnten Clustering verwenden, um Tumore in einer Reihe medizinischer Scans zu identifizieren.

‚úÖ Denken Sie einen Moment dar√ºber nach, wie Sie Clustering ‚Äûin der Wildnis‚Äú begegnet sind, sei es im Bankwesen, im E-Commerce oder in einem Gesch√§ftsumfeld.

> üéì Interessanterweise stammt die Clusteranalyse aus den Bereichen Anthropologie und Psychologie in den 1930er Jahren. K√∂nnen Sie sich vorstellen, wie sie verwendet worden sein k√∂nnte?

Alternativ k√∂nnten Sie es verwenden, um Suchergebnisse zu gruppieren ‚Äì nach Einkaufslinks, Bildern oder Bewertungen zum Beispiel. Clustering ist n√ºtzlich, wenn Sie einen gro√üen Datensatz haben, den Sie reduzieren m√∂chten und auf dem Sie eine detailliertere Analyse durchf√ºhren m√∂chten, sodass die Technik verwendet werden kann, um mehr √ºber Daten zu lernen, bevor andere Modelle erstellt werden.

‚úÖ Sobald Ihre Daten in Clustern organisiert sind, weisen Sie ihnen eine Cluster-ID zu, und diese Technik kann n√ºtzlich sein, um die Privatsph√§re eines Datensatzes zu wahren; Sie k√∂nnen stattdessen auf einen Datenpunkt √ºber seine Cluster-ID verweisen, anstatt auf aufschlussreichere identifizierbare Daten. K√∂nnen Sie an andere Gr√ºnde denken, warum Sie auf eine Cluster-ID anstelle anderer Elemente des Clusters verweisen w√ºrden, um ihn zu identifizieren?

Vertiefen Sie Ihr Verst√§ndnis der Clustering-Techniken in diesem [Lernmodul](https://docs.microsoft.com/learn/modules/train-evaluate-cluster-models?WT.mc_id=academic-77952-leestott).

## Erste Schritte mit Clustering

[Scikit-learn bietet eine gro√üe Auswahl](https://scikit-learn.org/stable/modules/clustering.html) an Methoden zur Durchf√ºhrung von Clustering. Die Wahl, die Sie treffen, h√§ngt von Ihrem Anwendungsfall ab. Laut der Dokumentation hat jede Methode verschiedene Vorteile. Hier ist eine vereinfachte Tabelle der von Scikit-learn unterst√ºtzten Methoden und ihrer geeigneten Anwendungsf√§lle:

| Methodenname                  | Anwendungsfall                                                       |
| :---------------------------- | :------------------------------------------------------------------- |
| K-Means                       | allgemeiner Zweck, induktiv                                         |
| Affinit√§tsausbreitung         | viele, ungleiche Cluster, induktiv                                  |
| Mean-Shift                    | viele, ungleiche Cluster, induktiv                                  |
| Spektrales Clustering         | wenige, gleichm√§√üige Cluster, transduktiv                           |
| Ward-hierarchisches Clustering | viele, eingeschr√§nkte Cluster, transduktiv                          |
| Agglomeratives Clustering     | viele, eingeschr√§nkte, nicht-euklidische Abst√§nde, transduktiv     |
| DBSCAN                        | nicht-flache Geometrie, ungleiche Cluster, transduktiv             |
| OPTICS                        | nicht-flache Geometrie, ungleiche Cluster mit variabler Dichte, transduktiv |
| Gau√üsche Mischungen           | flache Geometrie, induktiv                                          |
| BIRCH                         | gro√üer Datensatz mit Ausrei√üern, induktiv                          |

> üéì Wie wir Cluster erstellen, h√§ngt stark davon ab, wie wir die Datenpunkte in Gruppen zusammenfassen. Lassen Sie uns einige Begriffe aufschl√ºsseln:
>
> üéì ['Transduktiv' vs. 'induktiv'](https://wikipedia.org/wiki/Transduction_(machine_learning))
> 
> Transduktive Inferenz wird aus beobachteten Trainingsf√§llen abgeleitet, die bestimmten Testf√§llen zugeordnet sind. Induktive Inferenz wird aus Trainingsf√§llen abgeleitet, die auf allgemeine Regeln abzielen, die dann auf Testf√§lle angewendet werden.
> 
> Ein Beispiel: Stellen Sie sich vor, Sie haben einen Datensatz, der nur teilweise beschriftet ist. Einige Dinge sind ‚ÄûPlatten‚Äú, einige ‚ÄûCDs‚Äú und einige sind leer. Ihre Aufgabe ist es, die leeren Felder zu beschriften. Wenn Sie sich f√ºr einen induktiven Ansatz entscheiden, w√ºrden Sie ein Modell trainieren, das nach ‚ÄûPlatten‚Äú und ‚ÄûCDs‚Äú sucht, und diese Beschriftungen auf Ihre unbeschrifteten Daten anwenden. Dieser Ansatz hat Schwierigkeiten, Dinge zu klassifizieren, die tats√§chlich ‚ÄûKassetten‚Äú sind. Ein transduktiver Ansatz hingegen behandelt diese unbekannten Daten effektiver, da er versucht, √§hnliche Elemente zusammenzufassen und dann eine Beschriftung f√ºr eine Gruppe anzuwenden. In diesem Fall k√∂nnten Cluster ‚Äûrunde musikalische Dinge‚Äú und ‚Äûquadratische musikalische Dinge‚Äú widerspiegeln.
> 
> üéì ['Nicht-flache' vs. 'flache' Geometrie](https://datascience.stackexchange.com/questions/52260/terminology-flat-geometry-in-the-context-of-clustering)
> 
> Abgeleitet aus der mathematischen Terminologie bezieht sich nicht-flache vs. flache Geometrie auf die Messung der Abst√§nde zwischen Punkten entweder durch ‚Äûflache‚Äú ([Euklidische](https://wikipedia.org/wiki/Euclidean_geometry)) oder ‚Äûnicht-flache‚Äú (nicht-euklidische) geometrische Methoden.
>
> ‚ÄûFlach‚Äú in diesem Kontext bezieht sich auf die euklidische Geometrie (Teile davon werden als ‚ÄûEbene‚Äú Geometrie gelehrt), und nicht-flach bezieht sich auf nicht-euklidische Geometrie. Was hat Geometrie mit maschinellem Lernen zu tun? Nun, da beide Bereiche auf Mathematik basieren, muss es eine gemeinsame M√∂glichkeit geben, Abst√§nde zwischen Punkten in Clustern zu messen, und das kann auf eine ‚Äûflache‚Äú oder ‚Äûnicht-flache‚Äú Weise geschehen, je nach Art der Daten. [Euklidische Abst√§nde](https://wikipedia.org/wiki/Euclidean_distance) werden als die L√§nge eines Liniensegments zwischen zwei Punkten gemessen. [Nicht-euklidische Abst√§nde](https://wikipedia.org/wiki/Non-Euclidean_geometry) werden entlang einer Kurve gemessen. Wenn Ihre Daten, visualisiert, nicht auf einer Ebene zu existieren scheinen, m√ºssen Sie m√∂glicherweise einen spezialisierten Algorithmus verwenden, um damit umzugehen.
>
![Flache vs. nicht-flache Geometrie Infografik](../../../../translated_images/flat-nonflat.d1c8c6e2a96110c1d57fa0b72913f6aab3c245478524d25baf7f4a18efcde224.de.png)
> Infografik von [Dasani Madipalli](https://twitter.com/dasani_decoded)
> 
> üéì ['Abst√§nde'](https://web.stanford.edu/class/cs345a/slides/12-clustering.pdf)
> 
> Cluster werden durch ihre Distanzmatrix definiert, z. B. die Abst√§nde zwischen Punkten. Diese Distanz kann auf verschiedene Weise gemessen werden. Euklidische Cluster werden durch den Durchschnitt der Punktwerte definiert und enthalten einen ‚ÄûZentroid‚Äú oder Mittelpunkt. Abst√§nde werden somit durch die Distanz zu diesem Zentroid gemessen. Nicht-euklidische Abst√§nde beziehen sich auf ‚ÄûClustroids‚Äú, den Punkt, der anderen Punkten am n√§chsten ist. Clustroids k√∂nnen wiederum auf verschiedene Weise definiert werden.
> 
> üéì ['Eingeschr√§nkt'](https://wikipedia.org/wiki/Constrained_clustering)
> 
> [Eingeschr√§nktes Clustering](https://web.cs.ucdavis.edu/~davidson/Publications/ICDMTutorial.pdf) f√ºhrt ‚Äûsemi-supervised‚Äú Lernen in diese un√ºberwachte Methode ein. Die Beziehungen zwischen Punkten werden als ‚Äûk√∂nnen nicht verlinken‚Äú oder ‚Äûm√ºssen verlinken‚Äú gekennzeichnet, sodass einige Regeln auf den Datensatz angewendet werden.
>
> Ein Beispiel: Wenn ein Algorithmus auf einen Batch von unbeschrifteten oder halb-beschrifteten Daten losgelassen wird, k√∂nnen die erzeugten Cluster von schlechter Qualit√§t sein. Im obigen Beispiel k√∂nnten die Cluster ‚Äûrunde Musikdinge‚Äú, ‚Äûquadratische Musikdinge‚Äú und ‚Äûdreieckige Dinge‚Äú sowie ‚ÄûKekse‚Äú gruppieren. Wenn einige Einschr√§nkungen oder Regeln vorgegeben werden (‚Äûder Artikel muss aus Kunststoff bestehen‚Äú, ‚Äûder Artikel muss in der Lage sein, Musik zu erzeugen‚Äú), kann dies helfen, den Algorithmus zu ‚Äûbeschr√§nken‚Äú, um bessere Entscheidungen zu treffen.
> 
> üéì 'Dichte'
> 
> Daten, die ‚Äûrauschend‚Äú sind, gelten als ‚Äûdicht‚Äú. Die Abst√§nde zwischen Punkten in jedem ihrer Cluster k√∂nnen bei n√§herer Betrachtung mehr oder weniger dicht oder ‚Äû√ºberf√ºllt‚Äú sein, und diese Daten m√ºssen mit der geeigneten Clustering-Methode analysiert werden. [Dieser Artikel](https://www.kdnuggets.com/2020/02/understanding-density-based-clustering.html) zeigt den Unterschied zwischen der Verwendung von K-Means-Clustering und HDBSCAN-Algorithmen zur Untersuchung eines rauschenden Datensatzes mit ungleicher Clusterdichte.

## Clustering-Algorithmen

Es gibt √ºber 100 Clustering-Algorithmen, und ihre Verwendung h√§ngt von der Art der vorliegenden Daten ab. Lassen Sie uns einige der wichtigsten besprechen:

- **Hierarchisches Clustering**. Wenn ein Objekt anhand seiner N√§he zu einem nahegelegenen Objekt klassifiziert wird, anstatt zu einem weiter entfernten, werden Cluster basierend auf der Distanz ihrer Mitglieder zu und von anderen Objekten gebildet. Das agglomerative Clustering von Scikit-learn ist hierarchisch.

   ![Hierarchisches Clustering Infografik](../../../../translated_images/hierarchical.bf59403aa43c8c47493bfdf1cc25230f26e45f4e38a3d62e8769cd324129ac15.de.png)
   > Infografik von [Dasani Madipalli](https://twitter.com/dasani_decoded)

- **Zentroid-Clustering**. Dieser beliebte Algorithmus erfordert die Wahl von ‚Äûk‚Äú oder der Anzahl der zu bildenden Cluster, nach der der Algorithmus den Mittelpunkt eines Clusters bestimmt und Daten um diesen Punkt herum sammelt. [K-Means-Clustering](https://wikipedia.org/wiki/K-means_clustering) ist eine beliebte Version des Zentroid-Clustering. Der Mittelpunkt wird durch den n√§chstgelegenen Mittelwert bestimmt, daher der Name. Die quadratische Distanz vom Cluster wird minimiert.

   ![Zentroid-Clustering Infografik](../../../../translated_images/centroid.097fde836cf6c9187d0b2033e9f94441829f9d86f4f0b1604dd4b3d1931aee34.de.png)
   > Infografik von [Dasani Madipalli](https://twitter.com/dasani_decoded)

- **Verteilungsbasiertes Clustering**. Basierend auf statistischer Modellierung konzentriert sich das verteilungsbasierte Clustering darauf, die Wahrscheinlichkeit zu bestimmen, dass ein Datenpunkt zu einem Cluster geh√∂rt, und ihn entsprechend zuzuordnen. Gau√üsche Mischmethoden geh√∂ren zu diesem Typ.

- **Dichtebasiertes Clustering**. Datenpunkte werden basierend auf ihrer Dichte oder ihrer Gruppierung um einander in Cluster eingeteilt. Datenpunkte, die weit von der Gruppe entfernt sind, gelten als Ausrei√üer oder Rauschen. DBSCAN, Mean-Shift und OPTICS geh√∂ren zu diesem Typ des Clustering.

- **Gitterbasiertes Clustering**. F√ºr mehrdimensionale Datens√§tze wird ein Gitter erstellt und die Daten werden auf die Zellen des Gitters verteilt, wodurch Cluster entstehen.

## √úbung - Clustern Sie Ihre Daten

Clustering als Technik wird stark durch die richtige Visualisierung unterst√ºtzt, also lassen Sie uns damit beginnen, unsere Musikdaten zu visualisieren. Diese √úbung wird uns helfen zu entscheiden, welche der Methoden des Clustering wir am effektivsten f√ºr die Natur dieser Daten verwenden sollten.

1. √ñffnen Sie die [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/1-Visualize/notebook.ipynb) Datei in diesem Ordner.

1. Importieren Sie das `Seaborn` Paket f√ºr eine gute Datenvisualisierung.

    ```python
    !pip install seaborn
    ```

1. F√ºgen Sie die Songdaten aus [_nigerian-songs.csv_](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/data/nigerian-songs.csv) hinzu. Laden Sie einen DataFrame mit einigen Daten √ºber die Songs. Machen Sie sich bereit, diese Daten zu erkunden, indem Sie die Bibliotheken importieren und die Daten ausgeben:

    ```python
    import matplotlib.pyplot as plt
    import pandas as pd
    
    df = pd.read_csv("../data/nigerian-songs.csv")
    df.head()
    ```

    √úberpr√ºfen Sie die ersten paar Zeilen der Daten:

    |     | name                     | album                        | artist              | artist_top_genre | release_date | length | popularity | danceability | acousticness | energy | instrumentalness | liveness | loudness | speechiness | tempo   | time_signature |
    | --- | ------------------------ | ---------------------------- | ------------------- | ---------------- | ------------ | ------ | ---------- | ------------ | ------------ | ------ | ---------------- | -------- | -------- | ----------- | ------- | -------------- |
    | 0   | Sparky                   | Mandy & The Jungle           | Cruel Santino       | alternative r&b  | 2019         | 144000 | 48         | 0.666        | 0.851        | 0.42   | 0.534            | 0.11     | -6.699   | 0.0829      | 133.015 | 5              |
    | 1   | shuga rush               | EVERYTHING YOU HEARD IS TRUE | Odunsi (The Engine) | afropop          | 2020         | 89488  | 30         | 0.71         | 0.0822       | 0.683  | 0.000169         | 0.101    | -5.64    | 0.36        | 129.993 | 3              |
    | 2   | LITT!                    | LITT!                        | AYL√ò                | indie r&b        | 2018         | 207758 | 40         | 0.836        | 0.272        | 0.564  | 0.000537         | 0.11     | -7.127   | 0.0424      | 130.005 | 4              |
    | 3   | Confident / Feeling Cool | Enjoy Your Life              | Lady Donli          | nigerian pop     | 2019         | 175135 | 14         | 0.894        | 0.798        | 0.611  | 0.000187         | 0.0964   | -4.961   | 0.113       | 111.087 | 4              |
    | 4   | wanted you               | rare.                        | Odunsi (The Engine) | afropop          | 2018         | 152049 | 25         | 0.702        | 0.116        | 0.833  | 0.91             | 0.348    | -6.044   | 0.0447      | 105.115 | 4              |

1. Holen Sie sich einige Informationen √ºber den DataFrame, indem Sie `info()` aufrufen:

    ```python
    df.info()
    ```

   Die Ausgabe sieht so aus:

    ```output
    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 530 entries, 0 to 529
    Data columns (total 16 columns):
     #   Column            Non-Null Count  Dtype  
    ---  ------            --------------  -----  
     0   name              530 non-null    object 
     1   album             530 non-null    object 
     2   artist            530 non-null    object 
     3   artist_top_genre  530 non-null    object 
     4   release_date      530 non-null    int64  
     5   length            530 non-null    int64  
     6   popularity        530 non-null    int64  
     7   danceability      530 non-null    float64
     8   acousticness      530 non-null    float64
     9   energy            530 non-null    float64
     10  instrumentalness  530 non-null    float64
     11  liveness          530 non-null    float64
     12  loudness          530 non-null    float64
     13  speechiness       530 non-null    float64
     14  tempo             530 non-null    float64
     15  time_signature    530 non-null    int64  
    dtypes: float64(8), int64(4), object(4)
    memory usage: 66.4+ KB
    ```

1. √úberpr√ºfen Sie auf Nullwerte, indem Sie `isnull()` aufrufen und √ºberpr√ºfen, ob die Summe 0 ist:

    ```python
    df.isnull().sum()
    ```

    Sieht gut aus:

    ```output
    name                0
    album               0
    artist              0
    artist_top_genre    0
    release_date        0
    length              0
    popularity          0
    danceability        0
    acousticness        0
    energy              0
    instrumentalness    0
    liveness            0
    loudness            0
    speechiness         0
    tempo               0
    time_signature      0
    dtype: int64
    ```

1. Beschreiben Sie die Daten:

    ```python
    df.describe()
    ```

    |       | release_date | length      | popularity | danceability | acousticness | energy   | instrumentalness | liveness | loudness  | speechiness | tempo      | time_signature |
    | ----- | ------------ | ----------- | ---------- | ------------ | ------------ | -------- | ---------------- | -------- | --------- | ----------- | ---------- | -------------- |
    | count | 530          | 530         | 530        | 530          | 530          | 530      | 530              | 530      | 530       | 530         | 530        | 530            |
    | mean  | 2015.390566  | 222298.1698 | 17.507547  | 0.741619     | 0.265412     | 0.760623 | 0.016305         | 0.147308 | -4.953011 | 0.130748    | 116.487864 | 3.986792       |
    | std   | 3.131688     | 39696.82226 | 18.992212  | 0.117522     | 0.208342     | 0.148533 | 0.090321         | 0.123588 | 2.464186  | 0.092939    | 23.518601  | 0.333701       |
    | min   | 199
## [Quiz nach der Vorlesung](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/28/)

## √úberpr√ºfung & Selbststudium

Bevor Sie Clustering-Algorithmen anwenden, wie wir gelernt haben, ist es eine gute Idee, die Natur Ihres Datensatzes zu verstehen. Lesen Sie mehr zu diesem Thema [hier](https://www.kdnuggets.com/2019/10/right-clustering-algorithm.html).

[Dieser hilfreiche Artikel](https://www.freecodecamp.org/news/8-clustering-algorithms-in-machine-learning-that-all-data-scientists-should-know/) erkl√§rt Ihnen die verschiedenen Verhaltensweisen der verschiedenen Clustering-Algorithmen, abh√§ngig von den unterschiedlichen Datenformen.

## Aufgabe

[Recherchieren Sie andere Visualisierungen f√ºr Clustering](assignment.md)

**Haftungsausschluss**:  
Dieses Dokument wurde mithilfe von maschinellen KI-√úbersetzungsdiensten √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, beachten Sie bitte, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache sollte als die ma√ügebliche Quelle betrachtet werden. F√ºr kritische Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die aus der Verwendung dieser √úbersetzung entstehen.