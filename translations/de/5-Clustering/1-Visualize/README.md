<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0ab69b161efd7a41d325ee28b29415d7",
  "translation_date": "2025-09-03T21:46:15+00:00",
  "source_file": "5-Clustering/1-Visualize/README.md",
  "language_code": "de"
}
-->
# Einf√ºhrung in Clustering

Clustering ist eine Art des [Un√ºberwachten Lernens](https://wikipedia.org/wiki/Unsupervised_learning), das davon ausgeht, dass ein Datensatz nicht beschriftet ist oder dass seine Eingaben nicht mit vordefinierten Ausgaben verkn√ºpft sind. Es verwendet verschiedene Algorithmen, um unbeschriftete Daten zu sortieren und Gruppierungen basierend auf Mustern zu erstellen, die es in den Daten erkennt.

[![No One Like You von PSquare](https://img.youtube.com/vi/ty2advRiWJM/0.jpg)](https://youtu.be/ty2advRiWJM "No One Like You von PSquare")

> üé• Klicken Sie auf das Bild oben f√ºr ein Video. W√§hrend Sie maschinelles Lernen mit Clustering studieren, genie√üen Sie einige nigerianische Dancehall-Tracks ‚Äì dies ist ein hoch bewertetes Lied aus dem Jahr 2014 von PSquare.

## [Quiz vor der Vorlesung](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/27/)

### Einf√ºhrung

[Clustering](https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-30164-8_124) ist sehr n√ºtzlich f√ºr die Datenexploration. Schauen wir mal, ob es helfen kann, Trends und Muster in der Art und Weise zu entdecken, wie nigerianische Zuh√∂rer Musik konsumieren.

‚úÖ Nehmen Sie sich eine Minute Zeit, um √ºber die Einsatzm√∂glichkeiten von Clustering nachzudenken. Im Alltag passiert Clustering immer dann, wenn Sie einen W√§schehaufen haben und die Kleidung Ihrer Familienmitglieder sortieren m√ºssen üß¶üëïüëñü©≤. In der Datenwissenschaft passiert Clustering, wenn versucht wird, die Vorlieben eines Nutzers zu analysieren oder die Eigenschaften eines unbeschrifteten Datensatzes zu bestimmen. Clustering hilft gewisserma√üen, Chaos zu ordnen, wie eine Sockenschublade.

[![Einf√ºhrung in ML](https://img.youtube.com/vi/esmzYhuFnds/0.jpg)](https://youtu.be/esmzYhuFnds "Einf√ºhrung in Clustering")

> üé• Klicken Sie auf das Bild oben f√ºr ein Video: John Guttag von MIT f√ºhrt in Clustering ein.

In einem professionellen Umfeld kann Clustering verwendet werden, um Dinge wie Marktsegmentierung zu bestimmen, beispielsweise welche Altersgruppen welche Artikel kaufen. Eine weitere Anwendung w√§re die Anomalieerkennung, m√∂glicherweise zur Betrugserkennung in einem Datensatz von Kreditkartentransaktionen. Oder Sie k√∂nnten Clustering verwenden, um Tumore in einer Reihe von medizinischen Scans zu identifizieren.

‚úÖ Denken Sie einen Moment dar√ºber nach, wie Sie Clustering ‚Äûin freier Wildbahn‚Äú erlebt haben, sei es im Bankwesen, E-Commerce oder Gesch√§ftsumfeld.

> üéì Interessanterweise stammt die Clusteranalyse aus den Bereichen Anthropologie und Psychologie der 1930er Jahre. K√∂nnen Sie sich vorstellen, wie sie damals verwendet wurde?

Alternativ k√∂nnten Sie es f√ºr die Gruppierung von Suchergebnissen verwenden ‚Äì beispielsweise nach Einkaufslinks, Bildern oder Bewertungen. Clustering ist n√ºtzlich, wenn Sie einen gro√üen Datensatz haben, den Sie reduzieren und auf dem Sie eine detailliertere Analyse durchf√ºhren m√∂chten. Die Technik kann verwendet werden, um Daten zu verstehen, bevor andere Modelle erstellt werden.

‚úÖ Sobald Ihre Daten in Clustern organisiert sind, weisen Sie ihnen eine Cluster-ID zu. Diese Technik kann n√ºtzlich sein, um die Privatsph√§re eines Datensatzes zu wahren; Sie k√∂nnen stattdessen auf einen Datenpunkt anhand seiner Cluster-ID verweisen, anstatt auf offenere identifizierbare Daten. K√∂nnen Sie sich andere Gr√ºnde vorstellen, warum Sie eine Cluster-ID anstelle anderer Elemente des Clusters verwenden w√ºrden, um sie zu identifizieren?

Vertiefen Sie Ihr Verst√§ndnis von Clustering-Techniken in diesem [Learn-Modul](https://docs.microsoft.com/learn/modules/train-evaluate-cluster-models?WT.mc_id=academic-77952-leestott).

## Einstieg in Clustering

[Scikit-learn bietet eine gro√üe Auswahl](https://scikit-learn.org/stable/modules/clustering.html) an Methoden zur Durchf√ºhrung von Clustering. Die Wahl der Methode h√§ngt von Ihrem Anwendungsfall ab. Laut Dokumentation hat jede Methode verschiedene Vorteile. Hier ist eine vereinfachte Tabelle der von Scikit-learn unterst√ºtzten Methoden und ihrer geeigneten Anwendungsf√§lle:

| Methodenname                 | Anwendungsfall                                                        |
| :--------------------------- | :-------------------------------------------------------------------- |
| K-Means                      | allgemeiner Zweck, induktiv                                           |
| Affinity Propagation         | viele, ungleichm√§√üige Cluster, induktiv                              |
| Mean-Shift                   | viele, ungleichm√§√üige Cluster, induktiv                              |
| Spectral Clustering          | wenige, gleichm√§√üige Cluster, transduktiv                            |
| Ward Hierarchical Clustering | viele, eingeschr√§nkte Cluster, transduktiv                           |
| Agglomerative Clustering     | viele, eingeschr√§nkte, nicht-euklidische Distanzen, transduktiv      |
| DBSCAN                       | nicht-flache Geometrie, ungleichm√§√üige Cluster, transduktiv          |
| OPTICS                       | nicht-flache Geometrie, ungleichm√§√üige Cluster mit variabler Dichte, transduktiv |
| Gaussian Mixtures            | flache Geometrie, induktiv                                           |
| BIRCH                        | gro√üer Datensatz mit Ausrei√üern, induktiv                            |

> üéì Wie wir Cluster erstellen, h√§ngt stark davon ab, wie wir die Datenpunkte zu Gruppen zusammenfassen. Lassen Sie uns einige Begriffe kl√§ren:
>
> üéì ['Transduktiv' vs. 'induktiv'](https://wikipedia.org/wiki/Transduction_(machine_learning))
> 
> Transduktive Inferenz wird aus beobachteten Trainingsf√§llen abgeleitet, die auf spezifische Testf√§lle abgebildet werden. Induktive Inferenz wird aus Trainingsf√§llen abgeleitet, die allgemeine Regeln ableiten, die dann auf Testf√§lle angewendet werden.
> 
> Ein Beispiel: Stellen Sie sich vor, Sie haben einen Datensatz, der nur teilweise beschriftet ist. Einige Dinge sind ‚ÄûSchallplatten‚Äú, einige ‚ÄûCDs‚Äú und einige sind leer. Ihre Aufgabe ist es, die leeren Felder zu beschriften. Wenn Sie einen induktiven Ansatz w√§hlen, w√ºrden Sie ein Modell trainieren, das nach ‚ÄûSchallplatten‚Äú und ‚ÄûCDs‚Äú sucht, und diese Labels auf Ihre unbeschrifteten Daten anwenden. Dieser Ansatz wird Schwierigkeiten haben, Dinge zu klassifizieren, die tats√§chlich ‚ÄûKassetten‚Äú sind. Ein transduktiver Ansatz hingegen geht mit diesen unbekannten Daten effektiver um, da er √§hnliche Elemente gruppiert und dann einer Gruppe ein Label zuweist. In diesem Fall k√∂nnten Cluster ‚Äûrunde Musiksachen‚Äú und ‚Äûquadratische Musiksachen‚Äú widerspiegeln.
> 
> üéì ['Nicht-flache' vs. 'flache' Geometrie](https://datascience.stackexchange.com/questions/52260/terminology-flat-geometry-in-the-context-of-clustering)
> 
> Abgeleitet aus mathematischer Terminologie bezieht sich nicht-flache vs. flache Geometrie auf die Messung von Distanzen zwischen Punkten entweder durch ‚Äûflache‚Äú ([euklidische](https://wikipedia.org/wiki/Euclidean_geometry)) oder ‚Äûnicht-flache‚Äú (nicht-euklidische) geometrische Methoden.
>
>'Flach' in diesem Kontext bezieht sich auf euklidische Geometrie (Teile davon werden als 'Ebene' Geometrie gelehrt), und nicht-flach bezieht sich auf nicht-euklidische Geometrie. Was hat Geometrie mit maschinellem Lernen zu tun? Nun, als zwei Felder, die in der Mathematik verwurzelt sind, muss es eine gemeinsame Methode geben, um Distanzen zwischen Punkten in Clustern zu messen, und das kann auf eine 'flache' oder 'nicht-flache' Weise erfolgen, abh√§ngig von der Natur der Daten. [Euklidische Distanzen](https://wikipedia.org/wiki/Euclidean_distance) werden als die L√§nge eines Liniensegments zwischen zwei Punkten gemessen. [Nicht-euklidische Distanzen](https://wikipedia.org/wiki/Non-Euclidean_geometry) werden entlang einer Kurve gemessen. Wenn Ihre Daten, visualisiert, nicht auf einer Ebene zu existieren scheinen, m√ºssen Sie m√∂glicherweise einen spezialisierten Algorithmus verwenden, um sie zu verarbeiten.
>
![Flache vs. nicht-flache Geometrie Infografik](../../../../translated_images/flat-nonflat.d1c8c6e2a96110c1d57fa0b72913f6aab3c245478524d25baf7f4a18efcde224.de.png)
> Infografik von [Dasani Madipalli](https://twitter.com/dasani_decoded)
> 
> üéì ['Distanzen'](https://web.stanford.edu/class/cs345a/slides/12-clustering.pdf)
> 
> Cluster werden durch ihre Distanzmatrix definiert, z. B. die Distanzen zwischen Punkten. Diese Distanz kann auf verschiedene Weise gemessen werden. Euklidische Cluster werden durch den Durchschnitt der Punktwerte definiert und enthalten einen 'Zentroid' oder Mittelpunkt. Distanzen werden somit durch die Entfernung zu diesem Zentroid gemessen. Nicht-euklidische Distanzen beziehen sich auf 'Clustroids', den Punkt, der anderen Punkten am n√§chsten ist. Clustroids k√∂nnen wiederum auf verschiedene Weise definiert werden.
> 
> üéì ['Eingeschr√§nkt'](https://wikipedia.org/wiki/Constrained_clustering)
> 
> [Eingeschr√§nktes Clustering](https://web.cs.ucdavis.edu/~davidson/Publications/ICDMTutorial.pdf) f√ºhrt 'semi-√ºberwachtes' Lernen in diese un√ºberwachte Methode ein. Die Beziehungen zwischen Punkten werden als 'kann nicht verkn√ºpfen' oder 'muss verkn√ºpfen' markiert, sodass einige Regeln auf den Datensatz angewendet werden.
>
>Ein Beispiel: Wenn ein Algorithmus auf einen Stapel unbeschrifteter oder halb-beschrifteter Daten losgelassen wird, k√∂nnen die von ihm erzeugten Cluster von schlechter Qualit√§t sein. Im obigen Beispiel k√∂nnten die Cluster ‚Äûrunde Musiksachen‚Äú, ‚Äûquadratische Musiksachen‚Äú, ‚Äûdreieckige Sachen‚Äú und ‚ÄûKekse‚Äú gruppieren. Wenn einige Einschr√§nkungen oder Regeln hinzugef√ºgt werden ("das Objekt muss aus Plastik bestehen", "das Objekt muss Musik produzieren k√∂nnen"), kann dies helfen, den Algorithmus zu besseren Entscheidungen zu f√ºhren.
> 
> üéì 'Dichte'
> 
> Daten, die ‚Äûrauschend‚Äú sind, gelten als ‚Äûdicht‚Äú. Die Distanzen zwischen Punkten in jedem seiner Cluster k√∂nnen sich bei der Untersuchung als mehr oder weniger dicht oder ‚Äûgedr√§ngt‚Äú erweisen, und daher m√ºssen diese Daten mit der geeigneten Clustering-Methode analysiert werden. [Dieser Artikel](https://www.kdnuggets.com/2020/02/understanding-density-based-clustering.html) zeigt den Unterschied zwischen der Verwendung von K-Means-Clustering und HDBSCAN-Algorithmen zur Untersuchung eines rauschenden Datensatzes mit ungleichm√§√üiger Clusterdichte.

## Clustering-Algorithmen

Es gibt √ºber 100 Clustering-Algorithmen, und ihre Verwendung h√§ngt von der Natur der vorliegenden Daten ab. Lassen Sie uns einige der wichtigsten besprechen:

- **Hierarchisches Clustering**. Wenn ein Objekt basierend auf seiner N√§he zu einem nahegelegenen Objekt klassifiziert wird, anstatt zu einem weiter entfernten, werden Cluster basierend auf den Distanzen ihrer Mitglieder zu und von anderen Objekten gebildet. Scikit-learns agglomeratives Clustering ist hierarchisch.

   ![Hierarchisches Clustering Infografik](../../../../translated_images/hierarchical.bf59403aa43c8c47493bfdf1cc25230f26e45f4e38a3d62e8769cd324129ac15.de.png)
   > Infografik von [Dasani Madipalli](https://twitter.com/dasani_decoded)

- **Zentroid-Clustering**. Dieser beliebte Algorithmus erfordert die Wahl von 'k', oder der Anzahl der zu bildenden Cluster, wonach der Algorithmus den Mittelpunkt eines Clusters bestimmt und Daten um diesen Punkt sammelt. [K-Means-Clustering](https://wikipedia.org/wiki/K-means_clustering) ist eine beliebte Version des Zentroid-Clustering. Der Mittelpunkt wird durch den n√§chstgelegenen Mittelwert bestimmt, daher der Name. Die quadratische Entfernung vom Cluster wird minimiert.

   ![Zentroid-Clustering Infografik](../../../../translated_images/centroid.097fde836cf6c9187d0b2033e9f94441829f9d86f4f0b1604dd4b3d1931aee34.de.png)
   > Infografik von [Dasani Madipalli](https://twitter.com/dasani_decoded)

- **Verteilungsbasiertes Clustering**. Basierend auf statistischer Modellierung konzentriert sich das verteilungsbasierte Clustering darauf, die Wahrscheinlichkeit zu bestimmen, dass ein Datenpunkt zu einem Cluster geh√∂rt, und ihn entsprechend zuzuweisen. Gaussian-Mischmethoden geh√∂ren zu diesem Typ.

- **Dichtebasiertes Clustering**. Datenpunkte werden basierend auf ihrer Dichte oder ihrer Gruppierung umeinander herum Clustern zugewiesen. Datenpunkte, die weit von der Gruppe entfernt sind, werden als Ausrei√üer oder Rauschen betrachtet. DBSCAN, Mean-Shift und OPTICS geh√∂ren zu diesem Typ des Clustering.

- **Rasterbasiertes Clustering**. F√ºr mehrdimensionale Datens√§tze wird ein Raster erstellt und die Daten werden auf die Zellen des Rasters verteilt, wodurch Cluster entstehen.

## √úbung ‚Äì Ihre Daten clustern

Clustering als Technik wird durch eine ordentliche Visualisierung erheblich erleichtert. Lassen Sie uns daher beginnen, unsere Musikdaten zu visualisieren. Diese √úbung wird uns helfen zu entscheiden, welche der Clustering-Methoden wir am effektivsten f√ºr die Natur dieser Daten verwenden sollten.

1. √ñffnen Sie die Datei [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/1-Visualize/notebook.ipynb) in diesem Ordner.

1. Importieren Sie das `Seaborn`-Paket f√ºr eine gute Datenvisualisierung.

    ```python
    !pip install seaborn
    ```

1. F√ºgen Sie die Songdaten aus [_nigerian-songs.csv_](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/data/nigerian-songs.csv) hinzu. Laden Sie ein DataFrame mit einigen Daten √ºber die Songs. Bereiten Sie sich darauf vor, diese Daten zu erkunden, indem Sie die Bibliotheken importieren und die Daten ausgeben:

    ```python
    import matplotlib.pyplot as plt
    import pandas as pd
    
    df = pd.read_csv("../data/nigerian-songs.csv")
    df.head()
    ```

    √úberpr√ºfen Sie die ersten Zeilen der Daten:

    |     | name                     | album                        | artist              | artist_top_genre | release_date | length | popularity | danceability | acousticness | energy | instrumentalness | liveness | loudness | speechiness | tempo   | time_signature |
    | --- | ------------------------ | ---------------------------- | ------------------- | ---------------- | ------------ | ------ | ---------- | ------------ | ------------ | ------ | ---------------- | -------- | -------- | ----------- | ------- | -------------- |
    | 0   | Sparky                   | Mandy & The Jungle           | Cruel Santino       | alternative r&b  | 2019         | 144000 | 48         | 0.666        | 0.851        | 0.42   | 0.534            | 0.11     | -6.699   | 0.0829      | 133.015 | 5              |
    | 1   | shuga rush               | EVERYTHING YOU HEARD IS TRUE | Odunsi (The Engine) | afropop          | 2020         | 89488  | 30         | 0.71         | 0.0822       | 0.683  | 0.000169         | 0.101    | -5.64    | 0.36        | 129.993 | 3              |
| 2   | LITT!                    | LITT!                        | AYL√ò                | indie r&b        | 2018         | 207758 | 40         | 0.836        | 0.272        | 0.564  | 0.000537         | 0.11     | -7.127   | 0.0424      | 130.005 | 4              |
| 3   | Confident / Feeling Cool | Enjoy Your Life              | Lady Donli          | nigerian pop     | 2019         | 175135 | 14         | 0.894        | 0.798        | 0.611  | 0.000187         | 0.0964   | -4.961   | 0.113       | 111.087 | 4              |
| 4   | wanted you               | rare.                        | Odunsi (The Engine) | afropop          | 2018         | 152049 | 25         | 0.702        | 0.116        | 0.833  | 0.91             | 0.348    | -6.044   | 0.0447      | 105.115 | 4              |

1. Holen Sie sich einige Informationen √ºber den DataFrame, indem Sie `info()` aufrufen:

    ```python
    df.info()
    ```

   Die Ausgabe sieht folgenderma√üen aus:

    ```output
    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 530 entries, 0 to 529
    Data columns (total 16 columns):
     #   Column            Non-Null Count  Dtype  
    ---  ------            --------------  -----  
     0   name              530 non-null    object 
     1   album             530 non-null    object 
     2   artist            530 non-null    object 
     3   artist_top_genre  530 non-null    object 
     4   release_date      530 non-null    int64  
     5   length            530 non-null    int64  
     6   popularity        530 non-null    int64  
     7   danceability      530 non-null    float64
     8   acousticness      530 non-null    float64
     9   energy            530 non-null    float64
     10  instrumentalness  530 non-null    float64
     11  liveness          530 non-null    float64
     12  loudness          530 non-null    float64
     13  speechiness       530 non-null    float64
     14  tempo             530 non-null    float64
     15  time_signature    530 non-null    int64  
    dtypes: float64(8), int64(4), object(4)
    memory usage: 66.4+ KB
    ```

1. √úberpr√ºfen Sie auf fehlende Werte, indem Sie `isnull()` aufrufen und sicherstellen, dass die Summe 0 ist:

    ```python
    df.isnull().sum()
    ```

    Sieht gut aus:

    ```output
    name                0
    album               0
    artist              0
    artist_top_genre    0
    release_date        0
    length              0
    popularity          0
    danceability        0
    acousticness        0
    energy              0
    instrumentalness    0
    liveness            0
    loudness            0
    speechiness         0
    tempo               0
    time_signature      0
    dtype: int64
    ```

1. Beschreiben Sie die Daten:

    ```python
    df.describe()
    ```

    |       | release_date | length      | popularity | danceability | acousticness | energy   | instrumentalness | liveness | loudness  | speechiness | tempo      | time_signature |
    | ----- | ------------ | ----------- | ---------- | ------------ | ------------ | -------- | ---------------- | -------- | --------- | ----------- | ---------- | -------------- |
    | count | 530          | 530         | 530        | 530          | 530          | 530      | 530              | 530      | 530       | 530         | 530        | 530            |
    | mean  | 2015.390566  | 222298.1698 | 17.507547  | 0.741619     | 0.265412     | 0.760623 | 0.016305         | 0.147308 | -4.953011 | 0.130748    | 116.487864 | 3.986792       |
    | std   | 3.131688     | 39696.82226 | 18.992212  | 0.117522     | 0.208342     | 0.148533 | 0.090321         | 0.123588 | 2.464186  | 0.092939    | 23.518601  | 0.333701       |
    | min   | 1998         | 89488       | 0          | 0.255        | 0.000665     | 0.111    | 0                | 0.0283   | -19.362   | 0.0278      | 61.695     | 3              |
    | 25%   | 2014         | 199305      | 0          | 0.681        | 0.089525     | 0.669    | 0                | 0.07565  | -6.29875  | 0.0591      | 102.96125  | 4              |
    | 50%   | 2016         | 218509      | 13         | 0.761        | 0.2205       | 0.7845   | 0.000004         | 0.1035   | -4.5585   | 0.09795     | 112.7145   | 4              |
    | 75%   | 2017         | 242098.5    | 31         | 0.8295       | 0.403        | 0.87575  | 0.000234         | 0.164    | -3.331    | 0.177       | 125.03925  | 4              |
    | max   | 2020         | 511738      | 73         | 0.966        | 0.954        | 0.995    | 0.91             | 0.811    | 0.582     | 0.514       | 206.007    | 5              |

> ü§î Wenn wir mit Clustering arbeiten, einer un√ºberwachten Methode, die keine gelabelten Daten ben√∂tigt, warum zeigen wir dann diese Daten mit Labels? In der Phase der Datenerkundung sind sie n√ºtzlich, aber f√ºr die Clustering-Algorithmen sind sie nicht notwendig. Sie k√∂nnten genauso gut die Spalten√ºberschriften entfernen und sich auf die Daten anhand der Spaltennummern beziehen.

Schauen Sie sich die allgemeinen Werte der Daten an. Beachten Sie, dass Popularit√§t '0' sein kann, was Songs zeigt, die kein Ranking haben. Lassen Sie uns diese gleich entfernen.

1. Verwenden Sie ein Balkendiagramm, um die beliebtesten Genres herauszufinden:

    ```python
    import seaborn as sns
    
    top = df['artist_top_genre'].value_counts()
    plt.figure(figsize=(10,7))
    sns.barplot(x=top[:5].index,y=top[:5].values)
    plt.xticks(rotation=45)
    plt.title('Top genres',color = 'blue')
    ```

    ![most popular](../../../../translated_images/popular.9c48d84b3386705f98bf44e26e9655bee9eb7c849d73be65195e37895bfedb5d.de.png)

‚úÖ Wenn Sie mehr Top-Werte sehen m√∂chten, √§ndern Sie das Top `[:5]` in einen gr√∂√üeren Wert oder entfernen Sie es, um alle anzuzeigen.

Beachten Sie, wenn das Top-Genre als 'Missing' beschrieben wird, bedeutet das, dass Spotify es nicht klassifiziert hat. Lassen Sie uns diese entfernen.

1. Entfernen Sie fehlende Daten, indem Sie sie herausfiltern:

    ```python
    df = df[df['artist_top_genre'] != 'Missing']
    top = df['artist_top_genre'].value_counts()
    plt.figure(figsize=(10,7))
    sns.barplot(x=top.index,y=top.values)
    plt.xticks(rotation=45)
    plt.title('Top genres',color = 'blue')
    ```

    √úberpr√ºfen Sie nun die Genres erneut:

    ![most popular](../../../../translated_images/all-genres.1d56ef06cefbfcd61183023834ed3cb891a5ee638a3ba5c924b3151bf80208d7.de.png)

1. Die drei Top-Genres dominieren bei weitem diesen Datensatz. Konzentrieren wir uns auf `afro dancehall`, `afropop` und `nigerian pop` und filtern den Datensatz zus√§tzlich, um alles mit einem Popularit√§tswert von 0 zu entfernen (was bedeutet, dass es im Datensatz nicht klassifiziert wurde und f√ºr unsere Zwecke als Rauschen betrachtet werden kann):

    ```python
    df = df[(df['artist_top_genre'] == 'afro dancehall') | (df['artist_top_genre'] == 'afropop') | (df['artist_top_genre'] == 'nigerian pop')]
    df = df[(df['popularity'] > 0)]
    top = df['artist_top_genre'].value_counts()
    plt.figure(figsize=(10,7))
    sns.barplot(x=top.index,y=top.values)
    plt.xticks(rotation=45)
    plt.title('Top genres',color = 'blue')
    ```

1. Machen Sie einen kurzen Test, um zu sehen, ob die Daten in irgendeiner Weise stark korrelieren:

    ```python
    corrmat = df.corr(numeric_only=True)
    f, ax = plt.subplots(figsize=(12, 9))
    sns.heatmap(corrmat, vmax=.8, square=True)
    ```

    ![correlations](../../../../translated_images/correlation.a9356bb798f5eea51f47185968e1ebac5c078c92fce9931e28ccf0d7fab71c2b.de.png)

    Die einzige starke Korrelation besteht zwischen `energy` und `loudness`, was nicht allzu √ºberraschend ist, da laute Musik normalerweise ziemlich energiegeladen ist. Ansonsten sind die Korrelationen relativ schwach. Es wird interessant sein zu sehen, was ein Clustering-Algorithmus aus diesen Daten machen kann.

    > üéì Beachten Sie, dass Korrelation keine Kausalit√§t impliziert! Wir haben einen Beweis f√ºr Korrelation, aber keinen Beweis f√ºr Kausalit√§t. Eine [am√ºsante Website](https://tylervigen.com/spurious-correlations) bietet einige Visualisierungen, die diesen Punkt betonen.

Gibt es in diesem Datensatz eine Konvergenz in Bezug auf die wahrgenommene Popularit√§t und Tanzbarkeit eines Songs? Ein FacetGrid zeigt, dass es konzentrische Kreise gibt, die sich unabh√§ngig vom Genre ausrichten. K√∂nnte es sein, dass nigerianische Geschm√§cker bei einem bestimmten Tanzbarkeitsniveau f√ºr dieses Genre konvergieren?

‚úÖ Probieren Sie verschiedene Datenpunkte (Energie, Lautst√§rke, Sprachanteil) und mehr oder andere Musikgenres aus. Was k√∂nnen Sie entdecken? Werfen Sie einen Blick auf die `df.describe()`-Tabelle, um die allgemeine Verteilung der Datenpunkte zu sehen.

### √úbung - Datenverteilung

Unterscheiden sich diese drei Genres signifikant in der Wahrnehmung ihrer Tanzbarkeit, basierend auf ihrer Popularit√§t?

1. Untersuchen Sie die Datenverteilung unserer drei Top-Genres in Bezug auf Popularit√§t und Tanzbarkeit entlang einer gegebenen x- und y-Achse.

    ```python
    sns.set_theme(style="ticks")
    
    g = sns.jointplot(
        data=df,
        x="popularity", y="danceability", hue="artist_top_genre",
        kind="kde",
    )
    ```

    Sie k√∂nnen konzentrische Kreise um einen allgemeinen Konvergenzpunkt entdecken, die die Verteilung der Punkte zeigen.

    > üéì Beachten Sie, dass dieses Beispiel ein KDE-Diagramm (Kernel Density Estimate) verwendet, das die Daten mit einer kontinuierlichen Wahrscheinlichkeitsdichtekurve darstellt. Dies erm√∂glicht es uns, Daten bei der Arbeit mit mehreren Verteilungen zu interpretieren.

    Im Allgemeinen stimmen die drei Genres lose in Bezug auf ihre Popularit√§t und Tanzbarkeit √ºberein. Cluster in diesen lose ausgerichteten Daten zu bestimmen, wird eine Herausforderung:

    ![distribution](../../../../translated_images/distribution.9be11df42356ca958dc8e06e87865e09d77cab78f94fe4fea8a1e6796c64dc4b.de.png)

1. Erstellen Sie ein Streudiagramm:

    ```python
    sns.FacetGrid(df, hue="artist_top_genre", height=5) \
       .map(plt.scatter, "popularity", "danceability") \
       .add_legend()
    ```

    Ein Streudiagramm derselben Achsen zeigt ein √§hnliches Muster der Konvergenz:

    ![Facetgrid](../../../../translated_images/facetgrid.9b2e65ce707eba1f983b7cdfed5d952e60f385947afa3011df6e3cc7d200eb5b.de.png)

Im Allgemeinen k√∂nnen Sie f√ºr das Clustering Streudiagramme verwenden, um Datencluster darzustellen. Daher ist es sehr n√ºtzlich, diese Art der Visualisierung zu beherrschen. In der n√§chsten Lektion werden wir diese gefilterten Daten verwenden und mit k-means Clustering Gruppen in diesen Daten entdecken, die sich auf interessante Weise √ºberlappen.

---

## üöÄ Herausforderung

Bereiten Sie sich auf die n√§chste Lektion vor, indem Sie ein Diagramm √ºber die verschiedenen Clustering-Algorithmen erstellen, die Sie m√∂glicherweise in einer Produktionsumgebung entdecken und verwenden k√∂nnten. Welche Arten von Problemen versucht das Clustering zu l√∂sen?

## [Quiz nach der Vorlesung](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/28/)

## R√ºckblick & Selbststudium

Bevor Sie Clustering-Algorithmen anwenden, ist es, wie wir gelernt haben, eine gute Idee, die Natur Ihres Datensatzes zu verstehen. Lesen Sie mehr zu diesem Thema [hier](https://www.kdnuggets.com/2019/10/right-clustering-algorithm.html).

[Dieser hilfreiche Artikel](https://www.freecodecamp.org/news/8-clustering-algorithms-in-machine-learning-that-all-data-scientists-should-know/) f√ºhrt Sie durch die verschiedenen Verhaltensweisen von Clustering-Algorithmen bei unterschiedlichen Datenformen.

## Aufgabe

[Erforschen Sie andere Visualisierungen f√ºr Clustering](assignment.md)

---

**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-√úbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, beachten Sie bitte, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache sollte als ma√ügebliche Quelle betrachtet werden. F√ºr kritische Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die sich aus der Nutzung dieser √úbersetzung ergeben.