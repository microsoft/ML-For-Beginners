<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6534e145d52a3890590d27be75386e5d",
  "translation_date": "2025-09-03T22:01:08+00:00",
  "source_file": "6-NLP/2-Tasks/README.md",
  "language_code": "de"
}
-->
# H√§ufige Aufgaben und Techniken der Verarbeitung nat√ºrlicher Sprache

F√ºr die meisten Aufgaben der *Verarbeitung nat√ºrlicher Sprache* muss der zu verarbeitende Text zerlegt, analysiert und die Ergebnisse gespeichert oder mit Regeln und Datens√§tzen abgeglichen werden. Diese Aufgaben erm√∂glichen es dem Programmierer, die _Bedeutung_ oder _Absicht_ oder nur die _H√§ufigkeit_ von Begriffen und W√∂rtern in einem Text abzuleiten.

## [Quiz vor der Vorlesung](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/33/)

Lassen Sie uns die g√§ngigen Techniken zur Verarbeitung von Text entdecken. In Kombination mit maschinellem Lernen helfen diese Techniken, gro√üe Mengen an Text effizient zu analysieren. Bevor Sie ML auf diese Aufgaben anwenden, sollten Sie jedoch die Probleme verstehen, mit denen ein NLP-Spezialist konfrontiert ist.

## H√§ufige Aufgaben in der NLP

Es gibt verschiedene M√∂glichkeiten, einen Text zu analysieren, an dem Sie arbeiten. Es gibt Aufgaben, die Sie durchf√ºhren k√∂nnen, und durch diese Aufgaben k√∂nnen Sie ein Verst√§ndnis des Textes gewinnen und Schlussfolgerungen ziehen. Diese Aufgaben werden normalerweise in einer bestimmten Reihenfolge durchgef√ºhrt.

### Tokenisierung

Wahrscheinlich ist das Erste, was die meisten NLP-Algorithmen tun m√ºssen, den Text in Token oder W√∂rter zu zerlegen. Obwohl dies einfach klingt, kann die Ber√ºcksichtigung von Satzzeichen und unterschiedlichen Wort- und Satzgrenzen in verschiedenen Sprachen schwierig sein. M√∂glicherweise m√ºssen Sie verschiedene Methoden anwenden, um die Abgrenzungen zu bestimmen.

![Tokenisierung](../../../../translated_images/tokenization.1641a160c66cd2d93d4524e8114e93158a9ce0eba3ecf117bae318e8a6ad3487.de.png)
> Tokenisierung eines Satzes aus **Stolz und Vorurteil**. Infografik von [Jen Looper](https://twitter.com/jenlooper)

### Einbettungen

[Worteinbettungen](https://wikipedia.org/wiki/Word_embedding) sind eine M√∂glichkeit, Ihre Textdaten numerisch zu konvertieren. Einbettungen werden so durchgef√ºhrt, dass W√∂rter mit √§hnlicher Bedeutung oder W√∂rter, die zusammen verwendet werden, gruppiert werden.

![Worteinbettungen](../../../../translated_images/embedding.2cf8953c4b3101d188c2f61a5de5b6f53caaa5ad4ed99236d42bc3b6bd6a1fe2.de.png)
> "Ich habe den gr√∂√üten Respekt vor Ihren Nerven, sie sind meine alten Freunde." - Worteinbettungen f√ºr einen Satz aus **Stolz und Vorurteil**. Infografik von [Jen Looper](https://twitter.com/jenlooper)

‚úÖ Probieren Sie [dieses interessante Tool](https://projector.tensorflow.org/) aus, um mit Worteinbettungen zu experimentieren. Wenn Sie auf ein Wort klicken, werden Cluster √§hnlicher W√∂rter angezeigt: 'Spielzeug' gruppiert sich mit 'Disney', 'Lego', 'Playstation' und 'Konsole'.

### Parsing & Part-of-speech-Tagging

Jedes Wort, das tokenisiert wurde, kann als Wortart markiert werden - Substantiv, Verb oder Adjektiv. Der Satz `der schnelle rote Fuchs sprang √ºber den faulen braunen Hund` k√∂nnte als POS markiert werden: Fuchs = Substantiv, sprang = Verb.

![Parsing](../../../../translated_images/parse.d0c5bbe1106eae8fe7d60a183cd1736c8b6cec907f38000366535f84f3036101.de.png)

> Parsing eines Satzes aus **Stolz und Vorurteil**. Infografik von [Jen Looper](https://twitter.com/jenlooper)

Parsing bedeutet, zu erkennen, welche W√∂rter in einem Satz miteinander verbunden sind - zum Beispiel `der schnelle rote Fuchs sprang` ist eine Adjektiv-Substantiv-Verb-Sequenz, die von der Sequenz `fauler brauner Hund` getrennt ist.

### Wort- und Phrasenh√§ufigkeiten

Ein n√ºtzliches Verfahren bei der Analyse eines gro√üen Textkorpus ist der Aufbau eines W√∂rterbuchs mit jedem interessanten Wort oder jeder interessanten Phrase und deren H√§ufigkeit. Die Phrase `der schnelle rote Fuchs sprang √ºber den faulen braunen Hund` hat eine Worth√§ufigkeit von 2 f√ºr das Wort "der".

Schauen wir uns einen Beispieltext an, in dem wir die H√§ufigkeit von W√∂rtern z√§hlen. Rudyard Kiplings Gedicht "The Winners" enth√§lt die folgende Strophe:

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

Da Phrasenh√§ufigkeiten je nach Bedarf gro√ü- oder kleinschreibungsempfindlich sein k√∂nnen, hat die Phrase `ein Freund` eine H√§ufigkeit von 2, `der` eine H√§ufigkeit von 6 und `reisen` eine H√§ufigkeit von 2.

### N-Gramme

Ein Text kann in Sequenzen von W√∂rtern einer festgelegten L√§nge aufgeteilt werden: ein einzelnes Wort (Unigramm), zwei W√∂rter (Bigramme), drei W√∂rter (Trigramme) oder eine beliebige Anzahl von W√∂rtern (N-Gramme).

Zum Beispiel ergibt `der schnelle rote Fuchs sprang √ºber den faulen braunen Hund` mit einem N-Gramm-Wert von 2 die folgenden N-Gramme:

1. der schnelle  
2. schnelle rote  
3. rote Fuchs  
4. Fuchs sprang  
5. sprang √ºber  
6. √ºber den  
7. den faulen  
8. faulen braunen  
9. braunen Hund  

Es k√∂nnte einfacher sein, es als ein gleitendes Fenster √ºber den Satz zu visualisieren. Hier ist es f√ºr N-Gramme mit 3 W√∂rtern, wobei das N-Gramm in jedem Satz fett hervorgehoben ist:

1.   <u>**der schnelle rote**</u> Fuchs sprang √ºber den faulen braunen Hund  
2.   der **<u>schnelle rote Fuchs</u>** sprang √ºber den faulen braunen Hund  
3.   der schnelle **<u>rote Fuchs sprang</u>** √ºber den faulen braunen Hund  
4.   der schnelle rote **<u>Fuchs sprang √ºber</u>** den faulen braunen Hund  
5.   der schnelle rote Fuchs **<u>sprang √ºber den</u>** faulen braunen Hund  
6.   der schnelle rote Fuchs sprang **<u>√ºber den faulen</u>** braunen Hund  
7.   der schnelle rote Fuchs sprang √ºber den **<u>faulen braunen Hund</u>**  

![N-Gramme gleitendes Fenster](../../../../6-NLP/2-Tasks/images/n-grams.gif)

> N-Gramm-Wert von 3: Infografik von [Jen Looper](https://twitter.com/jenlooper)

### Extraktion von Substantivphrasen

In den meisten S√§tzen gibt es ein Substantiv, das das Subjekt oder Objekt des Satzes ist. Im Englischen ist es oft daran zu erkennen, dass es mit 'a', 'an' oder 'the' eingeleitet wird. Das Identifizieren des Subjekts oder Objekts eines Satzes durch 'Extraktion der Substantivphrase' ist eine g√§ngige Aufgabe in der NLP, wenn versucht wird, die Bedeutung eines Satzes zu verstehen.

‚úÖ Im Satz "Ich kann weder die Stunde noch den Ort noch den Blick oder die Worte festlegen, die den Grundstein gelegt haben. Es ist zu lange her. Ich war mittendrin, bevor ich wusste, dass ich angefangen hatte.", k√∂nnen Sie die Substantivphrasen identifizieren?

Im Satz `der schnelle rote Fuchs sprang √ºber den faulen braunen Hund` gibt es 2 Substantivphrasen: **schneller roter Fuchs** und **fauler brauner Hund**.

### Sentiment-Analyse

Ein Satz oder Text kann auf seine Stimmung analysiert werden, also wie *positiv* oder *negativ* er ist. Stimmung wird in *Polarit√§t* und *Objektivit√§t/Subjektivit√§t* gemessen. Polarit√§t wird von -1.0 bis 1.0 (negativ bis positiv) und 0.0 bis 1.0 (am objektivsten bis am subjektivsten) gemessen.

‚úÖ Sp√§ter lernen Sie, dass es verschiedene M√∂glichkeiten gibt, die Stimmung mithilfe von maschinellem Lernen zu bestimmen. Eine M√∂glichkeit besteht darin, eine Liste von W√∂rtern und Phrasen zu haben, die von einem menschlichen Experten als positiv oder negativ kategorisiert wurden, und dieses Modell auf Text anzuwenden, um einen Polarit√§tswert zu berechnen. K√∂nnen Sie erkennen, wie dies in einigen F√§llen funktioniert und in anderen weniger gut?

### Flexion

Flexion erm√∂glicht es Ihnen, ein Wort zu nehmen und die Singular- oder Pluralform des Wortes zu erhalten.

### Lemmatisierung

Ein *Lemma* ist die Grundform oder das Stammwort f√ºr eine Gruppe von W√∂rtern, zum Beispiel haben *flog*, *fliegen*, *fliegend* das Lemma des Verbs *fliegen*.

Es gibt auch n√ºtzliche Datenbanken f√ºr NLP-Forscher, insbesondere:

### WordNet

[WordNet](https://wordnet.princeton.edu/) ist eine Datenbank von W√∂rtern, Synonymen, Antonymen und vielen anderen Details f√ºr jedes Wort in vielen verschiedenen Sprachen. Es ist unglaublich n√ºtzlich beim Versuch, √úbersetzungen, Rechtschreibpr√ºfungen oder Sprachwerkzeuge jeglicher Art zu erstellen.

## NLP-Bibliotheken

Gl√ºcklicherweise m√ºssen Sie nicht alle diese Techniken selbst entwickeln, da es hervorragende Python-Bibliotheken gibt, die Entwicklern, die nicht auf Verarbeitung nat√ºrlicher Sprache oder maschinelles Lernen spezialisiert sind, den Zugang erheblich erleichtern. In den n√§chsten Lektionen werden weitere Beispiele vorgestellt, aber hier lernen Sie einige n√ºtzliche Beispiele kennen, die Ihnen bei der n√§chsten Aufgabe helfen.

### √úbung - Verwendung der `TextBlob`-Bibliothek

Lassen Sie uns eine Bibliothek namens TextBlob verwenden, da sie hilfreiche APIs f√ºr die Bew√§ltigung dieser Aufgaben enth√§lt. TextBlob "steht auf den Schultern von [NLTK](https://nltk.org) und [pattern](https://github.com/clips/pattern) und arbeitet gut mit beiden zusammen." Es enth√§lt eine betr√§chtliche Menge an ML in seiner API.

> Hinweis: Ein n√ºtzlicher [Quick Start](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart)-Leitfaden ist f√ºr TextBlob verf√ºgbar und wird erfahrenen Python-Entwicklern empfohlen.

Wenn Sie versuchen, *Substantivphrasen* zu identifizieren, bietet TextBlob mehrere Optionen von Extraktoren, um Substantivphrasen zu finden.

1. Schauen Sie sich `ConllExtractor` an.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > Was passiert hier? [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) ist "Ein Substantivphrasen-Extraktor, der Chunk-Parsing verwendet, das mit dem ConLL-2000-Trainingskorpus trainiert wurde." ConLL-2000 bezieht sich auf die Konferenz √ºber Computational Natural Language Learning im Jahr 2000. Jedes Jahr veranstaltete die Konferenz einen Workshop, um ein schwieriges NLP-Problem zu l√∂sen, und im Jahr 2000 war es das Chunking von Substantivphrasen. Ein Modell wurde auf dem Wall Street Journal trainiert, mit "Abschnitten 15-18 als Trainingsdaten (211727 Token) und Abschnitt 20 als Testdaten (47377 Token)". Sie k√∂nnen die verwendeten Verfahren [hier](https://www.clips.uantwerpen.be/conll2000/chunking/) und die [Ergebnisse](https://ifarm.nl/erikt/research/np-chunking.html) einsehen.

### Herausforderung - Verbesserung Ihres Bots mit NLP

In der vorherigen Lektion haben Sie einen sehr einfachen Q&A-Bot erstellt. Jetzt machen Sie Marvin ein wenig einf√ºhlsamer, indem Sie Ihre Eingabe auf Stimmung analysieren und eine Antwort drucken, die zur Stimmung passt. Sie m√ºssen auch eine `Substantivphrase` identifizieren und dazu eine Frage stellen.

Ihre Schritte beim Erstellen eines besseren Konversationsbots:

1. Drucken Sie Anweisungen, die den Benutzer dar√ºber informieren, wie er mit dem Bot interagieren soll.
2. Starten Sie die Schleife:
   1. Akzeptieren Sie die Benutzereingabe.
   2. Wenn der Benutzer um Beenden gebeten hat, dann beenden.
   3. Verarbeiten Sie die Benutzereingabe und bestimmen Sie die passende Stimmungsantwort.
   4. Wenn eine Substantivphrase in der Stimmung erkannt wird, machen Sie sie plural und fragen Sie nach weiteren Eingaben zu diesem Thema.
   5. Drucken Sie die Antwort.
3. Kehren Sie zu Schritt 2 zur√ºck.

Hier ist der Codeausschnitt, um die Stimmung mit TextBlob zu bestimmen. Beachten Sie, dass es nur vier *Abstufungen* der Stimmungsantwort gibt (Sie k√∂nnten mehr hinzuf√ºgen, wenn Sie m√∂chten):

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

Hier ist eine Beispielausgabe zur Orientierung (Benutzereingaben beginnen mit >):

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

Eine m√∂gliche L√∂sung f√ºr die Aufgabe finden Sie [hier](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/2-Tasks/solution/bot.py).

‚úÖ Wissens√ºberpr√ºfung

1. Glauben Sie, dass die einf√ºhlsamen Antworten jemanden dazu bringen k√∂nnten, zu denken, dass der Bot sie tats√§chlich versteht?
2. Macht das Identifizieren der Substantivphrase den Bot glaubw√ºrdiger?
3. Warum w√§re das Extrahieren einer 'Substantivphrase' aus einem Satz eine n√ºtzliche Aufgabe?

---

Implementieren Sie den Bot aus der vorherigen Wissens√ºberpr√ºfung und testen Sie ihn mit einem Freund. Kann er sie t√§uschen? K√∂nnen Sie Ihren Bot glaubw√ºrdiger machen?

## üöÄHerausforderung

Nehmen Sie eine Aufgabe aus der vorherigen Wissens√ºberpr√ºfung und versuchen Sie, sie zu implementieren. Testen Sie den Bot mit einem Freund. Kann er sie t√§uschen? K√∂nnen Sie Ihren Bot glaubw√ºrdiger machen?

## [Quiz nach der Vorlesung](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/34/)

## √úberpr√ºfung & Selbststudium

In den n√§chsten Lektionen werden Sie mehr √ºber Sentiment-Analyse lernen. Recherchieren Sie diese interessante Technik in Artikeln wie diesen auf [KDNuggets](https://www.kdnuggets.com/tag/nlp).

## Aufgabe

[Bringen Sie einen Bot zum Antworten](assignment.md)

---

**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-√úbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, beachten Sie bitte, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache sollte als ma√ügebliche Quelle betrachtet werden. F√ºr kritische Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die sich aus der Nutzung dieser √úbersetzung ergeben.