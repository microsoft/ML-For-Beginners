# H√§ufige Aufgaben und Techniken der Verarbeitung nat√ºrlicher Sprache

F√ºr die meisten Aufgaben der *Verarbeitung nat√ºrlicher Sprache* muss der zu verarbeitende Text in kleinere Einheiten zerlegt, analysiert und die Ergebnisse gespeichert oder mit Regeln und Datens√§tzen abgeglichen werden. Diese Aufgaben erm√∂glichen es dem Programmierer, die _Bedeutung_ oder _Absicht_ oder nur die _H√§ufigkeit_ von Begriffen und W√∂rtern in einem Text abzuleiten.

## [Vorlesungsquiz](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/33/)

Lass uns g√§ngige Techniken zur Textverarbeitung entdecken. In Kombination mit maschinellem Lernen helfen diese Techniken dabei, gro√üe Textmengen effizient zu analysieren. Bevor wir ML auf diese Aufgaben anwenden, lass uns jedoch die Probleme verstehen, mit denen ein NLP-Spezialist konfrontiert ist.

## Aufgaben, die in der NLP h√§ufig vorkommen

Es gibt verschiedene M√∂glichkeiten, einen Text zu analysieren, an dem du arbeitest. Es gibt Aufgaben, die du durchf√ºhren kannst, und durch diese Aufgaben kannst du ein Verst√§ndnis des Textes gewinnen und Schlussfolgerungen ziehen. Du f√ºhrst diese Aufgaben normalerweise in einer bestimmten Reihenfolge durch.

### Tokenisierung

Wahrscheinlich ist das Erste, was die meisten NLP-Algorithmen tun m√ºssen, den Text in Token oder W√∂rter zu zerlegen. Obwohl das einfach klingt, kann es schwierig werden, wenn man Satzzeichen und die Wort- und Satztrennzeichen verschiedener Sprachen ber√ºcksichtigen muss. M√∂glicherweise musst du verschiedene Methoden verwenden, um die Abgrenzungen zu bestimmen.

![tokenization](../../../../translated_images/tokenization.1641a160c66cd2d93d4524e8114e93158a9ce0eba3ecf117bae318e8a6ad3487.de.png)
> Tokenisierung eines Satzes aus **Stolz und Vorurteil**. Infografik von [Jen Looper](https://twitter.com/jenlooper)

### Einbettungen

[Worteinbettungen](https://wikipedia.org/wiki/Word_embedding) sind eine M√∂glichkeit, deine Textdaten numerisch zu konvertieren. Einbettungen werden so durchgef√ºhrt, dass W√∂rter mit √§hnlicher Bedeutung oder W√∂rter, die zusammen verwendet werden, zusammengefasst werden.

![word embeddings](../../../../translated_images/embedding.2cf8953c4b3101d188c2f61a5de5b6f53caaa5ad4ed99236d42bc3b6bd6a1fe2.de.png)
> "Ich habe den h√∂chsten Respekt vor deinen Nerven, sie sind meine alten Freunde." - Worteinbettungen f√ºr einen Satz in **Stolz und Vorurteil**. Infografik von [Jen Looper](https://twitter.com/jenlooper)

‚úÖ Probiere [dieses interessante Tool](https://projector.tensorflow.org/) aus, um mit Worteinbettungen zu experimentieren. Wenn du auf ein Wort klickst, siehst du Cluster √§hnlicher W√∂rter: 'Spielzeug' gruppiert sich mit 'Disney', 'Lego', 'Playstation' und 'Konsole'.

### Parsing & Part-of-Speech-Tagging

Jedes Wort, das tokenisiert wurde, kann als Teil der Sprache markiert werden - als Substantiv, Verb oder Adjektiv. Der Satz `the quick red fox jumped over the lazy brown dog` k√∂nnte als POS getaggt werden: fox = Substantiv, jumped = Verb.

![parsing](../../../../translated_images/parse.d0c5bbe1106eae8fe7d60a183cd1736c8b6cec907f38000366535f84f3036101.de.png)

> Parsing eines Satzes aus **Stolz und Vorurteil**. Infografik von [Jen Looper](https://twitter.com/jenlooper)

Parsing bedeutet, zu erkennen, welche W√∂rter in einem Satz miteinander verbunden sind - zum Beispiel ist `the quick red fox jumped` eine Adjektiv-Substantiv-Verb-Sequenz, die von der `lazy brown dog`-Sequenz getrennt ist.

### Wort- und Phrasenh√§ufigkeiten

Ein n√ºtzlicher Vorgang bei der Analyse eines gro√üen Textkorpus besteht darin, ein W√∂rterbuch aller interessierenden W√∂rter oder Phrasen und deren H√§ufigkeit zu erstellen. Die Phrase `the quick red fox jumped over the lazy brown dog` hat eine Wortfrequenz von 2 f√ºr das.

Schauen wir uns ein Beispiel an, in dem wir die H√§ufigkeit von W√∂rtern z√§hlen. Rudyard Kiplings Gedicht The Winners enth√§lt die folgende Strophe:

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

Da Phrasenh√§ufigkeiten je nach Bedarf gro√ü- oder kleinschreibungsempfindlich sein k√∂nnen, hat die Phrase `a friend` has a frequency of 2 and `the` has a frequency of 6, and `travels` eine H√§ufigkeit von 2.

### N-Gramme

Ein Text kann in Wortfolgen einer festgelegten L√§nge zerlegt werden, ein einzelnes Wort (Unigramm), zwei W√∂rter (Bigramm), drei W√∂rter (Trigramm) oder eine beliebige Anzahl von W√∂rtern (N-Gramme).

Zum Beispiel `the quick red fox jumped over the lazy brown dog` mit einem N-Gramm-Wert von 2 produziert die folgenden N-Gramme:

1. der schnelle 
2. schnelle rote 
3. rote F√ºchse
4. Fuchs sprang 
5. sprang √ºber 
6. √ºber die 
7. die faulen 
8. faulen braunen 
9. braunen Hund

Es k√∂nnte einfacher sein, es als ein gleitendes Fenster √ºber den Satz zu visualisieren. Hier ist es f√ºr N-Gramme von 3 W√∂rtern, das N-Gramm ist in jedem Satz fett hervorgehoben:

1.   <u>**der schnelle rote**</u> Fuchs sprang √ºber den faulen braunen Hund
2.   der **<u>schnelle rote Fuchs</u>** sprang √ºber den faulen braunen Hund
3.   der schnelle **<u>rote Fuchs sprang</u>** √ºber den faulen braunen Hund
4.   der schnelle rote **<u>Fuchs sprang √ºber</u>** den faulen braunen Hund
5.   der schnelle rote Fuchs **<u>sprang √ºber den</u>** faulen braunen Hund
6.   der schnelle rote Fuchs sprang **<u>√ºber den faulen</u>** braunen Hund
7.   der schnelle rote Fuchs sprang √ºber <u>**den faulen braunen**</u> Hund
8.   der schnelle rote Fuchs sprang √ºber den **<u>faulen braunen Hund</u>**

![n-grams sliding window](../../../../6-NLP/2-Tasks/images/n-grams.gif)

> N-Gramm-Wert von 3: Infografik von [Jen Looper](https://twitter.com/jenlooper)

### Nomenphrase-Extraktion

In den meisten S√§tzen gibt es ein Substantiv, das das Subjekt oder Objekt des Satzes ist. Im Englischen ist es oft erkennbar, da es von 'a', 'an' oder 'the' gefolgt wird. Das Subjekt oder Objekt eines Satzes durch 'Extrahieren der Nomenphrase' zu identifizieren, ist eine g√§ngige Aufgabe in der NLP, wenn versucht wird, die Bedeutung eines Satzes zu verstehen.

‚úÖ Im Satz "Ich kann mich nicht auf die Stunde, den Ort, den Blick oder die Worte festlegen, die das Fundament gelegt haben. Es ist zu lange her. Ich war in der Mitte, bevor ich wusste, dass ich begonnen hatte.", kannst du die Nomenphrasen identifizieren?

Im Satz `the quick red fox jumped over the lazy brown dog` gibt es 2 Nomenphrasen: **schneller roter Fuchs** und **fauler brauner Hund**.

### Sentiment-Analyse

Ein Satz oder Text kann hinsichtlich seines Sentiments analysiert werden, also wie *positiv* oder *negativ* er ist. Das Sentiment wird in *Polarit√§t* und *Objektivit√§t/Subjektivit√§t* gemessen. Die Polarit√§t wird von -1,0 bis 1,0 (negativ bis positiv) und von 0,0 bis 1,0 (am objektivsten bis am subjektivsten) gemessen.

‚úÖ Sp√§ter wirst du lernen, dass es verschiedene M√∂glichkeiten gibt, das Sentiment mithilfe von maschinellem Lernen zu bestimmen. Eine M√∂glichkeit besteht darin, eine Liste von W√∂rtern und Phrasen zu haben, die von einem menschlichen Experten als positiv oder negativ kategorisiert werden, und dieses Modell auf Texte anzuwenden, um einen Polarit√§tswert zu berechnen. Kannst du sehen, wie das in einigen F√§llen funktioniert und in anderen weniger gut?

### Flexion

Flexion erm√∂glicht es dir, ein Wort in die Einzahl oder Mehrzahl zu bringen.

### Lemmatisierung

Ein *Lemma* ist das Grund- oder Stammwort f√ºr eine Gruppe von W√∂rtern. Zum Beispiel haben *flog*, *fliegen*, *fliegende* ein Lemma des Verbs *fliegen*.

Es gibt auch n√ºtzliche Datenbanken f√ºr den NLP-Forscher, insbesondere:

### WordNet

[WordNet](https://wordnet.princeton.edu/) ist eine Datenbank von W√∂rtern, Synonymen, Antonymen und vielen anderen Details f√ºr jedes Wort in vielen verschiedenen Sprachen. Es ist unglaublich n√ºtzlich, wenn man versucht, √úbersetzungen, Rechtschreibpr√ºfungen oder Sprachtools jeglicher Art zu erstellen.

## NLP-Bibliotheken

Gl√ºcklicherweise musst du nicht alle diese Techniken selbst entwickeln, da es hervorragende Python-Bibliotheken gibt, die es Entwicklern, die nicht auf die Verarbeitung nat√ºrlicher Sprache oder maschinelles Lernen spezialisiert sind, viel zug√§nglicher machen. Die n√§chsten Lektionen enthalten weitere Beispiele daf√ºr, aber hier wirst du einige n√ºtzliche Beispiele lernen, die dir bei der n√§chsten Aufgabe helfen.

### √úbung - Verwendung von `TextBlob` library

Let's use a library called TextBlob as it contains helpful APIs for tackling these types of tasks. TextBlob "stands on the giant shoulders of [NLTK](https://nltk.org) and [pattern](https://github.com/clips/pattern), and plays nicely with both." It has a considerable amount of ML embedded in its API.

> Note: A useful [Quick Start](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart) guide is available for TextBlob that is recommended for experienced Python developers 

When attempting to identify *noun phrases*, TextBlob offers several options of extractors to find noun phrases. 

1. Take a look at `ConllExtractor`.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > Was passiert hier? [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) ist "Ein Nomenphrase-Extraktor, der Chunk-Parsing verwendet, das mit dem ConLL-2000-Trainingskorpus trainiert wurde." ConLL-2000 bezieht sich auf die Konferenz 2000 √ºber Computerlinguistik und maschinelles Lernen. Jedes Jahr veranstaltete die Konferenz einen Workshop, um ein schwieriges NLP-Problem anzugehen, und im Jahr 2000 ging es um Nomenchunking. Ein Modell wurde mit dem Wall Street Journal trainiert, wobei "Abschnitte 15-18 als Trainingsdaten (211727 Token) und Abschnitt 20 als Testdaten (47377 Token)" verwendet wurden. Du kannst die verwendeten Verfahren [hier](https://www.clips.uantwerpen.be/conll2000/chunking/) und die [Ergebnisse](https://ifarm.nl/erikt/research/np-chunking.html) einsehen.

### Herausforderung - Verbesserung deines Bots mit NLP

In der vorherigen Lektion hast du einen sehr einfachen Q&A-Bot erstellt. Jetzt wirst du Marvin etwas sympathischer machen, indem du deine Eingaben auf Sentiment analysierst und eine Antwort druckst, die dem Sentiment entspricht. Du musst auch eine `noun_phrase` identifizieren und danach fragen.

Deine Schritte beim Erstellen eines besseren Konversationsbots:

1. Drucke Anweisungen aus, die den Benutzer beraten, wie er mit dem Bot interagieren kann
2. Starte die Schleife 
   1. Nimm die Benutzereingabe entgegen
   2. Wenn der Benutzer gefragt hat, zu beenden, beende dann
   3. Verarbeite die Benutzereingabe und bestimme die geeignete Sentiment-Antwort
   4. Wenn in der Sentimentanalyse eine Nomenphrase erkannt wird, mache sie plural und frage nach mehr Informationen zu diesem Thema
   5. Drucke die Antwort
3. Kehre zu Schritt 2 zur√ºck

Hier ist der Code-Schnipsel zur Bestimmung des Sentiments mit TextBlob. Beachte, dass es nur vier *Gradationen* der Sentimentantwort gibt (du k√∂nntest mehr haben, wenn du m√∂chtest):

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

Hier ist eine Beispielausgabe zur Orientierung (Benutzereingaben stehen in den Zeilen, die mit > beginnen):

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

Eine m√∂gliche L√∂sung f√ºr die Aufgabe ist [hier](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/2-Tasks/solution/bot.py)

‚úÖ Wissens√ºberpr√ºfung

1. Glaubst du, dass die sympathischen Antworten jemanden 't√§uschen' w√ºrden, dass der Bot sie tats√§chlich verstanden hat?
2. Macht die Identifizierung der Nomenphrase den Bot 'glaubw√ºrdiger'?
3. Warum w√§re es n√ºtzlich, eine 'Nomenphrase' aus einem Satz zu extrahieren?

---

Implementiere den Bot in der vorherigen Wissens√ºberpr√ºfung und teste ihn an einem Freund. Kann er ihn t√§uschen? Kannst du deinen Bot glaubw√ºrdiger machen?

## üöÄHerausforderung

Nimm eine Aufgabe aus der vorherigen Wissens√ºberpr√ºfung und versuche, sie umzusetzen. Teste den Bot an einem Freund. Kann er ihn t√§uschen? Kannst du deinen Bot glaubw√ºrdiger machen?

## [Nachlesequiz](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/34/)

## √úberpr√ºfung & Selbststudium

In den n√§chsten Lektionen wirst du mehr √ºber Sentiment-Analyse lernen. Recherchiere diese interessante Technik in Artikeln wie diesen auf [KDNuggets](https://www.kdnuggets.com/tag/nlp)

## Aufgabe 

[Mach einen Bot, der zur√ºckredet](assignment.md)

**Haftungsausschluss**:  
Dieses Dokument wurde mithilfe von KI-√úbersetzungsdiensten √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, beachten Sie bitte, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache sollte als die ma√ügebliche Quelle betrachtet werden. F√ºr kritische Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die aus der Verwendung dieser √úbersetzung entstehen.