<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6a05fec147e734c3e6bfa54505648e2b",
  "translation_date": "2025-09-04T22:00:31+00:00",
  "source_file": "1-Introduction/2-history-of-ML/README.md",
  "language_code": "de"
}
-->
# Geschichte des maschinellen Lernens

![Zusammenfassung der Geschichte des maschinellen Lernens in einer Sketchnote](../../../../sketchnotes/ml-history.png)
> Sketchnote von [Tomomi Imura](https://www.twitter.com/girlie_mac)

## [Quiz vor der Vorlesung](https://ff-quizzes.netlify.app/en/ml/)

---

[![ML f√ºr Anf√§nger - Geschichte des maschinellen Lernens](https://img.youtube.com/vi/N6wxM4wZ7V0/0.jpg)](https://youtu.be/N6wxM4wZ7V0 "ML f√ºr Anf√§nger - Geschichte des maschinellen Lernens")

> üé• Klicken Sie auf das Bild oben, um ein kurzes Video zu dieser Lektion anzusehen.

In dieser Lektion gehen wir die wichtigsten Meilensteine in der Geschichte des maschinellen Lernens und der k√ºnstlichen Intelligenz durch.

Die Geschichte der k√ºnstlichen Intelligenz (KI) als Forschungsfeld ist eng mit der Geschichte des maschinellen Lernens verbunden, da die Algorithmen und rechnerischen Fortschritte, die ML zugrunde liegen, zur Entwicklung der KI beigetragen haben. Es ist hilfreich, sich daran zu erinnern, dass, obwohl sich diese Bereiche als eigenst√§ndige Forschungsgebiete in den 1950er Jahren herauskristallisierten, wichtige [algorithmische, statistische, mathematische, rechnerische und technische Entdeckungen](https://wikipedia.org/wiki/Timeline_of_machine_learning) diese √Ñra vorwegnahmen und √ºberlappten. Tats√§chlich besch√§ftigen sich Menschen schon seit [Hunderten von Jahren](https://wikipedia.org/wiki/History_of_artificial_intelligence) mit diesen Fragen: Dieser Artikel beleuchtet die historischen intellektuellen Grundlagen der Idee einer ‚Äûdenkenden Maschine‚Äú.

---
## Bedeutende Entdeckungen

- 1763, 1812 [Bayes-Theorem](https://wikipedia.org/wiki/Bayes%27_theorem) und seine Vorl√§ufer. Dieses Theorem und seine Anwendungen bilden die Grundlage f√ºr Inferenz, indem sie die Wahrscheinlichkeit eines Ereignisses basierend auf Vorwissen beschreiben.
- 1805 [Methode der kleinsten Quadrate](https://wikipedia.org/wiki/Least_squares) des franz√∂sischen Mathematikers Adrien-Marie Legendre. Diese Theorie, die Sie in unserer Regressionseinheit kennenlernen werden, hilft bei der Datenanpassung.
- 1913 [Markow-Ketten](https://wikipedia.org/wiki/Markov_chain), benannt nach dem russischen Mathematiker Andrey Markov, beschreiben eine Abfolge m√∂glicher Ereignisse basierend auf einem vorherigen Zustand.
- 1957 [Perzeptron](https://wikipedia.org/wiki/Perceptron), ein von dem amerikanischen Psychologen Frank Rosenblatt erfundener linearer Klassifikator, der die Grundlage f√ºr Fortschritte im Deep Learning bildet.

---

- 1967 [N√§chster-Nachbar-Algorithmus](https://wikipedia.org/wiki/Nearest_neighbor), urspr√ºnglich entwickelt, um Routen zu kartieren. Im ML-Kontext wird er zur Mustererkennung verwendet.
- 1970 [Backpropagation](https://wikipedia.org/wiki/Backpropagation) wird verwendet, um [Feedforward-Neuronale Netze](https://wikipedia.org/wiki/Feedforward_neural_network) zu trainieren.
- 1982 [Rekurrente Neuronale Netze](https://wikipedia.org/wiki/Recurrent_neural_network) sind k√ºnstliche neuronale Netze, die aus Feedforward-Netzen abgeleitet sind und zeitliche Graphen erstellen.

‚úÖ Recherchieren Sie ein wenig. Welche anderen Daten sind Ihrer Meinung nach entscheidend in der Geschichte des maschinellen Lernens und der KI?

---
## 1950: Maschinen, die denken

Alan Turing, eine wahrhaft bemerkenswerte Pers√∂nlichkeit, die [2019 von der √ñffentlichkeit](https://wikipedia.org/wiki/Icons:_The_Greatest_Person_of_the_20th_Century) zum gr√∂√üten Wissenschaftler des 20. Jahrhunderts gew√§hlt wurde, wird zugeschrieben, das Fundament f√ºr das Konzept einer ‚Äûdenkenden Maschine‚Äú gelegt zu haben. Er setzte sich mit Skeptikern auseinander und suchte nach empirischen Beweisen f√ºr dieses Konzept, unter anderem durch die Entwicklung des [Turing-Tests](https://www.bbc.com/news/technology-18475646), den Sie in unseren NLP-Lektionen n√§her kennenlernen werden.

---
## 1956: Dartmouth Summer Research Project

‚ÄûDas Dartmouth Summer Research Project zur k√ºnstlichen Intelligenz war ein wegweisendes Ereignis f√ºr das Feld der k√ºnstlichen Intelligenz‚Äú, und hier wurde der Begriff ‚Äûk√ºnstliche Intelligenz‚Äú gepr√§gt ([Quelle](https://250.dartmouth.edu/highlights/artificial-intelligence-ai-coined-dartmouth)).

> Jeder Aspekt des Lernens oder eines anderen Merkmals von Intelligenz kann im Prinzip so pr√§zise beschrieben werden, dass eine Maschine es simulieren kann.

---

Der leitende Forscher, Mathematikprofessor John McCarthy, hoffte, ‚Äûauf der Grundlage der Vermutung vorzugehen, dass jeder Aspekt des Lernens oder eines anderen Merkmals von Intelligenz im Prinzip so pr√§zise beschrieben werden kann, dass eine Maschine es simulieren kann.‚Äú Zu den Teilnehmern geh√∂rte auch eine weitere Koryph√§e des Feldes, Marvin Minsky.

Der Workshop wird daf√ºr verantwortlich gemacht, mehrere Diskussionen angesto√üen und gef√∂rdert zu haben, darunter ‚Äûden Aufstieg symbolischer Methoden, Systeme, die sich auf begrenzte Dom√§nen konzentrieren (fr√ºhe Expertensysteme), und deduktive Systeme versus induktive Systeme.‚Äú ([Quelle](https://wikipedia.org/wiki/Dartmouth_workshop)).

---
## 1956 - 1974: ‚ÄûDie goldenen Jahre‚Äú

Von den 1950er Jahren bis Mitte der 1970er Jahre herrschte gro√üer Optimismus, dass KI viele Probleme l√∂sen k√∂nnte. 1967 erkl√§rte Marvin Minsky zuversichtlich: ‚ÄûInnerhalb einer Generation ... wird das Problem, ‚Äök√ºnstliche Intelligenz‚Äò zu schaffen, im Wesentlichen gel√∂st sein.‚Äú (Minsky, Marvin (1967), Computation: Finite and Infinite Machines, Englewood Cliffs, N.J.: Prentice-Hall)

Die Forschung zur Verarbeitung nat√ºrlicher Sprache bl√ºhte auf, Suchalgorithmen wurden verfeinert und leistungsf√§higer, und das Konzept der ‚ÄûMikrowelten‚Äú wurde entwickelt, in denen einfache Aufgaben mit einfachen Sprachbefehlen ausgef√ºhrt werden konnten.

---

Die Forschung wurde gut von Regierungsbeh√∂rden finanziert, Fortschritte in der Rechenleistung und bei Algorithmen wurden erzielt, und Prototypen intelligenter Maschinen wurden gebaut. Einige dieser Maschinen umfassen:

* [Shakey der Roboter](https://wikipedia.org/wiki/Shakey_the_robot), der sich bewegen und ‚Äûintelligent‚Äú entscheiden konnte, wie Aufgaben ausgef√ºhrt werden sollten.

    ![Shakey, ein intelligenter Roboter](../../../../1-Introduction/2-history-of-ML/images/shakey.jpg)
    > Shakey im Jahr 1972

---

* Eliza, ein fr√ºher ‚ÄûChatterbot‚Äú, konnte mit Menschen kommunizieren und als primitiver ‚ÄûTherapeut‚Äú fungieren. Sie werden mehr √ºber Eliza in den NLP-Lektionen erfahren.

    ![Eliza, ein Bot](../../../../1-Introduction/2-history-of-ML/images/eliza.png)
    > Eine Version von Eliza, einem Chatbot

---

* ‚ÄûBlocks World‚Äú war ein Beispiel f√ºr eine Mikrowelt, in der Bl√∂cke gestapelt und sortiert werden konnten, und Experimente zur Entscheidungsfindung von Maschinen durchgef√ºhrt wurden. Fortschritte mit Bibliotheken wie [SHRDLU](https://wikipedia.org/wiki/SHRDLU) trieben die Sprachverarbeitung voran.

    [![Blocks World mit SHRDLU](https://img.youtube.com/vi/QAJz4YKUwqw/0.jpg)](https://www.youtube.com/watch?v=QAJz4YKUwqw "Blocks World mit SHRDLU")

    > üé• Klicken Sie auf das Bild oben f√ºr ein Video: Blocks World mit SHRDLU

---
## 1974 - 1980: ‚ÄûKI-Winter‚Äú

Mitte der 1970er Jahre wurde klar, dass die Komplexit√§t der Entwicklung ‚Äûintelligenter Maschinen‚Äú untersch√§tzt und ihr Potenzial angesichts der verf√ºgbaren Rechenleistung √ºbersch√§tzt worden war. Die Finanzierung versiegte, und das Vertrauen in das Feld nahm ab. Einige Probleme, die das Vertrauen beeintr√§chtigten, waren:

---
- **Einschr√§nkungen**. Die Rechenleistung war zu begrenzt.
- **Kombinatorische Explosion**. Die Anzahl der zu trainierenden Parameter wuchs exponentiell, je mehr von Computern verlangt wurde, ohne dass die Rechenleistung und -f√§higkeit parallel dazu wuchsen.
- **Mangel an Daten**. Es gab einen Mangel an Daten, der den Prozess des Testens, Entwickelns und Verfeinerns von Algorithmen behinderte.
- **Stellen wir die richtigen Fragen?**. Die gestellten Fragen selbst wurden infrage gestellt. Forscher sahen sich Kritik an ihren Ans√§tzen ausgesetzt:
  - Turing-Tests wurden unter anderem durch die ‚ÄûChinese Room‚Äú-Theorie infrage gestellt, die besagt, dass ‚Äûdas Programmieren eines digitalen Computers zwar den Anschein erwecken kann, Sprache zu verstehen, aber kein echtes Verst√§ndnis erzeugen kann.‚Äú ([Quelle](https://plato.stanford.edu/entries/chinese-room/))
  - Die Ethik der Einf√ºhrung k√ºnstlicher Intelligenzen wie des ‚ÄûTherapeuten‚Äú ELIZA in die Gesellschaft wurde hinterfragt.

---

Gleichzeitig begannen sich verschiedene Schulen der KI-Forschung zu bilden. Es entstand eine Dichotomie zwischen ["Scruffy" vs. "Neat AI"](https://wikipedia.org/wiki/Neats_and_scruffies)-Praktiken. _Scruffy_-Labore optimierten Programme stundenlang, bis sie die gew√ºnschten Ergebnisse erzielten. _Neat_-Labore ‚Äûkonzentrierten sich auf Logik und formale Probleml√∂sung‚Äú. ELIZA und SHRDLU waren bekannte _Scruffy_-Systeme. In den 1980er Jahren, als die Nachfrage nach reproduzierbaren ML-Systemen wuchs, setzte sich der _Neat_-Ansatz allm√§hlich durch, da seine Ergebnisse besser erkl√§rbar sind.

---
## 1980er Jahre: Expertensysteme

Mit dem Wachstum des Feldes wurde sein Nutzen f√ºr Unternehmen deutlicher, und in den 1980er Jahren verbreiteten sich ‚ÄûExpertensysteme‚Äú. ‚ÄûExpertensysteme waren eine der ersten wirklich erfolgreichen Formen von KI-Software.‚Äú ([Quelle](https://wikipedia.org/wiki/Expert_system))

Dieser Systemtyp ist tats√§chlich _hybrid_ und besteht teilweise aus einer Regel-Engine, die Gesch√§ftsanforderungen definiert, und einer Inferenz-Engine, die das Regelwerk nutzt, um neue Fakten abzuleiten.

In dieser √Ñra wurde auch den neuronalen Netzen zunehmend Aufmerksamkeit geschenkt.

---
## 1987 - 1993: ‚ÄûKI-Abk√ºhlung‚Äú

Die Verbreitung spezialisierter Hardware f√ºr Expertensysteme hatte den ungl√ºcklichen Effekt, zu spezialisiert zu werden. Der Aufstieg von Personal Computern konkurrierte mit diesen gro√üen, spezialisierten, zentralisierten Systemen. Die Demokratisierung des Rechnens hatte begonnen und ebnete schlie√ülich den Weg f√ºr die moderne Explosion von Big Data.

---
## 1993 - 2011

Diese Epoche markierte eine neue √Ñra f√ºr ML und KI, um einige der Probleme zu l√∂sen, die zuvor durch den Mangel an Daten und Rechenleistung verursacht worden waren. Die Menge an Daten begann rapide zu wachsen und wurde zunehmend verf√ºgbar, sowohl zum Guten als auch zum Schlechten, insbesondere mit dem Aufkommen des Smartphones um 2007. Die Rechenleistung wuchs exponentiell, und Algorithmen entwickelten sich parallel dazu weiter. Das Feld begann, sich zu einer echten Disziplin zu entwickeln, w√§hrend die unstrukturierten Ans√§tze der Vergangenheit allm√§hlich einer gereiften Struktur wichen.

---
## Heute

Heute ber√ºhren maschinelles Lernen und KI fast jeden Bereich unseres Lebens. Diese √Ñra erfordert ein sorgf√§ltiges Verst√§ndnis der Risiken und potenziellen Auswirkungen dieser Algorithmen auf das menschliche Leben. Wie Brad Smith von Microsoft erkl√§rt hat: ‚ÄûInformationstechnologie wirft Fragen auf, die das Herzst√ºck grundlegender Menschenrechtsfragen wie Datenschutz und Meinungsfreiheit betreffen. Diese Fragen erh√∂hen die Verantwortung von Technologieunternehmen, die diese Produkte entwickeln. Unserer Ansicht nach erfordern sie auch eine durchdachte staatliche Regulierung und die Entwicklung von Normen f√ºr akzeptable Nutzungen.‚Äú ([Quelle](https://www.technologyreview.com/2019/12/18/102365/the-future-of-ais-impact-on-society/))

---

Es bleibt abzuwarten, was die Zukunft bringt, aber es ist wichtig, diese Computersysteme sowie die Software und Algorithmen, die sie ausf√ºhren, zu verstehen. Wir hoffen, dass dieses Curriculum Ihnen hilft, ein besseres Verst√§ndnis zu erlangen, damit Sie selbst entscheiden k√∂nnen.

[![Die Geschichte des Deep Learning](https://img.youtube.com/vi/mTtDfKgLm54/0.jpg)](https://www.youtube.com/watch?v=mTtDfKgLm54 "Die Geschichte des Deep Learning")
> üé• Klicken Sie auf das Bild oben f√ºr ein Video: Yann LeCun spricht in diesem Vortrag √ºber die Geschichte des Deep Learning

---
## üöÄ Herausforderung

Tauchen Sie in einen dieser historischen Momente ein und erfahren Sie mehr √ºber die Menschen dahinter. Es gibt faszinierende Pers√∂nlichkeiten, und keine wissenschaftliche Entdeckung wurde jemals in einem kulturellen Vakuum gemacht. Was entdecken Sie?

## [Quiz nach der Vorlesung](https://ff-quizzes.netlify.app/en/ml/)

---
## R√ºckblick & Selbststudium

Hier sind einige Inhalte zum Anschauen und Anh√∂ren:

[Dieser Podcast, in dem Amy Boyd √ºber die Entwicklung der KI spricht](http://runasradio.com/Shows/Show/739)

[![Die Geschichte der KI von Amy Boyd](https://img.youtube.com/vi/EJt3_bFYKss/0.jpg)](https://www.youtube.com/watch?v=EJt3_bFYKss "Die Geschichte der KI von Amy Boyd")

---

## Aufgabe

[Erstellen Sie eine Zeitleiste](assignment.md)

---

**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-√úbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, weisen wir darauf hin, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache sollte als ma√ügebliche Quelle betrachtet werden. F√ºr kritische Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die sich aus der Nutzung dieser √úbersetzung ergeben.