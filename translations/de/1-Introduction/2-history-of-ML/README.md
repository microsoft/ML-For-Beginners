<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b2d11df10030cacc41427a1fbc8bc8f1",
  "translation_date": "2025-09-03T21:52:04+00:00",
  "source_file": "1-Introduction/2-history-of-ML/README.md",
  "language_code": "de"
}
-->
# Geschichte des maschinellen Lernens

![Zusammenfassung der Geschichte des maschinellen Lernens in einer Sketchnote](../../../../translated_images/ml-history.a1bdfd4ce1f464d9a0502f38d355ffda384c95cd5278297a46c9a391b5053bc4.de.png)
> Sketchnote von [Tomomi Imura](https://www.twitter.com/girlie_mac)

## [Quiz vor der Vorlesung](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/3/)

---

[![ML fÃ¼r AnfÃ¤nger - Geschichte des maschinellen Lernens](https://img.youtube.com/vi/N6wxM4wZ7V0/0.jpg)](https://youtu.be/N6wxM4wZ7V0 "ML fÃ¼r AnfÃ¤nger - Geschichte des maschinellen Lernens")

> ğŸ¥ Klicken Sie auf das Bild oben, um ein kurzes Video zu dieser Lektion anzusehen.

In dieser Lektion gehen wir die wichtigsten Meilensteine in der Geschichte des maschinellen Lernens und der kÃ¼nstlichen Intelligenz durch.

Die Geschichte der kÃ¼nstlichen Intelligenz (KI) als Forschungsfeld ist eng mit der Geschichte des maschinellen Lernens verbunden, da die Algorithmen und rechnerischen Fortschritte, die ML zugrunde liegen, die Entwicklung der KI vorangetrieben haben. Es ist wichtig zu bedenken, dass sich diese Bereiche zwar erst in den 1950er Jahren als eigenstÃ¤ndige Forschungsgebiete herauskristallisierten, aber wichtige [algorithmische, statistische, mathematische, rechnerische und technische Entdeckungen](https://wikipedia.org/wiki/Timeline_of_machine_learning) bereits vorher gemacht wurden und sich mit dieser Ã„ra Ã¼berschnitten. TatsÃ¤chlich beschÃ¤ftigen sich Menschen schon seit [Hunderten von Jahren](https://wikipedia.org/wiki/History_of_artificial_intelligence) mit diesen Fragen: Dieser Artikel beleuchtet die historischen intellektuellen Grundlagen der Idee einer â€denkenden Maschineâ€œ.

---
## Bedeutende Entdeckungen

- 1763, 1812 [Bayes-Theorem](https://wikipedia.org/wiki/Bayes%27_theorem) und seine VorgÃ¤nger. Dieses Theorem und seine Anwendungen bilden die Grundlage der Inferenz und beschreiben die Wahrscheinlichkeit eines Ereignisses basierend auf vorherigem Wissen.
- 1805 [Methode der kleinsten Quadrate](https://wikipedia.org/wiki/Least_squares) von dem franzÃ¶sischen Mathematiker Adrien-Marie Legendre. Diese Theorie, die Sie in unserer Regressionseinheit kennenlernen werden, hilft bei der Datenanpassung.
- 1913 [Markow-Ketten](https://wikipedia.org/wiki/Markov_chain), benannt nach dem russischen Mathematiker Andrey Markov, werden verwendet, um eine Abfolge mÃ¶glicher Ereignisse basierend auf einem vorherigen Zustand zu beschreiben.
- 1957 [Perceptron](https://wikipedia.org/wiki/Perceptron) ist eine Art linearer Klassifikator, der von dem amerikanischen Psychologen Frank Rosenblatt erfunden wurde und die Grundlage fÃ¼r Fortschritte im Deep Learning bildet.

---

- 1967 [NÃ¤chster Nachbar](https://wikipedia.org/wiki/Nearest_neighbor) ist ein Algorithmus, der ursprÃ¼nglich zur Routenplanung entwickelt wurde. Im ML-Kontext wird er zur Mustererkennung verwendet.
- 1970 [Backpropagation](https://wikipedia.org/wiki/Backpropagation) wird verwendet, um [Feedforward-Neuronale Netze](https://wikipedia.org/wiki/Feedforward_neural_network) zu trainieren.
- 1982 [Rekurrente Neuronale Netze](https://wikipedia.org/wiki/Recurrent_neural_network) sind kÃ¼nstliche neuronale Netze, die aus Feedforward-Netzen abgeleitet sind und zeitliche Graphen erstellen.

âœ… Machen Sie ein wenig Recherche. Welche anderen Daten sind Ihrer Meinung nach entscheidend in der Geschichte des maschinellen Lernens und der KI?

---
## 1950: Maschinen, die denken

Alan Turing, eine wirklich bemerkenswerte PersÃ¶nlichkeit, die [2019 von der Ã–ffentlichkeit](https://wikipedia.org/wiki/Icons:_The_Greatest_Person_of_the_20th_Century) als der grÃ¶ÃŸte Wissenschaftler des 20. Jahrhunderts gewÃ¤hlt wurde, wird zugeschrieben, die Grundlage fÃ¼r das Konzept einer â€denkenden Maschineâ€œ gelegt zu haben. Er setzte sich mit Kritikern auseinander und suchte nach empirischen Beweisen fÃ¼r dieses Konzept, unter anderem durch die Entwicklung des [Turing-Tests](https://www.bbc.com/news/technology-18475646), den Sie in unseren NLP-Lektionen nÃ¤her kennenlernen werden.

---
## 1956: Dartmouth Summer Research Project

â€Das Dartmouth Summer Research Project zur kÃ¼nstlichen Intelligenz war ein wegweisendes Ereignis fÃ¼r die KI als Forschungsfeldâ€œ, und hier wurde der Begriff â€kÃ¼nstliche Intelligenzâ€œ geprÃ¤gt ([Quelle](https://250.dartmouth.edu/highlights/artificial-intelligence-ai-coined-dartmouth)).

> Jeder Aspekt des Lernens oder eines anderen Merkmals der Intelligenz kann im Prinzip so genau beschrieben werden, dass eine Maschine dazu gebracht werden kann, ihn zu simulieren.

---

Der leitende Forscher, Mathematikprofessor John McCarthy, hoffte â€auf der Grundlage der Vermutung vorzugehen, dass jeder Aspekt des Lernens oder eines anderen Merkmals der Intelligenz im Prinzip so genau beschrieben werden kann, dass eine Maschine dazu gebracht werden kann, ihn zu simulieren.â€œ Zu den Teilnehmern gehÃ¶rte auch eine weitere bedeutende PersÃ¶nlichkeit des Feldes, Marvin Minsky.

Der Workshop wird dafÃ¼r anerkannt, mehrere Diskussionen angestoÃŸen und gefÃ¶rdert zu haben, darunter â€der Aufstieg symbolischer Methoden, Systeme, die sich auf begrenzte DomÃ¤nen konzentrieren (frÃ¼he Expertensysteme), und deduktive Systeme versus induktive Systeme.â€œ ([Quelle](https://wikipedia.org/wiki/Dartmouth_workshop)).

---
## 1956 - 1974: â€Die goldenen Jahreâ€œ

Von den 1950er Jahren bis Mitte der 1970er Jahre herrschte groÃŸe Zuversicht, dass KI viele Probleme lÃ¶sen kÃ¶nnte. 1967 erklÃ¤rte Marvin Minsky selbstbewusst: â€Innerhalb einer Generation ... wird das Problem der Schaffung von â€škÃ¼nstlicher Intelligenzâ€˜ im Wesentlichen gelÃ¶st sein.â€œ (Minsky, Marvin (1967), Computation: Finite and Infinite Machines, Englewood Cliffs, N.J.: Prentice-Hall)

Die Forschung zur Verarbeitung natÃ¼rlicher Sprache blÃ¼hte auf, Suchalgorithmen wurden verfeinert und leistungsfÃ¤higer gemacht, und das Konzept der â€Mikroweltenâ€œ wurde entwickelt, in denen einfache Aufgaben mit einfachen Sprachbefehlen ausgefÃ¼hrt werden konnten.

---

Die Forschung wurde von RegierungsbehÃ¶rden gut finanziert, Fortschritte in der Berechnung und bei Algorithmen wurden erzielt, und Prototypen intelligenter Maschinen wurden gebaut. Einige dieser Maschinen umfassen:

* [Shakey der Roboter](https://wikipedia.org/wiki/Shakey_the_robot), der sich bewegen und entscheiden konnte, wie er Aufgaben â€intelligentâ€œ ausfÃ¼hrt.

    ![Shakey, ein intelligenter Roboter](../../../../translated_images/shakey.4dc17819c447c05bf4b52f76da0bdd28817d056fdb906252ec20124dd4cfa55e.de.jpg)
    > Shakey im Jahr 1972

---

* Eliza, ein frÃ¼her â€Chatterbotâ€œ, konnte mit Menschen kommunizieren und als primitiver â€Therapeutâ€œ fungieren. Sie werden mehr Ã¼ber Eliza in den NLP-Lektionen erfahren.

    ![Eliza, ein Bot](../../../../translated_images/eliza.84397454cda9559bb5ec296b5b8fff067571c0cccc5405f9c1ab1c3f105c075c.de.png)
    > Eine Version von Eliza, ein Chatbot

---

* â€Blocks Worldâ€œ war ein Beispiel fÃ¼r eine Mikrowelt, in der BlÃ¶cke gestapelt und sortiert werden konnten und Experimente zur Entscheidungsfindung von Maschinen durchgefÃ¼hrt wurden. Fortschritte mit Bibliotheken wie [SHRDLU](https://wikipedia.org/wiki/SHRDLU) trieben die Sprachverarbeitung voran.

    [![Blocks World mit SHRDLU](https://img.youtube.com/vi/QAJz4YKUwqw/0.jpg)](https://www.youtube.com/watch?v=QAJz4YKUwqw "Blocks World mit SHRDLU")

    > ğŸ¥ Klicken Sie auf das Bild oben fÃ¼r ein Video: Blocks World mit SHRDLU

---
## 1974 - 1980: â€AI Winterâ€œ

Mitte der 1970er Jahre wurde klar, dass die KomplexitÃ¤t der Schaffung â€intelligenter Maschinenâ€œ unterschÃ¤tzt und ihr Versprechen angesichts der verfÃ¼gbaren Rechenleistung Ã¼berbewertet worden war. Die Finanzierung versiegte und das Vertrauen in das Feld nahm ab. Einige Probleme, die das Vertrauen beeintrÃ¤chtigten, waren:
---
- **EinschrÃ¤nkungen**. Die Rechenleistung war zu begrenzt.
- **Kombinatorische Explosion**. Die Anzahl der zu trainierenden Parameter wuchs exponentiell, je mehr von Computern verlangt wurde, ohne dass sich die Rechenleistung und -fÃ¤higkeit parallel weiterentwickelten.
- **Mangel an Daten**. Es gab einen Mangel an Daten, der den Prozess des Testens, Entwickelns und Verfeinerns von Algorithmen behinderte.
- **Stellen wir die richtigen Fragen?**. Die gestellten Fragen selbst wurden infrage gestellt. Forscher sahen sich Kritik an ihren AnsÃ¤tzen gegenÃ¼ber:
  - Turing-Tests wurden unter anderem durch die â€Chinese Room Theoryâ€œ infrage gestellt, die besagt, dass â€das Programmieren eines digitalen Computers ihn zwar so erscheinen lassen kann, als wÃ¼rde er Sprache verstehen, aber kein echtes VerstÃ¤ndnis erzeugen kÃ¶nnte.â€œ ([Quelle](https://plato.stanford.edu/entries/chinese-room/))
  - Die Ethik der EinfÃ¼hrung kÃ¼nstlicher Intelligenzen wie des â€Therapeutenâ€œ ELIZA in die Gesellschaft wurde herausgefordert.

---

Gleichzeitig begannen sich verschiedene Schulen der KI-Forschung zu bilden. Es entstand eine Dichotomie zwischen ["Scruffy" vs. "Neat AI"](https://wikipedia.org/wiki/Neats_and_scruffies)-Praktiken. _Scruffy_-Labore optimierten Programme stundenlang, bis sie die gewÃ¼nschten Ergebnisse erzielten. _Neat_-Labore â€konzentrierten sich auf Logik und formale ProblemlÃ¶sungâ€œ. ELIZA und SHRDLU waren bekannte _Scruffy_-Systeme. In den 1980er Jahren, als die Nachfrage nach reproduzierbaren ML-Systemen aufkam, setzte sich der _Neat_-Ansatz allmÃ¤hlich durch, da seine Ergebnisse besser erklÃ¤rbar sind.

---
## 1980er Jahre: Expertensysteme

Mit dem Wachstum des Feldes wurde sein Nutzen fÃ¼r Unternehmen deutlicher, und in den 1980er Jahren verbreiteten sich â€Expertensystemeâ€œ. â€Expertensysteme gehÃ¶rten zu den ersten wirklich erfolgreichen Formen von kÃ¼nstlicher Intelligenz (KI)-Software.â€œ ([Quelle](https://wikipedia.org/wiki/Expert_system)).

Diese Art von System ist tatsÃ¤chlich _hybrid_ und besteht teilweise aus einer Regel-Engine, die GeschÃ¤ftsanforderungen definiert, und einer Inferenz-Engine, die das Regelwerk nutzt, um neue Fakten abzuleiten.

In dieser Ã„ra wurde auch den neuronalen Netzen zunehmend Aufmerksamkeit geschenkt.

---
## 1987 - 1993: AI â€Chillâ€œ

Die Verbreitung spezialisierter Expertensystem-Hardware hatte den unglÃ¼cklichen Effekt, zu spezialisiert zu werden. Der Aufstieg von Personal Computern konkurrierte mit diesen groÃŸen, spezialisierten, zentralisierten Systemen. Die Demokratisierung des Rechnens hatte begonnen und ebnete schlieÃŸlich den Weg fÃ¼r die moderne Explosion von Big Data.

---
## 1993 - 2011

Diese Epoche markierte eine neue Ã„ra fÃ¼r ML und KI, um einige der Probleme zu lÃ¶sen, die zuvor durch den Mangel an Daten und Rechenleistung verursacht worden waren. Die Menge an Daten begann rapide zu wachsen und wurde zunehmend verfÃ¼gbar, sowohl zum Guten als auch zum Schlechten, insbesondere mit der EinfÃ¼hrung des Smartphones um 2007. Die Rechenleistung nahm exponentiell zu, und Algorithmen entwickelten sich parallel dazu weiter. Das Feld begann, Reife zu erlangen, da die ungebundenen Tage der Vergangenheit sich zu einer echten Disziplin formten.

---
## Heute

Heute berÃ¼hren maschinelles Lernen und KI fast jeden Teil unseres Lebens. Diese Ã„ra erfordert ein sorgfÃ¤ltiges VerstÃ¤ndnis der Risiken und potenziellen Auswirkungen dieser Algorithmen auf das menschliche Leben. Wie Brad Smith von Microsoft erklÃ¤rt hat: â€Informationstechnologie wirft Fragen auf, die das HerzstÃ¼ck grundlegender Menschenrechtsfragen wie PrivatsphÃ¤re und Meinungsfreiheit berÃ¼hren. Diese Fragen erhÃ¶hen die Verantwortung fÃ¼r Technologieunternehmen, die diese Produkte entwickeln. Aus unserer Sicht erfordern sie auch eine durchdachte staatliche Regulierung und die Entwicklung von Normen fÃ¼r akzeptable Anwendungen.â€œ ([Quelle](https://www.technologyreview.com/2019/12/18/102365/the-future-of-ais-impact-on-society/)).

---

Es bleibt abzuwarten, was die Zukunft bringt, aber es ist wichtig, diese Computersysteme sowie die Software und Algorithmen, die sie ausfÃ¼hren, zu verstehen. Wir hoffen, dass dieses Curriculum Ihnen hilft, ein besseres VerstÃ¤ndnis zu erlangen, damit Sie selbst entscheiden kÃ¶nnen.

[![Die Geschichte des Deep Learning](https://img.youtube.com/vi/mTtDfKgLm54/0.jpg)](https://www.youtube.com/watch?v=mTtDfKgLm54 "Die Geschichte des Deep Learning")
> ğŸ¥ Klicken Sie auf das Bild oben fÃ¼r ein Video: Yann LeCun diskutiert die Geschichte des Deep Learning in diesem Vortrag

---
## ğŸš€ Herausforderung

Tauchen Sie in einen dieser historischen Momente ein und erfahren Sie mehr Ã¼ber die Menschen dahinter. Es gibt faszinierende PersÃ¶nlichkeiten, und keine wissenschaftliche Entdeckung wurde jemals in einem kulturellen Vakuum gemacht. Was entdecken Sie?

## [Quiz nach der Vorlesung](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/4/)

---
## ÃœberprÃ¼fung & Selbststudium

Hier sind einige Dinge, die Sie sich ansehen und anhÃ¶ren kÃ¶nnen:

[Dieser Podcast, in dem Amy Boyd die Entwicklung der KI diskutiert](http://runasradio.com/Shows/Show/739)

[![Die Geschichte der KI von Amy Boyd](https://img.youtube.com/vi/EJt3_bFYKss/0.jpg)](https://www.youtube.com/watch?v=EJt3_bFYKss "Die Geschichte der KI von Amy Boyd")

---

## Aufgabe

[Erstellen Sie eine Zeitleiste](assignment.md)

---

**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-Ãœbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) Ã¼bersetzt. Obwohl wir uns um Genauigkeit bemÃ¼hen, beachten Sie bitte, dass automatisierte Ãœbersetzungen Fehler oder Ungenauigkeiten enthalten kÃ¶nnen. Das Originaldokument in seiner ursprÃ¼nglichen Sprache sollte als maÃŸgebliche Quelle betrachtet werden. FÃ¼r kritische Informationen wird eine professionelle menschliche Ãœbersetzung empfohlen. Wir Ã¼bernehmen keine Haftung fÃ¼r MissverstÃ¤ndnisse oder Fehlinterpretationen, die sich aus der Nutzung dieser Ãœbersetzung ergeben.