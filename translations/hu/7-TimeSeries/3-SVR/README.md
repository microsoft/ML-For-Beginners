<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "482bccabe1df958496ea71a3667995cd",
  "translation_date": "2025-09-05T15:36:39+00:00",
  "source_file": "7-TimeSeries/3-SVR/README.md",
  "language_code": "hu"
}
-->
# Id≈ësoros el≈ërejelz√©s Support Vector Regressor seg√≠ts√©g√©vel

Az el≈ëz≈ë leck√©ben megtanultad, hogyan haszn√°lhatod az ARIMA modellt id≈ësoros el≈ërejelz√©sek k√©sz√≠t√©s√©re. Most a Support Vector Regressor modellel fogsz megismerkedni, amely egy regresszi√≥s modell folyamatos adatok el≈ërejelz√©s√©re.

## [El≈ëzetes kv√≠z](https://ff-quizzes.netlify.app/en/ml/) 

## Bevezet√©s

Ebben a leck√©ben felfedezheted, hogyan √©p√≠thetsz modelleket [**SVM**: **S**upport **V**ector **M**achine](https://en.wikipedia.org/wiki/Support-vector_machine) seg√≠ts√©g√©vel regresszi√≥hoz, vagyis **SVR: Support Vector Regressor**.

### SVR az id≈ësoros el≈ërejelz√©s kontextus√°ban [^1]

Miel≈ëtt meg√©rten√©d az SVR fontoss√°g√°t az id≈ësoros el≈ërejelz√©sben, √≠me n√©h√°ny fontos fogalom, amelyet ismerned kell:

- **Regresszi√≥:** Fel√ºgyelt tanul√°si technika, amely folyamatos √©rt√©keket j√≥sol meg egy adott bemeneti halmazb√≥l. Az √∂tlet az, hogy egy g√∂rb√©t (vagy egyenes vonalat) illessz√ºnk a jellemz≈ëk ter√©be, amely a legt√∂bb adatpontot tartalmazza. [Kattints ide](https://en.wikipedia.org/wiki/Regression_analysis) tov√°bbi inform√°ci√≥√©rt.
- **Support Vector Machine (SVM):** Egy fel√ºgyelt g√©pi tanul√°si modell, amelyet oszt√°lyoz√°sra, regresszi√≥ra √©s kiugr√≥ √©rt√©kek detekt√°l√°s√°ra haszn√°lnak. A modell egy hipers√≠k a jellemz≈ëk ter√©ben, amely oszt√°lyoz√°s eset√©n hat√°rk√©nt, regresszi√≥ eset√©n pedig legjobban illeszked≈ë vonalk√©nt m≈±k√∂dik. Az SVM-ben √°ltal√°ban Kernel f√ºggv√©nyt haszn√°lnak az adathalmaz magasabb dimenzi√≥j√∫ t√©rbe t√∂rt√©n≈ë √°talak√≠t√°s√°ra, hogy k√∂nnyebben elv√°laszthat√≥ak legyenek. [Kattints ide](https://en.wikipedia.org/wiki/Support-vector_machine) tov√°bbi inform√°ci√≥√©rt az SVM-ekr≈ël.
- **Support Vector Regressor (SVR):** Az SVM egy t√≠pusa, amely megtal√°lja a legjobban illeszked≈ë vonalat (ami az SVM eset√©ben egy hipers√≠k), amely a legt√∂bb adatpontot tartalmazza.

### Mi√©rt SVR? [^1]

Az el≈ëz≈ë leck√©ben megismerkedt√©l az ARIMA modellel, amely egy nagyon sikeres statisztikai line√°ris m√≥dszer id≈ësoros adatok el≈ërejelz√©s√©re. Azonban sok esetben az id≈ësoros adatok *nemlinearit√°st* mutatnak, amelyet a line√°ris modellek nem tudnak lek√©pezni. Ilyen esetekben az SVM k√©pess√©ge, hogy figyelembe vegye az adatok nemlinearit√°s√°t a regresszi√≥s feladatok sor√°n, sikeress√© teszi az SVR-t az id≈ësoros el≈ërejelz√©sben.

## Gyakorlat - SVR modell √©p√≠t√©se

Az els≈ë n√©h√°ny adat-el≈ëk√©sz√≠t√©si l√©p√©s megegyezik az el≈ëz≈ë [ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA) leck√©ben tanultakkal.

Nyisd meg a [_/working_](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/3-SVR/working) mapp√°t ebben a leck√©ben, √©s keresd meg a [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/7-TimeSeries/3-SVR/working/notebook.ipynb) f√°jlt. [^2]

1. Futtasd a notebookot, √©s import√°ld a sz√ºks√©ges k√∂nyvt√°rakat: [^2]

   ```python
   import sys
   sys.path.append('../../')
   ```

   ```python
   import os
   import warnings
   import matplotlib.pyplot as plt
   import numpy as np
   import pandas as pd
   import datetime as dt
   import math
   
   from sklearn.svm import SVR
   from sklearn.preprocessing import MinMaxScaler
   from common.utils import load_data, mape
   ```

2. T√∂ltsd be az adatokat a `/data/energy.csv` f√°jlb√≥l egy Pandas dataframe-be, √©s n√©zd meg: [^2]

   ```python
   energy = load_data('../../data')[['load']]
   ```

3. √Åbr√°zold az √∂sszes el√©rhet≈ë energiaadatot 2012 janu√°rj√°t√≥l 2014 december√©ig: [^2]

   ```python
   energy.plot(y='load', subplots=True, figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![teljes adatok](../../../../7-TimeSeries/3-SVR/images/full-data.png)

   Most √©p√≠ts√ºk meg az SVR modell√ºnket.

### K√©pz√©si √©s tesztel√©si adathalmazok l√©trehoz√°sa

Most, hogy az adatok bet√∂ltve vannak, sz√©tv√°laszthatod ≈ëket k√©pz√©si √©s tesztel√©si halmazokra. Ezut√°n √°talak√≠tod az adatokat id≈ël√©p√©s-alap√∫ adathalmazz√°, amelyre sz√ºks√©g lesz az SVR-hez. A modell k√©pz√©s√©t a k√©pz√©si halmazon v√©gzed. Miut√°n a modell befejezte a k√©pz√©st, ki√©rt√©keled a pontoss√°g√°t a k√©pz√©si halmazon, a tesztel√©si halmazon, majd az eg√©sz adathalmazon, hogy l√°thasd az √°ltal√°nos teljes√≠tm√©nyt. Biztos√≠tanod kell, hogy a tesztel√©si halmaz egy k√©s≈ëbbi id≈ëszakot fedjen le, mint a k√©pz√©si halmaz, hogy elker√ºld, hogy a modell inform√°ci√≥t szerezzen a j√∂v≈ëbeli id≈ëszakokb√≥l [^2] (ezt a helyzetet *t√∫ltanul√°snak* nevezz√ºk).

1. Jel√∂lj ki egy k√©t h√≥napos id≈ëszakot 2014. szeptember 1-t≈ël okt√≥ber 31-ig a k√©pz√©si halmaz sz√°m√°ra. A tesztel√©si halmaz a 2014. november 1-t≈ël december 31-ig tart√≥ k√©t h√≥napos id≈ëszakot fogja tartalmazni: [^2]

   ```python
   train_start_dt = '2014-11-01 00:00:00'
   test_start_dt = '2014-12-30 00:00:00'
   ```

2. Vizualiz√°ld a k√ºl√∂nbs√©geket: [^2]

   ```python
   energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)][['load']].rename(columns={'load':'train'}) \
       .join(energy[test_start_dt:][['load']].rename(columns={'load':'test'}), how='outer') \
       .plot(y=['train', 'test'], figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![k√©pz√©si √©s tesztel√©si adatok](../../../../7-TimeSeries/3-SVR/images/train-test.png)

### Adatok el≈ëk√©sz√≠t√©se a k√©pz√©shez

Most el≈ë kell k√©sz√≠tened az adatokat a k√©pz√©shez, sz≈±r√©ssel √©s sk√°l√°z√°ssal. Sz≈±rd az adathalmazt, hogy csak a sz√ºks√©ges id≈ëszakokat √©s oszlopokat tartalmazza, majd sk√°l√°zd az adatokat, hogy az √©rt√©kek a 0 √©s 1 k√∂z√∂tti intervallumba essenek.

1. Sz≈±rd az eredeti adathalmazt, hogy csak az eml√≠tett id≈ëszakokat √©s a sz√ºks√©ges 'load' oszlopot, valamint a d√°tumot tartalmazza: [^2]

   ```python
   train = energy.copy()[(energy.index >= train_start_dt) & (energy.index < test_start_dt)][['load']]
   test = energy.copy()[energy.index >= test_start_dt][['load']]
   
   print('Training data shape: ', train.shape)
   print('Test data shape: ', test.shape)
   ```

   ```output
   Training data shape:  (1416, 1)
   Test data shape:  (48, 1)
   ```
   
2. Sk√°l√°zd a k√©pz√©si adatokat a (0, 1) tartom√°nyba: [^2]

   ```python
   scaler = MinMaxScaler()
   train['load'] = scaler.fit_transform(train)
   ```
   
4. Most sk√°l√°zd a tesztel√©si adatokat: [^2]

   ```python
   test['load'] = scaler.transform(test)
   ```

### Adatok l√©trehoz√°sa id≈ël√©p√©sekkel [^1]

Az SVR-hez az input adatokat `[batch, timesteps]` form√°ra kell √°talak√≠tani. Ez√©rt √°talak√≠tod a megl√©v≈ë `train_data` √©s `test_data` adatokat √∫gy, hogy legyen egy √∫j dimenzi√≥, amely az id≈ël√©p√©seket jel√∂li.

```python
# Converting to numpy arrays
train_data = train.values
test_data = test.values
```

Ebben a p√©ld√°ban `timesteps = 5` √©rt√©ket vesz√ºnk. Teh√°t a modell bemenete az els≈ë 4 id≈ël√©p√©s adatai lesznek, a kimenet pedig az 5. id≈ël√©p√©s adatai.

```python
timesteps=5
```

A k√©pz√©si adatok 2D tensorra val√≥ √°talak√≠t√°sa be√°gyazott listakomprehenzi√≥val:

```python
train_data_timesteps=np.array([[j for j in train_data[i:i+timesteps]] for i in range(0,len(train_data)-timesteps+1)])[:,:,0]
train_data_timesteps.shape
```

```output
(1412, 5)
```

A tesztel√©si adatok 2D tensorra val√≥ √°talak√≠t√°sa:

```python
test_data_timesteps=np.array([[j for j in test_data[i:i+timesteps]] for i in range(0,len(test_data)-timesteps+1)])[:,:,0]
test_data_timesteps.shape
```

```output
(44, 5)
```

A k√©pz√©si √©s tesztel√©si adatok bemeneteinek √©s kimeneteinek kiv√°laszt√°sa:

```python
x_train, y_train = train_data_timesteps[:,:timesteps-1],train_data_timesteps[:,[timesteps-1]]
x_test, y_test = test_data_timesteps[:,:timesteps-1],test_data_timesteps[:,[timesteps-1]]

print(x_train.shape, y_train.shape)
print(x_test.shape, y_test.shape)
```

```output
(1412, 4) (1412, 1)
(44, 4) (44, 1)
```

### SVR megval√≥s√≠t√°sa [^1]

Most itt az ideje, hogy megval√≥s√≠tsd az SVR-t. Tov√°bbi inform√°ci√≥√©rt err≈ël a megval√≥s√≠t√°sr√≥l, olvasd el [ezt a dokument√°ci√≥t](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html). A mi megval√≥s√≠t√°sunkban a k√∂vetkez≈ë l√©p√©seket k√∂vetj√ºk:

  1. Defini√°ld a modellt az `SVR()` megh√≠v√°s√°val, √©s add meg a modell hiperparam√©tereit: kernel, gamma, c √©s epsilon
  2. K√©sz√≠tsd el≈ë a modellt a k√©pz√©si adatokhoz az `fit()` f√ºggv√©ny megh√≠v√°s√°val
  3. V√©gezz el≈ërejelz√©seket az `predict()` f√ºggv√©ny megh√≠v√°s√°val

Most l√©trehozzuk az SVR modellt. Itt az [RBF kernel](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel) haszn√°lat√°t v√°lasztjuk, √©s a hiperparam√©tereket gamma, C √©s epsilon √©rt√©kekre √°ll√≠tjuk: 0.5, 10 √©s 0.05.

```python
model = SVR(kernel='rbf',gamma=0.5, C=10, epsilon = 0.05)
```

#### Modell illeszt√©se a k√©pz√©si adatokra [^1]

```python
model.fit(x_train, y_train[:,0])
```

```output
SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.05, gamma=0.5,
    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)
```

#### Modell el≈ërejelz√©sek k√©sz√≠t√©se [^1]

```python
y_train_pred = model.predict(x_train).reshape(-1,1)
y_test_pred = model.predict(x_test).reshape(-1,1)

print(y_train_pred.shape, y_test_pred.shape)
```

```output
(1412, 1) (44, 1)
```

Elk√©sz√≠tetted az SVR-t! Most ki kell √©rt√©kelni.

### Modell ki√©rt√©kel√©se [^1]

A ki√©rt√©kel√©shez el≈ësz√∂r visszask√°l√°zzuk az adatokat az eredeti sk√°l√°ra. Ezut√°n az eredm√©ny ellen≈ërz√©s√©hez √°br√°zoljuk az eredeti √©s el≈ërejelzett id≈ësoros adatokat, valamint ki√≠rjuk a MAPE eredm√©nyt.

Az el≈ërejelzett √©s eredeti kimenet sk√°l√°z√°sa:

```python
# Scaling the predictions
y_train_pred = scaler.inverse_transform(y_train_pred)
y_test_pred = scaler.inverse_transform(y_test_pred)

print(len(y_train_pred), len(y_test_pred))
```

```python
# Scaling the original values
y_train = scaler.inverse_transform(y_train)
y_test = scaler.inverse_transform(y_test)

print(len(y_train), len(y_test))
```

#### Modell teljes√≠tm√©ny√©nek ellen≈ërz√©se a k√©pz√©si √©s tesztel√©si adatokon [^1]

Kinyerj√ºk az id≈ëb√©lyegeket az adathalmazb√≥l, hogy az x-tengelyen megjelen√≠ts√ºk ≈ëket. Ne feledd, hogy az els≈ë ```timesteps-1``` √©rt√©keket haszn√°ljuk bemenetk√©nt az els≈ë kimenethez, √≠gy a kimenet id≈ëb√©lyegei ezut√°n kezd≈ëdnek.

```python
train_timestamps = energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)].index[timesteps-1:]
test_timestamps = energy[test_start_dt:].index[timesteps-1:]

print(len(train_timestamps), len(test_timestamps))
```

```output
1412 44
```

A k√©pz√©si adatok el≈ërejelz√©seinek √°br√°zol√°sa:

```python
plt.figure(figsize=(25,6))
plt.plot(train_timestamps, y_train, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(train_timestamps, y_train_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.title("Training data prediction")
plt.show()
```

![k√©pz√©si adatok el≈ërejelz√©se](../../../../7-TimeSeries/3-SVR/images/train-data-predict.png)

MAPE ki√≠r√°sa a k√©pz√©si adatokra:

```python
print('MAPE for training data: ', mape(y_train_pred, y_train)*100, '%')
```

```output
MAPE for training data: 1.7195710200875551 %
```

A tesztel√©si adatok el≈ërejelz√©seinek √°br√°zol√°sa:

```python
plt.figure(figsize=(10,3))
plt.plot(test_timestamps, y_test, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(test_timestamps, y_test_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![tesztel√©si adatok el≈ërejelz√©se](../../../../7-TimeSeries/3-SVR/images/test-data-predict.png)

MAPE ki√≠r√°sa a tesztel√©si adatokra:

```python
print('MAPE for testing data: ', mape(y_test_pred, y_test)*100, '%')
```

```output
MAPE for testing data:  1.2623790187854018 %
```

üèÜ Nagyon j√≥ eredm√©nyt √©rt√©l el a tesztel√©si adathalmazon!

### Modell teljes√≠tm√©ny√©nek ellen≈ërz√©se a teljes adathalmazon [^1]

```python
# Extracting load values as numpy array
data = energy.copy().values

# Scaling
data = scaler.transform(data)

# Transforming to 2D tensor as per model input requirement
data_timesteps=np.array([[j for j in data[i:i+timesteps]] for i in range(0,len(data)-timesteps+1)])[:,:,0]
print("Tensor shape: ", data_timesteps.shape)

# Selecting inputs and outputs from data
X, Y = data_timesteps[:,:timesteps-1],data_timesteps[:,[timesteps-1]]
print("X shape: ", X.shape,"\nY shape: ", Y.shape)
```

```output
Tensor shape:  (26300, 5)
X shape:  (26300, 4) 
Y shape:  (26300, 1)
```

```python
# Make model predictions
Y_pred = model.predict(X).reshape(-1,1)

# Inverse scale and reshape
Y_pred = scaler.inverse_transform(Y_pred)
Y = scaler.inverse_transform(Y)
```

```python
plt.figure(figsize=(30,8))
plt.plot(Y, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(Y_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![teljes adatok el≈ërejelz√©se](../../../../7-TimeSeries/3-SVR/images/full-data-predict.png)

```python
print('MAPE: ', mape(Y_pred, Y)*100, '%')
```

```output
MAPE:  2.0572089029888656 %
```

üèÜ Nagyon sz√©p √°br√°k, amelyek egy j√≥ pontoss√°g√∫ modellt mutatnak. Sz√©p munka!

---

## üöÄKih√≠v√°s

- Pr√≥b√°ld meg m√≥dos√≠tani a hiperparam√©tereket (gamma, C, epsilon) a modell l√©trehoz√°sakor, √©s √©rt√©keld ki az adatokat, hogy l√°sd, melyik hiperparam√©ter-k√©szlet adja a legjobb eredm√©nyeket a tesztel√©si adatokon. Tov√°bbi inform√°ci√≥√©rt ezekr≈ël a hiperparam√©terekr≈ël olvasd el [ezt a dokumentumot](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel). 
- Pr√≥b√°lj ki k√ºl√∂nb√∂z≈ë kernel f√ºggv√©nyeket a modellhez, √©s elemezd a teljes√≠tm√©ny√ºket az adathalmazon. Egy hasznos dokumentumot itt tal√°lhatsz: [kernel f√ºggv√©nyek](https://scikit-learn.org/stable/modules/svm.html#kernel-functions).
- Pr√≥b√°lj ki k√ºl√∂nb√∂z≈ë √©rt√©keket a `timesteps` param√©terhez, hogy a modell visszatekintve k√©sz√≠tsen el≈ërejelz√©st.

## [Ut√≥lagos kv√≠z](https://ff-quizzes.netlify.app/en/ml/)

## √Åttekint√©s √©s √∂n√°ll√≥ tanul√°s

Ez a lecke az SVR alkalmaz√°s√°t mutatta be id≈ësoros el≈ërejelz√©shez. Tov√°bbi inform√°ci√≥√©rt az SVR-r≈ël olvasd el [ezt a blogot](https://www.analyticsvidhya.com/blog/2020/03/support-vector-regression-tutorial-for-machine-learning/). Ez a [scikit-learn dokument√°ci√≥](https://scikit-learn.org/stable/modules/svm.html) √°tfog√≥bb magyar√°zatot ny√∫jt az SVM-ekr≈ël √°ltal√°ban, az [SVR-ekr≈ël](https://scikit-learn.org/stable/modules/svm.html#regression), valamint m√°s megval√≥s√≠t√°si r√©szletekr≈ël, p√©ld√°ul a k√ºl√∂nb√∂z≈ë [kernel f√ºggv√©nyekr≈ël](https://scikit-learn.org/stable/modules/svm.html#kernel-functions), amelyek haszn√°lhat√≥k, √©s azok param√©tereir≈ël.

## Feladat

[Egy √∫j SVR modell](assignment.md)

## K√∂sz√∂net

[^1]: A sz√∂veget, k√≥dot √©s kimenetet ebben a szakaszban [@AnirbanMukherjeeXD](https://github.com/AnirbanMukherjeeXD) k√©sz√≠tette
[^2]: A sz√∂veget, k√≥dot √©s kimenetet ebben a szakaszban az [ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA) leck√©b≈ël vett√ºk

---

**Felel≈ëss√©g kiz√°r√°sa**:  
Ez a dokumentum az AI ford√≠t√°si szolg√°ltat√°s, a [Co-op Translator](https://github.com/Azure/co-op-translator) seg√≠ts√©g√©vel lett leford√≠tva. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelv√©n tekintend≈ë hiteles forr√°snak. Kritikus inform√°ci√≥k eset√©n javasolt professzion√°lis emberi ford√≠t√°st ig√©nybe venni. Nem v√°llalunk felel≈ëss√©get az ebb≈ël a ford√≠t√°sb√≥l ered≈ë f√©lre√©rt√©sek√©rt vagy t√©ves √©rtelmez√©sek√©rt.