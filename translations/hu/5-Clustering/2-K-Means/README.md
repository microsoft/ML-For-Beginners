<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7cdd17338d9bbd7e2171c2cd462eb081",
  "translation_date": "2025-09-05T15:45:56+00:00",
  "source_file": "5-Clustering/2-K-Means/README.md",
  "language_code": "hu"
}
-->
# K-Means klaszterez√©s

## [El≈ëad√°s el≈ëtti kv√≠z](https://ff-quizzes.netlify.app/en/ml/)

Ebben a leck√©ben megtanulod, hogyan hozz l√©tre klasztereket a Scikit-learn √©s az el≈ëz≈ëekben import√°lt nig√©riai zenei adat√°llom√°ny seg√≠ts√©g√©vel. √Åttekintj√ºk a K-Means alapjait a klaszterez√©shez. Ne feledd, ahogy az el≈ëz≈ë leck√©ben tanultad, sz√°mos m√≥dja van a klaszterekkel val√≥ munk√°nak, √©s az alkalmazott m√≥dszer az adataidt√≥l f√ºgg. Kipr√≥b√°ljuk a K-Means-t, mivel ez a leggyakoribb klaszterez√©si technika. Kezdj√ºk!

Fogalmak, amelyeket megismerhetsz:

- Silhouette pontsz√°m
- K√∂ny√∂km√≥dszer
- Inertia
- Variancia

## Bevezet√©s

A [K-Means klaszterez√©s](https://wikipedia.org/wiki/K-means_clustering) a jelfeldolgoz√°s ter√ºlet√©r≈ël sz√°rmaz√≥ m√≥dszer. Arra haszn√°lj√°k, hogy az adatokat 'k' klaszterekbe ossz√°k √©s csoportos√≠ts√°k megfigyel√©sek sorozata alapj√°n. Minden megfigyel√©s arra t√∂rekszik, hogy az adott adatpontot a legk√∂zelebbi '√°tlaghoz', vagyis egy klaszter k√∂z√©ppontj√°hoz csoportos√≠tsa.

A klaszterek [Voronoi diagramokk√©nt](https://wikipedia.org/wiki/Voronoi_diagram) is megjelen√≠thet≈ëk, amelyek tartalmaznak egy pontot (vagy 'magot') √©s annak megfelel≈ë r√©gi√≥j√°t.

![voronoi diagram](../../../../5-Clustering/2-K-Means/images/voronoi.png)

> Infografika: [Jen Looper](https://twitter.com/jenlooper)

A K-Means klaszterez√©si folyamat [h√°rom l√©p√©sben zajlik](https://scikit-learn.org/stable/modules/clustering.html#k-means):

1. Az algoritmus kiv√°lasztja az adat√°llom√°nyb√≥l k sz√°m√∫ k√∂z√©ppontot mintav√©telez√©ssel. Ezut√°n ism√©tl≈ëd≈ëen:
    1. Minden mint√°t hozz√°rendel a legk√∂zelebbi centroidhoz.
    2. √öj centroidokat hoz l√©tre az el≈ëz≈ë centroidokhoz rendelt mint√°k √°tlag√©rt√©ke alapj√°n.
    3. Ezut√°n kisz√°m√≠tja az √∫j √©s r√©gi centroidok k√∂z√∂tti k√ºl√∂nbs√©get, √©s addig ism√©tli, am√≠g a centroidok stabiliz√°l√≥dnak.

A K-Means haszn√°lat√°nak egyik h√°tr√°nya, hogy meg kell hat√°roznod 'k'-t, azaz a centroidok sz√°m√°t. Szerencs√©re a 'k√∂ny√∂km√≥dszer' seg√≠t egy j√≥ kiindul√°si √©rt√©k becsl√©s√©ben 'k'-hoz. Mindj√°rt kipr√≥b√°ljuk.

## El≈ëfelt√©tel

Ebben a lecke [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/2-K-Means/notebook.ipynb) f√°jlj√°ban fogsz dolgozni, amely tartalmazza az el≈ëz≈ë leck√©ben v√©gzett adatimport√°l√°st √©s el≈ëzetes tiszt√≠t√°st.

## Gyakorlat - el≈ëk√©sz√≠t√©s

Kezdd azzal, hogy √∫jra megn√©zed a dalok adatait.

1. Hozz l√©tre egy boxplotot, √©s h√≠vd meg a `boxplot()` f√ºggv√©nyt minden oszlopra:

    ```python
    plt.figure(figsize=(20,20), dpi=200)
    
    plt.subplot(4,3,1)
    sns.boxplot(x = 'popularity', data = df)
    
    plt.subplot(4,3,2)
    sns.boxplot(x = 'acousticness', data = df)
    
    plt.subplot(4,3,3)
    sns.boxplot(x = 'energy', data = df)
    
    plt.subplot(4,3,4)
    sns.boxplot(x = 'instrumentalness', data = df)
    
    plt.subplot(4,3,5)
    sns.boxplot(x = 'liveness', data = df)
    
    plt.subplot(4,3,6)
    sns.boxplot(x = 'loudness', data = df)
    
    plt.subplot(4,3,7)
    sns.boxplot(x = 'speechiness', data = df)
    
    plt.subplot(4,3,8)
    sns.boxplot(x = 'tempo', data = df)
    
    plt.subplot(4,3,9)
    sns.boxplot(x = 'time_signature', data = df)
    
    plt.subplot(4,3,10)
    sns.boxplot(x = 'danceability', data = df)
    
    plt.subplot(4,3,11)
    sns.boxplot(x = 'length', data = df)
    
    plt.subplot(4,3,12)
    sns.boxplot(x = 'release_date', data = df)
    ```

    Ez az adat kiss√© zajos: az egyes oszlopok boxplotjait megfigyelve l√°thatod a kiugr√≥ √©rt√©keket.

    ![outliers](../../../../5-Clustering/2-K-Means/images/boxplots.png)

Az adat√°llom√°nyt √°tn√©zve elt√°vol√≠thatn√°d ezeket a kiugr√≥ √©rt√©keket, de ez az adatokat el√©gg√© minimaliz√°ln√°.

1. Egyel≈ëre v√°laszd ki, mely oszlopokat fogod haszn√°lni a klaszterez√©si gyakorlatban. V√°lassz olyanokat, amelyek hasonl√≥ tartom√°nyokkal rendelkeznek, √©s k√≥dold az `artist_top_genre` oszlopot numerikus adatk√©nt:

    ```python
    from sklearn.preprocessing import LabelEncoder
    le = LabelEncoder()
    
    X = df.loc[:, ('artist_top_genre','popularity','danceability','acousticness','loudness','energy')]
    
    y = df['artist_top_genre']
    
    X['artist_top_genre'] = le.fit_transform(X['artist_top_genre'])
    
    y = le.transform(y)
    ```

1. Most meg kell hat√°roznod, h√°ny klasztert c√©lozz meg. Tudod, hogy az adat√°llom√°nyb√≥l 3 zenei m≈±fajt v√°lasztottunk ki, √≠gy pr√≥b√°ljuk meg a 3-at:

    ```python
    from sklearn.cluster import KMeans
    
    nclusters = 3 
    seed = 0
    
    km = KMeans(n_clusters=nclusters, random_state=seed)
    km.fit(X)
    
    # Predict the cluster for each data point
    
    y_cluster_kmeans = km.predict(X)
    y_cluster_kmeans
    ```

Egy t√∂mb√∂t l√°tsz, amely az adatkeret minden sor√°ra el≈ërejelzett klasztereket (0, 1 vagy 2) tartalmaz.

1. Haszn√°ld ezt a t√∂mb√∂t egy 'silhouette pontsz√°m' kisz√°m√≠t√°s√°hoz:

    ```python
    from sklearn import metrics
    score = metrics.silhouette_score(X, y_cluster_kmeans)
    score
    ```

## Silhouette pontsz√°m

Keress egy silhouette pontsz√°mot, amely k√∂zelebb van az 1-hez. Ez a pontsz√°m -1 √©s 1 k√∂z√∂tt v√°ltozik, √©s ha a pontsz√°m 1, akkor a klaszter s≈±r≈± √©s j√≥l elk√ºl√∂n√ºl a t√∂bbi klasztert≈ël. A 0-hoz k√∂zeli √©rt√©k √°tfed≈ë klasztereket jel√∂l, ahol a mint√°k nagyon k√∂zel vannak a szomsz√©dos klaszterek d√∂nt√©si hat√°r√°hoz. [(Forr√°s)](https://dzone.com/articles/kmeans-silhouette-score-explained-with-python-exam)

A pontsz√°munk **.53**, teh√°t k√∂z√©pen van. Ez azt jelzi, hogy az adataink nem k√ºl√∂n√∂sebben alkalmasak erre a klaszterez√©si t√≠pusra, de folytassuk.

### Gyakorlat - modell √©p√≠t√©se

1. Import√°ld a `KMeans`-t, √©s kezdj bele a klaszterez√©si folyamatba.

    ```python
    from sklearn.cluster import KMeans
    wcss = []
    
    for i in range(1, 11):
        kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)
        kmeans.fit(X)
        wcss.append(kmeans.inertia_)
    
    ```

    N√©h√°ny r√©szlet magyar√°zatra szorul.

    > üéì range: Ezek a klaszterez√©si folyamat iter√°ci√≥i.

    > üéì random_state: "Meghat√°rozza a v√©letlensz√°m-gener√°l√°st a centroid inicializ√°l√°s√°hoz." [Forr√°s](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)

    > üéì WCSS: "a klaszteren bel√ºli n√©gyzetes √∂sszeg" m√©ri az √∂sszes pont √°tlagos n√©gyzetes t√°vols√°g√°t a klaszter centroidj√°t√≥l. [Forr√°s](https://medium.com/@ODSC/unsupervised-learning-evaluating-clusters-bd47eed175ce).

    > üéì Inertia: A K-Means algoritmusok arra t√∂rekednek, hogy olyan centroidokat v√°lasszanak, amelyek minimaliz√°lj√°k az 'inertia'-t, "a klaszterek bels≈ë koherenci√°j√°nak m√©rt√©k√©t." [Forr√°s](https://scikit-learn.org/stable/modules/clustering.html). Az √©rt√©ket minden iter√°ci√≥ sor√°n hozz√°adjuk a wcss v√°ltoz√≥hoz.

    > üéì k-means++: A [Scikit-learn](https://scikit-learn.org/stable/modules/clustering.html#k-means) haszn√°lat√°val alkalmazhatod a 'k-means++' optimaliz√°l√°st, amely "√°ltal√°ban egym√°st√≥l t√°voli centroidokat inicializ√°l, val√≥sz√≠n≈±leg jobb eredm√©nyeket eredm√©nyezve, mint a v√©letlenszer≈± inicializ√°l√°s."

### K√∂ny√∂km√≥dszer

Kor√°bban felt√©telezted, hogy mivel 3 zenei m≈±fajt c√©lozt√°l meg, 3 klasztert kell v√°lasztanod. De val√≥ban √≠gy van?

1. Haszn√°ld a 'k√∂ny√∂km√≥dszert', hogy megbizonyosodj r√≥la.

    ```python
    plt.figure(figsize=(10,5))
    sns.lineplot(x=range(1, 11), y=wcss, marker='o', color='red')
    plt.title('Elbow')
    plt.xlabel('Number of clusters')
    plt.ylabel('WCSS')
    plt.show()
    ```

    Haszn√°ld a kor√°bbi l√©p√©sben l√©trehozott `wcss` v√°ltoz√≥t, hogy k√©sz√≠ts egy diagramot, amely megmutatja, hol van a 'kanyar' a k√∂ny√∂kben, ami a klaszterek optim√°lis sz√°m√°t jelzi. Tal√°n t√©nyleg **3**!

    ![elbow method](../../../../5-Clustering/2-K-Means/images/elbow.png)

## Gyakorlat - klaszterek megjelen√≠t√©se

1. Pr√≥b√°ld √∫jra a folyamatot, ez√∫ttal h√°rom klasztert be√°ll√≠tva, √©s jelen√≠tsd meg a klasztereket sz√≥r√°sdiagramk√©nt:

    ```python
    from sklearn.cluster import KMeans
    kmeans = KMeans(n_clusters = 3)
    kmeans.fit(X)
    labels = kmeans.predict(X)
    plt.scatter(df['popularity'],df['danceability'],c = labels)
    plt.xlabel('popularity')
    plt.ylabel('danceability')
    plt.show()
    ```

1. Ellen≈ërizd a modell pontoss√°g√°t:

    ```python
    labels = kmeans.labels_
    
    correct_labels = sum(y == labels)
    
    print("Result: %d out of %d samples were correctly labeled." % (correct_labels, y.size))
    
    print('Accuracy score: {0:0.2f}'. format(correct_labels/float(y.size)))
    ```

    Ennek a modellnek a pontoss√°ga nem t√∫l j√≥, √©s a klaszterek alakja ad egy tippet, hogy mi√©rt.

    ![clusters](../../../../5-Clustering/2-K-Means/images/clusters.png)

    Ezek az adatok t√∫l kiegyens√∫lyozatlanok, t√∫l kev√©ss√© korrel√°ltak, √©s az oszlop√©rt√©kek k√∂z√∂tt t√∫l nagy a variancia ahhoz, hogy j√≥l klaszterezhet≈ëk legyenek. Val√≥j√°ban az √°ltalunk meghat√°rozott h√°rom m≈±fajkateg√≥ria val√≥sz√≠n≈±leg er≈ësen befoly√°solja vagy torz√≠tja a kialakul√≥ klasztereket. Ez egy tanul√°si folyamat volt!

    A Scikit-learn dokument√°ci√≥j√°ban l√°thatod, hogy egy ilyen modell, ahol a klaszterek nem nagyon j√≥l elk√ºl√∂n√ºltek, 'variancia' probl√©m√°val k√ºzd:

    ![problem models](../../../../5-Clustering/2-K-Means/images/problems.png)
    > Infografika: Scikit-learn

## Variancia

A variancia √∫gy defini√°lhat√≥, mint "az √°tlagt√≥l val√≥ n√©gyzetes elt√©r√©sek √°tlaga" [(Forr√°s)](https://www.mathsisfun.com/data/standard-deviation.html). Ebben a klaszterez√©si probl√©m√°ban arra utal, hogy az adat√°llom√°ny sz√°mai hajlamosak t√∫lzottan elt√©rni az √°tlagt√≥l.

‚úÖ Ez egy remek pillanat arra, hogy √°tgondold, milyen m√≥dokon jav√≠thatn√°d ezt a probl√©m√°t. Finom√≠tsd az adatokat? Haszn√°lj m√°s oszlopokat? Pr√≥b√°lj ki egy m√°sik algoritmust? Tipp: Pr√≥b√°ld meg [normaliz√°lni az adatokat](https://www.mygreatlearning.com/blog/learning-data-science-with-k-means-clustering/) √©s tesztelj m√°s oszlopokat.

> Pr√≥b√°ld ki ezt a '[variancia kalkul√°tort](https://www.calculatorsoup.com/calculators/statistics/variance-calculator.php)', hogy jobban meg√©rtsd a fogalmat.

---

## üöÄKih√≠v√°s

T√∂lts el egy kis id≈ët ezzel a notebookkal, √©s finom√≠tsd a param√©tereket. Jav√≠thatod-e a modell pontoss√°g√°t az adatok tov√°bbi tiszt√≠t√°s√°val (p√©ld√°ul a kiugr√≥ √©rt√©kek elt√°vol√≠t√°s√°val)? Haszn√°lhatsz s√∫lyokat, hogy bizonyos adatmint√°knak nagyobb s√∫lyt adj. Mit tehetsz m√©g a jobb klaszterek l√©trehoz√°sa √©rdek√©ben?

Tipp: Pr√≥b√°ld meg sk√°l√°zni az adatokat. A notebookban van komment√°lt k√≥d, amely hozz√°adja a standard sk√°l√°z√°st, hogy az adat√°llom√°ny oszlopai jobban hasonl√≠tsanak egym√°sra tartom√°ny szempontj√°b√≥l. Meg fogod l√°tni, hogy b√°r a silhouette pontsz√°m cs√∂kken, a k√∂ny√∂k grafikon 'kanyarja' kisimul. Ez az√©rt van, mert az adatok sk√°l√°zatlanul hagy√°sa lehet≈ëv√© teszi, hogy a kisebb varianci√°j√∫ adatok nagyobb s√∫lyt kapjanak. Olvass t√∂bbet err≈ël a probl√©m√°r√≥l [itt](https://stats.stackexchange.com/questions/21222/are-mean-normalization-and-feature-scaling-needed-for-k-means-clustering/21226#21226).

## [El≈ëad√°s ut√°ni kv√≠z](https://ff-quizzes.netlify.app/en/ml/)

## √Åttekint√©s √©s √∂n√°ll√≥ tanul√°s

N√©zd meg egy K-Means szimul√°tort [p√©ld√°ul ezt](https://user.ceng.metu.edu.tr/~akifakkus/courses/ceng574/k-means/). Ezzel az eszk√∂zzel vizualiz√°lhatod a mintapontokat √©s meghat√°rozhatod a centroidokat. Szerkesztheted az adatok v√©letlenszer≈±s√©g√©t, a klaszterek sz√°m√°t √©s a centroidok sz√°m√°t. Seg√≠t ez abban, hogy jobban meg√©rtsd, hogyan csoportos√≠that√≥k az adatok?

N√©zd meg [ezt a K-Means seg√©danyagot](https://stanford.edu/~cpiech/cs221/handouts/kmeans.html) a Stanfordt√≥l.

## Feladat

[Pr√≥b√°lj ki k√ºl√∂nb√∂z≈ë klaszterez√©si m√≥dszereket](assignment.md)

---

**Felel≈ëss√©g kiz√°r√°sa**:  
Ez a dokumentum az AI ford√≠t√°si szolg√°ltat√°s, a [Co-op Translator](https://github.com/Azure/co-op-translator) seg√≠ts√©g√©vel lett leford√≠tva. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelv√©n tekintend≈ë hiteles forr√°snak. Kritikus inform√°ci√≥k eset√©n javasolt professzion√°lis emberi ford√≠t√°st ig√©nybe venni. Nem v√°llalunk felel≈ëss√©get semmilyen f√©lre√©rt√©s√©rt vagy t√©ves √©rtelmez√©s√©rt, amely a ford√≠t√°s haszn√°lat√°b√≥l eredhet.