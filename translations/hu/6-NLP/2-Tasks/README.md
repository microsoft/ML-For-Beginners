<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "5f3cb462e3122e1afe7ab0050ccf2bd3",
  "translation_date": "2025-09-05T16:50:29+00:00",
  "source_file": "6-NLP/2-Tasks/README.md",
  "language_code": "hu"
}
-->
# Gyakori term√©szetes nyelvfeldolgoz√°si feladatok √©s technik√°k

A legt√∂bb *term√©szetes nyelvfeldolgoz√°si* feladat eset√©ben a feldolgozand√≥ sz√∂veget fel kell bontani, meg kell vizsg√°lni, √©s az eredm√©nyeket el kell t√°rolni vagy √∂ssze kell vetni szab√°lyokkal √©s adatb√°zisokkal. Ezek a feladatok lehet≈ëv√© teszik a programoz√≥ sz√°m√°ra, hogy a sz√∂veg _jelent√©s√©t_, _sz√°nd√©k√°t_ vagy csak a kifejez√©sek √©s szavak _gyakoris√°g√°t_ meg√©rtse.

## [El≈ëad√°s el≈ëtti kv√≠z](https://ff-quizzes.netlify.app/en/ml/)

Fedezz√ºk fel a sz√∂vegfeldolgoz√°sban haszn√°lt gyakori technik√°kat. Ezek a technik√°k g√©pi tanul√°ssal kombin√°lva seg√≠tenek hat√©konyan elemezni nagy mennyis√©g≈± sz√∂veget. Miel≈ëtt g√©pi tanul√°st alkalmazn√°nk ezekre a feladatokra, el≈ësz√∂r √©rts√ºk meg azokat a probl√©m√°kat, amelyekkel egy NLP szakember szembes√ºl.

## NLP-hez kapcsol√≥d√≥ feladatok

Sz√°mos m√≥dja van annak, hogy elemezz√ºk a sz√∂veget, amelyen dolgozunk. Vannak feladatok, amelyeket elv√©gezhet√ºnk, √©s ezek r√©v√©n meg√©rthetj√ºk a sz√∂veget, valamint k√∂vetkeztet√©seket vonhatunk le. Ezeket a feladatokat √°ltal√°ban egy meghat√°rozott sorrendben hajtjuk v√©gre.

### Tokeniz√°ci√≥

Val√≥sz√≠n≈±leg az els≈ë dolog, amit a legt√∂bb NLP algoritmusnak el kell v√©geznie, az a sz√∂veg tokenekre vagy szavakra bont√°sa. B√°r ez egyszer≈±nek t≈±nik, a k√ºl√∂nb√∂z≈ë nyelvek √≠r√°sjelei √©s mondathat√°rol√≥i miatt bonyolult lehet. K√ºl√∂nb√∂z≈ë m√≥dszereket kell alkalmazni a hat√°rok meghat√°roz√°s√°hoz.

![tokeniz√°ci√≥](../../../../6-NLP/2-Tasks/images/tokenization.png)
> Egy mondat tokeniz√°l√°sa a **B√ºszkes√©g √©s bal√≠t√©let** c√≠m≈± m≈±b≈ël. Infografika: [Jen Looper](https://twitter.com/jenlooper)

### Be√°gyaz√°sok

[A szavak be√°gyaz√°sa](https://wikipedia.org/wiki/Word_embedding) egy m√≥dszer arra, hogy a sz√∂vegadatokat numerikus form√°ba alak√≠tsuk. A be√°gyaz√°sokat √∫gy v√©gezz√ºk, hogy a hasonl√≥ jelent√©s≈± vagy egy√ºtt haszn√°lt szavak csoportosuljanak.

![szavak be√°gyaz√°sa](../../../../6-NLP/2-Tasks/images/embedding.png)
> "A legnagyobb tisztelettel vagyok az idegeid ir√°nt, ≈ëk a r√©gi bar√°taim." - Szavak be√°gyaz√°sa egy mondatban a **B√ºszkes√©g √©s bal√≠t√©let** c√≠m≈± m≈±b≈ël. Infografika: [Jen Looper](https://twitter.com/jenlooper)

‚úÖ Pr√≥b√°ld ki [ezt az √©rdekes eszk√∂zt](https://projector.tensorflow.org/) a szavak be√°gyaz√°s√°nak k√≠s√©rletez√©s√©hez. Egy sz√≥ kiv√°laszt√°s√°val hasonl√≥ szavak csoportjait l√°thatod: p√©ld√°ul a 'j√°t√©k' csoportosul a 'disney', 'lego', 'playstation' √©s 'konzol' szavakkal.

### Elemz√©s √©s sz√≥faji c√≠mk√©z√©s

Minden tokeniz√°lt sz√≥t sz√≥fajk√©nt lehet c√≠mk√©zni - p√©ld√°ul f≈ën√©v, ige vagy mell√©kn√©v. A mondat `a gyors v√∂r√∂s r√≥ka √°tugrott a lusta barna kutya felett` sz√≥faji c√≠mk√©z√©se lehet p√©ld√°ul r√≥ka = f≈ën√©v, ugrott = ige.

![elemz√©s](../../../../6-NLP/2-Tasks/images/parse.png)

> Egy mondat elemz√©se a **B√ºszkes√©g √©s bal√≠t√©let** c√≠m≈± m≈±b≈ël. Infografika: [Jen Looper](https://twitter.com/jenlooper)

Az elemz√©s sor√°n felismerj√ºk, hogy mely szavak kapcsol√≥dnak egym√°shoz egy mondatban - p√©ld√°ul `a gyors v√∂r√∂s r√≥ka ugrott` egy mell√©kn√©v-f≈ën√©v-ige sorozat, amely elk√ºl√∂n√ºl a `lusta barna kutya` sorozatt√≥l.

### Sz√≥- √©s kifejez√©sgyakoris√°gok

Egy nagy sz√∂vegtest elemz√©sekor hasznos lehet egy sz√≥t√°r l√©trehoz√°sa, amely tartalmazza az √∂sszes √©rdekes sz√≥t vagy kifejez√©st, valamint azok el≈ëfordul√°si gyakoris√°g√°t. A mondat `a gyors v√∂r√∂s r√≥ka √°tugrott a lusta barna kutya felett` sz√≥gyakoris√°ga p√©ld√°ul 2 a 'a' eset√©ben.

N√©zz√ºnk egy p√©ldasz√∂veget, ahol megsz√°moljuk a szavak gyakoris√°g√°t. Rudyard Kipling verse, A gy≈ëztesek, tartalmazza a k√∂vetkez≈ë versszakot:

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

Mivel a kifejez√©sgyakoris√°g lehet kis- √©s nagybet≈±√©rz√©keny, a `egy bar√°t` kifejez√©s gyakoris√°ga 2, a `a` gyakoris√°ga 6, √©s a `utazik` gyakoris√°ga 2.

### N-gramok

Egy sz√∂veg feloszthat√≥ meghat√°rozott hossz√∫s√°g√∫ sz√≥sorozatokra: egy sz√≥ (unigram), k√©t sz√≥ (bigram), h√°rom sz√≥ (trigram) vagy b√°rmilyen sz√°m√∫ sz√≥ (n-gram).

P√©ld√°ul `a gyors v√∂r√∂s r√≥ka √°tugrott a lusta barna kutya felett` egy 2-es n-gram √©rt√©kkel a k√∂vetkez≈ë n-gramokat eredm√©nyezi:

1. a gyors  
2. gyors v√∂r√∂s  
3. v√∂r√∂s r√≥ka  
4. r√≥ka ugrott  
5. ugrott √°t  
6. √°t a  
7. a lusta  
8. lusta barna  
9. barna kutya  

K√∂nnyebb lehet ezt egy cs√∫sz√≥ ablakk√©nt elk√©pzelni a mondat felett. √çme egy 3 szavas n-gram p√©ld√°ja, ahol az n-gram kiemelve l√°that√≥:

1.   <u>**a gyors v√∂r√∂s**</u> r√≥ka √°tugrott a lusta barna kutya felett  
2.   a **<u>gyors v√∂r√∂s r√≥ka</u>** √°tugrott a lusta barna kutya felett  
3.   a gyors **<u>v√∂r√∂s r√≥ka ugrott</u>** √°t a lusta barna kutya felett  
4.   a gyors v√∂r√∂s **<u>r√≥ka ugrott √°t</u>** a lusta barna kutya felett  
5.   a gyors v√∂r√∂s r√≥ka **<u>ugrott √°t a</u>** lusta barna kutya felett  
6.   a gyors v√∂r√∂s r√≥ka ugrott **<u>√°t a lusta</u>** barna kutya felett  
7.   a gyors v√∂r√∂s r√≥ka ugrott √°t <u>**a lusta barna**</u> kutya felett  
8.   a gyors v√∂r√∂s r√≥ka ugrott √°t a **<u>lusta barna kutya</u>**

![n-gramok cs√∫sz√≥ ablak](../../../../6-NLP/2-Tasks/images/n-grams.gif)

> N-gram √©rt√©k 3: Infografika: [Jen Looper](https://twitter.com/jenlooper)

### F≈ën√©vi kifejez√©sek kinyer√©se

A legt√∂bb mondatban van egy f≈ën√©v, amely a mondat alanya vagy t√°rgya. Angol nyelvben gyakran azonos√≠that√≥ az 'a', 'an' vagy 'the' el≈ëtag alapj√°n. A mondat alany√°nak vagy t√°rgy√°nak azonos√≠t√°sa a 'f≈ën√©vi kifejez√©s kinyer√©s√©vel' gyakori feladat az NLP-ben, amikor a mondat jelent√©s√©t pr√≥b√°ljuk meg√©rteni.

‚úÖ A mondatban "Nem tudom megmondani az √≥r√°t, a helyet, a kin√©zetet vagy a szavakat, amelyek megalapozt√°k. T√∫l r√©gen volt. M√°r benne voltam, miel≈ëtt tudtam volna, hogy elkezdtem." Fel tudod ismerni a f≈ën√©vi kifejez√©seket?

A mondatban `a gyors v√∂r√∂s r√≥ka √°tugrott a lusta barna kutya felett` 2 f≈ën√©vi kifejez√©s van: **gyors v√∂r√∂s r√≥ka** √©s **lusta barna kutya**.

### √ârzelemelemz√©s

Egy mondat vagy sz√∂veg elemezhet≈ë az √©rzelmek szempontj√°b√≥l, hogy mennyire *pozit√≠v* vagy *negat√≠v*. Az √©rzelmeket *polarit√°s* √©s *objektivit√°s/szubjektivit√°s* alapj√°n m√©rj√ºk. A polarit√°s -1.0-t√≥l 1.0-ig terjed (negat√≠vt√≥l pozit√≠vig), az objektivit√°s pedig 0.0-t√≥l 1.0-ig (legobjekt√≠vebbt≈ël legszubjekt√≠vebbig).

‚úÖ K√©s≈ëbb megtanulod, hogy k√ºl√∂nb√∂z≈ë m√≥dokon lehet meghat√°rozni az √©rzelmeket g√©pi tanul√°s seg√≠ts√©g√©vel, de az egyik m√≥dszer az, hogy egy emberi szak√©rt≈ë √°ltal pozit√≠vnak vagy negat√≠vnak kategoriz√°lt szavak √©s kifejez√©sek list√°j√°t alkalmazzuk a sz√∂vegre, hogy kisz√°m√≠tsuk a polarit√°si pontsz√°mot. L√°tod, hogyan m≈±k√∂dhet ez bizonyos helyzetekben, √©s kev√©sb√© j√≥l m√°sokban?

### Inflekci√≥

Az inflekci√≥ lehet≈ëv√© teszi, hogy egy sz√≥t √°talak√≠tsunk egyes vagy t√∂bbes sz√°m√∫ form√°j√°ba.

### Lemmatiz√°ci√≥

A *lemma* egy sz√≥ gy√∂kere vagy alapform√°ja, p√©ld√°ul *rep√ºlt*, *rep√ºl≈ëk*, *rep√ºl√©s* eset√©ben a lemma az *rep√ºl* ige.

Hasznos adatb√°zisok is rendelkez√©sre √°llnak az NLP kutat√≥k sz√°m√°ra, k√ºl√∂n√∂sen:

### WordNet

[WordNet](https://wordnet.princeton.edu/) egy adatb√°zis, amely szavakat, szinonim√°kat, ellent√©teket √©s sok m√°s r√©szletet tartalmaz k√ºl√∂nb√∂z≈ë nyelveken. Rendk√≠v√ºl hasznos ford√≠t√°sok, helyes√≠r√°s-ellen≈ërz≈ëk vagy b√°rmilyen nyelvi eszk√∂z l√©trehoz√°sakor.

## NLP k√∂nyvt√°rak

Szerencs√©re nem kell ezeket a technik√°kat magunknak fel√©p√≠teni, mivel kiv√°l√≥ Python k√∂nyvt√°rak √°llnak rendelkez√©sre, amelyek sokkal hozz√°f√©rhet≈ëbb√© teszik azokat a fejleszt≈ëk sz√°m√°ra, akik nem szakosodtak term√©szetes nyelvfeldolgoz√°sra vagy g√©pi tanul√°sra. A k√∂vetkez≈ë leck√©kben t√∂bb p√©ld√°t is bemutatunk ezekre, de itt n√©h√°ny hasznos p√©ld√°t tal√°lsz, amelyek seg√≠tenek a k√∂vetkez≈ë feladatban.

### Gyakorlat - `TextBlob` k√∂nyvt√°r haszn√°lata

Haszn√°ljunk egy TextBlob nev≈± k√∂nyvt√°rat, mivel hasznos API-kat tartalmaz az ilyen t√≠pus√∫ feladatok megold√°s√°hoz. A TextBlob "a [NLTK](https://nltk.org) √©s a [pattern](https://github.com/clips/pattern) √≥ri√°si v√°llain √°ll, √©s j√≥l m≈±k√∂dik mindkett≈ëvel." Jelent≈ës mennyis√©g≈± g√©pi tanul√°s van be√©p√≠tve az API-j√°ba.

> Megjegyz√©s: Egy hasznos [Gyors kezd√©s](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart) √∫tmutat√≥ el√©rhet≈ë a TextBlob sz√°m√°ra, amelyet tapasztalt Python fejleszt≈ëknek aj√°nlunk.

Amikor *f≈ën√©vi kifejez√©seket* pr√≥b√°lunk azonos√≠tani, a TextBlob t√∂bb lehet≈ës√©get k√≠n√°l az ilyen kifejez√©sek kinyer√©s√©re.

1. N√©zd meg a `ConllExtractor`-t.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > Mi t√∂rt√©nik itt? A [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) egy "f≈ën√©vi kifejez√©s kinyer≈ë, amely a ConLL-2000 tanul√°si korpusz alapj√°n k√©pzett chunk parsingot haszn√°l." A ConLL-2000 a 2000-es Sz√°m√≠t√≥g√©pes Term√©szetes Nyelv Tanul√°si Konferencia. Minden √©vben a konferencia egy workshopot tartott egy neh√©z NLP probl√©ma megold√°s√°ra, √©s 2000-ben ez a f≈ën√©vi chunking volt. Egy modellt k√©peztek a Wall Street Journal alapj√°n, "a 15-18. szakaszokat haszn√°lva tanul√°si adatk√©nt (211727 token) √©s a 20. szakaszt tesztadatk√©nt (47377 token)". Az alkalmazott elj√°r√°sokat [itt](https://www.clips.uantwerpen.be/conll2000/chunking/) √©s az [eredm√©nyeket](https://ifarm.nl/erikt/research/np-chunking.html) megtekintheted.

### Kih√≠v√°s - jav√≠tsd a botodat NLP seg√≠ts√©g√©vel

Az el≈ëz≈ë leck√©ben egy nagyon egyszer≈± k√©rd√©s-v√°lasz botot k√©sz√≠tett√©l. Most Marvin-t egy kicsit szimpatikusabb√° teszed az√°ltal, hogy elemzed a bemenetet √©rzelmek szempontj√°b√≥l, √©s ennek megfelel≈ë v√°laszt adsz. Emellett azonos√≠tanod kell egy `f≈ën√©vi kifejez√©st`, √©s k√©rdezned kell r√≥la.

A jobb besz√©lget≈ë bot l√©trehoz√°s√°nak l√©p√©sei:

1. Nyomtass utas√≠t√°sokat, amelyek tan√°csot adnak a felhaszn√°l√≥nak, hogyan l√©pjen kapcsolatba a bottal.
2. Ind√≠tsd el a ciklust:
   1. Fogadd el a felhaszn√°l√≥i bemenetet.
   2. Ha a felhaszn√°l√≥ kil√©p√©st k√©rt, l√©pj ki.
   3. Dolgozd fel a felhaszn√°l√≥i bemenetet, √©s hat√°rozd meg a megfelel≈ë √©rzelmi v√°laszt.
   4. Ha f≈ën√©vi kifejez√©st √©szlelsz az √©rzelemben, tedd t√∂bbes sz√°mba, √©s k√©rj tov√°bbi bemenetet a t√©m√°r√≥l.
   5. Nyomtass v√°laszt.
3. T√©rj vissza a 2. l√©p√©shez.

√çme a k√≥dr√©szlet az √©rzelem meghat√°roz√°s√°hoz a TextBlob seg√≠ts√©g√©vel. Figyeld meg, hogy csak n√©gy *√©rzelmi gradiens* van (ha szeretn√©d, lehet t√∂bb is):

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

√çme n√©h√°ny minta kimenet, amely seg√≠thet (a felhaszn√°l√≥i bemenet a > jellel kezd≈ëd≈ë sorokon tal√°lhat√≥):

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

Egy lehets√©ges megold√°s a feladatra [itt tal√°lhat√≥](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/2-Tasks/solution/bot.py)

‚úÖ Tud√°sellen≈ërz√©s

1. Szerinted a szimpatikus v√°laszok 'becsapn√°k' valakit, hogy azt higgye, a bot val√≥ban meg√©rti ≈ët?
2. A f≈ën√©vi kifejez√©s azonos√≠t√°sa hitelesebb√© teszi a botot?
3. Mi√©rt lehet hasznos egy mondatb√≥l f≈ën√©vi kifejez√©st kinyerni?

---

Val√≥s√≠tsd meg a botot az el≈ëz≈ë tud√°sellen≈ërz√©s alapj√°n, √©s teszteld egy bar√°todon. Siker√ºl becsapnia ≈ëket? Tudod hitelesebb√© tenni a botodat?

## üöÄKih√≠v√°s

V√°lassz egy feladatot az el≈ëz≈ë tud√°sellen≈ërz√©sb≈ël, √©s pr√≥b√°ld megval√≥s√≠tani. Teszteld a botot egy bar√°todon. Siker√ºl becsapnia ≈ëket? Tudod hitelesebb√© tenni a botodat?

## [El≈ëad√°s ut√°ni kv√≠z](https://ff-quizzes.netlify.app/en/ml/)

## √Åttekint√©s √©s √∂n√°ll√≥ tanul√°s

A k√∂vetkez≈ë n√©h√°ny leck√©ben t√∂bbet fogsz tanulni az √©rzelemelemz√©sr≈ël. Kutass err≈ël az √©rdekes technik√°r√≥l olyan cikkekben, mint p√©ld√°ul ezek a [KDNuggets](https://www.kdnuggets.com/tag/nlp) oldalon.

## Feladat 

[Bot k√©sz√≠t√©se, amely v√°laszol](assignment.md)

---

**Felel≈ëss√©g kiz√°r√°sa**:  
Ez a dokumentum az AI ford√≠t√°si szolg√°ltat√°s, a [Co-op Translator](https://github.com/Azure/co-op-translator) seg√≠ts√©g√©vel lett leford√≠tva. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelv√©n tekintend≈ë hiteles forr√°snak. Kritikus inform√°ci√≥k eset√©n javasolt professzion√°lis emberi ford√≠t√°st ig√©nybe venni. Nem v√°llalunk felel≈ëss√©get semmilyen f√©lre√©rt√©s√©rt vagy t√©ves √©rtelmez√©s√©rt, amely a ford√≠t√°s haszn√°lat√°b√≥l eredhet.