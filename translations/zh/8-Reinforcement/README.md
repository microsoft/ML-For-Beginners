<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20ca019012b1725de956681d036d8b18",
  "translation_date": "2025-09-03T18:26:49+00:00",
  "source_file": "8-Reinforcement/README.md",
  "language_code": "zh"
}
-->
# 强化学习简介

强化学习（RL）被认为是与监督学习和无监督学习并列的基本机器学习范式之一。RL的核心是决策：做出正确的决策，或者至少从决策中学习。

想象一下，你有一个模拟环境，比如股票市场。如果你实施某项规定，会发生什么？它会产生积极还是消极的影响？如果发生了消极的事情，你需要接受这种_负强化_，从中学习并调整方向。如果是积极的结果，你需要基于这种_正强化_继续发展。

![彼得与狼](../../../translated_images/peter.779730f9ba3a8a8d9290600dcf55f2e491c0640c785af7ac0d64f583c49b8864.zh.png)

> 彼得和他的朋友们需要逃离饥饿的狼！图片由 [Jen Looper](https://twitter.com/jenlooper) 提供

## 地区主题：彼得与狼（俄罗斯）

[彼得与狼](https://en.wikipedia.org/wiki/Peter_and_the_Wolf) 是由俄罗斯作曲家 [谢尔盖·普罗科菲耶夫](https://en.wikipedia.org/wiki/Sergei_Prokofiev) 创作的一部音乐童话。故事讲述了年轻的先锋彼得勇敢地走出家门，来到森林空地追逐狼。在本节中，我们将训练机器学习算法来帮助彼得：

- **探索**周围区域并构建最佳导航地图
- **学习**如何使用滑板并保持平衡，以便更快地移动

[![彼得与狼](https://img.youtube.com/vi/Fmi5zHg4QSM/0.jpg)](https://www.youtube.com/watch?v=Fmi5zHg4QSM)

> 🎥 点击上方图片收听普罗科菲耶夫的《彼得与狼》

## 强化学习

在之前的章节中，你已经看到两种机器学习问题的例子：

- **监督学习**，我们有数据集提供问题的样本解决方案。[分类](../4-Classification/README.md) 和 [回归](../2-Regression/README.md) 是监督学习任务。
- **无监督学习**，我们没有标注的训练数据。无监督学习的主要例子是 [聚类](../5-Clustering/README.md)。

在本节中，我们将向你介绍一种不需要标注训练数据的新型学习问题。这类问题有几种类型：

- **[半监督学习](https://wikipedia.org/wiki/Semi-supervised_learning)**，我们有大量未标注的数据，可以用来预训练模型。
- **[强化学习](https://wikipedia.org/wiki/Reinforcement_learning)**，代理通过在某些模拟环境中进行实验来学习如何行动。

### 示例 - 电脑游戏

假设你想教电脑玩游戏，比如国际象棋或 [超级马里奥](https://wikipedia.org/wiki/Super_Mario)。为了让电脑玩游戏，我们需要它预测在每个游戏状态下应该采取的行动。虽然这看起来像是一个分类问题，但实际上并不是——因为我们没有一个包含状态和对应动作的数据集。虽然我们可能有一些数据，比如现有的国际象棋比赛或玩家玩超级马里奥的录像，但这些数据可能不足以覆盖足够多的可能状态。

与其寻找现有的游戏数据，**强化学习**（RL）基于一个理念：*让电脑多次玩游戏并观察结果*。因此，要应用强化学习，我们需要两样东西：

- **一个环境**和**一个模拟器**，允许我们多次玩游戏。这个模拟器会定义所有的游戏规则以及可能的状态和动作。

- **一个奖励函数**，告诉我们每次行动或游戏过程中表现得如何。

强化学习与其他类型的机器学习的主要区别在于，在RL中我们通常不知道自己是否赢了或输了，直到游戏结束。因此，我们无法单独判断某个动作是否是好的——我们只有在游戏结束时才会收到奖励。而我们的目标是设计算法，使我们能够在不确定的条件下训练模型。我们将学习一种称为**Q学习**的RL算法。

## 课程

1. [强化学习和Q学习简介](1-QLearning/README.md)
2. [使用Gym模拟环境](2-Gym/README.md)

## 致谢

《强化学习简介》由 [Dmitry Soshnikov](http://soshnikov.com) 倾情创作 ❤️

---

**免责声明**：  
本文档使用AI翻译服务[Co-op Translator](https://github.com/Azure/co-op-translator)进行翻译。尽管我们努力确保翻译的准确性，但请注意，自动翻译可能包含错误或不准确之处。原始语言的文档应被视为权威来源。对于关键信息，建议使用专业人工翻译。我们不对因使用此翻译而产生的任何误解或误读承担责任。