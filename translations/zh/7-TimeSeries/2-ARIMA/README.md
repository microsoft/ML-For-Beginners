# ARIMA æ—¶é—´åºåˆ—é¢„æµ‹

åœ¨ä¸Šä¸€èŠ‚è¯¾ä¸­ï¼Œä½ äº†è§£äº†ä¸€äº›æ—¶é—´åºåˆ—é¢„æµ‹çš„åŸºç¡€çŸ¥è¯†ï¼Œå¹¶åŠ è½½äº†ä¸€ä¸ªæ˜¾ç¤ºæŸæ®µæ—¶é—´å†…ç”µåŠ›è´Ÿè½½æ³¢åŠ¨çš„æ•°æ®é›†ã€‚

[![ARIMA ç®€ä»‹](https://img.youtube.com/vi/IUSk-YDau10/0.jpg)](https://youtu.be/IUSk-YDau10 "Introduction to ARIMA")

> ğŸ¥ ç‚¹å‡»ä¸Šé¢çš„å›¾ç‰‡è§‚çœ‹è§†é¢‘ï¼šARIMA æ¨¡å‹çš„ç®€è¦ä»‹ç»ã€‚ç¤ºä¾‹ä½¿ç”¨ R è¯­è¨€ï¼Œä½†æ¦‚å¿µæ˜¯é€šç”¨çš„ã€‚

## [è¯¾å‰å°æµ‹éªŒ](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/43/)

## ç®€ä»‹

åœ¨æœ¬è¯¾ä¸­ï¼Œä½ å°†äº†è§£ä¸€ç§ç‰¹å®šçš„æ„å»ºæ¨¡å‹çš„æ–¹æ³•ï¼Œå³ [ARIMA: *A*uto*R*egressive *I*ntegrated *M*oving *A*verage](https://wikipedia.org/wiki/Autoregressive_integrated_moving_average)ã€‚ARIMA æ¨¡å‹ç‰¹åˆ«é€‚åˆæ‹Ÿåˆæ˜¾ç¤º [éå¹³ç¨³æ€§](https://wikipedia.org/wiki/Stationary_process)çš„æ•°æ®ã€‚

## åŸºæœ¬æ¦‚å¿µ

ä¸ºäº†èƒ½å¤Ÿä½¿ç”¨ ARIMAï¼Œæœ‰ä¸€äº›æ¦‚å¿µä½ éœ€è¦äº†è§£ï¼š

- ğŸ“ **å¹³ç¨³æ€§**ã€‚åœ¨ç»Ÿè®¡å­¦èƒŒæ™¯ä¸‹ï¼Œå¹³ç¨³æ€§æŒ‡çš„æ˜¯æ•°æ®çš„åˆ†å¸ƒåœ¨æ—¶é—´ä¸Šä¸å˜ã€‚éå¹³ç¨³æ•°æ®åˆ™ç”±äºè¶‹åŠ¿è€Œæ˜¾ç¤ºæ³¢åŠ¨ï¼Œå¿…é¡»é€šè¿‡è½¬æ¢æ¥è¿›è¡Œåˆ†æã€‚ä¾‹å¦‚ï¼Œå­£èŠ‚æ€§å¯ä»¥å¼•å…¥æ•°æ®æ³¢åŠ¨ï¼Œå¯ä»¥é€šè¿‡â€œå­£èŠ‚æ€§å·®åˆ†â€è¿‡ç¨‹æ¥æ¶ˆé™¤ã€‚

- ğŸ“ **[å·®åˆ†](https://wikipedia.org/wiki/Autoregressive_integrated_moving_average#Differencing)**ã€‚åœ¨ç»Ÿè®¡å­¦èƒŒæ™¯ä¸‹ï¼Œå·®åˆ†æŒ‡çš„æ˜¯é€šè¿‡ç§»é™¤éæ’å®šè¶‹åŠ¿å°†éå¹³ç¨³æ•°æ®è½¬æ¢ä¸ºå¹³ç¨³æ•°æ®çš„è¿‡ç¨‹ã€‚â€œå·®åˆ†ç§»é™¤äº†æ—¶é—´åºåˆ—ä¸­çš„æ°´å¹³å˜åŒ–ï¼Œæ¶ˆé™¤äº†è¶‹åŠ¿å’Œå­£èŠ‚æ€§ï¼Œä»è€Œç¨³å®šäº†æ—¶é—´åºåˆ—çš„å‡å€¼ã€‚â€ [Shixiong ç­‰äººçš„è®ºæ–‡](https://arxiv.org/abs/1904.07632)

## ARIMA åœ¨æ—¶é—´åºåˆ—ä¸­çš„åº”ç”¨

è®©æˆ‘ä»¬æ‹†è§£ ARIMA çš„å„ä¸ªéƒ¨åˆ†ï¼Œä»¥ä¾¿æ›´å¥½åœ°ç†è§£å®ƒå¦‚ä½•å¸®åŠ©æˆ‘ä»¬å»ºæ¨¡æ—¶é—´åºåˆ—å¹¶è¿›è¡Œé¢„æµ‹ã€‚

- **AR - è‡ªå›å½’**ã€‚è‡ªå›å½’æ¨¡å‹ï¼Œé¡¾åæ€ä¹‰ï¼Œæ˜¯å‘â€œåâ€çœ‹ï¼Œåˆ†ææ•°æ®ä¸­çš„å…ˆå‰å€¼å¹¶å¯¹å…¶è¿›è¡Œå‡è®¾ã€‚è¿™äº›å…ˆå‰å€¼è¢«ç§°ä¸ºâ€œæ»åâ€ã€‚ä¾‹å¦‚ï¼Œæ˜¾ç¤ºæ¯æœˆé“…ç¬”é”€å”®æ•°æ®çš„æ•°æ®é›†ã€‚æ¯ä¸ªæœˆçš„é”€å”®æ€»é¢å°†è¢«è§†ä¸ºæ•°æ®é›†ä¸­çš„â€œæ¼”å˜å˜é‡â€ã€‚è¯¥æ¨¡å‹æ˜¯â€œå¯¹å…¶è‡ªèº«æ»åï¼ˆå³å…ˆå‰ï¼‰å€¼è¿›è¡Œå›å½’â€ã€‚[wikipedia](https://wikipedia.org/wiki/Autoregressive_integrated_moving_average)

- **I - ç§¯åˆ†**ã€‚ä¸ç±»ä¼¼çš„â€œARMAâ€æ¨¡å‹ä¸åŒï¼ŒARIMA ä¸­çš„â€œIâ€æŒ‡çš„æ˜¯å…¶ *[ç§¯åˆ†](https://wikipedia.org/wiki/Order_of_integration)* æ–¹é¢ã€‚é€šè¿‡åº”ç”¨å·®åˆ†æ­¥éª¤æ¥æ¶ˆé™¤éå¹³ç¨³æ€§ï¼Œæ•°æ®è¢«â€œç§¯åˆ†â€ã€‚

- **MA - ç§»åŠ¨å¹³å‡**ã€‚è¯¥æ¨¡å‹çš„ [ç§»åŠ¨å¹³å‡](https://wikipedia.org/wiki/Moving-average_model) æ–¹é¢æŒ‡çš„æ˜¯é€šè¿‡è§‚å¯Ÿå½“å‰å’Œè¿‡å»çš„æ»åå€¼æ¥ç¡®å®šè¾“å‡ºå˜é‡ã€‚

æ€»è€Œè¨€ä¹‹ï¼šARIMA è¢«ç”¨æ¥ä½¿æ¨¡å‹å°½å¯èƒ½ç´§å¯†åœ°æ‹Ÿåˆæ—¶é—´åºåˆ—æ•°æ®çš„ç‰¹æ®Šå½¢å¼ã€‚

## ç»ƒä¹  - æ„å»º ARIMA æ¨¡å‹

æ‰“å¼€æœ¬è¯¾ä¸­çš„ [_/working_](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA/working) æ–‡ä»¶å¤¹ï¼Œå¹¶æ‰¾åˆ° [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/7-TimeSeries/2-ARIMA/working/notebook.ipynb) æ–‡ä»¶ã€‚

1. è¿è¡Œ notebook ä»¥åŠ è½½ `statsmodels` Python åº“ï¼›ä½ å°†éœ€è¦å®ƒæ¥æ„å»º ARIMA æ¨¡å‹ã€‚

1. åŠ è½½å¿…è¦çš„åº“

1. ç°åœ¨ï¼ŒåŠ è½½ä¸€äº›å¯¹ç»˜å›¾æœ‰ç”¨çš„åº“ï¼š

    ```python
    import os
    import warnings
    import matplotlib.pyplot as plt
    import numpy as np
    import pandas as pd
    import datetime as dt
    import math

    from pandas.plotting import autocorrelation_plot
    from statsmodels.tsa.statespace.sarimax import SARIMAX
    from sklearn.preprocessing import MinMaxScaler
    from common.utils import load_data, mape
    from IPython.display import Image

    %matplotlib inline
    pd.options.display.float_format = '{:,.2f}'.format
    np.set_printoptions(precision=2)
    warnings.filterwarnings("ignore") # specify to ignore warning messages
    ```

1. å°† `/data/energy.csv` æ–‡ä»¶ä¸­çš„æ•°æ®åŠ è½½åˆ° Pandas æ•°æ®æ¡†ä¸­å¹¶æŸ¥çœ‹ï¼š

    ```python
    energy = load_data('./data')[['load']]
    energy.head(10)
    ```

1. ç»˜åˆ¶ 2012 å¹´ 1 æœˆè‡³ 2014 å¹´ 12 æœˆçš„æ‰€æœ‰å¯ç”¨èƒ½æºæ•°æ®ã€‚åº”è¯¥æ²¡æœ‰æ„å¤–ï¼Œå› ä¸ºæˆ‘ä»¬åœ¨ä¸Šä¸€èŠ‚è¯¾ä¸­çœ‹åˆ°äº†è¿™äº›æ•°æ®ï¼š

    ```python
    energy.plot(y='load', subplots=True, figsize=(15, 8), fontsize=12)
    plt.xlabel('timestamp', fontsize=12)
    plt.ylabel('load', fontsize=12)
    plt.show()
    ```

    ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ„å»ºä¸€ä¸ªæ¨¡å‹ï¼

### åˆ›å»ºè®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†

ç°åœ¨ä½ çš„æ•°æ®å·²ç»åŠ è½½ï¼Œå¯ä»¥å°†å…¶åˆ†æˆè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚ä½ å°†ç”¨è®­ç»ƒé›†æ¥è®­ç»ƒä½ çš„æ¨¡å‹ã€‚åƒå¾€å¸¸ä¸€æ ·ï¼Œæ¨¡å‹è®­ç»ƒå®Œæˆåï¼Œä½ å°†ä½¿ç”¨æµ‹è¯•é›†è¯„ä¼°å…¶å‡†ç¡®æ€§ã€‚ä½ éœ€è¦ç¡®ä¿æµ‹è¯•é›†è¦†ç›–æ¯”è®­ç»ƒé›†æ™šçš„æ—¶é—´æ®µï¼Œä»¥ç¡®ä¿æ¨¡å‹ä¸ä¼šä»æœªæ¥æ—¶é—´æ®µè·å–ä¿¡æ¯ã€‚

1. å°† 2014 å¹´ 9 æœˆ 1 æ—¥è‡³ 10 æœˆ 31 æ—¥çš„ä¸¤ä¸ªæœˆåˆ†é…ç»™è®­ç»ƒé›†ã€‚æµ‹è¯•é›†å°†åŒ…æ‹¬ 2014 å¹´ 11 æœˆ 1 æ—¥è‡³ 12 æœˆ 31 æ—¥çš„ä¸¤ä¸ªæœˆï¼š

    ```python
    train_start_dt = '2014-11-01 00:00:00'
    test_start_dt = '2014-12-30 00:00:00'
    ```

    ç”±äºè¿™äº›æ•°æ®åæ˜ äº†æ¯æ—¥èƒ½æºæ¶ˆè€—ï¼Œå­˜åœ¨æ˜æ˜¾çš„å­£èŠ‚æ€§æ¨¡å¼ï¼Œä½†æœ€è¿‘å‡ å¤©çš„æ¶ˆè€—æœ€ä¸ºç›¸ä¼¼ã€‚

1. å¯è§†åŒ–å·®å¼‚ï¼š

    ```python
    energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)][['load']].rename(columns={'load':'train'}) \
        .join(energy[test_start_dt:][['load']].rename(columns={'load':'test'}), how='outer') \
        .plot(y=['train', 'test'], figsize=(15, 8), fontsize=12)
    plt.xlabel('timestamp', fontsize=12)
    plt.ylabel('load', fontsize=12)
    plt.show()
    ```

    ![è®­ç»ƒå’Œæµ‹è¯•æ•°æ®](../../../../translated_images/train-test.8928d14e5b91fc942f0ca9201b2d36c890ea7e98f7619fd94f75de3a4c2bacb9.zh.png)

    å› æ­¤ï¼Œä½¿ç”¨ç›¸å¯¹è¾ƒå°çš„æ—¶é—´çª—å£æ¥è®­ç»ƒæ•°æ®åº”è¯¥æ˜¯è¶³å¤Ÿçš„ã€‚

    > æ³¨æ„ï¼šç”±äºæˆ‘ä»¬ç”¨æ¥æ‹Ÿåˆ ARIMA æ¨¡å‹çš„å‡½æ•°åœ¨æ‹Ÿåˆè¿‡ç¨‹ä¸­ä½¿ç”¨äº†æ ·æœ¬å†…éªŒè¯ï¼Œæˆ‘ä»¬å°†çœç•¥éªŒè¯æ•°æ®ã€‚

### å‡†å¤‡æ•°æ®è¿›è¡Œè®­ç»ƒ

ç°åœ¨ï¼Œä½ éœ€è¦é€šè¿‡å¯¹æ•°æ®è¿›è¡Œè¿‡æ»¤å’Œç¼©æ”¾æ¥å‡†å¤‡è®­ç»ƒæ•°æ®ã€‚è¿‡æ»¤æ•°æ®é›†ä»¥ä»…åŒ…æ‹¬æ‰€éœ€çš„æ—¶é—´æ®µå’Œåˆ—ï¼Œå¹¶ç¼©æ”¾ä»¥ç¡®ä¿æ•°æ®åœ¨ 0 åˆ° 1 ä¹‹é—´ã€‚

1. è¿‡æ»¤åŸå§‹æ•°æ®é›†ä»¥ä»…åŒ…æ‹¬ä¸Šè¿°æ—¶é—´æ®µå’Œæ‰€éœ€çš„â€œloadâ€åˆ—åŠæ—¥æœŸï¼š

    ```python
    train = energy.copy()[(energy.index >= train_start_dt) & (energy.index < test_start_dt)][['load']]
    test = energy.copy()[energy.index >= test_start_dt][['load']]

    print('Training data shape: ', train.shape)
    print('Test data shape: ', test.shape)
    ```

    ä½ å¯ä»¥çœ‹åˆ°æ•°æ®çš„å½¢çŠ¶ï¼š

    ```output
    Training data shape:  (1416, 1)
    Test data shape:  (48, 1)
    ```

1. å°†æ•°æ®ç¼©æ”¾åˆ° 0 åˆ° 1 çš„èŒƒå›´å†…ã€‚

    ```python
    scaler = MinMaxScaler()
    train['load'] = scaler.fit_transform(train)
    train.head(10)
    ```

1. å¯è§†åŒ–åŸå§‹æ•°æ®ä¸ç¼©æ”¾åçš„æ•°æ®ï¼š

    ```python
    energy[(energy.index >= train_start_dt) & (energy.index < test_start_dt)][['load']].rename(columns={'load':'original load'}).plot.hist(bins=100, fontsize=12)
    train.rename(columns={'load':'scaled load'}).plot.hist(bins=100, fontsize=12)
    plt.show()
    ```

    ![åŸå§‹æ•°æ®](../../../../translated_images/original.b2b15efe0ce92b8745918f071dceec2231661bf49c8db6918e3ff4b3b0b183c2.zh.png)

    > åŸå§‹æ•°æ®

    ![ç¼©æ”¾åçš„æ•°æ®](../../../../translated_images/scaled.e35258ca5cd3d43f86d5175e584ba96b38d51501f234abf52e11f4fe2631e45f.zh.png)

    > ç¼©æ”¾åçš„æ•°æ®

1. ç°åœ¨ä½ å·²ç»æ ¡å‡†äº†ç¼©æ”¾åçš„æ•°æ®ï¼Œå¯ä»¥ç¼©æ”¾æµ‹è¯•æ•°æ®ï¼š

    ```python
    test['load'] = scaler.transform(test)
    test.head()
    ```

### å®ç° ARIMA

ç°åœ¨æ˜¯æ—¶å€™å®ç° ARIMA äº†ï¼ä½ å°†ä½¿ç”¨ä¹‹å‰å®‰è£…çš„ `statsmodels` åº“ã€‚

ç°åœ¨ä½ éœ€è¦æŒ‰ç…§å‡ ä¸ªæ­¥éª¤è¿›è¡Œ

   1. é€šè¿‡è°ƒç”¨ `SARIMAX()` and passing in the model parameters: p, d, and q parameters, and P, D, and Q parameters.
   2. Prepare the model for the training data by calling the fit() function.
   3. Make predictions calling the `forecast()` function and specifying the number of steps (the `horizon`) to forecast.

> ğŸ“ What are all these parameters for? In an ARIMA model there are 3 parameters that are used to help model the major aspects of a time series: seasonality, trend, and noise. These parameters are:

`p`: the parameter associated with the auto-regressive aspect of the model, which incorporates *past* values.
`d`: the parameter associated with the integrated part of the model, which affects the amount of *differencing* (ğŸ“ remember differencing ğŸ‘†?) to apply to a time series.
`q`: the parameter associated with the moving-average part of the model.

> Note: If your data has a seasonal aspect - which this one does - , we use a seasonal ARIMA model (SARIMA). In that case you need to use another set of parameters: `P`, `D`, and `Q` which describe the same associations as `p`, `d`, and `q` æ¥å®šä¹‰æ¨¡å‹ï¼Œä½†å¯¹åº”äºæ¨¡å‹çš„å­£èŠ‚æ€§ç»„ä»¶ã€‚

1. é¦–å…ˆè®¾ç½®ä½ é¦–é€‰çš„ horizon å€¼ã€‚è®©æˆ‘ä»¬å°è¯• 3 å°æ—¶ï¼š

    ```python
    # Specify the number of steps to forecast ahead
    HORIZON = 3
    print('Forecasting horizon:', HORIZON, 'hours')
    ```

    ä¸º ARIMA æ¨¡å‹é€‰æ‹©æœ€ä½³å‚æ•°å€¼å¯èƒ½å…·æœ‰æŒ‘æˆ˜æ€§ï¼Œå› ä¸ºå®ƒåœ¨æŸç§ç¨‹åº¦ä¸Šæ˜¯ä¸»è§‚ä¸”è€—æ—¶çš„ã€‚ä½ å¯ä»¥è€ƒè™‘ä½¿ç”¨ `auto_arima()` function from the [`pyramid` åº“](https://alkaline-ml.com/pmdarima/0.9.0/modules/generated/pyramid.arima.auto_arima.html)ï¼Œ

1. ç°åœ¨å°è¯•ä¸€äº›æ‰‹åŠ¨é€‰æ‹©ä»¥æ‰¾åˆ°ä¸€ä¸ªå¥½çš„æ¨¡å‹ã€‚

    ```python
    order = (4, 1, 0)
    seasonal_order = (1, 1, 0, 24)

    model = SARIMAX(endog=train, order=order, seasonal_order=seasonal_order)
    results = model.fit()

    print(results.summary())
    ```

    æ‰“å°å‡ºç»“æœè¡¨æ ¼ã€‚

ä½ å·²ç»æ„å»ºäº†ä½ çš„ç¬¬ä¸€ä¸ªæ¨¡å‹ï¼ç°åœ¨æˆ‘ä»¬éœ€è¦æ‰¾åˆ°ä¸€ç§æ–¹æ³•æ¥è¯„ä¼°å®ƒã€‚

### è¯„ä¼°ä½ çš„æ¨¡å‹

ä¸ºäº†è¯„ä¼°ä½ çš„æ¨¡å‹ï¼Œä½ å¯ä»¥è¿›è¡Œæ‰€è°“çš„ `walk forward` éªŒè¯ã€‚å®é™…ä¸Šï¼Œæ—¶é—´åºåˆ—æ¨¡å‹åœ¨æ¯æ¬¡æ–°æ•°æ®å¯ç”¨æ—¶éƒ½ä¼šé‡æ–°è®­ç»ƒã€‚è¿™å…è®¸æ¨¡å‹åœ¨æ¯ä¸ªæ—¶é—´æ­¥é•¿ä¸Šåšå‡ºæœ€ä½³é¢„æµ‹ã€‚

ä½¿ç”¨è¿™ç§æŠ€æœ¯ä»æ—¶é—´åºåˆ—çš„å¼€å¤´å¼€å§‹ï¼Œåœ¨è®­ç»ƒæ•°æ®é›†ä¸Šè®­ç»ƒæ¨¡å‹ã€‚ç„¶åå¯¹ä¸‹ä¸€ä¸ªæ—¶é—´æ­¥é•¿è¿›è¡Œé¢„æµ‹ã€‚é¢„æµ‹ç»“æœä¸å·²çŸ¥å€¼è¿›è¡Œè¯„ä¼°ã€‚ç„¶åæ‰©å±•è®­ç»ƒé›†ä»¥åŒ…æ‹¬å·²çŸ¥å€¼ï¼Œå¹¶é‡å¤è¯¥è¿‡ç¨‹ã€‚

> æ³¨æ„ï¼šä½ åº”è¯¥ä¿æŒè®­ç»ƒé›†çª—å£å›ºå®šï¼Œä»¥ä¾¿æ¯æ¬¡å°†æ–°è§‚å¯Ÿå€¼æ·»åŠ åˆ°è®­ç»ƒé›†ä¸­æ—¶ï¼Œéƒ½ä»é›†å¼€å§‹ç§»é™¤è§‚å¯Ÿå€¼ã€‚

æ­¤è¿‡ç¨‹æä¾›äº†æ¨¡å‹åœ¨å®é™…åº”ç”¨ä¸­çš„æ›´ç¨³å¥ä¼°è®¡ã€‚ç„¶è€Œï¼Œåˆ›å»ºå¦‚æ­¤å¤šçš„æ¨¡å‹ä¼šå¸¦æ¥è®¡ç®—æˆæœ¬ã€‚å¦‚æœæ•°æ®é‡å°æˆ–æ¨¡å‹ç®€å•ï¼Œè¿™æ˜¯å¯ä»¥æ¥å—çš„ï¼Œä½†åœ¨å¤§è§„æ¨¡åº”ç”¨ä¸­å¯èƒ½ä¼šæˆä¸ºé—®é¢˜ã€‚

æ­¥è¿›éªŒè¯æ˜¯æ—¶é—´åºåˆ—æ¨¡å‹è¯„ä¼°çš„é»„é‡‘æ ‡å‡†ï¼Œæ¨èç”¨äºä½ è‡ªå·±çš„é¡¹ç›®ã€‚

1. é¦–å…ˆï¼Œä¸ºæ¯ä¸ª HORIZON æ­¥é•¿åˆ›å»ºä¸€ä¸ªæµ‹è¯•æ•°æ®ç‚¹ã€‚

    ```python
    test_shifted = test.copy()

    for t in range(1, HORIZON+1):
        test_shifted['load+'+str(t)] = test_shifted['load'].shift(-t, freq='H')

    test_shifted = test_shifted.dropna(how='any')
    test_shifted.head(5)
    ```

    |            |          | load | load+1 | load+2 |
    | ---------- | -------- | ---- | ------ | ------ |
    | 2014-12-30 | 00:00:00 | 0.33 | 0.29   | 0.27   |
    | 2014-12-30 | 01:00:00 | 0.29 | 0.27   | 0.27   |
    | 2014-12-30 | 02:00:00 | 0.27 | 0.27   | 0.30   |
    | 2014-12-30 | 03:00:00 | 0.27 | 0.30   | 0.41   |
    | 2014-12-30 | 04:00:00 | 0.30 | 0.41   | 0.57   |

    æ•°æ®æ ¹æ®å…¶ horizon ç‚¹æ°´å¹³ç§»åŠ¨ã€‚

1. ä½¿ç”¨è¿™ç§æ»‘åŠ¨çª—å£æ–¹æ³•å¯¹æµ‹è¯•æ•°æ®è¿›è¡Œé¢„æµ‹ï¼Œå¾ªç¯å¤§å°ä¸ºæµ‹è¯•æ•°æ®é•¿åº¦ï¼š

    ```python
    %%time
    training_window = 720 # dedicate 30 days (720 hours) for training

    train_ts = train['load']
    test_ts = test_shifted

    history = [x for x in train_ts]
    history = history[(-training_window):]

    predictions = list()

    order = (2, 1, 0)
    seasonal_order = (1, 1, 0, 24)

    for t in range(test_ts.shape[0]):
        model = SARIMAX(endog=history, order=order, seasonal_order=seasonal_order)
        model_fit = model.fit()
        yhat = model_fit.forecast(steps = HORIZON)
        predictions.append(yhat)
        obs = list(test_ts.iloc[t])
        # move the training window
        history.append(obs[0])
        history.pop(0)
        print(test_ts.index[t])
        print(t+1, ': predicted =', yhat, 'expected =', obs)
    ```

    ä½ å¯ä»¥è§‚çœ‹è®­ç»ƒè¿‡ç¨‹ï¼š

    ```output
    2014-12-30 00:00:00
    1 : predicted = [0.32 0.29 0.28] expected = [0.32945389435989236, 0.2900626678603402, 0.2739480752014323]

    2014-12-30 01:00:00
    2 : predicted = [0.3  0.29 0.3 ] expected = [0.2900626678603402, 0.2739480752014323, 0.26812891674127126]

    2014-12-30 02:00:00
    3 : predicted = [0.27 0.28 0.32] expected = [0.2739480752014323, 0.26812891674127126, 0.3025962399283795]
    ```

1. æ¯”è¾ƒé¢„æµ‹å€¼å’Œå®é™…è´Ÿè½½ï¼š

    ```python
    eval_df = pd.DataFrame(predictions, columns=['t+'+str(t) for t in range(1, HORIZON+1)])
    eval_df['timestamp'] = test.index[0:len(test.index)-HORIZON+1]
    eval_df = pd.melt(eval_df, id_vars='timestamp', value_name='prediction', var_name='h')
    eval_df['actual'] = np.array(np.transpose(test_ts)).ravel()
    eval_df[['prediction', 'actual']] = scaler.inverse_transform(eval_df[['prediction', 'actual']])
    eval_df.head()
    ```

    è¾“å‡º
    |     |            | timestamp | h   | prediction | actual   |
    | --- | ---------- | --------- | --- | ---------- | -------- |
    | 0   | 2014-12-30 | 00:00:00  | t+1 | 3,008.74   | 3,023.00 |
    | 1   | 2014-12-30 | 01:00:00  | t+1 | 2,955.53   | 2,935.00 |
    | 2   | 2014-12-30 | 02:00:00  | t+1 | 2,900.17   | 2,899.00 |
    | 3   | 2014-12-30 | 03:00:00  | t+1 | 2,917.69   | 2,886.00 |
    | 4   | 2014-12-30 | 04:00:00  | t+1 | 2,946.99   | 2,963.00 |

    è§‚å¯Ÿæ¯å°æ—¶æ•°æ®çš„é¢„æµ‹å€¼ä¸å®é™…è´Ÿè½½ã€‚å‡†ç¡®æ€§å¦‚ä½•ï¼Ÿ

### æ£€æŸ¥æ¨¡å‹å‡†ç¡®æ€§

é€šè¿‡æµ‹è¯•æ‰€æœ‰é¢„æµ‹çš„å¹³å‡ç»å¯¹ç™¾åˆ†æ¯”è¯¯å·®ï¼ˆMAPEï¼‰æ¥æ£€æŸ¥æ¨¡å‹çš„å‡†ç¡®æ€§ã€‚

> **ğŸ§® å±•ç¤ºæ•°å­¦å…¬å¼**
>
> ![MAPE](../../../../translated_images/mape.fd87bbaf4d346846df6af88b26bf6f0926bf9a5027816d5e23e1200866e3e8a4.zh.png)
>
>  [MAPE](https://www.linkedin.com/pulse/what-mape-mad-msd-time-series-allameh-statistics/) ç”¨äºæ˜¾ç¤ºé¢„æµ‹å‡†ç¡®æ€§ï¼Œå®šä¹‰å¦‚ä¸Šå…¬å¼ã€‚å®é™…å€¼<sub>t</sub>å’Œé¢„æµ‹å€¼<sub>t</sub>ä¹‹å·®é™¤ä»¥å®é™…å€¼<sub>t</sub>ã€‚â€œåœ¨æ­¤è®¡ç®—ä¸­ï¼Œæ¯ä¸ªé¢„æµ‹ç‚¹çš„ç»å¯¹å€¼ä¹‹å’Œé™¤ä»¥æ‹Ÿåˆç‚¹æ•° nã€‚â€ [wikipedia](https://wikipedia.org/wiki/Mean_absolute_percentage_error)

1. ç”¨ä»£ç è¡¨è¾¾å…¬å¼ï¼š

    ```python
    if(HORIZON > 1):
        eval_df['APE'] = (eval_df['prediction'] - eval_df['actual']).abs() / eval_df['actual']
        print(eval_df.groupby('h')['APE'].mean())
    ```

1. è®¡ç®—ä¸€æ­¥çš„ MAPEï¼š

    ```python
    print('One step forecast MAPE: ', (mape(eval_df[eval_df['h'] == 't+1']['prediction'], eval_df[eval_df['h'] == 't+1']['actual']))*100, '%')
    ```

    ä¸€æ­¥é¢„æµ‹ MAPEï¼š 0.5570581332313952 %

1. æ‰“å°å¤šæ­¥é¢„æµ‹ MAPEï¼š

    ```python
    print('Multi-step forecast MAPE: ', mape(eval_df['prediction'], eval_df['actual'])*100, '%')
    ```

    ```output
    Multi-step forecast MAPE:  1.1460048657704118 %
    ```

    ä¸€ä¸ªè¾ƒä½çš„æ•°å€¼æ˜¯æœ€å¥½çš„ï¼šè€ƒè™‘åˆ°ä¸€ä¸ªé¢„æµ‹ MAPE ä¸º 10 çš„æ¨¡å‹ï¼Œè¯¯å·®ä¸º 10%ã€‚

1. ä½†æ­£å¦‚å¾€å¸¸ï¼Œè§†è§‰åŒ–è¿™ç§å‡†ç¡®æ€§æµ‹é‡æ›´å®¹æ˜“ï¼Œæ‰€ä»¥è®©æˆ‘ä»¬ç»˜åˆ¶å®ƒï¼š

    ```python
     if(HORIZON == 1):
        ## Plotting single step forecast
        eval_df.plot(x='timestamp', y=['actual', 'prediction'], style=['r', 'b'], figsize=(15, 8))

    else:
        ## Plotting multi step forecast
        plot_df = eval_df[(eval_df.h=='t+1')][['timestamp', 'actual']]
        for t in range(1, HORIZON+1):
            plot_df['t+'+str(t)] = eval_df[(eval_df.h=='t+'+str(t))]['prediction'].values

        fig = plt.figure(figsize=(15, 8))
        ax = plt.plot(plot_df['timestamp'], plot_df['actual'], color='red', linewidth=4.0)
        ax = fig.add_subplot(111)
        for t in range(1, HORIZON+1):
            x = plot_df['timestamp'][(t-1):]
            y = plot_df['t+'+str(t)][0:len(x)]
            ax.plot(x, y, color='blue', linewidth=4*math.pow(.9,t), alpha=math.pow(0.8,t))

        ax.legend(loc='best')

    plt.xlabel('timestamp', fontsize=12)
    plt.ylabel('load', fontsize=12)
    plt.show()
    ```

    ![ä¸€ä¸ªæ—¶é—´åºåˆ—æ¨¡å‹](../../../../translated_images/accuracy.2c47fe1bf15f44b3656651c84d5e2ba9b37cd929cd2aa8ab6cc3073f50570f4e.zh.png)

ğŸ† ä¸€ä¸ªéå¸¸æ¼‚äº®çš„å›¾è¡¨ï¼Œæ˜¾ç¤ºäº†ä¸€ä¸ªå‡†ç¡®æ€§è‰¯å¥½çš„æ¨¡å‹ã€‚åšå¾—å¥½ï¼

---

## ğŸš€æŒ‘æˆ˜

æ·±å…¥ç ”ç©¶æµ‹è¯•æ—¶é—´åºåˆ—æ¨¡å‹å‡†ç¡®æ€§çš„æ–¹æ³•ã€‚åœ¨æœ¬è¯¾ä¸­æˆ‘ä»¬è®¨è®ºäº† MAPEï¼Œä½†è¿˜æœ‰å…¶ä»–æ–¹æ³•å¯ä»¥ä½¿ç”¨å—ï¼Ÿç ”ç©¶å®ƒä»¬å¹¶æ³¨é‡Šã€‚ä¸€ä»½æœ‰ç”¨çš„æ–‡æ¡£å¯ä»¥åœ¨ [è¿™é‡Œ](https://otexts.com/fpp2/accuracy.html) æ‰¾åˆ°ã€‚

## [è¯¾åå°æµ‹éªŒ](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/44/)

## å¤ä¹ ä¸è‡ªå­¦

æœ¬è¯¾ä»…è§¦åŠäº†ä½¿ç”¨ ARIMA è¿›è¡Œæ—¶é—´åºåˆ—é¢„æµ‹çš„åŸºç¡€çŸ¥è¯†ã€‚èŠ±äº›æ—¶é—´é€šè¿‡æ·±å…¥ç ”ç©¶ [è¿™ä¸ªä»“åº“](https://microsoft.github.io/forecasting/) åŠå…¶å„ç§æ¨¡å‹ç±»å‹æ¥åŠ æ·±ä½ çš„çŸ¥è¯†ï¼Œå­¦ä¹ å…¶ä»–æ„å»ºæ—¶é—´åºåˆ—æ¨¡å‹çš„æ–¹æ³•ã€‚

## ä½œä¸š

[ä¸€ä¸ªæ–°çš„ ARIMA æ¨¡å‹](assignment.md)

**å…è´£å£°æ˜**ï¼š
æœ¬æ–‡ä»¶ä½¿ç”¨åŸºäºæœºå™¨çš„äººå·¥æ™ºèƒ½ç¿»è¯‘æœåŠ¡è¿›è¡Œç¿»è¯‘ã€‚å°½ç®¡æˆ‘ä»¬åŠªåŠ›ç¡®ä¿å‡†ç¡®æ€§ï¼Œä½†è¯·æ³¨æ„ï¼Œè‡ªåŠ¨ç¿»è¯‘å¯èƒ½åŒ…å«é”™è¯¯æˆ–ä¸å‡†ç¡®ä¹‹å¤„ã€‚åº”ä»¥åŸæ–‡æ¡£çš„æ¯è¯­ç‰ˆæœ¬ä¸ºæƒå¨æ¥æºã€‚å¯¹äºå…³é”®ä¿¡æ¯ï¼Œå»ºè®®å¯»æ±‚ä¸“ä¸šäººå·¥ç¿»è¯‘ã€‚å¯¹äºå› ä½¿ç”¨æœ¬ç¿»è¯‘è€Œå¼•èµ·çš„ä»»ä½•è¯¯è§£æˆ–è¯¯è¯»ï¼Œæˆ‘ä»¬ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚