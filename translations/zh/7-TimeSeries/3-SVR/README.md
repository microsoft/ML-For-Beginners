# ä½¿ç”¨æ”¯æŒå‘é‡å›å½’è¿›è¡Œæ—¶é—´åºåˆ—é¢„æµ‹

åœ¨ä¸Šä¸€è¯¾ä¸­ï¼Œä½ å­¦ä¹ äº†å¦‚ä½•ä½¿ç”¨ARIMAæ¨¡å‹è¿›è¡Œæ—¶é—´åºåˆ—é¢„æµ‹ã€‚ç°åœ¨ä½ å°†å­¦ä¹ ä½¿ç”¨æ”¯æŒå‘é‡å›å½’æ¨¡å‹ï¼Œè¿™æ˜¯ä¸€ç§ç”¨äºé¢„æµ‹è¿ç»­æ•°æ®çš„å›å½’æ¨¡å‹ã€‚

## [è¯¾å‰æµ‹éªŒ](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/51/)

## ä»‹ç»

åœ¨æœ¬è¯¾ä¸­ï¼Œä½ å°†äº†è§£å¦‚ä½•ä½¿ç”¨[**SVM**: **æ”¯æŒå‘é‡æœº**](https://en.wikipedia.org/wiki/Support-vector_machine)è¿›è¡Œå›å½’ï¼Œæˆ–**SVR: æ”¯æŒå‘é‡å›å½’**ã€‚

### æ—¶é—´åºåˆ—èƒŒæ™¯ä¸‹çš„SVR [^1]

åœ¨ç†è§£SVRåœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„é‡è¦æ€§ä¹‹å‰ï¼Œè¿™é‡Œæœ‰ä¸€äº›ä½ éœ€è¦äº†è§£çš„é‡è¦æ¦‚å¿µï¼š

- **å›å½’:** ä¸€ç§ç›‘ç£å­¦ä¹ æŠ€æœ¯ï¼Œç”¨äºä»ç»™å®šçš„è¾“å…¥é›†é¢„æµ‹è¿ç»­å€¼ã€‚å…¶æ€æƒ³æ˜¯åœ¨ç‰¹å¾ç©ºé—´ä¸­æ‹Ÿåˆä¸€æ¡åŒ…å«æœ€å¤šæ•°æ®ç‚¹çš„æ›²çº¿ï¼ˆæˆ–ç›´çº¿ï¼‰ã€‚[ç‚¹å‡»è¿™é‡Œ](https://en.wikipedia.org/wiki/Regression_analysis)äº†è§£æ›´å¤šä¿¡æ¯ã€‚
- **æ”¯æŒå‘é‡æœº (SVM):** ä¸€ç§ç”¨äºåˆ†ç±»ã€å›å½’å’Œå¼‚å¸¸æ£€æµ‹çš„ç›‘ç£å­¦ä¹ æ¨¡å‹ã€‚åœ¨åˆ†ç±»ä¸­ï¼Œè¯¥æ¨¡å‹åœ¨ç‰¹å¾ç©ºé—´ä¸­ä½œä¸ºè¾¹ç•Œï¼Œåœ¨å›å½’ä¸­ä½œä¸ºæœ€ä½³æ‹Ÿåˆçº¿ã€‚SVMä¸­é€šå¸¸ä½¿ç”¨æ ¸å‡½æ•°å°†æ•°æ®é›†è½¬æ¢åˆ°æ›´é«˜ç»´åº¦çš„ç©ºé—´ï¼Œä½¿å…¶æ›´æ˜“äºåˆ†ç¦»ã€‚[ç‚¹å‡»è¿™é‡Œ](https://en.wikipedia.org/wiki/Support-vector_machine)äº†è§£æ›´å¤šå…³äºSVMçš„ä¿¡æ¯ã€‚
- **æ”¯æŒå‘é‡å›å½’ (SVR):** ä¸€ç§SVMï¼Œç”¨äºæ‰¾åˆ°åŒ…å«æœ€å¤šæ•°æ®ç‚¹çš„æœ€ä½³æ‹Ÿåˆçº¿ï¼ˆåœ¨SVMä¸­æ˜¯è¶…å¹³é¢ï¼‰ã€‚

### ä¸ºä»€ä¹ˆé€‰æ‹©SVR? [^1]

åœ¨ä¸Šä¸€è¯¾ä¸­ï¼Œä½ å­¦ä¹ äº†ARIMAï¼Œè¿™æ˜¯ä¸€ç§éå¸¸æˆåŠŸçš„ç»Ÿè®¡çº¿æ€§æ–¹æ³•ï¼Œç”¨äºé¢„æµ‹æ—¶é—´åºåˆ—æ•°æ®ã€‚ç„¶è€Œï¼Œåœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œæ—¶é—´åºåˆ—æ•°æ®å…·æœ‰*éçº¿æ€§*ï¼Œè¿™æ— æ³•é€šè¿‡çº¿æ€§æ¨¡å‹æ˜ å°„ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼ŒSVMåœ¨å›å½’ä»»åŠ¡ä¸­è€ƒè™‘æ•°æ®éçº¿æ€§çš„èƒ½åŠ›ä½¿å¾—SVRåœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­éå¸¸æˆåŠŸã€‚

## ç»ƒä¹  - æ„å»ºä¸€ä¸ªSVRæ¨¡å‹

æ•°æ®å‡†å¤‡çš„å‰å‡ æ­¥ä¸ä¸Šä¸€è¯¾çš„[ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA)ç›¸åŒã€‚

æ‰“å¼€æœ¬è¯¾çš„[_/working_](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/3-SVR/working)æ–‡ä»¶å¤¹ï¼Œæ‰¾åˆ°[_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/7-TimeSeries/3-SVR/working/notebook.ipynb)æ–‡ä»¶ã€‚[ ^2 ]

1. è¿è¡Œç¬”è®°æœ¬å¹¶å¯¼å…¥å¿…è¦çš„åº“: [^2]

   ```python
   import sys
   sys.path.append('../../')
   ```

   ```python
   import os
   import warnings
   import matplotlib.pyplot as plt
   import numpy as np
   import pandas as pd
   import datetime as dt
   import math
   
   from sklearn.svm import SVR
   from sklearn.preprocessing import MinMaxScaler
   from common.utils import load_data, mape
   ```

2. ä»`/data/energy.csv`æ–‡ä»¶ä¸­åŠ è½½æ•°æ®åˆ°Pandasæ•°æ®æ¡†å¹¶æŸ¥çœ‹: [^2]

   ```python
   energy = load_data('../../data')[['load']]
   ```

3. ç»˜åˆ¶2012å¹´1æœˆè‡³2014å¹´12æœˆçš„æ‰€æœ‰å¯ç”¨èƒ½æºæ•°æ®: [^2]

   ```python
   energy.plot(y='load', subplots=True, figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![å®Œæ•´æ•°æ®](../../../../translated_images/full-data.a82ec9957e580e976f651a4fc38f280b9229c6efdbe3cfe7c60abaa9486d2cbe.zh.png)

   ç°åœ¨ï¼Œè®©æˆ‘ä»¬æ„å»ºæˆ‘ä»¬çš„SVRæ¨¡å‹ã€‚

### åˆ›å»ºè®­ç»ƒå’Œæµ‹è¯•æ•°æ®é›†

ç°åœ¨æ•°æ®å·²ç»åŠ è½½ï¼Œä½ å¯ä»¥å°†å…¶åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚ç„¶åä½ å°†é‡å¡‘æ•°æ®ä»¥åˆ›å»ºåŸºäºæ—¶é—´æ­¥é•¿çš„æ•°æ®é›†ï¼Œè¿™å¯¹äºSVRæ˜¯å¿…è¦çš„ã€‚ä½ å°†åœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒä½ çš„æ¨¡å‹ã€‚æ¨¡å‹è®­ç»ƒå®Œæˆåï¼Œä½ å°†è¯„ä¼°å…¶åœ¨è®­ç»ƒé›†ã€æµ‹è¯•é›†å’Œæ•´ä¸ªæ•°æ®é›†ä¸Šçš„å‡†ç¡®æ€§ï¼Œä»¥æŸ¥çœ‹æ•´ä½“æ€§èƒ½ã€‚ä½ éœ€è¦ç¡®ä¿æµ‹è¯•é›†è¦†ç›–è®­ç»ƒé›†ä¹‹åçš„æ—¶é—´æ®µï¼Œä»¥ç¡®ä¿æ¨¡å‹ä¸ä¼šä»æœªæ¥æ—¶é—´æ®µè·å–ä¿¡æ¯[^2]ï¼ˆè¿™ç§æƒ…å†µç§°ä¸º*è¿‡æ‹Ÿåˆ*ï¼‰ã€‚

1. å°†2014å¹´9æœˆ1æ—¥è‡³10æœˆ31æ—¥çš„ä¸¤ä¸ªæœˆåˆ†é…ç»™è®­ç»ƒé›†ã€‚æµ‹è¯•é›†å°†åŒ…æ‹¬2014å¹´11æœˆ1æ—¥è‡³12æœˆ31æ—¥çš„ä¸¤ä¸ªæœˆ: [^2]

   ```python
   train_start_dt = '2014-11-01 00:00:00'
   test_start_dt = '2014-12-30 00:00:00'
   ```

2. å¯è§†åŒ–å·®å¼‚: [^2]

   ```python
   energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)][['load']].rename(columns={'load':'train'}) \
       .join(energy[test_start_dt:][['load']].rename(columns={'load':'test'}), how='outer') \
       .plot(y=['train', 'test'], figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![è®­ç»ƒå’Œæµ‹è¯•æ•°æ®](../../../../translated_images/train-test.ead0cecbfc341921d4875eccf25fed5eefbb860cdbb69cabcc2276c49e4b33e5.zh.png)

### å‡†å¤‡è®­ç»ƒæ•°æ®

ç°åœ¨ï¼Œä½ éœ€è¦é€šè¿‡å¯¹æ•°æ®è¿›è¡Œè¿‡æ»¤å’Œç¼©æ”¾æ¥å‡†å¤‡è®­ç»ƒæ•°æ®ã€‚è¿‡æ»¤æ•°æ®é›†ä»¥ä»…åŒ…æ‹¬æ‰€éœ€çš„æ—¶é—´æ®µå’Œåˆ—ï¼Œå¹¶ç¼©æ”¾ä»¥ç¡®ä¿æ•°æ®åœ¨0åˆ°1çš„èŒƒå›´å†…ã€‚

1. è¿‡æ»¤åŸå§‹æ•°æ®é›†ï¼Œä»…åŒ…æ‹¬æ¯ä¸ªé›†åˆçš„ä¸Šè¿°æ—¶é—´æ®µï¼Œå¹¶ä»…åŒ…æ‹¬æ‰€éœ€çš„'load'åˆ—å’Œæ—¥æœŸ: [^2]

   ```python
   train = energy.copy()[(energy.index >= train_start_dt) & (energy.index < test_start_dt)][['load']]
   test = energy.copy()[energy.index >= test_start_dt][['load']]
   
   print('Training data shape: ', train.shape)
   print('Test data shape: ', test.shape)
   ```

   ```output
   Training data shape:  (1416, 1)
   Test data shape:  (48, 1)
   ```

2. å°†è®­ç»ƒæ•°æ®ç¼©æ”¾åˆ°ï¼ˆ0ï¼Œ1ï¼‰èŒƒå›´: [^2]

   ```python
   scaler = MinMaxScaler()
   train['load'] = scaler.fit_transform(train)
   ```

4. ç°åœ¨ï¼Œç¼©æ”¾æµ‹è¯•æ•°æ®: [^2]

   ```python
   test['load'] = scaler.transform(test)
   ```

### åˆ›å»ºå¸¦æœ‰æ—¶é—´æ­¥é•¿çš„æ•°æ® [^1]

å¯¹äºSVRï¼Œä½ éœ€è¦å°†è¾“å…¥æ•°æ®è½¬æ¢ä¸º`[batch, timesteps]`. So, you reshape the existing `train_data` and `test_data`çš„å½¢å¼ï¼Œä½¿å¾—æœ‰ä¸€ä¸ªæ–°çš„ç»´åº¦è¡¨ç¤ºæ—¶é—´æ­¥é•¿ã€‚

```python
# Converting to numpy arrays
train_data = train.values
test_data = test.values
```

å¯¹äºè¿™ä¸ªä¾‹å­ï¼Œæˆ‘ä»¬å–`timesteps = 5`ã€‚å› æ­¤ï¼Œæ¨¡å‹çš„è¾“å…¥æ˜¯å‰4ä¸ªæ—¶é—´æ­¥é•¿çš„æ•°æ®ï¼Œè¾“å‡ºæ˜¯ç¬¬5ä¸ªæ—¶é—´æ­¥é•¿çš„æ•°æ®ã€‚

```python
timesteps=5
```

ä½¿ç”¨åµŒå¥—åˆ—è¡¨æ¨å¯¼å°†è®­ç»ƒæ•°æ®è½¬æ¢ä¸º2Då¼ é‡:

```python
train_data_timesteps=np.array([[j for j in train_data[i:i+timesteps]] for i in range(0,len(train_data)-timesteps+1)])[:,:,0]
train_data_timesteps.shape
```

```output
(1412, 5)
```

å°†æµ‹è¯•æ•°æ®è½¬æ¢ä¸º2Då¼ é‡:

```python
test_data_timesteps=np.array([[j for j in test_data[i:i+timesteps]] for i in range(0,len(test_data)-timesteps+1)])[:,:,0]
test_data_timesteps.shape
```

```output
(44, 5)
```

é€‰æ‹©è®­ç»ƒå’Œæµ‹è¯•æ•°æ®çš„è¾“å…¥å’Œè¾“å‡º:

```python
x_train, y_train = train_data_timesteps[:,:timesteps-1],train_data_timesteps[:,[timesteps-1]]
x_test, y_test = test_data_timesteps[:,:timesteps-1],test_data_timesteps[:,[timesteps-1]]

print(x_train.shape, y_train.shape)
print(x_test.shape, y_test.shape)
```

```output
(1412, 4) (1412, 1)
(44, 4) (44, 1)
```

### å®ç°SVR [^1]

ç°åœ¨ï¼Œæ˜¯æ—¶å€™å®ç°SVRäº†ã€‚è¦äº†è§£æ›´å¤šå…³äºæ­¤å®ç°çš„ä¿¡æ¯ï¼Œä½ å¯ä»¥å‚è€ƒ[æ­¤æ–‡æ¡£](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html)ã€‚å¯¹äºæˆ‘ä»¬çš„å®ç°ï¼Œæˆ‘ä»¬éµå¾ªä»¥ä¸‹æ­¥éª¤:

  1. é€šè¿‡è°ƒç”¨`SVR()` and passing in the model hyperparameters: kernel, gamma, c and epsilon
  2. Prepare the model for the training data by calling the `fit()` function
  3. Make predictions calling the `predict()`å‡½æ•°å®šä¹‰æ¨¡å‹

ç°åœ¨æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªSVRæ¨¡å‹ã€‚è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨[RBFæ ¸](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel)ï¼Œå¹¶å°†è¶…å‚æ•°gammaã€Cå’Œepsilonåˆ†åˆ«è®¾ç½®ä¸º0.5ã€10å’Œ0.05ã€‚

```python
model = SVR(kernel='rbf',gamma=0.5, C=10, epsilon = 0.05)
```

#### åœ¨è®­ç»ƒæ•°æ®ä¸Šæ‹Ÿåˆæ¨¡å‹ [^1]

```python
model.fit(x_train, y_train[:,0])
```

```output
SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.05, gamma=0.5,
    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)
```

#### è¿›è¡Œæ¨¡å‹é¢„æµ‹ [^1]

```python
y_train_pred = model.predict(x_train).reshape(-1,1)
y_test_pred = model.predict(x_test).reshape(-1,1)

print(y_train_pred.shape, y_test_pred.shape)
```

```output
(1412, 1) (44, 1)
```

ä½ å·²ç»æ„å»ºäº†ä½ çš„SVRï¼ç°åœ¨æˆ‘ä»¬éœ€è¦è¯„ä¼°å®ƒã€‚

### è¯„ä¼°ä½ çš„æ¨¡å‹ [^1]

ä¸ºäº†è¯„ä¼°ï¼Œé¦–å…ˆæˆ‘ä»¬å°†æ•°æ®ç¼©æ”¾å›åŸå§‹æ¯”ä¾‹ã€‚ç„¶åï¼Œä¸ºäº†æ£€æŸ¥æ€§èƒ½ï¼Œæˆ‘ä»¬å°†ç»˜åˆ¶åŸå§‹å’Œé¢„æµ‹çš„æ—¶é—´åºåˆ—å›¾ï¼Œå¹¶æ‰“å°MAPEç»“æœã€‚

ç¼©æ”¾é¢„æµ‹å’ŒåŸå§‹è¾“å‡º:

```python
# Scaling the predictions
y_train_pred = scaler.inverse_transform(y_train_pred)
y_test_pred = scaler.inverse_transform(y_test_pred)

print(len(y_train_pred), len(y_test_pred))
```

```python
# Scaling the original values
y_train = scaler.inverse_transform(y_train)
y_test = scaler.inverse_transform(y_test)

print(len(y_train), len(y_test))
```

#### æ£€æŸ¥æ¨¡å‹åœ¨è®­ç»ƒå’Œæµ‹è¯•æ•°æ®ä¸Šçš„è¡¨ç° [^1]

æˆ‘ä»¬ä»æ•°æ®é›†ä¸­æå–æ—¶é—´æˆ³ä»¥æ˜¾ç¤ºåœ¨å›¾è¡¨çš„xè½´ä¸Šã€‚æ³¨æ„ï¼Œæˆ‘ä»¬ä½¿ç”¨ç¬¬ä¸€ä¸ª```timesteps-1```å€¼ä½œä¸ºç¬¬ä¸€ä¸ªè¾“å‡ºçš„è¾“å…¥ï¼Œå› æ­¤è¾“å‡ºçš„æ—¶é—´æˆ³å°†ä»é‚£ä¹‹åå¼€å§‹ã€‚

```python
train_timestamps = energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)].index[timesteps-1:]
test_timestamps = energy[test_start_dt:].index[timesteps-1:]

print(len(train_timestamps), len(test_timestamps))
```

```output
1412 44
```

ç»˜åˆ¶è®­ç»ƒæ•°æ®çš„é¢„æµ‹:

```python
plt.figure(figsize=(25,6))
plt.plot(train_timestamps, y_train, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(train_timestamps, y_train_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.title("Training data prediction")
plt.show()
```

![è®­ç»ƒæ•°æ®é¢„æµ‹](../../../../translated_images/train-data-predict.3c4ef4e78553104ffdd53d47a4c06414007947ea328e9261ddf48d3eafdefbbf.zh.png)

æ‰“å°è®­ç»ƒæ•°æ®çš„MAPE

```python
print('MAPE for training data: ', mape(y_train_pred, y_train)*100, '%')
```

```output
MAPE for training data: 1.7195710200875551 %
```

ç»˜åˆ¶æµ‹è¯•æ•°æ®çš„é¢„æµ‹

```python
plt.figure(figsize=(10,3))
plt.plot(test_timestamps, y_test, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(test_timestamps, y_test_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![æµ‹è¯•æ•°æ®é¢„æµ‹](../../../../translated_images/test-data-predict.8afc47ee7e52874f514ebdda4a798647e9ecf44a97cc927c535246fcf7a28aa9.zh.png)

æ‰“å°æµ‹è¯•æ•°æ®çš„MAPE

```python
print('MAPE for testing data: ', mape(y_test_pred, y_test)*100, '%')
```

```output
MAPE for testing data:  1.2623790187854018 %
```

ğŸ† ä½ åœ¨æµ‹è¯•æ•°æ®é›†ä¸Šå¾—åˆ°äº†éå¸¸å¥½çš„ç»“æœï¼

### æ£€æŸ¥æ¨¡å‹åœ¨å®Œæ•´æ•°æ®é›†ä¸Šçš„è¡¨ç° [^1]

```python
# Extracting load values as numpy array
data = energy.copy().values

# Scaling
data = scaler.transform(data)

# Transforming to 2D tensor as per model input requirement
data_timesteps=np.array([[j for j in data[i:i+timesteps]] for i in range(0,len(data)-timesteps+1)])[:,:,0]
print("Tensor shape: ", data_timesteps.shape)

# Selecting inputs and outputs from data
X, Y = data_timesteps[:,:timesteps-1],data_timesteps[:,[timesteps-1]]
print("X shape: ", X.shape,"\nY shape: ", Y.shape)
```

```output
Tensor shape:  (26300, 5)
X shape:  (26300, 4) 
Y shape:  (26300, 1)
```

```python
# Make model predictions
Y_pred = model.predict(X).reshape(-1,1)

# Inverse scale and reshape
Y_pred = scaler.inverse_transform(Y_pred)
Y = scaler.inverse_transform(Y)
```

```python
plt.figure(figsize=(30,8))
plt.plot(Y, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(Y_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![å®Œæ•´æ•°æ®é¢„æµ‹](../../../../translated_images/full-data-predict.4f0fed16a131c8f3bcc57a3060039dc7f2f714a05b07b68c513e0fe7fb3d8964.zh.png)

```python
print('MAPE: ', mape(Y_pred, Y)*100, '%')
```

```output
MAPE:  2.0572089029888656 %
```

ğŸ† éå¸¸å¥½çš„å›¾è¡¨ï¼Œæ˜¾ç¤ºäº†ä¸€ä¸ªå…·æœ‰è‰¯å¥½å‡†ç¡®æ€§çš„æ¨¡å‹ã€‚åšå¾—å¥½ï¼

---

## ğŸš€æŒ‘æˆ˜

- å°è¯•åœ¨åˆ›å»ºæ¨¡å‹æ—¶è°ƒæ•´è¶…å‚æ•°ï¼ˆgammaã€Cã€epsilonï¼‰ï¼Œå¹¶åœ¨æ•°æ®ä¸Šè¿›è¡Œè¯„ä¼°ï¼Œçœ‹çœ‹å“ªç»„è¶…å‚æ•°åœ¨æµ‹è¯•æ•°æ®ä¸Šç»™å‡ºæœ€ä½³ç»“æœã€‚è¦äº†è§£æ›´å¤šå…³äºè¿™äº›è¶…å‚æ•°çš„ä¿¡æ¯ï¼Œä½ å¯ä»¥å‚è€ƒ[æ­¤æ–‡æ¡£](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel)ã€‚
- å°è¯•ä¸ºæ¨¡å‹ä½¿ç”¨ä¸åŒçš„æ ¸å‡½æ•°ï¼Œå¹¶åˆ†æå®ƒä»¬åœ¨æ•°æ®é›†ä¸Šçš„è¡¨ç°ã€‚å¯ä»¥å‚è€ƒ[æ­¤æ–‡æ¡£](https://scikit-learn.org/stable/modules/svm.html#kernel-functions)ã€‚
- å°è¯•ä½¿ç”¨ä¸åŒçš„`timesteps`å€¼æ¥è®©æ¨¡å‹å›é¡¾ä»¥è¿›è¡Œé¢„æµ‹ã€‚

## [è¯¾åæµ‹éªŒ](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/52/)

## å¤ä¹ ä¸è‡ªå­¦

æœ¬è¯¾æ—¨åœ¨ä»‹ç»SVRåœ¨æ—¶é—´åºåˆ—é¢„æµ‹ä¸­çš„åº”ç”¨ã€‚è¦äº†è§£æ›´å¤šå…³äºSVRçš„ä¿¡æ¯ï¼Œä½ å¯ä»¥å‚è€ƒ[è¿™ç¯‡åšå®¢](https://www.analyticsvidhya.com/blog/2020/03/support-vector-regression-tutorial-for-machine-learning/)ã€‚è¿™ç¯‡[scikit-learnæ–‡æ¡£](https://scikit-learn.org/stable/modules/svm.html)æä¾›äº†å…³äºSVMçš„ä¸€èˆ¬è§£é‡Šï¼Œ[SVR](https://scikit-learn.org/stable/modules/svm.html#regression)ä»¥åŠå…¶ä»–å®ç°ç»†èŠ‚ï¼Œå¦‚å¯ä»¥ä½¿ç”¨çš„ä¸åŒ[æ ¸å‡½æ•°](https://scikit-learn.org/stable/modules/svm.html#kernel-functions)åŠå…¶å‚æ•°ã€‚

## ä½œä¸š

[ä¸€ä¸ªæ–°çš„SVRæ¨¡å‹](assignment.md)

## è‡´è°¢

[^1]: æœ¬èŠ‚ä¸­çš„æ–‡å­—ã€ä»£ç å’Œè¾“å‡ºç”±[@AnirbanMukherjeeXD](https://github.com/AnirbanMukherjeeXD)è´¡çŒ®
[^2]: æœ¬èŠ‚ä¸­çš„æ–‡å­—ã€ä»£ç å’Œè¾“å‡ºå–è‡ª[ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA)

**å…è´£å£°æ˜**ï¼š
æœ¬æ–‡æ¡£ä½¿ç”¨åŸºäºæœºå™¨çš„äººå·¥æ™ºèƒ½ç¿»è¯‘æœåŠ¡è¿›è¡Œç¿»è¯‘ã€‚å°½ç®¡æˆ‘ä»¬åŠ›æ±‚å‡†ç¡®ï¼Œä½†è¯·æ³¨æ„ï¼Œè‡ªåŠ¨ç¿»è¯‘å¯èƒ½åŒ…å«é”™è¯¯æˆ–ä¸å‡†ç¡®ä¹‹å¤„ã€‚åº”å°†åŸå§‹è¯­è¨€çš„æ–‡æ¡£è§†ä¸ºæƒå¨æ¥æºã€‚å¯¹äºå…³é”®ä¿¡æ¯ï¼Œå»ºè®®ä½¿ç”¨ä¸“ä¸šäººå·¥ç¿»è¯‘ã€‚å¯¹äºå› ä½¿ç”¨æ­¤ç¿»è¯‘è€Œäº§ç”Ÿçš„ä»»ä½•è¯¯è§£æˆ–è¯¯é‡Šï¼Œæˆ‘ä»¬ä¸æ‰¿æ‹…ä»»ä½•è´£ä»»ã€‚