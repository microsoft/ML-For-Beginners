{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "lesson_12-R.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "ir",
   "display_name": "R"
  },
  "language_info": {
   "name": "R"
  },
  "coopTranslator": {
   "original_hash": "fab50046ca413a38939d579f8432274f",
   "translation_date": "2025-09-03T20:28:54+00:00",
   "source_file": "4-Classification/3-Classifiers-2/solution/R/lesson_12-R.ipynb",
   "language_code": "lt"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsFutf_ygqSx"
   },
   "source": [
    "# Sukurkite klasifikavimo modelį: Skanūs Azijos ir Indijos patiekalai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HD54bEefgtNO"
   },
   "source": [
    "## Virtuvės klasifikatoriai 2\n",
    "\n",
    "Šioje antroje klasifikavimo pamokoje nagrinėsime `daugiau būdų` klasifikuoti kategorinius duomenis. Taip pat sužinosime apie pasekmes, susijusias su vieno klasifikatoriaus pasirinkimu vietoj kito.\n",
    "\n",
    "### [**Išankstinis testas**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/23/)\n",
    "\n",
    "### **Būtinos žinios**\n",
    "\n",
    "Darome prielaidą, kad jau baigėte ankstesnes pamokas, nes naudosime kai kurias anksčiau išmoktas sąvokas.\n",
    "\n",
    "Šiai pamokai reikės šių paketų:\n",
    "\n",
    "-   `tidyverse`: [tidyverse](https://www.tidyverse.org/) yra [R paketų rinkinys](https://www.tidyverse.org/packages), sukurtas tam, kad duomenų mokslas būtų greitesnis, paprastesnis ir įdomesnis!\n",
    "\n",
    "-   `tidymodels`: [tidymodels](https://www.tidymodels.org/) sistema yra [paketų rinkinys](https://www.tidymodels.org/packages/) modeliavimui ir mašininio mokymosi užduotims.\n",
    "\n",
    "-   `themis`: [themis paketas](https://themis.tidymodels.org/) siūlo papildomus receptų žingsnius, skirtus spręsti nesubalansuotų duomenų problemas.\n",
    "\n",
    "Galite juos įdiegti naudodami šią komandą:\n",
    "\n",
    "`install.packages(c(\"tidyverse\", \"tidymodels\", \"kernlab\", \"themis\", \"ranger\", \"xgboost\", \"kknn\"))`\n",
    "\n",
    "Arba galite naudoti žemiau pateiktą scenarijų, kuris patikrina, ar turite reikalingus paketus šiam moduliui užbaigti, ir, jei jų trūksta, įdiegia juos už jus.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vZ57IuUxgyQt"
   },
   "source": [
    "suppressWarnings(if (!require(\"pacman\"))install.packages(\"pacman\"))\n",
    "\n",
    "pacman::p_load(tidyverse, tidymodels, themis, kernlab, ranger, xgboost, kknn)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z22M-pj4g07x"
   },
   "source": [
    "## **1. Klasifikacijos žemėlapis**\n",
    "\n",
    "Mūsų [ankstesnėje pamokoje](https://github.com/microsoft/ML-For-Beginners/tree/main/4-Classification/2-Classifiers-1) bandėme atsakyti į klausimą: kaip pasirinkti tarp kelių modelių? Didžiąja dalimi tai priklauso nuo duomenų savybių ir problemos tipo, kurią norime išspręsti (pavyzdžiui, klasifikacija ar regresija?).\n",
    "\n",
    "Anksčiau sužinojome apie įvairias galimybes, kurias turite klasifikuodami duomenis, naudodami „Microsoft“ parengtą atmintinę. Python mašininio mokymosi sistema, Scikit-learn, siūlo panašią, bet detalesnę atmintinę, kuri gali dar labiau padėti susiaurinti jūsų pasirinkimą tarp vertintojų (kitas terminas klasifikatoriams):\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/map.png\"\n",
    "   width=\"700\"/>\n",
    "   <figcaption></figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1i3xRIVg7vG"
   },
   "source": [
    "> Patarimas: [aplankykite šį žemėlapį internete](https://scikit-learn.org/stable/tutorial/machine_learning_map/) ir sekite kelią, kad perskaitytumėte dokumentaciją.\n",
    ">\n",
    "> [Tidymodels nuorodų svetainė](https://www.tidymodels.org/find/parsnip/#models) taip pat pateikia puikią dokumentaciją apie skirtingus modelių tipus.\n",
    "\n",
    "### **Planas** 🗺️\n",
    "\n",
    "Šis žemėlapis yra labai naudingas, kai gerai suprantate savo duomenis, nes galite „eiti“ jo keliais iki sprendimo:\n",
    "\n",
    "-   Turime \\>50 pavyzdžių\n",
    "\n",
    "-   Norime prognozuoti kategoriją\n",
    "\n",
    "-   Turime pažymėtus duomenis\n",
    "\n",
    "-   Turime mažiau nei 100K pavyzdžių\n",
    "\n",
    "-   ✨ Galime pasirinkti Linear SVC\n",
    "\n",
    "-   Jei tai neveikia, kadangi turime skaitinius duomenis\n",
    "\n",
    "    -   Galime pabandyti ✨ KNeighbors Classifier\n",
    "\n",
    "        -   Jei tai neveikia, pabandykite ✨ SVC ir ✨ Ensemble Classifiers\n",
    "\n",
    "Tai labai naudingas kelias, kurį verta sekti. Dabar pereikime tiesiai prie darbo, naudodami [tidymodels](https://www.tidymodels.org/) modeliavimo sistemą: nuoseklią ir lankstią R paketų kolekciją, sukurtą skatinti gerą statistinę praktiką 😊.\n",
    "\n",
    "## 2. Padalykite duomenis ir spręskite nesubalansuoto duomenų rinkinio problemą.\n",
    "\n",
    "Iš ankstesnių pamokų sužinojome, kad mūsų virtuvėse buvo bendrų ingredientų rinkinys. Taip pat pastebėjome, kad virtuvių skaičiaus pasiskirstymas buvo gana netolygus.\n",
    "\n",
    "Šias problemas spręsime:\n",
    "\n",
    "-   Pašalindami dažniausiai pasitaikančius ingredientus, kurie sukelia painiavą tarp skirtingų virtuvių, naudodami `dplyr::select()`.\n",
    "\n",
    "-   Naudodami `recipe`, kuris iš anksto apdoroja duomenis, kad jie būtų paruošti modeliui, taikydami `over-sampling` algoritmą.\n",
    "\n",
    "Apie tai jau kalbėjome ankstesnėje pamokoje, todėl tai turėtų būti paprasta 🥳!\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6tj_rN00hClA"
   },
   "source": [
    "# Load the core Tidyverse and Tidymodels packages\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "\n",
    "# Load the original cuisines data\n",
    "df <- read_csv(file = \"https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/data/cuisines.csv\")\n",
    "\n",
    "# Drop id column, rice, garlic and ginger from our original data set\n",
    "df_select <- df %>% \n",
    "  select(-c(1, rice, garlic, ginger)) %>%\n",
    "  # Encode cuisine column as categorical\n",
    "  mutate(cuisine = factor(cuisine))\n",
    "\n",
    "\n",
    "# Create data split specification\n",
    "set.seed(2056)\n",
    "cuisines_split <- initial_split(data = df_select,\n",
    "                                strata = cuisine,\n",
    "                                prop = 0.7)\n",
    "\n",
    "# Extract the data in each split\n",
    "cuisines_train <- training(cuisines_split)\n",
    "cuisines_test <- testing(cuisines_split)\n",
    "\n",
    "# Display distribution of cuisines in the training set\n",
    "cuisines_train %>% \n",
    "  count(cuisine) %>% \n",
    "  arrange(desc(n))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFin5yw3hHb1"
   },
   "source": [
    "### Darbas su nesubalansuotais duomenimis\n",
    "\n",
    "Nesubalansuoti duomenys dažnai neigiamai veikia modelio veikimą. Daugelis modelių geriausiai veikia, kai stebėjimų skaičius yra vienodas, todėl jie dažnai susiduria su sunkumais dirbant su nesubalansuotais duomenimis.\n",
    "\n",
    "Yra du pagrindiniai būdai, kaip spręsti nesubalansuotų duomenų rinkinių problemą:\n",
    "\n",
    "-   pridėti stebėjimų prie mažumos klasės: `Perėmimas` (angl. Over-sampling), pvz., naudojant SMOTE algoritmą, kuris sintetiškai generuoja naujus mažumos klasės pavyzdžius, naudodamas artimiausius šių atvejų kaimynus.\n",
    "\n",
    "-   pašalinti stebėjimus iš daugumos klasės: `Perėmimas` (angl. Under-sampling)\n",
    "\n",
    "Ankstesnėje pamokoje mes pademonstravome, kaip spręsti nesubalansuotų duomenų rinkinių problemą naudojant `receptą`. Receptą galima laikyti planu, kuris aprašo, kokie žingsniai turėtų būti taikomi duomenų rinkiniui, kad jis būtų paruoštas duomenų analizei. Mūsų atveju norime užtikrinti vienodą mūsų `mokymo rinkinio` virtuvių skaičiaus pasiskirstymą. Pradėkime!\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cRzTnHolhLWd"
   },
   "source": [
    "# Load themis package for dealing with imbalanced data\n",
    "library(themis)\n",
    "\n",
    "# Create a recipe for preprocessing training data\n",
    "cuisines_recipe <- recipe(cuisine ~ ., data = cuisines_train) %>%\n",
    "  step_smote(cuisine) \n",
    "\n",
    "# Print recipe\n",
    "cuisines_recipe"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxOQ2ORhhO81"
   },
   "source": [
    "Dabar esame pasiruošę mokyti modelius 👩‍💻👨‍💻!\n",
    "\n",
    "## 3. Daugiau nei multinominiai regresijos modeliai\n",
    "\n",
    "Ankstesnėje pamokoje aptarėme multinominius regresijos modelius. Pažvelkime į lankstesnius klasifikavimo modelius.\n",
    "\n",
    "### Atraminių vektorių mašinos\n",
    "\n",
    "Klasifikavimo kontekste `Atraminių vektorių mašinos` yra mašininio mokymosi metodas, kuris siekia rasti *hiperplokštumą*, kuri \"geriausiai\" atskiria klases. Pažvelkime į paprastą pavyzdį:\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/svm.png\"\n",
    "   width=\"300\"/>\n",
    "   <figcaption>https://commons.wikimedia.org/w/index.php?curid=22877598</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4Wsd0vZhXYu"
   },
   "source": [
    "H1~ nesiskiria klasės. H2~ skiria, bet tik su mažu tarpu. H3~ skiria maksimaliai.\n",
    "\n",
    "#### Linijinis atraminių vektorių klasifikatorius\n",
    "\n",
    "Atraminių vektorių klasterizavimas (SVC) yra atraminių vektorių mašinų šeimos ML technikų dalis. SVC atveju hiperlėktuvą pasirenkama taip, kad jis teisingai atskirtų `daugumą` mokymo stebėjimų, tačiau `gali neteisingai klasifikuoti` kelis stebėjimus. Leidžiant kai kuriems taškams būti neteisingoje pusėje, SVM tampa atsparesnis išskirtims, todėl geriau apibendrina naujus duomenis. Parametras, reguliuojantis šį pažeidimą, vadinamas `kaina`, kurios numatytoji vertė yra 1 (žr. `help(\"svm_poly\")`).\n",
    "\n",
    "Sukurkime linijinį SVC nustatydami `degree = 1` polinominio SVM modelyje.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vJpp6nuChlBz"
   },
   "source": [
    "# Make a linear SVC specification\n",
    "svc_linear_spec <- svm_poly(degree = 1) %>% \n",
    "  set_engine(\"kernlab\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle specification and recipe into a worklow\n",
    "svc_linear_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(svc_linear_spec)\n",
    "\n",
    "# Print out workflow\n",
    "svc_linear_wf"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDs8cWNkhoqu"
   },
   "source": [
    "Dabar, kai apibrėžėme išankstinio apdorojimo veiksmus ir modelio specifikaciją *darbo eigoje*, galime pereiti prie linijinio SVC mokymo ir rezultatų vertinimo tuo pačiu metu. Kalbant apie našumo rodiklius, sukurkime rodiklių rinkinį, kuris įvertins: `tikslumą`, `jautrumą`, `teigiamą prognozuojamą vertę` ir `F matą`.\n",
    "\n",
    "> `augment()` pridės stulpelį(-ius) su prognozėmis prie pateiktų duomenų.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "81wiqcwuhrnq"
   },
   "source": [
    "# Train a linear SVC model\n",
    "svc_linear_fit <- svc_linear_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "# Create a metric set\n",
    "eval_metrics <- metric_set(ppv, sens, accuracy, f_meas)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "svc_linear_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UFQvHf-huo3"
   },
   "source": [
    "#### Atramos vektorių mašina\n",
    "\n",
    "Atramos vektorių mašina (SVM) yra atramos vektorių klasifikatoriaus išplėtimas, leidžiantis pritaikyti netiesinę ribą tarp klasių. Iš esmės, SVM naudoja *branduolio triuką* (angl. *kernel trick*), kad išplėstų požymių erdvę ir prisitaikytų prie netiesinių ryšių tarp klasių. Viena populiari ir itin lanksti branduolio funkcija, kurią naudoja SVM, yra *radialinės bazės funkcija*. Pažiūrėkime, kaip ji veiks su mūsų duomenimis.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-KX4S8mzhzmp"
   },
   "source": [
    "set.seed(2056)\n",
    "\n",
    "# Make an RBF SVM specification\n",
    "svm_rbf_spec <- svm_rbf() %>% \n",
    "  set_engine(\"kernlab\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle specification and recipe into a worklow\n",
    "svm_rbf_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(svm_rbf_spec)\n",
    "\n",
    "\n",
    "# Train an RBF model\n",
    "svm_rbf_fit <- svm_rbf_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "svm_rbf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBFSa7WSh4HQ"
   },
   "source": [
    "Daug geriau 🤩!\n",
    "\n",
    "> ✅ Prašome peržiūrėti:\n",
    ">\n",
    "> -   [*Support Vector Machines*](https://bradleyboehmke.github.io/HOML/svm.html), Hands-on Machine Learning with R\n",
    ">\n",
    "> -   [*Support Vector Machines*](https://www.statlearning.com/), An Introduction to Statistical Learning with Applications in R\n",
    ">\n",
    "> norint sužinoti daugiau.\n",
    "\n",
    "### Artimiausių kaimynų klasifikatoriai\n",
    "\n",
    "*K*-artimiausių kaimynų (KNN) algoritmas yra metodas, kuriame kiekviena stebėsena prognozuojama remiantis jos *panašumu* su kitomis stebėsenomis.\n",
    "\n",
    "Pritaikykime jį mūsų duomenims.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k4BxxBcdh9Ka"
   },
   "source": [
    "# Make a KNN specification\n",
    "knn_spec <- nearest_neighbor() %>% \n",
    "  set_engine(\"kknn\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "knn_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(knn_spec)\n",
    "\n",
    "# Train a boosted tree model\n",
    "knn_wf_fit <- knn_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "knn_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaegQseriAcj"
   },
   "source": [
    "Atrodo, kad šis modelis neveikia taip gerai. Tikėtina, kad pakeitus modelio parametrus (žr. `help(\"nearest_neighbor\")`), modelio veikimas pagerės. Būtinai išbandykite.\n",
    "\n",
    "> ✅ Prašome peržiūrėti:\n",
    ">\n",
    "> -   [Hands-on Machine Learning with R](https://bradleyboehmke.github.io/HOML/)\n",
    ">\n",
    "> -   [An Introduction to Statistical Learning with Applications in R](https://www.statlearning.com/)\n",
    ">\n",
    "> kad sužinotumėte daugiau apie *K*-artimiausių kaimynų klasifikatorius.\n",
    "\n",
    "### Ansambliniai klasifikatoriai\n",
    "\n",
    "Ansambliniai algoritmai veikia sujungdami kelis bazinius vertintojus, kad sukurtų optimalų modelį, tai daroma:\n",
    "\n",
    "`bagging`: taikant *vidurkinimo funkciją* bazinei modelių kolekcijai\n",
    "\n",
    "`boosting`: kuriant modelių seką, kurioje kiekvienas modelis remiasi ankstesniu, siekiant pagerinti prognozavimo tikslumą.\n",
    "\n",
    "Pradėkime nuo Random Forest modelio, kuris sukuria didelę sprendimų medžių kolekciją ir tada taiko vidurkinimo funkciją, kad sukurtų geresnį bendrą modelį.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "49DPoVs6iK1M"
   },
   "source": [
    "# Make a random forest specification\n",
    "rf_spec <- rand_forest() %>% \n",
    "  set_engine(\"ranger\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "rf_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(rf_spec)\n",
    "\n",
    "# Train a random forest model\n",
    "rf_wf_fit <- rf_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "rf_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGVYwC_aiUWc"
   },
   "source": [
    "Puikus darbas 👏!\n",
    "\n",
    "Išbandykime ir Boosted Tree modelį.\n",
    "\n",
    "Boosted Tree apibrėžia ansamblio metodą, kuris sukuria seką nuoseklių sprendimų medžių, kur kiekvienas medis priklauso nuo ankstesnių medžių rezultatų, siekiant palaipsniui sumažinti klaidą. Jis sutelkia dėmesį į neteisingai klasifikuotų elementų svorius ir koreguoja kitą klasifikatorių, kad ištaisytų klaidas.\n",
    "\n",
    "Yra įvairių būdų, kaip pritaikyti šį modelį (žr. `help(\"boost_tree\")`). Šiame pavyzdyje Boosted trees bus pritaikytas naudojant `xgboost` variklį.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Py1YWo-micWs"
   },
   "source": [
    "# Make a boosted tree specification\n",
    "boost_spec <- boost_tree(trees = 200) %>% \n",
    "  set_engine(\"xgboost\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "boost_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(boost_spec)\n",
    "\n",
    "# Train a boosted tree model\n",
    "boost_wf_fit <- boost_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "boost_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNQnbuejigZM"
   },
   "source": [
    "✅ Prašome peržiūrėti:\n",
    "\n",
    "-   [Mašininis mokymasis socialiniams mokslininkams](https://cimentadaj.github.io/ml_socsci/tree-based-methods.html#random-forests)\n",
    "\n",
    "-   [Praktinis mašininis mokymasis su R](https://bradleyboehmke.github.io/HOML/)\n",
    "\n",
    "-   [Statistinio mokymosi įvadas su R programos taikymu](https://www.statlearning.com/)\n",
    "\n",
    "-   <https://algotech.netlify.app/blog/xgboost/> - Aptariamas AdaBoost modelis, kuris yra gera alternatyva xgboost.\n",
    "\n",
    "Norėdami sužinoti daugiau apie ansamblių klasifikatorius.\n",
    "\n",
    "## 4. Papildoma - kelių modelių palyginimas\n",
    "\n",
    "Šiame laboratoriniame darbe pritaikėme nemažai modelių 🙌. Gali tapti varginančiu ar sudėtingu užduotis sukurti daugybę darbo eigų iš skirtingų išankstinio apdorojimo rinkinių ir/arba modelio specifikacijų, o tada po vieną apskaičiuoti našumo rodiklius.\n",
    "\n",
    "Pažiūrėkime, ar galime tai išspręsti sukurdami funkciją, kuri pritaiko darbo eigų sąrašą mokymo rinkiniui, o tada grąžina našumo rodiklius, remdamasi testavimo rinkiniu. Naudosime `map()` ir `map_dfr()` iš [purrr](https://purrr.tidyverse.org/) paketo, kad pritaikytume funkcijas kiekvienam sąrašo elementui.\n",
    "\n",
    "> [`map()`](https://purrr.tidyverse.org/reference/map.html) funkcijos leidžia pakeisti daugybę for ciklų kodu, kuris yra ir glaustesnis, ir lengviau skaitomas. Geriausia vieta sužinoti apie [`map()`](https://purrr.tidyverse.org/reference/map.html) funkcijas yra [iteracijos skyrius](http://r4ds.had.co.nz/iteration.html) knygoje \"R for Data Science\".\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Qzb7LyZnimd2"
   },
   "source": [
    "set.seed(2056)\n",
    "\n",
    "# Create a metric set\n",
    "eval_metrics <- metric_set(ppv, sens, accuracy, f_meas)\n",
    "\n",
    "# Define a function that returns performance metrics\n",
    "compare_models <- function(workflow_list, train_set, test_set){\n",
    "  \n",
    "  suppressWarnings(\n",
    "    # Fit each model to the train_set\n",
    "    map(workflow_list, fit, data = train_set) %>% \n",
    "    # Make predictions on the test set\n",
    "      map_dfr(augment, new_data = test_set, .id = \"model\") %>%\n",
    "    # Select desired columns\n",
    "      select(model, cuisine, .pred_class) %>% \n",
    "    # Evaluate model performance\n",
    "      group_by(model) %>% \n",
    "      eval_metrics(truth = cuisine, estimate = .pred_class) %>% \n",
    "      ungroup()\n",
    "  )\n",
    "  \n",
    "} # End of function"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fwa712sNisDA"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3i4VJOi2iu-a"
   },
   "source": [
    "# Make a list of workflows\n",
    "workflow_list <- list(\n",
    "  \"svc\" = svc_linear_wf,\n",
    "  \"svm\" = svm_rbf_wf,\n",
    "  \"knn\" = knn_wf,\n",
    "  \"random_forest\" = rf_wf,\n",
    "  \"xgboost\" = boost_wf)\n",
    "\n",
    "# Call the function\n",
    "set.seed(2056)\n",
    "perf_metrics <- compare_models(workflow_list = workflow_list, train_set = cuisines_train, test_set = cuisines_test)\n",
    "\n",
    "# Print out performance metrics\n",
    "perf_metrics %>% \n",
    "  group_by(.metric) %>% \n",
    "  arrange(desc(.estimate)) %>% \n",
    "  slice_head(n=7)\n",
    "\n",
    "# Compare accuracy\n",
    "perf_metrics %>% \n",
    "  filter(.metric == \"accuracy\") %>% \n",
    "  arrange(desc(.estimate))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuWK_lEli4nW"
   },
   "source": [
    "[**workflowset**](https://workflowsets.tidymodels.org/) paketas leidžia vartotojams kurti ir lengvai pritaikyti daugybę modelių, tačiau jis daugiausia skirtas dirbti su persamplingo technikomis, tokiomis kaip `kryžminė validacija`, metodas, kurį dar aptarsime.\n",
    "\n",
    "## **🚀Iššūkis**\n",
    "\n",
    "Kiekviena iš šių technikų turi daugybę parametrų, kuriuos galite koreguoti, pavyzdžiui, `cost` SVM modeliuose, `neighbors` KNN modeliuose, `mtry` (atsitiktinai parinkti prediktoriai) Atsitiktinių Miškų modeliuose.\n",
    "\n",
    "Ištyrinėkite kiekvieno modelio numatytuosius parametrus ir pagalvokite, ką šių parametrų koregavimas reikštų modelio kokybei.\n",
    "\n",
    "Norėdami sužinoti daugiau apie konkretų modelį ir jo parametrus, naudokite: `help(\"model\")`, pvz., `help(\"rand_forest\")`.\n",
    "\n",
    "> Praktikoje mes dažniausiai *įvertiname* *geriausias reikšmes* treniruodami daugybę modelių su `simuliuotu duomenų rinkiniu` ir matuodami, kaip gerai visi šie modeliai veikia. Šis procesas vadinamas **derinimu**.\n",
    "\n",
    "### [**Po paskaitos testas**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/24/)\n",
    "\n",
    "### **Peržiūra ir savarankiškas mokymasis**\n",
    "\n",
    "Šiose pamokose yra daug terminų, todėl skirkite minutę peržiūrėti [šį sąrašą](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) naudingų terminų!\n",
    "\n",
    "#### DĖKOJAME:\n",
    "\n",
    "[`Allison Horst`](https://twitter.com/allison_horst/) už nuostabius iliustracijas, kurios padaro R labiau prieinamą ir įdomų. Daugiau iliustracijų rasite jos [galerijoje](https://www.google.com/url?q=https://github.com/allisonhorst/stats-illustrations&sa=D&source=editors&ust=1626380772530000&usg=AOvVaw3zcfyCizFQZpkSLzxiiQEM).\n",
    "\n",
    "[Cassie Breviu](https://www.twitter.com/cassieview) ir [Jen Looper](https://www.twitter.com/jenlooper) už originalios šio modulio Python versijos sukūrimą ♥️\n",
    "\n",
    "Sėkmingo mokymosi,\n",
    "\n",
    "[Eric](https://twitter.com/ericntay), Gold Microsoft Learn Student Ambasadorius.\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/r_learners_sm.jpeg\"\n",
    "   width=\"569\"/>\n",
    "   <figcaption>Piešinys @allison_horst</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Atsakomybės apribojimas**:  \nŠis dokumentas buvo išverstas naudojant AI vertimo paslaugą [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, prašome atkreipti dėmesį, kad automatiniai vertimai gali turėti klaidų ar netikslumų. Originalus dokumentas jo gimtąja kalba turėtų būti laikomas autoritetingu šaltiniu. Kritinei informacijai rekomenduojama profesionali žmogaus vertimo paslauga. Mes neprisiimame atsakomybės už nesusipratimus ar klaidingus interpretavimus, atsiradusius dėl šio vertimo naudojimo.\n"
   ]
  }
 ]
}