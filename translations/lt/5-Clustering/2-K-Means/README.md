<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "085d571097d201810720df4cd379f8c2",
  "translation_date": "2025-09-03T17:17:09+00:00",
  "source_file": "5-Clustering/2-K-Means/README.md",
  "language_code": "lt"
}
-->
# K-Means klasterizacija

## [PrieÅ¡ paskaitos testÄ…](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/29/)

Å ioje pamokoje iÅ¡moksite kurti klasterius naudodami Scikit-learn ir anksÄiau importuotÄ… Nigerijos muzikos duomenÅ³ rinkinÄ¯. Aptarsime K-Means klasterizacijos pagrindus. Atminkite, kad, kaip suÅ¾inojote ankstesnÄ—je pamokoje, yra daug bÅ«dÅ³ dirbti su klasteriais, o pasirinktas metodas priklauso nuo jÅ«sÅ³ duomenÅ³. IÅ¡bandysime K-Means, nes tai yra daÅ¾niausiai naudojama klasterizacijos technika. PradÄ—kime!

SÄ…vokos, kurias iÅ¡moksite:

- Silueto Ä¯vertinimas
- AlkÅ«nÄ—s metodas
- Inercija
- Dispersija

## Ä®vadas

[K-Means klasterizacija](https://wikipedia.org/wiki/K-means_clustering) yra metodas, kilÄ™s iÅ¡ signalÅ³ apdorojimo srities. Jis naudojamas duomenÅ³ grupÄ—ms padalyti ir suskirstyti Ä¯ 'k' klasterius, remiantis stebÄ—jimÅ³ serija. Kiekvienas stebÄ—jimas veikia taip, kad duomenÅ³ taÅ¡kas bÅ«tÅ³ priskirtas artimiausiam 'vidurkiui' arba klasterio centrui.

Klasteriai gali bÅ«ti vizualizuojami kaip [Voronoi diagramos](https://wikipedia.org/wiki/Voronoi_diagram), kurios apima taÅ¡kÄ… (arba 'sÄ—klÄ…') ir atitinkamÄ… regionÄ….

![voronoi diagrama](../../../../translated_images/voronoi.1dc1613fb0439b9564615eca8df47a4bcd1ce06217e7e72325d2406ef2180795.lt.png)

> Infografika sukÅ«rÄ— [Jen Looper](https://twitter.com/jenlooper)

K-Means klasterizacijos procesas [vykdomas trijÅ³ Å¾ingsniÅ³ procese](https://scikit-learn.org/stable/modules/clustering.html#k-means):

1. Algoritmas pasirenka k skaiÄiÅ³ centriniÅ³ taÅ¡kÅ³, imdamas mÄ—ginius iÅ¡ duomenÅ³ rinkinio. Po to jis kartoja:
    1. Priskiria kiekvienÄ… mÄ—ginÄ¯ artimiausiam centroidui.
    2. Sukuria naujus centroidus, apskaiÄiuodamas visÅ³ mÄ—giniÅ³, priskirtÅ³ ankstesniems centroidams, vidutinÄ™ vertÄ™.
    3. Tada apskaiÄiuoja skirtumÄ… tarp naujÅ³ ir senÅ³ centroidÅ³ ir kartoja, kol centroidai stabilizuojasi.

Vienas K-Means metodo trÅ«kumas yra tas, kad reikia nustatyti 'k', tai yra centriniÅ³ taÅ¡kÅ³ skaiÄiÅ³. Laimei, 'alkÅ«nÄ—s metodas' padeda nustatyti gerÄ… pradinÄ™ 'k' vertÄ™. Netrukus tai iÅ¡bandysite.

## BÅ«tinos sÄ…lygos

Dirbsite su Å¡ios pamokos [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/2-K-Means/notebook.ipynb) failu, kuriame yra duomenÅ³ importavimas ir preliminarus valymas, atliktas ankstesnÄ—je pamokoje.

## Pratimai - pasiruoÅ¡imas

PradÄ—kite dar kartÄ… perÅ¾iÅ«rÄ—dami dainÅ³ duomenis.

1. Sukurkite dÄ—Å¾utÄ—s diagramÄ…, iÅ¡kviesdami `boxplot()` kiekvienai stulpeliui:

    ```python
    plt.figure(figsize=(20,20), dpi=200)
    
    plt.subplot(4,3,1)
    sns.boxplot(x = 'popularity', data = df)
    
    plt.subplot(4,3,2)
    sns.boxplot(x = 'acousticness', data = df)
    
    plt.subplot(4,3,3)
    sns.boxplot(x = 'energy', data = df)
    
    plt.subplot(4,3,4)
    sns.boxplot(x = 'instrumentalness', data = df)
    
    plt.subplot(4,3,5)
    sns.boxplot(x = 'liveness', data = df)
    
    plt.subplot(4,3,6)
    sns.boxplot(x = 'loudness', data = df)
    
    plt.subplot(4,3,7)
    sns.boxplot(x = 'speechiness', data = df)
    
    plt.subplot(4,3,8)
    sns.boxplot(x = 'tempo', data = df)
    
    plt.subplot(4,3,9)
    sns.boxplot(x = 'time_signature', data = df)
    
    plt.subplot(4,3,10)
    sns.boxplot(x = 'danceability', data = df)
    
    plt.subplot(4,3,11)
    sns.boxplot(x = 'length', data = df)
    
    plt.subplot(4,3,12)
    sns.boxplot(x = 'release_date', data = df)
    ```

    Å ie duomenys yra Å¡iek tiek triukÅ¡mingi: stebÄ—dami kiekvienÄ… stulpelÄ¯ kaip dÄ—Å¾utÄ—s diagramÄ…, galite matyti anomalijas.

    ![anomalijos](../../../../translated_images/boxplots.8228c29dabd0f29227dd38624231a175f411f1d8d4d7c012cb770e00e4fdf8b6.lt.png)

GalÄ—tumÄ—te perÅ¾iÅ«rÄ—ti duomenÅ³ rinkinÄ¯ ir paÅ¡alinti Å¡ias anomalijas, taÄiau tai padarytÅ³ duomenis gana minimaliais.

1. Å iuo metu pasirinkite, kuriuos stulpelius naudosite klasterizacijos pratyboms. Pasirinkite tuos, kurie turi panaÅ¡ius diapazonus, ir uÅ¾koduokite `artist_top_genre` stulpelÄ¯ kaip skaitinius duomenis:

    ```python
    from sklearn.preprocessing import LabelEncoder
    le = LabelEncoder()
    
    X = df.loc[:, ('artist_top_genre','popularity','danceability','acousticness','loudness','energy')]
    
    y = df['artist_top_genre']
    
    X['artist_top_genre'] = le.fit_transform(X['artist_top_genre'])
    
    y = le.transform(y)
    ```

1. Dabar turite nusprÄ™sti, kiek klasteriÅ³ taikysite. Å½inote, kad yra 3 dainÅ³ Å¾anrai, kuriuos iÅ¡skyrÄ—me iÅ¡ duomenÅ³ rinkinio, todÄ—l pabandykime 3:

    ```python
    from sklearn.cluster import KMeans
    
    nclusters = 3 
    seed = 0
    
    km = KMeans(n_clusters=nclusters, random_state=seed)
    km.fit(X)
    
    # Predict the cluster for each data point
    
    y_cluster_kmeans = km.predict(X)
    y_cluster_kmeans
    ```

Matote iÅ¡spausdintÄ… masyvÄ… su numatytais klasteriais (0, 1 arba 2) kiekvienai duomenÅ³ rÄ—melio eilutei.

1. Naudokite Å¡Ä¯ masyvÄ…, kad apskaiÄiuotumÄ—te 'silueto Ä¯vertinimÄ…':

    ```python
    from sklearn import metrics
    score = metrics.silhouette_score(X, y_cluster_kmeans)
    score
    ```

## Silueto Ä¯vertinimas

IeÅ¡kokite silueto Ä¯vertinimo, artimo 1. Å is Ä¯vertinimas svyruoja nuo -1 iki 1, ir jei Ä¯vertinimas yra 1, klasteris yra tankus ir gerai atskirtas nuo kitÅ³ klasteriÅ³. VertÄ—, artima 0, reiÅ¡kia persidengianÄius klasterius, kuriÅ³ mÄ—giniai yra labai arti kaimyniniÅ³ klasteriÅ³ sprendimo ribos. [(Å altinis)](https://dzone.com/articles/kmeans-silhouette-score-explained-with-python-exam)

MÅ«sÅ³ Ä¯vertinimas yra **.53**, taigi vidutinis. Tai rodo, kad mÅ«sÅ³ duomenys nÄ—ra ypaÄ tinkami Å¡io tipo klasterizacijai, taÄiau tÄ™skime.

### Pratimai - modelio kÅ«rimas

1. Importuokite `KMeans` ir pradÄ—kite klasterizacijos procesÄ….

    ```python
    from sklearn.cluster import KMeans
    wcss = []
    
    for i in range(1, 11):
        kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)
        kmeans.fit(X)
        wcss.append(kmeans.inertia_)
    
    ```

    ÄŒia yra keletas daliÅ³, kurias verta paaiÅ¡kinti.

    > ğŸ“ diapazonas: Tai yra klasterizacijos proceso iteracijos.

    > ğŸ“ random_state: "Nustato atsitiktiniÅ³ skaiÄiÅ³ generavimÄ… centroidÅ³ inicializavimui." [Å altinis](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)

    > ğŸ“ WCSS: "klasterio viduje esanÄiÅ³ kvadratÅ³ suma" matuoja vidutinÄ¯ kvadratinÄ¯ atstumÄ… visÅ³ taÅ¡kÅ³ klasteryje iki klasterio centro. [Å altinis](https://medium.com/@ODSC/unsupervised-learning-evaluating-clusters-bd47eed175ce).

    > ğŸ“ Inercija: K-Means algoritmai bando pasirinkti centroidus, kad sumaÅ¾intÅ³ 'inercijÄ…', "matÄ…, kaip viduje nuoseklÅ«s yra klasteriai." [Å altinis](https://scikit-learn.org/stable/modules/clustering.html). VertÄ— pridedama prie wcss kintamojo kiekvienoje iteracijoje.

    > ğŸ“ k-means++: [Scikit-learn](https://scikit-learn.org/stable/modules/clustering.html#k-means) galite naudoti 'k-means++' optimizacijÄ…, kuri "inicializuoja centroidus taip, kad jie (paprastai) bÅ«tÅ³ toli vienas nuo kito, todÄ—l rezultatai greiÄiausiai bus geresni nei atsitiktinÄ— inicializacija."

### AlkÅ«nÄ—s metodas

AnksÄiau spÄ—jote, kad, kadangi taikote 3 dainÅ³ Å¾anrus, turÄ—tumÄ—te pasirinkti 3 klasterius. Bet ar tai tiesa?

1. Naudokite 'alkÅ«nÄ—s metodÄ…', kad Ä¯sitikintumÄ—te.

    ```python
    plt.figure(figsize=(10,5))
    sns.lineplot(x=range(1, 11), y=wcss, marker='o', color='red')
    plt.title('Elbow')
    plt.xlabel('Number of clusters')
    plt.ylabel('WCSS')
    plt.show()
    ```

    Naudokite `wcss` kintamÄ…jÄ¯, kurÄ¯ sukÅ«rÄ—te ankstesniame Å¾ingsnyje, kad sukurtumÄ—te diagramÄ…, rodanÄiÄ…, kur yra 'alkÅ«nÄ—s' lenkimas, kuris nurodo optimalÅ³ klasteriÅ³ skaiÄiÅ³. GalbÅ«t tai **tikrai** yra 3!

    ![alkÅ«nÄ—s metodas](../../../../translated_images/elbow.72676169eed744ff03677e71334a16c6b8f751e9e716e3d7f40dd7cdef674cca.lt.png)

## Pratimai - klasteriÅ³ vaizdavimas

1. IÅ¡bandykite procesÄ… dar kartÄ…, Å¡Ä¯ kartÄ… nustatydami tris klasterius, ir pavaizduokite klasterius kaip sklaidos diagramÄ…:

    ```python
    from sklearn.cluster import KMeans
    kmeans = KMeans(n_clusters = 3)
    kmeans.fit(X)
    labels = kmeans.predict(X)
    plt.scatter(df['popularity'],df['danceability'],c = labels)
    plt.xlabel('popularity')
    plt.ylabel('danceability')
    plt.show()
    ```

1. Patikrinkite modelio tikslumÄ…:

    ```python
    labels = kmeans.labels_
    
    correct_labels = sum(y == labels)
    
    print("Result: %d out of %d samples were correctly labeled." % (correct_labels, y.size))
    
    print('Accuracy score: {0:0.2f}'. format(correct_labels/float(y.size)))
    ```

    Å io modelio tikslumas nÄ—ra labai geras, o klasteriÅ³ forma suteikia uÅ¾uominÄ…, kodÄ—l.

    ![klasteriai](../../../../translated_images/clusters.b635354640d8e4fd4a49ef545495518e7be76172c97c13bd748f5b79f171f69a.lt.png)

    Å ie duomenys yra per daug nesubalansuoti, per maÅ¾ai koreliuoti, o stulpeliÅ³ reikÅ¡miÅ³ variacija yra per didelÄ—, kad klasteriai bÅ«tÅ³ gerai suformuoti. IÅ¡ tiesÅ³, klasteriai, kurie susiformuoja, tikriausiai yra stipriai paveikti arba iÅ¡kreipti trijÅ³ Å¾anrÅ³ kategorijÅ³, kurias apibrÄ—Å¾Ä—me aukÅ¡Äiau. Tai buvo mokymosi procesas!

    Scikit-learn dokumentacijoje galite matyti, kad modelis, kaip Å¡is, su klasteriais, kurie nÄ—ra gerai apibrÄ—Å¾ti, turi 'dispersijos' problemÄ…:

    ![probleminiai modeliai](../../../../translated_images/problems.f7fb539ccd80608e1f35c319cf5e3ad1809faa3c08537aead8018c6b5ba2e33a.lt.png)
    > Infografika iÅ¡ Scikit-learn

## Dispersija

Dispersija apibrÄ—Å¾iama kaip "vidutinÄ— kvadratiniÅ³ skirtumÅ³ nuo vidurkio vertÄ—" [(Å altinis)](https://www.mathsisfun.com/data/standard-deviation.html). Å io klasterizacijos problemos kontekste tai reiÅ¡kia, kad mÅ«sÅ³ duomenÅ³ rinkinio skaiÄiai linkÄ™ per daug nukrypti nuo vidurkio.

âœ… Tai puikus momentas pagalvoti apie visus bÅ«dus, kaip galÄ—tumÄ—te iÅ¡taisyti Å¡iÄ… problemÄ…. Ar verta dar labiau koreguoti duomenis? Naudoti kitus stulpelius? IÅ¡bandyti kitÄ… algoritmÄ…? UÅ¾uomina: Pabandykite [normalizuoti duomenis](https://www.mygreatlearning.com/blog/learning-data-science-with-k-means-clustering/) ir iÅ¡bandyti kitus stulpelius.

> Pabandykite Å¡Ä¯ '[dispersijos skaiÄiuoklÄ™](https://www.calculatorsoup.com/calculators/statistics/variance-calculator.php)', kad geriau suprastumÄ—te Å¡iÄ… sÄ…vokÄ….

---

## ğŸš€IÅ¡Å¡Å«kis

Praleiskite Å¡iek tiek laiko su Å¡iuo uÅ¾raÅ¡Å³ knygeliu, koreguodami parametrus. Ar galite pagerinti modelio tikslumÄ…, dar labiau iÅ¡valydami duomenis (pvz., paÅ¡alindami anomalijas)? Galite naudoti svorius, kad suteiktumÄ—te daugiau reikÅ¡mÄ—s tam tikriems duomenÅ³ mÄ—giniams. KÄ… dar galite padaryti, kad sukurtumÄ—te geresnius klasterius?

UÅ¾uomina: Pabandykite normalizuoti duomenis. UÅ¾raÅ¡Å³ knygelÄ—je yra komentaruose pateiktas kodas, kuris prideda standartinÄ¯ mastelio keitimÄ…, kad duomenÅ³ stulpeliai bÅ«tÅ³ panaÅ¡esni pagal diapazonÄ…. PastebÄ—site, kad nors silueto Ä¯vertinimas sumaÅ¾Ä—ja, 'alkÅ«nÄ—s' grafiko lenkimas tampa lygesnis. Taip yra todÄ—l, kad paliekant duomenis nenormalizuotus, duomenys su maÅ¾esne dispersija turi didesnÄ™ Ä¯takÄ…. Skaitykite daugiau apie Å¡iÄ… problemÄ… [Äia](https://stats.stackexchange.com/questions/21222/are-mean-normalization-and-feature-scaling-needed-for-k-means-clustering/21226#21226).

## [Po paskaitos testÄ…](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/30/)

## ApÅ¾valga ir savarankiÅ¡kas mokymasis

PaÅ¾velkite Ä¯ K-Means simuliatoriÅ³ [tokÄ¯ kaip Å¡is](https://user.ceng.metu.edu.tr/~akifakkus/courses/ceng574/k-means/). Galite naudoti Å¡Ä¯ Ä¯rankÄ¯, kad vizualizuotumÄ—te mÄ—giniÅ³ duomenÅ³ taÅ¡kus ir nustatytumÄ—te jÅ³ centroidus. Galite redaguoti duomenÅ³ atsitiktinumÄ…, klasteriÅ³ skaiÄiÅ³ ir centroidÅ³ skaiÄiÅ³. Ar tai padeda jums suprasti, kaip duomenys gali bÅ«ti grupuojami?

Taip pat perÅ¾iÅ«rÄ—kite [Å¡Ä¯ Stanfordo K-Means vadovÄ…](https://stanford.edu/~cpiech/cs221/handouts/kmeans.html).

## UÅ¾duotis

[IÅ¡bandykite skirtingus klasterizacijos metodus](assignment.md)

---

**AtsakomybÄ—s apribojimas**:  
Å is dokumentas buvo iÅ¡verstas naudojant AI vertimo paslaugÄ… [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, praÅ¡ome atkreipti dÄ—mesÄ¯, kad automatiniai vertimai gali turÄ—ti klaidÅ³ ar netikslumÅ³. Originalus dokumentas jo gimtÄ…ja kalba turÄ—tÅ³ bÅ«ti laikomas autoritetingu Å¡altiniu. Kritinei informacijai rekomenduojama profesionali Å¾mogaus vertimo paslauga. Mes neprisiimame atsakomybÄ—s uÅ¾ nesusipratimus ar klaidingus interpretavimus, atsiradusius naudojant Å¡Ä¯ vertimÄ….