<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7cdd17338d9bbd7e2171c2cd462eb081",
  "translation_date": "2025-09-05T07:51:31+00:00",
  "source_file": "5-Clustering/2-K-Means/README.md",
  "language_code": "lt"
}
-->
# K-Means klasterizacija

## [PrieÅ¡ paskaitÄ… - testas](https://ff-quizzes.netlify.app/en/ml/)

Å ioje pamokoje iÅ¡moksite kurti klasterius naudodami Scikit-learn ir anksÄiau importuotÄ… Nigerijos muzikos duomenÅ³ rinkinÄ¯. Aptarsime K-Means klasterizacijos pagrindus. Atminkite, kad, kaip suÅ¾inojote ankstesnÄ—je pamokoje, yra daug bÅ«dÅ³ dirbti su klasteriais, o pasirinktas metodas priklauso nuo jÅ«sÅ³ duomenÅ³. IÅ¡bandysime K-Means, nes tai yra daÅ¾niausiai naudojama klasterizacijos technika. PradÄ—kime!

SÄ…vokos, apie kurias suÅ¾inosite:

- Silueto Ä¯vertinimas
- AlkÅ«nÄ—s metodas
- Inercija
- Dispersija

## Ä®vadas

[K-Means klasterizacija](https://wikipedia.org/wiki/K-means_clustering) yra metodas, kilÄ™s iÅ¡ signalÅ³ apdorojimo srities. Jis naudojamas duomenÅ³ grupÄ—ms padalyti ir suskirstyti Ä¯ â€kâ€œ klasterius, remiantis stebÄ—jimÅ³ serija. Kiekvienas stebÄ—jimas padeda priskirti duomenÅ³ taÅ¡kÄ… artimiausiam â€vidurkiuiâ€œ arba klasterio centrui.

Klasteriai gali bÅ«ti vizualizuojami kaip [Voronoi diagramos](https://wikipedia.org/wiki/Voronoi_diagram), kurios apima taÅ¡kÄ… (arba â€sÄ—klÄ…â€œ) ir atitinkamÄ… regionÄ….

![voronoi diagrama](../../../../5-Clustering/2-K-Means/images/voronoi.png)

> Infografikas sukurtas [Jen Looper](https://twitter.com/jenlooper)

K-Means klasterizacijos procesas [vykdomas trijÅ³ Å¾ingsniÅ³ procesu](https://scikit-learn.org/stable/modules/clustering.html#k-means):

1. Algoritmas pasirenka k skaiÄiÅ³ centriniÅ³ taÅ¡kÅ³, imdamas mÄ—ginius iÅ¡ duomenÅ³ rinkinio. Po to jis kartoja:
    1. Priskiria kiekvienÄ… mÄ—ginÄ¯ artimiausiam centroidui.
    2. Sukuria naujus centroidus, apskaiÄiuodamas visÅ³ ankstesniems centroidams priskirtÅ³ mÄ—giniÅ³ vidurkÄ¯.
    3. Tada apskaiÄiuoja skirtumÄ… tarp naujÅ³ ir senÅ³ centroidÅ³ ir kartoja, kol centroidai stabilizuojasi.

Vienas iÅ¡ K-Means trÅ«kumÅ³ yra tas, kad reikia nustatyti â€kâ€œ, t. y. centriniÅ³ taÅ¡kÅ³ skaiÄiÅ³. Laimei, â€alkÅ«nÄ—s metodasâ€œ padeda Ä¯vertinti gerÄ… pradinÄ™ â€kâ€œ reikÅ¡mÄ™. Netrukus tai iÅ¡bandysite.

## BÅ«tinos Å¾inios

Å ioje pamokoje dirbsite su [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/2-K-Means/notebook.ipynb) failu, kuriame yra duomenÅ³ importavimas ir preliminarus valymas, atliktas ankstesnÄ—je pamokoje.

## UÅ¾duotis - pasiruoÅ¡imas

PradÄ—kite dar kartÄ… perÅ¾iÅ«rÄ—dami dainÅ³ duomenis.

1. Sukurkite dÄ—Å¾utÄ—s diagramÄ…, iÅ¡kviesdami `boxplot()` kiekvienai stulpelio reikÅ¡mei:

    ```python
    plt.figure(figsize=(20,20), dpi=200)
    
    plt.subplot(4,3,1)
    sns.boxplot(x = 'popularity', data = df)
    
    plt.subplot(4,3,2)
    sns.boxplot(x = 'acousticness', data = df)
    
    plt.subplot(4,3,3)
    sns.boxplot(x = 'energy', data = df)
    
    plt.subplot(4,3,4)
    sns.boxplot(x = 'instrumentalness', data = df)
    
    plt.subplot(4,3,5)
    sns.boxplot(x = 'liveness', data = df)
    
    plt.subplot(4,3,6)
    sns.boxplot(x = 'loudness', data = df)
    
    plt.subplot(4,3,7)
    sns.boxplot(x = 'speechiness', data = df)
    
    plt.subplot(4,3,8)
    sns.boxplot(x = 'tempo', data = df)
    
    plt.subplot(4,3,9)
    sns.boxplot(x = 'time_signature', data = df)
    
    plt.subplot(4,3,10)
    sns.boxplot(x = 'danceability', data = df)
    
    plt.subplot(4,3,11)
    sns.boxplot(x = 'length', data = df)
    
    plt.subplot(4,3,12)
    sns.boxplot(x = 'release_date', data = df)
    ```

    Å ie duomenys yra Å¡iek tiek triukÅ¡mingi: stebÄ—dami kiekvienÄ… stulpelÄ¯ kaip dÄ—Å¾utÄ—s diagramÄ…, galite pastebÄ—ti iÅ¡skirtis.

    ![iÅ¡skirtys](../../../../5-Clustering/2-K-Means/images/boxplots.png)

GalÄ—tumÄ—te perÅ¾iÅ«rÄ—ti duomenÅ³ rinkinÄ¯ ir paÅ¡alinti Å¡ias iÅ¡skirtis, taÄiau tai padarytÅ³ duomenis gana minimaliais.

1. Å iuo metu pasirinkite, kuriuos stulpelius naudosite klasterizacijos uÅ¾duoÄiai. Pasirinkite tuos, kuriÅ³ reikÅ¡mÄ—s yra panaÅ¡aus diapazono, ir uÅ¾koduokite `artist_top_genre` stulpelÄ¯ kaip skaitinius duomenis:

    ```python
    from sklearn.preprocessing import LabelEncoder
    le = LabelEncoder()
    
    X = df.loc[:, ('artist_top_genre','popularity','danceability','acousticness','loudness','energy')]
    
    y = df['artist_top_genre']
    
    X['artist_top_genre'] = le.fit_transform(X['artist_top_genre'])
    
    y = le.transform(y)
    ```

1. Dabar turite nusprÄ™sti, kiek klasteriÅ³ taikysite. Å½inote, kad duomenÅ³ rinkinyje yra 3 dainÅ³ Å¾anrai, todÄ—l pabandykime 3:

    ```python
    from sklearn.cluster import KMeans
    
    nclusters = 3 
    seed = 0
    
    km = KMeans(n_clusters=nclusters, random_state=seed)
    km.fit(X)
    
    # Predict the cluster for each data point
    
    y_cluster_kmeans = km.predict(X)
    y_cluster_kmeans
    ```

Matote iÅ¡spausdintÄ… masyvÄ… su numatytais klasteriais (0, 1 arba 2) kiekvienai duomenÅ³ rÄ—melio eilutei.

1. Naudokite Å¡Ä¯ masyvÄ…, kad apskaiÄiuotumÄ—te â€silueto Ä¯vertinimÄ…â€œ:

    ```python
    from sklearn import metrics
    score = metrics.silhouette_score(X, y_cluster_kmeans)
    score
    ```

## Silueto Ä¯vertinimas

Siekite silueto Ä¯vertinimo, artimo 1. Å is Ä¯vertinimas svyruoja nuo -1 iki 1, ir jei Ä¯vertinimas yra 1, klasteris yra tankus ir gerai atskirtas nuo kitÅ³ klasteriÅ³. ReikÅ¡mÄ—, artima 0, reiÅ¡kia persidengianÄius klasterius, kuriÅ³ mÄ—giniai yra labai arti kaimyniniÅ³ klasteriÅ³ sprendimo ribos. [(Å altinis)](https://dzone.com/articles/kmeans-silhouette-score-explained-with-python-exam)

MÅ«sÅ³ Ä¯vertinimas yra **0.53**, taigi vidutinis. Tai rodo, kad mÅ«sÅ³ duomenys nÄ—ra ypaÄ tinkami Å¡io tipo klasterizacijai, taÄiau tÄ™skime.

### UÅ¾duotis - modelio kÅ«rimas

1. Importuokite `KMeans` ir pradÄ—kite klasterizacijos procesÄ….

    ```python
    from sklearn.cluster import KMeans
    wcss = []
    
    for i in range(1, 11):
        kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)
        kmeans.fit(X)
        wcss.append(kmeans.inertia_)
    
    ```

    ÄŒia yra keletas daliÅ³, kurias verta paaiÅ¡kinti.

    > ğŸ“ range: Tai yra klasterizacijos proceso iteracijos.

    > ğŸ“ random_state: â€Nustato atsitiktiniÅ³ skaiÄiÅ³ generavimÄ… centroidÅ³ inicializavimui.â€œ [Å altinis](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)

    > ğŸ“ WCSS: â€klasterio viduje esanÄiÅ³ kvadratÅ³ sumaâ€œ matuoja vidutinÄ¯ kvadratinÄ¯ atstumÄ… tarp visÅ³ taÅ¡kÅ³ klasteryje ir klasterio centro. [Å altinis](https://medium.com/@ODSC/unsupervised-learning-evaluating-clusters-bd47eed175ce).

    > ğŸ“ Inercija: K-Means algoritmai bando pasirinkti centroidus, kad sumaÅ¾intÅ³ â€inercijÄ…â€œ, â€matuojanÄiÄ…, kaip viduje klasteriai yra nuoseklÅ«sâ€œ. [Å altinis](https://scikit-learn.org/stable/modules/clustering.html). ReikÅ¡mÄ— pridedama prie wcss kintamojo kiekvienoje iteracijoje.

    > ğŸ“ k-means++: Naudojant [Scikit-learn](https://scikit-learn.org/stable/modules/clustering.html#k-means), galite naudoti â€k-means++â€œ optimizacijÄ…, kuri â€inicializuoja centroidus taip, kad jie bÅ«tÅ³ (paprastai) nutolÄ™ vienas nuo kito, o tai daÅ¾niausiai duoda geresnius rezultatus nei atsitiktinÄ— inicializacijaâ€œ.

### AlkÅ«nÄ—s metodas

AnksÄiau nusprendÄ—te, kad, kadangi taikote 3 dainÅ³ Å¾anrus, turÄ—tumÄ—te pasirinkti 3 klasterius. Bet ar tikrai?

1. Naudokite â€alkÅ«nÄ—s metodÄ…â€œ, kad Ä¯sitikintumÄ—te.

    ```python
    plt.figure(figsize=(10,5))
    sns.lineplot(x=range(1, 11), y=wcss, marker='o', color='red')
    plt.title('Elbow')
    plt.xlabel('Number of clusters')
    plt.ylabel('WCSS')
    plt.show()
    ```

    Naudokite `wcss` kintamÄ…jÄ¯, kurÄ¯ sukÅ«rÄ—te ankstesniame Å¾ingsnyje, kad sukurtumÄ—te diagramÄ…, rodanÄiÄ…, kur yra â€alkÅ«nÄ—sâ€œ lenkimas, kuris nurodo optimalÅ³ klasteriÅ³ skaiÄiÅ³. GalbÅ«t tai **tikrai** yra 3!

    ![alkÅ«nÄ—s metodas](../../../../5-Clustering/2-K-Means/images/elbow.png)

## UÅ¾duotis - klasteriÅ³ atvaizdavimas

1. Pakartokite procesÄ…, Å¡Ä¯ kartÄ… nustatydami tris klasterius, ir atvaizduokite juos kaip sklaidos diagramÄ…:

    ```python
    from sklearn.cluster import KMeans
    kmeans = KMeans(n_clusters = 3)
    kmeans.fit(X)
    labels = kmeans.predict(X)
    plt.scatter(df['popularity'],df['danceability'],c = labels)
    plt.xlabel('popularity')
    plt.ylabel('danceability')
    plt.show()
    ```

1. Patikrinkite modelio tikslumÄ…:

    ```python
    labels = kmeans.labels_
    
    correct_labels = sum(y == labels)
    
    print("Result: %d out of %d samples were correctly labeled." % (correct_labels, y.size))
    
    print('Accuracy score: {0:0.2f}'. format(correct_labels/float(y.size)))
    ```

    Å io modelio tikslumas nÄ—ra labai geras, o klasteriÅ³ forma leidÅ¾ia suprasti, kodÄ—l.

    ![klasteriai](../../../../5-Clustering/2-K-Means/images/clusters.png)

    Å ie duomenys yra per daug nesubalansuoti, per maÅ¾ai susijÄ™, o stulpeliÅ³ reikÅ¡miÅ³ dispersija yra per didelÄ—, kad bÅ«tÅ³ galima gerai klasterizuoti. IÅ¡ tiesÅ³, susiformavÄ™ klasteriai tikriausiai yra stipriai paveikti arba iÅ¡kreipti trijÅ³ Å¾anrÅ³ kategorijÅ³, kurias apibrÄ—Å¾Ä—me aukÅ¡Äiau. Tai buvo mokymosi procesas!

    Scikit-learn dokumentacijoje galite matyti, kad modelis, kaip Å¡is, su prastai apibrÄ—Å¾tais klasteriais, turi â€dispersijosâ€œ problemÄ…:

    ![probleminiai modeliai](../../../../5-Clustering/2-K-Means/images/problems.png)
    > Infografikas iÅ¡ Scikit-learn

## Dispersija

Dispersija apibrÄ—Å¾iama kaip â€vidutinÄ— kvadratiniÅ³ skirtumÅ³ nuo vidurkio reikÅ¡mÄ—â€œ [(Å altinis)](https://www.mathsisfun.com/data/standard-deviation.html). Å ios klasterizacijos problemos kontekste tai reiÅ¡kia, kad mÅ«sÅ³ duomenÅ³ reikÅ¡mÄ—s per daug nutolsta nuo vidurkio.

âœ… Tai puikus momentas pagalvoti apie visus bÅ«dus, kaip galÄ—tumÄ—te iÅ¡sprÄ™sti Å¡iÄ… problemÄ…. Patobulinti duomenis? Naudoti kitus stulpelius? IÅ¡bandyti kitÄ… algoritmÄ…? UÅ¾uomina: pabandykite [normalizuoti savo duomenis](https://www.mygreatlearning.com/blog/learning-data-science-with-k-means-clustering/) ir iÅ¡bandyti kitus stulpelius.

> IÅ¡bandykite Å¡Ä¯ '[dispersijos skaiÄiuoklÄ™](https://www.calculatorsoup.com/calculators/statistics/variance-calculator.php)', kad geriau suprastumÄ—te Å¡iÄ… sÄ…vokÄ….

---

## ğŸš€IÅ¡Å¡Å«kis

Praleiskite Å¡iek tiek laiko su Å¡iuo uÅ¾raÅ¡Å³ knygeliu, keisdami parametrus. Ar galite pagerinti modelio tikslumÄ…, dar labiau iÅ¡valydami duomenis (pavyzdÅ¾iui, paÅ¡alindami iÅ¡skirtis)? Galite naudoti svorius, kad suteiktumÄ—te daugiau reikÅ¡mÄ—s tam tikriems duomenÅ³ mÄ—giniams. KÄ… dar galite padaryti, kad sukurtumÄ—te geresnius klasterius?

UÅ¾uomina: pabandykite normalizuoti savo duomenis. UÅ¾raÅ¡Å³ knygelÄ—je yra pakomentuotas kodas, kuris prideda standartinÄ¯ mastelio keitimÄ…, kad duomenÅ³ stulpeliai bÅ«tÅ³ panaÅ¡esni pagal diapazonÄ…. PastebÄ—site, kad nors silueto Ä¯vertinimas sumaÅ¾Ä—ja, â€alkÅ«nÄ—sâ€œ grafiko lenkimas tampa lygesnis. Taip yra todÄ—l, kad palikus duomenis nenormalizuotus, maÅ¾esnÄ—s dispersijos duomenys turi didesnÄ™ Ä¯takÄ…. PlaÄiau apie Å¡iÄ… problemÄ… skaitykite [Äia](https://stats.stackexchange.com/questions/21222/are-mean-normalization-and-feature-scaling-needed-for-k-means-clustering/21226#21226).

## [Po paskaitos - testas](https://ff-quizzes.netlify.app/en/ml/)

## ApÅ¾valga ir savarankiÅ¡kas mokymasis

PaÅ¾velkite Ä¯ K-Means simuliatoriÅ³ [tokÄ¯ kaip Å¡is](https://user.ceng.metu.edu.tr/~akifakkus/courses/ceng574/k-means/). Naudodami Å¡Ä¯ Ä¯rankÄ¯ galite vizualizuoti pavyzdinius duomenÅ³ taÅ¡kus ir nustatyti jÅ³ centroidus. Galite redaguoti duomenÅ³ atsitiktinumÄ…, klasteriÅ³ skaiÄiÅ³ ir centroidÅ³ skaiÄiÅ³. Ar tai padeda geriau suprasti, kaip duomenys gali bÅ«ti grupuojami?

Taip pat perÅ¾iÅ«rÄ—kite [Å¡Ä¯ Stanfordo K-Means vadovÄ…](https://stanford.edu/~cpiech/cs221/handouts/kmeans.html).

## UÅ¾duotis

[IÅ¡bandykite skirtingus klasterizacijos metodus](assignment.md)

---

**AtsakomybÄ—s apribojimas**:  
Å is dokumentas buvo iÅ¡verstas naudojant AI vertimo paslaugÄ… [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, praÅ¡ome atkreipti dÄ—mesÄ¯, kad automatiniai vertimai gali turÄ—ti klaidÅ³ ar netikslumÅ³. Originalus dokumentas jo gimtÄ…ja kalba turÄ—tÅ³ bÅ«ti laikomas autoritetingu Å¡altiniu. Kritinei informacijai rekomenduojama naudoti profesionalÅ³ Å¾mogaus vertimÄ…. Mes neprisiimame atsakomybÄ—s uÅ¾ nesusipratimus ar klaidingus aiÅ¡kinimus, atsiradusius dÄ—l Å¡io vertimo naudojimo.