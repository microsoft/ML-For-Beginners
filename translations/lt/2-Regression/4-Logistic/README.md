<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "72b5bae0879baddf6aafc82bb07b8776",
  "translation_date": "2025-09-03T16:25:42+00:00",
  "source_file": "2-Regression/4-Logistic/README.md",
  "language_code": "lt"
}
-->
# LogistinÄ— regresija kategorijoms prognozuoti

![LogistinÄ— vs. linijinÄ— regresija infografikas](../../../../translated_images/linear-vs-logistic.ba180bf95e7ee66721ba10ebf2dac2666acbd64a88b003c83928712433a13c7d.lt.png)

## [PrieÅ¡ paskaitÄ… atlikite testÄ…](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/15/)

> ### [Å i pamoka taip pat prieinama R kalba!](../../../../2-Regression/4-Logistic/solution/R/lesson_4.html)

## Ä®vadas

Å ioje paskutinÄ—je pamokoje apie regresijÄ…, vienÄ… iÅ¡ pagrindiniÅ³ _klasikiniÅ³_ maÅ¡ininio mokymosi technikÅ³, aptarsime logistinÄ™ regresijÄ…. Å i technika naudojama norint atrasti dÄ—sningumus, leidÅ¾ianÄius prognozuoti dvejetaines kategorijas. Ar Å¡is saldainis yra Å¡okoladas, ar ne? Ar Å¡i liga yra uÅ¾kreÄiama, ar ne? Ar Å¡is klientas pasirinks Å¡Ä¯ produktÄ…, ar ne?

Å ioje pamokoje suÅ¾inosite:

- NaujÄ… bibliotekÄ… duomenÅ³ vizualizacijai
- LogistinÄ—s regresijos technikas

âœ… Gilinkite savo supratimÄ… apie darbÄ… su Å¡io tipo regresija Å¡iame [mokymosi modulyje](https://docs.microsoft.com/learn/modules/train-evaluate-classification-models?WT.mc_id=academic-77952-leestott)

## PrieÅ¡ pradedant

Dirbdami su moliÅ«gÅ³ duomenimis, jau esame pakankamai susipaÅ¾inÄ™ su jais, kad pastebÄ—tume vienÄ… dvejetainÄ™ kategorijÄ…, su kuria galime dirbti: `Spalva`.

Sukurkime logistinÄ¯ regresijos modelÄ¯, kuris prognozuotÅ³, kokia spalva greiÄiausiai bus tam tikras moliÅ«gas (oranÅ¾inis ğŸƒ ar baltas ğŸ‘»).

> KodÄ—l kalbame apie dvejetainÄ™ klasifikacijÄ… pamokoje apie regresijÄ…? Tik dÄ—l lingvistinio patogumo, nes logistinÄ— regresija yra [iÅ¡ tikrÅ³jÅ³ klasifikacijos metodas](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression), nors ir pagrÄ¯stas linijine metodologija. SuÅ¾inokite apie kitus duomenÅ³ klasifikavimo bÅ«dus kitoje pamokÅ³ grupÄ—je.

## ApibrÄ—Å¾kime klausimÄ…

MÅ«sÅ³ tikslams iÅ¡reikÅ¡ime tai kaip dvejetainÄ¯ klausimÄ…: â€Baltaâ€œ arba â€Ne baltaâ€œ. MÅ«sÅ³ duomenÅ³ rinkinyje taip pat yra â€dryÅ¾uotaâ€œ kategorija, taÄiau jos pavyzdÅ¾iÅ³ yra nedaug, todÄ—l jos nenaudosime. Ji vis tiek iÅ¡nyksta, kai paÅ¡aliname trÅ«kstamas reikÅ¡mes iÅ¡ duomenÅ³ rinkinio.

> ğŸƒ Smagus faktas: baltus moliÅ«gus kartais vadiname â€vaiduokliÅ³â€œ moliÅ«gais. Juos nÄ—ra lengva iÅ¡skaptuoti, todÄ—l jie nÄ—ra tokie populiarÅ«s kaip oranÅ¾iniai, bet atrodo labai Ä¯domiai! Taigi, galÄ—tume reformuluoti savo klausimÄ… kaip: â€Vaiduoklisâ€œ arba â€Ne vaiduoklisâ€œ. ğŸ‘»

## Apie logistinÄ™ regresijÄ…

LogistinÄ— regresija skiriasi nuo linijinÄ—s regresijos, apie kuriÄ… jau mokÄ—tÄ—s, keliais svarbiais aspektais.

[![Pradedantiesiems apie ML - LogistinÄ—s regresijos supratimas maÅ¡ininio mokymosi klasifikacijai](https://img.youtube.com/vi/KpeCT6nEpBY/0.jpg)](https://youtu.be/KpeCT6nEpBY "Pradedantiesiems apie ML - LogistinÄ—s regresijos supratimas maÅ¡ininio mokymosi klasifikacijai")

> ğŸ¥ SpustelÄ—kite aukÅ¡Äiau esanÄiÄ… nuotraukÄ…, kad perÅ¾iÅ«rÄ—tumÄ—te trumpÄ… vaizdo Ä¯raÅ¡Ä… apie logistinÄ—s regresijos apÅ¾valgÄ….

### DvejetainÄ— klasifikacija

LogistinÄ— regresija nepasiÅ«lo tÅ³ paÄiÅ³ galimybiÅ³ kaip linijinÄ— regresija. Pirmoji pateikia prognozÄ™ apie dvejetainÄ™ kategorijÄ… (â€balta arba ne baltaâ€œ), o antroji gali prognozuoti tÄ™stines reikÅ¡mes, pavyzdÅ¾iui, atsiÅ¾velgiant Ä¯ moliÅ«go kilmÄ™ ir derliaus nuÄ—mimo laikÄ…, _kaip kils jo kaina_.

![MoliÅ«gÅ³ klasifikavimo modelis](../../../../translated_images/pumpkin-classifier.562771f104ad5436b87d1c67bca02a42a17841133556559325c0a0e348e5b774.lt.png)
> Infografikas sukurtas [Dasani Madipalli](https://twitter.com/dasani_decoded)

### Kitos klasifikacijos

Yra ir kitÅ³ logistinÄ—s regresijos tipÅ³, Ä¯skaitant daugianarÄ™ ir eilinÄ™:

- **DaugianarÄ—**, kuri apima daugiau nei vienÄ… kategorijÄ… - â€OranÅ¾inÄ—, Balta ir DryÅ¾uotaâ€œ.
- **EilinÄ—**, kuri apima tvarkingas kategorijas, naudingas, jei norime logiÅ¡kai iÅ¡dÄ—styti rezultatus, pavyzdÅ¾iui, mÅ«sÅ³ moliÅ«gus, kurie yra iÅ¡dÄ—styti pagal ribotÄ… dydÅ¾iÅ³ skaiÄiÅ³ (mini, maÅ¾as, vidutinis, didelis, labai didelis, ypaÄ didelis).

![DaugianarÄ— vs eilinÄ— regresija](../../../../translated_images/multinomial-vs-ordinal.36701b4850e37d86c9dd49f7bef93a2f94dbdb8fe03443eb68f0542f97f28f29.lt.png)

### Kintamieji NETURI bÅ«ti koreliuoti

Prisiminkite, kaip linijinÄ— regresija geriau veikÄ— su labiau koreliuotais kintamaisiais? LogistinÄ— regresija yra prieÅ¡inga â€“ kintamieji neturi bÅ«ti suderinti. Tai tinka Å¡iems duomenims, kuriuose koreliacijos yra gana silpnos.

### Reikia daug Å¡variÅ³ duomenÅ³

LogistinÄ— regresija pateiks tikslesnius rezultatus, jei naudosite daugiau duomenÅ³; mÅ«sÅ³ maÅ¾as duomenÅ³ rinkinys nÄ—ra optimalus Å¡iai uÅ¾duoÄiai, todÄ—l tai turÄ—kite omenyje.

[![Pradedantiesiems apie ML - DuomenÅ³ analizÄ— ir paruoÅ¡imas logistinei regresijai](https://img.youtube.com/vi/B2X4H9vcXTs/0.jpg)](https://youtu.be/B2X4H9vcXTs "Pradedantiesiems apie ML - DuomenÅ³ analizÄ— ir paruoÅ¡imas logistinei regresijai")

âœ… Pagalvokite apie duomenÅ³ tipus, kurie geriausiai tiktÅ³ logistinei regresijai

## UÅ¾duotis â€“ sutvarkykite duomenis

Pirmiausia Å¡iek tiek iÅ¡valykite duomenis, paÅ¡alindami trÅ«kstamas reikÅ¡mes ir pasirinkdami tik kai kuriuos stulpelius:

1. PridÄ—kite Å¡Ä¯ kodÄ…:

    ```python
  
    columns_to_select = ['City Name','Package','Variety', 'Origin','Item Size', 'Color']
    pumpkins = full_pumpkins.loc[:, columns_to_select]

    pumpkins.dropna(inplace=True)
    ```

    Visada galite paÅ¾velgti Ä¯ savo naujÄ… duomenÅ³ rÄ—melÄ¯:

    ```python
    pumpkins.info
    ```

### Vizualizacija â€“ kategorinis grafikas

Iki Å¡iol jÅ«s jau Ä¯kÄ—lÄ—te [pradinÄ¯ uÅ¾raÅ¡Å³ knygelÄ™](./notebook.ipynb) su moliÅ«gÅ³ duomenimis ir iÅ¡valÄ—te jÄ… taip, kad iÅ¡saugotumÄ—te duomenÅ³ rinkinÄ¯, kuriame yra keli kintamieji, Ä¯skaitant `SpalvÄ…`. Vizualizuokime duomenÅ³ rÄ—melÄ¯ uÅ¾raÅ¡Å³ knygelÄ—je naudodami kitÄ… bibliotekÄ…: [Seaborn](https://seaborn.pydata.org/index.html), kuri yra sukurta ant Matplotlib, kurÄ¯ naudojome anksÄiau.

Seaborn siÅ«lo Ä¯domiÅ³ bÅ«dÅ³ vizualizuoti jÅ«sÅ³ duomenis. PavyzdÅ¾iui, galite palyginti duomenÅ³ pasiskirstymÄ… pagal kiekvienÄ… `Variety` ir `Color` kategorijÄ… kategoriniame grafike.

1. Sukurkite tokÄ¯ grafikÄ… naudodami `catplot` funkcijÄ…, naudodami mÅ«sÅ³ moliÅ«gÅ³ duomenis `pumpkins` ir nurodydami spalvÅ³ Å¾ymÄ—jimÄ… kiekvienai moliÅ«gÅ³ kategorijai (oranÅ¾inÄ— arba balta):

    ```python
    import seaborn as sns
    
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }

    sns.catplot(
    data=pumpkins, y="Variety", hue="Color", kind="count",
    palette=palette, 
    )
    ```

    ![DuomenÅ³ vizualizacijos tinklelis](../../../../translated_images/pumpkins_catplot_1.c55c409b71fea2ecc01921e64b91970542101f90bcccfa4aa3a205db8936f48b.lt.png)

    StebÄ—dami duomenis galite pamatyti, kaip `Spalva` duomenys susijÄ™ su `Variety`.

    âœ… AtsiÅ¾velgiant Ä¯ Å¡Ä¯ kategorinÄ¯ grafikÄ…, kokius Ä¯domius tyrimus galite Ä¯sivaizduoti?

### DuomenÅ³ paruoÅ¡imas: poÅ¾ymiÅ³ ir etikeÄiÅ³ kodavimas
MÅ«sÅ³ moliÅ«gÅ³ duomenÅ³ rinkinyje visi stulpeliai yra tekstiniai. Nors Å¾monÄ—ms dirbti su kategoriniais duomenimis yra intuityvu, maÅ¡inoms tai nÄ—ra taip paprasta. MaÅ¡ininio mokymosi algoritmai geriau veikia su skaiÄiais. TodÄ—l kodavimas yra labai svarbus duomenÅ³ paruoÅ¡imo etapas, nes jis leidÅ¾ia paversti kategorinius duomenis Ä¯ skaitinius, neprarandant jokios informacijos. Geras kodavimas padeda sukurti gerÄ… modelÄ¯.

PoÅ¾ymiÅ³ kodavimui yra du pagrindiniai kodavimo tipai:

1. Ordinalinis koduotojas: jis gerai tinka eiliniams kintamiesiems, kurie yra kategoriniai kintamieji, kuriÅ³ duomenys turi loginÄ™ tvarkÄ…, kaip `Item Size` stulpelis mÅ«sÅ³ duomenÅ³ rinkinyje. Jis sukuria Å¾emÄ—lapÄ¯, kuriame kiekviena kategorija yra atvaizduojama skaiÄiumi, kuris atitinka kategorijos tvarkÄ… stulpelyje.

    ```python
    from sklearn.preprocessing import OrdinalEncoder

    item_size_categories = [['sml', 'med', 'med-lge', 'lge', 'xlge', 'jbo', 'exjbo']]
    ordinal_features = ['Item Size']
    ordinal_encoder = OrdinalEncoder(categories=item_size_categories)
    ```

2. Kategorinis koduotojas: jis gerai tinka nominaliems kintamiesiems, kurie yra kategoriniai kintamieji, kuriÅ³ duomenys neturi loginÄ—s tvarkos, kaip visi kiti poÅ¾ymiai, iÅ¡skyrus `Item Size`, mÅ«sÅ³ duomenÅ³ rinkinyje. Tai yra vieno karÅ¡to kodavimo metodas, kuris reiÅ¡kia, kad kiekviena kategorija yra atvaizduojama dvejetainiu stulpeliu: koduotas kintamasis yra lygus 1, jei moliÅ«gas priklauso tai `Variety`, ir 0, jei ne.

    ```python
    from sklearn.preprocessing import OneHotEncoder

    categorical_features = ['City Name', 'Package', 'Variety', 'Origin']
    categorical_encoder = OneHotEncoder(sparse_output=False)
    ```
Tada `ColumnTransformer` naudojamas keliems koduotojams sujungti Ä¯ vienÄ… Å¾ingsnÄ¯ ir pritaikyti juos tinkamiems stulpeliams.

```python
    from sklearn.compose import ColumnTransformer
    
    ct = ColumnTransformer(transformers=[
        ('ord', ordinal_encoder, ordinal_features),
        ('cat', categorical_encoder, categorical_features)
        ])
    
    ct.set_output(transform='pandas')
    encoded_features = ct.fit_transform(pumpkins)
```
Kita vertus, norint uÅ¾koduoti etiketÄ™, naudojame scikit-learn `LabelEncoder` klasÄ™, kuri yra pagalbinÄ— klasÄ—, padedanti normalizuoti etiketes, kad jos turÄ—tÅ³ tik reikÅ¡mes tarp 0 ir n_classes-1 (Äia, 0 ir 1).

```python
    from sklearn.preprocessing import LabelEncoder

    label_encoder = LabelEncoder()
    encoded_label = label_encoder.fit_transform(pumpkins['Color'])
```
Kai uÅ¾koduojame poÅ¾ymius ir etiketÄ™, galime juos sujungti Ä¯ naujÄ… duomenÅ³ rÄ—melÄ¯ `encoded_pumpkins`.

```python
    encoded_pumpkins = encoded_features.assign(Color=encoded_label)
```
âœ… Kokie yra ordinalinio koduotojo privalumai `Item Size` stulpeliui?

### Analizuokite kintamÅ³jÅ³ tarpusavio ryÅ¡ius

Dabar, kai paruoÅ¡Ä—me savo duomenis, galime analizuoti poÅ¾ymiÅ³ ir etiketÄ—s tarpusavio ryÅ¡ius, kad suprastume, kaip gerai modelis galÄ—s prognozuoti etiketÄ™ pagal poÅ¾ymius.
Geriausias bÅ«das atlikti tokiÄ… analizÄ™ yra duomenÅ³ vizualizavimas. Naudosime Seaborn `catplot` funkcijÄ…, kad vizualizuotume `Item Size`, `Variety` ir `Color` tarpusavio ryÅ¡ius kategoriniame grafike. NorÄ—dami geriau vizualizuoti duomenis, naudosime uÅ¾koduotÄ… `Item Size` stulpelÄ¯ ir neuÅ¾koduotÄ… `Variety` stulpelÄ¯.

```python
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }
    pumpkins['Item Size'] = encoded_pumpkins['ord__Item Size']

    g = sns.catplot(
        data=pumpkins,
        x="Item Size", y="Color", row='Variety',
        kind="box", orient="h",
        sharex=False, margin_titles=True,
        height=1.8, aspect=4, palette=palette,
    )
    g.set(xlabel="Item Size", ylabel="").set(xlim=(0,6))
    g.set_titles(row_template="{row_name}")
```
![Kategorinis grafikas](../../../../translated_images/pumpkins_catplot_2.87a354447880b3889278155957f8f60dd63db4598de5a6d0fda91c334d31f9f1.lt.png)

### Naudokite â€swarmâ€œ grafikÄ…

Kadangi `Color` yra dvejetainÄ— kategorija (Balta arba Ne), jai reikia â€[specialaus poÅ¾iÅ«rio](https://seaborn.pydata.org/tutorial/categorical.html?highlight=bar) vizualizacijaiâ€œ. Yra ir kitÅ³ bÅ«dÅ³ vizualizuoti Å¡ios kategorijos ryÅ¡Ä¯ su kitais kintamaisiais.

Galite vizualizuoti kintamuosius Å¡alia vienas kito naudodami Seaborn grafikus.

1. IÅ¡bandykite â€swarmâ€œ grafikÄ…, kad parodytumÄ—te reikÅ¡miÅ³ pasiskirstymÄ…:

    ```python
    palette = {
    0: 'orange',
    1: 'wheat'
    }
    sns.swarmplot(x="Color", y="ord__Item Size", data=encoded_pumpkins, palette=palette)
    ```

    ![Swarm grafikas](../../../../translated_images/swarm_2.efeacfca536c2b577dc7b5f8891f28926663fbf62d893ab5e1278ae734ca104e.lt.png)

**Atkreipkite dÄ—mesÄ¯**: aukÅ¡Äiau pateiktas kodas gali sugeneruoti Ä¯spÄ—jimÄ…, nes Seaborn nepavyksta atvaizduoti tokio kiekio duomenÅ³ taÅ¡kÅ³ â€swarmâ€œ grafike. Galimas sprendimas yra sumaÅ¾inti Å¾ymeklio dydÄ¯ naudojant â€sizeâ€œ parametrÄ…. TaÄiau atkreipkite dÄ—mesÄ¯, kad tai gali paveikti grafiko skaitomumÄ….

> **ğŸ§® Parodykite matematikÄ…**
>
> LogistinÄ— regresija remiasi â€maksimalaus tikÄ—tinumoâ€œ koncepcija, naudojant [sigmoidines funkcijas](https://wikipedia.org/wiki/Sigmoid_function). SigmoidinÄ— funkcija grafike atrodo kaip â€Sâ€œ formos kreivÄ—. Ji priima reikÅ¡mÄ™ ir priskiria jÄ… intervalui tarp 0 ir 1. Jos kreivÄ— taip pat vadinama â€logistine kreiveâ€œ. Jos formulÄ— atrodo taip:
>
> ![logistinÄ— funkcija](../../../../translated_images/sigmoid.8b7ba9d095c789cf72780675d0d1d44980c3736617329abfc392dfc859799704.lt.png)
>
> kur sigmoidÄ—s vidurys yra ties x = 0, L yra kreivÄ—s maksimali reikÅ¡mÄ—, o k yra kreivÄ—s staigumas. Jei funkcijos rezultatas yra didesnis nei 0,5, atitinkama etiketÄ— bus priskirta klasei â€1â€œ iÅ¡ dvejetainio pasirinkimo. Jei ne, ji bus priskirta klasei â€0â€œ.

## Sukurkite savo modelÄ¯

Sukurti modelÄ¯, skirtÄ… Å¡iai dvejetainiai klasifikacijai, yra stebÄ—tinai paprasta naudojant Scikit-learn.

[![Pradedantiesiems apie ML - LogistinÄ— regresija duomenÅ³ klasifikacijai](https://img.youtube.com/vi/MmZS2otPrQ8/0.jpg)](https://youtu.be/MmZS2otPrQ8 "Pradedantiesiems apie ML - LogistinÄ— regresija duomenÅ³ klasifikacijai")

> ğŸ¥ SpustelÄ—kite aukÅ¡Äiau esanÄiÄ… nuotraukÄ…, kad perÅ¾iÅ«rÄ—tumÄ—te trumpÄ… vaizdo Ä¯raÅ¡Ä… apie logistinÄ—s regresijos modelio kÅ«rimÄ…

1. Pasirinkite kintamuosius, kuriuos norite naudoti savo klasifikacijos modelyje, ir padalykite mokymo ir testavimo rinkinius, iÅ¡kviesdami `train_test_split()`:

    ```python
    from sklearn.model_selection import train_test_split
    
    X = encoded_pumpkins[encoded_pumpkins.columns.difference(['Color'])]
    y = encoded_pumpkins['Color']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
    
    ```

2. Dabar galite apmokyti savo modelÄ¯, iÅ¡kviesdami `fit()` su savo mokymo duomenimis, ir iÅ¡spausdinkite jo rezultatÄ…:

    ```python
    from sklearn.metrics import f1_score, classification_report 
    from sklearn.linear_model import LogisticRegression

    model = LogisticRegression()
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)

    print(classification_report(y_test, predictions))
    print('Predicted labels: ', predictions)
    print('F1-score: ', f1_score(y_test, predictions))
    ```

    PaÅ¾velkite Ä¯ savo modelio rezultatÅ³ lentelÄ™. Ji nÄ—ra bloga, atsiÅ¾velgiant Ä¯ tai, kad turite tik apie 1000 eiluÄiÅ³ duomenÅ³:

    ```output
                       precision    recall  f1-score   support
    
                    0       0.94      0.98      0.96       166
                    1       0.85      0.67      0.75        33
    
        accuracy                                0.92       199
        macro avg           0.89      0.82      0.85       199
        weighted avg        0.92      0.92      0.92       199
    
        Predicted labels:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0
        0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
        1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0
        0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0
        0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
        0 0 0 1 0 0 0 0 0 0 0 0 1 1]
        F1-score:  0.7457627118644068
    ```

## Geresnis supratimas naudojant painiavos matricÄ…

Nors galite gauti rezultatÅ³ lentelÄ™ su [terminais](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html?highlight=classification_report#sklearn.metrics.classification_report), iÅ¡spausdindami aukÅ¡Äiau pateiktus elementus, galbÅ«t galÄ—site geriau suprasti savo modelÄ¯ naudodami [painiavos matricÄ…](https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix), kuri padeda suprasti, kaip modelis veikia.

> ğŸ“ â€[Painiavos matrica](https://wikipedia.org/wiki/Confusion_matrix)â€œ (arba â€klaidÅ³ matricaâ€œ) yra lentelÄ—, kuri iÅ¡reiÅ¡kia jÅ«sÅ³ modelio tikrus ir klaidingus teigiamus bei neigiamus rezultatus, taip Ä¯vertinant prognoziÅ³ tikslumÄ….

1. NorÄ—dami naudoti painiavos matricÄ…, iÅ¡kvieskite `confusion_matrix()`:

    ```python
    from sklearn.metrics import confusion_matrix
    confusion_matrix(y_test, predictions)
    ```

    PaÅ¾velkite Ä¯ savo modelio painiavos matricÄ…:

    ```output
    array([[162,   4],
           [ 11,  22]])
    ```

Scikit-learn painiavos matricose eilutÄ—s (aÅ¡is 0) yra tikros etiketÄ—s, o stulpeliai (aÅ¡is 1) yra prognozuotos etiketÄ—s.

|       |   0   |   1   |
| :---: | :---: | :---: |
|   0   |  TN   |  FP   |
|   1   |  FN   |  TP   |

Kas Äia vyksta? Tarkime, mÅ«sÅ³ modelis yra praÅ¡omas klasifikuoti moliÅ«gus Ä¯ dvi dvejetaines kategorijas: â€baltaâ€œ ir â€ne baltaâ€œ.

- Jei jÅ«sÅ³ modelis prognozuoja, kad moliÅ«gas nÄ—ra baltas, ir jis iÅ¡ tikrÅ³jÅ³ priklauso kategorijai â€ne baltaâ€œ, tai vadiname tikru neigiamu (TN), parodytu virÅ¡utiniame kairiajame kampe.
- Jei jÅ«sÅ³ modelis prognozuoja, kad moliÅ«gas yra baltas, bet jis iÅ¡ tikrÅ³jÅ³ priklauso kategor
Kaip painiavos matrica susijusi su tikslumu ir atÅ¡aukimu? Atminkite, kad aukÅ¡Äiau pateiktoje klasifikacijos ataskaitoje buvo nurodytas tikslumas (0.85) ir atÅ¡aukimas (0.67).

Tikslumas = tp / (tp + fp) = 22 / (22 + 4) = 0.8461538461538461

AtÅ¡aukimas = tp / (tp + fn) = 22 / (22 + 11) = 0.6666666666666666

âœ… Klausimas: Remiantis painiavos matrica, kaip sekÄ—si modeliui? Atsakymas: Ne blogai; yra nemaÅ¾ai teigiamÅ³ neigiamÅ³ atvejÅ³, taÄiau taip pat keletas klaidingÅ³ neigiamÅ³ atvejÅ³.

GrÄ¯Å¾kime prie terminÅ³, kuriuos matÄ—me anksÄiau, pasitelkdami painiavos matricos TP/TN ir FP/FN Å¾ymÄ—jimÄ…:

ğŸ“ Tikslumas: TP/(TP + FP) ReikÅ¡mingÅ³ atvejÅ³ dalis tarp gautÅ³ atvejÅ³ (pvz., kurie Å¾ymÄ—jimai buvo gerai paÅ¾ymÄ—ti)

ğŸ“ AtÅ¡aukimas: TP/(TP + FN) ReikÅ¡mingÅ³ atvejÅ³ dalis, kurie buvo gauti, nesvarbu, ar jie buvo gerai paÅ¾ymÄ—ti, ar ne

ğŸ“ f1-rezultatas: (2 * tikslumas * atÅ¡aukimas)/(tikslumas + atÅ¡aukimas) Tikslumo ir atÅ¡aukimo svertinis vidurkis, geriausias rezultatas yra 1, o blogiausias â€“ 0

ğŸ“ Palaikymas: Kiekvieno gauto Å¾ymÄ—jimo pasikartojimÅ³ skaiÄius

ğŸ“ Tikslumas: (TP + TN)/(TP + TN + FP + FN) Procentas Å¾ymÄ—jimÅ³, kurie buvo tiksliai numatyti pavyzdyje.

ğŸ“ Makro vidurkis: NeÄ¯vertintas kiekvieno Å¾ymÄ—jimo metrikÅ³ vidurkio skaiÄiavimas, neatsiÅ¾velgiant Ä¯ Å¾ymÄ—jimÅ³ disbalansÄ….

ğŸ“ Svertinis vidurkis: Kiekvieno Å¾ymÄ—jimo metrikÅ³ vidurkio skaiÄiavimas, atsiÅ¾velgiant Ä¯ Å¾ymÄ—jimÅ³ disbalansÄ…, sveriant juos pagal palaikymÄ… (tikrÅ³ atvejÅ³ skaiÄiÅ³ kiekvienam Å¾ymÄ—jimui).

âœ… Ar galite pagalvoti, kuriÄ… metrikÄ… reikÄ—tÅ³ stebÄ—ti, jei norite, kad jÅ«sÅ³ modelis sumaÅ¾intÅ³ klaidingÅ³ neigiamÅ³ atvejÅ³ skaiÄiÅ³?

## Vizualizuokite Å¡io modelio ROC kreivÄ™

[![ML pradedantiesiems - LogistinÄ—s regresijos naÅ¡umo analizÄ— su ROC kreivÄ—mis](https://img.youtube.com/vi/GApO575jTA0/0.jpg)](https://youtu.be/GApO575jTA0 "ML pradedantiesiems - LogistinÄ—s regresijos naÅ¡umo analizÄ— su ROC kreivÄ—mis")

> ğŸ¥ SpustelÄ—kite aukÅ¡Äiau esanÄiÄ… nuotraukÄ…, kad perÅ¾iÅ«rÄ—tumÄ—te trumpÄ… vaizdo Ä¯raÅ¡Ä… apie ROC kreives

Atlikime dar vienÄ… vizualizacijÄ…, kad pamatytume vadinamÄ…jÄ… â€ROCâ€œ kreivÄ™:

```python
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline

y_scores = model.predict_proba(X_test)
fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])

fig = plt.figure(figsize=(6, 6))
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.show()
```

Naudodami Matplotlib, nubrÄ—Å¾kite modelio [Gavimo veikimo charakteristikos](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html?highlight=roc) arba ROC kreivÄ™. ROC kreivÄ—s daÅ¾nai naudojamos norint pamatyti klasifikatoriaus iÅ¡vestÄ¯ pagal tikrus ir klaidingus teigiamus atvejus. â€ROC kreivÄ—se paprastai Y aÅ¡yje vaizduojamas tikrÅ³ teigiamÅ³ atvejÅ³ rodiklis, o X aÅ¡yje â€“ klaidingÅ³ teigiamÅ³ atvejÅ³ rodiklis.â€œ Taigi kreivÄ—s staigumas ir erdvÄ— tarp vidurio linijos ir kreivÄ—s yra svarbÅ«s: norite kreivÄ—s, kuri greitai kyla aukÅ¡tyn ir virÅ¡ linijos. MÅ«sÅ³ atveju pradÅ¾ioje yra klaidingÅ³ teigiamÅ³ atvejÅ³, o tada linija tinkamai kyla aukÅ¡tyn ir virÅ¡.

![ROC](../../../../translated_images/ROC_2.777f20cdfc4988ca683ade6850ac832cb70c96c12f1b910d294f270ef36e1a1c.lt.png)

Galiausiai naudokite Scikit-learn [`roc_auc_score` API](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html?highlight=roc_auc#sklearn.metrics.roc_auc_score), kad apskaiÄiuotumÄ—te faktinÄ™ â€PlotÄ… po kreiveâ€œ (AUC):

```python
auc = roc_auc_score(y_test,y_scores[:,1])
print(auc)
```
Rezultatas yra `0.9749908725812341`. Kadangi AUC svyruoja nuo 0 iki 1, norite didelio rezultato, nes modelis, kuris 100% tiksliai numato, turÄ—s AUC lygiÄ… 1; Å¡iuo atveju modelis yra _gana geras_.

BÅ«simose klasifikacijos pamokose suÅ¾inosite, kaip iteruoti, kad pagerintumÄ—te savo modelio rezultatus. Bet kol kas â€“ sveikiname! JÅ«s baigÄ—te Å¡ias regresijos pamokas!

---
## ğŸš€IÅ¡Å¡Å«kis

LogistinÄ—je regresijoje yra daug kÄ… iÅ¡nagrinÄ—ti! TaÄiau geriausias bÅ«das mokytis yra eksperimentuoti. Suraskite duomenÅ³ rinkinÄ¯, kuris tinka tokio tipo analizei, ir sukurkite modelÄ¯. KÄ… suÅ¾inote? Patarimas: pabandykite [Kaggle](https://www.kaggle.com/search?q=logistic+regression+datasets) ieÅ¡koti Ä¯domiÅ³ duomenÅ³ rinkiniÅ³.

## [Po paskaitos testas](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/16/)

## ApÅ¾valga ir savarankiÅ¡kas mokymasis

Perskaitykite pirmuosius kelis [Å¡io Stanfordo dokumento](https://web.stanford.edu/~jurafsky/slp3/5.pdf) puslapius apie praktinius logistinÄ—s regresijos panaudojimo bÅ«dus. Pagalvokite apie uÅ¾duotis, kurios geriau tinka vienam ar kitam regresijos tipui, kuriuos studijavome iki Å¡iol. Kas veiktÅ³ geriausiai?

## UÅ¾duotis

[Pakartokite Å¡iÄ… regresijÄ…](assignment.md)

---

**AtsakomybÄ—s apribojimas**:  
Å is dokumentas buvo iÅ¡verstas naudojant dirbtinio intelekto vertimo paslaugÄ… [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, atkreipiame dÄ—mesÄ¯, kad automatiniai vertimai gali turÄ—ti klaidÅ³ ar netikslumÅ³. Originalus dokumentas jo gimtÄ…ja kalba turÄ—tÅ³ bÅ«ti laikomas autoritetingu Å¡altiniu. Kritinei informacijai rekomenduojama naudotis profesionaliÅ³ vertÄ—jÅ³ paslaugomis. Mes neprisiimame atsakomybÄ—s uÅ¾ nesusipratimus ar klaidingus aiÅ¡kinimus, kylanÄius dÄ—l Å¡io vertimo naudojimo.