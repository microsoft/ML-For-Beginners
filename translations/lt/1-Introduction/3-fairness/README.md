<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "9a6b702d1437c0467e3c5c28d763dac2",
  "translation_date": "2025-09-05T07:55:02+00:00",
  "source_file": "1-Introduction/3-fairness/README.md",
  "language_code": "lt"
}
-->
# Kuriant maÅ¡ininio mokymosi sprendimus su atsakingu dirbtiniu intelektu

![Atsakingo dirbtinio intelekto maÅ¡ininio mokymosi santrauka sketchnote](../../../../sketchnotes/ml-fairness.png)
> Sketchnote sukÅ«rÄ— [Tomomi Imura](https://www.twitter.com/girlie_mac)

## [PrieÅ¡ paskaitÄ… atlikite testÄ…](https://ff-quizzes.netlify.app/en/ml/)

## Ä®vadas

Å ioje mokymo programoje pradÄ—site suprasti, kaip maÅ¡ininis mokymasis veikia mÅ«sÅ³ kasdienÄ¯ gyvenimÄ…. Jau dabar sistemos ir modeliai dalyvauja kasdieniuose sprendimÅ³ priÄ—mimo procesuose, tokiuose kaip sveikatos prieÅ¾iÅ«ros diagnozÄ—s, paskolÅ³ patvirtinimai ar sukÄiavimo aptikimas. TodÄ—l svarbu, kad Å¡ie modeliai veiktÅ³ patikimai ir teiktÅ³ patikimus rezultatus. Kaip ir bet kuri programinÄ— Ä¯ranga, dirbtinio intelekto sistemos gali neatitikti lÅ«kesÄiÅ³ arba turÄ—ti nepageidaujamÅ³ rezultatÅ³. TodÄ—l bÅ«tina suprasti ir paaiÅ¡kinti dirbtinio intelekto modelio elgesÄ¯.

Ä®sivaizduokite, kas gali nutikti, kai duomenys, kuriuos naudojate modeliÅ³ kÅ«rimui, neturi tam tikrÅ³ demografiniÅ³ duomenÅ³, tokiÅ³ kaip rasÄ—, lytis, politinÄ—s paÅ¾iÅ«ros, religija, arba neproporcingai atspindi Å¡iuos demografinius duomenis. O kas, jei modelio rezultatai yra interpretuojami taip, kad jie palankÅ«s tam tikrai demografinei grupei? Kokios pasekmÄ—s tai gali turÄ—ti programai? Be to, kas nutinka, kai modelis sukelia neigiamÄ… rezultatÄ… ir yra Å¾alingas Å¾monÄ—ms? Kas atsakingas uÅ¾ dirbtinio intelekto sistemos elgesÄ¯? Tai yra klausimai, kuriuos nagrinÄ—sime Å¡ioje mokymo programoje.

Å ioje pamokoje jÅ«s:

- Suprasite, kodÄ—l svarbu uÅ¾tikrinti teisingumÄ… maÅ¡ininiame mokymesi ir iÅ¡vengti su tuo susijusiÅ³ Å¾alingÅ³ pasekmiÅ³.
- SusipaÅ¾insite su praktika, kaip analizuoti iÅ¡skirtinius atvejus ir neÄ¯prastas situacijas, siekiant uÅ¾tikrinti patikimumÄ… ir saugumÄ….
- Suprasite, kodÄ—l bÅ«tina kurti Ä¯traukias sistemas, kurios suteikia galimybes visiems.
- IÅ¡nagrinÄ—site, kodÄ—l svarbu apsaugoti duomenÅ³ ir Å¾moniÅ³ privatumÄ… bei saugumÄ….
- Suprasite, kodÄ—l bÅ«tina turÄ—ti â€stiklinÄ—s dÄ—Å¾Ä—sâ€œ poÅ¾iÅ«rÄ¯, kad bÅ«tÅ³ galima paaiÅ¡kinti dirbtinio intelekto modeliÅ³ elgesÄ¯.
- BÅ«site sÄ…moningi, kodÄ—l atsakomybÄ— yra bÅ«tina, siekiant sukurti pasitikÄ—jimÄ… dirbtinio intelekto sistemomis.

## Privalomos Å¾inios

PrieÅ¡ pradedant, rekomenduojame perÅ¾iÅ«rÄ—ti â€Atsakingo dirbtinio intelekto principÅ³â€œ mokymo keliÄ… ir paÅ¾iÅ«rÄ—ti Å¾emiau pateiktÄ… vaizdo Ä¯raÅ¡Ä… Å¡ia tema:

SuÅ¾inokite daugiau apie atsakingÄ… dirbtinÄ¯ intelektÄ…, sekdami Å¡Ä¯ [mokymo keliÄ…](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77952-leestott)

[![Microsoft poÅ¾iÅ«ris Ä¯ atsakingÄ… dirbtinÄ¯ intelektÄ…](https://img.youtube.com/vi/dnC8-uUZXSc/0.jpg)](https://youtu.be/dnC8-uUZXSc "Microsoft poÅ¾iÅ«ris Ä¯ atsakingÄ… dirbtinÄ¯ intelektÄ…")

> ğŸ¥ SpustelÄ—kite aukÅ¡Äiau esanÄiÄ… nuotraukÄ…, kad perÅ¾iÅ«rÄ—tumÄ—te vaizdo Ä¯raÅ¡Ä…: Microsoft poÅ¾iÅ«ris Ä¯ atsakingÄ… dirbtinÄ¯ intelektÄ…

## Teisingumas

Dirbtinio intelekto sistemos turÄ—tÅ³ elgtis teisingai su visais ir vengti skirtingo poveikio panaÅ¡ioms Å¾moniÅ³ grupÄ—ms. PavyzdÅ¾iui, kai dirbtinio intelekto sistemos teikia rekomendacijas dÄ—l medicininio gydymo, paskolÅ³ paraiÅ¡kÅ³ ar Ä¯darbinimo, jos turÄ—tÅ³ pateikti tas paÄias rekomendacijas visiems, turintiems panaÅ¡ius simptomus, finansines aplinkybes ar profesinÄ™ kvalifikacijÄ…. Kiekvienas iÅ¡ mÅ«sÅ³, kaip Å¾monÄ—s, turime paveldÄ—tus Å¡aliÅ¡kumus, kurie veikia mÅ«sÅ³ sprendimus ir veiksmus. Å ie Å¡aliÅ¡kumai gali atsispindÄ—ti duomenyse, kuriuos naudojame dirbtinio intelekto sistemÅ³ mokymui. Tokia manipuliacija kartais gali Ä¯vykti netyÄia. DaÅ¾nai sunku sÄ…moningai suvokti, kada Ä¯ duomenis Ä¯vedate Å¡aliÅ¡kumÄ….

**â€Netolygumasâ€œ** apima neigiamÄ… poveikÄ¯ arba â€Å¾alÄ…â€œ Å¾moniÅ³ grupei, pavyzdÅ¾iui, apibrÄ—Å¾tai pagal rasÄ™, lytÄ¯, amÅ¾iÅ³ ar negalios statusÄ…. PagrindinÄ—s su teisingumu susijusios Å¾alos rÅ«Å¡ys gali bÅ«ti klasifikuojamos taip:

- **Paskirstymas**, kai, pavyzdÅ¾iui, lytis ar etninÄ— grupÄ— yra palankesnÄ— uÅ¾ kitÄ….
- **Paslaugos kokybÄ—**. Jei duomenys mokomi tik vienam konkreÄiam scenarijui, taÄiau realybÄ— yra daug sudÄ—tingesnÄ—, tai lemia prastai veikianÄiÄ… paslaugÄ…. PavyzdÅ¾iui, rankÅ³ muilo dozatorius, kuris negali aptikti Å¾moniÅ³ su tamsia oda. [Nuoroda](https://gizmodo.com/why-cant-this-soap-dispenser-identify-dark-skin-1797931773)
- **Menkinimas**. NesÄ…Å¾iningai kritikuoti ir Å¾ymÄ—ti kÄ… nors ar kaÅ¾kÄ…. PavyzdÅ¾iui, vaizdÅ³ Å¾ymÄ—jimo technologija klaidingai paÅ¾ymÄ—jo tamsiaodÅ¾iÅ³ Å¾moniÅ³ nuotraukas kaip gorilas.
- **Perteklinis arba nepakankamas atstovavimas**. IdÄ—ja, kad tam tikra grupÄ— nÄ—ra matoma tam tikroje profesijoje, o bet kokia paslauga ar funkcija, kuri toliau tai skatina, prisideda prie Å¾alos.
- **Stereotipai**. Tam tikros grupÄ—s susiejimas su iÅ¡ anksto priskirtais atributais. PavyzdÅ¾iui, kalbos vertimo sistema tarp anglÅ³ ir turkÅ³ kalbÅ³ gali turÄ—ti netikslumÅ³ dÄ—l Å¾odÅ¾iÅ³, susijusiÅ³ su stereotipiniais lyties ryÅ¡iais.

![vertimas Ä¯ turkÅ³ kalbÄ…](../../../../1-Introduction/3-fairness/images/gender-bias-translate-en-tr.png)
> vertimas Ä¯ turkÅ³ kalbÄ…

![vertimas atgal Ä¯ anglÅ³ kalbÄ…](../../../../1-Introduction/3-fairness/images/gender-bias-translate-tr-en.png)
> vertimas atgal Ä¯ anglÅ³ kalbÄ…

Kuriant ir testuojant dirbtinio intelekto sistemas, turime uÅ¾tikrinti, kad dirbtinis intelektas bÅ«tÅ³ teisingas ir neprogramuotas priimti Å¡aliÅ¡kÅ³ ar diskriminuojanÄiÅ³ sprendimÅ³, kuriÅ³ Å¾monÄ—ms taip pat draudÅ¾iama priimti. Teisingumo uÅ¾tikrinimas dirbtiniame intelekte ir maÅ¡ininiame mokymesi iÅ¡lieka sudÄ—tingu sociotechniniu iÅ¡Å¡Å«kiu.

### Patikimumas ir saugumas

Norint sukurti pasitikÄ—jimÄ…, dirbtinio intelekto sistemos turi bÅ«ti patikimos, saugios ir nuoseklios tiek Ä¯prastomis, tiek netikÄ—tomis sÄ…lygomis. Svarbu Å¾inoti, kaip dirbtinio intelekto sistemos elgsis Ä¯vairiose situacijose, ypaÄ kai jos yra iÅ¡skirtinÄ—s. Kuriant dirbtinio intelekto sprendimus, reikia skirti daug dÄ—mesio tam, kaip sprÄ™sti Ä¯vairias aplinkybes, su kuriomis dirbtinio intelekto sprendimai gali susidurti. PavyzdÅ¾iui, savarankiÅ¡kai vairuojantis automobilis turi prioritetÄ… teikti Å¾moniÅ³ saugumui. TodÄ—l dirbtinis intelektas, valdantis automobilÄ¯, turi atsiÅ¾velgti Ä¯ visas galimas situacijas, su kuriomis automobilis gali susidurti, tokias kaip naktis, audros, pÅ«gos, vaikai, bÄ—gantys per gatvÄ™, augintiniai, kelio darbai ir pan. Kaip gerai dirbtinio intelekto sistema gali patikimai ir saugiai sprÄ™sti Ä¯vairias sÄ…lygas, atspindi duomenÅ³ mokslininko ar dirbtinio intelekto kÅ«rÄ—jo numatymo lygÄ¯ projektavimo ar testavimo metu.

> [ğŸ¥ SpustelÄ—kite Äia, kad perÅ¾iÅ«rÄ—tumÄ—te vaizdo Ä¯raÅ¡Ä…: ](https://www.microsoft.com/videoplayer/embed/RE4vvIl)

### Ä®trauktis

Dirbtinio intelekto sistemos turÄ—tÅ³ bÅ«ti sukurtos taip, kad Ä¯trauktÅ³ ir suteiktÅ³ galimybes visiems. Kuriant ir Ä¯gyvendinant dirbtinio intelekto sistemas, duomenÅ³ mokslininkai ir dirbtinio intelekto kÅ«rÄ—jai identifikuoja ir sprendÅ¾ia galimas kliÅ«tis sistemoje, kurios netyÄia galÄ—tÅ³ iÅ¡skirti Å¾mones. PavyzdÅ¾iui, pasaulyje yra 1 milijardas Å¾moniÅ³ su negalia. Su dirbtinio intelekto paÅ¾anga jie gali lengviau pasiekti Ä¯vairiÄ… informacijÄ… ir galimybes savo kasdieniame gyvenime. SprendÅ¾iant kliÅ«tis, atsiranda galimybÄ—s inovuoti ir kurti dirbtinio intelekto produktus su geresnÄ—mis patirtimis, kurios naudingos visiems.

> [ğŸ¥ SpustelÄ—kite Äia, kad perÅ¾iÅ«rÄ—tumÄ—te vaizdo Ä¯raÅ¡Ä…: Ä¯trauktis dirbtiniame intelekte](https://www.microsoft.com/videoplayer/embed/RE4vl9v)

### Saugumas ir privatumas

Dirbtinio intelekto sistemos turÄ—tÅ³ bÅ«ti saugios ir gerbti Å¾moniÅ³ privatumÄ…. Å½monÄ—s maÅ¾iau pasitiki sistemomis, kurios kelia pavojÅ³ jÅ³ privatumui, informacijai ar gyvybei. Mokant maÅ¡ininio mokymosi modelius, mes pasikliaujame duomenimis, kad gautume geriausius rezultatus. Tai darydami turime atsiÅ¾velgti Ä¯ duomenÅ³ kilmÄ™ ir vientisumÄ…. PavyzdÅ¾iui, ar duomenys buvo pateikti vartotojÅ³, ar vieÅ¡ai prieinami? Be to, dirbant su duomenimis, bÅ«tina kurti dirbtinio intelekto sistemas, kurios galÄ—tÅ³ apsaugoti konfidencialiÄ… informacijÄ… ir atsispirti atakoms. Kadangi dirbtinis intelektas tampa vis labiau paplitÄ™s, privatumo apsauga ir svarbios asmeninÄ—s bei verslo informacijos saugumas tampa vis svarbesni ir sudÄ—tingesni. Privatumo ir duomenÅ³ saugumo klausimai reikalauja ypatingo dÄ—mesio dirbtiniam intelektui, nes duomenÅ³ prieiga yra bÅ«tina, kad dirbtinio intelekto sistemos galÄ—tÅ³ tiksliai ir informuotai priimti sprendimus apie Å¾mones.

> [ğŸ¥ SpustelÄ—kite Äia, kad perÅ¾iÅ«rÄ—tumÄ—te vaizdo Ä¯raÅ¡Ä…: saugumas dirbtiniame intelekte](https://www.microsoft.com/videoplayer/embed/RE4voJF)

- PramonÄ—je pasiekÄ—me reikÅ¡mingÅ³ privatumo ir saugumo paÅ¾angÅ³, kurias labai paskatino tokie reglamentai kaip GDPR (Bendrasis duomenÅ³ apsaugos reglamentas).
- TaÄiau dirbtinio intelekto sistemose turime pripaÅ¾inti Ä¯tampÄ… tarp poreikio turÄ—ti daugiau asmeniniÅ³ duomenÅ³, kad sistemos bÅ«tÅ³ asmeniÅ¡kesnÄ—s ir efektyvesnÄ—s, ir privatumo.
- Kaip ir su interneto atsiradimu, matome didelÄ¯ saugumo problemÅ³, susijusiÅ³ su dirbtiniu intelektu, augimÄ….
- Tuo paÄiu metu matome, kaip dirbtinis intelektas naudojamas saugumui gerinti. PavyzdÅ¾iui, dauguma moderniÅ³ antivirusiniÅ³ skeneriÅ³ Å¡iandien yra pagrÄ¯sti dirbtinio intelekto heuristika.
- Turime uÅ¾tikrinti, kad mÅ«sÅ³ duomenÅ³ mokslÅ³ procesai harmoningai derÄ—tÅ³ su naujausiomis privatumo ir saugumo praktikomis.

### Skaidrumas

Dirbtinio intelekto sistemos turÄ—tÅ³ bÅ«ti suprantamos. Svarbi skaidrumo dalis yra paaiÅ¡kinti dirbtinio intelekto sistemÅ³ ir jÅ³ komponentÅ³ elgesÄ¯. Gerinant dirbtinio intelekto sistemÅ³ supratimÄ…, reikia, kad suinteresuotosios Å¡alys suprastÅ³, kaip ir kodÄ—l jos veikia, kad galÄ—tÅ³ identifikuoti galimas veikimo problemas, saugumo ir privatumo rÅ«pesÄius, Å¡aliÅ¡kumus, iÅ¡skirtines praktikas ar netikÄ—tus rezultatus. Taip pat tikime, kad tie, kurie naudoja dirbtinio intelekto sistemas, turÄ—tÅ³ bÅ«ti sÄ…Å¾iningi ir atviri apie tai, kada, kodÄ—l ir kaip jie nusprendÅ¾ia jas naudoti. Taip pat apie naudojamÅ³ sistemÅ³ apribojimus. PavyzdÅ¾iui, jei bankas naudoja dirbtinio intelekto sistemÄ…, kad palaikytÅ³ vartotojÅ³ paskolÅ³ sprendimus, svarbu iÅ¡nagrinÄ—ti rezultatus ir suprasti, kurie duomenys daro Ä¯takÄ… sistemos rekomendacijoms. VyriausybÄ—s pradeda reguliuoti dirbtinÄ¯ intelektÄ… Ä¯vairiose pramonÄ—s Å¡akose, todÄ—l duomenÅ³ mokslininkai ir organizacijos turi paaiÅ¡kinti, ar dirbtinio intelekto sistema atitinka reglamentavimo reikalavimus, ypaÄ kai yra nepageidaujamas rezultatas.

> [ğŸ¥ SpustelÄ—kite Äia, kad perÅ¾iÅ«rÄ—tumÄ—te vaizdo Ä¯raÅ¡Ä…: skaidrumas dirbtiniame intelekte](https://www.microsoft.com/videoplayer/embed/RE4voJF)

- Kadangi dirbtinio intelekto sistemos yra tokios sudÄ—tingos, sunku suprasti, kaip jos veikia ir interpretuoti rezultatus.
- Å is supratimo trÅ«kumas veikia tai, kaip Å¡ios sistemos yra valdomos, operatyviai naudojamos ir dokumentuojamos.
- Å is supratimo trÅ«kumas dar svarbiau veikia sprendimus, priimamus remiantis Å¡iÅ³ sistemÅ³ rezultatais.

### AtsakomybÄ—

Å½monÄ—s, kurie kuria ir diegia dirbtinio intelekto sistemas, turi bÅ«ti atsakingi uÅ¾ tai, kaip jÅ³ sistemos veikia. AtsakomybÄ—s poreikis yra ypaÄ svarbus jautriÅ³ technologijÅ³, tokiÅ³ kaip veido atpaÅ¾inimas, naudojimo atveju. Pastaruoju metu didÄ—ja veido atpaÅ¾inimo technologijos paklausa, ypaÄ iÅ¡ teisÄ—saugos organizacijÅ³, kurios mato technologijos potencialÄ…, pavyzdÅ¾iui, ieÅ¡kant dingusiÅ³ vaikÅ³. TaÄiau Å¡ios technologijos galÄ—tÅ³ bÅ«ti naudojamos vyriausybiÅ³, kad bÅ«tÅ³ paÅ¾eistos pilieÄiÅ³ pagrindinÄ—s laisvÄ—s, pavyzdÅ¾iui, leidÅ¾iant nuolatinÄ™ tam tikrÅ³ asmenÅ³ stebÄ—senÄ…. TodÄ—l duomenÅ³ mokslininkai ir organizacijos turi bÅ«ti atsakingi uÅ¾ tai, kaip jÅ³ dirbtinio intelekto sistema veikia Å¾mones ar visuomenÄ™.

[![Pirmaujantis dirbtinio intelekto tyrÄ—jas Ä¯spÄ—ja apie masinÄ™ stebÄ—senÄ… per veido atpaÅ¾inimÄ…](../../../../1-Introduction/3-fairness/images/accountability.png)](https://www.youtube.com/watch?v=Wldt8P5V6D0 "Microsoft poÅ¾iÅ«ris Ä¯ atsakingÄ… dirbtinÄ¯ intelektÄ…")

> ğŸ¥ SpustelÄ—kite aukÅ¡Äiau esanÄiÄ… nuotraukÄ…, kad perÅ¾iÅ«rÄ—tumÄ—te vaizdo Ä¯raÅ¡Ä…: Ä®spÄ—jimai apie masinÄ™ stebÄ—senÄ… per veido atpaÅ¾inimÄ…

GalÅ³ gale vienas didÅ¾iausiÅ³ mÅ«sÅ³ kartos klausimÅ³, kaip pirmosios kartos, kuri Ä¯veda dirbtinÄ¯ intelektÄ… Ä¯ visuomenÄ™, yra tai, kaip uÅ¾tikrinti, kad kompiuteriai iÅ¡liktÅ³ atsakingi Å¾monÄ—ms ir kaip uÅ¾tikrinti, kad Å¾monÄ—s, kurie kuria kompiuterius, iÅ¡liktÅ³ atsakingi visiems kitiems.

## Poveikio vertinimas

PrieÅ¡ mokant maÅ¡ininio mokymosi modelÄ¯, svarbu atlikti poveikio vertinimÄ…, kad suprastumÄ—te dirbtinio intelekto sistemos tikslÄ…; kokia yra numatyta paskirtis; kur ji bus naudojama; ir kas sÄ…veikaus su sistema. Tai naudinga vertintojams ar testuotojams, kad jie Å¾inotÅ³, kokius veiksnius reikia apsvarstyti identifikuojant galimas rizikas ir numatomas pasekmes.

Å tai sritys, Ä¯ kurias reikia atkreipti dÄ—mesÄ¯ atliekant poveikio vertinimÄ…:

* **Neigiamas poveikis asmenims**. Svarbu Å¾inoti apie bet kokius apribojimus
Å½iÅ«rÄ—kite Å¡Ä¯ seminarÄ…, kad giliau suprastumÄ—te temas:

- Atsakingo dirbtinio intelekto siekimas: principÅ³ Ä¯gyvendinimas praktikoje, pristato Besmira Nushi, Mehrnoosh Sameki ir Amit Sharma

[![Atsakingo DI Ä¯rankiÅ³ rinkinys: atvirojo kodo sistema atsakingam DI kurti](https://img.youtube.com/vi/tGgJCrA-MZU/0.jpg)](https://www.youtube.com/watch?v=tGgJCrA-MZU "RAI Toolbox: Atvirojo kodo sistema atsakingam DI kurti")

> ğŸ¥ SpustelÄ—kite paveikslÄ—lÄ¯ aukÅ¡Äiau, kad perÅ¾iÅ«rÄ—tumÄ—te vaizdo Ä¯raÅ¡Ä…: RAI Toolbox: Atvirojo kodo sistema atsakingam DI kurti, pristato Besmira Nushi, Mehrnoosh Sameki ir Amit Sharma

Taip pat skaitykite:

- Microsoft atsakingo DI iÅ¡tekliÅ³ centras: [Atsakingo DI iÅ¡tekliai â€“ Microsoft AI](https://www.microsoft.com/ai/responsible-ai-resources?activetab=pivot1%3aprimaryr4)

- Microsoft FATE tyrimÅ³ grupÄ—: [FATE: SÄ…Å¾iningumas, AtsakomybÄ—, Skaidrumas ir Etika DI - Microsoft Research](https://www.microsoft.com/research/theme/fate/)

RAI Ä¯rankiÅ³ rinkinys:

- [Atsakingo DI Ä¯rankiÅ³ rinkinio GitHub saugykla](https://github.com/microsoft/responsible-ai-toolbox)

Skaitykite apie Azure Machine Learning Ä¯rankius, skirtus uÅ¾tikrinti sÄ…Å¾iningumÄ…:

- [Azure Machine Learning](https://docs.microsoft.com/azure/machine-learning/concept-fairness-ml?WT.mc_id=academic-77952-leestott)

## UÅ¾duotis

[SusipaÅ¾inkite su RAI Ä¯rankiÅ³ rinkiniu](assignment.md)

---

**AtsakomybÄ—s apribojimas**:  
Å is dokumentas buvo iÅ¡verstas naudojant AI vertimo paslaugÄ… [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, praÅ¡ome atkreipti dÄ—mesÄ¯, kad automatiniai vertimai gali turÄ—ti klaidÅ³ ar netikslumÅ³. Originalus dokumentas jo gimtÄ…ja kalba turÄ—tÅ³ bÅ«ti laikomas autoritetingu Å¡altiniu. Kritinei informacijai rekomenduojama profesionali Å¾mogaus vertimo paslauga. Mes neprisiimame atsakomybÄ—s uÅ¾ nesusipratimus ar klaidingus interpretavimus, atsiradusius dÄ—l Å¡io vertimo naudojimo.