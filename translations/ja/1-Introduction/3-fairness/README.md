<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8f819813b2ca08ec7b9f60a2c9336045",
  "translation_date": "2025-09-03T23:27:16+00:00",
  "source_file": "1-Introduction/3-fairness/README.md",
  "language_code": "ja"
}
-->
# 責任あるAIを用いた機械学習ソリューションの構築

![機械学習における責任あるAIの概要を示すスケッチノート](../../../../translated_images/ml-fairness.ef296ebec6afc98a44566d7b6c1ed18dc2bf1115c13ec679bb626028e852fa1d.ja.png)
> スケッチノート: [Tomomi Imura](https://www.twitter.com/girlie_mac)

## [講義前のクイズ](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/5/)

## はじめに

このカリキュラムでは、機械学習が私たちの日常生活にどのように影響を与えているかを学び始めます。現在でも、システムやモデルは医療診断、ローン承認、詐欺検出などの日常的な意思決定タスクに関与しています。そのため、これらのモデルが信頼できる結果を提供することが重要です。ソフトウェアアプリケーションと同様に、AIシステムは期待を外れたり、望ましくない結果を生むことがあります。そのため、AIモデルの挙動を理解し、説明できることが不可欠です。

使用するデータが特定の人種、性別、政治的見解、宗教などの属性を欠いている場合、またはそれらの属性が不均衡に表現されている場合、どのようなことが起こるでしょうか。さらに、モデルの出力が特定の属性を優遇するように解釈された場合、アプリケーションにどのような影響があるでしょうか。また、モデルが有害な結果を生み出した場合、誰がその責任を負うべきでしょうか。これらは、このカリキュラムで探求する質問の一部です。

このレッスンでは以下を学びます:

- 機械学習における公平性の重要性と公平性に関連する害についての認識を高める
- 外れ値や異常なシナリオを探求する実践を通じて信頼性と安全性を確保する方法を学ぶ
- 包括的なシステムを設計することで、すべての人を支援する必要性を理解する
- データと人々のプライバシーとセキュリティを保護することの重要性を探る
- AIモデルの挙動を説明するための透明性のあるアプローチの重要性を理解する
- AIシステムに対する信頼を構築するために責任が不可欠であることを意識する

## 前提条件

前提条件として、「責任あるAIの原則」学習パスを受講し、以下のトピックに関するビデオを視聴してください:

[学習パス](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77952-leestott)を通じて責任あるAIについてさらに学びましょう。

[![Microsoftの責任あるAIへのアプローチ](https://img.youtube.com/vi/dnC8-uUZXSc/0.jpg)](https://youtu.be/dnC8-uUZXSc "Microsoftの責任あるAIへのアプローチ")

> 🎥 上の画像をクリックしてビデオを見る: Microsoftの責任あるAIへのアプローチ

## 公平性

AIシステムはすべての人を公平に扱い、似たようなグループに異なる影響を与えないようにするべきです。例えば、AIシステムが医療治療、ローン申請、雇用に関する助言を提供する場合、似たような症状、財務状況、職業資格を持つすべての人に同じ推奨をするべきです。私たち人間は、意思決定や行動に影響を与える先天的な偏見を持っています。この偏見は、AIシステムを訓練するために使用するデータに現れることがあります。このような操作は時に意図せずに起こることがあります。データに偏りを導入していることを意識的に知るのは難しいことが多いです。

**「不公平」**とは、人種、性別、年齢、障害の有無などで定義されるグループに対する否定的な影響、つまり「害」を指します。主な公平性に関連する害は以下のように分類されます:

- **割り当て**: 例えば、性別や民族が他の属性よりも優遇される場合。
- **サービスの質**: 特定のシナリオに対してデータを訓練したが、現実ははるかに複雑である場合、サービスの質が低下します。例えば、暗い肌の人を感知できないハンドソープディスペンサー。[参考](https://gizmodo.com/why-cant-this-soap-dispenser-identify-dark-skin-1797931773)
- **中傷**: 不公平に批判したり、何かや誰かをラベル付けすること。例えば、画像ラベリング技術が暗い肌の人々の画像をゴリラとして誤認識したこと。
- **過剰または過少な表現**: 特定の職業に特定のグループが見られないという考えであり、それを促進し続けるサービスや機能は害を助長します。
- **ステレオタイプ化**: 特定のグループに事前に割り当てられた属性を関連付けること。例えば、英語とトルコ語間の言語翻訳システムが性別に関連するステレオタイプによる不正確さを持つ場合。

![トルコ語への翻訳](../../../../translated_images/gender-bias-translate-en-tr.f185fd8822c2d4372912f2b690f6aaddd306ffbb49d795ad8d12a4bf141e7af0.ja.png)
> トルコ語への翻訳

![英語への翻訳](../../../../translated_images/gender-bias-translate-tr-en.4eee7e3cecb8c70e13a8abbc379209bc8032714169e585bdeac75af09b1752aa.ja.png)
> 英語への翻訳

AIシステムを設計・テストする際には、AIが公平であり、偏ったり差別的な決定をするようにプログラムされていないことを確認する必要があります。AIと機械学習における公平性を保証することは、依然として複雑な社会技術的課題です。

### 信頼性と安全性

信頼を構築するためには、AIシステムが通常の条件や予期しない条件下でも信頼性があり、安全で一貫性がある必要があります。AIシステムがさまざまな状況でどのように振る舞うかを知ることが重要です。特に外れ値の場合です。AIソリューションを構築する際には、AIソリューションが遭遇する可能性のあるさまざまな状況に対処する方法に十分な焦点を当てる必要があります。例えば、自動運転車は人々の安全を最優先にする必要があります。その結果、車を動かすAIは、夜間、雷雨、吹雪、道路を横切る子供、ペット、道路工事など、車が遭遇する可能性のあるすべてのシナリオを考慮する必要があります。AIシステムが幅広い条件を信頼性と安全性を持って処理できるかどうかは、データサイエンティストやAI開発者が設計やテスト中に考慮した予測のレベルを反映しています。

> [🎥 ビデオを見る: ](https://www.microsoft.com/videoplayer/embed/RE4vvIl)

### 包括性

AIシステムはすべての人を巻き込み、支援するように設計されるべきです。AIシステムを設計・実装する際、データサイエンティストやAI開発者は、意図せずに人々を排除する可能性のあるシステム内の障壁を特定し、対処します。例えば、世界には10億人の障害を持つ人々がいます。AIの進歩により、彼らは日常生活で情報や機会により簡単にアクセスできるようになります。障壁に対処することで、すべての人に利益をもたらすより良い体験を提供するAI製品を革新し、開発する機会が生まれます。

> [🎥 ビデオを見る: AIにおける包括性](https://www.microsoft.com/videoplayer/embed/RE4vl9v)

### セキュリティとプライバシー

AIシステムは安全であり、人々のプライバシーを尊重するべきです。プライバシー、情報、または生命を危険にさらすシステムには、人々は信頼を置きません。機械学習モデルを訓練する際には、最良の結果を得るためにデータに依存します。その際、データの出所と整合性を考慮する必要があります。例えば、データがユーザーによって提出されたものか、公開されているものかを確認します。次に、データを扱う際には、機密情報を保護し、攻撃に耐えるAIシステムを開発することが重要です。AIが普及するにつれて、プライバシーを保護し、重要な個人情報やビジネス情報を安全に保つことがますます重要かつ複雑になっています。プライバシーとデータセキュリティの問題は、AIにとって特に注意が必要です。データへのアクセスは、AIシステムが人々について正確で情報に基づいた予測や意思決定を行うために不可欠です。

> [🎥 ビデオを見る: AIにおけるセキュリティ](https://www.microsoft.com/videoplayer/embed/RE4voJF)

- 業界として、GDPR（一般データ保護規則）などの規制によって大きく促進されたプライバシーとセキュリティの分野で大きな進歩を遂げました。
- しかし、AIシステムでは、システムをより個人的で効果的にするためにより多くの個人データが必要であるというニーズとプライバシーの間の緊張を認識する必要があります。
- インターネットによる接続されたコンピュータの誕生と同様に、AIに関連するセキュリティ問題の数が急増しているのを目にしています。
- 同時に、AIがセキュリティを向上させるために使用されているのも目にしています。例えば、ほとんどの現代のウイルス対策スキャナーは今日AIのヒューリスティックによって駆動されています。
- データサイエンスプロセスが最新のプライバシーとセキュリティの実践と調和して融合することを確保する必要があります。

### 透明性

AIシステムは理解可能であるべきです。透明性の重要な部分は、AIシステムとその構成要素の挙動を説明することです。AIシステムの理解を向上させるには、利害関係者がその機能や理由を理解し、潜在的な性能問題、安全性やプライバシーの懸念、偏り、排除的な慣行、または意図しない結果を特定できるようにする必要があります。また、AIシステムを使用する人々が、いつ、なぜ、どのようにそれを展開することを選択するかについて正直で率直であるべきだと考えています。さらに、使用するシステムの限界についても説明する必要があります。例えば、銀行が消費者の貸付決定を支援するためにAIシステムを使用する場合、結果を検討し、システムの推奨に影響を与えるデータを理解することが重要です。政府は産業全体でAIを規制し始めているため、データサイエンティストや組織は、AIシステムが規制要件を満たしているかどうかを説明する必要があります。特に望ましくない結果が生じた場合には。

> [🎥 ビデオを見る: AIにおける透明性](https://www.microsoft.com/videoplayer/embed/RE4voJF)

- AIシステムは非常に複雑であるため、どのように機能するかを理解し、結果を解釈するのが難しいです。
- この理解の欠如は、これらのシステムが管理、運用、文書化される方法に影響を与えます。
- この理解の欠如はさらに重要なことに、これらのシステムが生成する結果を使用して行われる意思決定に影響を与えます。

### 責任

AIシステムを設計し展開する人々は、そのシステムの動作に対して責任を負うべきです。責任の必要性は、特に顔認識のようなセンシティブな技術において重要です。最近、顔認識技術の需要が高まっています。特に、行方不明の子供を見つけるなどの用途でその技術の可能性を見出している法執行機関からの需要が増えています。しかし、これらの技術は、特定の個人の継続的な監視を可能にするなど、政府が市民の基本的な自由を危険にさらす可能性があります。そのため、データサイエンティストや組織は、AIシステムが個人や社会に与える影響について責任を負う必要があります。

[![主要なAI研究者が顔認識による大量監視の警告](../../../../translated_images/accountability.41d8c0f4b85b6231301d97f17a450a805b7a07aaeb56b34015d71c757cad142e.ja.png)](https://www.youtube.com/watch?v=Wldt8P5V6D0 "Microsoftの責任あるAIへのアプローチ")

> 🎥 上の画像をクリックしてビデオを見る: 顔認識による大量監視の警告

最終的に、AIを社会に導入する最初の世代として、コンピュータが人々に対して責任を持ち続けることをどのように保証するか、そしてコンピュータを設計する人々が他のすべての人々に対して責任を持ち続けることをどのように保証するかが、私たちの世代にとって最大の課題の一つです。

## 影響評価

機械学習モデルを訓練する前に、AIシステムの目的、意図された使用法、展開される場所、システムと対話する人々を理解するために影響評価を行うことが重要です。これらは、システムを評価するレビュー担当者やテスターが、潜在的なリスクや予想される結果を特定する際に考慮すべき要因を知るのに役立ちます。

影響評価を行う際の重点領域は以下の通りです:

* **個人への悪影響**: 制限や要件、サポートされていない使用法、またはシステムの性能を妨げる既知の制限に注意を払うことは、システムが個人に害を与える方法で使用されないようにするために重要です。
* **データ要件**: システムがデータをどのように使用するか、どこで使用するかを理解することで、考慮すべきデータ要件（例: GDPRやHIPPAデータ規制）を探ることができます。また、データの出所や量が訓練に十分であるかどうかを検討します。
* **影響の概要**: システムの使用から生じる可能性のある害のリストを収集します。MLライフサイクル全体を通じて、特定された問題が軽減または対処されているかどうかを確認します。
* **6つのコア原則に基づく適用可能な目標**: 各原則の目標が達成されているか、ギャップがあるかどうかを評価します。

## 責任あるAIによるデバッグ

ソフトウェアアプリケーションのデバッグと同様に、AIシステムのデバッグはシステム内の問題を特定し解決する必要なプロセスです。モデルが期待通りに、または責任を持って動作しない理由には多くの要因があります。従来のモデル性能指標の多くは、モデルの性能の定量的な集計であり、責任あるAI原則に違反する方法を分析するには十分ではありません。さらに、機械学習モデルはブラックボックスであり、その結果を導く要因を理解したり、誤りを説明するのが難しいです。このコースの後半では、責任あるAIダッシュボードを使用してAIシステムをデバッグする方法を学びます。このダッシュボードは、データサイエンティストやAI開発者が
このレッスンでは、機械学習における公平性と不公平性の基本的な概念について学びました。

以下のワークショップを視聴して、さらに深く学びましょう：

- 責任あるAIの追求: 原則を実践に移す方法  
  講師: Besmira Nushi、Mehrnoosh Sameki、Amit Sharma

[![責任あるAIツールボックス: 責任あるAIを構築するためのオープンソースフレームワーク](https://img.youtube.com/vi/tGgJCrA-MZU/0.jpg)](https://www.youtube.com/watch?v=tGgJCrA-MZU "RAI Toolbox: 責任あるAIを構築するためのオープンソースフレームワーク")

> 🎥 上の画像をクリックして動画を視聴:  
RAI Toolbox: 責任あるAIを構築するためのオープンソースフレームワーク  
講師: Besmira Nushi、Mehrnoosh Sameki、Amit Sharma

また、以下も読んでみてください：

- MicrosoftのRAIリソースセンター: [責任あるAIリソース – Microsoft AI](https://www.microsoft.com/ai/responsible-ai-resources?activetab=pivot1%3aprimaryr4)

- MicrosoftのFATE研究グループ: [FATE: AIにおける公平性、説明責任、透明性、倫理 - Microsoft Research](https://www.microsoft.com/research/theme/fate/)

RAI Toolbox:

- [責任あるAIツールボックス GitHubリポジトリ](https://github.com/microsoft/responsible-ai-toolbox)

Azure Machine Learningの公平性を確保するためのツールについて読む:

- [Azure Machine Learning](https://docs.microsoft.com/azure/machine-learning/concept-fairness-ml?WT.mc_id=academic-77952-leestott)

## 課題

[RAI Toolboxを探索する](assignment.md)

---

**免責事項**:  
この文書はAI翻訳サービス[Co-op Translator](https://github.com/Azure/co-op-translator)を使用して翻訳されています。正確性を追求しておりますが、自動翻訳には誤りや不正確な部分が含まれる可能性があります。元の言語で記載された文書を正式な情報源としてお考えください。重要な情報については、専門の人間による翻訳を推奨します。この翻訳の使用に起因する誤解や誤認について、当方は責任を負いません。