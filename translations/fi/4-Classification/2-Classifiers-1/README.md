<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1a6e9e46b34a2e559fbbfc1f95397c7b",
  "translation_date": "2025-09-05T00:44:45+00:00",
  "source_file": "4-Classification/2-Classifiers-1/README.md",
  "language_code": "fi"
}
-->
# Ruokakulttuuriluokittelijat 1

T√§ss√§ oppitunnissa k√§yt√§t edellisess√§ oppitunnissa tallentamaasi tasapainoista ja siisti√§ datasetti√§, joka k√§sittelee ruokakulttuureja.

K√§yt√§t t√§t√§ datasetti√§ eri luokittelijoiden kanssa _ennustaaksesi tietyn kansallisen ruokakulttuurin ainesosaryhm√§n perusteella_. Samalla opit lis√§√§ tavoista, joilla algoritmeja voidaan hy√∂dynt√§√§ luokitteluteht√§viss√§.

## [Esiluennon kysely](https://ff-quizzes.netlify.app/en/ml/)
# Valmistelu

Jos olet suorittanut [Oppitunnin 1](../1-Introduction/README.md), varmista, ett√§ _cleaned_cuisines.csv_-tiedosto on olemassa juurihakemistossa `/data` n√§it√§ nelj√§√§ oppituntia varten.

## Harjoitus - ennusta kansallinen ruokakulttuuri

1. Ty√∂skentele t√§m√§n oppitunnin _notebook.ipynb_-kansiossa ja tuo tiedosto sek√§ Pandas-kirjasto:

    ```python
    import pandas as pd
    cuisines_df = pd.read_csv("../data/cleaned_cuisines.csv")
    cuisines_df.head()
    ```

    Data n√§ytt√§√§ t√§lt√§:

|     | Unnamed: 0 | cuisine | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood | yam | yeast | yogurt | zucchini |
| --- | ---------- | ------- | ------ | -------- | ----- | ---------- | ----- | ------------ | ------- | -------- | --- | ------- | ----------- | ---------- | ----------------------- | ---- | ---- | --- | ----- | ------ | -------- |
| 0   | 0          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 1   | 1          | indian  | 1      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 2   | 2          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 3   | 3          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 4   | 4          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 1      | 0        |
  

1. Tuo nyt lis√§√§ kirjastoja:

    ```python
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    from sklearn.svm import SVC
    import numpy as np
    ```

1. Jaa X- ja y-koordinaatit kahteen datafreimiin koulutusta varten. `cuisine` voi olla labelien datafreimi:

    ```python
    cuisines_label_df = cuisines_df['cuisine']
    cuisines_label_df.head()
    ```

    Se n√§ytt√§√§ t√§lt√§:

    ```output
    0    indian
    1    indian
    2    indian
    3    indian
    4    indian
    Name: cuisine, dtype: object
    ```

1. Poista `Unnamed: 0`-sarake ja `cuisine`-sarake k√§ytt√§m√§ll√§ `drop()`. Tallenna loput tiedot koulutettaviksi ominaisuuksiksi:

    ```python
    cuisines_feature_df = cuisines_df.drop(['Unnamed: 0', 'cuisine'], axis=1)
    cuisines_feature_df.head()
    ```

    Ominaisuudet n√§ytt√§v√§t t√§lt√§:

|      | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | artemisia | artichoke |  ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood |  yam | yeast | yogurt | zucchini |
| ---: | -----: | -------: | ----: | ---------: | ----: | -----------: | ------: | -------: | --------: | --------: | ---: | ------: | ----------: | ---------: | ----------------------: | ---: | ---: | ---: | ----: | -----: | -------: |
|    0 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    1 |      1 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    2 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    3 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    4 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      1 |        0 | 0 |

Nyt olet valmis kouluttamaan mallisi!

## Luokittelijan valinta

Kun datasi on puhdas ja valmis koulutukseen, sinun t√§ytyy p√§√§tt√§√§, mit√§ algoritmia k√§yt√§t teht√§v√§√§n.

Scikit-learn ryhmittelee luokittelun ohjatun oppimisen alle, ja t√§ss√§ kategoriassa on monia tapoja luokitella. [Vaihtoehtojen m√§√§r√§](https://scikit-learn.org/stable/supervised_learning.html) voi aluksi tuntua h√§mment√§v√§lt√§. Seuraavat menetelm√§t sis√§lt√§v√§t luokittelutekniikoita:

- Lineaariset mallit
- Tukivektorikoneet
- Stokastinen gradienttilaskenta
- L√§himm√§t naapurit
- Gaussin prosessit
- P√§√§t√∂spuut
- Yhdistelm√§mallit (√§√§nestysluokittelija)
- Moniluokka- ja monitulostusalgoritmit (moniluokka- ja monilabel-luokittelu, moniluokka-monitulostusluokittelu)

> Voit my√∂s k√§ytt√§√§ [neuroverkkoja datan luokitteluun](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#classification), mutta se ei kuulu t√§m√§n oppitunnin aihepiiriin.

### Mink√§ luokittelijan valita?

Mink√§ luokittelijan siis valitset? Usein useiden kokeileminen ja hyv√§n tuloksen etsiminen on tapa testata. Scikit-learn tarjoaa [vertailun rinnakkain](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) luodulla datasetill√§, jossa verrataan KNeighbors, SVC kahdella tavalla, GaussianProcessClassifier, DecisionTreeClassifier, RandomForestClassifier, MLPClassifier, AdaBoostClassifier, GaussianNB ja QuadraticDiscriminationAnalysis, ja tulokset visualisoidaan:

![luokittelijoiden vertailu](../../../../4-Classification/2-Classifiers-1/images/comparison.png)
> Kuva Scikit-learnin dokumentaatiosta

> AutoML ratkaisee t√§m√§n ongelman k√§tev√§sti suorittamalla n√§m√§ vertailut pilvess√§, jolloin voit valita parhaan algoritmin datallesi. Kokeile [t√§√§ll√§](https://docs.microsoft.com/learn/modules/automate-model-selection-with-azure-automl/?WT.mc_id=academic-77952-leestott)

### Parempi l√§hestymistapa

Parempi tapa kuin arvaaminen on seurata ladattavaa [ML Cheat Sheet](https://docs.microsoft.com/azure/machine-learning/algorithm-cheat-sheet?WT.mc_id=academic-77952-leestott). T√§ss√§ huomataan, ett√§ moniluokkaongelmaamme varten meill√§ on joitakin vaihtoehtoja:

![moniluokkaongelmien huijauslista](../../../../4-Classification/2-Classifiers-1/images/cheatsheet.png)
> Osa Microsoftin algoritmien huijauslistasta, joka k√§sittelee moniluokkaluokitteluvaihtoehtoja

‚úÖ Lataa t√§m√§ huijauslista, tulosta se ja ripusta sein√§llesi!

### Perustelu

Katsotaan, voimmeko perustella eri l√§hestymistapoja annettujen rajoitusten perusteella:

- **Neuroverkot ovat liian raskaita**. Puhdas mutta minimaalinen datasetti ja se, ett√§ koulutus tapahtuu paikallisesti notebookien kautta, tekev√§t neuroverkoista liian raskaita t√§h√§n teht√§v√§√§n.
- **Ei kaksiluokkaista luokittelijaa**. Emme k√§yt√§ kaksiluokkaista luokittelijaa, joten se sulkee pois one-vs-all-menetelm√§n.
- **P√§√§t√∂spuu tai logistinen regressio voisi toimia**. P√§√§t√∂spuu voisi toimia, tai logistinen regressio moniluokkaiselle datalle.
- **Moniluokkaiset Boosted Decision Trees ratkaisevat eri ongelman**. Moniluokkainen Boosted Decision Tree sopii parhaiten ei-parametrisiin teht√§viin, kuten teht√§viin, jotka on suunniteltu luomaan sijoituksia, joten se ei ole hy√∂dyllinen meille.

### Scikit-learnin k√§ytt√∂

K√§yt√§mme Scikit-learnia datan analysointiin. On kuitenkin monia tapoja k√§ytt√§√§ logistista regressiota Scikit-learnissa. Katso [parametrit, jotka voit asettaa](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regressio#sklearn.linear_model.LogisticRegression).  

K√§yt√§nn√∂ss√§ on kaksi t√§rke√§√§ parametria - `multi_class` ja `solver` - jotka meid√§n t√§ytyy m√§√§ritt√§√§, kun pyyd√§mme Scikit-learnia suorittamaan logistisen regression. `multi_class`-arvo soveltaa tietty√§ k√§ytt√§ytymist√§. Solverin arvo m√§√§ritt√§√§, mit√§ algoritmia k√§ytet√§√§n. Kaikkia solvereita ei voi yhdist√§√§ kaikkiin `multi_class`-arvoihin.

Dokumentaation mukaan moniluokkaisessa tapauksessa koulutusalgoritmi:

- **K√§ytt√§√§ one-vs-rest (OvR) -menetelm√§√§**, jos `multi_class`-vaihtoehto on asetettu `ovr`
- **K√§ytt√§√§ ristientropiah√§vi√∂t√§**, jos `multi_class`-vaihtoehto on asetettu `multinomial`. (T√§ll√§ hetkell√§ `multinomial`-vaihtoehto on tuettu vain ‚Äòlbfgs‚Äô, ‚Äòsag‚Äô, ‚Äòsaga‚Äô ja ‚Äònewton-cg‚Äô solvereilla.)

> üéì 'Menetelm√§' voi olla joko 'ovr' (one-vs-rest) tai 'multinomial'. Koska logistinen regressio on suunniteltu tukemaan bin√§√§riluokittelua, n√§m√§ menetelm√§t auttavat sit√§ k√§sittelem√§√§n paremmin moniluokkaluokitteluteht√§vi√§. [l√§hde](https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/)

> üéì 'Solver' m√§√§ritell√§√§n "algoritmiksi, jota k√§ytet√§√§n optimointiongelmassa". [l√§hde](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regressio#sklearn.linear_model.LogisticRegression).

Scikit-learn tarjoaa t√§m√§n taulukon selitt√§m√§√§n, miten solverit k√§sittelev√§t eri haasteita, joita eri datarakenteet esitt√§v√§t:

![solverit](../../../../4-Classification/2-Classifiers-1/images/solvers.png)

## Harjoitus - jaa data

Voimme keskitty√§ logistiseen regressioon ensimm√§isess√§ koulutuskokeilussamme, koska opit siit√§ √§skett√§in edellisess√§ oppitunnissa.
Jaa datasi koulutus- ja testiryhmiin kutsumalla `train_test_split()`:

```python
X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)
```

## Harjoitus - sovella logistista regressiota

Koska k√§yt√§t moniluokkaista tapausta, sinun t√§ytyy valita, mit√§ _menetelm√§√§_ k√§yt√§t ja mit√§ _solveria_ asetat. K√§yt√§ LogisticRegressionia moniluokka-asetuksella ja **liblinear**-solveria koulutukseen.

1. Luo logistinen regressio, jossa multi_class on asetettu `ovr` ja solver asetettu `liblinear`:

    ```python
    lr = LogisticRegression(multi_class='ovr',solver='liblinear')
    model = lr.fit(X_train, np.ravel(y_train))
    
    accuracy = model.score(X_test, y_test)
    print ("Accuracy is {}".format(accuracy))
    ```

    ‚úÖ Kokeile eri solveria, kuten `lbfgs`, joka on usein asetettu oletusarvoksi
> Huomaa, k√§yt√§ Pandasin [`ravel`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.ravel.html) -funktiota litist√§√§ksesi datasi tarvittaessa.
Tarkkuus on hyv√§, yli **80%**!

1. Voit n√§hd√§ t√§m√§n mallin toiminnassa testaamalla yht√§ rivi√§ (#50):

    ```python
    print(f'ingredients: {X_test.iloc[50][X_test.iloc[50]!=0].keys()}')
    print(f'cuisine: {y_test.iloc[50]}')
    ```

    Tulos tulostetaan:

   ```output
   ingredients: Index(['cilantro', 'onion', 'pea', 'potato', 'tomato', 'vegetable_oil'], dtype='object')
   cuisine: indian
   ```

   ‚úÖ Kokeile eri rivinumeroa ja tarkista tulokset

1. Syvemm√§lle ment√§ess√§ voit tarkistaa t√§m√§n ennusteen tarkkuuden:

    ```python
    test= X_test.iloc[50].values.reshape(-1, 1).T
    proba = model.predict_proba(test)
    classes = model.classes_
    resultdf = pd.DataFrame(data=proba, columns=classes)
    
    topPrediction = resultdf.T.sort_values(by=[0], ascending = [False])
    topPrediction.head()
    ```

    Tulos tulostetaan - Intialainen keitti√∂ on paras arvaus, hyv√§ll√§ todenn√§k√∂isyydell√§:

    |          |        0 |
    | -------: | -------: |
    |   indian | 0.715851 |
    |  chinese | 0.229475 |
    | japanese | 0.029763 |
    |   korean | 0.017277 |
    |     thai | 0.007634 |

    ‚úÖ Voitko selitt√§√§, miksi malli on melko varma, ett√§ kyseess√§ on intialainen keitti√∂?

1. Saat lis√§√§ yksityiskohtia tulostamalla luokitteluraportin, kuten teit regressio-opetuksissa:

    ```python
    y_pred = model.predict(X_test)
    print(classification_report(y_test,y_pred))
    ```

    |              | tarkkuus | recall | f1-score | tuki    |
    | ------------ | -------- | ------ | -------- | ------- |
    | chinese      | 0.73     | 0.71   | 0.72     | 229     |
    | indian       | 0.91     | 0.93   | 0.92     | 254     |
    | japanese     | 0.70     | 0.75   | 0.72     | 220     |
    | korean       | 0.86     | 0.76   | 0.81     | 242     |
    | thai         | 0.79     | 0.85   | 0.82     | 254     |
    | tarkkuus     | 0.80     | 1199   |          |         |
    | keskiarvo    | 0.80     | 0.80   | 0.80     | 1199    |
    | painotettu   | 0.80     | 0.80   | 0.80     | 1199    |

## üöÄHaaste

T√§ss√§ oppitunnissa k√§ytit siivottua dataasi rakentaaksesi koneoppimismallin, joka voi ennustaa kansallisen keitti√∂n ainesosien perusteella. K√§yt√§ aikaa tutkiaksesi Scikit-learnin tarjoamia monia vaihtoehtoja datan luokitteluun. Syvenny tarkemmin 'solver'-k√§sitteeseen ymm√§rt√§√§ksesi, mit√§ kulissien takana tapahtuu.

## [Luennon j√§lkeinen kysely](https://ff-quizzes.netlify.app/en/ml/)

## Kertaus & Itseopiskelu

Tutustu hieman tarkemmin logistisen regression matematiikkaan [t√§ss√§ oppitunnissa](https://people.eecs.berkeley.edu/~russell/classes/cs194/f11/lectures/CS194%20Fall%202011%20Lecture%2006.pdf)
## Teht√§v√§ 

[Tutki solvereita](assignment.md)

---

**Vastuuvapauslauseke**:  
T√§m√§ asiakirja on k√§√§nnetty k√§ytt√§m√§ll√§ teko√§lypohjaista k√§√§nn√∂spalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, ett√§ automaattiset k√§√§nn√∂kset voivat sis√§lt√§√§ virheit√§ tai ep√§tarkkuuksia. Alkuper√§inen asiakirja sen alkuper√§isell√§ kielell√§ tulisi pit√§√§ ensisijaisena l√§hteen√§. Kriittisen tiedon osalta suositellaan ammattimaista ihmisk√§√§nn√∂st√§. Emme ole vastuussa v√§√§rink√§sityksist√§ tai virhetulkinnoista, jotka johtuvat t√§m√§n k√§√§nn√∂ksen k√§yt√∂st√§.