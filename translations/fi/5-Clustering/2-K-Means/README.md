<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7cdd17338d9bbd7e2171c2cd462eb081",
  "translation_date": "2025-09-05T00:06:37+00:00",
  "source_file": "5-Clustering/2-K-Means/README.md",
  "language_code": "fi"
}
-->
# K-Means-klusterointi

## [Pre-lecture quiz](https://ff-quizzes.netlify.app/en/ml/)

T√§ss√§ oppitunnissa opit luomaan klustereita Scikit-learnin avulla ja k√§ytt√§m√§ll√§ aiemmin tuomaasi Nigerian musiikkidataa. K√§ymme l√§pi K-Meansin perusteet klusterointia varten. Muista, ett√§ kuten opit aiemmassa oppitunnissa, klustereiden kanssa ty√∂skentelyyn on monia tapoja, ja k√§ytt√§m√§si menetelm√§ riippuu datastasi. Kokeilemme K-Meansia, koska se on yleisin klusterointitekniikka. Aloitetaan!

Termit, joista opit lis√§√§:

- Silhouette-pisteytys
- Kyyn√§rp√§√§menetelm√§
- Inertia
- Varianssi

## Johdanto

[K-Means-klusterointi](https://wikipedia.org/wiki/K-means_clustering) on menetelm√§, joka on per√§isin signaalink√§sittelyn alalta. Sit√§ k√§ytet√§√§n jakamaan ja ryhmittelem√§√§n dataa 'k' klusteriin havaintojen avulla. Jokainen havainto pyrkii ryhmittelem√§√§n tietyn datapisteen l√§himp√§√§n 'keskiarvoon' eli klusterin keskipisteeseen.

Klusterit voidaan visualisoida [Voronoi-diagrammeina](https://wikipedia.org/wiki/Voronoi_diagram), jotka sis√§lt√§v√§t pisteen (tai 'siemenen') ja sen vastaavan alueen.

![voronoi diagram](../../../../5-Clustering/2-K-Means/images/voronoi.png)

> Infografiikka: [Jen Looper](https://twitter.com/jenlooper)

K-Means-klusterointiprosessi [etenee kolmivaiheisessa prosessissa](https://scikit-learn.org/stable/modules/clustering.html#k-means):

1. Algoritmi valitsee k-m√§√§r√§n keskipisteit√§ ottamalla n√§ytteit√§ datasta. T√§m√§n j√§lkeen se toistaa:
    1. Se m√§√§ritt√§√§ jokaisen n√§ytteen l√§himp√§√§n keskipisteeseen.
    2. Se luo uusia keskipisteit√§ laskemalla kaikkien edellisiin keskipisteisiin m√§√§ritettyjen n√§ytteiden keskiarvon.
    3. Sitten se laskee eron uusien ja vanhojen keskipisteiden v√§lill√§ ja toistaa, kunnes keskipisteet vakiintuvat.

Yksi K-Meansin k√§yt√∂n haittapuoli on se, ett√§ sinun t√§ytyy m√§√§ritt√§√§ 'k', eli keskipisteiden m√§√§r√§. Onneksi 'kyyn√§rp√§√§menetelm√§' auttaa arvioimaan hyv√§n l√§ht√∂arvon 'k':lle. Kokeilet sit√§ pian.

## Esitiedot

Ty√∂skentelet t√§m√§n oppitunnin [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/2-K-Means/notebook.ipynb)-tiedostossa, joka sis√§lt√§√§ datan tuonnin ja alustavan puhdistuksen, jonka teit edellisess√§ oppitunnissa.

## Harjoitus - valmistelu

Aloita tarkastelemalla uudelleen kappaledataa.

1. Luo laatikkokaavio kutsumalla `boxplot()` jokaiselle sarakkeelle:

    ```python
    plt.figure(figsize=(20,20), dpi=200)
    
    plt.subplot(4,3,1)
    sns.boxplot(x = 'popularity', data = df)
    
    plt.subplot(4,3,2)
    sns.boxplot(x = 'acousticness', data = df)
    
    plt.subplot(4,3,3)
    sns.boxplot(x = 'energy', data = df)
    
    plt.subplot(4,3,4)
    sns.boxplot(x = 'instrumentalness', data = df)
    
    plt.subplot(4,3,5)
    sns.boxplot(x = 'liveness', data = df)
    
    plt.subplot(4,3,6)
    sns.boxplot(x = 'loudness', data = df)
    
    plt.subplot(4,3,7)
    sns.boxplot(x = 'speechiness', data = df)
    
    plt.subplot(4,3,8)
    sns.boxplot(x = 'tempo', data = df)
    
    plt.subplot(4,3,9)
    sns.boxplot(x = 'time_signature', data = df)
    
    plt.subplot(4,3,10)
    sns.boxplot(x = 'danceability', data = df)
    
    plt.subplot(4,3,11)
    sns.boxplot(x = 'length', data = df)
    
    plt.subplot(4,3,12)
    sns.boxplot(x = 'release_date', data = df)
    ```

    T√§m√§ data on hieman meluisaa: tarkastelemalla kutakin saraketta laatikkokaaviona voit n√§hd√§ poikkeamia.

    ![outliers](../../../../5-Clustering/2-K-Means/images/boxplots.png)

Voisit k√§yd√§ datasetin l√§pi ja poistaa n√§m√§ poikkeamat, mutta se tekisi datasta melko v√§h√§ist√§.

1. Valitse toistaiseksi, mitk√§ sarakkeet k√§yt√§t klusterointiharjoituksessa. Valitse sarakkeet, joilla on samanlaiset vaihteluv√§lit, ja koodaa `artist_top_genre`-sarake numeeriseksi dataksi:

    ```python
    from sklearn.preprocessing import LabelEncoder
    le = LabelEncoder()
    
    X = df.loc[:, ('artist_top_genre','popularity','danceability','acousticness','loudness','energy')]
    
    y = df['artist_top_genre']
    
    X['artist_top_genre'] = le.fit_transform(X['artist_top_genre'])
    
    y = le.transform(y)
    ```

1. Nyt sinun t√§ytyy p√§√§tt√§√§, kuinka monta klusteria kohdistat. Tied√§t, ett√§ datasetist√§ on erotettu kolme kappaletyyli√§, joten kokeillaan kolmea:

    ```python
    from sklearn.cluster import KMeans
    
    nclusters = 3 
    seed = 0
    
    km = KMeans(n_clusters=nclusters, random_state=seed)
    km.fit(X)
    
    # Predict the cluster for each data point
    
    y_cluster_kmeans = km.predict(X)
    y_cluster_kmeans
    ```

N√§et tulostettuna taulukon, jossa on ennustetut klusterit (0, 1 tai 2) jokaiselle dataframe-riville.

1. K√§yt√§ t√§t√§ taulukkoa laskeaksesi 'silhouette-pisteen':

    ```python
    from sklearn import metrics
    score = metrics.silhouette_score(X, y_cluster_kmeans)
    score
    ```

## Silhouette-pisteytys

Etsi silhouette-piste, joka on l√§hemp√§n√§ 1:t√§. T√§m√§ piste vaihtelee -1:st√§ 1:een, ja jos piste on 1, klusteri on tiivis ja hyvin erotettu muista klustereista. Arvo l√§hell√§ 0:aa edustaa p√§√§llekk√§isi√§ klustereita, joissa n√§ytteet ovat hyvin l√§hell√§ naapuriklusterien p√§√§t√∂srajaa. [(L√§hde)](https://dzone.com/articles/kmeans-silhouette-score-explained-with-python-exam)

Meid√§n pisteemme on **.53**, eli keskivaiheilla. T√§m√§ osoittaa, ett√§ datamme ei ole erityisen hyvin soveltuvaa t√§m√§n tyyppiseen klusterointiin, mutta jatketaan.

### Harjoitus - mallin rakentaminen

1. Tuo `KMeans` ja aloita klusterointiprosessi.

    ```python
    from sklearn.cluster import KMeans
    wcss = []
    
    for i in range(1, 11):
        kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)
        kmeans.fit(X)
        wcss.append(kmeans.inertia_)
    
    ```

    T√§ss√§ on muutama osa, jotka vaativat selityst√§.

    > üéì range: N√§m√§ ovat klusterointiprosessin iteroinnit.

    > üéì random_state: "M√§√§ritt√§√§ satunnaislukugeneraation keskipisteiden alustamiseen." [L√§hde](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)

    > üéì WCSS: "klusterin sis√§iset neli√∂summat" mittaa kaikkien klusterin sis√§ll√§ olevien pisteiden keskipisteeseen kohdistuvan keskim√§√§r√§isen et√§isyyden neli√∂n. [L√§hde](https://medium.com/@ODSC/unsupervised-learning-evaluating-clusters-bd47eed175ce).

    > üéì Inertia: K-Means-algoritmit pyrkiv√§t valitsemaan keskipisteet minimoimaan 'inertiaa', "mitta, kuinka sis√§isesti yhten√§isi√§ klusterit ovat." [L√§hde](https://scikit-learn.org/stable/modules/clustering.html). Arvo lis√§t√§√§n wcss-muuttujaan jokaisella iteroinnilla.

    > üéì k-means++: [Scikit-learnissa](https://scikit-learn.org/stable/modules/clustering.html#k-means) voit k√§ytt√§√§ 'k-means++'-optimointia, joka "alustaa keskipisteet olemaan (yleens√§) kaukana toisistaan, mik√§ johtaa todenn√§k√∂isesti parempiin tuloksiin kuin satunnainen alustus."

### Kyyn√§rp√§√§menetelm√§

Aiemmin oletit, ett√§ koska olet kohdistanut kolme kappaletyyli√§, sinun pit√§isi valita kolme klusteria. Mutta onko n√§in?

1. K√§yt√§ 'kyyn√§rp√§√§menetelm√§√§' varmistaaksesi.

    ```python
    plt.figure(figsize=(10,5))
    sns.lineplot(x=range(1, 11), y=wcss, marker='o', color='red')
    plt.title('Elbow')
    plt.xlabel('Number of clusters')
    plt.ylabel('WCSS')
    plt.show()
    ```

    K√§yt√§ `wcss`-muuttujaa, jonka rakensit edellisess√§ vaiheessa, luodaksesi kaavion, joka n√§ytt√§√§, miss√§ kyyn√§rp√§√§n "taite" on, mik√§ osoittaa optimaalisen klusterien m√§√§r√§n. Ehk√§ se **onkin** 3!

    ![elbow method](../../../../5-Clustering/2-K-Means/images/elbow.png)

## Harjoitus - klustereiden n√§ytt√§minen

1. Kokeile prosessia uudelleen, t√§ll√§ kertaa asettamalla kolme klusteria, ja n√§yt√§ klusterit hajontakaaviona:

    ```python
    from sklearn.cluster import KMeans
    kmeans = KMeans(n_clusters = 3)
    kmeans.fit(X)
    labels = kmeans.predict(X)
    plt.scatter(df['popularity'],df['danceability'],c = labels)
    plt.xlabel('popularity')
    plt.ylabel('danceability')
    plt.show()
    ```

1. Tarkista mallin tarkkuus:

    ```python
    labels = kmeans.labels_
    
    correct_labels = sum(y == labels)
    
    print("Result: %d out of %d samples were correctly labeled." % (correct_labels, y.size))
    
    print('Accuracy score: {0:0.2f}'. format(correct_labels/float(y.size)))
    ```

    T√§m√§n mallin tarkkuus ei ole kovin hyv√§, ja klustereiden muoto antaa vihjeen miksi.

    ![clusters](../../../../5-Clustering/2-K-Means/images/clusters.png)

    T√§m√§ data on liian ep√§tasapainoista, liian v√§h√§n korreloitua ja sarakearvojen v√§lill√§ on liikaa vaihtelua, jotta klusterointi onnistuisi hyvin. Itse asiassa muodostuvat klusterit ovat todenn√§k√∂isesti vahvasti vaikuttuneita tai vinoutuneita yll√§ m√§√§rittelemiemme kolmen tyylilajin mukaan. T√§m√§ oli oppimisprosessi!

    Scikit-learnin dokumentaatiosta voit n√§hd√§, ett√§ t√§llaisella mallilla, jossa klusterit eiv√§t ole kovin hyvin rajattuja, on 'varianssi'-ongelma:

    ![problem models](../../../../5-Clustering/2-K-Means/images/problems.png)
    > Infografiikka: Scikit-learn

## Varianssi

Varianssi m√§√§ritell√§√§n "keskiarvona neli√∂llisist√§ eroista keskiarvosta" [(L√§hde)](https://www.mathsisfun.com/data/standard-deviation.html). T√§ss√§ klusterointiongelman kontekstissa se viittaa dataan, jossa datasetin numerot poikkeavat hieman liikaa keskiarvosta.

‚úÖ T√§m√§ on hyv√§ hetki mietti√§ kaikkia tapoja, joilla voisit korjata t√§m√§n ongelman. Voisitko muokata dataa hieman enemm√§n? K√§ytt√§√§ eri sarakkeita? K√§ytt√§√§ eri algoritmia? Vinkki: Kokeile [skaalata dataasi](https://www.mygreatlearning.com/blog/learning-data-science-with-k-means-clustering/) normalisoidaksesi sen ja testataksesi muita sarakkeita.

> Kokeile t√§t√§ '[varianssilaskuria](https://www.calculatorsoup.com/calculators/statistics/variance-calculator.php)' ymm√§rt√§√§ksesi konseptia hieman paremmin.

---

## üöÄHaaste

K√§yt√§ aikaa t√§m√§n notebookin parissa ja s√§√§d√§ parametreja. Voitko parantaa mallin tarkkuutta puhdistamalla dataa enemm√§n (esimerkiksi poistamalla poikkeamat)? Voit k√§ytt√§√§ painotuksia antaaksesi enemm√§n painoarvoa tietyille datan√§ytteille. Mit√§ muuta voisit tehd√§ luodaksesi parempia klustereita?

Vinkki: Kokeile skaalata dataasi. Notebookissa on kommentoitua koodia, joka lis√§√§ standardisoinnin, jotta datan sarakkeet muistuttaisivat toisiaan enemm√§n vaihteluv√§lin osalta. Huomaat, ett√§ vaikka silhouette-piste laskee, kyyn√§rp√§√§kaavion "taite" tasoittuu. T√§m√§ johtuu siit√§, ett√§ j√§tt√§m√§ll√§ datan skaalaamatta, data, jolla on v√§hemm√§n varianssia, saa enemm√§n painoarvoa. Lue lis√§√§ t√§st√§ ongelmasta [t√§√§lt√§](https://stats.stackexchange.com/questions/21222/are-mean-normalization-and-feature-scaling-needed-for-k-means-clustering/21226#21226).

## [Post-lecture quiz](https://ff-quizzes.netlify.app/en/ml/)

## Kertaus ja itseopiskelu

Tutustu K-Means-simulaattoriin [kuten t√§h√§n](https://user.ceng.metu.edu.tr/~akifakkus/courses/ceng574/k-means/). Voit k√§ytt√§√§ t√§t√§ ty√∂kalua visualisoidaksesi n√§ytepisteit√§ ja m√§√§ritt√§√§ksesi niiden keskipisteet. Voit muokata datan satunnaisuutta, klusterien m√§√§r√§√§ ja keskipisteiden m√§√§r√§√§. Auttaako t√§m√§ sinua saamaan k√§sityksen siit√§, miten data voidaan ryhmitell√§?

Tutustu my√∂s [t√§h√§n K-Means-materiaaliin](https://stanford.edu/~cpiech/cs221/handouts/kmeans.html) Stanfordilta.

## Teht√§v√§

[Kokeile eri klusterointimenetelmi√§](assignment.md)

---

**Vastuuvapauslauseke**:  
T√§m√§ asiakirja on k√§√§nnetty k√§ytt√§m√§ll√§ teko√§lypohjaista k√§√§nn√∂spalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, ett√§ automaattiset k√§√§nn√∂kset voivat sis√§lt√§√§ virheit√§ tai ep√§tarkkuuksia. Alkuper√§inen asiakirja sen alkuper√§isell√§ kielell√§ tulisi pit√§√§ ensisijaisena l√§hteen√§. Kriittisen tiedon osalta suositellaan ammattimaista ihmisk√§√§nn√∂st√§. Emme ole vastuussa v√§√§rink√§sityksist√§ tai virhetulkinnoista, jotka johtuvat t√§m√§n k√§√§nn√∂ksen k√§yt√∂st√§.