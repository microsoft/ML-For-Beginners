<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "9660fbd80845c59c15715cb418cd6e23",
  "translation_date": "2025-08-29T18:16:22+00:00",
  "source_file": "8-Reinforcement/2-Gym/README.md",
  "language_code": "pa"
}
-->
## ‡®™‡©Ç‡®∞‡®µ ‡®∏‡®º‡®∞‡®§‡®æ‡®Ç

‡®á‡®∏ ‡®™‡®æ‡®† ‡®µ‡®ø‡©±‡®ö, ‡®Ö‡®∏‡©Ä‡®Ç **OpenAI Gym** ‡®®‡®æ‡®Æ‡®ï ‡®≤‡®æ‡®á‡®¨‡©ç‡®∞‡©á‡®∞‡©Ä ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®æ‡®Ç‡®ó‡©á ‡®ú‡©ã ‡®µ‡©±‡®ñ-‡®µ‡©±‡®ñ **‡®Æ‡®æ‡®π‡©å‡®≤‡®æ‡®Ç** ‡®¶‡©Ä ‡®®‡®ï‡®≤ ‡®ï‡®∞‡®¶‡©Ä ‡®π‡©à‡•§ ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®á‡®∏ ‡®™‡®æ‡®† ‡®¶‡®æ ‡®ï‡©ã‡®° ‡®Ü‡®™‡®£‡©á ‡®∏‡®•‡®æ‡®®‡®ï ‡®∏‡®ø‡®∏‡®ü‡®Æ (‡®ú‡®ø‡®µ‡©á‡®Ç Visual Studio Code) '‡®§‡©á ‡®ö‡®≤‡®æ ‡®∏‡®ï‡®¶‡©á ‡®π‡©ã, ‡®ú‡®ø‡®∏ ‡®µ‡®ø‡©±‡®ö ‡®∏‡®ø‡®Æ‡©Ç‡®≤‡©á‡®∏‡®º‡®® ‡®á‡©±‡®ï ‡®®‡®µ‡©Ä‡®Ç ‡®µ‡®ø‡©∞‡®°‡©ã ‡®µ‡®ø‡©±‡®ö ‡®ñ‡©Å‡©±‡®≤‡©á‡®ó‡®æ‡•§ ‡®ú‡©á ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®ï‡©ã‡®° ‡®Ü‡®®‡®≤‡®æ‡®à‡®® ‡®ö‡®≤‡®æ ‡®∞‡®π‡©á ‡®π‡©ã, ‡®§‡®æ‡®Ç ‡®§‡©Å‡®π‡®æ‡®®‡©Ç‡©∞ ‡®ï‡©Å‡®ù ‡®ï‡©ã‡®° ‡®µ‡®ø‡©±‡®ö ‡®§‡®¨‡®¶‡©Ä‡®≤‡©Ä‡®Ü‡®Ç ‡®ï‡®∞‡®® ‡®¶‡©Ä ‡®≤‡©ã‡©ú ‡®π‡©ã ‡®∏‡®ï‡®¶‡©Ä ‡®π‡©à, ‡®ú‡®ø‡®µ‡©á‡®Ç ‡®ï‡®ø [‡®á‡©±‡®•‡©á](https://towardsdatascience.com/rendering-openai-gym-envs-on-binder-and-google-colab-536f99391cc7) ‡®µ‡®∞‡®£‡®® ‡®ï‡©Ä‡®§‡®æ ‡®ó‡®ø‡®Ü ‡®π‡©à‡•§

## OpenAI Gym

‡®™‡®ø‡®õ‡®≤‡©á ‡®™‡®æ‡®† ‡®µ‡®ø‡©±‡®ö, ‡®ñ‡©á‡®° ‡®¶‡©á ‡®®‡®ø‡®Ø‡®Æ ‡®Ö‡®§‡©á ‡®∏‡®•‡®ø‡®§‡©Ä ‡®®‡©Ç‡©∞ `Board` ‡®ï‡®≤‡®æ‡®∏ ‡®¶‡©Å‡®Ü‡®∞‡®æ ‡®™‡®∞‡®ø‡®≠‡®æ‡®∏‡®º‡®ø‡®§ ‡®ï‡©Ä‡®§‡®æ ‡®ó‡®ø‡®Ü ‡®∏‡©Ä, ‡®ú‡®ø‡®∏ ‡®®‡©Ç‡©∞ ‡®Ö‡®∏‡©Ä‡®Ç ‡®ñ‡©Å‡®¶ ‡®¨‡®£‡®æ‡®á‡®Ü ‡®∏‡©Ä‡•§ ‡®á‡©±‡®•‡©á ‡®Ö‡®∏‡©Ä‡®Ç ‡®á‡©±‡®ï ‡®µ‡®ø‡®∏‡®º‡©á‡®∏‡®º **‡®∏‡®ø‡®Æ‡©Ç‡®≤‡©á‡®∏‡®º‡®® ‡®Æ‡®æ‡®π‡©å‡®≤** ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®æ‡®Ç‡®ó‡©á, ‡®ú‡©ã ‡®¨‡©à‡®≤‡©∞‡®∏‡®ø‡©∞‡®ó ‡®™‡©ã‡®≤ ‡®¶‡©á ‡®≠‡©å‡®§‡®ø‡®ï ‡®µ‡®ø‡®ó‡®ø‡®Ü‡®® ‡®¶‡©Ä ‡®®‡®ï‡®≤ ‡®ï‡®∞‡©á‡®ó‡®æ‡•§ ‡®∞‡©Ä‡®á‡®®‡®´‡©ã‡®∞‡®∏‡®Æ‡©à‡®Ç‡®ü ‡®≤‡®∞‡®®‡®ø‡©∞‡®ó ‡®ê‡®≤‡®ó‡©ã‡®∞‡®ø‡®•‡®Æ‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®∏‡®ø‡®ñ‡®æ‡®â‡®£ ‡®≤‡®à ‡®∏‡®≠ ‡®§‡©ã‡®Ç ‡®™‡©ç‡®∞‡®∏‡®ø‡©±‡®ß ‡®∏‡®ø‡®Æ‡©Ç‡®≤‡©á‡®∏‡®º‡®® ‡®Æ‡®æ‡®π‡©å‡®≤‡®æ‡®Ç ‡®µ‡®ø‡©±‡®ö‡©ã‡®Ç ‡®á‡©±‡®ï [Gym](https://gym.openai.com/) ‡®π‡©à, ‡®ú‡®ø‡®∏‡®®‡©Ç‡©∞ [OpenAI](https://openai.com/) ‡®¶‡©Å‡®Ü‡®∞‡®æ ‡®∏‡©∞‡®≠‡®æ‡®≤‡®ø‡®Ü ‡®ú‡®æ‡®Ç‡®¶‡®æ ‡®π‡©à‡•§ ‡®á‡®∏ Gym ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®Ö‡®∏‡©Ä‡®Ç ‡®µ‡©±‡®ñ-‡®µ‡©±‡®ñ **‡®Æ‡®æ‡®π‡©å‡®≤‡®æ‡®Ç** ‡®¨‡®£‡®æ‡®â‡®£ ‡®¶‡©á ‡®Ø‡©ã‡®ó ‡®π‡©ã ‡®ú‡®æ‡®µ‡®æ‡®Ç‡®ó‡©á, ‡®ú‡®ø‡®µ‡©á‡®Ç ‡®ï‡®ø cartpole simulation ‡®§‡©ã‡®Ç Atari games ‡®§‡©±‡®ï‡•§

> **Note**: ‡®§‡©Å‡®∏‡©Ä‡®Ç OpenAI Gym ‡®¶‡©Å‡®Ü‡®∞‡®æ ‡®â‡®™‡®≤‡®¨‡®ß ‡®π‡©ã‡®∞ ‡®Æ‡®æ‡®π‡©å‡®≤‡®æ‡®Ç ‡®®‡©Ç‡©∞ [‡®á‡©±‡®•‡©á](https://gym.openai.com/envs/#classic_control) ‡®¶‡©á‡®ñ ‡®∏‡®ï‡®¶‡©á ‡®π‡©ã‡•§

‡®∏‡®≠ ‡®§‡©ã‡®Ç ‡®™‡®π‡®ø‡®≤‡®æ‡®Ç, Gym ‡®®‡©Ç‡©∞ ‡®á‡©∞‡®∏‡®ü‡®æ‡®≤ ‡®ï‡®∞‡©ã ‡®Ö‡®§‡©á ‡®≤‡©ã‡©ú‡©Ä‡®Ç‡®¶‡©á ‡®≤‡®æ‡®á‡®¨‡©ç‡®∞‡©á‡®∞‡©Ä‡®ú‡®º ‡®®‡©Ç‡©∞ ‡®á‡©∞‡®™‡©ã‡®∞‡®ü ‡®ï‡®∞‡©ã (code block 1):

```python
import sys
!{sys.executable} -m pip install gym 

import gym
import matplotlib.pyplot as plt
import numpy as np
import random
```

## ‡®Ö‡®≠‡®ø‡®Ü‡®∏ - ‡®á‡©±‡®ï cartpole ‡®Æ‡®æ‡®π‡©å‡®≤ ‡®∏‡®º‡©Å‡®∞‡©Ç ‡®ï‡®∞‡©ã

Cartpole ‡®¨‡©à‡®≤‡©∞‡®∏‡®ø‡©∞‡®ó ‡®∏‡®Æ‡©±‡®∏‡®ø‡®Ü '‡®§‡©á ‡®ï‡©∞‡®Æ ‡®ï‡®∞‡®® ‡®≤‡®à, ‡®∏‡®æ‡®®‡©Ç‡©∞ ‡®∏‡©∞‡®¨‡©∞‡®ß‡®ø‡®§ ‡®Æ‡®æ‡®π‡©å‡®≤ ‡®∏‡®º‡©Å‡®∞‡©Ç ‡®ï‡®∞‡®® ‡®¶‡©Ä ‡®≤‡©ã‡©ú ‡®π‡©à‡•§ ‡®π‡®∞ ‡®Æ‡®æ‡®π‡©å‡®≤ ‡®®‡®æ‡®≤ ‡®ú‡©Å‡©ú‡®ø‡®Ü ‡®π‡©Å‡©∞‡®¶‡®æ ‡®π‡©à:

- **Observation space** ‡®ú‡©ã ‡®Æ‡®æ‡®π‡©å‡®≤ ‡®§‡©ã‡®Ç ‡®™‡©ç‡®∞‡®æ‡®™‡®§ ‡®ú‡®æ‡®£‡®ï‡®æ‡®∞‡©Ä ‡®¶‡©Ä ‡®¨‡®£‡®§‡®∞ ‡®®‡©Ç‡©∞ ‡®™‡®∞‡®ø‡®≠‡®æ‡®∏‡®º‡®ø‡®§ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à‡•§ Cartpole ‡®∏‡®Æ‡©±‡®∏‡®ø‡®Ü ‡®≤‡®à, ‡®∏‡®æ‡®®‡©Ç‡©∞ ‡®™‡©ã‡®≤ ‡®¶‡©Ä ‡®∏‡®•‡®ø‡®§‡©Ä, ‡®ó‡®§‡©Ä ‡®Ö‡®§‡©á ‡®ï‡©Å‡®ù ‡®π‡©ã‡®∞ ‡®Æ‡©Å‡©±‡®≤ ‡®™‡©ç‡®∞‡®æ‡®™‡®§ ‡®π‡©Å‡©∞‡®¶‡©á ‡®π‡®®‡•§

- **Action space** ‡®ú‡©ã ‡®∏‡©∞‡®≠‡®æ‡®µ‡®ø‡®§ ‡®ï‡®æ‡®∞‡®µ‡®æ‡®à‡®Ü‡®Ç ‡®®‡©Ç‡©∞ ‡®™‡®∞‡®ø‡®≠‡®æ‡®∏‡®º‡®ø‡®§ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à‡•§ ‡®∏‡®æ‡®°‡©á ‡®ï‡©á‡®∏ ‡®µ‡®ø‡©±‡®ö, action space discrete ‡®π‡©à, ‡®Ö‡®§‡©á ‡®á‡®∏ ‡®µ‡®ø‡©±‡®ö ‡®¶‡©ã ‡®ï‡®æ‡®∞‡®µ‡®æ‡®à‡®Ü‡®Ç ‡®π‡®® - **‡®ñ‡©±‡®¨‡©á** ‡®Ö‡®§‡©á **‡®∏‡©±‡®ú‡©á**‡•§ (code block 2)

1. ‡®∏‡®º‡©Å‡®∞‡©Ç ‡®ï‡®∞‡®® ‡®≤‡®à, ‡®π‡©á‡®†‡®æ‡®Ç ‡®¶‡®ø‡©±‡®§‡®æ ‡®ï‡©ã‡®° ‡®≤‡®ø‡®ñ‡©ã:

    ```python
    env = gym.make("CartPole-v1")
    print(env.action_space)
    print(env.observation_space)
    print(env.action_space.sample())
    ```

‡®Æ‡®æ‡®π‡©å‡®≤ ‡®ï‡®ø‡®µ‡©á‡®Ç ‡®ï‡©∞‡®Æ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à, ‡®á‡®π ‡®¶‡©á‡®ñ‡®£ ‡®≤‡®à, ‡®Ü‡®ì 100 ‡®ï‡®¶‡®Æ‡®æ‡®Ç ‡®≤‡®à ‡®á‡©±‡®ï ‡®õ‡©ã‡®ü‡©Ä ‡®∏‡®ø‡®Æ‡©Ç‡®≤‡©á‡®∏‡®º‡®® ‡®ö‡®≤‡®æ‡®à‡®è‡•§ ‡®π‡®∞ ‡®ï‡®¶‡®Æ '‡®§‡©á, ‡®Ö‡®∏‡©Ä‡®Ç ‡®á‡©±‡®ï ‡®ï‡®æ‡®∞‡®µ‡®æ‡®à ‡®™‡©ç‡®∞‡®¶‡®æ‡®® ‡®ï‡®∞‡®¶‡©á ‡®π‡®æ‡®Ç - ‡®á‡®∏ ‡®∏‡®ø‡®Æ‡©Ç‡®≤‡©á‡®∏‡®º‡®® ‡®µ‡®ø‡©±‡®ö ‡®Ö‡®∏‡©Ä‡®Ç ‡®∏‡®ø‡®∞‡®´‡®º `action_space` ‡®§‡©ã‡®Ç ‡®á‡©±‡®ï ‡®ï‡®æ‡®∞‡®µ‡®æ‡®à ‡®®‡©Ç‡©∞ ‡®∞‡©à‡®Ç‡®°‡®Æ ‡®§‡®∞‡©Ä‡®ï‡©á ‡®®‡®æ‡®≤ ‡®ö‡©Å‡®£‡®¶‡©á ‡®π‡®æ‡®Ç‡•§

1. ‡®π‡©á‡®†‡®æ‡®Ç ‡®¶‡®ø‡©±‡®§‡®æ ‡®ï‡©ã‡®° ‡®ö‡®≤‡®æ‡®ì ‡®Ö‡®§‡©á ‡®¶‡©á‡®ñ‡©ã ‡®ï‡®ø ‡®á‡®π ‡®ï‡©Ä ‡®®‡®§‡©Ä‡®ú‡®æ ‡®¶‡®ø‡©∞‡®¶‡®æ ‡®π‡©à‡•§

    ‚úÖ ‡®Ø‡®æ‡®¶ ‡®∞‡©±‡®ñ‡©ã ‡®ï‡®ø ‡®á‡®π ‡®ï‡©ã‡®° ‡®∏‡®•‡®æ‡®®‡®ï Python ‡®á‡©∞‡®∏‡®ü‡®æ‡®≤‡©á‡®∏‡®º‡®® '‡®§‡©á ‡®ö‡®≤‡®æ‡®â‡®£‡®æ ‡®µ‡®ß‡©Ä‡®Ü ‡®π‡©à! (code block 3)

    ```python
    env.reset()
    
    for i in range(100):
       env.render()
       env.step(env.action_space.sample())
    env.close()
    ```

    ‡®§‡©Å‡®π‡®æ‡®®‡©Ç‡©∞ ‡®ï‡©Å‡®ù ‡®á‡®∏ ‡®§‡®∞‡©ç‡®π‡®æ‡®Ç ‡®¶‡©Ä ‡®§‡®∏‡®µ‡©Ä‡®∞ ‡®¶‡©á‡®ñ‡®£‡©Ä ‡®ö‡®æ‡®π‡©Ä‡®¶‡©Ä ‡®π‡©à:

    ![non-balancing cartpole](../../../../8-Reinforcement/2-Gym/images/cartpole-nobalance.gif)

1. ‡®∏‡®ø‡®Æ‡©Ç‡®≤‡©á‡®∏‡®º‡®® ‡®¶‡©å‡®∞‡®æ‡®®, ‡®∏‡®æ‡®®‡©Ç‡©∞ ‡®®‡®ø‡®∞‡®£‡®Ø ‡®≤‡©à‡®£ ‡®≤‡®à observations ‡®™‡©ç‡®∞‡®æ‡®™‡®§ ‡®ï‡®∞‡®® ‡®¶‡©Ä ‡®≤‡©ã‡©ú ‡®π‡©Å‡©∞‡®¶‡©Ä ‡®π‡©à‡•§ ‡®Ö‡®∏‡®≤ ‡®µ‡®ø‡©±‡®ö, step function ‡®Æ‡©å‡®ú‡©Ç‡®¶‡®æ observations, ‡®á‡©±‡®ï reward function, ‡®Ö‡®§‡©á done flag ‡®µ‡®æ‡®™‡®∏ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à ‡®ú‡©ã ‡®á‡®π ‡®¶‡®∞‡®∏‡®æ‡®â‡®Ç‡®¶‡®æ ‡®π‡©à ‡®ï‡®ø ‡®∏‡®ø‡®Æ‡©Ç‡®≤‡©á‡®∏‡®º‡®® ‡®ú‡®æ‡®∞‡©Ä ‡®∞‡©±‡®ñ‡®£ ‡®¶‡®æ ‡®ï‡©ã‡®à ‡®Æ‡®§‡®≤‡®¨ ‡®π‡©à ‡®ú‡®æ‡®Ç ‡®®‡®π‡©Ä‡®Ç: (code block 4)

    ```python
    env.reset()
    
    done = False
    while not done:
       env.render()
       obs, rew, done, info = env.step(env.action_space.sample())
       print(f"{obs} -> {rew}")
    env.close()
    ```

    ‡®§‡©Å‡®π‡®æ‡®®‡©Ç‡©∞ ‡®®‡©ã‡®ü‡®¨‡©Å‡©±‡®ï ‡®Ü‡®â‡®ü‡®™‡©Å‡©±‡®ü ‡®µ‡®ø‡©±‡®ö ‡®ï‡©Å‡®ù ‡®á‡®∏ ‡®§‡®∞‡©ç‡®π‡®æ‡®Ç ‡®¶‡©á‡®ñ‡®£ ‡®®‡©Ç‡©∞ ‡®Æ‡®ø‡®≤‡©á‡®ó‡®æ:

    ```text
    [ 0.03403272 -0.24301182  0.02669811  0.2895829 ] -> 1.0
    [ 0.02917248 -0.04828055  0.03248977  0.00543839] -> 1.0
    [ 0.02820687  0.14636075  0.03259854 -0.27681916] -> 1.0
    [ 0.03113408  0.34100283  0.02706215 -0.55904489] -> 1.0
    [ 0.03795414  0.53573468  0.01588125 -0.84308041] -> 1.0
    ...
    [ 0.17299878  0.15868546 -0.20754175 -0.55975453] -> 1.0
    [ 0.17617249  0.35602306 -0.21873684 -0.90998894] -> 1.0
    ```

    ‡®∏‡®ø‡®Æ‡©Ç‡®≤‡©á‡®∏‡®º‡®® ‡®¶‡©á ‡®π‡®∞ ‡®ï‡®¶‡®Æ '‡®§‡©á ‡®µ‡®æ‡®™‡®∏ ‡®ï‡©Ä‡®§‡©á ‡®ó‡®è observation vector ‡®µ‡®ø‡©±‡®ö ‡®π‡©á‡®†‡®æ‡®Ç ‡®¶‡®ø‡©±‡®§‡©á ‡®Æ‡©Å‡©±‡®≤ ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®π‡©Å‡©∞‡®¶‡©á ‡®π‡®®:
    - Cart ‡®¶‡©Ä ‡®∏‡®•‡®ø‡®§‡©Ä
    - Cart ‡®¶‡©Ä ‡®ó‡®§‡©Ä
    - Pole ‡®¶‡®æ ‡®ï‡©ã‡®£
    - Pole ‡®¶‡©Ä ‡®ò‡©Å‡©∞‡®Æ‡®£ ‡®¶‡©Ä ‡®¶‡®∞

1. ‡®â‡®π‡®®‡®æ‡®Ç ‡®®‡©∞‡®¨‡®∞‡®æ‡®Ç ‡®¶‡©á ‡®ò‡©±‡®ü‡©ã-‡®ò‡©±‡®ü ‡®Ö‡®§‡©á ‡®µ‡©±‡®ß ‡®§‡©ã‡®Ç ‡®µ‡©±‡®ß ‡®Æ‡©Å‡©±‡®≤ ‡®™‡©ç‡®∞‡®æ‡®™‡®§ ‡®ï‡®∞‡©ã: (code block 5)

    ```python
    print(env.observation_space.low)
    print(env.observation_space.high)
    ```

    ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®á‡®π ‡®µ‡©Ä ‡®®‡©ã‡®ü ‡®ï‡®∞ ‡®∏‡®ï‡®¶‡©á ‡®π‡©ã ‡®ï‡®ø ‡®π‡®∞ ‡®∏‡®ø‡®Æ‡©Ç‡®≤‡©á‡®∏‡®º‡®® ‡®ï‡®¶‡®Æ '‡®§‡©á reward value ‡®π‡®Æ‡©á‡®∏‡®º‡®æ 1 ‡®π‡©Å‡©∞‡®¶‡©Ä ‡®π‡©à‡•§ ‡®á‡®π ‡®á‡®∏ ‡®≤‡®à ‡®π‡©à ‡®ï‡®ø‡®â‡®Ç‡®ï‡®ø ‡®∏‡®æ‡®°‡®æ ‡®≤‡®ï‡®∏‡®º ‡®π‡©à ‡®ú‡®ø‡©∞‡®®‡®æ ‡®π‡©ã ‡®∏‡®ï‡©á ‡®≤‡©∞‡®¨‡©á ‡®∏‡®Æ‡©á‡®Ç ‡®≤‡®à ‡®™‡©ã‡®≤ ‡®®‡©Ç‡©∞ ‡®á‡©±‡®ï ‡®∏‡®Æ‡®ù‡®¶‡®æ‡®∞ vertical ‡®∏‡®•‡®ø‡®§‡©Ä ‡®µ‡®ø‡©±‡®ö ‡®∞‡©±‡®ñ‡®£‡®æ‡•§

    ‚úÖ ‡®Ö‡®∏‡®≤ ‡®µ‡®ø‡©±‡®ö, CartPole ‡®∏‡®ø‡®Æ‡©Ç‡®≤‡©á‡®∏‡®º‡®® ‡®®‡©Ç‡©∞ solved ‡®Æ‡©∞‡®®‡®ø‡®Ü ‡®ú‡®æ‡®Ç‡®¶‡®æ ‡®π‡©à ‡®ú‡©á‡®ï‡®∞ ‡®Ö‡®∏‡©Ä‡®Ç 100 ‡®≤‡®ó‡®æ‡®§‡®æ‡®∞ ‡®ü‡©ç‡®∞‡®æ‡®á‡®≤‡®æ‡®Ç '‡®§‡©á 195 ‡®¶‡®æ ‡®î‡®∏‡®§ reward ‡®™‡©ç‡®∞‡®æ‡®™‡®§ ‡®ï‡®∞ ‡®∏‡®ï‡®¶‡©á ‡®π‡®æ‡®Ç‡•§

## ‡®∏‡®•‡®ø‡®§‡©Ä ‡®®‡©Ç‡©∞ discrete ‡®¨‡®£‡®æ‡®â‡®£‡®æ

Q-Learning ‡®µ‡®ø‡©±‡®ö, ‡®∏‡®æ‡®®‡©Ç‡©∞ Q-Table ‡®¨‡®£‡®æ‡®â‡®£ ‡®¶‡©Ä ‡®≤‡©ã‡©ú ‡®π‡©Å‡©∞‡®¶‡©Ä ‡®π‡©à ‡®ú‡©ã ‡®π‡®∞ ‡®∏‡®•‡®ø‡®§‡©Ä '‡®§‡©á ‡®ï‡©Ä ‡®ï‡®∞‡®®‡®æ ‡®π‡©à ‡®á‡®π ‡®™‡®∞‡®ø‡®≠‡®æ‡®∏‡®º‡®ø‡®§ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à‡•§ ‡®á‡®π ‡®ï‡®∞‡®® ‡®≤‡®à, ‡®∏‡®•‡®ø‡®§‡©Ä **discreet** ‡®π‡©ã‡®£‡©Ä ‡®ö‡®æ‡®π‡©Ä‡®¶‡©Ä ‡®π‡©à, ‡®ú‡®º‡®ø‡®Ü‡®¶‡®æ ‡®∏‡®π‡©Ä ‡®§‡©å‡®∞ '‡®§‡©á, ‡®á‡®∏ ‡®µ‡®ø‡©±‡®ö finite number of discrete values ‡®π‡©ã‡®£‡©Ä‡®Ü‡®Ç ‡®ö‡®æ‡®π‡©Ä‡®¶‡©Ä‡®Ü‡®Ç ‡®π‡®®‡•§ ‡®á‡®∏ ‡®≤‡®à, ‡®∏‡®æ‡®®‡©Ç‡©∞ ‡®ï‡®ø‡®∏‡©á ‡®§‡®∞‡©Ä‡®ï‡©á ‡®®‡®æ‡®≤ ‡®Ü‡®™‡®£‡©á observations ‡®®‡©Ç‡©∞ **discretize** ‡®ï‡®∞‡®®‡®æ ‡®™‡®µ‡©á‡®ó‡®æ, ‡®Ö‡®§‡©á ‡®â‡®®‡©ç‡®π‡®æ‡®Ç ‡®®‡©Ç‡©∞ finite set of states ‡®µ‡®ø‡©±‡®ö ‡®Æ‡©à‡®™ ‡®ï‡®∞‡®®‡®æ ‡®™‡®µ‡©á‡®ó‡®æ‡•§

‡®á‡®∏ ‡®®‡©Ç‡©∞ ‡®ï‡®∞‡®® ‡®¶‡©á ‡®ï‡©Å‡®ù ‡®§‡®∞‡©Ä‡®ï‡©á ‡®π‡®®:

- **Bins ‡®µ‡®ø‡©±‡®ö ‡®µ‡©∞‡®°‡©ã**‡•§ ‡®ú‡©á‡®ï‡®∞ ‡®∏‡®æ‡®®‡©Ç‡©∞ ‡®ï‡®ø‡®∏‡©á ‡®Æ‡©Å‡©±‡®≤ ‡®¶‡©á interval ‡®¶‡®æ ‡®™‡®§‡®æ ‡®π‡©à, ‡®§‡®æ‡®Ç ‡®Ö‡®∏‡©Ä‡®Ç ‡®á‡®∏ interval ‡®®‡©Ç‡©∞ ‡®ï‡©Å‡®ù **bins** ‡®µ‡®ø‡©±‡®ö ‡®µ‡©∞‡®° ‡®∏‡®ï‡®¶‡©á ‡®π‡®æ‡®Ç, ‡®Ö‡®§‡©á ‡®´‡®ø‡®∞ ‡®â‡®∏ ‡®Æ‡©Å‡©±‡®≤ ‡®®‡©Ç‡©∞ ‡®â‡®∏ bin number ‡®®‡®æ‡®≤ ‡®¨‡®¶‡®≤ ‡®∏‡®ï‡®¶‡©á ‡®π‡®æ‡®Ç ‡®ú‡®ø‡®∏ ‡®µ‡®ø‡©±‡®ö ‡®á‡®π ‡®∏‡®º‡®æ‡®Æ‡®≤ ‡®π‡©à‡•§ ‡®á‡®π numpy ‡®¶‡©á [`digitize`](https://numpy.org/doc/stable/reference/generated/numpy.digitize.html) ‡®µ‡®ø‡®ß‡©Ä ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®ï‡©Ä‡®§‡®æ ‡®ú‡®æ ‡®∏‡®ï‡®¶‡®æ ‡®π‡©à‡•§ ‡®á‡®∏ ‡®ï‡©á‡®∏ ‡®µ‡®ø‡©±‡®ö, ‡®∏‡®æ‡®®‡©Ç‡©∞ state size ‡®¶‡®æ ‡®∏‡®π‡©Ä ‡®™‡®§‡®æ ‡®π‡©ã‡®µ‡©á‡®ó‡®æ, ‡®ï‡®ø‡®â‡®Ç‡®ï‡®ø ‡®á‡®π bins ‡®¶‡©Ä ‡®ó‡®ø‡®£‡®§‡©Ä '‡®§‡©á ‡®®‡®ø‡®∞‡®≠‡®∞ ‡®ï‡®∞‡©á‡®ó‡®æ ‡®ú‡©ã ‡®Ö‡®∏‡©Ä‡®Ç digitalization ‡®≤‡®à ‡®ö‡©Å‡®£‡®¶‡©á ‡®π‡®æ‡®Ç‡•§

‚úÖ ‡®Ö‡®∏‡©Ä‡®Ç linear interpolation ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®Æ‡©Å‡©±‡®≤‡®æ‡®Ç ‡®®‡©Ç‡©∞ finite interval (‡®ú‡®ø‡®µ‡©á‡®Ç -20 ‡®§‡©ã‡®Ç 20) ‡®µ‡®ø‡©±‡®ö ‡®≤‡®ø‡®Ü ‡®∏‡®ï‡®¶‡©á ‡®π‡®æ‡®Ç, ‡®Ö‡®§‡©á ‡®´‡®ø‡®∞ rounding ‡®ï‡®∞‡®ï‡©á ‡®®‡©∞‡®¨‡®∞‡®æ‡®Ç ‡®®‡©Ç‡©∞ integers ‡®µ‡®ø‡©±‡®ö ‡®¨‡®¶‡®≤ ‡®∏‡®ï‡®¶‡©á ‡®π‡®æ‡®Ç‡•§ ‡®á‡®∏ ‡®§‡®∞‡©Ä‡®ï‡©á ‡®®‡®æ‡®≤ ‡®∏‡®æ‡®®‡©Ç‡©∞ state size '‡®§‡©á ‡®ò‡©±‡®ü ‡®ï‡©∞‡®ü‡®∞‡©ã‡®≤ ‡®Æ‡®ø‡®≤‡®¶‡®æ ‡®π‡©à, ‡®ñ‡®æ‡®∏ ‡®ï‡®∞‡®ï‡©á ‡®ú‡©á‡®ï‡®∞ ‡®∏‡®æ‡®®‡©Ç‡©∞ input values ‡®¶‡©á exact ranges ‡®¶‡®æ ‡®™‡®§‡®æ ‡®®‡®π‡©Ä‡®Ç ‡®π‡©à‡•§ ‡®â‡®¶‡®æ‡®π‡®∞‡®® ‡®≤‡®à, ‡®∏‡®æ‡®°‡©á ‡®ï‡©á‡®∏ ‡®µ‡®ø‡©±‡®ö 4 ‡®µ‡®ø‡©±‡®ö‡©ã‡®Ç 2 ‡®Æ‡©Å‡©±‡®≤‡®æ‡®Ç ‡®¶‡©á ‡®â‡©±‡®™‡®∞/‡®π‡©á‡®†‡®æ‡®Ç ‡®¶‡©Ä‡®Ü‡®Ç ‡®π‡©±‡®¶‡®æ‡®Ç ‡®®‡®π‡©Ä‡®Ç ‡®π‡®®, ‡®ú‡®ø‡®∏ ‡®®‡®æ‡®≤ states ‡®¶‡©Ä infinite ‡®ó‡®ø‡®£‡®§‡©Ä ‡®π‡©ã ‡®∏‡®ï‡®¶‡©Ä ‡®π‡©à‡•§

‡®∏‡®æ‡®°‡©á ‡®â‡®¶‡®æ‡®π‡®∞‡®® ‡®µ‡®ø‡©±‡®ö, ‡®Ö‡®∏‡©Ä‡®Ç ‡®¶‡©Ç‡®ú‡©á ‡®§‡®∞‡©Ä‡®ï‡©á ‡®®‡®æ‡®≤ ‡®ú‡®æ‡®µ‡®æ‡®Ç‡®ó‡©á‡•§ ‡®ú‡®ø‡®µ‡©á‡®Ç ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®¨‡®æ‡®Ö‡®¶ ‡®µ‡®ø‡©±‡®ö ‡®®‡©ã‡®ü‡®ø‡®∏ ‡®ï‡®∞ ‡®∏‡®ï‡®¶‡©á ‡®π‡©ã, undefined upper/lower bounds ‡®¶‡©á ‡®¨‡®æ‡®µ‡®ú‡©Ç‡®¶, ‡®â‡®π ‡®Æ‡©Å‡©±‡®≤ ‡®ï‡®¶‡©á-‡®ï‡®¶‡©á finite intervals ‡®§‡©ã‡®Ç ‡®¨‡®æ‡®π‡®∞ ‡®ú‡®æ‡®Ç‡®¶‡©á ‡®π‡®®, ‡®á‡®∏ ‡®≤‡®à ‡®â‡®π states ‡®ú‡®ø‡®®‡©ç‡®π‡®æ‡®Ç ‡®¶‡©á extreme values ‡®π‡®®, ‡®¨‡®π‡©Å‡®§ ‡®π‡©Ä rare ‡®π‡©ã‡®£‡®ó‡©á‡•§

1. ‡®á‡®π function ‡®π‡©à ‡®ú‡©ã ‡®∏‡®æ‡®°‡©á ‡®Æ‡®æ‡®°‡®≤ ‡®§‡©ã‡®Ç observation ‡®≤‡®µ‡©á‡®ó‡®æ ‡®Ö‡®§‡©á 4 integer values ‡®¶‡©á tuple ‡®®‡©Ç‡©∞ produce ‡®ï‡®∞‡©á‡®ó‡®æ: (code block 6)

    ```python
    def discretize(x):
        return tuple((x/np.array([0.25, 0.25, 0.01, 0.1])).astype(np.int))
    ```

1. ‡®Ü‡®ì bins ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®π‡©ã‡®∞ ‡®á‡©±‡®ï discretization ‡®§‡®∞‡©Ä‡®ï‡©á ‡®¶‡©Ä ‡®µ‡©Ä ‡®ú‡®æ‡®Ç‡®ö ‡®ï‡®∞‡©Ä‡®è: (code block 7)

    ```python
    def create_bins(i,num):
        return np.arange(num+1)*(i[1]-i[0])/num+i[0]
    
    print("Sample bins for interval (-5,5) with 10 bins\n",create_bins((-5,5),10))
    
    ints = [(-5,5),(-2,2),(-0.5,0.5),(-2,2)] # intervals of values for each parameter
    nbins = [20,20,10,10] # number of bins for each parameter
    bins = [create_bins(ints[i],nbins[i]) for i in range(4)]
    
    def discretize_bins(x):
        return tuple(np.digitize(x[i],bins[i]) for i in range(4))
    ```

1. ‡®π‡©Å‡®£ ‡®á‡©±‡®ï ‡®õ‡©ã‡®ü‡©Ä ‡®∏‡®ø‡®Æ‡©Ç‡®≤‡©á‡®∏‡®º‡®® ‡®ö‡®≤‡®æ‡®ì ‡®Ö‡®§‡©á ‡®â‡®π‡®®‡®æ‡®Ç discrete environment values ‡®®‡©Ç‡©∞ observe ‡®ï‡®∞‡©ã‡•§ `discretize` ‡®Ö‡®§‡©á `discretize_bins` ‡®¶‡©ã‡®µ‡®æ‡®Ç ‡®®‡©Ç‡©∞ try ‡®ï‡®∞‡®® ‡®≤‡®à ‡®ñ‡©Å‡©±‡®≤‡©ç‡®π‡®æ ‡®Æ‡®π‡®ø‡®∏‡©Ç‡®∏ ‡®ï‡®∞‡©ã ‡®Ö‡®§‡©á ‡®¶‡©á‡®ñ‡©ã ‡®ï‡®ø ‡®ï‡©Ä ‡®ï‡©ã‡®à ‡®´‡®∞‡®ï ‡®π‡©à‡•§

    ‚úÖ `discretize_bins` bin number ‡®µ‡®æ‡®™‡®∏ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à, ‡®ú‡©ã ‡®ï‡®ø 0-based ‡®π‡©Å‡©∞‡®¶‡®æ ‡®π‡©à‡•§ ‡®á‡®∏ ‡®≤‡®à input variable ‡®¶‡©á ‡®Æ‡©Å‡©±‡®≤‡®æ‡®Ç ‡®¶‡©á ‡®Ü‡®∏-‡®™‡®æ‡®∏ 0 ‡®≤‡®à ‡®á‡®π interval ‡®¶‡©á ‡®µ‡®ø‡®ö‡®ï‡®æ‡®∞ (10) ‡®§‡©ã‡®Ç ‡®®‡©∞‡®¨‡®∞ ‡®µ‡®æ‡®™‡®∏ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à‡•§ `discretize` ‡®µ‡®ø‡©±‡®ö, ‡®Ö‡®∏‡©Ä‡®Ç output values ‡®¶‡©Ä range ‡®¶‡©Ä ‡®ö‡®ø‡©∞‡®§‡®æ ‡®®‡®π‡©Ä‡®Ç ‡®ï‡©Ä‡®§‡©Ä, ‡®ú‡®ø‡®∏ ‡®®‡®æ‡®≤ ‡®â‡®π state values shift ‡®®‡®π‡©Ä‡®Ç ‡®π‡©Å‡©∞‡®¶‡©Ä‡®Ü‡®Ç, ‡®Ö‡®§‡©á 0 0 ‡®®‡©Ç‡©∞ ‡®¶‡®∞‡®∏‡®æ‡®â‡®Ç‡®¶‡®æ ‡®π‡©à‡•§ (code block 8)

    ```python
    env.reset()
    
    done = False
    while not done:
       #env.render()
       obs, rew, done, info = env.step(env.action_space.sample())
       #print(discretize_bins(obs))
       print(discretize(obs))
    env.close()
    ```

    ‚úÖ env.render ‡®®‡®æ‡®≤ ‡®∏‡®º‡©Å‡®∞‡©Ç ‡®π‡©ã‡®£ ‡®µ‡®æ‡®≤‡©Ä line ‡®®‡©Ç‡©∞ uncomment ‡®ï‡®∞‡©ã ‡®ú‡©á‡®ï‡®∞ ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®¶‡©á‡®ñ‡®£‡®æ ‡®ö‡®æ‡®π‡©Å‡©∞‡®¶‡©á ‡®π‡©ã ‡®ï‡®ø ‡®Æ‡®æ‡®π‡©å‡®≤ ‡®ï‡®ø‡®µ‡©á‡®Ç execute ‡®π‡©Å‡©∞‡®¶‡®æ ‡®π‡©à‡•§ ‡®®‡®π‡©Ä‡®Ç ‡®§‡®æ‡®Ç ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®á‡®∏‡®®‡©Ç‡©∞ background ‡®µ‡®ø‡©±‡®ö execute ‡®ï‡®∞ ‡®∏‡®ï‡®¶‡©á ‡®π‡©ã, ‡®ú‡©ã ‡®ï‡®ø ‡®§‡©á‡®ú‡®º ‡®π‡©à‡•§ ‡®Ö‡®∏‡©Ä‡®Ç ‡®Ü‡®™‡®£‡©á Q-Learning ‡®™‡©ç‡®∞‡®ï‡®ø‡®∞‡®ø‡®Ü ‡®¶‡©å‡®∞‡®æ‡®® ‡®á‡®∏ "‡®Ö‡®¶‡©ç‡®∞‡®ø‡®∏‡®º" execution ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®æ‡®Ç‡®ó‡©á‡•§

## Q-Table ‡®¶‡©Ä ‡®¨‡®£‡®§‡®∞

‡®™‡®ø‡®õ‡®≤‡©á ‡®™‡®æ‡®† ‡®µ‡®ø‡©±‡®ö, state ‡®á‡©±‡®ï ‡®∏‡®ß‡®æ‡®∞‡®® ‡®ú‡©ã‡©ú‡©á ‡®®‡©∞‡®¨‡®∞‡®æ‡®Ç ‡®§‡©ã‡®Ç 0 ‡®§‡©ã‡®Ç 8 ‡®§‡©±‡®ï ‡®∏‡©Ä, ‡®Ö‡®§‡©á ‡®á‡®∏ ‡®≤‡®à Q-Table ‡®®‡©Ç‡©∞ numpy tensor ‡®¶‡©Å‡®Ü‡®∞‡®æ shape 8x8x2 ‡®®‡®æ‡®≤ ‡®¶‡®∞‡®∏‡®æ‡®â‡®£‡®æ ‡®∏‡©Å‡®µ‡®ø‡®ß‡®æ‡®ú‡®®‡®ï ‡®∏‡©Ä‡•§ ‡®ú‡©á‡®ï‡®∞ ‡®Ö‡®∏‡©Ä‡®Ç bins discretization ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®¶‡©á ‡®π‡®æ‡®Ç, state vector ‡®¶‡®æ size ‡®µ‡©Ä ‡®ú‡®æ‡®£‡®ø‡®Ü ‡®ú‡®æ‡®Ç‡®¶‡®æ ‡®π‡©à, ‡®á‡®∏ ‡®≤‡®à ‡®Ö‡®∏‡©Ä‡®Ç ‡®â‡®π‡©Ä ‡®§‡®∞‡©Ä‡®ï‡®æ ‡®µ‡®∞‡®§ ‡®∏‡®ï‡®¶‡©á ‡®π‡®æ‡®Ç ‡®Ö‡®§‡©á state ‡®®‡©Ç‡©∞ shape 20x20x10x10x2 ‡®¶‡©á array ‡®¶‡©Å‡®Ü‡®∞‡®æ ‡®¶‡®∞‡®∏‡®æ ‡®∏‡®ï‡®¶‡©á ‡®π‡®æ‡®Ç (‡®á‡©±‡®•‡©á 2 action space ‡®¶‡®æ dimension ‡®π‡©à, ‡®Ö‡®§‡©á ‡®™‡®π‡®ø‡®≤‡©Ä‡®Ü‡®Ç dimensions observation space ‡®µ‡®ø‡©±‡®ö ‡®π‡®∞ parameter ‡®≤‡®à bins ‡®¶‡©Ä ‡®ó‡®ø‡®£‡®§‡©Ä ‡®®‡©Ç‡©∞ ‡®¶‡®∞‡®∏‡®æ‡®â‡®Ç‡®¶‡©Ä‡®Ü‡®Ç ‡®π‡®®)‡•§

‡®π‡®æ‡®≤‡®æ‡®Ç‡®ï‡®ø, ‡®ï‡®à ‡®µ‡®æ‡®∞ observation space ‡®¶‡©á precise dimensions ‡®ú‡®æ‡®£‡©á ‡®®‡®π‡©Ä‡®Ç ‡®ú‡®æ‡®Ç‡®¶‡©á‡•§ `discretize` function ‡®¶‡©á ‡®ï‡©á‡®∏ ‡®µ‡®ø‡©±‡®ö, ‡®Ö‡®∏‡©Ä‡®Ç ‡®ï‡®¶‡©á ‡®µ‡©Ä ‡®á‡®π ‡®Ø‡®ï‡©Ä‡®® ‡®®‡®π‡©Ä‡®Ç ‡®ï‡®∞ ‡®∏‡®ï‡®¶‡©á ‡®ï‡®ø state ‡®ï‡©Å‡®ù ‡®π‡©±‡®¶‡®æ‡®Ç ‡®µ‡®ø‡©±‡®ö ‡®∞‡®π‡©á‡®ó‡©Ä, ‡®ï‡®ø‡®â‡®Ç‡®ï‡®ø ‡®ï‡©Å‡®ù original values bound ‡®®‡®π‡©Ä‡®Ç ‡®π‡®®‡•§ ‡®á‡®∏ ‡®≤‡®à, ‡®Ö‡®∏‡©Ä‡®Ç ‡®•‡©ã‡©ú‡©ç‡®π‡®æ ‡®µ‡©±‡®ñ‡®∞‡®æ ‡®§‡®∞‡©Ä‡®ï‡®æ ‡®µ‡®∞‡®§‡®æ‡®Ç‡®ó‡©á ‡®Ö‡®§‡©á Q-Table ‡®®‡©Ç‡©∞ dictionary ‡®¶‡©Å‡®Ü‡®∞‡®æ ‡®¶‡®∞‡®∏‡®æ‡®â‡®Ç‡®¶‡©á ‡®π‡®æ‡®Ç‡•§

1. *(state,action)* ‡®ú‡©ã‡©ú‡©á ‡®®‡©Ç‡©∞ dictionary key ‡®µ‡®ú‡©ã‡®Ç ‡®µ‡®∞‡®§‡©ã, ‡®Ö‡®§‡©á value Q-Table entry value ‡®®‡©Ç‡©∞ ‡®¶‡®∞‡®∏‡®æ‡®â‡®Ç‡®¶‡©Ä ‡®π‡©ã‡®µ‡©á‡®ó‡©Ä‡•§ (code block 9)

    ```python
    Q = {}
    actions = (0,1)
    
    def qvalues(state):
        return [Q.get((state,a),0) for a in actions]
    ```

    ‡®á‡©±‡®•‡©á ‡®Ö‡®∏‡©Ä‡®Ç ‡®á‡©±‡®ï function `qvalues()` ‡®µ‡©Ä define ‡®ï‡®∞‡®¶‡©á ‡®π‡®æ‡®Ç, ‡®ú‡©ã ‡®¶‡®ø‡©±‡®§‡©á state ‡®≤‡®à Q-Table values ‡®¶‡©Ä list ‡®µ‡®æ‡®™‡®∏ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à ‡®ú‡©ã ‡®∏‡®æ‡®∞‡©Ä‡®Ü‡®Ç ‡®∏‡©∞‡®≠‡®æ‡®µ‡®ø‡®§ actions ‡®®‡©Ç‡©∞ ‡®¶‡®∞‡®∏‡®æ‡®â‡®Ç‡®¶‡©Ä ‡®π‡©à‡•§ ‡®ú‡©á‡®ï‡®∞ Q-Table ‡®µ‡®ø‡©±‡®ö entry ‡®Æ‡©å‡®ú‡©Ç‡®¶ ‡®®‡®π‡©Ä‡®Ç ‡®π‡©à, ‡®§‡®æ‡®Ç ‡®Ö‡®∏‡©Ä‡®Ç default ‡®µ‡®ú‡©ã‡®Ç 0 ‡®µ‡®æ‡®™‡®∏ ‡®ï‡®∞‡®æ‡®Ç‡®ó‡©á‡•§

## ‡®Ü‡®ì Q-Learning ‡®∏‡®º‡©Å‡®∞‡©Ç ‡®ï‡®∞‡©Ä‡®è

‡®π‡©Å‡®£ ‡®Ö‡®∏‡©Ä‡®Ç ‡®™‡©Ä‡®ü‡®∞ ‡®®‡©Ç‡©∞ ‡®¨‡©à‡®≤‡©∞‡®∏ ‡®∏‡®ø‡®ñ‡®æ‡®â‡®£ ‡®≤‡®à ‡®§‡®ø‡®Ü‡®∞ ‡®π‡®æ‡®Ç!

1. ‡®∏‡®≠ ‡®§‡©ã‡®Ç ‡®™‡®π‡®ø‡®≤‡®æ‡®Ç, ‡®ï‡©Å‡®ù hyperparameters ‡®∏‡©à‡®ü ‡®ï‡®∞‡©Ä‡®è: (code block 10)

    ```python
    # hyperparameters
    alpha = 0.3
    gamma = 0.9
    epsilon = 0.90
    ```

    ‡®á‡©±‡®•‡©á, `alpha` **learning rate** ‡®π‡©à ‡®ú‡©ã ‡®á‡®π ‡®¶‡®∞‡®∏‡®æ‡®â‡®Ç‡®¶‡®æ ‡®π‡©à ‡®ï‡®ø Q-Table ‡®¶‡©á ‡®Æ‡©å‡®ú‡©Ç‡®¶‡®æ ‡®Æ‡©Å‡©±‡®≤‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®π‡®∞ ‡®ï‡®¶‡®Æ '‡®§‡©á ‡®ï‡®ø‡©∞‡®®‡®æ adjust ‡®ï‡®∞‡®®‡®æ ‡®ö‡®æ‡®π‡©Ä‡®¶‡®æ ‡®π‡©à‡•§ ‡®™‡®ø‡®õ‡®≤‡©á ‡®™‡®æ‡®† ‡®µ‡®ø‡©±‡®ö ‡®Ö‡®∏‡©Ä‡®Ç 1 ‡®®‡®æ‡®≤ ‡®∏‡®º‡©Å‡®∞‡©Ç ‡®ï‡©Ä‡®§‡®æ ‡®∏‡©Ä, ‡®Ö‡®§‡©á ‡®´‡®ø‡®∞ ‡®∏‡®ø‡®ñ‡®≤‡®æ‡®à ‡®¶‡©å‡®∞‡®æ‡®® `alpha` ‡®®‡©Ç‡©∞ ‡®ò‡®ü‡®æ ‡®ï‡©á ‡®ò‡©±‡®ü ‡®Æ‡©Å‡©±‡®≤‡®æ‡®Ç '‡®§‡©á ‡®≤‡®ø‡®Ü‡•§ ‡®á‡®∏ ‡®â‡®¶‡®æ‡®π‡®∞‡®® ‡®µ‡®ø‡©±‡®ö ‡®Ö‡®∏‡©Ä‡®Ç ‡®á‡®∏‡®®‡©Ç‡©∞ ‡®∏‡®ø‡®∞‡®´ ‡®∏‡®ß‡®æ‡®∞‡®®‡®§‡®æ ‡®≤‡®à constant ‡®∞‡©±‡®ñ‡®æ‡®Ç‡®ó‡©á, ‡®Ö‡®§‡©á ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®¨‡®æ‡®Ö‡®¶ ‡®µ‡®ø‡©±‡®ö `alpha` ‡®Æ‡©Å‡©±‡®≤‡®æ‡®Ç ‡®®‡©Ç‡©∞ adjust ‡®ï‡®∞‡®® ‡®¶‡©á ‡®®‡®æ‡®≤ experiment ‡®ï‡®∞ ‡®∏‡®ï‡®¶‡©á ‡®π‡©ã‡•§

    `gamma` **discount factor** ‡®π‡©à ‡®ú‡©ã ‡®á‡®π ‡®¶‡®∞‡®∏‡®æ‡®â‡®Ç‡®¶‡®æ ‡®π‡©à ‡®ï‡®ø ‡®Ö‡®∏‡©Ä‡®Ç ‡®≠‡®µ‡®ø‡©±‡®ñ ‡®¶‡©á reward ‡®®‡©Ç‡©∞ ‡®Æ‡©å‡®ú‡©Ç‡®¶‡®æ reward ‡®¶‡©á ‡®â‡©±‡®§‡©á ‡®ï‡®ø‡©∞‡®®‡®æ ‡®§‡®∞‡®ú‡©Ä‡®π ‡®¶‡©á‡®£‡©Ä ‡®ö‡®æ‡®π‡©Ä‡®¶‡©Ä ‡®π‡©à‡•§

    `epsilon` **exploration/exploitation factor** ‡®π‡©à ‡®ú‡©ã ‡®á‡®π ‡®®‡®ø‡®∞‡®ß‡®æ‡®∞‡®§ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à ‡®ï‡®ø ‡®Ö‡®∏‡©Ä‡®Ç exploration ‡®®‡©Ç‡©∞ exploitation ‡®¶‡©á ‡®â‡©±‡®§‡©á ‡®§‡®∞‡®ú‡©Ä‡®π ‡®¶‡©á‡®£‡©Ä ‡®ö‡®æ‡®π‡©Ä‡®¶‡©Ä ‡®π‡©à ‡®ú‡®æ‡®Ç vice versa‡•§ ‡®∏‡®æ‡®°‡©á algorithm ‡®µ‡®ø‡©±‡®ö, ‡®Ö‡®∏‡©Ä‡®Ç `epsilon` percent ‡®ï‡©á‡®∏‡®æ‡®Ç ‡®µ‡®ø‡©±‡®ö Q-Table values ‡®¶‡©á ‡®Ö‡®®‡©Å‡®∏‡®æ‡®∞ ‡®Ö‡®ó‡®≤‡©Ä action ‡®ö‡©Å‡®£‡®æ‡®Ç‡®ó‡©á, ‡®Ö‡®§‡©á ‡®¨‡®æ‡®ï‡©Ä ‡®ï‡©á‡®∏‡®æ‡®Ç ‡®µ‡®ø‡©±‡®ö ‡®Ö‡®∏‡©Ä‡®Ç random action execute ‡®ï‡®∞‡®æ‡®Ç‡®ó‡©á‡•§ ‡®á‡®π ‡®∏‡®æ‡®®‡©Ç‡©∞ search space ‡®¶‡©á ‡®â‡®π‡®®‡®æ‡®Ç ‡®ñ‡©á‡®§‡®∞‡®æ‡®Ç ‡®¶‡©Ä ‡®ú‡®æ‡®Ç‡®ö ‡®ï‡®∞‡®® ‡®¶‡©Ä ‡®Ü‡®ó‡®ø‡®Ü ‡®¶‡©á‡®µ‡©á‡®ó‡®æ ‡®ú‡©ã ‡®Ö‡®∏‡©Ä‡®Ç ‡®™‡®π‡®ø‡®≤‡®æ‡®Ç ‡®ï‡®¶‡©á ‡®®‡®π‡©Ä‡®Ç ‡®¶‡©á‡®ñ‡©á‡•§

    ‚úÖ ‡®¨‡©à‡®≤‡©∞‡®∏‡®ø‡©∞‡®ó ‡®¶‡©á ‡®π‡®ø‡®∏‡®æ‡®¨ ‡®®‡®æ‡®≤ - random action (exploration) ‡®ö‡©Å‡®£‡®®‡®æ ‡®á‡©±‡®ï random punch ‡®µ‡®ú‡©ã‡®Ç ‡®ï‡©∞‡®Æ ‡®ï‡®∞‡©á‡®ó‡®æ ‡®ú‡©ã ‡®ó‡®≤‡®§ ‡®¶‡®ø‡®∏‡®º‡®æ ‡®µ‡®ø‡©±‡®ö ‡®π‡©ã‡®µ‡©á‡®ó‡®æ, ‡®Ö‡®§‡©á pole ‡®®‡©Ç‡©∞ ‡®â‡®π‡®®‡®æ‡®Ç "‡®ó‡®≤‡®§‡©Ä‡®Ü‡®Ç" ‡®§‡©ã‡®Ç ‡®¨‡©à‡®≤‡©∞‡®∏ ‡®®‡©Ç‡©∞ ‡®Æ‡©Å‡©ú ‡®™‡©ç‡®∞‡®æ‡®™‡®§ ‡®ï‡®∞‡®® ‡®¶‡®æ ‡®∏‡®ø‡®ñ‡®£‡®æ ‡®™‡®µ‡©á‡®ó‡®æ‡•§

### Algorithm ‡®®‡©Ç‡©∞ ‡®∏‡©Å‡®ß‡®æ‡®∞‡©ã

‡®Ö‡®∏‡©Ä‡®Ç ‡®™‡®ø‡®õ‡®≤‡©á ‡®™‡®æ‡®† ‡®¶‡©á algorithm ‡®µ‡®ø‡©±‡®ö ‡®¶‡©ã ‡®∏‡©Å‡®ß‡®æ‡®∞ ‡®ï‡®∞ ‡®∏‡®ï‡®¶‡©á ‡®π‡®æ‡®Ç:

- **Average cumulative reward ‡®¶‡©Ä ‡®ó‡®£‡®®‡®æ ‡®ï‡®∞‡©ã**, ‡®ï‡®à simulations ‡®¶‡©á ‡®î‡®∏‡®§ ‡®¶‡©á ‡®Ö‡®ß‡®æ‡®∞ '‡®§‡©á‡•§ ‡®Ö‡®∏‡©Ä‡®Ç ‡®π‡®∞ 5000 iterations '‡®§‡©á progress print ‡®ï‡®∞‡®æ‡®Ç‡®ó‡©á, ‡®Ö‡®§‡©á ‡®Ö‡®∏‡©Ä‡®Ç cumulative reward ‡®®‡©Ç‡©∞ ‡®â‡®∏ ‡®∏‡®Æ‡©á‡®Ç ‡®¶‡©á ‡®Ö‡®ß‡®æ‡®∞ '‡®§‡©á average ‡®ï‡®∞‡®æ‡®Ç‡®ó‡©á‡•§ ‡®á‡®∏‡®¶‡®æ ‡®Æ‡®§‡®≤‡®¨ ‡®π‡©à ‡®ï‡®ø ‡®ú‡©á‡®ï‡®∞ ‡®Ö‡®∏‡©Ä‡®Ç 195 point ‡®§‡©ã‡®Ç ‡®µ‡©±‡®ß ‡®™‡©ç‡®∞‡®æ‡®™‡®§ ‡®ï‡®∞‡®¶‡©á ‡®π‡®æ‡®Ç - ‡®Ö‡®∏‡©Ä‡®Ç ‡®∏‡®Æ‡©±‡®∏‡®ø‡®Ü ‡®®‡©Ç‡©∞ solved ‡®Æ‡©∞‡®® ‡®∏‡®ï‡®¶‡©á ‡®π‡®æ‡®Ç, ‡®ú‡©á‡®ï‡®∞ quality required ‡®§‡©ã‡®Ç ‡®µ‡©Ä ‡®â‡©±‡®ö‡©Ä ‡®π‡©ã‡®µ‡©á‡•§

- **Maximum average cumulative result ‡®¶‡©Ä ‡®ó‡®£‡®®‡®æ ‡®ï‡®∞‡©ã**, `Qmax`, ‡®Ö‡®§‡©á ‡®Ö‡®∏‡©Ä‡®Ç ‡®â‡®∏ Q-Table ‡®®‡©Ç‡©∞ ‡®∏‡®ü‡©ã‡®∞ ‡®ï‡®∞‡®æ‡®Ç‡®ó‡©á ‡®ú‡©ã ‡®â‡®∏ result ‡®®‡©Ç‡©∞ ‡®¶‡®∞‡®∏‡®æ‡®â‡®Ç‡®¶‡®æ ‡®π‡©à‡•§ ‡®ú‡®¶‡©ã‡®Ç ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®∏‡®ø‡®ñ‡®≤‡®æ‡®à ‡®ö‡®≤‡®æ‡®â‡®Ç‡®¶‡©á ‡®π‡©ã, ‡®§‡®æ‡®Ç ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®®‡©ã‡®ü‡®ø‡®∏ ‡®ï‡®∞‡©ã‡®ó‡©á ‡®ï‡®ø ‡®ï‡®à ‡®µ‡®æ‡®∞ average cumulative result ‡®ò‡®ü‡®£‡®æ ‡®∏‡®º‡©Å‡®∞‡©Ç ‡®ï‡®∞ ‡®¶‡®ø‡©∞‡®¶‡®æ ‡®π‡©à, ‡®Ö‡®§‡©á ‡®Ö‡®∏‡©Ä‡®Ç Q-Table ‡®¶‡©á ‡®â‡®π values ‡®®‡©Ç‡©∞ ‡®∞‡©±‡®ñ‡®£‡®æ ‡®ö‡®æ‡®π‡©Å‡©∞‡®¶‡©á ‡®π‡®æ‡®Ç ‡®ú‡©ã ‡®∏‡®ø‡®ñ‡®≤‡®æ‡®à ‡®¶‡©å‡®∞‡®æ‡®® observed ‡®ï‡©Ä‡®§‡©á ‡®ó‡®è best model ‡®®‡©Ç‡©∞ ‡®¶‡®∞‡®∏‡®æ‡®â‡®Ç‡®¶‡©á ‡®π‡®®‡•§

1. ‡®π‡®∞ simulation '‡®§‡©á ‡®∏‡®æ‡®∞‡©á cumulative rewards ‡®®‡©Ç‡©∞ `rewards` vector ‡®µ‡®ø‡©±‡®ö ‡®á‡®ï‡©±‡®†‡®æ ‡®ï‡®∞‡©ã ‡®ú‡©ã plotting ‡®≤‡®à ‡®µ‡®∞‡®§‡®ø‡®Ü ‡®ú‡®æ‡®µ‡©á‡®ó‡®æ‡•§ (code block 11)

    ```python
    def probs(v,eps=1e-4):
        v = v-v.min()+eps
        v = v/v.sum()
        return v
    
    Qmax = 0
    cum_rewards = []
    rewards = []
    for epoch in range(100000):
        obs = env.reset()
        done = False
        cum_reward=0
        # == do the simulation ==
        while not done:
            s = discretize(obs)
            if random.random()<epsilon:
                # exploitation - chose the action according to Q-Table probabilities
                v = probs(np.array(qvalues(s)))
                a = random.choices(actions,weights=v)[0]
            else:
                # exploration - randomly chose the action
                a = np.random.randint(env.action_space.n)
    
            obs, rew, done, info = env.step(a)
            cum_reward+=rew
            ns = discretize(obs)
            Q[(s,a)] = (1 - alpha) * Q.get((s,a),0) + alpha * (rew + gamma * max(qvalues(ns)))
        cum_rewards.append(cum_reward)
        rewards.append(cum_reward)
        # == Periodically print results and calculate average reward ==
        if epoch%5000==0:
            print(f"{epoch}: {np.average(cum_rewards)}, alpha={alpha}, epsilon={epsilon}")
            if np.average(cum_rewards) > Qmax:
                Qmax = np.average(cum_rewards)
                Qbest = Q
            cum_rewards=[]
    ```

‡®á‡®π‡®®‡®æ‡®Ç ‡®®‡®§‡©Ä‡®ú‡®ø‡®Ü‡®Ç ‡®§‡©ã‡®Ç ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®ï‡©Ä ‡®®‡©ã‡®ü‡®ø‡®∏ ‡®ï‡®∞ ‡®∏‡®ï‡®¶‡©á ‡®π‡©ã:

- **‡®∏‡®æ‡®°‡©á ‡®≤‡®ï‡®∏‡®º ‡®¶‡©á ‡®®‡©á‡©ú‡©á**‡•§ ‡®Ö‡®∏‡©Ä‡®Ç 100+ ‡®≤‡®ó‡®æ‡®§‡®æ‡®∞ simulations ‡®¶‡©á ‡®î‡®∏‡®§ rewards ‡®¶‡©á 195 cumulative rewards ‡®™‡©ç‡®∞‡®æ‡®™‡®§ ‡®ï‡®∞‡®® ‡®¶‡©á ‡®≤‡®ï‡®∏‡®º ‡®¶‡©á ‡®¨‡®π‡©Å‡®§ ‡®®‡©á‡©ú‡©á ‡®π‡®æ‡®Ç, ‡®ú‡®æ‡®Ç ‡®Ö‡®∏‡©Ä‡®Ç ‡®á‡®∏‡®®‡©Ç‡©∞ ‡®π‡®æ‡®∏‡®≤ ‡®ï‡®∞ ‡®≤‡®ø‡®Ü ‡®π‡©à! ‡®ú‡©á‡®ï‡®∞ ‡®Ö‡®∏‡©Ä‡®Ç ‡®õ‡©ã‡®ü‡©á ‡®®‡©∞‡®¨‡®∞ ‡®™‡©ç‡®∞‡®æ‡®™‡®§ ‡®ï‡®∞‡®¶‡©á ‡®π‡®æ‡®Ç, ‡®§‡®æ‡®Ç ‡®Ö‡®∏‡©Ä‡®Ç ‡®Ö‡®ú‡©á ‡®µ‡©Ä ‡®®‡®π‡©Ä‡®Ç ‡®ú‡®æ‡®£‡®¶‡©á, ‡®ï‡®ø‡®â‡®Ç‡®ï‡®ø ‡®Ö‡®∏‡©Ä‡®Ç 5000 runs ‡®¶‡©á ‡®î‡®∏‡®§ '‡®§‡©á ‡®ó‡®ø‡®£‡®§‡©Ä ‡®ï‡®∞‡®¶‡©á ‡®π‡®æ‡®Ç, ‡®Ö‡®§‡©á ‡®∏‡®ø‡®∞‡®´ 100 runs formal criteria ‡®µ‡®ø‡©±‡®ö ‡®≤‡©ã‡©ú‡©Ä‡®Ç‡®¶‡©á ‡®π‡®®‡•§

- **Reward ‡®ò‡®ü‡®£‡®æ ‡®∏‡®º‡©Å‡®∞‡©Ç ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à**‡•§ ‡®ï‡®à ‡®µ‡®æ‡®∞ reward ‡®ò‡®ü‡®£‡®æ ‡®∏‡®º‡©Å‡®∞‡©Ç ‡®ï‡®∞ ‡®¶‡®ø‡©∞‡®¶‡®æ ‡®π‡©à, ‡®ú‡®ø‡®∏‡®¶‡®æ ‡®Æ‡®§‡®≤‡®¨ ‡®π‡©à ‡®ï‡®ø ‡®Ö‡®∏‡©Ä‡®Ç Q-Table ‡®µ‡®ø‡©±‡®ö ‡®™‡®π‡®ø‡®≤‡®æ‡®Ç ‡®∏‡®ø‡©±‡®ñ‡©á ‡®Æ‡©Å‡©±‡®≤‡®æ‡®Ç ‡®®‡©Ç‡©∞ "‡®®‡®∏‡®º‡®ü" ‡®ï‡®∞ ‡®∏‡®ï‡®¶‡©á ‡®π‡®æ‡®Ç ‡®ú‡©ã ‡®∏‡®•‡®ø‡®§‡©Ä ‡®®‡©Ç‡©∞ ‡®¨‡®¶‡®§‡®∞ ‡®¨‡®£‡®æ‡®â‡®Ç‡®¶‡©á ‡®π‡®®‡•§

‡®á‡®π observation training progress ‡®®‡©Ç‡©∞ plot ‡®ï‡®∞‡®® '‡®§‡©á ‡®π‡©ã‡®∞ ‡®∏‡®™‡®∏‡®º‡®ü ‡®§‡®∞‡©Ä‡®ï‡©á ‡®®‡®æ‡®≤ ‡®¶‡®ø‡®ñ‡®æ‡®à ‡®¶‡®ø‡©∞‡®¶‡©Ä ‡®π‡©à‡•§

## Training Progress ‡®®‡©Ç‡©∞ Plot ‡®ï‡®∞‡®®‡®æ

‡®∏‡®ø‡®ñ‡®≤‡®æ‡®à ‡®¶‡©å‡®∞‡®æ‡®®, ‡®Ö‡®∏‡©Ä‡®Ç cumulative reward value ‡®®‡©Ç‡©∞ `rewards` vector ‡®µ‡®ø‡©±‡®ö ‡®π‡®∞ iteration '‡®§‡©á ‡®á‡®ï‡©±‡®†‡®æ ‡®ï‡©Ä‡®§‡®æ‡•§ ‡®á‡®π graph ‡®µ‡®ø‡©±‡®ö iteration number ‡®¶‡©á ‡®ñ‡®ø‡®≤‡®æ‡®´ plot ‡®ï‡®∞‡®® '‡®§‡©á ‡®á‡®∏ ‡®§‡®∞‡©ç‡®π‡®æ‡®Ç ‡®¶‡®ø‡®ñ‡®æ‡®à ‡®¶‡®ø‡©∞‡®¶‡®æ ‡®π‡©à:

```python
plt.plot(rewards)
```

![raw progress](../../../../translated_images/train_progress_raw.2adfdf2daea09c596fc786fa347a23e9aceffe1b463e2257d20a9505794823ec.pa.png)

‡®á‡®∏ graph ‡®§‡©ã‡®Ç ‡®ï‡©Å‡®ù ‡®µ‡©Ä ‡®ï‡®π‡®ø‡®£‡®æ ‡®∏‡©∞‡®≠‡®µ ‡®®‡®π‡©Ä‡®Ç ‡®π‡©à, ‡®ï‡®ø‡®â‡®Ç‡®ï‡®ø stochastic training process ‡®¶‡©Ä nature ‡®¶‡©á ‡®ï‡®æ‡®∞‡®® training sessions ‡®¶‡©Ä ‡®≤‡©∞‡®¨‡®æ‡®à ‡®¨‡®π‡©Å‡®§ ‡®µ‡©±‡®ñ-‡®µ‡©±‡®ñ ‡®π‡©Å‡©∞‡®¶‡©Ä ‡®π‡©à‡•§ ‡®á‡®∏ graph ‡®®‡©Ç‡©∞ ‡®π‡©ã‡®∞ ‡®∏‡®Æ‡®ù‡®£‡®Ø‡©ã‡®ó ‡®¨‡®£‡®æ‡®â‡®£ ‡®≤‡®à, ‡®Ö‡®∏‡©Ä‡®Ç 100 simulations ‡®¶‡©á ‡®î‡®∏‡®§ '‡®§‡©á **running average** ‡®¶‡©Ä ‡®ó‡®£‡®®‡®æ ‡®ï‡®∞ ‡®∏‡®ï‡®¶‡©á ‡®π‡®æ‡®Ç‡•§ ‡®á‡®π `np.convolve` ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®∏‡©Å‡®µ‡®ø‡®ß‡®æ‡®ú‡®®‡®ï ‡®§‡®∞‡©Ä‡®ï‡©á ‡®®‡®æ‡®≤ ‡®ï‡©Ä‡®§‡®æ ‡®ú‡®æ ‡®∏‡®ï‡®¶‡®æ ‡®π‡©à: (code block 12)

```python
def running_average(x,window):
    return np.convolve(x,np.ones(window)/window,mode='valid')

plt.plot(running_average(rewards,100))
```

![training progress](../../../../translated_images/train_progress_runav.c71694a8fa9ab35935aff6f109e5ecdfdbdf1b0ae265da49479a81b5fae8f0aa.pa.png)

## Hyperparameters ‡®®‡©Ç‡©∞ ‡®µ‡©±‡®ñ-‡®µ‡©±‡®ñ
> **‡®ï‡®ø‡®∞‡®ø‡®Ü 1**: ‡®π‡®æ‡®à‡®™‡®∞‡®™‡©à‡®∞‡®æ‡®Æ‡©Ä‡®ü‡®∞ ‡®Æ‡©Å‡©±‡®≤‡®æ‡®Ç ‡®®‡®æ‡®≤ ‡®ñ‡©á‡®°‡©ã ‡®Ö‡®§‡©á ‡®µ‡©á‡®ñ‡©ã ‡®ï‡®ø ‡®ï‡©Ä ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®µ‡®ß‡©á‡®∞‡©á ‡®ï‡©Å‡©±‡®≤ ‡®á‡®®‡®æ‡®Æ ‡®™‡©ç‡®∞‡®æ‡®™‡®§ ‡®ï‡®∞ ‡®∏‡®ï‡®¶‡©á ‡®π‡©ã‡•§ ‡®ï‡©Ä ‡®§‡©Å‡®∏‡©Ä‡®Ç 195 ‡®§‡©ã‡®Ç ‡®â‡©±‡®™‡®∞ ‡®™‡©ç‡®∞‡®æ‡®™‡®§ ‡®ï‡®∞ ‡®∞‡®π‡©á ‡®π‡©ã?
> **‡®ü‡®æ‡®∏‡®ï 2**: ‡®∏‡®Æ‡©±‡®∏‡®ø‡®Ü ‡®®‡©Ç‡©∞ ‡®î‡®™‡®ö‡®æ‡®∞‡®ø‡®ï ‡®§‡©å‡®∞ '‡®§‡©á ‡®π‡©±‡®≤ ‡®ï‡®∞‡®® ‡®≤‡®à, ‡®§‡©Å‡®π‡®æ‡®®‡©Ç‡©∞ 100 ‡®≤‡®ó‡®æ‡®§‡®æ‡®∞ ‡®¶‡©å‡©ú‡®æ‡®Ç ‡®µ‡®ø‡©±‡®ö 195 ‡®î‡®∏‡®§ ‡®á‡®®‡®æ‡®Æ ‡®™‡©ç‡®∞‡®æ‡®™‡®§ ‡®ï‡®∞‡®®‡®æ ‡®π‡©ã‡®µ‡©á‡®ó‡®æ‡•§ ‡®ü‡©ç‡®∞‡©á‡®®‡®ø‡©∞‡®ó ‡®¶‡©å‡®∞‡®æ‡®® ‡®á‡®∏ ‡®®‡©Ç‡©∞ ‡®Æ‡®æ‡®™‡©ã ‡®Ö‡®§‡©á ‡®Ø‡®ï‡©Ä‡®®‡©Ä ‡®¨‡®£‡®æ‡®ì ‡®ï‡®ø ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®∏‡®Æ‡©±‡®∏‡®ø‡®Ü ‡®®‡©Ç‡©∞ ‡®î‡®™‡®ö‡®æ‡®∞‡®ø‡®ï ‡®§‡©å‡®∞ '‡®§‡©á ‡®π‡©±‡®≤ ‡®ï‡®∞ ‡®≤‡®ø‡®Ü ‡®π‡©à!

## ‡®®‡®§‡©Ä‡®ú‡©á ‡®®‡©Ç‡©∞ ‡®ï‡®æ‡®∞‡®µ‡®æ‡®à ‡®µ‡®ø‡©±‡®ö ‡®¶‡©á‡®ñ‡®£‡®æ

‡®á‡®π ‡®¶‡®ø‡®≤‡®ö‡®∏‡®™ ‡®π‡©ã‡®µ‡©á‡®ó‡®æ ‡®ï‡®ø ‡®∏‡©±‡®ö‡®Æ‡©Å‡©±‡®ö ‡®¶‡©á‡®ñ‡®ø‡®Ü ‡®ú‡®æ‡®µ‡©á ‡®ï‡®ø ‡®ü‡©ç‡®∞‡©á‡®® ‡®ï‡©Ä‡®§‡©á ‡®Æ‡®æ‡®°‡®≤ ‡®¶‡®æ ‡®µ‡®ø‡®π‡®æ‡®∞ ‡®ï‡®ø‡®µ‡©á‡®Ç ‡®π‡©Å‡©∞‡®¶‡®æ ‡®π‡©à‡•§ ‡®Ü‡®ì ‡®∏‡®ø‡®Æ‡©Ç‡®≤‡©á‡®∏‡®º‡®® ‡®ö‡®≤‡®æ‡®à‡®è ‡®Ö‡®§‡©á ‡®ü‡©ç‡®∞‡©á‡®®‡®ø‡©∞‡®ó ‡®¶‡©å‡®∞‡®æ‡®® ‡®µ‡®∞‡®§‡©Ä ‡®ó‡®à ‡®á‡©±‡®ï‡©ã ‡®ú‡®ø‡®π‡©Ä ‡®ê‡®ï‡®∏‡®º‡®® ‡®ö‡©ã‡®£ ‡®∞‡®£‡®®‡©Ä‡®§‡©Ä ‡®¶‡©Ä ‡®™‡®æ‡®≤‡®£‡®æ ‡®ï‡®∞‡©Ä‡®è, Q-Table ‡®µ‡®ø‡©±‡®ö ‡®∏‡©∞‡®≠‡®æ‡®µ‡®®‡®æ ‡®µ‡©∞‡®° ‡®Ö‡®®‡©Å‡®∏‡®æ‡®∞ ‡®∏‡©à‡®Ç‡®™‡®≤‡®ø‡©∞‡®ó ‡®ï‡®∞‡®¶‡©á ‡®π‡©ã‡®è: (‡®ï‡©ã‡®° ‡®¨‡®≤‡®æ‡®ï 13)

```python
obs = env.reset()
done = False
while not done:
   s = discretize(obs)
   env.render()
   v = probs(np.array(qvalues(s)))
   a = random.choices(actions,weights=v)[0]
   obs,_,done,_ = env.step(a)
env.close()
```

‡®§‡©Å‡®π‡®æ‡®®‡©Ç‡©∞ ‡®ï‡©Å‡®ù ‡®á‡®∏ ‡®§‡®∞‡©ç‡®π‡®æ‡®Ç ‡®¶‡©á‡®ñ‡®£ ‡®®‡©Ç‡©∞ ‡®Æ‡®ø‡®≤‡©á‡®ó‡®æ:

![‡®á‡©±‡®ï ‡®∏‡©∞‡®§‡©Å‡®≤‡®ø‡®§ ‡®ï‡®æ‡®∞‡®ü‡®™‡©ã‡®≤](../../../../8-Reinforcement/2-Gym/images/cartpole-balance.gif)

---

## üöÄ‡®ö‡©Å‡®£‡©å‡®§‡©Ä

> **‡®ü‡®æ‡®∏‡®ï 3**: ‡®á‡©±‡®•‡©á, ‡®Ö‡®∏‡©Ä‡®Ç Q-Table ‡®¶‡©Ä ‡®Ö‡©∞‡®§‡®Æ ‡®ï‡®æ‡®™‡©Ä ‡®µ‡®∞‡®§ ‡®∞‡®π‡©á ‡®∏‡©Ä, ‡®ú‡©ã ‡®∏‡®º‡®æ‡®á‡®¶ ‡®∏‡®≠ ‡®§‡©ã‡®Ç ‡®µ‡®ß‡©Ä‡®Ü ‡®®‡®æ ‡®π‡©ã‡®µ‡©á‡•§ ‡®Ø‡®æ‡®¶ ‡®∞‡©±‡®ñ‡©ã ‡®ï‡®ø ‡®Ö‡®∏‡©Ä‡®Ç ‡®∏‡®≠ ‡®§‡©ã‡®Ç ‡®µ‡®ß‡©Ä‡®Ü ‡®™‡©ç‡®∞‡®¶‡®∞‡®∏‡®º‡®® ‡®ï‡®∞‡®® ‡®µ‡®æ‡®≤‡©Ä Q-Table ‡®®‡©Ç‡©∞ `Qbest` ‡®µ‡©à‡®∞‡©Ä‡®è‡®¨‡®≤ ‡®µ‡®ø‡©±‡®ö ‡®∏‡®ü‡©ã‡®∞ ‡®ï‡©Ä‡®§‡®æ ‡®π‡©à! `Qbest` ‡®®‡©Ç‡©∞ `Q` ‡®µ‡®ø‡©±‡®ö ‡®ï‡®æ‡®™‡©Ä ‡®ï‡®∞‡®ï‡©á ‡®Ö‡®§‡©á ‡®á‡®π ‡®¶‡©á‡®ñ ‡®ï‡©á ‡®ï‡®ø ‡®ï‡©Ä ‡®§‡©Å‡®∏‡©Ä‡®Ç ‡®ï‡©ã‡®à ‡®Ö‡©∞‡®§‡®∞ ‡®Æ‡®π‡®ø‡®∏‡©Ç‡®∏ ‡®ï‡®∞‡®¶‡©á ‡®π‡©ã, ‡®á‡®∏‡©á ‡®â‡®¶‡®æ‡®π‡®∞‡®® ‡®®‡©Ç‡©∞ ‡®∏‡®≠ ‡®§‡©ã‡®Ç ‡®µ‡®ß‡©Ä‡®Ü Q-Table ‡®®‡®æ‡®≤ ‡®Ö‡®ú‡®º‡®Æ‡®æ‡®ì‡•§

> **‡®ü‡®æ‡®∏‡®ï 4**: ‡®á‡©±‡®•‡©á ‡®Ö‡®∏‡©Ä‡®Ç ‡®π‡®∞ ‡®ï‡®¶‡®Æ '‡®§‡©á ‡®∏‡®≠ ‡®§‡©ã‡®Ç ‡®µ‡®ß‡©Ä‡®Ü ‡®ê‡®ï‡®∏‡®º‡®® ‡®®‡®π‡©Ä‡®Ç ‡®ö‡©Å‡®£ ‡®∞‡®π‡©á ‡®∏‡©Ä, ‡®∏‡®ó‡©ã‡®Ç ‡®∏‡©∞‡®≠‡®æ‡®µ‡®®‡®æ ‡®µ‡©∞‡®° ‡®¶‡©á ‡®Ö‡®®‡©Å‡®∏‡®æ‡®∞ ‡®∏‡©à‡®Ç‡®™‡®≤‡®ø‡©∞‡®ó ‡®ï‡®∞ ‡®∞‡®π‡©á ‡®∏‡©Ä‡•§ ‡®ï‡©Ä ‡®á‡®π ‡®ú‡®º‡®ø‡®Ü‡®¶‡®æ ‡®Æ‡®æ‡®®‡®∏‡®ø‡®ï ‡®π‡©ã‡®µ‡©á‡®ó‡®æ ‡®ï‡®ø ‡®π‡®Æ‡©á‡®∏‡®º‡®æ ‡®∏‡®≠ ‡®§‡©ã‡®Ç ‡®µ‡®ß‡©Ä‡®Ü ‡®ê‡®ï‡®∏‡®º‡®® ‡®ö‡©Å‡®£‡®ø‡®Ü ‡®ú‡®æ‡®µ‡©á, ‡®ú‡®ø‡®∏‡®¶‡®æ Q-Table ‡®Æ‡©Å‡©±‡®≤ ‡®∏‡®≠ ‡®§‡©ã‡®Ç ‡®â‡©±‡®ö‡®æ ‡®π‡©ã‡®µ‡©á? ‡®á‡®π `np.argmax` ‡®´‡©∞‡®ï‡®∏‡®º‡®® ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®ï‡©Ä‡®§‡®æ ‡®ú‡®æ ‡®∏‡®ï‡®¶‡®æ ‡®π‡©à, ‡®ú‡©ã ‡®∏‡®≠ ‡®§‡©ã‡®Ç ‡®â‡©±‡®ö‡©á Q-Table ‡®Æ‡©Å‡©±‡®≤ ‡®¶‡©á ‡®Ö‡®®‡©Å‡®∏‡®æ‡®∞ ‡®ê‡®ï‡®∏‡®º‡®® ‡®®‡©∞‡®¨‡®∞ ‡®¶‡®æ ‡®™‡®§‡®æ ‡®≤‡®ó‡®æ‡®â‡®Ç‡®¶‡®æ ‡®π‡©à‡•§ ‡®á‡®∏ ‡®∞‡®£‡®®‡©Ä‡®§‡©Ä ‡®®‡©Ç‡©∞ ‡®≤‡®æ‡®ó‡©Ç ‡®ï‡®∞‡©ã ‡®Ö‡®§‡©á ‡®¶‡©á‡®ñ‡©ã ‡®ï‡®ø ‡®ï‡©Ä ‡®á‡®π ‡®∏‡©∞‡®§‡©Å‡®≤‡®® ‡®µ‡®ø‡©±‡®ö ‡®∏‡©Å‡®ß‡®æ‡®∞ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à‡•§

## [‡®™‡©ã‡®∏‡®ü-‡®≤‡©à‡®ï‡®ö‡®∞ ‡®ï‡®µ‡®ø‡®ú‡®º](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/48/)

## ‡®Ö‡®∏‡®æ‡®à‡®®‡®Æ‡©à‡®Ç‡®ü
[‡®Æ‡®æ‡®ä‡®Ç‡®ü‡©á‡®® ‡®ï‡®æ‡®∞ ‡®®‡©Ç‡©∞ ‡®ü‡©ç‡®∞‡©á‡®® ‡®ï‡®∞‡©ã](assignment.md)

## ‡®®‡®ø‡®∏‡®ï‡®∞‡®∏‡®º

‡®Ö‡®∏‡©Ä‡®Ç ‡®π‡©Å‡®£ ‡®∏‡®ø‡©±‡®ñ ‡®≤‡®ø‡®Ü ‡®π‡©à ‡®ï‡®ø ‡®ï‡©á‡®µ‡®≤ ‡®á‡©±‡®ï ‡®á‡®®‡®æ‡®Æ ‡®´‡©∞‡®ï‡®∏‡®º‡®® ‡®™‡©ç‡®∞‡®¶‡®æ‡®® ‡®ï‡®∞‡®ï‡©á, ‡®ú‡©ã ‡®ñ‡©á‡®° ‡®¶‡©Ä ‡®á‡©±‡®õ‡®ø‡®§ ‡®∏‡®•‡®ø‡®§‡©Ä ‡®®‡©Ç‡©∞ ‡®™‡®∞‡®ø‡®≠‡®æ‡®∏‡®º‡®ø‡®§ ‡®ï‡®∞‡®¶‡®æ ‡®π‡©à, ‡®Ö‡®§‡©á ‡®â‡®®‡©ç‡®π‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®∏‡®Æ‡®∞‡®•‡®ï ‡®§‡®∞‡©Ä‡®ï‡©á ‡®®‡®æ‡®≤ ‡®ñ‡©ã‡®ú ‡®∏‡®•‡®æ‡®® ‡®¶‡©Ä ‡®™‡©ú‡®ö‡©ã‡®≤ ‡®ï‡®∞‡®® ‡®¶‡®æ ‡®Æ‡©å‡®ï‡®æ ‡®¶‡©á ‡®ï‡©á, ‡®è‡®ú‡©∞‡®ü‡®æ‡®Ç ‡®®‡©Ç‡©∞ ‡®ö‡©∞‡®ó‡©á ‡®®‡®§‡©Ä‡®ú‡©á ‡®™‡©ç‡®∞‡®æ‡®™‡®§ ‡®ï‡®∞‡®® ‡®≤‡®à ‡®ï‡®ø‡®µ‡©á‡®Ç ‡®ü‡©ç‡®∞‡©á‡®® ‡®ï‡©Ä‡®§‡®æ ‡®ú‡®æ ‡®∏‡®ï‡®¶‡®æ ‡®π‡©à‡•§ ‡®Ö‡®∏‡©Ä‡®Ç ‡®∏‡®´‡®≤‡®§‡®æ‡®™‡©Ç‡®∞‡®µ‡®ï Q-Learning ‡®ê‡®≤‡®ó‡©ã‡®∞‡®ø‡®•‡®Æ ‡®®‡©Ç‡©∞ ‡®µ‡®ø‡®∏‡®º‡©á‡®∏‡®º ‡®Ö‡®§‡©á ‡®≤‡®ó‡®æ‡®§‡®æ‡®∞ ‡®µ‡®æ‡®§‡®æ‡®µ‡®∞‡®£‡®æ‡®Ç ‡®¶‡©á ‡®Æ‡®æ‡®Æ‡®≤‡®ø‡®Ü‡®Ç ‡®µ‡®ø‡©±‡®ö ‡®≤‡®æ‡®ó‡©Ç ‡®ï‡©Ä‡®§‡®æ ‡®π‡©à, ‡®™‡®∞ ‡®µ‡®ø‡®∏‡®º‡©á‡®∏‡®º ‡®ï‡®æ‡®∞‡®µ‡®æ‡®à‡®Ü‡®Ç ‡®®‡®æ‡®≤‡•§

‡®á‡®π ‡®µ‡©Ä ‡®Ö‡®π‡®ø‡®Æ ‡®π‡©à ‡®ï‡®ø ‡®â‡®π ‡®∏‡®•‡®ø‡®§‡©Ä‡®Ü‡®Ç ‡®¶‡®æ ‡®Ö‡®ß‡®ø‡®ê‡®® ‡®ï‡©Ä‡®§‡®æ ‡®ú‡®æ‡®µ‡©á ‡®ú‡®ø‡©±‡®•‡©á ‡®ï‡®æ‡®∞‡®µ‡®æ‡®à ‡®∏‡®•‡®ø‡®§‡©Ä ‡®µ‡©Ä ‡®≤‡®ó‡®æ‡®§‡®æ‡®∞ ‡®π‡©Å‡©∞‡®¶‡©Ä ‡®π‡©à, ‡®Ö‡®§‡©á ‡®ú‡®¶‡©ã‡®Ç ‡®Ö‡®µ‡®≤‡©ã‡®ï‡®® ‡®∏‡®•‡®æ‡®® ‡®ï‡®æ‡®´‡©Ä ‡®ú‡®ü‡®ø‡®≤ ‡®π‡©Å‡©∞‡®¶‡®æ ‡®π‡©à, ‡®ú‡®ø‡®µ‡©á‡®Ç ‡®ï‡®ø Atari ‡®ó‡©á‡®Æ ‡®∏‡®ï‡®∞‡©Ä‡®® ‡®¶‡©Ä ‡®ö‡®ø‡©±‡®§‡®∞‡•§ ‡®â‡®π‡®®‡®æ‡®Ç ‡®∏‡®Æ‡©±‡®∏‡®ø‡®Ü‡®µ‡®æ‡®Ç ‡®µ‡®ø‡©±‡®ö ‡®Ö‡®ï‡®∏‡®∞ ‡®ö‡©∞‡®ó‡©á ‡®®‡®§‡©Ä‡®ú‡©á ‡®™‡©ç‡®∞‡®æ‡®™‡®§ ‡®ï‡®∞‡®® ‡®≤‡®à ‡®π‡©ã‡®∞ ‡®∏‡®º‡®ï‡®§‡©Ä‡®∏‡®º‡®æ‡®≤‡©Ä ‡®Æ‡®∏‡®º‡©Ä‡®® ‡®≤‡®∞‡®®‡®ø‡©∞‡®ó ‡®§‡®ï‡®®‡©Ä‡®ï‡®æ‡®Ç ‡®¶‡©Ä ‡®≤‡©ã‡©ú ‡®π‡©Å‡©∞‡®¶‡©Ä ‡®π‡©à, ‡®ú‡®ø‡®µ‡©á‡®Ç ‡®ï‡®ø ‡®®‡®ø‡®ä‡®∞‡®≤ ‡®®‡©à‡®ü‡®µ‡®∞‡®ï‡•§ ‡®â‡®π ‡®π‡©ã‡®∞ ‡®Ö‡®ó‡®∞‡®ó‡®§‡©Ä ‡®µ‡®ø‡®∏‡®º‡©á ‡®Ö‡®∏‡©Ä‡®Ç ‡®Ü‡®™‡®£‡©á ‡®Ü‡®â‡®£ ‡®µ‡®æ‡®≤‡©á ‡®Ö‡®ó‡®∞‡®ó‡®§‡©Ä AI ‡®ï‡©ã‡®∞‡®∏ ‡®µ‡®ø‡©±‡®ö ‡®ï‡®µ‡®∞ ‡®ï‡®∞‡®æ‡®Ç‡®ó‡©á‡•§

---

**‡®Ö‡®∏‡®µ‡©Ä‡®ï‡®æ‡®∞‡®®‡®æ**:  
‡®á‡®π ‡®¶‡®∏‡®§‡®æ‡®µ‡©á‡®ú‡®º AI ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®∏‡©á‡®µ‡®æ [Co-op Translator](https://github.com/Azure/co-op-translator) ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®ï‡®∞‡®ï‡©á ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®ï‡©Ä‡®§‡®æ ‡®ó‡®ø‡®Ü ‡®π‡©à‡•§ ‡®π‡®æ‡®≤‡®æ‡®Ç‡®ï‡®ø ‡®Ö‡®∏‡©Ä‡®Ç ‡®∏‡®π‡©Ä‡®Ö‡®§ ‡®≤‡®à ‡®Ø‡®§‡®®‡®∏‡®º‡©Ä‡®≤ ‡®π‡®æ‡®Ç, ‡®ï‡®ø‡®∞‡®™‡®æ ‡®ï‡®∞‡®ï‡©á ‡®ß‡®ø‡®Ü‡®® ‡®¶‡®ø‡®ì ‡®ï‡®ø ‡®∏‡®µ‡©à‡®ö‡®æ‡®≤‡®ø‡®§ ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶‡®æ‡®Ç ‡®µ‡®ø‡©±‡®ö ‡®ó‡®≤‡®§‡©Ä‡®Ü‡®Ç ‡®ú‡®æ‡®Ç ‡®Ö‡®∏‡©Å‡©±‡®§‡©Ä‡®Ü‡®Ç ‡®π‡©ã ‡®∏‡®ï‡®¶‡©Ä‡®Ü‡®Ç ‡®π‡®®‡•§ ‡®Æ‡©Ç‡®≤ ‡®¶‡®∏‡®§‡®æ‡®µ‡©á‡®ú‡®º, ‡®ú‡©ã ‡®á‡®∏‡®¶‡©Ä ‡®Æ‡©Ç‡®≤ ‡®≠‡®æ‡®∏‡®º‡®æ ‡®µ‡®ø‡©±‡®ö ‡®π‡©à, ‡®®‡©Ç‡©∞ ‡®Ö‡®ß‡®ø‡®ï‡®æ‡®∞‡®§ ‡®∏‡®∞‡©ã‡®§ ‡®Æ‡©∞‡®®‡®ø‡®Ü ‡®ú‡®æ‡®£‡®æ ‡®ö‡®æ‡®π‡©Ä‡®¶‡®æ ‡®π‡©à‡•§ ‡®Æ‡®π‡©±‡®§‡®µ‡®™‡©Ç‡®∞‡®® ‡®ú‡®æ‡®£‡®ï‡®æ‡®∞‡©Ä ‡®≤‡®à, ‡®™‡©á‡®∏‡®º‡©á‡®µ‡®∞ ‡®Æ‡®®‡©Å‡©±‡®ñ‡©Ä ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®¶‡©Ä ‡®∏‡®ø‡®´‡®æ‡®∞‡®∏‡®º ‡®ï‡©Ä‡®§‡©Ä ‡®ú‡®æ‡®Ç‡®¶‡©Ä ‡®π‡©à‡•§ ‡®á‡®∏ ‡®Ö‡®®‡©Å‡®µ‡®æ‡®¶ ‡®¶‡©Ä ‡®µ‡®∞‡®§‡©ã‡®Ç ‡®§‡©ã‡®Ç ‡®™‡©à‡®¶‡®æ ‡®π‡©ã‡®£ ‡®µ‡®æ‡®≤‡©á ‡®ï‡®ø‡®∏‡©á ‡®µ‡©Ä ‡®ó‡®≤‡®§‡®´‡®π‡®ø‡®Æ‡©Ä ‡®ú‡®æ‡®Ç ‡®ó‡®≤‡®§ ‡®µ‡®ø‡®Ü‡®ñ‡®ø‡®Ü ‡®≤‡®à ‡®Ö‡®∏‡©Ä‡®Ç ‡®ú‡®º‡®ø‡©∞‡®Æ‡©á‡®µ‡®æ‡®∞ ‡®®‡®π‡©Ä‡®Ç ‡®π‡®æ‡®Ç‡•§