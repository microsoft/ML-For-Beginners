<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "abf86d845c84330bce205a46b382ec88",
  "translation_date": "2025-09-06T06:48:36+00:00",
  "source_file": "2-Regression/4-Logistic/README.md",
  "language_code": "pa"
}
-->
# ਲਾਜਿਸਟਿਕ ਰਿਗ੍ਰੈਸ਼ਨ ਨਾਲ ਸ਼੍ਰੇਣੀਆਂ ਦੀ ਪੇਸ਼ਗੂਈ

![ਲਾਜਿਸਟਿਕ ਵਿਰੁੱਧ ਰੇਖੀ ਰਿਗ੍ਰੈਸ਼ਨ ਇਨਫੋਗ੍ਰਾਫਿਕ](../../../../2-Regression/4-Logistic/images/linear-vs-logistic.png)

## [ਪ੍ਰੀ-ਲੈਕਚਰ ਕਵਿਜ਼](https://ff-quizzes.netlify.app/en/ml/)

> ### [ਇਹ ਪਾਠ R ਵਿੱਚ ਉਪਲਬਧ ਹੈ!](../../../../2-Regression/4-Logistic/solution/R/lesson_4.html)

## ਪਰਿਚਯ

ਰਿਗ੍ਰੈਸ਼ਨ ਦੇ ਇਸ ਅੰਤਿਮ ਪਾਠ ਵਿੱਚ, ਜੋ ਕਿ ML ਦੀ ਇੱਕ ਬੁਨਿਆਦੀ _ਕਲਾਸਿਕ_ ਤਕਨੀਕ ਹੈ, ਅਸੀਂ ਲਾਜਿਸਟਿਕ ਰਿਗ੍ਰੈਸ਼ਨ ਦਾ ਅਧਿਐਨ ਕਰਾਂਗੇ। ਤੁਸੀਂ ਇਸ ਤਕਨੀਕ ਨੂੰ ਬਾਈਨਰੀ ਸ਼੍ਰੇਣੀਆਂ ਦੀ ਪੇਸ਼ਗੂਈ ਕਰਨ ਲਈ ਪੈਟਰਨ ਖੋਜਣ ਲਈ ਵਰਤ ਸਕਦੇ ਹੋ। ਕੀ ਇਹ ਕੈਂਡੀ ਚਾਕਲੇਟ ਹੈ ਜਾਂ ਨਹੀਂ? ਕੀ ਇਹ ਬਿਮਾਰੀ ਸੰਕਰਮਕ ਹੈ ਜਾਂ ਨਹੀਂ? ਕੀ ਇਹ ਗਾਹਕ ਇਸ ਉਤਪਾਦ ਨੂੰ ਚੁਣੇਗਾ ਜਾਂ ਨਹੀਂ?

ਇਸ ਪਾਠ ਵਿੱਚ, ਤੁਸੀਂ ਸਿੱਖੋਗੇ:

- ਡਾਟਾ ਵਿਜ਼ੁਅਲਾਈਜ਼ੇਸ਼ਨ ਲਈ ਇੱਕ ਨਵੀਂ ਲਾਇਬ੍ਰੇਰੀ
- ਲਾਜਿਸਟਿਕ ਰਿਗ੍ਰੈਸ਼ਨ ਲਈ ਤਕਨੀਕਾਂ

✅ ਇਸ [Learn module](https://docs.microsoft.com/learn/modules/train-evaluate-classification-models?WT.mc_id=academic-77952-leestott) ਵਿੱਚ ਇਸ ਕਿਸਮ ਦੇ ਰਿਗ੍ਰੈਸ਼ਨ ਨਾਲ ਕੰਮ ਕਰਨ ਦੀ ਸਮਝ ਨੂੰ ਗਹਿਰਾ ਕਰੋ।

## ਪੂਰਵ ਸ਼ਰਤ

ਕਦੂ ਦੇ ਡਾਟਾ ਨਾਲ ਕੰਮ ਕਰਦੇ ਹੋਏ, ਅਸੀਂ ਹੁਣ ਇਸ ਨਾਲ ਕਾਫ਼ੀ ਜਾਣੂ ਹੋ ਗਏ ਹਾਂ ਕਿ ਇੱਕ ਬਾਈਨਰੀ ਸ਼੍ਰੇਣੀ ਹੈ ਜਿਸ ਨਾਲ ਅਸੀਂ ਕੰਮ ਕਰ ਸਕਦੇ ਹਾਂ: `Color`।

ਆਓ ਇੱਕ ਲਾਜਿਸਟਿਕ ਰਿਗ੍ਰੈਸ਼ਨ ਮਾਡਲ ਬਣਾਈਏ ਜੋ ਕੁਝ ਵੈਰੀਏਬਲ ਦੇ ਆਧਾਰ 'ਇੱਕ ਦਿੱਤੇ ਕਦੂ ਦਾ ਰੰਗ ਕਿਹੜਾ ਹੋ ਸਕਦਾ ਹੈ' ਦੀ ਪੇਸ਼ਗੂਈ ਕਰੇ (ਸੰਤਰੀ 🎃 ਜਾਂ ਚਿੱਟਾ 👻)।

> ਅਸੀਂ ਰਿਗ੍ਰੈਸ਼ਨ ਦੇ ਪਾਠ ਸਮੂਹ ਵਿੱਚ ਬਾਈਨਰੀ ਕਲਾਸੀਫਿਕੇਸ਼ਨ ਬਾਰੇ ਕਿਉਂ ਗੱਲ ਕਰ ਰਹੇ ਹਾਂ? ਸਿਰਫ਼ ਭਾਸ਼ਾਈ ਸੁਵਿਧਾ ਲਈ, ਕਿਉਂਕਿ ਲਾਜਿਸਟਿਕ ਰਿਗ੍ਰੈਸ਼ਨ [ਵਾਸਤਵ ਵਿੱਚ ਇੱਕ ਕਲਾਸੀਫਿਕੇਸ਼ਨ ਤਰੀਕਾ](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression) ਹੈ, ਹਾਲਾਂਕਿ ਇਹ ਰੇਖੀ-ਅਧਾਰਿਤ ਹੈ। ਡਾਟਾ ਨੂੰ ਕਲਾਸੀਫਾਈ ਕਰਨ ਦੇ ਹੋਰ ਤਰੀਕਿਆਂ ਬਾਰੇ ਅਗਲੇ ਪਾਠ ਸਮੂਹ ਵਿੱਚ ਸਿੱਖੋ।

## ਪ੍ਰਸ਼ਨ ਨੂੰ ਪਰਿਭਾਸ਼ਿਤ ਕਰੋ

ਸਾਡੇ ਮਕਸਦ ਲਈ, ਅਸੀਂ ਇਸਨੂੰ ਇੱਕ ਬਾਈਨਰੀ ਵਜੋਂ ਪ੍ਰਗਟ ਕਰਾਂਗੇ: 'ਚਿੱਟਾ' ਜਾਂ 'ਚਿੱਟਾ ਨਹੀਂ'। ਸਾਡੇ ਡਾਟਾਸੈਟ ਵਿੱਚ ਇੱਕ 'ਧਾਰੀਦਾਰ' ਸ਼੍ਰੇਣੀ ਵੀ ਹੈ ਪਰ ਇਸਦੇ ਕੁਝ ਹੀ ਉਦਾਹਰਨ ਹਨ, ਇਸ ਲਈ ਅਸੀਂ ਇਸਨੂੰ ਵਰਤ ਨਹੀਂ ਰਹੇ। ਇਹ ਡਾਟਾਸੈਟ ਤੋਂ null ਮੁੱਲਾਂ ਨੂੰ ਹਟਾਉਣ ਤੋਂ ਬਾਅਦ ਖਤਮ ਹੋ ਜਾਂਦੀ ਹੈ।

> 🎃 ਮਜ਼ੇਦਾਰ ਤੱਥ: ਅਸੀਂ ਕਈ ਵਾਰ ਚਿੱਟੇ ਕਦੂਆਂ ਨੂੰ 'ਭੂਤ' ਕਦੂ ਕਹਿੰਦੇ ਹਾਂ। ਇਹ ਕੱਟਣ ਲਈ ਬਹੁਤ ਆਸਾਨ ਨਹੀਂ ਹੁੰਦੇ, ਇਸ ਲਈ ਇਹ ਸੰਤਰੀ ਕਦੂਆਂ ਜਿੰਨੇ ਲੋਕਪ੍ਰਿਯ ਨਹੀਂ ਹਨ, ਪਰ ਇਹ ਦਿਖਣ ਵਿੱਚ ਬਹੁਤ ਕੂਲ ਹੁੰਦੇ ਹਨ! ਇਸ ਲਈ ਅਸੀਂ ਆਪਣੇ ਪ੍ਰਸ਼ਨ ਨੂੰ ਇਸ ਤਰੀਕੇ ਨਾਲ ਵੀ ਦੁਬਾਰਾ ਬਣਾਉਣ ਦੇ ਬਾਰੇ ਸੋਚ ਸਕਦੇ ਹਾਂ: 'ਭੂਤ' ਜਾਂ 'ਭੂਤ ਨਹੀਂ'। 👻

## ਲਾਜਿਸਟਿਕ ਰਿਗ੍ਰੈਸ਼ਨ ਬਾਰੇ

ਲਾਜਿਸਟਿਕ ਰਿਗ੍ਰੈਸ਼ਨ ਕੁਝ ਮਹੱਤਵਪੂਰਨ ਤਰੀਕਿਆਂ ਵਿੱਚ ਰੇਖੀ ਰਿਗ੍ਰੈਸ਼ਨ ਤੋਂ ਵੱਖਰਾ ਹੈ, ਜਿਸ ਬਾਰੇ ਤੁਸੀਂ ਪਹਿਲਾਂ ਸਿੱਖਿਆ ਸੀ।

[![ML ਸ਼ੁਰੂਆਤੀ ਲਈ - ਮਸ਼ੀਨ ਲਰਨਿੰਗ ਕਲਾਸੀਫਿਕੇਸ਼ਨ ਲਈ ਲਾਜਿਸਟਿਕ ਰਿਗ੍ਰੈਸ਼ਨ ਨੂੰ ਸਮਝਣਾ](https://img.youtube.com/vi/KpeCT6nEpBY/0.jpg)](https://youtu.be/KpeCT6nEpBY "ML ਸ਼ੁਰੂਆਤੀ ਲਈ - ਮਸ਼ੀਨ ਲਰਨਿੰਗ ਕਲਾਸੀਫਿਕੇਸ਼ਨ ਲਈ ਲਾਜਿਸਟਿਕ ਰਿਗ੍ਰੈਸ਼ਨ ਨੂੰ ਸਮਝਣਾ")

> 🎥 ਲਾਜਿਸਟਿਕ ਰਿਗ੍ਰੈਸ਼ਨ ਦੇ ਇੱਕ ਛੋਟੇ ਵੀਡੀਓ ਝਲਕ ਲਈ ਉਪਰੋਕਤ ਚਿੱਤਰ 'ਤੇ ਕਲਿਕ ਕਰੋ।

### ਬਾਈਨਰੀ ਕਲਾਸੀਫਿਕੇਸ਼ਨ

ਲਾਜਿਸਟਿਕ ਰਿਗ੍ਰੈਸ਼ਨ ਰੇਖੀ ਰਿਗ੍ਰੈਸ਼ਨ ਦੇ ਜਿਵੇਂ ਵਿਸ਼ੇਸ਼ਤਾਵਾਂ ਨਹੀਂ ਦਿੰਦਾ। ਪਹਿਲਾ ਇੱਕ ਬਾਈਨਰੀ ਸ਼੍ਰੇਣੀ ('ਚਿੱਟਾ ਜਾਂ ਚਿੱਟਾ ਨਹੀਂ') ਬਾਰੇ ਪੇਸ਼ਗੂਈ ਦਿੰਦਾ ਹੈ ਜਦਕਿ ਦੂਜਾ ਲਗਾਤਾਰ ਮੁੱਲਾਂ ਦੀ ਪੇਸ਼ਗੂਈ ਕਰਨ ਦੇ ਯੋਗ ਹੈ, ਉਦਾਹਰਨ ਲਈ, ਕਦੂ ਦੇ ਮੂਲ ਅਤੇ ਫਸਲ ਦੇ ਸਮੇਂ ਦੇ ਆਧਾਰ 'ਇਸਦੀ ਕੀਮਤ ਕਿੰਨੀ ਵਧੇਗੀ'।

![ਕਦੂ ਕਲਾਸੀਫਿਕੇਸ਼ਨ ਮਾਡਲ](../../../../2-Regression/4-Logistic/images/pumpkin-classifier.png)
> ਇਨਫੋਗ੍ਰਾਫਿਕ [ਦਸਾਨੀ ਮਾਡੀਪੱਲੀ](https://twitter.com/dasani_decoded) ਦੁਆਰਾ

### ਹੋਰ ਕਲਾਸੀਫਿਕੇਸ਼ਨ

ਲਾਜਿਸਟਿਕ ਰਿਗ੍ਰੈਸ਼ਨ ਦੇ ਹੋਰ ਕਿਸਮਾਂ ਵੀ ਹਨ, ਜਿਵੇਂ ਕਿ ਮਲਟੀਨੋਮਿਅਲ ਅਤੇ ਆਰਡਿਨਲ:

- **ਮਲਟੀਨੋਮਿਅਲ**, ਜਿਸ ਵਿੱਚ ਇੱਕ ਤੋਂ ਵੱਧ ਸ਼੍ਰੇਣੀਆਂ ਸ਼ਾਮਲ ਹੁੰਦੀਆਂ ਹਨ - "ਸੰਤਰੀ, ਚਿੱਟਾ, ਅਤੇ ਧਾਰੀਦਾਰ"।
- **ਆਰਡਿਨਲ**, ਜਿਸ ਵਿੱਚ ਕ੍ਰਮਬੱਧ ਸ਼੍ਰੇਣੀਆਂ ਸ਼ਾਮਲ ਹੁੰਦੀਆਂ ਹਨ, ਜੇਕਰ ਅਸੀਂ ਆਪਣੇ ਨਤੀਜਿਆਂ ਨੂੰ ਤਰਕਸੰਗਤ ਤੌਰ 'ਤੇ ਕ੍ਰਮਬੱਧ ਕਰਨਾ ਚਾਹੁੰਦੇ ਹਾਂ, ਜਿਵੇਂ ਕਿ ਸਾਡੇ ਕਦੂ ਜੋ ਇੱਕ ਨਿਰਧਾਰਿਤ ਗਿਣਤੀ ਦੇ ਆਕਾਰਾਂ (mini, sm, med, lg, xl, xxl) ਦੁਆਰਾ ਕ੍ਰਮਬੱਧ ਹਨ।

![ਮਲਟੀਨੋਮਿਅਲ ਵਿਰੁੱਧ ਆਰਡਿਨਲ ਰਿਗ੍ਰੈਸ਼ਨ](../../../../2-Regression/4-Logistic/images/multinomial-vs-ordinal.png)

### ਵੈਰੀਏਬਲਾਂ ਨੂੰ ਸੰਬੰਧਿਤ ਹੋਣ ਦੀ ਲੋੜ ਨਹੀਂ

ਯਾਦ ਹੈ ਕਿ ਰੇਖੀ ਰਿਗ੍ਰੈਸ਼ਨ ਵਧੇਰੇ ਸੰਬੰਧਿਤ ਵੈਰੀਏਬਲਾਂ ਨਾਲ ਚੰਗਾ ਕੰਮ ਕਰਦਾ ਸੀ? ਲਾਜਿਸਟਿਕ ਰਿਗ੍ਰੈਸ਼ਨ ਇਸਦਾ ਉਲਟ ਹੈ - ਵੈਰੀਏਬਲਾਂ ਨੂੰ ਸੰਬੰਧਿਤ ਹੋਣ ਦੀ ਲੋੜ ਨਹੀਂ। ਇਹ ਇਸ ਡਾਟਾ ਲਈ ਕੰਮ ਕਰਦਾ ਹੈ ਜਿਸ ਵਿੱਚ ਕੁਝ ਕਮਜ਼ੋਰ ਸੰਬੰਧ ਹਨ।

### ਤੁਹਾਨੂੰ ਬਹੁਤ ਸਾਰੇ ਸਾਫ਼ ਡਾਟਾ ਦੀ ਲੋੜ ਹੈ

ਲਾਜਿਸਟਿਕ ਰਿਗ੍ਰੈਸ਼ਨ ਜ਼ਿਆਦਾ ਸਹੀ ਨਤੀਜੇ ਦੇਵੇਗਾ ਜੇ ਤੁਸੀਂ ਜ਼ਿਆਦਾ ਡਾਟਾ ਵਰਤੋਂਗੇ; ਸਾਡਾ ਛੋਟਾ ਡਾਟਾਸੈਟ ਇਸ ਕੰਮ ਲਈ ਉਤਮ ਨਹੀਂ ਹੈ, ਇਸ ਲਈ ਇਸਨੂੰ ਯਾਦ ਰੱਖੋ।

[![ML ਸ਼ੁਰੂਆਤੀ ਲਈ - ਲਾਜਿਸਟਿਕ ਰਿਗ੍ਰੈਸ਼ਨ ਲਈ ਡਾਟਾ ਵਿਸ਼ਲੇਸ਼ਣ ਅਤੇ ਤਿਆਰੀ](https://img.youtube.com/vi/B2X4H9vcXTs/0.jpg)](https://youtu.be/B2X4H9vcXTs "ML ਸ਼ੁਰੂਆਤੀ ਲਈ - ਲਾਜਿਸਟਿਕ ਰਿਗ੍ਰੈਸ਼ਨ ਲਈ ਡਾਟਾ ਵਿਸ਼ਲੇਸ਼ਣ ਅਤੇ ਤਿਆਰੀ")

> 🎥 ਲਾਜਿਸਟਿਕ ਰਿਗ੍ਰੈਸ਼ਨ ਲਈ ਡਾਟਾ ਤਿਆਰੀ ਦੇ ਇੱਕ ਛੋਟੇ ਵੀਡੀਓ ਝਲਕ ਲਈ ਉਪਰੋਕਤ ਚਿੱਤਰ 'ਤੇ ਕਲਿਕ ਕਰੋ।

✅ ਉਹ ਡਾਟਾ ਦੇ ਕਿਸਮਾਂ ਬਾਰੇ ਸੋਚੋ ਜੋ ਲਾਜਿਸਟਿਕ ਰਿਗ੍ਰੈਸ਼ਨ ਲਈ ਚੰਗੇ ਹੋ ਸਕਦੇ ਹਨ।

## ਅਭਿਆਸ - ਡਾਟਾ ਨੂੰ ਸਾਫ਼ ਕਰੋ

ਸਭ ਤੋਂ ਪਹਿਲਾਂ, ਡਾਟਾ ਨੂੰ ਕੁਝ ਸਾਫ਼ ਕਰੋ, null ਮੁੱਲਾਂ ਨੂੰ ਹਟਾਓ ਅਤੇ ਕੁਝ ਕਾਲਮਾਂ ਨੂੰ ਚੁਣੋ:

1. ਹੇਠਾਂ ਦਿੱਤਾ ਕੋਡ ਸ਼ਾਮਲ ਕਰੋ:

    ```python
  
    columns_to_select = ['City Name','Package','Variety', 'Origin','Item Size', 'Color']
    pumpkins = full_pumpkins.loc[:, columns_to_select]

    pumpkins.dropna(inplace=True)
    ```

    ਤੁਸੀਂ ਹਮੇਸ਼ਾ ਆਪਣੇ ਨਵੇਂ ਡਾਟਾਫਰੇਮ 'ਤੇ ਇੱਕ ਝਲਕ ਮਾਰ ਸਕਦੇ ਹੋ:

    ```python
    pumpkins.info
    ```

### ਵਿਜ਼ੁਅਲਾਈਜ਼ੇਸ਼ਨ - ਸ਼੍ਰੇਣੀਬੱਧ ਪਲਾਟ

ਹੁਣ ਤੱਕ ਤੁਸੀਂ [ਸ਼ੁਰੂਆਤੀ ਨੋਟਬੁੱਕ](../../../../2-Regression/4-Logistic/notebook.ipynb) ਵਿੱਚ ਕਦੂ ਡਾਟਾ ਲੋਡ ਕਰ ਲਿਆ ਹੈ ਅਤੇ ਇਸਨੂੰ ਸਾਫ਼ ਕੀਤਾ ਹੈ ਤਾਂ ਜੋ ਕੁਝ ਵੈਰੀਏਬਲਾਂ ਸਮੇਤ `Color` ਵਾਲਾ ਡਾਟਾਸੈਟ ਬਚ ਸਕੇ। ਆਓ ਨੋਟਬੁੱਕ ਵਿੱਚ ਡਾਟਾਫਰੇਮ ਨੂੰ ਇੱਕ ਵੱਖਰੀ ਲਾਇਬ੍ਰੇਰੀ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਵਿਜ਼ੁਅਲਾਈਜ਼ ਕਰੀਏ: [Seaborn](https://seaborn.pydata.org/index.html), ਜੋ ਪਹਿਲਾਂ ਵਰਤੇ ਗਏ Matplotlib 'ਤੇ ਬਣਿਆ ਹੈ।

Seaborn ਤੁਹਾਡੇ ਡਾਟਾ ਨੂੰ ਵਿਜ਼ੁਅਲਾਈਜ਼ ਕਰਨ ਦੇ ਕੁਝ ਸ਼ਾਨਦਾਰ ਤਰੀਕੇ ਪੇਸ਼ ਕਰਦਾ ਹੈ। ਉਦਾਹਰਨ ਲਈ, ਤੁਸੀਂ ਇੱਕ ਸ਼੍ਰੇਣੀਬੱਧ ਪਲਾਟ ਵਿੱਚ `Variety` ਅਤੇ `Color` ਦੇ ਡਾਟਾ ਦੇ ਵੰਡ ਦੀ ਤੁਲਨਾ ਕਰ ਸਕਦੇ ਹੋ।

1. `catplot` ਫੰਕਸ਼ਨ ਦੀ ਵਰਤੋਂ ਕਰਕੇ, ਸਾਡੇ ਕਦੂ ਡਾਟਾ `pumpkins` ਦੀ ਵਰਤੋਂ ਕਰਕੇ, ਅਤੇ ਹਰ ਕਦੂ ਸ਼੍ਰੇਣੀ (ਸੰਤਰੀ ਜਾਂ ਚਿੱਟਾ) ਲਈ ਇੱਕ ਰੰਗ ਨਕਸ਼ਾ ਨਿਰਧਾਰਤ ਕਰਕੇ, ਇੱਕ ਪਲਾਟ ਬਣਾਓ:

    ```python
    import seaborn as sns
    
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }

    sns.catplot(
    data=pumpkins, y="Variety", hue="Color", kind="count",
    palette=palette, 
    )
    ```

    ![ਡਾਟਾ ਦੀ ਵਿਜ਼ੁਅਲਾਈਜ਼ ਕੀਤੀ ਗ੍ਰਿਡ](../../../../2-Regression/4-Logistic/images/pumpkins_catplot_1.png)

    ਡਾਟਾ ਨੂੰ ਦੇਖ ਕੇ, ਤੁਸੀਂ ਦੇਖ ਸਕਦੇ ਹੋ ਕਿ Color ਡਾਟਾ `Variety` ਨਾਲ ਕਿਵੇਂ ਸੰਬੰਧਿਤ ਹੈ।

    ✅ ਇਸ ਸ਼੍ਰੇਣੀਬੱਧ ਪਲਾਟ ਦੇ ਆਧਾਰ ਤੇ, ਤੁਹਾਡੇ ਮਨ ਵਿੱਚ ਕਿਹੜੀਆਂ ਦਿਲਚਸਪ ਖੋਜਾਂ ਆ ਸਕਦੀਆਂ ਹਨ?

### ਡਾਟਾ ਪ੍ਰੀ-ਪ੍ਰੋਸੈਸਿੰਗ: ਫੀਚਰ ਅਤੇ ਲੇਬਲ ਐਨਕੋਡਿੰਗ

ਸਾਡੇ ਕਦੂ ਡਾਟਾਸੈਟ ਵਿੱਚ ਇਸਦੇ ਸਾਰੇ ਕਾਲਮਾਂ ਲਈ ਸਤਰ ਮੁੱਲ ਹਨ। ਸ਼੍ਰੇਣੀਬੱਧ ਡਾਟਾ ਨਾਲ ਕੰਮ ਕਰਨਾ ਮਨੁੱਖਾਂ ਲਈ ਬਹੁਤ ਸਹਜ ਹੈ ਪਰ ਮਸ਼ੀਨਾਂ ਲਈ ਨਹੀਂ। ਮਸ਼ੀਨ ਲਰਨਿੰਗ ਐਲਗੋਰਿਥਮ ਨੰਬਰਾਂ ਨਾਲ ਚੰਗਾ ਕੰਮ ਕਰਦੇ ਹਨ। ਇਸੇ ਲਈ ਐਨਕੋਡਿੰਗ ਡਾਟਾ ਪ੍ਰੀ-ਪ੍ਰੋਸੈਸਿੰਗ ਦੇ ਚਰਨ ਵਿੱਚ ਇੱਕ ਬਹੁਤ ਮਹੱਤਵਪੂਰਨ ਕਦਮ ਹੈ, ਕਿਉਂਕਿ ਇਹ ਸਾਨੂੰ ਸ਼੍ਰੇਣੀਬੱਧ ਡਾਟਾ ਨੂੰ ਸੰਖਿਆਤਮਕ ਡਾਟਾ ਵਿੱਚ ਬਦਲਣ ਯੋਗ ਬਣਾਉਂਦਾ ਹੈ, ਬਿਨਾਂ ਕੋਈ ਜਾਣਕਾਰੀ ਗੁਆਏ। ਚੰਗੀ ਐਨਕੋਡਿੰਗ ਇੱਕ ਚੰਗਾ ਮਾਡਲ ਬਣਾਉਣ ਵਿੱਚ ਸਹਾਇਕ ਹੈ।

ਫੀਚਰ ਐਨਕੋਡਿੰਗ ਲਈ ਦੋ ਮੁੱਖ ਕਿਸਮ ਦੇ ਐਨਕੋਡਰ ਹਨ:

1. ਆਰਡਿਨਲ ਐਨਕੋਡਰ: ਇਹ ਆਰਡਿਨਲ ਵੈਰੀਏਬਲਾਂ ਲਈ ਚੰਗਾ ਹੈ, ਜੋ ਸ਼੍ਰੇਣੀਬੱਧ ਵੈਰੀਏਬਲ ਹਨ ਜਿਨ੍ਹਾਂ ਦੇ ਡਾਟਾ ਦਾ ਲਾਜ਼ਮੀ ਕ੍ਰਮ ਹੁੰਦਾ ਹੈ, ਜਿਵੇਂ ਕਿ ਸਾਡੇ ਡਾਟਾਸੈਟ ਵਿੱਚ `Item Size` ਕਾਲਮ। ਇਹ ਇੱਕ ਨਕਸ਼ਾ ਬਣਾਉਂਦਾ ਹੈ ਜਿਸ ਵਿੱਚ ਹਰ ਸ਼੍ਰੇਣੀ ਨੂੰ ਇੱਕ ਨੰਬਰ ਦੁਆਰਾ ਦਰਸਾਇਆ ਜਾਂਦਾ ਹੈ, ਜੋ ਕਾਲਮ ਵਿੱਚ ਸ਼੍ਰੇਣੀ ਦਾ ਕ੍ਰਮ ਹੈ।

    ```python
    from sklearn.preprocessing import OrdinalEncoder

    item_size_categories = [['sml', 'med', 'med-lge', 'lge', 'xlge', 'jbo', 'exjbo']]
    ordinal_features = ['Item Size']
    ordinal_encoder = OrdinalEncoder(categories=item_size_categories)
    ```

2. ਸ਼੍ਰੇਣੀਬੱਧ ਐਨਕੋਡਰ: ਇਹ ਨਾਮਵਾਚਕ ਵੈਰੀਏਬਲਾਂ ਲਈ ਚੰਗਾ ਹੈ, ਜੋ ਸ਼੍ਰੇਣੀਬੱਧ ਵੈਰੀਏਬਲ ਹਨ ਜਿਨ੍ਹਾਂ ਦੇ ਡਾਟਾ ਦਾ ਲਾਜ਼ਮੀ ਕ੍ਰਮ ਨਹੀਂ ਹੁੰਦਾ, ਜਿਵੇਂ ਕਿ ਸਾਡੇ ਡਾਟਾਸੈਟ ਵਿੱਚ `Item Size` ਤੋਂ ਵੱਖਰੇ ਸਾਰੇ ਫੀਚਰ। ਇਹ ਇੱਕ one-hot ਐਨਕੋਡਿੰਗ ਹੈ, ਜਿਸਦਾ ਅਰਥ ਹੈ ਕਿ ਹਰ ਸ਼੍ਰੇਣੀ ਨੂੰ ਇੱਕ ਬਾਈਨਰੀ ਕਾਲਮ ਦੁਆਰਾ ਦਰਸਾਇਆ ਜਾਂਦਾ ਹੈ: ਐਨਕੋਡ ਕੀਤੀ ਵੈਰੀਏਬਲ 1 ਦੇ ਬਰਾਬਰ ਹੈ ਜੇਕਰ ਕਦੂ ਉਸ Variety ਨਾਲ ਸਬੰਧਿਤ ਹੈ ਅਤੇ 0 ਹੋਰਥਾਂ।

    ```python
    from sklearn.preprocessing import OneHotEncoder

    categorical_features = ['City Name', 'Package', 'Variety', 'Origin']
    categorical_encoder = OneHotEncoder(sparse_output=False)
    ```

ਫਿਰ, `ColumnTransformer` ਨੂੰ ਕਈ ਐਨਕੋਡਰਾਂ ਨੂੰ ਇੱਕ ਸਿੰਗਲ ਕਦਮ ਵਿੱਚ ਜੋੜਨ ਅਤੇ ਉਨ੍ਹਾਂ ਨੂੰ ਸਹੀ ਕਾਲਮਾਂ 'ਤੇ ਲਾਗੂ ਕਰਨ ਲਈ ਵਰਤਿਆ ਜਾਂਦਾ ਹੈ।

```python
    from sklearn.compose import ColumnTransformer
    
    ct = ColumnTransformer(transformers=[
        ('ord', ordinal_encoder, ordinal_features),
        ('cat', categorical_encoder, categorical_features)
        ])
    
    ct.set_output(transform='pandas')
    encoded_features = ct.fit_transform(pumpkins)
```

ਦੂਜੇ ਪਾਸੇ, ਲੇਬਲ ਨੂੰ ਐਨਕੋਡ ਕਰਨ ਲਈ, ਅਸੀਂ scikit-learn `LabelEncoder` ਕਲਾਸ ਦੀ ਵਰਤੋਂ ਕਰਦੇ ਹਾਂ, ਜੋ ਲੇਬਲਾਂ ਨੂੰ ਸਧਾਰਨ ਕਰਨ ਵਿੱਚ ਮਦਦ ਕਰਨ ਲਈ ਇੱਕ ਯੂਟਿਲਿਟੀ ਕਲਾਸ ਹੈ ਤਾਂ ਜੋ ਉਹ ਸਿਰਫ਼ 0 ਤੋਂ n_classes-1 (ਇੱਥੇ, 0 ਅਤੇ 1) ਦੇ ਮੁੱਲਾਂ ਨੂੰ ਸ਼ਾਮਲ ਕਰੇ।

```python
    from sklearn.preprocessing import LabelEncoder

    label_encoder = LabelEncoder()
    encoded_label = label_encoder.fit_transform(pumpkins['Color'])
```

ਜਦੋਂ ਸਾਨੂੰ ਫੀਚਰ ਅਤੇ ਲੇਬਲ ਐਨਕੋਡ ਕਰ ਲਏ, ਅਸੀਂ ਉਨ੍ਹਾਂ ਨੂੰ ਇੱਕ ਨਵੇਂ ਡਾਟਾਫਰੇਮ `encoded_pumpkins` ਵਿੱਚ ਮਿਲਾ ਸਕਦੇ ਹਾਂ।

```python
    encoded_pumpkins = encoded_features.assign(Color=encoded_label)
```

✅ `Item Size` ਕਾਲਮ ਲਈ ਆਰਡਿਨਲ ਐਨਕੋਡਰ ਦੀ ਵਰਤੋਂ ਕਰਨ ਦੇ ਫਾਇਦੇ ਕੀ ਹਨ?

### ਵੈਰੀਏਬਲਾਂ ਦੇ ਵਿਚਕਾਰ ਸੰਬੰਧਾਂ ਦਾ ਵਿਸ਼ਲੇਸ਼ਣ ਕਰੋ

ਹੁਣ ਜਦੋਂ ਅਸੀਂ ਆਪਣੇ ਡਾਟਾ ਨੂੰ ਪ੍ਰੀ-ਪ੍ਰੋਸੈਸ ਕਰ ਲਿਆ ਹੈ, ਅਸੀਂ ਫੀਚਰ ਅਤੇ ਲੇਬਲ ਦੇ ਵਿਚਕਾਰ ਸੰਬੰਧਾਂ ਦਾ ਵਿਸ਼ਲੇਸ਼ਣ ਕਰ ਸਕਦੇ ਹਾਂ ਤਾਂ ਜੋ ਇਹ ਸਮਝ ਸਕੀਏ ਕਿ ਮਾਡਲ ਫੀਚਰ ਦੇ ਆਧਾਰ 'ਤੇ ਲੇਬਲ ਦੀ ਪੇਸ਼ਗੂਈ ਕਿੰਨਾ ਚੰਗਾ ਕਰੇਗਾ।

ਇਸ ਕਿਸਮ ਦੇ ਵਿਸ਼ਲੇਸ਼ਣ ਨੂੰ ਕਰਨ ਦਾ ਸਭ ਤੋਂ ਵਧੀਆ ਤਰੀਕਾ ਡਾਟਾ ਨੂੰ ਪਲਾਟ ਕਰਨਾ ਹੈ। ਅਸੀਂ ਫਿਰ Seaborn `catplot` ਫੰਕਸ਼ਨ ਦੀ ਵਰਤੋਂ ਕਰਾਂਗੇ, `Item Size`, `Variety` ਅਤੇ `Color` ਦੇ ਵਿਚਕਾਰ ਸੰਬੰਧਾਂ ਨੂੰ ਇੱਕ ਸ਼੍ਰੇਣੀਬੱਧ ਪਲਾਟ ਵਿੱਚ ਵਿਜ਼ੁਅਲਾਈਜ਼ ਕਰਨ ਲਈ। ਡਾਟਾ ਨੂੰ ਵਧੀਆ ਪਲਾਟ ਕਰਨ ਲਈ ਅਸੀਂ ਐਨਕੋਡ ਕੀਤੇ `Item Size` ਕਾਲਮ ਅਤੇ ਅਨਐਨਕੋਡ ਕੀਤੇ `Variety` ਕਾਲਮ ਦੀ ਵਰਤੋਂ ਕਰਾਂਗੇ।

```python
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }
    pumpkins['Item Size'] = encoded_pumpkins['ord__Item Size']

    g = sns.catplot(
        data=pumpkins,
        x="Item Size", y="Color", row='Variety',
        kind="box", orient="h",
        sharex=False, margin_titles=True,
        height=1.8, aspect=4, palette=palette,
    )
    g.set(xlabel="Item Size", ylabel="").set(xlim=(0,6))
    g.set_titles(row_template="{row_name}")
```

![ਡਾਟਾ ਦੀ ਵਿਜ਼ੁਅਲਾਈਜ਼ ਕੀਤੀ ਕੈਟਪਲਾਟ](../../../../2-Regression/4-Logistic/images/pumpkins_catplot_2.png)

### ਸਵਾਰਮ ਪਲਾਟ ਦੀ ਵਰਤੋਂ ਕਰੋ

ਕਿਉਂਕਿ Color ਇੱਕ ਬਾਈਨਰੀ ਸ਼੍ਰੇਣੀ ਹੈ (ਚਿੱਟਾ ਜਾਂ ਚਿੱਟਾ ਨਹੀਂ), ਇਸਨੂੰ ਵਿਜ਼ੁਅਲਾਈਜ਼ ਕਰਨ ਲਈ 'ਇੱਕ [ਵਿਸ਼ੇਸ਼ ਤਰੀਕਾ](https://seaborn.pydata.org/tutorial/categorical.html?highlight=bar)' ਦੀ ਲੋੜ ਹੈ। ਇਸ ਸ਼੍ਰੇਣੀ ਦੇ ਹੋਰ ਵੈਰੀਏਬਲਾਂ ਨਾਲ ਸੰਬੰਧ ਨੂੰ ਵਿਜ਼ੁਅਲਾਈਜ਼ ਕਰਨ ਦੇ ਹੋਰ ਤਰੀਕੇ ਹਨ।

ਤੁਸੀਂ Seaborn ਪਲਾਟਾਂ ਨਾਲ ਵੈਰੀਏਬਲਾਂ ਨੂੰ ਸਾਈਡ-ਬਾਈ-ਸਾਈਡ ਵਿਜ਼ੁਅਲਾਈਜ਼ ਕਰ ਸਕਦੇ ਹੋ।

1. ਮੁੱਲਾਂ
ਕਨਫਿਊਜ਼ਨ ਮੈਟ੍ਰਿਕਸ ਪ੍ਰਿਸੀਜ਼ਨ ਅਤੇ ਰੀਕਾਲ ਨਾਲ ਕਿਵੇਂ ਸੰਬੰਧਿਤ ਹੈ? ਯਾਦ ਰੱਖੋ, ਉੱਪਰ ਪ੍ਰਿੰਟ ਕੀਤੀ ਕਲਾਸੀਫਿਕੇਸ਼ਨ ਰਿਪੋਰਟ ਨੇ ਪ੍ਰਿਸੀਜ਼ਨ (0.85) ਅਤੇ ਰੀਕਾਲ (0.67) ਦਿਖਾਈ।

ਪ੍ਰਿਸੀਜ਼ਨ = tp / (tp + fp) = 22 / (22 + 4) = 0.8461538461538461

ਰੀਕਾਲ = tp / (tp + fn) = 22 / (22 + 11) = 0.6666666666666666

✅ ਪ੍ਰਸ਼ਨ: ਕਨਫਿਊਜ਼ਨ ਮੈਟ੍ਰਿਕਸ ਦੇ ਅਨੁਸਾਰ, ਮਾਡਲ ਕਿਵੇਂ ਕਰ ਰਿਹਾ ਹੈ? ਜਵਾਬ: ਬੁਰਾ ਨਹੀਂ; ਸਹੀ ਨੈਗੇਟਿਵਜ਼ ਦੀ ਚੰਗੀ ਗਿਣਤੀ ਹੈ ਪਰ ਕੁਝ ਗਲਤ ਨੈਗੇਟਿਵਜ਼ ਵੀ ਹਨ।

ਆਓ ਉਹ ਸ਼ਬਦਾਵਲੀ ਦੁਬਾਰਾ ਵੇਖੀਏ ਜੋ ਅਸੀਂ ਪਹਿਲਾਂ ਦੇਖੀ ਸੀ, TP/TN ਅਤੇ FP/FN ਦੇ ਕਨਫਿਊਜ਼ਨ ਮੈਟ੍ਰਿਕਸ ਦੇ ਮੈਪਿੰਗ ਦੀ ਮਦਦ ਨਾਲ:

🎓 ਪ੍ਰਿਸੀਜ਼ਨ: TP/(TP + FP) ਰਿਕਵਰ ਕੀਤੇ ਗਏ ਇੰਸਟੈਂਸ ਵਿੱਚੋਂ ਸਬੰਧਤ ਇੰਸਟੈਂਸ ਦਾ ਅੰਸ਼ (ਉਦਾਹਰਣ ਲਈ, ਕਿਹੜੇ ਲੇਬਲ ਚੰਗੀ ਤਰ੍ਹਾਂ ਲੇਬਲ ਕੀਤੇ ਗਏ)

🎓 ਰੀਕਾਲ: TP/(TP + FN) ਸਬੰਧਤ ਇੰਸਟੈਂਸ ਦਾ ਅੰਸ਼ ਜੋ ਰਿਕਵਰ ਕੀਤਾ ਗਿਆ, ਚਾਹੇ ਚੰਗੀ ਤਰ੍ਹਾਂ ਲੇਬਲ ਕੀਤਾ ਗਿਆ ਹੋ ਜਾਂ ਨਹੀਂ

🎓 f1-ਸਕੋਰ: (2 * ਪ੍ਰਿਸੀਜ਼ਨ * ਰੀਕਾਲ)/(ਪ੍ਰਿਸੀਜ਼ਨ + ਰੀਕਾਲ) ਪ੍ਰਿਸੀਜ਼ਨ ਅਤੇ ਰੀਕਾਲ ਦਾ ਵਜ਼ਨੀ ਔਸਤ, ਸਭ ਤੋਂ ਵਧੀਆ 1 ਅਤੇ ਸਭ ਤੋਂ ਖਰਾਬ 0

🎓 ਸਪੋਰਟ: ਹਰ ਲੇਬਲ ਲਈ ਰਿਕਵਰ ਕੀਤੇ ਗਏ ਇੰਸਟੈਂਸ ਦੀ ਗਿਣਤੀ

🎓 ਐਕੁਰੇਸੀ: (TP + TN)/(TP + TN + FP + FN) ਨਮੂਨੇ ਲਈ ਸਹੀ ਤਰੀਕੇ ਨਾਲ ਅਨੁਮਾਨਿਤ ਲੇਬਲਾਂ ਦਾ ਪ੍ਰਤੀਸ਼ਤ।

🎓 ਮੈਕਰੋ ਐਵਰੇਜ: ਹਰ ਲੇਬਲ ਲਈ ਅਣਵਜ਼ਨੀ ਮੀਨ ਮੈਟ੍ਰਿਕਸ ਦੀ ਗਣਨਾ, ਲੇਬਲ ਅਸਮਤਲਤਾ ਨੂੰ ਧਿਆਨ ਵਿੱਚ ਨਾ ਲਿਆਉਂਦੇ ਹੋਏ।

🎓 ਵਜ਼ਨੀ ਐਵਰੇਜ: ਹਰ ਲੇਬਲ ਲਈ ਮੀਨ ਮੈਟ੍ਰਿਕਸ ਦੀ ਗਣਨਾ, ਲੇਬਲ ਅਸਮਤਲਤਾ ਨੂੰ ਧਿਆਨ ਵਿੱਚ ਲਿਆਉਂਦੇ ਹੋਏ, ਉਨ੍ਹਾਂ ਦੇ ਸਪੋਰਟ (ਹਰ ਲੇਬਲ ਲਈ ਸਹੀ ਇੰਸਟੈਂਸ ਦੀ ਗਿਣਤੀ) ਦੁਆਰਾ ਵਜ਼ਨੀ।

✅ ਕੀ ਤੁਸੀਂ ਸੋਚ ਸਕਦੇ ਹੋ ਕਿ ਕਿਹੜੀ ਮੈਟ੍ਰਿਕਸ ਨੂੰ ਦੇਖਣਾ ਚਾਹੀਦਾ ਹੈ ਜੇ ਤੁਸੀਂ ਆਪਣੇ ਮਾਡਲ ਵਿੱਚ ਗਲਤ ਨੈਗੇਟਿਵਜ਼ ਦੀ ਗਿਣਤੀ ਘਟਾਉਣਾ ਚਾਹੁੰਦੇ ਹੋ?

## ਇਸ ਮਾਡਲ ਦੇ ROC ਕਰਵ ਨੂੰ ਵਿਜੁਅਲਾਈਜ਼ ਕਰੋ

[![ML for beginners - Analyzing Logistic Regression Performance with ROC Curves](https://img.youtube.com/vi/GApO575jTA0/0.jpg)](https://youtu.be/GApO575jTA0 "ML for beginners - Analyzing Logistic Regression Performance with ROC Curves")

> 🎥 ਉੱਪਰ ਦਿੱਤੀ ਤਸਵੀਰ 'ਤੇ ਕਲਿਕ ਕਰੋ ROC ਕਰਵਜ਼ ਦਾ ਛੋਟਾ ਵੀਡੀਓ ਝਲਕ ਦੇਖਣ ਲਈ

ਆਓ ਇੱਕ ਹੋਰ ਵਿਜੁਅਲਾਈਜ਼ੇਸ਼ਨ ਕਰੀਏ ਤਾਂ ਜੋ 'ROC' ਕਰਵ ਨੂੰ ਵੇਖ ਸਕੀਏ:

```python
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline

y_scores = model.predict_proba(X_test)
fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])

fig = plt.figure(figsize=(6, 6))
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.show()
```

Matplotlib ਦੀ ਵਰਤੋਂ ਕਰਦੇ ਹੋਏ, ਮਾਡਲ ਦਾ [Receiving Operating Characteristic](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html?highlight=roc) ਜਾਂ ROC ਪਲਾਟ ਕਰੋ। ROC ਕਰਵਜ਼ ਨੂੰ ਅਕਸਰ ਇੱਕ ਕਲਾਸੀਫਾਇਰ ਦੇ ਆਉਟਪੁੱਟ ਨੂੰ ਇਸਦੇ ਸਹੀ ਅਤੇ ਗਲਤ ਪਾਜ਼ਿਟਿਵਜ਼ ਦੇ ਤੌਰ 'ਤੇ ਵੇਖਣ ਲਈ ਵਰਤਿਆ ਜਾਂਦਾ ਹੈ। "ROC ਕਰਵਜ਼ ਆਮ ਤੌਰ 'ਤੇ Y ਅਕਸ 'ਤੇ ਸਹੀ ਪਾਜ਼ਿਟਿਵ ਦਰ ਅਤੇ X ਅਕਸ 'ਤੇ ਗਲਤ ਪਾਜ਼ਿਟਿਵ ਦਰ ਦਿਖਾਉਂਦੇ ਹਨ।" ਇਸ ਲਈ, ਕਰਵ ਦੀ ਢਲਾਨ ਅਤੇ ਮਿਡਪੋਇੰਟ ਲਾਈਨ ਅਤੇ ਕਰਵ ਦੇ ਵਿਚਕਾਰ ਦੀ ਜਗ੍ਹਾ ਮਹੱਤਵਪੂਰਨ ਹੈ: ਤੁਸੀਂ ਇੱਕ ਕਰਵ ਚਾਹੁੰਦੇ ਹੋ ਜੋ ਜਲਦੀ ਉੱਪਰ ਅਤੇ ਲਾਈਨ ਤੋਂ ਪਰੇ ਜਾਵੇ। ਸਾਡੇ ਕੇਸ ਵਿੱਚ, ਸ਼ੁਰੂ ਵਿੱਚ ਕੁਝ ਗਲਤ ਪਾਜ਼ਿਟਿਵਜ਼ ਹਨ, ਅਤੇ ਫਿਰ ਲਾਈਨ ਠੀਕ ਢੰਗ ਨਾਲ ਉੱਪਰ ਅਤੇ ਪਰੇ ਚਲੀ ਜਾਂਦੀ ਹੈ:

![ROC](../../../../2-Regression/4-Logistic/images/ROC_2.png)

ਅੰਤ ਵਿੱਚ, Scikit-learn ਦੇ [`roc_auc_score` API](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html?highlight=roc_auc#sklearn.metrics.roc_auc_score) ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਅਸਲ 'Area Under the Curve' (AUC) ਦੀ ਗਣਨਾ ਕਰੋ:

```python
auc = roc_auc_score(y_test,y_scores[:,1])
print(auc)
```
ਨਤੀਜਾ ਹੈ `0.9749908725812341`। ਜਿਵੇਂ ਕਿ AUC 0 ਤੋਂ 1 ਤੱਕ ਹੁੰਦੀ ਹੈ, ਤੁਸੀਂ ਇੱਕ ਵੱਡਾ ਸਕੋਰ ਚਾਹੁੰਦੇ ਹੋ, ਕਿਉਂਕਿ ਇੱਕ ਮਾਡਲ ਜੋ ਆਪਣੇ ਅਨੁਮਾਨਾਂ ਵਿੱਚ 100% ਸਹੀ ਹੈ ਉਸਦਾ AUC 1 ਹੋਵੇਗਾ; ਇਸ ਕੇਸ ਵਿੱਚ, ਮਾਡਲ _ਕਾਫ਼ੀ ਚੰਗਾ_ ਹੈ।

ਭਵਿੱਖ ਦੇ ਕਲਾਸੀਫਿਕੇਸ਼ਨ ਪਾਠਾਂ ਵਿੱਚ, ਤੁਸੀਂ ਆਪਣੇ ਮਾਡਲ ਦੇ ਸਕੋਰਾਂ ਨੂੰ ਸੁਧਾਰਨ ਲਈ ਦੁਹਰਾਉਣ ਦੇ ਤਰੀਕੇ ਸਿੱਖੋਗੇ। ਪਰ ਇਸ ਸਮੇਂ ਲਈ, ਵਧਾਈ ਹੋਵੇ! ਤੁਸੀਂ ਇਹ ਰਿਗ੍ਰੈਸ਼ਨ ਪਾਠ ਪੂਰੇ ਕਰ ਲਏ ਹਨ!

---
## 🚀ਚੈਲੈਂਜ

ਲੌਜਿਸਟਿਕ ਰਿਗ੍ਰੈਸ਼ਨ ਬਾਰੇ ਬਹੁਤ ਕੁਝ ਸਿੱਖਣ ਲਈ ਹੈ! ਪਰ ਸਿੱਖਣ ਦਾ ਸਭ ਤੋਂ ਵਧੀਆ ਤਰੀਕਾ ਅਨੁਭਵ ਕਰਨਾ ਹੈ। ਇੱਕ ਡਾਟਾਸੈਟ ਲੱਭੋ ਜੋ ਇਸ ਕਿਸਮ ਦੇ ਵਿਸ਼ਲੇਸ਼ਣ ਲਈ ਉਚਿਤ ਹੋਵੇ ਅਤੇ ਇਸ ਨਾਲ ਇੱਕ ਮਾਡਲ ਬਣਾਓ। ਤੁਸੀਂ ਕੀ ਸਿੱਖਦੇ ਹੋ? ਸੁਝਾਅ: ਦਿਲਚਸਪ ਡਾਟਾਸੈਟ ਲਈ [Kaggle](https://www.kaggle.com/search?q=logistic+regression+datasets) ਦੀ ਕੋਸ਼ਿਸ਼ ਕਰੋ।

## [ਪੋਸਟ-ਲੈਕਚਰ ਕਵਿਜ਼](https://ff-quizzes.netlify.app/en/ml/)

## ਸਮੀਖਿਆ ਅਤੇ ਸਵੈ ਅਧਿਐਨ

[Stanford ਦੇ ਇਸ ਪੇਪਰ](https://web.stanford.edu/~jurafsky/slp3/5.pdf) ਦੇ ਪਹਿਲੇ ਕੁਝ ਪੰਨੇ ਪੜ੍ਹੋ ਜੋ ਲੌਜਿਸਟਿਕ ਰਿਗ੍ਰੈਸ਼ਨ ਦੇ ਕੁਝ ਵਿਹਾਰਕ ਉਪਯੋਗਾਂ ਬਾਰੇ ਹਨ। ਉਹ ਕੰਮਾਂ ਬਾਰੇ ਸੋਚੋ ਜੋ ਅਸੀਂ ਹੁਣ ਤੱਕ ਪੜ੍ਹੇ ਰਿਗ੍ਰੈਸ਼ਨ ਦੇ ਕਿਸੇ ਇੱਕ ਜਾਂ ਦੂਜੇ ਕਿਸਮ ਲਈ ਵਧੀਆ ਹੋ ਸਕਦੇ ਹਨ। ਕੀ ਸਭ ਤੋਂ ਵਧੀਆ ਕੰਮ ਕਰੇਗਾ?

## ਅਸਾਈਨਮੈਂਟ

[ਇਸ ਰਿਗ੍ਰੈਸ਼ਨ ਨੂੰ ਦੁਬਾਰਾ ਕਰਨ ਦੀ ਕੋਸ਼ਿਸ਼ ਕਰੋ](assignment.md)

---

**ਅਸਵੀਕਤੀ**:  
ਇਹ ਦਸਤਾਵੇਜ਼ AI ਅਨੁਵਾਦ ਸੇਵਾ [Co-op Translator](https://github.com/Azure/co-op-translator) ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਅਨੁਵਾਦ ਕੀਤਾ ਗਿਆ ਹੈ। ਜਦੋਂ ਕਿ ਅਸੀਂ ਸਹੀਤਾ ਲਈ ਯਤਨਸ਼ੀਲ ਹਾਂ, ਕਿਰਪਾ ਕਰਕੇ ਧਿਆਨ ਦਿਓ ਕਿ ਸਵੈਚਾਲਿਤ ਅਨੁਵਾਦਾਂ ਵਿੱਚ ਗਲਤੀਆਂ ਜਾਂ ਅਸੁਚਤਤਾਵਾਂ ਹੋ ਸਕਦੀਆਂ ਹਨ। ਮੂਲ ਦਸਤਾਵੇਜ਼ ਨੂੰ ਇਸਦੀ ਮੂਲ ਭਾਸ਼ਾ ਵਿੱਚ ਅਧਿਕਾਰਤ ਸਰੋਤ ਮੰਨਿਆ ਜਾਣਾ ਚਾਹੀਦਾ ਹੈ। ਮਹੱਤਵਪੂਰਨ ਜਾਣਕਾਰੀ ਲਈ, ਪੇਸ਼ੇਵਰ ਮਨੁੱਖੀ ਅਨੁਵਾਦ ਦੀ ਸਿਫਾਰਸ਼ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਇਸ ਅਨੁਵਾਦ ਦੀ ਵਰਤੋਂ ਤੋਂ ਪੈਦਾ ਹੋਣ ਵਾਲੇ ਕਿਸੇ ਵੀ ਗਲਤਫਹਿਮੀ ਜਾਂ ਗਲਤ ਵਿਆਖਿਆ ਲਈ ਅਸੀਂ ਜ਼ਿੰਮੇਵਾਰ ਨਹੀਂ ਹਾਂ।