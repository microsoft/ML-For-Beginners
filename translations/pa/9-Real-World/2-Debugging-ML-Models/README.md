<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "df2b538e8fbb3e91cf0419ae2f858675",
  "translation_date": "2025-09-06T07:01:30+00:00",
  "source_file": "9-Real-World/2-Debugging-ML-Models/README.md",
  "language_code": "pa"
}
-->
# ਪੋਸਟਸਕ੍ਰਿਪਟ: ਮਸ਼ੀਨ ਲਰਨਿੰਗ ਵਿੱਚ ਮਾਡਲ ਡੀਬੱਗਿੰਗ ਲਈ ਜ਼ਿੰਮੇਵਾਰ AI ਡੈਸ਼ਬੋਰਡ ਕੰਪੋਨੈਂਟਸ ਦੀ ਵਰਤੋਂ

## [ਪ੍ਰੀ-ਲੈਕਚਰ ਕਵਿਜ਼](https://ff-quizzes.netlify.app/en/ml/)

## ਤਾਰਫ਼

ਮਸ਼ੀਨ ਲਰਨਿੰਗ ਸਾਡੇ ਰੋਜ਼ਾਨਾ ਜੀਵਨ ਨੂੰ ਪ੍ਰਭਾਵਿਤ ਕਰਦੀ ਹੈ। AI ਸਿਹਤ ਸੇਵਾਵਾਂ, ਵਿੱਤ, ਸਿੱਖਿਆ ਅਤੇ ਰੋਜ਼ਗਾਰ ਵਰਗੇ ਖੇਤਰਾਂ ਵਿੱਚ ਦਾਖਲ ਹੋ ਰਹੀ ਹੈ, ਜੋ ਸਾਡੇ ਸਮਾਜ ਅਤੇ ਵਿਅਕਤੀਗਤ ਜੀਵਨ ਨੂੰ ਪ੍ਰਭਾਵਿਤ ਕਰਦੇ ਹਨ। ਉਦਾਹਰਣ ਲਈ, ਸਿਸਟਮ ਅਤੇ ਮਾਡਲ ਦਿਨ-ਰਾਤ ਦੇ ਫੈਸਲੇ ਲੈਣ ਵਾਲੇ ਕੰਮਾਂ ਵਿੱਚ ਸ਼ਾਮਲ ਹਨ, ਜਿਵੇਂ ਕਿ ਸਿਹਤ ਸੇਵਾ ਦੀ ਨਿਦਾਨ ਜਾਂ ਧੋਖਾਧੜੀ ਦੀ ਪਛਾਣ। ਇਸ ਦੇ ਨਤੀਜੇ ਵਜੋਂ, AI ਵਿੱਚ ਤਰੱਕੀ ਅਤੇ ਇਸ ਦੀ ਤੇਜ਼ੀ ਨਾਲ ਅਪਨਾਉਣ ਨੂੰ ਸਮਾਜਿਕ ਉਮੀਦਾਂ ਅਤੇ ਨਿਯਮਾਂ ਦੇ ਵਿਕਾਸ ਨਾਲ ਮਿਲਾਇਆ ਜਾ ਰਿਹਾ ਹੈ। ਅਸੀਂ ਅਕਸਰ ਵੇਖਦੇ ਹਾਂ ਕਿ AI ਸਿਸਟਮ ਕਈ ਵਾਰ ਉਮੀਦਾਂ 'ਤੇ ਖਰੇ ਨਹੀਂ ਉਤਰਦੇ; ਇਹ ਨਵੇਂ ਚੁਣੌਤੀ ਪੇਸ਼ ਕਰਦੇ ਹਨ; ਅਤੇ ਸਰਕਾਰਾਂ AI ਹੱਲਾਂ ਨੂੰ ਨਿਯਮਿਤ ਕਰਨਾ ਸ਼ੁਰੂ ਕਰ ਰਹੀਆਂ ਹਨ। ਇਸ ਲਈ, ਇਹ ਜ਼ਰੂਰੀ ਹੈ ਕਿ ਇਹ ਮਾਡਲਾਂ ਦਾ ਵਿਸ਼ਲੇਸ਼ਣ ਕੀਤਾ ਜਾਵੇ ਤਾਂ ਜੋ ਸਾਰੇ ਲਈ ਨਿਰਪੱਖ, ਭਰੋਸੇਯੋਗ, ਸ਼ਾਮਿਲ, ਪਾਰਦਰਸ਼ੀ ਅਤੇ ਜਵਾਬਦੇਹ ਨਤੀਜੇ ਪ੍ਰਦਾਨ ਕੀਤੇ ਜਾ ਸਕਣ।

ਇਸ ਪਾਠਕ੍ਰਮ ਵਿੱਚ, ਅਸੀਂ ਅਜਿਹੇ ਪ੍ਰਯੋਗਿਕ ਟੂਲਾਂ ਦੀ ਜਾਂਚ ਕਰਾਂਗੇ ਜੋ ਮਾਡਲ ਵਿੱਚ ਜ਼ਿੰਮੇਵਾਰ AI ਸੰਬੰਧੀ ਸਮੱਸਿਆਵਾਂ ਦੀ ਪਛਾਣ ਕਰਨ ਲਈ ਵਰਤੇ ਜਾ ਸਕਦੇ ਹਨ। ਰਵਾਇਤੀ ਮਸ਼ੀਨ ਲਰਨਿੰਗ ਡੀਬੱਗਿੰਗ ਤਕਨੀਕਾਂ ਆਮ ਤੌਰ 'ਤੇ ਗਣਿਤੀ ਗਣਨਾਵਾਂ 'ਤੇ ਅਧਾਰਿਤ ਹੁੰਦੀਆਂ ਹਨ, ਜਿਵੇਂ ਕਿ ਕੁੱਲ ਸਹੀਤਾ ਜਾਂ ਔਸਤ ਗਲਤੀ ਹਾਨੀ। ਸੋਚੋ ਕਿ ਕੀ ਹੋ ਸਕਦਾ ਹੈ ਜਦੋਂ ਤੁਸੀਂ ਮਾਡਲ ਬਣਾਉਣ ਲਈ ਵਰਤ ਰਹੇ ਡਾਟਾ ਵਿੱਚ ਕੁਝ ਜਾਤੀਆਂ, ਲਿੰਗ, ਰਾਜਨੀਤਿਕ ਦ੍ਰਿਸ਼ਟੀਕੋਣ, ਧਰਮ ਜਾਂ ਅਸਮਾਨ ਪ੍ਰਤੀਨਿਧਤਾ ਦੀ ਘਾਟ ਹੁੰਦੀ ਹੈ। ਜਦੋਂ ਮਾਡਲ ਦਾ ਨਤੀਜਾ ਕੁਝ ਜਾਤੀਆਂ ਨੂੰ ਵਧੇਰੇ ਤਰਜੀਹ ਦਿੰਦਾ ਹੈ, ਤਾਂ ਇਹ ਸੰਵੇਦਨਸ਼ੀਲ ਫੀਚਰ ਸਮੂਹਾਂ ਦੀ ਵਧੇਰੇ ਜਾਂ ਘੱਟ ਪ੍ਰਤੀਨਿਧਤਾ ਪੈਦਾ ਕਰ ਸਕਦਾ ਹੈ, ਜਿਸ ਨਾਲ ਮਾਡਲ ਵਿੱਚ ਨਿਰਪੱਖਤਾ, ਸ਼ਾਮਿਲਤਾ ਜਾਂ ਭਰੋਸੇਯੋਗਤਾ ਦੀ ਸਮੱਸਿਆ ਹੋ ਸਕਦੀ ਹੈ। ਇੱਕ ਹੋਰ ਕਾਰਕ ਇਹ ਹੈ ਕਿ ਮਸ਼ੀਨ ਲਰਨਿੰਗ ਮਾਡਲਾਂ ਨੂੰ "ਬਲੈਕ ਬਾਕਸ" ਮੰਨਿਆ ਜਾਂਦਾ ਹੈ, ਜਿਸ ਨਾਲ ਇਹ ਸਮਝਣਾ ਮੁਸ਼ਕਲ ਹੋ ਜਾਂਦਾ ਹੈ ਕਿ ਮਾਡਲ ਦੇ ਅਨੁਮਾਨਾਂ ਨੂੰ ਕੀ ਚਲਾਉਂਦਾ ਹੈ। ਇਹ ਸਾਰੀਆਂ ਚੁਣੌਤੀਆਂ ਡਾਟਾ ਸਾਇੰਟਿਸਟਾਂ ਅਤੇ AI ਡਿਵੈਲਪਰਾਂ ਨੂੰ ਸਾਹਮਣਾ ਕਰਦੀਆਂ ਹਨ ਜਦੋਂ ਉਨ੍ਹਾਂ ਕੋਲ ਮਾਡਲ ਦੀ ਨਿਰਪੱਖਤਾ ਜਾਂ ਭਰੋਸੇਯੋਗਤਾ ਦੀ ਜਾਂਚ ਕਰਨ ਲਈ ਯਥਾਰਥ ਟੂਲ ਨਹੀਂ ਹੁੰਦੇ।

ਇਸ ਪਾਠ ਵਿੱਚ, ਤੁਸੀਂ ਆਪਣੇ ਮਾਡਲਾਂ ਨੂੰ ਡੀਬੱਗ ਕਰਨ ਬਾਰੇ ਸਿੱਖੋਗੇ:

- **ਗਲਤੀ ਵਿਸ਼ਲੇਸ਼ਣ**: ਪਛਾਣ ਕਰੋ ਕਿ ਤੁਹਾਡੇ ਡਾਟਾ ਵੰਡ ਵਿੱਚ ਕਿੱਥੇ ਮਾਡਲ ਦੀ ਗਲਤੀ ਦਰ ਉੱਚੀ ਹੈ।
- **ਮਾਡਲ ਝਲਕ**: ਵੱਖ-ਵੱਖ ਡਾਟਾ ਸਮੂਹਾਂ ਵਿੱਚ ਤੁਲਨਾਤਮਕ ਵਿਸ਼ਲੇਸ਼ਣ ਕਰੋ ਤਾਂ ਜੋ ਤੁਹਾਡੇ ਮਾਡਲ ਦੇ ਪ੍ਰਦਰਸ਼ਨ ਮਾਪਦੰਡਾਂ ਵਿੱਚ ਅਸਮਾਨਤਾ ਦੀ ਪਛਾਣ ਕੀਤੀ ਜਾ ਸਕੇ।
- **ਡਾਟਾ ਵਿਸ਼ਲੇਸ਼ਣ**: ਜਾਂਚ ਕਰੋ ਕਿ ਕਿੱਥੇ ਤੁਹਾਡੇ ਡਾਟਾ ਵਿੱਚ ਵਧੇਰੇ ਜਾਂ ਘੱਟ ਪ੍ਰਤੀਨਿਧਤਾ ਹੋ ਸਕਦੀ ਹੈ, ਜੋ ਤੁਹਾਡੇ ਮਾਡਲ ਨੂੰ ਇੱਕ ਡਾਟਾ ਜਾਤੀ ਦੇ ਮੁਕਾਬਲੇ ਦੂਜੇ ਨੂੰ ਵਧੇਰੇ ਤਰਜੀਹ ਦੇਣ ਲਈ ਝੁਕਾ ਸਕਦੀ ਹੈ।
- **ਫੀਚਰ ਮਹੱਤਤਾ**: ਸਮਝੋ ਕਿ ਕਿਹੜੇ ਫੀਚਰ ਤੁਹਾਡੇ ਮਾਡਲ ਦੇ ਅਨੁਮਾਨਾਂ ਨੂੰ ਗਲੋਬਲ ਜਾਂ ਸਥਾਨਕ ਪੱਧਰ 'ਤੇ ਚਲਾਉਂਦੇ ਹਨ।

## ਪੂਰਵ-ਸ਼ਰਤ

ਪੂਰਵ-ਸ਼ਰਤ ਵਜੋਂ, ਕਿਰਪਾ ਕਰਕੇ [ਡਿਵੈਲਪਰਾਂ ਲਈ ਜ਼ਿੰਮੇਵਾਰ AI ਟੂਲ](https://www.microsoft.com/ai/ai-lab-responsible-ai-dashboard) ਦੀ ਸਮੀਖਿਆ ਕਰੋ।

> ![ਜ਼ਿੰਮੇਵਾਰ AI ਟੂਲਾਂ 'ਤੇ Gif](../../../../9-Real-World/2-Debugging-ML-Models/images/rai-overview.gif)

## ਗਲਤੀ ਵਿਸ਼ਲੇਸ਼ਣ

ਰਵਾਇਤੀ ਮਾਡਲ ਪ੍ਰਦਰਸ਼ਨ ਮਾਪਦੰਡ, ਜਿਵੇਂ ਕਿ ਸਹੀ ਅਤੇ ਗਲਤ ਅਨੁਮਾਨਾਂ ਦੇ ਅਧਾਰ 'ਤੇ ਗਣਨਾ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਉਦਾਹਰਣ ਲਈ, ਇਹ ਨਿਰਧਾਰਤ ਕਰਨਾ ਕਿ ਮਾਡਲ 89% ਸਮੇਂ ਸਹੀ ਹੈ ਅਤੇ ਗਲਤੀ ਹਾਨੀ 0.001 ਹੈ, ਇਹ ਚੰਗੇ ਪ੍ਰਦਰਸ਼ਨ ਵਜੋਂ ਮੰਨਿਆ ਜਾ ਸਕਦਾ ਹੈ। ਗਲਤੀਆਂ ਅਕਸਰ ਤੁਹਾਡੇ ਅਧਾਰਭੂਤ ਡਾਟਾ ਸੈੱਟ ਵਿੱਚ ਸਮਾਨ ਤੌਰ 'ਤੇ ਵੰਡੀਆਂ ਨਹੀਂ ਹੁੰਦੀਆਂ। ਤੁਸੀਂ 89% ਮਾਡਲ ਸਹੀਤਾ ਸਕੋਰ ਪ੍ਰਾਪਤ ਕਰ ਸਕਦੇ ਹੋ, ਪਰ ਪਤਾ ਲਗਾ ਸਕਦੇ ਹੋ ਕਿ ਤੁਹਾਡੇ ਡਾਟਾ ਦੇ ਵੱਖ-ਵੱਖ ਖੇਤਰਾਂ ਵਿੱਚ ਮਾਡਲ 42% ਸਮੇਂ ਫੇਲ੍ਹ ਹੋ ਰਿਹਾ ਹੈ। ਕੁਝ ਡਾਟਾ ਸਮੂਹਾਂ ਵਿੱਚ ਗਲਤੀ ਦੇ ਇਹ ਪੈਟਰਨ ਨਿਰਪੱਖਤਾ ਜਾਂ ਭਰੋਸੇਯੋਗਤਾ ਦੀ ਸਮੱਸਿਆ ਪੈਦਾ ਕਰ ਸਕਦੇ ਹਨ। ਇਹ ਸਮਝਣਾ ਜ਼ਰੂਰੀ ਹੈ ਕਿ ਮਾਡਲ ਕਿੱਥੇ ਚੰਗਾ ਕਰ ਰਿਹਾ ਹੈ ਜਾਂ ਨਹੀਂ। ਉਹ ਡਾਟਾ ਖੇਤਰ ਜਿੱਥੇ ਤੁਹਾਡੇ ਮਾਡਲ ਵਿੱਚ ਗਲਤੀਆਂ ਦੀ ਸੰਖਿਆ ਜ਼ਿਆਦਾ ਹੈ, ਇੱਕ ਮਹੱਤਵਪੂਰਨ ਡਾਟਾ ਜਾਤੀ ਹੋ ਸਕਦੀ ਹੈ।

![ਮਾਡਲ ਗਲਤੀਆਂ ਦਾ ਵਿਸ਼ਲੇਸ਼ਣ ਅਤੇ ਡੀਬੱਗ](../../../../9-Real-World/2-Debugging-ML-Models/images/ea-error-distribution.png)

RAI ਡੈਸ਼ਬੋਰਡ 'ਤੇ ਗਲਤੀ ਵਿਸ਼ਲੇਸ਼ਣ ਕੰਪੋਨੈਂਟ ਦਰਸਾਉਂਦਾ ਹੈ ਕਿ ਮਾਡਲ ਦੀ ਨਾਕਾਮੀ ਵੱਖ-ਵੱਖ ਸਮੂਹਾਂ ਵਿੱਚ ਕਿਵੇਂ ਵੰਡੀ ਗਈ ਹੈ। ਇਹ ਤੁਹਾਡੇ ਡਾਟਾ ਸੈੱਟ ਵਿੱਚ ਉੱਚ ਗਲਤੀ ਦਰ ਵਾਲੇ ਖੇਤਰਾਂ ਜਾਂ ਫੀਚਰਾਂ ਦੀ ਪਛਾਣ ਕਰਨ ਵਿੱਚ ਮਦਦਗਾਰ ਹੈ। ਜਿੱਥੇ ਮਾਡਲ ਦੀਆਂ ਜ਼ਿਆਦਾਤਰ ਗਲਤੀਆਂ ਆ ਰਹੀਆਂ ਹਨ, ਉਥੇ ਤੁਸੀਂ ਜੜ੍ਹੇ ਕਾਰਨ ਦੀ ਜਾਂਚ ਸ਼ੁਰੂ ਕਰ ਸਕਦੇ ਹੋ। ਤੁਸੀਂ ਡਾਟਾ ਸਮੂਹਾਂ ਬਣਾਉਣ ਲਈ ਵੀ ਵਿਸ਼ਲੇਸ਼ਣ ਕਰ ਸਕਦੇ ਹੋ। ਇਹ ਡਾਟਾ ਸਮੂਹ ਡੀਬੱਗਿੰਗ ਪ੍ਰਕਿਰਿਆ ਵਿੱਚ ਮਦਦ ਕਰਦੇ ਹਨ ਤਾਂ ਜੋ ਪਤਾ ਲਗਾਇਆ ਜਾ ਸਕੇ ਕਿ ਮਾਡਲ ਦਾ ਪ੍ਰਦਰਸ਼ਨ ਇੱਕ ਸਮੂਹ ਵਿੱਚ ਚੰਗਾ ਹੈ, ਪਰ ਦੂਜੇ ਵਿੱਚ ਗਲਤ ਹੈ।

![ਗਲਤੀ ਵਿਸ਼ਲੇਸ਼ਣ](../../../../9-Real-World/2-Debugging-ML-Models/images/ea-error-cohort.png)

ਟ੍ਰੀ ਮੈਪ 'ਤੇ ਦ੍ਰਿਸ਼ਮਾਨ ਸੰਕੇਤਕ ਸਮੱਸਿਆ ਵਾਲੇ ਖੇਤਰਾਂ ਨੂੰ ਤੇਜ਼ੀ ਨਾਲ ਪਛਾਣ ਕਰਨ ਵਿੱਚ ਮਦਦ ਕਰਦੇ ਹਨ। ਉਦਾਹਰਣ ਲਈ, ਜੇਕਰ ਟ੍ਰੀ ਨੋਡ ਦਾ ਰੰਗ ਗੂੜ੍ਹਾ ਲਾਲ ਹੈ, ਤਾਂ ਗਲਤੀ ਦਰ ਉੱਚੀ ਹੈ।

ਹੀਟ ਮੈਪ ਇੱਕ ਹੋਰ ਦ੍ਰਿਸ਼ਮਾਨ ਕਾਰਗੁਜ਼ਾਰੀ ਹੈ ਜੋ ਉਪਭੋਗਤਾਵਾਂ ਨੂੰ ਇੱਕ ਜਾਂ ਦੋ ਫੀਚਰਾਂ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਗਲਤੀ ਦਰ ਦੀ ਜਾਂਚ ਕਰਨ ਦੀ ਸਹੂਲਤ ਦਿੰਦੀ ਹੈ, ਤਾਂ ਜੋ ਪੂਰੇ ਡਾਟਾ ਸੈੱਟ ਜਾਂ ਸਮੂਹਾਂ ਵਿੱਚ ਮਾਡਲ ਗਲਤੀਆਂ ਦੇ ਯੋਗਦਾਨਕਰਤਾ ਦੀ ਪਛਾਣ ਕੀਤੀ ਜਾ ਸਕੇ।

![ਗਲਤੀ ਵਿਸ਼ਲੇਸ਼ਣ ਹੀਟਮੈਪ](../../../../9-Real-World/2-Debugging-ML-Models/images/ea-heatmap.png)

ਗਲਤੀ ਵਿਸ਼ਲੇਸ਼ਣ ਦੀ ਵਰਤੋਂ ਕਰੋ ਜਦੋਂ ਤੁਹਾਨੂੰ:

* ਸਮਝਣਾ ਹੋਵੇ ਕਿ ਮਾਡਲ ਦੀਆਂ ਨਾਕਾਮੀਆਂ ਕਿਵੇਂ ਡਾਟਾ ਸੈੱਟ ਅਤੇ ਕਈ ਇਨਪੁਟ ਅਤੇ ਫੀਚਰ ਮਾਪਦੰਡਾਂ ਵਿੱਚ ਵੰਡੀਆਂ ਗਈਆਂ ਹਨ।
* ਕੁੱਲ ਪ੍ਰਦਰਸ਼ਨ ਮਾਪਦੰਡਾਂ ਨੂੰ ਤੋੜ ਕੇ ਗਲਤ ਸਮੂਹਾਂ ਦੀ ਪਛਾਣ ਕਰੋ, ਤਾਂ ਜੋ ਤੁਹਾਡੇ ਨਿਸ਼ਾਨਾ ਬਣਾਉਣ ਵਾਲੇ ਰੋਕਥਾਮ ਕਦਮਾਂ ਨੂੰ ਜਾਣਕਾਰੀ ਪ੍ਰਦਾਨ ਕੀਤੀ ਜਾ ਸਕੇ।

## ਮਾਡਲ ਝਲਕ

ਮਸ਼ੀਨ ਲਰਨਿੰਗ ਮਾਡਲ ਦੇ ਪ੍ਰਦਰਸ਼ਨ ਦਾ ਮੁਲਾਂਕਣ ਕਰਨ ਲਈ ਇਸ ਦੇ ਵਿਹਾਰ ਦੀ ਸਮੁੱਚੀ ਸਮਝ ਪ੍ਰਾਪਤ ਕਰਨੀ ਪੈਂਦੀ ਹੈ। ਇਹ ਇੱਕ ਤੋਂ ਵੱਧ ਮਾਪਦੰਡਾਂ ਦੀ ਸਮੀਖਿਆ ਕਰਕੇ ਕੀਤਾ ਜਾ ਸਕਦਾ ਹੈ, ਜਿਵੇਂ ਕਿ ਗਲਤੀ ਦਰ, ਸਹੀਤਾ, ਰਿਕਾਲ, ਪ੍ਰਿਸੀਸ਼ਨ ਜਾਂ MAE (Mean Absolute Error)। ਇੱਕ ਮਾਪਦੰਡ ਚੰਗਾ ਲੱਗ ਸਕਦਾ ਹੈ, ਪਰ ਦੂਜੇ ਮਾਪਦੰਡ ਵਿੱਚ ਗਲਤੀਆਂ ਸਾਹਮਣੇ ਆ ਸਕਦੀਆਂ ਹਨ। ਇਸ ਤੋਂ ਇਲਾਵਾ, ਪੂਰੇ ਡਾਟਾ ਸੈੱਟ ਜਾਂ ਸਮੂਹਾਂ ਵਿੱਚ ਮਾਪਦੰਡਾਂ ਦੀ ਤੁਲਨਾ ਕਰਕੇ ਮਾਡਲ ਕਿੱਥੇ ਚੰਗਾ ਕਰ ਰਿਹਾ ਹੈ ਜਾਂ ਨਹੀਂ, ਇਸ ਬਾਰੇ ਰੋਸ਼ਨੀ ਪਾਈ ਜਾ ਸਕਦੀ ਹੈ। ਇਹ ਖਾਸ ਤੌਰ 'ਤੇ ਸੰਵੇਦਨਸ਼ੀਲ ਅਤੇ ਅਸੰਵੇਦਨਸ਼ੀਲ ਫੀਚਰਾਂ (ਜਿਵੇਂ ਕਿ ਮਰੀਜ਼ ਦੀ ਜਾਤੀ, ਲਿੰਗ ਜਾਂ ਉਮਰ) ਵਿੱਚ ਮਾਡਲ ਦੇ ਪ੍ਰਦਰਸ਼ਨ ਨੂੰ ਵੇਖਣ ਲਈ ਮਹੱਤਵਪੂਰਨ ਹੈ, ਤਾਂ ਜੋ ਮਾਡਲ ਵਿੱਚ ਸੰਭਾਵਿਤ ਨਿਰਪੱਖਤਾ ਦੀ ਪਛਾਣ ਕੀਤੀ ਜਾ ਸਕੇ। ਉਦਾਹਰਣ ਲਈ, ਜੇਕਰ ਪਤਾ ਲੱਗੇ ਕਿ ਮਾਡਲ ਸੰਵੇਦਨਸ਼ੀਲ ਫੀਚਰਾਂ ਵਾਲੇ ਸਮੂਹ ਵਿੱਚ ਜ਼ਿਆਦਾ ਗਲਤ ਹੈ, ਤਾਂ ਇਹ ਮਾਡਲ ਵਿੱਚ ਸੰਭਾਵਿਤ ਨਿਰਪੱਖਤਾ ਨੂੰ ਦਰਸਾ ਸਕਦਾ ਹੈ।

RAI ਡੈਸ਼ਬੋਰਡ ਦਾ ਮਾਡਲ ਝਲਕ ਕੰਪੋਨੈਂਟ ਸਿਰਫ਼ ਡਾਟਾ ਪ੍ਰਤੀਨਿਧਤਾ ਦੇ ਪ੍ਰਦਰਸ਼ਨ ਮਾਪਦੰਡਾਂ ਦੀ ਵਿਸ਼ਲੇਸ਼ਣ ਕਰਨ ਵਿੱਚ ਮਦਦ ਨਹੀਂ ਕਰਦਾ, ਬਲਕਿ ਇਹ ਉਪਭੋਗਤਾਵਾਂ ਨੂੰ ਵੱਖ-ਵੱਖ ਸਮੂਹਾਂ ਵਿੱਚ ਮਾਡਲ ਦੇ ਵਿਹਾਰ ਦੀ ਤੁਲਨਾ ਕਰਨ ਦੀ ਯੋਗਤਾ ਦਿੰਦਾ ਹੈ।

![ਡਾਟਾ ਸਮੂਹ - RAI ਡੈਸ਼ਬੋਰਡ ਵਿੱਚ ਮਾਡਲ ਝਲਕ](../../../../9-Real-World/2-Debugging-ML-Models/images/model-overview-dataset-cohorts.png)

ਕੰਪੋਨੈਂਟ ਦੀ ਫੀਚਰ-ਅਧਾਰਿਤ ਵਿਸ਼ਲੇਸ਼ਣ ਕਾਰਗੁਜ਼ਾਰੀ ਉਪਭੋਗਤਾਵਾਂ ਨੂੰ ਇੱਕ ਖਾਸ ਫੀਚਰ ਦੇ ਅੰਦਰ ਡਾਟਾ ਉਪ-ਸਮੂਹਾਂ ਨੂੰ ਸੰਕੁਚਿਤ ਕਰਨ ਦੀ ਯੋਗਤਾ ਦਿੰਦੀ ਹੈ, ਤਾਂ ਜੋ ਗ੍ਰੈਨੂਲਰ ਪੱਧਰ 'ਤੇ ਅਸਮਾਨਤਾਵਾਂ ਦੀ ਪਛਾਣ ਕੀਤੀ ਜਾ ਸਕੇ। ਉਦਾਹਰਣ ਲਈ, ਡੈਸ਼ਬੋਰਡ ਵਿੱਚ ਸਮਾਰਟ ਇੰਟੈਲੀਜੈਂਸ ਹੈ ਜੋ ਉਪਭੋਗਤਾ-ਚੁਣੇ ਫੀਚਰ ਲਈ ਆਪਣੇ ਆਪ ਸਮੂਹ ਬਣਾਉਂਦਾ ਹੈ (ਜਿਵੇਂ ਕਿ *"time_in_hospital < 3"* ਜਾਂ *"time_in_hospital >= 7"*)। ਇਹ ਉਪਭੋਗਤਾ ਨੂੰ ਵੱਡੇ ਡਾਟਾ ਸਮੂਹ ਤੋਂ ਇੱਕ ਖਾਸ ਫੀਚਰ ਨੂੰ ਅਲੱਗ ਕਰਨ ਦੀ ਯੋਗਤਾ ਦਿੰਦਾ ਹੈ, ਤਾਂ ਜੋ ਵੇਖਿਆ ਜਾ ਸਕੇ ਕਿ ਕੀ ਇਹ ਮਾਡਲ ਦੇ ਗਲਤ ਨਤੀਜਿਆਂ ਦਾ ਮੁੱਖ ਪ੍ਰਭਾਵਕ ਹੈ।

![ਫੀਚਰ ਸਮੂਹ - RAI ਡੈਸ਼ਬੋਰਡ ਵਿੱਚ ਮਾਡਲ ਝਲਕ](../../../../9-Real-World/2-Debugging-ML-Models/images/model-overview-feature-cohorts.png)

ਮਾਡਲ ਝਲਕ ਕੰਪੋਨੈਂਟ ਦੋ ਕਿਸਮਾਂ ਦੇ ਅਸਮਾਨਤਾ ਮਾਪਦੰਡਾਂ ਦਾ ਸਮਰਥਨ ਕਰਦਾ ਹੈ:

**ਮਾਡਲ ਪ੍ਰਦਰਸ਼ਨ ਵਿੱਚ ਅਸਮਾਨਤਾ**: ਇਹ ਮਾਪਦੰਡਾਂ ਡਾਟਾ ਦੇ ਉਪ-ਸਮੂਹਾਂ ਵਿੱਚ ਚੁਣੇ ਗਏ ਪ੍ਰਦਰਸ਼ਨ ਮਾਪਦੰਡ ਦੇ ਮੁੱਲਾਂ ਵਿੱਚ ਅਸਮਾਨਤਾ (ਫਰਕ) ਦੀ ਗਣਨਾ ਕਰਦੇ ਹਨ। ਕੁਝ ਉਦਾਹਰਣ:

* ਸਹੀਤਾ ਦਰ ਵਿੱਚ ਅਸਮਾਨਤਾ
* ਗਲਤੀ ਦਰ ਵਿੱਚ ਅਸਮਾਨਤਾ
* ਪ੍ਰਿਸੀਸ਼ਨ ਵਿੱਚ ਅਸਮਾਨਤਾ
* ਰਿਕਾਲ ਵਿੱਚ ਅਸਮਾਨਤਾ
* Mean Absolute Error (MAE) ਵਿੱਚ ਅਸਮਾਨਤਾ

**ਚੋਣ ਦਰ ਵਿੱਚ ਅਸਮਾਨਤਾ**: ਇਹ ਮਾਪਦੰਡ ਉਪ-ਸਮੂਹਾਂ ਵਿੱਚ ਚੋਣ ਦਰ (ਪਸੰਦੀਦਾ ਅਨੁਮਾਨ) ਵਿੱਚ ਫਰਕ ਨੂੰ ਸ਼ਾਮਲ ਕਰਦਾ ਹੈ। ਇਸ ਦਾ ਇੱਕ ਉਦਾਹਰਣ ਲੋਨ ਅਪ੍ਰੂਵਲ ਦਰ ਵਿੱਚ ਅਸਮਾਨਤਾ ਹੈ। ਚੋਣ ਦਰ ਦਾ ਮਤਲਬ ਹੈ ਕਿ ਹਰ ਵਰਗ ਵਿੱਚ ਡਾਟਾ ਪਾਇੰਟਾਂ ਦਾ ਅੰਸ਼ ਜੋ 1 ਵਜੋਂ ਵਰਗਬੱਧ ਕੀਤਾ ਗਿਆ ਹੈ (ਬਾਈਨਰੀ ਵਰਗਬੱਧਤਾ ਵਿੱਚ) ਜਾਂ ਅਨੁਮਾਨ ਮੁੱਲਾਂ ਦਾ ਵੰਡ (ਰੈਗਰੈਸ਼ਨ ਵਿੱਚ)।

## ਡਾਟਾ ਵਿਸ਼ਲੇਸ਼ਣ

> "ਜੇ ਤੁਸੀਂ ਡਾਟਾ ਨੂੰ ਕਾਫ਼ੀ ਲੰਮੇ ਸਮੇਂ ਤੱਕ ਪੀੜਤ ਕਰੋ, ਤਾਂ ਇਹ ਕੁਝ ਵੀ ਸਵੀਕਾਰ ਕਰ ਲਵੇਗਾ" - ਰੋਨਾਲਡ ਕੋਸ

ਇਹ ਬਿਆਨ ਕਾਫ਼ੀ ਅਤਿ-ਵਾਦੀ ਲੱਗਦਾ ਹੈ, ਪਰ ਇਹ ਸੱਚ ਹੈ ਕਿ ਡਾਟਾ ਨੂੰ ਕਿਸੇ ਵੀ ਨਤੀਜੇ ਦਾ ਸਮਰਥਨ ਕਰਨ ਲਈ ਹੇਰ-ਫੇਰ ਕੀਤਾ ਜਾ ਸਕਦਾ ਹੈ। ਅਜਿਹੀ ਹੇਰ-ਫੇਰ ਕਈ ਵਾਰ ਅਣਜਾਣੇ ਵਿੱਚ ਹੋ ਸਕਦੀ ਹੈ। ਇੱਕ ਮਨੁੱਖ ਵਜੋਂ, ਸਾਡੇ ਵਿੱਚ ਸਾਰਿਆਂ ਵਿੱਚ ਪੱਖਪਾਤ ਹੁੰਦਾ ਹੈ, ਅਤੇ ਅਕਸਰ ਇਹ ਜਾਣਨਾ ਮੁਸ਼ਕਲ ਹੁੰਦਾ ਹੈ ਕਿ ਤੁਸੀਂ ਡਾਟਾ ਵਿੱਚ ਪੱਖਪਾਤ ਕਦੋਂ ਸ਼ਾਮਲ ਕਰ ਰਹੇ ਹੋ। AI ਅਤੇ ਮਸ਼ੀਨ ਲਰਨਿੰਗ ਵਿੱਚ ਨਿਰਪੱਖਤਾ ਦੀ ਗਰੰਟੀ ਦੇਣਾ ਇੱਕ ਜਟਿਲ ਚੁਣੌਤੀ ਬਣੀ ਰਹੀ ਹੈ।

ਡਾਟਾ ਰਵਾਇਤੀ ਮਾਡਲ ਪ੍ਰਦਰਸ਼ਨ ਮਾਪਦੰਡਾਂ ਲਈ ਇੱਕ ਵੱਡਾ ਅੰਧਾ ਖੇਤਰ ਹੈ। ਤੁਹਾਡੇ ਕੋਲ ਉੱਚ ਸਹੀਤਾ ਸਕੋਰ ਹੋ ਸਕਦੇ ਹਨ, ਪਰ ਇਹ ਹਮੇਸ਼ਾ ਤੁਹਾਡੇ ਡਾਟਾ ਸੈੱਟ ਵਿੱਚ ਅਧਾਰਭੂਤ ਡਾਟਾ ਪੱਖਪਾਤ ਨੂੰ ਪ੍ਰਤੀਬਿੰਬਿਤ ਨਹੀਂ ਕਰਦੇ। ਉਦਾਹਰਣ ਲਈ, ਜੇਕਰ ਇੱਕ ਕੰਪਨੀ ਦੇ ਕਰਮਚਾਰੀਆਂ ਦੇ ਡਾਟਾ ਸੈੱਟ ਵਿੱਚ 27% ਔਰਤਾਂ ਕਾਰਜਕਾਰੀ ਪਦਾਂ 'ਤੇ ਹਨ ਅਤੇ 73% ਪੁਰਸ਼ ਉਸੇ ਪੱਧਰ 'ਤੇ ਹਨ, ਤਾਂ ਇਸ ਡਾਟਾ 'ਤੇ ਤਿਆਰ ਕੀਤਾ ਗਿਆ ਨੌਕਰੀ ਵਿਗਿਆਪਨ AI ਮਾਡਲ ਮੁੱਖ ਤੌਰ 'ਤੇ ਪੁਰਸ਼ ਦਰਸ਼ਕਾਂ ਨੂੰ ਉੱਚ ਪੱਧਰ ਦੀਆਂ ਨੌਕਰੀਆਂ ਲਈ ਟਾਰਗਟ ਕਰ ਸਕਦਾ ਹੈ। ਇਸ ਡਾਟਾ ਵਿੱਚ ਇਹ ਅਸਮਾਨਤਾ ਮਾਡਲ ਦੇ ਅਨੁਮਾਨ ਨੂੰ ਇੱਕ ਲਿੰਗ ਨੂੰ ਵਧੇਰੇ ਤਰਜੀਹ ਦੇਣ ਲਈ ਝੁਕਾ ਦਿੰਦੀ ਹੈ। ਇਹ ਨਿਰਪੱਖਤਾ ਦੀ ਸਮੱਸਿਆ ਨੂੰ ਦਰਸਾਉਂਦਾ ਹੈ ਜਿੱਥੇ AI ਮਾਡਲ ਵਿੱਚ ਲਿੰਗ ਪੱਖਪਾਤ ਹੈ।

RAI ਡੈਸ਼ਬੋਰਡ 'ਤੇ ਡਾਟਾ ਵਿਸ਼ਲੇਸ਼ਣ ਕੰਪੋਨੈਂਟ ਉਹ ਖੇਤਰਾਂ ਦੀ ਪਛਾਣ ਕਰਨ ਵਿੱਚ ਮਦਦ ਕਰਦਾ ਹੈ ਜਿੱਥੇ ਡਾਟਾ ਸੈੱਟ ਵਿੱਚ ਵਧੇਰੇ ਜਾਂ ਘੱਟ ਪ੍ਰਤੀਨਿਧਤਾ ਹੈ। ਇਹ ਉਪਭੋਗਤਾਵਾਂ ਨੂੰ ਡ
- **ਜਿਆਦਾ ਜਾਂ ਘੱਟ ਪ੍ਰਤੀਨਿਧਤਾ**। ਇਹ ਵਿਚਾਰ ਹੈ ਕਿ ਕੁਝ ਸਮੂਹ ਕਿਸੇ ਖਾਸ ਪੇਸ਼ੇ ਵਿੱਚ ਨਹੀਂ ਦਿਖਾਈ ਦਿੰਦੇ, ਅਤੇ ਕੋਈ ਵੀ ਸੇਵਾ ਜਾਂ ਫੰਕਸ਼ਨ ਜੋ ਇਸਨੂੰ ਵਧਾਉਂਦਾ ਹੈ, ਉਹ ਨੁਕਸਾਨ ਪਹੁੰਚਾਉਣ ਵਿੱਚ ਯੋਗਦਾਨ ਪਾਉਂਦਾ ਹੈ।

### Azure RAI ਡੈਸ਼ਬੋਰਡ

[Azure RAI ਡੈਸ਼ਬੋਰਡ](https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai-dashboard?WT.mc_id=aiml-90525-ruyakubu) ਖੁੱਲ੍ਹੇ-ਸਰੋਤ ਟੂਲਾਂ 'ਤੇ ਅਧਾਰਿਤ ਹੈ ਜੋ ਪ੍ਰਮੁੱਖ ਅਕਾਦਮਿਕ ਸੰਸਥਾਵਾਂ ਅਤੇ ਸੰਗਠਨਾਂ ਦੁਆਰਾ ਵਿਕਸਿਤ ਕੀਤੇ ਗਏ ਹਨ, ਜਿਨ੍ਹਾਂ ਵਿੱਚ Microsoft ਸ਼ਾਮਲ ਹੈ। ਇਹ ਡਾਟਾ ਸਾਇੰਟਿਸਟਾਂ ਅਤੇ AI ਡਿਵੈਲਪਰਾਂ ਨੂੰ ਮਾਡਲ ਦੇ ਵਿਹਾਰ ਨੂੰ ਬਿਹਤਰ ਸਮਝਣ, ਅਤੇ AI ਮਾਡਲਾਂ ਵਿੱਚੋਂ ਅਣਚਾਹੇ ਮੁੱਦਿਆਂ ਦੀ ਪਛਾਣ ਅਤੇ ਨਿਬਾਰਨ ਕਰਨ ਵਿੱਚ ਮਦਦ ਕਰਦੇ ਹਨ।

- RAI ਡੈਸ਼ਬੋਰਡ ਦੇ ਵੱਖ-ਵੱਖ ਹਿੱਸਿਆਂ ਨੂੰ ਵਰਤਣ ਦਾ ਤਰੀਕਾ ਸਿੱਖਣ ਲਈ [ਡੌਕਸ](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-responsible-ai-dashboard?WT.mc_id=aiml-90525-ruyakubu) ਦੇਖੋ।

- Azure Machine Learning ਵਿੱਚ ਜ਼ਿਆਦਾ ਜ਼ਿੰਮੇਵਾਰ AI ਸਥਿਤੀਆਂ ਨੂੰ ਡਿਬੱਗ ਕਰਨ ਲਈ ਕੁਝ RAI ਡੈਸ਼ਬੋਰਡ [ਨਮੂਨਾ ਨੋਟਬੁੱਕਾਂ](https://github.com/Azure/RAI-vNext-Preview/tree/main/examples/notebooks) ਦੇਖੋ।

---
## 🚀 ਚੁਣੌਤੀ

ਸੰਭਾਵਿਤ ਅੰਕੜਿਆਂ ਜਾਂ ਡਾਟਾ ਪੱਖਪਾਤ ਨੂੰ ਪਹਿਲੇ ਹੀ ਰੋਕਣ ਲਈ, ਸਾਨੂੰ:

- ਸਿਸਟਮਾਂ 'ਤੇ ਕੰਮ ਕਰਨ ਵਾਲੇ ਲੋਕਾਂ ਵਿੱਚ ਪਿਛੋਕੜ ਅਤੇ ਨਜ਼ਰੀਏ ਦੀ ਵਿਵਿਧਤਾ ਹੋਣੀ ਚਾਹੀਦੀ ਹੈ।
- ਅਜਿਹੇ ਡਾਟਾਸੈਟਾਂ ਵਿੱਚ ਨਿਵੇਸ਼ ਕਰਨਾ ਚਾਹੀਦਾ ਹੈ ਜੋ ਸਾਡੇ ਸਮਾਜ ਦੀ ਵਿਵਿਧਤਾ ਨੂੰ ਦਰਸਾਉਂਦੇ ਹਨ।
- ਪੱਖਪਾਤ ਦੀ ਪਛਾਣ ਅਤੇ ਠੀਕ ਕਰਨ ਦੇ ਬਿਹਤਰ ਤਰੀਕੇ ਵਿਕਸਿਤ ਕਰਨੇ ਚਾਹੀਦੇ ਹਨ ਜਦੋਂ ਇਹ ਵਾਪਰਦਾ ਹੈ।

ਅਸਲੀ ਜ਼ਿੰਦਗੀ ਦੇ ਸਥਿਤੀਆਂ ਬਾਰੇ ਸੋਚੋ ਜਿੱਥੇ ਮਾਡਲ-ਬਿਲਡਿੰਗ ਅਤੇ ਵਰਤੋਂ ਵਿੱਚ ਅਨਿਆਇਤਾ ਸਪਸ਼ਟ ਹੈ। ਹੋਰ ਕੀ ਵਿਚਾਰ ਕਰਨਾ ਚਾਹੀਦਾ ਹੈ?

## [ਪੋਸਟ-ਲੈਕਚਰ ਕਵਿਜ਼](https://ff-quizzes.netlify.app/en/ml/)
## ਸਮੀਖਿਆ ਅਤੇ ਸਵੈ-ਅਧਿਐਨ

ਇਸ ਪਾਠ ਵਿੱਚ, ਤੁਸੀਂ ਮਸ਼ੀਨ ਲਰਨਿੰਗ ਵਿੱਚ ਜ਼ਿੰਮੇਵਾਰ AI ਨੂੰ ਸ਼ਾਮਲ ਕਰਨ ਦੇ ਕੁਝ ਵਿਆਵਹਾਰਿਕ ਟੂਲ ਸਿੱਖੇ ਹਨ।

ਇਹ ਵਰਕਸ਼ਾਪ ਦੇਖੋ ਤਾਂ ਜੋ ਵਿਸ਼ਿਆਂ ਵਿੱਚ ਹੋਰ ਡੂੰਘਾਈ ਨਾਲ ਜਾ ਸਕੋ:

- ਜ਼ਿੰਮੇਵਾਰ AI ਡੈਸ਼ਬੋਰਡ: ਅਮਲ ਵਿੱਚ RAI ਨੂੰ ਚਲਾਉਣ ਲਈ ਇੱਕ-ਸਟਾਪ ਦੁਕਾਨ, ਬੇਸਮੀਰਾ ਨੂਸ਼ੀ ਅਤੇ ਮਹਰਨੂਸ਼ ਸਾਮੇਕੀ ਦੁਆਰਾ

[![ਜ਼ਿੰਮੇਵਾਰ AI ਡੈਸ਼ਬੋਰਡ: ਅਮਲ ਵਿੱਚ RAI ਨੂੰ ਚਲਾਉਣ ਲਈ ਇੱਕ-ਸਟਾਪ ਦੁਕਾਨ](https://img.youtube.com/vi/f1oaDNl3djg/0.jpg)](https://www.youtube.com/watch?v=f1oaDNl3djg "ਜ਼ਿੰਮੇਵਾਰ AI ਡੈਸ਼ਬੋਰਡ: ਅਮਲ ਵਿੱਚ RAI ਨੂੰ ਚਲਾਉਣ ਲਈ ਇੱਕ-ਸਟਾਪ ਦੁਕਾਨ")

> 🎥 ਉਪਰੋਕਤ ਚਿੱਤਰ 'ਤੇ ਕਲਿਕ ਕਰੋ ਇੱਕ ਵੀਡੀਓ ਲਈ: ਜ਼ਿੰਮੇਵਾਰ AI ਡੈਸ਼ਬੋਰਡ: ਅਮਲ ਵਿੱਚ RAI ਨੂੰ ਚਲਾਉਣ ਲਈ ਇੱਕ-ਸਟਾਪ ਦੁਕਾਨ, ਬੇਸਮੀਰਾ ਨੂਸ਼ੀ ਅਤੇ ਮਹਰਨੂਸ਼ ਸਾਮੇਕੀ ਦੁਆਰਾ

ਜ਼ਿੰਮੇਵਾਰ AI ਬਾਰੇ ਹੋਰ ਸਿੱਖਣ ਅਤੇ ਹੋਰ ਭਰੋਸੇਯੋਗ ਮਾਡਲ ਬਣਾਉਣ ਲਈ ਹਵਾਲੇ ਦੇ ਸਮੱਗਰੀ ਨੂੰ ਦੇਖੋ:

- ML ਮਾਡਲਾਂ ਨੂੰ ਡਿਬੱਗ ਕਰਨ ਲਈ Microsoft ਦੇ RAI ਡੈਸ਼ਬੋਰਡ ਟੂਲ: [ਜ਼ਿੰਮੇਵਾਰ AI ਟੂਲਾਂ ਦੇ ਸਰੋਤ](https://aka.ms/rai-dashboard)

- ਜ਼ਿੰਮੇਵਾਰ AI ਟੂਲਕਿਟ ਦੀ ਖੋਜ ਕਰੋ: [Github](https://github.com/microsoft/responsible-ai-toolbox)

- Microsoft ਦਾ RAI ਸਰੋਤ ਕੇਂਦਰ: [ਜ਼ਿੰਮੇਵਾਰ AI ਸਰੋਤ – Microsoft AI](https://www.microsoft.com/ai/responsible-ai-resources?activetab=pivot1%3aprimaryr4)

- Microsoft ਦਾ FATE ਰਿਸਰਚ ਗਰੁੱਪ: [FATE: ਨਿਆਂ, ਜਵਾਬਦੇਹੀ, ਪਾਰਦਰਸ਼ਤਾ, ਅਤੇ AI ਵਿੱਚ ਨੈਤਿਕਤਾ - Microsoft Research](https://www.microsoft.com/research/theme/fate/)

## ਅਸਾਈਨਮੈਂਟ

[RAI ਡੈਸ਼ਬੋਰਡ ਦੀ ਖੋਜ ਕਰੋ](assignment.md)

---

**ਅਸਵੀਕਤੀ**:  
ਇਹ ਦਸਤਾਵੇਜ਼ AI ਅਨੁਵਾਦ ਸੇਵਾ [Co-op Translator](https://github.com/Azure/co-op-translator) ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਅਨੁਵਾਦ ਕੀਤਾ ਗਿਆ ਹੈ। ਜਦੋਂ ਕਿ ਅਸੀਂ ਸਹੀਤਾ ਲਈ ਯਤਨਸ਼ੀਲ ਹਾਂ, ਕਿਰਪਾ ਕਰਕੇ ਧਿਆਨ ਦਿਓ ਕਿ ਸਵੈਚਾਲਿਤ ਅਨੁਵਾਦਾਂ ਵਿੱਚ ਗਲਤੀਆਂ ਜਾਂ ਅਸੁਚਨਾਵਾਂ ਹੋ ਸਕਦੀਆਂ ਹਨ। ਮੂਲ ਦਸਤਾਵੇਜ਼ ਨੂੰ ਇਸਦੀ ਮੂਲ ਭਾਸ਼ਾ ਵਿੱਚ ਅਧਿਕਾਰਤ ਸਰੋਤ ਮੰਨਿਆ ਜਾਣਾ ਚਾਹੀਦਾ ਹੈ। ਮਹੱਤਵਪੂਰਨ ਜਾਣਕਾਰੀ ਲਈ, ਪੇਸ਼ੇਵਰ ਮਨੁੱਖੀ ਅਨੁਵਾਦ ਦੀ ਸਿਫਾਰਸ਼ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਇਸ ਅਨੁਵਾਦ ਦੀ ਵਰਤੋਂ ਤੋਂ ਪੈਦਾ ਹੋਣ ਵਾਲੇ ਕਿਸੇ ਵੀ ਗਲਤਫਹਿਮੀ ਜਾਂ ਗਲਤ ਵਿਆਖਿਆ ਲਈ ਅਸੀਂ ਜ਼ਿੰਮੇਵਾਰ ਨਹੀਂ ਹਾਂ।