<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6534e145d52a3890590d27be75386e5d",
  "translation_date": "2025-09-03T18:47:04+00:00",
  "source_file": "6-NLP/2-Tasks/README.md",
  "language_code": "pl"
}
-->
# Typowe zadania i techniki przetwarzania jÄ™zyka naturalnego

W wiÄ™kszoÅ›ci zadaÅ„ zwiÄ…zanych z *przetwarzaniem jÄ™zyka naturalnego* tekst, ktÃ³ry ma byÄ‡ przetworzony, musi zostaÄ‡ podzielony, przeanalizowany, a wyniki zapisane lub porÃ³wnane z reguÅ‚ami i zestawami danych. Te zadania pozwalajÄ… programiÅ›cie wyciÄ…gnÄ…Ä‡ _znaczenie_, _intencjÄ™_ lub jedynie _czÄ™stotliwoÅ›Ä‡_ wystÄ™powania terminÃ³w i sÅ‚Ã³w w tekÅ›cie.

## [Quiz przed wykÅ‚adem](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/33/)

Poznajmy typowe techniki stosowane w przetwarzaniu tekstu. W poÅ‚Ä…czeniu z uczeniem maszynowym techniki te pomagajÄ… efektywnie analizowaÄ‡ duÅ¼e iloÅ›ci tekstu. Zanim jednak zastosujemy ML do tych zadaÅ„, zrozummy problemy, z ktÃ³rymi mierzy siÄ™ specjalista NLP.

## Typowe zadania w NLP

Istnieje wiele sposobÃ³w analizy tekstu, nad ktÃ³rym pracujesz. SÄ… zadania, ktÃ³re moÅ¼esz wykonaÄ‡, a dziÄ™ki nim moÅ¼esz zrozumieÄ‡ tekst i wyciÄ…gnÄ…Ä‡ wnioski. Zazwyczaj wykonujesz te zadania w okreÅ›lonej kolejnoÅ›ci.

### Tokenizacja

Prawdopodobnie pierwszym krokiem wiÄ™kszoÅ›ci algorytmÃ³w NLP jest podzielenie tekstu na tokeny, czyli sÅ‚owa. ChoÄ‡ brzmi to prosto, uwzglÄ™dnienie interpunkcji oraz rÃ³Å¼nych jÄ™zykowych granic sÅ‚Ã³w i zdaÅ„ moÅ¼e byÄ‡ trudne. MoÅ¼esz potrzebowaÄ‡ rÃ³Å¼nych metod, aby okreÅ›liÄ‡ podziaÅ‚y.

![tokenizacja](../../../../translated_images/tokenization.1641a160c66cd2d93d4524e8114e93158a9ce0eba3ecf117bae318e8a6ad3487.pl.png)
> Tokenizacja zdania z **Dumy i uprzedzenia**. Infografika autorstwa [Jen Looper](https://twitter.com/jenlooper)

### Osadzenia (Embeddings)

[Osadzenia sÅ‚Ã³w](https://wikipedia.org/wiki/Word_embedding) to sposÃ³b na numeryczne przeksztaÅ‚cenie danych tekstowych. Osadzenia sÄ… tworzone w taki sposÃ³b, aby sÅ‚owa o podobnym znaczeniu lub uÅ¼ywane razem grupowaÅ‚y siÄ™ w klastrach.

![osadzenia sÅ‚Ã³w](../../../../translated_images/embedding.2cf8953c4b3101d188c2f61a5de5b6f53caaa5ad4ed99236d42bc3b6bd6a1fe2.pl.png)
> "Mam najwyÅ¼szy szacunek dla twoich nerwÃ³w, sÄ… moimi starymi przyjaciÃ³Å‚mi." - Osadzenia sÅ‚Ã³w dla zdania z **Dumy i uprzedzenia**. Infografika autorstwa [Jen Looper](https://twitter.com/jenlooper)

âœ… WyprÃ³buj [to interesujÄ…ce narzÄ™dzie](https://projector.tensorflow.org/), aby eksperymentowaÄ‡ z osadzeniami sÅ‚Ã³w. KlikniÄ™cie na jedno sÅ‚owo pokazuje klastry podobnych sÅ‚Ã³w: 'zabawka' grupuje siÄ™ z 'disney', 'lego', 'playstation' i 'konsola'.

### Parsowanie i Tagowanie CzÄ™Å›ci Mowy

KaÅ¼de sÅ‚owo, ktÃ³re zostaÅ‚o podzielone na tokeny, moÅ¼e byÄ‡ oznaczone jako czÄ™Å›Ä‡ mowy - rzeczownik, czasownik lub przymiotnik. Zdanie `szybki czerwony lis przeskoczyÅ‚ nad leniwym brÄ…zowym psem` moÅ¼e byÄ‡ oznaczone jako lis = rzeczownik, przeskoczyÅ‚ = czasownik.

![parsowanie](../../../../translated_images/parse.d0c5bbe1106eae8fe7d60a183cd1736c8b6cec907f38000366535f84f3036101.pl.png)

> Parsowanie zdania z **Dumy i uprzedzenia**. Infografika autorstwa [Jen Looper](https://twitter.com/jenlooper)

Parsowanie polega na rozpoznawaniu, ktÃ³re sÅ‚owa sÄ… ze sobÄ… powiÄ…zane w zdaniu - na przykÅ‚ad `szybki czerwony lis przeskoczyÅ‚` to sekwencja przymiotnik-rzeczownik-czasownik, ktÃ³ra jest oddzielna od sekwencji `leniwy brÄ…zowy pies`.

### CzÄ™stotliwoÅ›Ä‡ sÅ‚Ã³w i fraz

Przydatnym procesem podczas analizy duÅ¼ej iloÅ›ci tekstu jest stworzenie sÅ‚ownika wszystkich interesujÄ…cych sÅ‚Ã³w lub fraz oraz czÄ™stotliwoÅ›ci ich wystÄ™powania. Fraza `szybki czerwony lis przeskoczyÅ‚ nad leniwym brÄ…zowym psem` ma czÄ™stotliwoÅ›Ä‡ wystÄ™powania sÅ‚owa "the" rÃ³wnÄ… 2.

Przyjrzyjmy siÄ™ przykÅ‚adowemu tekstowi, w ktÃ³rym liczymy czÄ™stotliwoÅ›Ä‡ sÅ‚Ã³w. Wiersz Rudyard Kiplinga "The Winners" zawiera nastÄ™pujÄ…cy fragment:

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

PoniewaÅ¼ czÄ™stotliwoÅ›Ä‡ fraz moÅ¼e byÄ‡ rozrÃ³Å¼niana na wielkoÅ›Ä‡ liter, fraza `a friend` wystÄ™puje 2 razy, `the` wystÄ™puje 6 razy, a `travels` wystÄ™puje 2 razy.

### N-gramy

Tekst moÅ¼na podzieliÄ‡ na sekwencje sÅ‚Ã³w o okreÅ›lonej dÅ‚ugoÅ›ci: jedno sÅ‚owo (unigram), dwa sÅ‚owa (bigramy), trzy sÅ‚owa (trigramy) lub dowolnÄ… liczbÄ™ sÅ‚Ã³w (n-gramy).

Na przykÅ‚ad `szybki czerwony lis przeskoczyÅ‚ nad leniwym brÄ…zowym psem` z wartoÅ›ciÄ… n-gramu rÃ³wnÄ… 2 daje nastÄ™pujÄ…ce n-gramy:

1. szybki czerwony  
2. czerwony lis  
3. lis przeskoczyÅ‚  
4. przeskoczyÅ‚ nad  
5. nad leniwym  
6. leniwy brÄ…zowy  
7. brÄ…zowy pies  

MoÅ¼na to Å‚atwiej zobrazowaÄ‡ jako przesuwajÄ…ce siÄ™ okno nad zdaniem. Oto przykÅ‚ad dla n-gramÃ³w o dÅ‚ugoÅ›ci 3 sÅ‚Ã³w, gdzie n-gram jest pogrubiony w kaÅ¼dym zdaniu:

1.   <u>**szybki czerwony lis**</u> przeskoczyÅ‚ nad leniwym brÄ…zowym psem  
2.   szybki **<u>czerwony lis przeskoczyÅ‚</u>** nad leniwym brÄ…zowym psem  
3.   szybki czerwony **<u>lis przeskoczyÅ‚ nad</u>** leniwym brÄ…zowym psem  
4.   szybki czerwony lis **<u>przeskoczyÅ‚ nad leniwym</u>** brÄ…zowym psem  
5.   szybki czerwony lis przeskoczyÅ‚ **<u>nad leniwym brÄ…zowym</u>** psem  
6.   szybki czerwony lis przeskoczyÅ‚ nad **<u>leniwym brÄ…zowym psem</u>**

![przesuwajÄ…ce siÄ™ okno n-gramÃ³w](../../../../6-NLP/2-Tasks/images/n-grams.gif)

> WartoÅ›Ä‡ n-gramu 3: Infografika autorstwa [Jen Looper](https://twitter.com/jenlooper)

### Ekstrakcja fraz rzeczownikowych

W wiÄ™kszoÅ›ci zdaÅ„ znajduje siÄ™ rzeczownik, ktÃ³ry jest podmiotem lub dopeÅ‚nieniem zdania. W jÄ™zyku angielskim czÄ™sto moÅ¼na go zidentyfikowaÄ‡ jako poprzedzony przez 'a', 'an' lub 'the'. Identyfikacja podmiotu lub dopeÅ‚nienia zdania poprzez 'ekstrakcjÄ™ frazy rzeczownikowej' jest czÄ™stym zadaniem w NLP, gdy prÃ³buje siÄ™ zrozumieÄ‡ znaczenie zdania.

âœ… W zdaniu "Nie mogÄ™ ustaliÄ‡ godziny, miejsca, wyglÄ…du ani sÅ‚Ã³w, ktÃ³re poÅ‚oÅ¼yÅ‚y fundament. To byÅ‚o zbyt dawno temu. ByÅ‚em w Å›rodku, zanim zdaÅ‚em sobie sprawÄ™, Å¼e zaczÄ…Å‚em." Czy potrafisz zidentyfikowaÄ‡ frazy rzeczownikowe?

W zdaniu `szybki czerwony lis przeskoczyÅ‚ nad leniwym brÄ…zowym psem` znajdujÄ… siÄ™ 2 frazy rzeczownikowe: **szybki czerwony lis** i **leniwy brÄ…zowy pies**.

### Analiza sentymentu

Zdanie lub tekst moÅ¼na przeanalizowaÄ‡ pod kÄ…tem sentymentu, czyli tego, jak *pozytywny* lub *negatywny* jest. Sentyment jest mierzony w *polaryzacji* oraz *obiektywnoÅ›ci/subiektywnoÅ›ci*. Polaryzacja jest mierzona od -1.0 do 1.0 (negatywna do pozytywnej) oraz od 0.0 do 1.0 (najbardziej obiektywna do najbardziej subiektywnej).

âœ… PÃ³Åºniej dowiesz siÄ™, Å¼e istniejÄ… rÃ³Å¼ne sposoby okreÅ›lania sentymentu za pomocÄ… uczenia maszynowego, ale jednym ze sposobÃ³w jest posiadanie listy sÅ‚Ã³w i fraz, ktÃ³re sÄ… kategoryzowane jako pozytywne lub negatywne przez eksperta i zastosowanie tego modelu do tekstu w celu obliczenia wyniku polaryzacji. Czy widzisz, jak to mogÅ‚oby dziaÅ‚aÄ‡ w niektÃ³rych okolicznoÅ›ciach, a w innych mniej?

### Odmiana

Odmiana pozwala na uzyskanie liczby pojedynczej lub mnogiej danego sÅ‚owa.

### Lematyzacja

*Lematyzacja* to proces sprowadzania sÅ‚owa do jego podstawowej formy, na przykÅ‚ad *poleciaÅ‚*, *lata*, *latanie* majÄ… lemat czasownika *lataÄ‡*.

DostÄ™pne sÄ… rÃ³wnieÅ¼ przydatne bazy danych dla badaczy NLP, w tym:

### WordNet

[WordNet](https://wordnet.princeton.edu/) to baza danych sÅ‚Ã³w, synonimÃ³w, antonimÃ³w i wielu innych szczegÃ³Å‚Ã³w dla kaÅ¼dego sÅ‚owa w wielu rÃ³Å¼nych jÄ™zykach. Jest niezwykle przydatna przy tworzeniu tÅ‚umaczeÅ„, korektorÃ³w pisowni lub narzÄ™dzi jÄ™zykowych kaÅ¼dego rodzaju.

## Biblioteki NLP

Na szczÄ™Å›cie nie musisz samodzielnie budowaÄ‡ wszystkich tych technik, poniewaÅ¼ dostÄ™pne sÄ… doskonaÅ‚e biblioteki Python, ktÃ³re sprawiajÄ…, Å¼e NLP jest znacznie bardziej dostÄ™pne dla programistÃ³w, ktÃ³rzy nie specjalizujÄ… siÄ™ w przetwarzaniu jÄ™zyka naturalnego ani uczeniu maszynowym. W kolejnych lekcjach znajdziesz wiÄ™cej przykÅ‚adÃ³w, ale tutaj poznasz kilka przydatnych przykÅ‚adÃ³w, ktÃ³re pomogÄ… Ci w nastÄ™pnym zadaniu.

### Ä†wiczenie - korzystanie z biblioteki `TextBlob`

UÅ¼yjmy biblioteki TextBlob, poniewaÅ¼ zawiera ona pomocne API do radzenia sobie z tego typu zadaniami. TextBlob "opiera siÄ™ na potÄ™Å¼nych fundamentach [NLTK](https://nltk.org) i [pattern](https://github.com/clips/pattern), i dobrze wspÃ³Å‚pracuje z obiema."

> Uwaga: Przydatny [Przewodnik Szybkiego Startu](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart) jest dostÄ™pny dla TextBlob i jest zalecany dla doÅ›wiadczonych programistÃ³w Python.

Podczas prÃ³by identyfikacji *frazy rzeczownikowej* TextBlob oferuje kilka opcji ekstraktorÃ³w do znajdowania fraz rzeczownikowych.

1. Przyjrzyj siÄ™ `ConllExtractor`.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > Co tu siÄ™ dzieje? [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) to "Ekstraktor fraz rzeczownikowych, ktÃ³ry wykorzystuje parsowanie chunkÃ³w wytrenowane na korpusie treningowym ConLL-2000." ConLL-2000 odnosi siÄ™ do Konferencji na temat Uczenia Naturalnego JÄ™zyka z 2000 roku. KaÅ¼dego roku konferencja organizowaÅ‚a warsztaty, aby rozwiÄ…zaÄ‡ trudny problem NLP, a w 2000 roku byÅ‚ to chunking fraz rzeczownikowych. Model zostaÅ‚ wytrenowany na Wall Street Journal, z "sekcjami 15-18 jako danymi treningowymi (211727 tokenÃ³w) i sekcjÄ… 20 jako danymi testowymi (47377 tokenÃ³w)". MoÅ¼esz zapoznaÄ‡ siÄ™ z procedurami uÅ¼ytymi [tutaj](https://www.clips.uantwerpen.be/conll2000/chunking/) oraz z [wynikami](https://ifarm.nl/erikt/research/np-chunking.html).

### Wyzwanie - ulepszanie swojego bota za pomocÄ… NLP

W poprzedniej lekcji stworzyÅ‚eÅ› bardzo prostego bota Q&A. Teraz sprawisz, Å¼e Marvin bÄ™dzie trochÄ™ bardziej empatyczny, analizujÄ…c Twoje dane wejÅ›ciowe pod kÄ…tem sentymentu i drukujÄ…c odpowiedÅº pasujÄ…cÄ… do sentymentu. Musisz rÃ³wnieÅ¼ zidentyfikowaÄ‡ `frazy rzeczownikowe` i zapytaÄ‡ o nie.

Twoje kroki przy budowaniu lepszego bota konwersacyjnego:

1. Wydrukuj instrukcje informujÄ…ce uÅ¼ytkownika, jak wchodziÄ‡ w interakcjÄ™ z botem  
2. Rozpocznij pÄ™tlÄ™  
   1. Przyjmij dane wejÅ›ciowe od uÅ¼ytkownika  
   2. JeÅ›li uÅ¼ytkownik poprosi o zakoÅ„czenie, zakoÅ„cz  
   3. PrzetwÃ³rz dane wejÅ›ciowe uÅ¼ytkownika i okreÅ›l odpowiedniÄ… odpowiedÅº na podstawie sentymentu  
   4. JeÅ›li w sentymencie zostanie wykryta fraza rzeczownikowa, zmieÅ„ jej liczbÄ™ na mnogÄ… i poproÅ› o wiÄ™cej danych na ten temat  
   5. Wydrukuj odpowiedÅº  
3. WrÃ³Ä‡ do kroku 2  

Oto fragment kodu do okreÅ›lania sentymentu za pomocÄ… TextBlob. ZauwaÅ¼, Å¼e istniejÄ… tylko cztery *gradienty* odpowiedzi na sentyment (moÅ¼esz mieÄ‡ wiÄ™cej, jeÅ›li chcesz):

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

Oto przykÅ‚adowy wynik, ktÃ³ry moÅ¼e CiÄ™ poprowadziÄ‡ (dane wejÅ›ciowe uÅ¼ytkownika sÄ… na liniach zaczynajÄ…cych siÄ™ od >):

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

Jedno z moÅ¼liwych rozwiÄ…zaÅ„ zadania znajduje siÄ™ [tutaj](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/2-Tasks/solution/bot.py)

âœ… SprawdÅº swojÄ… wiedzÄ™

1. Czy uwaÅ¼asz, Å¼e empatyczne odpowiedzi mogÅ‚yby 'oszukaÄ‡' kogoÅ›, aby uwierzyÅ‚, Å¼e bot faktycznie go rozumie?  
2. Czy identyfikacja frazy rzeczownikowej sprawia, Å¼e bot jest bardziej 'wiarygodny'?  
3. Dlaczego ekstrakcja 'frazy rzeczownikowej' ze zdania jest przydatna?

---

Zaimplementuj bota z poprzedniego sprawdzania wiedzy i przetestuj go na znajomym. Czy potrafi ich oszukaÄ‡? Czy moÅ¼esz sprawiÄ‡, Å¼e TwÃ³j bot bÄ™dzie bardziej 'wiarygodny'?

## ğŸš€Wyzwanie

Wykonaj zadanie z poprzedniego sprawdzania wiedzy i sprÃ³buj je zaimplementowaÄ‡. Przetestuj bota na znajomym. Czy potrafi ich oszukaÄ‡? Czy moÅ¼esz sprawiÄ‡, Å¼e TwÃ³j bot bÄ™dzie bardziej 'wiarygodny'?

## [Quiz po wykÅ‚adzie](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/34/)

## PrzeglÄ…d i samodzielna nauka

W kolejnych lekcjach dowiesz siÄ™ wiÄ™cej o analizie sentymentu. Zbadaj tÄ™ interesujÄ…cÄ… technikÄ™ w artykuÅ‚ach takich jak te na [KDNuggets](https://www.kdnuggets.com/tag/nlp)

## Zadanie 

[Spraw, aby bot odpowiadaÅ‚](assignment.md)

---

**ZastrzeÅ¼enie**:  
Ten dokument zostaÅ‚ przetÅ‚umaczony za pomocÄ… usÅ‚ugi tÅ‚umaczeniowej AI [Co-op Translator](https://github.com/Azure/co-op-translator). ChociaÅ¼ dokÅ‚adamy wszelkich staraÅ„, aby tÅ‚umaczenie byÅ‚o precyzyjne, prosimy pamiÄ™taÄ‡, Å¼e automatyczne tÅ‚umaczenia mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jego rodzimym jÄ™zyku powinien byÄ‡ uznawany za wiarygodne ÅºrÃ³dÅ‚o. W przypadku informacji o kluczowym znaczeniu zaleca siÄ™ skorzystanie z profesjonalnego tÅ‚umaczenia wykonanego przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za jakiekolwiek nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z korzystania z tego tÅ‚umaczenia.