<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "5f3cb462e3122e1afe7ab0050ccf2bd3",
  "translation_date": "2025-09-05T08:29:20+00:00",
  "source_file": "6-NLP/2-Tasks/README.md",
  "language_code": "pl"
}
-->
# Typowe zadania i techniki przetwarzania jÄ™zyka naturalnego

W wiÄ™kszoÅ›ci zadaÅ„ zwiÄ…zanych z *przetwarzaniem jÄ™zyka naturalnego* tekst, ktÃ³ry ma byÄ‡ przetworzony, musi zostaÄ‡ podzielony, przeanalizowany, a wyniki zapisane lub porÃ³wnane z reguÅ‚ami i zestawami danych. Te zadania pozwalajÄ… programiÅ›cie wyciÄ…gnÄ…Ä‡ _znaczenie_, _intencjÄ™_ lub tylko _czÄ™stotliwoÅ›Ä‡_ wystÄ™powania terminÃ³w i sÅ‚Ã³w w tekÅ›cie.

## [Quiz przed wykÅ‚adem](https://ff-quizzes.netlify.app/en/ml/)

Poznajmy typowe techniki stosowane w przetwarzaniu tekstu. W poÅ‚Ä…czeniu z uczeniem maszynowym techniki te pomagajÄ… efektywnie analizowaÄ‡ duÅ¼e iloÅ›ci tekstu. Zanim jednak zastosujesz ML do tych zadaÅ„, zrozummy problemy, z ktÃ³rymi mierzy siÄ™ specjalista NLP.

## Typowe zadania w NLP

Istnieje wiele sposobÃ³w analizy tekstu, nad ktÃ³rym pracujesz. SÄ… zadania, ktÃ³re moÅ¼esz wykonaÄ‡, a dziÄ™ki nim moÅ¼esz zrozumieÄ‡ tekst i wyciÄ…gnÄ…Ä‡ wnioski. Zazwyczaj wykonujesz te zadania w okreÅ›lonej kolejnoÅ›ci.

### Tokenizacja

Prawdopodobnie pierwszym krokiem, ktÃ³ry wiÄ™kszoÅ›Ä‡ algorytmÃ³w NLP musi wykonaÄ‡, jest podzielenie tekstu na tokeny, czyli sÅ‚owa. ChoÄ‡ brzmi to prosto, uwzglÄ™dnienie znakÃ³w interpunkcyjnych oraz rÃ³Å¼nych jÄ™zykowych ogranicznikÃ³w zdaÅ„ i sÅ‚Ã³w moÅ¼e byÄ‡ trudne. MoÅ¼esz potrzebowaÄ‡ rÃ³Å¼nych metod, aby okreÅ›liÄ‡ granice.

![tokenizacja](../../../../6-NLP/2-Tasks/images/tokenization.png)
> Tokenizacja zdania z **Dumy i uprzedzenia**. Infografika autorstwa [Jen Looper](https://twitter.com/jenlooper)

### Osadzenia (Embeddings)

[Osadzenia sÅ‚Ã³w](https://wikipedia.org/wiki/Word_embedding) to sposÃ³b na numeryczne przeksztaÅ‚cenie danych tekstowych. Osadzenia sÄ… tworzone w taki sposÃ³b, aby sÅ‚owa o podobnym znaczeniu lub uÅ¼ywane razem grupowaÅ‚y siÄ™ w klastrach.

![osadzenia sÅ‚Ã³w](../../../../6-NLP/2-Tasks/images/embedding.png)
> "Mam najwyÅ¼szy szacunek dla twoich nerwÃ³w, sÄ… moimi starymi przyjaciÃ³Å‚mi." - Osadzenia sÅ‚Ã³w dla zdania z **Dumy i uprzedzenia**. Infografika autorstwa [Jen Looper](https://twitter.com/jenlooper)

âœ… WyprÃ³buj [to ciekawe narzÄ™dzie](https://projector.tensorflow.org/), aby eksperymentowaÄ‡ z osadzeniami sÅ‚Ã³w. KlikniÄ™cie na jedno sÅ‚owo pokazuje klastry podobnych sÅ‚Ã³w: 'toy' grupuje siÄ™ z 'disney', 'lego', 'playstation' i 'console'.

### Parsowanie i Tagowanie CzÄ™Å›ci Mowy

KaÅ¼de sÅ‚owo, ktÃ³re zostaÅ‚o podzielone na tokeny, moÅ¼e byÄ‡ oznaczone jako czÄ™Å›Ä‡ mowy - rzeczownik, czasownik lub przymiotnik. Zdanie `the quick red fox jumped over the lazy brown dog` moÅ¼e byÄ‡ oznaczone jako fox = rzeczownik, jumped = czasownik.

![parsowanie](../../../../6-NLP/2-Tasks/images/parse.png)

> Parsowanie zdania z **Dumy i uprzedzenia**. Infografika autorstwa [Jen Looper](https://twitter.com/jenlooper)

Parsowanie polega na rozpoznawaniu, ktÃ³re sÅ‚owa sÄ… ze sobÄ… powiÄ…zane w zdaniu - na przykÅ‚ad `the quick red fox jumped` to sekwencja przymiotnik-rzeczownik-czasownik, ktÃ³ra jest oddzielna od sekwencji `lazy brown dog`.

### CzÄ™stotliwoÅ›Ä‡ sÅ‚Ã³w i fraz

Przydatnym procesem podczas analizy duÅ¼ej iloÅ›ci tekstu jest stworzenie sÅ‚ownika wszystkich interesujÄ…cych sÅ‚Ã³w lub fraz oraz ich czÄ™stotliwoÅ›ci wystÄ™powania. Fraza `the quick red fox jumped over the lazy brown dog` ma czÄ™stotliwoÅ›Ä‡ 2 dla sÅ‚owa "the".

SpÃ³jrzmy na przykÅ‚ad tekstu, w ktÃ³rym liczymy czÄ™stotliwoÅ›Ä‡ sÅ‚Ã³w. Wiersz Rudyard Kiplinga "The Winners" zawiera nastÄ™pujÄ…cy fragment:

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

PoniewaÅ¼ czÄ™stotliwoÅ›Ä‡ fraz moÅ¼e byÄ‡ wraÅ¼liwa na wielkoÅ›Ä‡ liter lub nie, fraza `a friend` wystÄ™puje 2 razy, `the` wystÄ™puje 6 razy, a `travels` wystÄ™puje 2 razy.

### N-gramy

Tekst moÅ¼na podzieliÄ‡ na sekwencje sÅ‚Ã³w o okreÅ›lonej dÅ‚ugoÅ›ci: jedno sÅ‚owo (unigram), dwa sÅ‚owa (bigramy), trzy sÅ‚owa (trigramy) lub dowolnÄ… liczbÄ™ sÅ‚Ã³w (n-gramy).

Na przykÅ‚ad `the quick red fox jumped over the lazy brown dog` z wartoÅ›ciÄ… n-gramu rÃ³wnÄ… 2 daje nastÄ™pujÄ…ce n-gramy:

1. the quick 
2. quick red 
3. red fox
4. fox jumped 
5. jumped over 
6. over the 
7. the lazy 
8. lazy brown 
9. brown dog

MoÅ¼na to Å‚atwiej zobrazowaÄ‡ jako przesuwajÄ…ce siÄ™ okno nad zdaniem. Oto przykÅ‚ad dla n-gramÃ³w zÅ‚oÅ¼onych z 3 sÅ‚Ã³w, gdzie n-gram jest pogrubiony w kaÅ¼dym zdaniu:

1.   <u>**the quick red**</u> fox jumped over the lazy brown dog
2.   the **<u>quick red fox</u>** jumped over the lazy brown dog
3.   the quick **<u>red fox jumped</u>** over the lazy brown dog
4.   the quick red **<u>fox jumped over</u>** the lazy brown dog
5.   the quick red fox **<u>jumped over the</u>** lazy brown dog
6.   the quick red fox jumped **<u>over the lazy</u>** brown dog
7.   the quick red fox jumped over <u>**the lazy brown**</u> dog
8.   the quick red fox jumped over the **<u>lazy brown dog</u>**

![przesuwajÄ…ce siÄ™ okno n-gramÃ³w](../../../../6-NLP/2-Tasks/images/n-grams.gif)

> WartoÅ›Ä‡ n-gramu: 3. Infografika autorstwa [Jen Looper](https://twitter.com/jenlooper)

### Ekstrakcja fraz rzeczownikowych

W wiÄ™kszoÅ›ci zdaÅ„ znajduje siÄ™ rzeczownik, ktÃ³ry jest podmiotem lub dopeÅ‚nieniem zdania. W jÄ™zyku angielskim czÄ™sto moÅ¼na go zidentyfikowaÄ‡ jako poprzedzony sÅ‚owami 'a', 'an' lub 'the'. Identyfikacja podmiotu lub dopeÅ‚nienia zdania poprzez 'ekstrakcjÄ™ frazy rzeczownikowej' jest czÄ™stym zadaniem w NLP, gdy prÃ³buje siÄ™ zrozumieÄ‡ znaczenie zdania.

âœ… W zdaniu "I cannot fix on the hour, or the spot, or the look or the words, which laid the foundation. It is too long ago. I was in the middle before I knew that I had begun." czy potrafisz zidentyfikowaÄ‡ frazy rzeczownikowe?

W zdaniu `the quick red fox jumped over the lazy brown dog` znajdujÄ… siÄ™ 2 frazy rzeczownikowe: **quick red fox** i **lazy brown dog**.

### Analiza sentymentu

Zdanie lub tekst moÅ¼na przeanalizowaÄ‡ pod kÄ…tem sentymentu, czyli tego, jak *pozytywny* lub *negatywny* jest. Sentyment jest mierzony w *polaryzacji* oraz *obiektywnoÅ›ci/subiektywnoÅ›ci*. Polaryzacja jest mierzona od -1.0 do 1.0 (negatywna do pozytywnej) oraz od 0.0 do 1.0 (najbardziej obiektywna do najbardziej subiektywnej).

âœ… PÃ³Åºniej dowiesz siÄ™, Å¼e istniejÄ… rÃ³Å¼ne sposoby okreÅ›lania sentymentu za pomocÄ… uczenia maszynowego, ale jednym ze sposobÃ³w jest posiadanie listy sÅ‚Ã³w i fraz sklasyfikowanych jako pozytywne lub negatywne przez eksperta i zastosowanie tego modelu do tekstu w celu obliczenia wyniku polaryzacji. Czy widzisz, jak to mogÅ‚oby dziaÅ‚aÄ‡ w niektÃ³rych okolicznoÅ›ciach, a w innych mniej?

### Odmiana

Odmiana pozwala na uzyskanie liczby pojedynczej lub mnogiej danego sÅ‚owa.

### Lematyzacja

*Lemmatyzacja* to proces sprowadzania sÅ‚owa do jego podstawowej formy, czyli *lematu*. Na przykÅ‚ad *flew*, *flies*, *flying* majÄ… lemat czasownika *fly*.

DostÄ™pne sÄ… rÃ³wnieÅ¼ przydatne bazy danych dla badaczy NLP, w tym:

### WordNet

[WordNet](https://wordnet.princeton.edu/) to baza danych sÅ‚Ã³w, synonimÃ³w, antonimÃ³w i wielu innych szczegÃ³Å‚Ã³w dla kaÅ¼dego sÅ‚owa w rÃ³Å¼nych jÄ™zykach. Jest niezwykle przydatna przy tworzeniu tÅ‚umaczeÅ„, korektorÃ³w pisowni czy narzÄ™dzi jÄ™zykowych kaÅ¼dego rodzaju.

## Biblioteki NLP

Na szczÄ™Å›cie nie musisz samodzielnie budowaÄ‡ wszystkich tych technik, poniewaÅ¼ istniejÄ… doskonaÅ‚e biblioteki Python, ktÃ³re sprawiajÄ…, Å¼e NLP jest bardziej dostÄ™pne dla programistÃ³w, ktÃ³rzy nie specjalizujÄ… siÄ™ w przetwarzaniu jÄ™zyka naturalnego ani uczeniu maszynowym. W kolejnych lekcjach znajdziesz wiÄ™cej przykÅ‚adÃ³w, ale tutaj poznasz kilka przydatnych przykÅ‚adÃ³w, ktÃ³re pomogÄ… Ci w nastÄ™pnym zadaniu.

### Ä†wiczenie - korzystanie z biblioteki `TextBlob`

UÅ¼yjmy biblioteki TextBlob, poniewaÅ¼ zawiera ona pomocne API do radzenia sobie z tego typu zadaniami. TextBlob "opiera siÄ™ na potÄ™Å¼nych fundamentach [NLTK](https://nltk.org) i [pattern](https://github.com/clips/pattern), i dobrze wspÃ³Å‚pracuje z obiema."

> Uwaga: Przydatny [Przewodnik Szybkiego Startu](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart) jest dostÄ™pny dla TextBlob i polecany dla doÅ›wiadczonych programistÃ³w Python.

Podczas prÃ³by identyfikacji *frazy rzeczownikowej* TextBlob oferuje kilka opcji ekstraktorÃ³w do znajdowania fraz rzeczownikowych.

1. SpÃ³jrz na `ConllExtractor`.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > Co tu siÄ™ dzieje? [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) to "Ekstraktor fraz rzeczownikowych, ktÃ³ry wykorzystuje parsowanie chunkÃ³w wytrenowane na korpusie treningowym ConLL-2000." ConLL-2000 odnosi siÄ™ do konferencji Computational Natural Language Learning z 2000 roku. KaÅ¼dego roku konferencja organizowaÅ‚a warsztaty, aby rozwiÄ…zaÄ‡ trudny problem NLP, a w 2000 roku byÅ‚ to chunking fraz rzeczownikowych. Model zostaÅ‚ wytrenowany na danych z Wall Street Journal, z "sekcjami 15-18 jako danymi treningowymi (211727 tokenÃ³w) i sekcjÄ… 20 jako danymi testowymi (47377 tokenÃ³w)". MoÅ¼esz zapoznaÄ‡ siÄ™ z procedurami uÅ¼ytymi [tutaj](https://www.clips.uantwerpen.be/conll2000/chunking/) oraz z [wynikami](https://ifarm.nl/erikt/research/np-chunking.html).

### Wyzwanie - ulepszanie swojego bota za pomocÄ… NLP

W poprzedniej lekcji stworzyÅ‚eÅ› bardzo prostego bota Q&A. Teraz sprawisz, Å¼e Marvin bÄ™dzie bardziej empatyczny, analizujÄ…c Twoje dane wejÅ›ciowe pod kÄ…tem sentymentu i drukujÄ…c odpowiedÅº pasujÄ…cÄ… do tego sentymentu. Musisz rÃ³wnieÅ¼ zidentyfikowaÄ‡ `noun_phrase` i zapytaÄ‡ o niÄ….

Twoje kroki przy budowaniu lepszego bota konwersacyjnego:

1. Wydrukuj instrukcje informujÄ…ce uÅ¼ytkownika, jak wchodziÄ‡ w interakcjÄ™ z botem
2. Rozpocznij pÄ™tlÄ™ 
   1. Przyjmij dane wejÅ›ciowe od uÅ¼ytkownika
   2. JeÅ›li uÅ¼ytkownik poprosi o zakoÅ„czenie, zakoÅ„cz
   3. PrzetwÃ³rz dane wejÅ›ciowe uÅ¼ytkownika i okreÅ›l odpowiedniÄ… odpowiedÅº na podstawie sentymentu
   4. JeÅ›li w sentymencie zostanie wykryta fraza rzeczownikowa, zmieÅ„ jej liczbÄ™ mnogÄ… i zapytaj o niÄ…
   5. Wydrukuj odpowiedÅº
3. WrÃ³Ä‡ do kroku 2

Oto fragment kodu do okreÅ›lania sentymentu za pomocÄ… TextBlob. ZauwaÅ¼, Å¼e sÄ… tylko cztery *gradienty* odpowiedzi na sentyment (moÅ¼esz dodaÄ‡ wiÄ™cej, jeÅ›li chcesz):

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

Oto przykÅ‚adowy wynik, ktÃ³ry moÅ¼e CiÄ™ poprowadziÄ‡ (dane wejÅ›ciowe uÅ¼ytkownika sÄ… na liniach zaczynajÄ…cych siÄ™ od >):

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

Jedno z moÅ¼liwych rozwiÄ…zaÅ„ zadania znajduje siÄ™ [tutaj](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/2-Tasks/solution/bot.py)

âœ… SprawdÅº swojÄ… wiedzÄ™

1. Czy uwaÅ¼asz, Å¼e empatyczne odpowiedzi mogÅ‚yby 'oszukaÄ‡' kogoÅ›, Å¼e bot faktycznie go rozumie?
2. Czy identyfikacja frazy rzeczownikowej sprawia, Å¼e bot jest bardziej 'wiarygodny'?
3. Dlaczego ekstrakcja 'frazy rzeczownikowej' ze zdania jest przydatna?

---

Zaimplementuj bota z poprzedniego sprawdzania wiedzy i przetestuj go na znajomym. Czy potrafi ich oszukaÄ‡? Czy moÅ¼esz sprawiÄ‡, Å¼e TwÃ³j bot bÄ™dzie bardziej 'wiarygodny'?

## ğŸš€Wyzwanie

Wykonaj zadanie z poprzedniego sprawdzania wiedzy i sprÃ³buj je zaimplementowaÄ‡. Przetestuj bota na znajomym. Czy potrafi ich oszukaÄ‡? Czy moÅ¼esz sprawiÄ‡, Å¼e TwÃ³j bot bÄ™dzie bardziej 'wiarygodny'?

## [Quiz po wykÅ‚adzie](https://ff-quizzes.netlify.app/en/ml/)

## PrzeglÄ…d i samodzielna nauka

W kolejnych lekcjach dowiesz siÄ™ wiÄ™cej o analizie sentymentu. Zbadaj tÄ™ interesujÄ…cÄ… technikÄ™ w artykuÅ‚ach takich jak te na [KDNuggets](https://www.kdnuggets.com/tag/nlp)

## Zadanie 

[Spraw, by bot odpowiadaÅ‚](assignment.md)

---

**ZastrzeÅ¼enie**:  
Ten dokument zostaÅ‚ przetÅ‚umaczony za pomocÄ… usÅ‚ugi tÅ‚umaczeniowej AI [Co-op Translator](https://github.com/Azure/co-op-translator). ChociaÅ¼ dokÅ‚adamy wszelkich staraÅ„, aby tÅ‚umaczenie byÅ‚o precyzyjne, prosimy pamiÄ™taÄ‡, Å¼e automatyczne tÅ‚umaczenia mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jego rodzimym jÄ™zyku powinien byÄ‡ uznawany za wiarygodne ÅºrÃ³dÅ‚o. W przypadku informacji krytycznych zaleca siÄ™ skorzystanie z profesjonalnego tÅ‚umaczenia wykonanego przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za jakiekolwiek nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z korzystania z tego tÅ‚umaczenia.