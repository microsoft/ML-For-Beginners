<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "40e64f004f3cb50aa1d8661672d3cd92",
  "translation_date": "2025-09-05T08:10:32+00:00",
  "source_file": "2-Regression/3-Linear/README.md",
  "language_code": "pl"
}
-->
# Budowanie modelu regresji za pomocÄ… Scikit-learn: regresja na cztery sposoby

![Infografika: regresja liniowa vs. wielomianowa](../../../../2-Regression/3-Linear/images/linear-polynomial.png)
> Infografika autorstwa [Dasani Madipalli](https://twitter.com/dasani_decoded)
## [Quiz przed wykÅ‚adem](https://ff-quizzes.netlify.app/en/ml/)

> ### [Ta lekcja jest dostÄ™pna w R!](../../../../2-Regression/3-Linear/solution/R/lesson_3.html)
### Wprowadzenie 

Do tej pory zapoznaÅ‚eÅ› siÄ™ z pojÄ™ciem regresji, korzystajÄ…c z przykÅ‚adowych danych z zestawu dotyczÄ…cego cen dyni, ktÃ³ry bÄ™dziemy uÅ¼ywaÄ‡ w tej lekcji. WizualizowaÅ‚eÅ› rÃ³wnieÅ¼ dane za pomocÄ… biblioteki Matplotlib.

Teraz jesteÅ› gotowy, aby zagÅ‚Ä™biÄ‡ siÄ™ w temat regresji w kontekÅ›cie uczenia maszynowego. ChociaÅ¼ wizualizacja pozwala zrozumieÄ‡ dane, prawdziwa siÅ‚a uczenia maszynowego tkwi w _trenowaniu modeli_. Modele sÄ… trenowane na danych historycznych, aby automatycznie uchwyciÄ‡ zaleÅ¼noÅ›ci miÄ™dzy danymi, co pozwala przewidywaÄ‡ wyniki dla nowych danych, ktÃ³rych model wczeÅ›niej nie widziaÅ‚.

W tej lekcji dowiesz siÄ™ wiÄ™cej o dwÃ³ch typach regresji: _podstawowej regresji liniowej_ i _regresji wielomianowej_, wraz z niektÃ³rymi aspektami matematycznymi stojÄ…cymi za tymi technikami. Te modele pozwolÄ… nam przewidywaÄ‡ ceny dyni w zaleÅ¼noÅ›ci od rÃ³Å¼nych danych wejÅ›ciowych.

[![ML dla poczÄ…tkujÄ…cych - Zrozumienie regresji liniowej](https://img.youtube.com/vi/CRxFT8oTDMg/0.jpg)](https://youtu.be/CRxFT8oTDMg "ML dla poczÄ…tkujÄ…cych - Zrozumienie regresji liniowej")

> ğŸ¥ Kliknij obrazek powyÅ¼ej, aby obejrzeÄ‡ krÃ³tki film o regresji liniowej.

> W caÅ‚ym tym kursie zakÅ‚adamy minimalnÄ… znajomoÅ›Ä‡ matematyki i staramy siÄ™ uczyniÄ‡ jÄ… przystÄ™pnÄ… dla studentÃ³w z innych dziedzin. Zwracaj uwagÄ™ na notatki, ğŸ§® wyjaÅ›nienia, diagramy i inne narzÄ™dzia edukacyjne, ktÃ³re pomogÄ… w zrozumieniu.

### Wymagania wstÄ™pne

PowinieneÅ› juÅ¼ znaÄ‡ strukturÄ™ danych o dyniach, ktÃ³re analizujemy. Dane te sÄ… wstÄ™pnie zaÅ‚adowane i oczyszczone w pliku _notebook.ipynb_ doÅ‚Ä…czonym do tej lekcji. W pliku cena dyni jest wyÅ›wietlana za buszel w nowej ramce danych. Upewnij siÄ™, Å¼e moÅ¼esz uruchomiÄ‡ te notatniki w kernelach w Visual Studio Code.

### Przygotowanie

Przypominamy, Å¼e wczytujesz te dane, aby zadawaÄ‡ im pytania.

- Kiedy najlepiej kupowaÄ‡ dynie? 
- Jakiej ceny mogÄ™ siÄ™ spodziewaÄ‡ za skrzynkÄ™ miniaturowych dyÅ„?
- Czy powinienem kupowaÄ‡ je w koszach o pojemnoÅ›ci pÃ³Å‚ buszla czy w pudeÅ‚kach o pojemnoÅ›ci 1 1/9 buszla?
ZagÅ‚Ä™bmy siÄ™ dalej w te dane.

W poprzedniej lekcji stworzyÅ‚eÅ› ramkÄ™ danych Pandas i wypeÅ‚niÅ‚eÅ› jÄ… czÄ™Å›ciÄ… oryginalnego zestawu danych, standaryzujÄ…c ceny wedÅ‚ug buszla. JednakÅ¼e, w ten sposÃ³b udaÅ‚o siÄ™ zebraÄ‡ tylko okoÅ‚o 400 punktÃ³w danych i tylko dla jesiennych miesiÄ™cy.

SpÃ³jrz na dane, ktÃ³re zostaÅ‚y wstÄ™pnie zaÅ‚adowane w notatniku doÅ‚Ä…czonym do tej lekcji. Dane sÄ… wstÄ™pnie zaÅ‚adowane, a poczÄ…tkowy wykres punktowy zostaÅ‚ utworzony, aby pokazaÄ‡ dane miesiÄ™czne. MoÅ¼e uda nam siÄ™ uzyskaÄ‡ wiÄ™cej szczegÃ³Å‚Ã³w na temat charakteru danych, oczyszczajÄ…c je bardziej.

## Linia regresji liniowej

Jak nauczyÅ‚eÅ› siÄ™ w Lekcji 1, celem Ä‡wiczenia regresji liniowej jest moÅ¼liwoÅ›Ä‡ narysowania linii, aby:

- **PokazaÄ‡ zaleÅ¼noÅ›ci miÄ™dzy zmiennymi**. PokazaÄ‡ relacjÄ™ miÄ™dzy zmiennymi
- **DokonywaÄ‡ prognoz**. DokonywaÄ‡ dokÅ‚adnych prognoz, gdzie nowy punkt danych znajdzie siÄ™ w stosunku do tej linii.

Typowe dla **Regresji MetodÄ… Najmniejszych KwadratÃ³w** jest rysowanie tego typu linii. Termin 'najmniejsze kwadraty' oznacza, Å¼e wszystkie punkty danych otaczajÄ…ce liniÄ™ regresji sÄ… podnoszone do kwadratu, a nastÄ™pnie sumowane. Idealnie, ta koÅ„cowa suma jest jak najmniejsza, poniewaÅ¼ chcemy mieÄ‡ maÅ‚Ä… liczbÄ™ bÅ‚Ä™dÃ³w, czyli `najmniejsze kwadraty`.

Robimy to, poniewaÅ¼ chcemy modelowaÄ‡ liniÄ™, ktÃ³ra ma najmniejszÄ… skumulowanÄ… odlegÅ‚oÅ›Ä‡ od wszystkich naszych punktÃ³w danych. Podnosimy rÃ³wnieÅ¼ wartoÅ›ci do kwadratu przed ich dodaniem, poniewaÅ¼ interesuje nas ich wielkoÅ›Ä‡, a nie kierunek.

> **ğŸ§® PokaÅ¼ mi matematykÄ™** 
> 
> Ta linia, nazywana _liniÄ… najlepszego dopasowania_, moÅ¼e byÄ‡ wyraÅ¼ona za pomocÄ… [rÃ³wnania](https://en.wikipedia.org/wiki/Simple_linear_regression): 
> 
> ```
> Y = a + bX
> ```
>
> `X` to 'zmienna objaÅ›niajÄ…ca'. `Y` to 'zmienna zaleÅ¼na'. Nachylenie linii to `b`, a `a` to punkt przeciÄ™cia z osiÄ… Y, ktÃ³ry odnosi siÄ™ do wartoÅ›ci `Y`, gdy `X = 0`. 
>
>![obliczanie nachylenia](../../../../2-Regression/3-Linear/images/slope.png)
>
> Najpierw oblicz nachylenie `b`. Infografika autorstwa [Jen Looper](https://twitter.com/jenlooper)
>
> Innymi sÅ‚owy, odnoszÄ…c siÄ™ do pierwotnego pytania dotyczÄ…cego danych o dyniach: "przewidzieÄ‡ cenÄ™ dyni za buszel wedÅ‚ug miesiÄ…ca", `X` odnosiÅ‚oby siÄ™ do ceny, a `Y` do miesiÄ…ca sprzedaÅ¼y. 
>
>![uzupeÅ‚nij rÃ³wnanie](../../../../2-Regression/3-Linear/images/calculation.png)
>
> Oblicz wartoÅ›Ä‡ Y. JeÅ›li pÅ‚acisz okoÅ‚o 4 dolarÃ³w, to musi byÄ‡ kwiecieÅ„! Infografika autorstwa [Jen Looper](https://twitter.com/jenlooper)
>
> Matematyka, ktÃ³ra oblicza liniÄ™, musi uwzglÄ™dniaÄ‡ nachylenie linii, ktÃ³re rÃ³wnieÅ¼ zaleÅ¼y od punktu przeciÄ™cia, czyli miejsca, gdzie `Y` znajduje siÄ™, gdy `X = 0`.
>
> MoÅ¼esz zobaczyÄ‡ metodÄ™ obliczania tych wartoÅ›ci na stronie [Math is Fun](https://www.mathsisfun.com/data/least-squares-regression.html). OdwiedÅº rÃ³wnieÅ¼ [ten kalkulator metodÄ… najmniejszych kwadratÃ³w](https://www.mathsisfun.com/data/least-squares-calculator.html), aby zobaczyÄ‡, jak wartoÅ›ci liczbowe wpÅ‚ywajÄ… na liniÄ™.

## Korelacja

Jeszcze jedno pojÄ™cie do zrozumienia to **WspÃ³Å‚czynnik Korelacji** miÄ™dzy danymi zmiennymi X i Y. KorzystajÄ…c z wykresu punktowego, moÅ¼esz szybko zwizualizowaÄ‡ ten wspÃ³Å‚czynnik. Wykres z punktami danych uÅ‚oÅ¼onymi w schludnÄ… liniÄ™ ma wysokÄ… korelacjÄ™, ale wykres z punktami danych rozrzuconymi wszÄ™dzie miÄ™dzy X i Y ma niskÄ… korelacjÄ™.

Dobry model regresji liniowej bÄ™dzie miaÅ‚ wysoki (bliÅ¼szy 1 niÅ¼ 0) WspÃ³Å‚czynnik Korelacji, korzystajÄ…c z metody Regresji MetodÄ… Najmniejszych KwadratÃ³w z liniÄ… regresji.

âœ… Uruchom notatnik doÅ‚Ä…czony do tej lekcji i spÃ³jrz na wykres punktowy MiesiÄ…c do Ceny. Czy dane Å‚Ä…czÄ…ce MiesiÄ…c z CenÄ… dla sprzedaÅ¼y dyni wydajÄ… siÄ™ mieÄ‡ wysokÄ… czy niskÄ… korelacjÄ™, wedÅ‚ug Twojej wizualnej interpretacji wykresu punktowego? Czy to siÄ™ zmienia, jeÅ›li uÅ¼yjesz bardziej szczegÃ³Å‚owego miary zamiast `MiesiÄ…c`, np. *dzieÅ„ roku* (czyli liczba dni od poczÄ…tku roku)?

W poniÅ¼szym kodzie zakÅ‚adamy, Å¼e oczyÅ›ciliÅ›my dane i uzyskaliÅ›my ramkÄ™ danych o nazwie `new_pumpkins`, podobnÄ… do nastÄ™pujÄ…cej:

ID | MiesiÄ…c | DzieÅ„Roku | Odmiana | Miasto | Opakowanie | Cena minimalna | Cena maksymalna | Cena
---|---------|-----------|---------|--------|------------|----------------|-----------------|-----
70 | 9 | 267 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 15.0 | 15.0 | 13.636364
71 | 9 | 267 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 18.0 | 18.0 | 16.363636
72 | 10 | 274 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 18.0 | 18.0 | 16.363636
73 | 10 | 274 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 17.0 | 17.0 | 15.454545
74 | 10 | 281 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 15.0 | 15.0 | 13.636364

> Kod do oczyszczenia danych jest dostÄ™pny w [`notebook.ipynb`](../../../../2-Regression/3-Linear/notebook.ipynb). WykonaliÅ›my te same kroki oczyszczania co w poprzedniej lekcji i obliczyliÅ›my kolumnÄ™ `DzieÅ„Roku` za pomocÄ… nastÄ™pujÄ…cego wyraÅ¼enia: 

```python
day_of_year = pd.to_datetime(pumpkins['Date']).apply(lambda dt: (dt-datetime(dt.year,1,1)).days)
```

Teraz, gdy rozumiesz matematykÄ™ stojÄ…cÄ… za regresjÄ… liniowÄ…, stwÃ³rzmy model regresji, aby sprawdziÄ‡, czy moÅ¼emy przewidzieÄ‡, ktÃ³re opakowanie dyni bÄ™dzie miaÅ‚o najlepsze ceny. KtoÅ› kupujÄ…cy dynie na Å›wiÄ…teczny plac dyniowy moÅ¼e chcieÄ‡ tej informacji, aby zoptymalizowaÄ‡ swoje zakupy opakowaÅ„ dyni na plac.

## Szukanie korelacji

[![ML dla poczÄ…tkujÄ…cych - Szukanie korelacji: Klucz do regresji liniowej](https://img.youtube.com/vi/uoRq-lW2eQo/0.jpg)](https://youtu.be/uoRq-lW2eQo "ML dla poczÄ…tkujÄ…cych - Szukanie korelacji: Klucz do regresji liniowej")

> ğŸ¥ Kliknij obrazek powyÅ¼ej, aby obejrzeÄ‡ krÃ³tki film o korelacji.

Z poprzedniej lekcji prawdopodobnie zauwaÅ¼yÅ‚eÅ›, Å¼e Å›rednia cena dla rÃ³Å¼nych miesiÄ™cy wyglÄ…da tak:

<img alt="Åšrednia cena wedÅ‚ug miesiÄ…ca" src="../2-Data/images/barchart.png" width="50%"/>

To sugeruje, Å¼e powinna istnieÄ‡ jakaÅ› korelacja, i moÅ¼emy sprÃ³bowaÄ‡ wytrenowaÄ‡ model regresji liniowej, aby przewidzieÄ‡ zwiÄ…zek miÄ™dzy `MiesiÄ…cem` a `CenÄ…`, lub miÄ™dzy `DniemRoku` a `CenÄ…`. Oto wykres punktowy pokazujÄ…cy tÄ™ drugÄ… zaleÅ¼noÅ›Ä‡:

<img alt="Wykres punktowy Cena vs. DzieÅ„ Roku" src="images/scatter-dayofyear.png" width="50%" /> 

SprawdÅºmy, czy istnieje korelacja, uÅ¼ywajÄ…c funkcji `corr`:

```python
print(new_pumpkins['Month'].corr(new_pumpkins['Price']))
print(new_pumpkins['DayOfYear'].corr(new_pumpkins['Price']))
```

WyglÄ…da na to, Å¼e korelacja jest doÅ›Ä‡ maÅ‚a, -0.15 dla `MiesiÄ…ca` i -0.17 dla `DniaRoku`, ale moÅ¼e istnieÄ‡ inna waÅ¼na zaleÅ¼noÅ›Ä‡. WyglÄ…da na to, Å¼e istniejÄ… rÃ³Å¼ne skupiska cen odpowiadajÄ…ce rÃ³Å¼nym odmianom dyni. Aby potwierdziÄ‡ tÄ™ hipotezÄ™, narysujmy kaÅ¼dÄ… kategoriÄ™ dyni w innym kolorze. PrzekazujÄ…c parametr `ax` do funkcji `scatter`, moÅ¼emy narysowaÄ‡ wszystkie punkty na tym samym wykresie:

```python
ax=None
colors = ['red','blue','green','yellow']
for i,var in enumerate(new_pumpkins['Variety'].unique()):
    df = new_pumpkins[new_pumpkins['Variety']==var]
    ax = df.plot.scatter('DayOfYear','Price',ax=ax,c=colors[i],label=var)
```

<img alt="Wykres punktowy Cena vs. DzieÅ„ Roku" src="images/scatter-dayofyear-color.png" width="50%" /> 

Nasze badanie sugeruje, Å¼e odmiana ma wiÄ™kszy wpÅ‚yw na ogÃ³lnÄ… cenÄ™ niÅ¼ rzeczywista data sprzedaÅ¼y. MoÅ¼emy to zobaczyÄ‡ na wykresie sÅ‚upkowym:

```python
new_pumpkins.groupby('Variety')['Price'].mean().plot(kind='bar')
```

<img alt="Wykres sÅ‚upkowy cena vs odmiana" src="images/price-by-variety.png" width="50%" /> 

Skupmy siÄ™ na chwilÄ™ tylko na jednej odmianie dyni, 'pie type', i zobaczmy, jaki wpÅ‚yw ma data na cenÄ™:

```python
pie_pumpkins = new_pumpkins[new_pumpkins['Variety']=='PIE TYPE']
pie_pumpkins.plot.scatter('DayOfYear','Price') 
```
<img alt="Wykres punktowy Cena vs. DzieÅ„ Roku" src="images/pie-pumpkins-scatter.png" width="50%" /> 

JeÅ›li teraz obliczymy korelacjÄ™ miÄ™dzy `CenÄ…` a `DniemRoku` za pomocÄ… funkcji `corr`, otrzymamy coÅ› w rodzaju `-0.27` - co oznacza, Å¼e trenowanie modelu predykcyjnego ma sens.

> Przed trenowaniem modelu regresji liniowej waÅ¼ne jest, aby upewniÄ‡ siÄ™, Å¼e nasze dane sÄ… czyste. Regresja liniowa nie dziaÅ‚a dobrze z brakujÄ…cymi wartoÅ›ciami, dlatego warto pozbyÄ‡ siÄ™ wszystkich pustych komÃ³rek:

```python
pie_pumpkins.dropna(inplace=True)
pie_pumpkins.info()
```

Innym podejÅ›ciem byÅ‚oby wypeÅ‚nienie tych pustych wartoÅ›ci Å›rednimi wartoÅ›ciami z odpowiedniej kolumny.

## Prosta regresja liniowa

[![ML dla poczÄ…tkujÄ…cych - Regresja liniowa i wielomianowa za pomocÄ… Scikit-learn](https://img.youtube.com/vi/e4c_UP2fSjg/0.jpg)](https://youtu.be/e4c_UP2fSjg "ML dla poczÄ…tkujÄ…cych - Regresja liniowa i wielomianowa za pomocÄ… Scikit-learn")

> ğŸ¥ Kliknij obrazek powyÅ¼ej, aby obejrzeÄ‡ krÃ³tki film o regresji liniowej i wielomianowej.

Aby wytrenowaÄ‡ nasz model regresji liniowej, uÅ¼yjemy biblioteki **Scikit-learn**.

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
```

Zaczynamy od oddzielenia wartoÅ›ci wejÅ›ciowych (cech) i oczekiwanych wynikÃ³w (etykiet) w osobne tablice numpy:

```python
X = pie_pumpkins['DayOfYear'].to_numpy().reshape(-1,1)
y = pie_pumpkins['Price']
```

> ZauwaÅ¼, Å¼e musieliÅ›my wykonaÄ‡ `reshape` na danych wejÅ›ciowych, aby pakiet regresji liniowej mÃ³gÅ‚ je poprawnie zrozumieÄ‡. Regresja liniowa oczekuje 2D-tablicy jako danych wejÅ›ciowych, gdzie kaÅ¼dy wiersz tablicy odpowiada wektorowi cech wejÅ›ciowych. W naszym przypadku, poniewaÅ¼ mamy tylko jeden wejÅ›ciowy parametr - potrzebujemy tablicy o ksztaÅ‚cie NÃ—1, gdzie N to rozmiar zestawu danych.

NastÄ™pnie musimy podzieliÄ‡ dane na zestawy treningowe i testowe, aby mÃ³c zweryfikowaÄ‡ nasz model po treningu:

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
```

Na koniec, trenowanie rzeczywistego modelu regresji liniowej zajmuje tylko dwie linie kodu. Definiujemy obiekt `LinearRegression` i dopasowujemy go do naszych danych za pomocÄ… metody `fit`:

```python
lin_reg = LinearRegression()
lin_reg.fit(X_train,y_train)
```

Obiekt `LinearRegression` po dopasowaniu zawiera wszystkie wspÃ³Å‚czynniki regresji, ktÃ³re moÅ¼na uzyskaÄ‡ za pomocÄ… wÅ‚aÅ›ciwoÅ›ci `.coef_`. W naszym przypadku jest tylko jeden wspÃ³Å‚czynnik, ktÃ³ry powinien wynosiÄ‡ okoÅ‚o `-0.017`. Oznacza to, Å¼e ceny wydajÄ… siÄ™ nieco spadaÄ‡ z czasem, ale niezbyt duÅ¼o, okoÅ‚o 2 centy dziennie. MoÅ¼emy rÃ³wnieÅ¼ uzyskaÄ‡ punkt przeciÄ™cia regresji z osiÄ… Y za pomocÄ… `lin_reg.intercept_` - w naszym przypadku bÄ™dzie to okoÅ‚o `21`, co wskazuje cenÄ™ na poczÄ…tku roku.

Aby zobaczyÄ‡, jak dokÅ‚adny jest nasz model, moÅ¼emy przewidzieÄ‡ ceny na zestawie testowym, a nastÄ™pnie zmierzyÄ‡, jak bliskie sÄ… nasze przewidywania do oczekiwanych wartoÅ›ci. MoÅ¼na to zrobiÄ‡ za pomocÄ… metryki Å›redniego bÅ‚Ä™du kwadratowego (MSE), ktÃ³ra jest Å›redniÄ… wszystkich kwadratowych rÃ³Å¼nic miÄ™dzy oczekiwanÄ… a przewidywanÄ… wartoÅ›ciÄ….

```python
pred = lin_reg.predict(X_test)

mse = np.sqrt(mean_squared_error(y_test,pred))
print(f'Mean error: {mse:3.3} ({mse/np.mean(pred)*100:3.3}%)')
```
Nasza pomyÅ‚ka wydaje siÄ™ dotyczyÄ‡ 2 punktÃ³w, co stanowi okoÅ‚o 17%. Niezbyt dobrze. Innym wskaÅºnikiem jakoÅ›ci modelu jest **wspÃ³Å‚czynnik determinacji**, ktÃ³ry moÅ¼na obliczyÄ‡ w nastÄ™pujÄ…cy sposÃ³b:

```python
score = lin_reg.score(X_train,y_train)
print('Model determination: ', score)
```  
JeÅ›li wartoÅ›Ä‡ wynosi 0, oznacza to, Å¼e model nie uwzglÄ™dnia danych wejÅ›ciowych i dziaÅ‚a jako *najgorszy liniowy predyktor*, czyli po prostu Å›rednia wartoÅ›Ä‡ wyniku. WartoÅ›Ä‡ 1 oznacza, Å¼e moÅ¼emy idealnie przewidzieÄ‡ wszystkie oczekiwane wyniki. W naszym przypadku wspÃ³Å‚czynnik wynosi okoÅ‚o 0,06, co jest doÅ›Ä‡ niskie.

MoÅ¼emy rÃ³wnieÅ¼ wykreÅ›liÄ‡ dane testowe wraz z liniÄ… regresji, aby lepiej zobaczyÄ‡, jak dziaÅ‚a regresja w naszym przypadku:

```python
plt.scatter(X_test,y_test)
plt.plot(X_test,pred)
```  

<img alt="Regresja liniowa" src="images/linear-results.png" width="50%" />

## Regresja wielomianowa

Innym rodzajem regresji liniowej jest regresja wielomianowa. ChociaÅ¼ czasami istnieje liniowa zaleÅ¼noÅ›Ä‡ miÄ™dzy zmiennymi â€“ im wiÄ™ksza objÄ™toÅ›Ä‡ dyni, tym wyÅ¼sza cena â€“ czasami te zaleÅ¼noÅ›ci nie mogÄ… byÄ‡ przedstawione jako pÅ‚aszczyzna lub linia prosta.

âœ… Oto [kilka przykÅ‚adÃ³w](https://online.stat.psu.edu/stat501/lesson/9/9.8) danych, ktÃ³re mogÄ… wymagaÄ‡ regresji wielomianowej.

SpÃ³jrz jeszcze raz na zaleÅ¼noÅ›Ä‡ miÄ™dzy datÄ… a cenÄ…. Czy ten wykres rozrzutu wydaje siÄ™ koniecznie analizowany za pomocÄ… linii prostej? Czy ceny nie mogÄ… siÄ™ wahaÄ‡? W takim przypadku moÅ¼esz sprÃ³bowaÄ‡ regresji wielomianowej.

âœ… Wielomiany to wyraÅ¼enia matematyczne, ktÃ³re mogÄ… skÅ‚adaÄ‡ siÄ™ z jednej lub wiÄ™cej zmiennych i wspÃ³Å‚czynnikÃ³w.

Regresja wielomianowa tworzy krzywÄ…, ktÃ³ra lepiej dopasowuje siÄ™ do nieliniowych danych. W naszym przypadku, jeÅ›li uwzglÄ™dnimy zmiennÄ… `DayOfYear` podniesionÄ… do kwadratu w danych wejÅ›ciowych, powinniÅ›my byÄ‡ w stanie dopasowaÄ‡ nasze dane do krzywej parabolicznej, ktÃ³ra osiÄ…gnie minimum w pewnym punkcie w ciÄ…gu roku.

Scikit-learn zawiera przydatne [API pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html?highlight=pipeline#sklearn.pipeline.make_pipeline), ktÃ³re pozwala Å‚Ä…czyÄ‡ rÃ³Å¼ne kroki przetwarzania danych. **Pipeline** to Å‚aÅ„cuch **estymatorÃ³w**. W naszym przypadku stworzymy pipeline, ktÃ³ry najpierw doda cechy wielomianowe do naszego modelu, a nastÄ™pnie przeprowadzi trening regresji:

```python
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

pipeline = make_pipeline(PolynomialFeatures(2), LinearRegression())

pipeline.fit(X_train,y_train)
```  

UÅ¼ycie `PolynomialFeatures(2)` oznacza, Å¼e uwzglÄ™dnimy wszystkie wielomiany drugiego stopnia z danych wejÅ›ciowych. W naszym przypadku oznacza to po prostu `DayOfYear`<sup>2</sup>, ale przy dwÃ³ch zmiennych wejÅ›ciowych X i Y, doda to X<sup>2</sup>, XY i Y<sup>2</sup>. MoÅ¼emy rÃ³wnieÅ¼ uÅ¼yÄ‡ wielomianÃ³w wyÅ¼szego stopnia, jeÅ›li tego chcemy.

Pipeline moÅ¼na uÅ¼ywaÄ‡ w taki sam sposÃ³b, jak oryginalny obiekt `LinearRegression`, tj. moÅ¼emy dopasowaÄ‡ (`fit`) pipeline, a nastÄ™pnie uÅ¼yÄ‡ `predict`, aby uzyskaÄ‡ wyniki predykcji. Oto wykres pokazujÄ…cy dane testowe i krzywÄ… aproksymacji:

<img alt="Regresja wielomianowa" src="images/poly-results.png" width="50%" />

KorzystajÄ…c z regresji wielomianowej, moÅ¼emy uzyskaÄ‡ nieco niÅ¼szy MSE i wyÅ¼szy wspÃ³Å‚czynnik determinacji, ale nieznacznie. Musimy uwzglÄ™dniÄ‡ inne cechy!

> MoÅ¼esz zauwaÅ¼yÄ‡, Å¼e minimalne ceny dyni obserwuje siÄ™ gdzieÅ› w okolicach Halloween. Jak to wyjaÅ›nisz?

ğŸƒ Gratulacje, wÅ‚aÅ›nie stworzyÅ‚eÅ› model, ktÃ³ry moÅ¼e pomÃ³c przewidzieÄ‡ cenÄ™ dyni na ciasto. Prawdopodobnie moÅ¼esz powtÃ³rzyÄ‡ tÄ™ samÄ… procedurÄ™ dla wszystkich rodzajÃ³w dyni, ale byÅ‚oby to Å¼mudne. Nauczmy siÄ™ teraz, jak uwzglÄ™dniÄ‡ rÃ³Å¼norodnoÅ›Ä‡ dyni w naszym modelu!

## Cechy kategoryczne

W idealnym Å›wiecie chcemy byÄ‡ w stanie przewidywaÄ‡ ceny dla rÃ³Å¼nych odmian dyni za pomocÄ… tego samego modelu. Jednak kolumna `Variety` rÃ³Å¼ni siÄ™ od takich kolumn jak `Month`, poniewaÅ¼ zawiera wartoÅ›ci nienumeryczne. Takie kolumny nazywamy **kategorycznymi**.

[![ML dla poczÄ…tkujÄ…cych - Predykcja cech kategorycznych za pomocÄ… regresji liniowej](https://img.youtube.com/vi/DYGliioIAE0/0.jpg)](https://youtu.be/DYGliioIAE0 "ML dla poczÄ…tkujÄ…cych - Predykcja cech kategorycznych za pomocÄ… regresji liniowej")

> ğŸ¥ Kliknij obrazek powyÅ¼ej, aby obejrzeÄ‡ krÃ³tki film o uÅ¼ywaniu cech kategorycznych.

Tutaj moÅ¼esz zobaczyÄ‡, jak Å›rednia cena zaleÅ¼y od odmiany:

<img alt="Åšrednia cena wedÅ‚ug odmiany" src="images/price-by-variety.png" width="50%" />

Aby uwzglÄ™dniÄ‡ odmianÄ™, najpierw musimy przekonwertowaÄ‡ jÄ… na formÄ™ numerycznÄ…, czyli **zakodowaÄ‡**. Istnieje kilka sposobÃ³w, aby to zrobiÄ‡:

* Proste **kodowanie numeryczne** utworzy tabelÄ™ rÃ³Å¼nych odmian, a nastÄ™pnie zastÄ…pi nazwÄ™ odmiany indeksem w tej tabeli. Nie jest to najlepszy pomysÅ‚ dla regresji liniowej, poniewaÅ¼ regresja liniowa uwzglÄ™dnia rzeczywistÄ… wartoÅ›Ä‡ liczbowÄ… indeksu i dodaje jÄ… do wyniku, mnoÅ¼Ä…c przez pewien wspÃ³Å‚czynnik. W naszym przypadku zaleÅ¼noÅ›Ä‡ miÄ™dzy numerem indeksu a cenÄ… jest wyraÅºnie nieliniowa, nawet jeÅ›li upewnimy siÄ™, Å¼e indeksy sÄ… uporzÄ…dkowane w okreÅ›lony sposÃ³b.
* **Kodowanie one-hot** zastÄ…pi kolumnÄ™ `Variety` czterema rÃ³Å¼nymi kolumnami, po jednej dla kaÅ¼dej odmiany. KaÅ¼da kolumna bÄ™dzie zawieraÄ‡ `1`, jeÅ›li odpowiedni wiersz dotyczy danej odmiany, i `0` w przeciwnym razie. Oznacza to, Å¼e w regresji liniowej bÄ™dÄ… cztery wspÃ³Å‚czynniki, po jednym dla kaÅ¼dej odmiany dyni, odpowiedzialne za "cenÄ™ poczÄ…tkowÄ…" (lub raczej "dodatkowÄ… cenÄ™") dla danej odmiany.

PoniÅ¼szy kod pokazuje, jak moÅ¼emy zakodowaÄ‡ odmianÄ™ za pomocÄ… one-hot:

```python
pd.get_dummies(new_pumpkins['Variety'])
```  

 ID | FAIRYTALE | MINIATURE | MIXED HEIRLOOM VARIETIES | PIE TYPE  
----|-----------|-----------|--------------------------|----------  
70 | 0 | 0 | 0 | 1  
71 | 0 | 0 | 0 | 1  
... | ... | ... | ... | ...  
1738 | 0 | 1 | 0 | 0  
1739 | 0 | 1 | 0 | 0  
1740 | 0 | 1 | 0 | 0  
1741 | 0 | 1 | 0 | 0  
1742 | 0 | 1 | 0 | 0  

Aby przeprowadziÄ‡ trening regresji liniowej z zakodowanÄ… odmianÄ… jako wejÅ›ciem, wystarczy poprawnie zainicjalizowaÄ‡ dane `X` i `y`:

```python
X = pd.get_dummies(new_pumpkins['Variety'])
y = new_pumpkins['Price']
```  

Reszta kodu jest taka sama jak ta, ktÃ³rej uÅ¼yliÅ›my powyÅ¼ej do trenowania regresji liniowej. JeÅ›li to wyprÃ³bujesz, zobaczysz, Å¼e Å›redni bÅ‚Ä…d kwadratowy (MSE) jest mniej wiÄ™cej taki sam, ale uzyskujemy znacznie wyÅ¼szy wspÃ³Å‚czynnik determinacji (~77%). Aby uzyskaÄ‡ jeszcze dokÅ‚adniejsze przewidywania, moÅ¼emy uwzglÄ™dniÄ‡ wiÄ™cej cech kategorycznych, a takÅ¼e cechy numeryczne, takie jak `Month` lub `DayOfYear`. Aby uzyskaÄ‡ jednÄ… duÅ¼Ä… tablicÄ™ cech, moÅ¼emy uÅ¼yÄ‡ `join`:

```python
X = pd.get_dummies(new_pumpkins['Variety']) \
        .join(new_pumpkins['Month']) \
        .join(pd.get_dummies(new_pumpkins['City'])) \
        .join(pd.get_dummies(new_pumpkins['Package']))
y = new_pumpkins['Price']
```  

Tutaj uwzglÄ™dniamy rÃ³wnieÅ¼ `City` i typ `Package`, co daje nam MSE 2,84 (10%) i wspÃ³Å‚czynnik determinacji 0,94!

## Podsumowanie

Aby stworzyÄ‡ najlepszy model, moÅ¼emy uÅ¼yÄ‡ poÅ‚Ä…czonych danych (zakodowane kategoryczne + numeryczne) z powyÅ¼szego przykÅ‚adu razem z regresjÄ… wielomianowÄ…. Oto kompletny kod dla wygody:

```python
# set up training data
X = pd.get_dummies(new_pumpkins['Variety']) \
        .join(new_pumpkins['Month']) \
        .join(pd.get_dummies(new_pumpkins['City'])) \
        .join(pd.get_dummies(new_pumpkins['Package']))
y = new_pumpkins['Price']

# make train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# setup and train the pipeline
pipeline = make_pipeline(PolynomialFeatures(2), LinearRegression())
pipeline.fit(X_train,y_train)

# predict results for test data
pred = pipeline.predict(X_test)

# calculate MSE and determination
mse = np.sqrt(mean_squared_error(y_test,pred))
print(f'Mean error: {mse:3.3} ({mse/np.mean(pred)*100:3.3}%)')

score = pipeline.score(X_train,y_train)
print('Model determination: ', score)
```  

To powinno daÄ‡ nam najlepszy wspÃ³Å‚czynnik determinacji wynoszÄ…cy prawie 97% i MSE=2,23 (~8% bÅ‚Ä™du predykcji).

| Model | MSE | Determinacja |  
|-------|-----|--------------|  
| `DayOfYear` Liniowy | 2,77 (17,2%) | 0,07 |  
| `DayOfYear` Wielomianowy | 2,73 (17,0%) | 0,08 |  
| `Variety` Liniowy | 5,24 (19,7%) | 0,77 |  
| Wszystkie cechy Liniowy | 2,84 (10,5%) | 0,94 |  
| Wszystkie cechy Wielomianowy | 2,23 (8,25%) | 0,97 |  

ğŸ† Brawo! StworzyÅ‚eÅ› cztery modele regresji w jednej lekcji i poprawiÅ‚eÅ› jakoÅ›Ä‡ modelu do 97%. W ostatniej sekcji dotyczÄ…cej regresji nauczysz siÄ™ o regresji logistycznej do okreÅ›lania kategorii.

---  
## ğŸš€ Wyzwanie  

Przetestuj kilka rÃ³Å¼nych zmiennych w tym notebooku, aby zobaczyÄ‡, jak korelacja wpÅ‚ywa na dokÅ‚adnoÅ›Ä‡ modelu.

## [Quiz po lekcji](https://ff-quizzes.netlify.app/en/ml/)

## PrzeglÄ…d i samodzielna nauka  

W tej lekcji nauczyliÅ›my siÄ™ o regresji liniowej. IstniejÄ… inne waÅ¼ne rodzaje regresji. Przeczytaj o technikach Stepwise, Ridge, Lasso i Elasticnet. Dobrym kursem do nauki jest [kurs Statystycznego Uczenia siÄ™ Stanforda](https://online.stanford.edu/courses/sohs-ystatslearning-statistical-learning).

## Zadanie  

[Zbuduj model](assignment.md)  

---

**ZastrzeÅ¼enie**:  
Ten dokument zostaÅ‚ przetÅ‚umaczony za pomocÄ… usÅ‚ugi tÅ‚umaczeniowej AI [Co-op Translator](https://github.com/Azure/co-op-translator). ChociaÅ¼ dokÅ‚adamy wszelkich staraÅ„, aby tÅ‚umaczenie byÅ‚o precyzyjne, prosimy pamiÄ™taÄ‡, Å¼e automatyczne tÅ‚umaczenia mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jego rodzimym jÄ™zyku powinien byÄ‡ uznawany za wiarygodne ÅºrÃ³dÅ‚o. W przypadku informacji krytycznych zaleca siÄ™ skorzystanie z profesjonalnego tÅ‚umaczenia wykonanego przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za jakiekolwiek nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z korzystania z tego tÅ‚umaczenia.