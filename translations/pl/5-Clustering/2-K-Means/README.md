<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7cdd17338d9bbd7e2171c2cd462eb081",
  "translation_date": "2025-09-05T08:17:54+00:00",
  "source_file": "5-Clustering/2-K-Means/README.md",
  "language_code": "pl"
}
-->
# Klasteryzacja metodÄ… K-Means

## [Quiz przed wykÅ‚adem](https://ff-quizzes.netlify.app/en/ml/)

W tej lekcji nauczysz siÄ™ tworzyÄ‡ klastry za pomocÄ… biblioteki Scikit-learn oraz nigeryjskiego zestawu danych muzycznych, ktÃ³ry zaimportowaÅ‚eÅ› wczeÅ›niej. OmÃ³wimy podstawy metody K-Means dla klasteryzacji. PamiÄ™taj, Å¼e jak nauczyÅ‚eÅ› siÄ™ w poprzedniej lekcji, istnieje wiele sposobÃ³w pracy z klastrami, a metoda, ktÃ³rÄ… wybierzesz, zaleÅ¼y od Twoich danych. SprÃ³bujemy metody K-Means, poniewaÅ¼ jest to najczÄ™Å›ciej stosowana technika klasteryzacji. Zaczynajmy!

PojÄ™cia, ktÃ³re poznasz:

- Ocena sylwetki (Silhouette scoring)
- Metoda Å‚okcia (Elbow method)
- Inercja
- Wariancja

## Wprowadzenie

[Klasteryzacja metodÄ… K-Means](https://wikipedia.org/wiki/K-means_clustering) to metoda wywodzÄ…ca siÄ™ z dziedziny przetwarzania sygnaÅ‚Ã³w. SÅ‚uÅ¼y do dzielenia i grupowania danych w 'k' klastry za pomocÄ… serii obserwacji. KaÅ¼da obserwacja dziaÅ‚a na rzecz grupowania danego punktu danych najbliÅ¼ej jego 'Å›redniej', czyli punktu centralnego klastra.

Klastry moÅ¼na wizualizowaÄ‡ jako [diagramy Voronoi](https://wikipedia.org/wiki/Voronoi_diagram), ktÃ³re zawierajÄ… punkt (lub 'nasiono') i odpowiadajÄ…cy mu obszar.

![diagram Voronoi](../../../../5-Clustering/2-K-Means/images/voronoi.png)

> Infografika autorstwa [Jen Looper](https://twitter.com/jenlooper)

Proces klasteryzacji metodÄ… K-Means [wykonuje siÄ™ w trzech krokach](https://scikit-learn.org/stable/modules/clustering.html#k-means):

1. Algorytm wybiera k liczbÄ™ punktÃ³w centralnych, prÃ³bkujÄ…c z zestawu danych. NastÄ™pnie wykonuje pÄ™tlÄ™:
    1. Przypisuje kaÅ¼dÄ… prÃ³bkÄ™ do najbliÅ¼szego centroidu.
    2. Tworzy nowe centroidy, obliczajÄ…c Å›redniÄ… wartoÅ›Ä‡ wszystkich prÃ³bek przypisanych do poprzednich centroidÃ³w.
    3. NastÄ™pnie oblicza rÃ³Å¼nicÄ™ miÄ™dzy nowymi a starymi centroidami i powtarza proces, aÅ¼ centroidy siÄ™ ustabilizujÄ….

Jednym z minusÃ³w metody K-Means jest koniecznoÅ›Ä‡ ustalenia 'k', czyli liczby centroidÃ³w. Na szczÄ™Å›cie metoda 'Å‚okcia' pomaga oszacowaÄ‡ dobrÄ… wartoÅ›Ä‡ poczÄ…tkowÄ… dla 'k'. Zaraz jÄ… wyprÃ³bujesz.

## Wymagania wstÄ™pne

BÄ™dziesz pracowaÄ‡ w pliku [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/2-K-Means/notebook.ipynb), ktÃ³ry zawiera import danych i wstÄ™pne czyszczenie, ktÃ³re wykonaÅ‚eÅ› w poprzedniej lekcji.

## Ä†wiczenie - przygotowanie

Zacznij od ponownego przyjrzenia siÄ™ danym o piosenkach.

1. UtwÃ³rz wykres pudeÅ‚kowy, wywoÅ‚ujÄ…c `boxplot()` dla kaÅ¼dej kolumny:

    ```python
    plt.figure(figsize=(20,20), dpi=200)
    
    plt.subplot(4,3,1)
    sns.boxplot(x = 'popularity', data = df)
    
    plt.subplot(4,3,2)
    sns.boxplot(x = 'acousticness', data = df)
    
    plt.subplot(4,3,3)
    sns.boxplot(x = 'energy', data = df)
    
    plt.subplot(4,3,4)
    sns.boxplot(x = 'instrumentalness', data = df)
    
    plt.subplot(4,3,5)
    sns.boxplot(x = 'liveness', data = df)
    
    plt.subplot(4,3,6)
    sns.boxplot(x = 'loudness', data = df)
    
    plt.subplot(4,3,7)
    sns.boxplot(x = 'speechiness', data = df)
    
    plt.subplot(4,3,8)
    sns.boxplot(x = 'tempo', data = df)
    
    plt.subplot(4,3,9)
    sns.boxplot(x = 'time_signature', data = df)
    
    plt.subplot(4,3,10)
    sns.boxplot(x = 'danceability', data = df)
    
    plt.subplot(4,3,11)
    sns.boxplot(x = 'length', data = df)
    
    plt.subplot(4,3,12)
    sns.boxplot(x = 'release_date', data = df)
    ```

    Dane sÄ… trochÄ™ haÅ‚aÅ›liwe: obserwujÄ…c kaÅ¼dÄ… kolumnÄ™ jako wykres pudeÅ‚kowy, moÅ¼esz zauwaÅ¼yÄ‡ wartoÅ›ci odstajÄ…ce.

    ![wartoÅ›ci odstajÄ…ce](../../../../5-Clustering/2-K-Means/images/boxplots.png)

MoÅ¼esz przejrzeÄ‡ zestaw danych i usunÄ…Ä‡ te wartoÅ›ci odstajÄ…ce, ale to sprawiÅ‚oby, Å¼e dane byÅ‚yby doÅ›Ä‡ ograniczone.

1. Na razie wybierz kolumny, ktÃ³re wykorzystasz w Ä‡wiczeniu klasteryzacji. Wybierz te o podobnych zakresach i zakoduj kolumnÄ™ `artist_top_genre` jako dane numeryczne:

    ```python
    from sklearn.preprocessing import LabelEncoder
    le = LabelEncoder()
    
    X = df.loc[:, ('artist_top_genre','popularity','danceability','acousticness','loudness','energy')]
    
    y = df['artist_top_genre']
    
    X['artist_top_genre'] = le.fit_transform(X['artist_top_genre'])
    
    y = le.transform(y)
    ```

1. Teraz musisz wybraÄ‡, ile klastrÃ³w chcesz utworzyÄ‡. Wiesz, Å¼e w zestawie danych wyodrÄ™bniliÅ›my 3 gatunki muzyczne, wiÄ™c sprÃ³bujmy z 3:

    ```python
    from sklearn.cluster import KMeans
    
    nclusters = 3 
    seed = 0
    
    km = KMeans(n_clusters=nclusters, random_state=seed)
    km.fit(X)
    
    # Predict the cluster for each data point
    
    y_cluster_kmeans = km.predict(X)
    y_cluster_kmeans
    ```

Zobaczysz wydrukowanÄ… tablicÄ™ z przewidywanymi klastrami (0, 1 lub 2) dla kaÅ¼dego wiersza ramki danych.

1. UÅ¼yj tej tablicy, aby obliczyÄ‡ 'ocenÄ™ sylwetki':

    ```python
    from sklearn import metrics
    score = metrics.silhouette_score(X, y_cluster_kmeans)
    score
    ```

## Ocena sylwetki

Szukaj oceny sylwetki bliÅ¼szej 1. Wynik ten waha siÄ™ od -1 do 1, a jeÅ›li wynik wynosi 1, klaster jest gÄ™sty i dobrze oddzielony od innych klastrÃ³w. WartoÅ›Ä‡ bliska 0 oznacza nakÅ‚adajÄ…ce siÄ™ klastry, w ktÃ³rych prÃ³bki znajdujÄ… siÄ™ bardzo blisko granicy decyzyjnej sÄ…siednich klastrÃ³w. [(Å¹rÃ³dÅ‚o)](https://dzone.com/articles/kmeans-silhouette-score-explained-with-python-exam)

Nasz wynik to **0.53**, czyli w samym Å›rodku. Wskazuje to, Å¼e nasze dane nie sÄ… szczegÃ³lnie dobrze dopasowane do tego typu klasteryzacji, ale kontynuujmy.

### Ä†wiczenie - budowa modelu

1. Zaimportuj `KMeans` i rozpocznij proces klasteryzacji.

    ```python
    from sklearn.cluster import KMeans
    wcss = []
    
    for i in range(1, 11):
        kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)
        kmeans.fit(X)
        wcss.append(kmeans.inertia_)
    
    ```

    Jest tu kilka elementÃ³w, ktÃ³re warto wyjaÅ›niÄ‡.

    > ğŸ“ range: SÄ… to iteracje procesu klasteryzacji.

    > ğŸ“ random_state: "OkreÅ›la generowanie liczb losowych dla inicjalizacji centroidÃ³w." [Å¹rÃ³dÅ‚o](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)

    > ğŸ“ WCSS: "suma kwadratÃ³w wewnÄ…trz klastra" mierzy Å›redniÄ… kwadratowÄ… odlegÅ‚oÅ›Ä‡ wszystkich punktÃ³w w klastrze od centroidu klastra. [Å¹rÃ³dÅ‚o](https://medium.com/@ODSC/unsupervised-learning-evaluating-clusters-bd47eed175ce).

    > ğŸ“ Inercja: Algorytmy K-Means prÃ³bujÄ… wybraÄ‡ centroidy, aby zminimalizowaÄ‡ 'inercjÄ™', "miarÄ™ spÃ³jnoÅ›ci wewnÄ™trznej klastrÃ³w." [Å¹rÃ³dÅ‚o](https://scikit-learn.org/stable/modules/clustering.html). WartoÅ›Ä‡ jest dodawana do zmiennej wcss przy kaÅ¼dej iteracji.

    > ğŸ“ k-means++: W [Scikit-learn](https://scikit-learn.org/stable/modules/clustering.html#k-means) moÅ¼esz uÅ¼yÄ‡ optymalizacji 'k-means++', ktÃ³ra "inicjalizuje centroidy tak, aby byÅ‚y (zazwyczaj) odlegÅ‚e od siebie, co prowadzi do prawdopodobnie lepszych wynikÃ³w niÅ¼ losowa inicjalizacja."

### Metoda Å‚okcia

WczeÅ›niej zaÅ‚oÅ¼yÅ‚eÅ›, Å¼e poniewaÅ¼ wyodrÄ™bniÅ‚eÅ› 3 gatunki muzyczne, powinieneÅ› wybraÄ‡ 3 klastry. Ale czy na pewno?

1. UÅ¼yj metody 'Å‚okcia', aby siÄ™ upewniÄ‡.

    ```python
    plt.figure(figsize=(10,5))
    sns.lineplot(x=range(1, 11), y=wcss, marker='o', color='red')
    plt.title('Elbow')
    plt.xlabel('Number of clusters')
    plt.ylabel('WCSS')
    plt.show()
    ```

    UÅ¼yj zmiennej `wcss`, ktÃ³rÄ… zbudowaÅ‚eÅ› w poprzednim kroku, aby stworzyÄ‡ wykres pokazujÄ…cy, gdzie znajduje siÄ™ 'zgiÄ™cie' Å‚okcia, co wskazuje optymalnÄ… liczbÄ™ klastrÃ³w. MoÅ¼e rzeczywiÅ›cie jest to **3**!

    ![metoda Å‚okcia](../../../../5-Clustering/2-K-Means/images/elbow.png)

## Ä†wiczenie - wyÅ›wietlanie klastrÃ³w

1. SprÃ³buj ponownie przeprowadziÄ‡ proces, tym razem ustawiajÄ…c trzy klastry, i wyÅ›wietl klastry jako wykres punktowy:

    ```python
    from sklearn.cluster import KMeans
    kmeans = KMeans(n_clusters = 3)
    kmeans.fit(X)
    labels = kmeans.predict(X)
    plt.scatter(df['popularity'],df['danceability'],c = labels)
    plt.xlabel('popularity')
    plt.ylabel('danceability')
    plt.show()
    ```

1. SprawdÅº dokÅ‚adnoÅ›Ä‡ modelu:

    ```python
    labels = kmeans.labels_
    
    correct_labels = sum(y == labels)
    
    print("Result: %d out of %d samples were correctly labeled." % (correct_labels, y.size))
    
    print('Accuracy score: {0:0.2f}'. format(correct_labels/float(y.size)))
    ```

    DokÅ‚adnoÅ›Ä‡ tego modelu nie jest zbyt dobra, a ksztaÅ‚t klastrÃ³w daje Ci wskazÃ³wkÄ™ dlaczego.

    ![klastry](../../../../5-Clustering/2-K-Means/images/clusters.png)

    Dane sÄ… zbyt niezrÃ³wnowaÅ¼one, zbyt maÅ‚o skorelowane, a miÄ™dzy wartoÅ›ciami kolumn wystÄ™puje zbyt duÅ¼a wariancja, aby dobrze je sklasteryzowaÄ‡. W rzeczywistoÅ›ci klastry, ktÃ³re siÄ™ tworzÄ…, sÄ… prawdopodobnie mocno wpÅ‚ywane lub znieksztaÅ‚cone przez trzy kategorie gatunkÃ³w, ktÃ³re zdefiniowaliÅ›my powyÅ¼ej. To byÅ‚ proces nauki!

    W dokumentacji Scikit-learn moÅ¼esz zobaczyÄ‡, Å¼e model taki jak ten, z klastrami niezbyt dobrze oddzielonymi, ma problem z 'wariancjÄ…':

    ![problematyczne modele](../../../../5-Clustering/2-K-Means/images/problems.png)
    > Infografika z Scikit-learn

## Wariancja

Wariancja jest definiowana jako "Å›rednia kwadratÃ³w rÃ³Å¼nic od Å›redniej" [(Å¹rÃ³dÅ‚o)](https://www.mathsisfun.com/data/standard-deviation.html). W kontekÅ›cie tego problemu klasteryzacji odnosi siÄ™ do danych, w ktÃ³rych liczby w naszym zestawie danych majÄ… tendencjÄ™ do zbytniego odchylenia od Å›redniej.

âœ… To Å›wietny moment, aby pomyÅ›leÄ‡ o wszystkich sposobach, w jakie moÅ¼esz rozwiÄ…zaÄ‡ ten problem. DopracowaÄ‡ dane? UÅ¼yÄ‡ innych kolumn? WyprÃ³bowaÄ‡ inny algorytm? PodpowiedÅº: SprÃ³buj [skalowaÄ‡ dane](https://www.mygreatlearning.com/blog/learning-data-science-with-k-means-clustering/), aby je znormalizowaÄ‡ i przetestowaÄ‡ inne kolumny.

> WyprÃ³buj ten '[kalkulator wariancji](https://www.calculatorsoup.com/calculators/statistics/variance-calculator.php)', aby lepiej zrozumieÄ‡ to pojÄ™cie.

---

## ğŸš€Wyzwanie

SpÄ™dÅº trochÄ™ czasu z tym notebookiem, dopracowujÄ…c parametry. Czy moÅ¼esz poprawiÄ‡ dokÅ‚adnoÅ›Ä‡ modelu, bardziej oczyszczajÄ…c dane (na przykÅ‚ad usuwajÄ…c wartoÅ›ci odstajÄ…ce)? MoÅ¼esz uÅ¼yÄ‡ wag, aby nadaÄ‡ wiÄ™kszÄ… wagÄ™ okreÅ›lonym prÃ³bkom danych. Co jeszcze moÅ¼esz zrobiÄ‡, aby stworzyÄ‡ lepsze klastry?

PodpowiedÅº: SprÃ³buj skalowaÄ‡ dane. W notebooku znajdziesz zakomentowany kod, ktÃ³ry dodaje standardowe skalowanie, aby kolumny danych bardziej przypominaÅ‚y siebie nawzajem pod wzglÄ™dem zakresu. ZauwaÅ¼ysz, Å¼e chociaÅ¼ ocena sylwetki spada, 'zgiÄ™cie' na wykresie Å‚okcia wygÅ‚adza siÄ™. Dzieje siÄ™ tak, poniewaÅ¼ pozostawienie danych nieskalowanych pozwala danym o mniejszej wariancji mieÄ‡ wiÄ™kszy wpÅ‚yw. Przeczytaj wiÄ™cej o tym problemie [tutaj](https://stats.stackexchange.com/questions/21222/are-mean-normalization-and-feature-scaling-needed-for-k-means-clustering/21226#21226).

## [Quiz po wykÅ‚adzie](https://ff-quizzes.netlify.app/en/ml/)

## PrzeglÄ…d i samodzielna nauka

SpÃ³jrz na symulator K-Means [taki jak ten](https://user.ceng.metu.edu.tr/~akifakkus/courses/ceng574/k-means/). MoÅ¼esz uÅ¼yÄ‡ tego narzÄ™dzia, aby wizualizowaÄ‡ prÃ³bki danych i okreÅ›liÄ‡ ich centroidy. MoÅ¼esz edytowaÄ‡ losowoÅ›Ä‡ danych, liczbÄ™ klastrÃ³w i liczbÄ™ centroidÃ³w. Czy pomaga Ci to zrozumieÄ‡, jak dane mogÄ… byÄ‡ grupowane?

Zobacz takÅ¼e [ten materiaÅ‚ o K-Means](https://stanford.edu/~cpiech/cs221/handouts/kmeans.html) ze Stanfordu.

## Zadanie

[WyprÃ³buj rÃ³Å¼ne metody klasteryzacji](assignment.md)

---

**ZastrzeÅ¼enie**:  
Ten dokument zostaÅ‚ przetÅ‚umaczony za pomocÄ… usÅ‚ugi tÅ‚umaczeniowej AI [Co-op Translator](https://github.com/Azure/co-op-translator). ChociaÅ¼ dokÅ‚adamy wszelkich staraÅ„, aby tÅ‚umaczenie byÅ‚o precyzyjne, prosimy pamiÄ™taÄ‡, Å¼e automatyczne tÅ‚umaczenia mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jego rodzimym jÄ™zyku powinien byÄ‡ uznawany za wiarygodne ÅºrÃ³dÅ‚o. W przypadku informacji krytycznych zaleca siÄ™ skorzystanie z profesjonalnego tÅ‚umaczenia wykonanego przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za jakiekolwiek nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z korzystania z tego tÅ‚umaczenia.