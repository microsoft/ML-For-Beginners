<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ba0f6e1019351351c8ee4c92867b6a0b",
  "translation_date": "2025-09-03T17:28:33+00:00",
  "source_file": "9-Real-World/2-Debugging-ML-Models/README.md",
  "language_code": "pl"
}
-->
# Postscript: Debugowanie modeli uczenia maszynowego za pomocÄ… komponentÃ³w dashboardu Responsible AI

## [Quiz przed wykÅ‚adem](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/5/)

## Wprowadzenie

Uczenie maszynowe wpÅ‚ywa na nasze codzienne Å¼ycie. Sztuczna inteligencja znajduje zastosowanie w najwaÅ¼niejszych systemach, ktÃ³re oddziaÅ‚ujÄ… na nas jako jednostki oraz na nasze spoÅ‚eczeÅ„stwo, takich jak opieka zdrowotna, finanse, edukacja czy zatrudnienie. Na przykÅ‚ad systemy i modele sÄ… zaangaÅ¼owane w codzienne procesy decyzyjne, takie jak diagnozy medyczne czy wykrywanie oszustw. Wraz z postÄ™pem w dziedzinie AI oraz jej przyspieszonÄ… adopcjÄ… rosnÄ… oczekiwania spoÅ‚eczne i regulacje. WciÄ…Å¼ widzimy obszary, w ktÃ³rych systemy AI zawodzÄ…, ujawniajÄ… nowe wyzwania, a rzÄ…dy zaczynajÄ… regulowaÄ‡ rozwiÄ…zania AI. Dlatego waÅ¼ne jest, aby te modele byÅ‚y analizowane pod kÄ…tem zapewnienia sprawiedliwych, wiarygodnych, inkluzywnych, przejrzystych i odpowiedzialnych wynikÃ³w dla wszystkich.

W tym kursie przyjrzymy siÄ™ praktycznym narzÄ™dziom, ktÃ³re moÅ¼na wykorzystaÄ‡ do oceny, czy model ma problemy zwiÄ…zane z odpowiedzialnÄ… AI. Tradycyjne techniki debugowania uczenia maszynowego opierajÄ… siÄ™ gÅ‚Ã³wnie na obliczeniach iloÅ›ciowych, takich jak zsumowana dokÅ‚adnoÅ›Ä‡ czy Å›rednia strata bÅ‚Ä™du. WyobraÅº sobie, co moÅ¼e siÄ™ staÄ‡, gdy dane, ktÃ³rych uÅ¼ywasz do budowy tych modeli, nie uwzglÄ™dniajÄ… pewnych demografii, takich jak rasa, pÅ‚eÄ‡, poglÄ…dy polityczne, religia, lub sÄ… nadmiernie reprezentowane w tych demografiach. Co w sytuacji, gdy wyniki modelu sÄ… interpretowane jako faworyzujÄ…ce pewnÄ… grupÄ™ demograficznÄ…? MoÅ¼e to prowadziÄ‡ do nadmiernej lub niedostatecznej reprezentacji tych wraÅ¼liwych grup cech, co skutkuje problemami ze sprawiedliwoÅ›ciÄ…, inkluzywnoÅ›ciÄ… lub wiarygodnoÅ›ciÄ… modelu. Dodatkowo, modele uczenia maszynowego sÄ… czÄ™sto traktowane jako "czarne skrzynki", co utrudnia zrozumienie i wyjaÅ›nienie, co napÄ™dza ich prognozy. Wszystkie te wyzwania stojÄ… przed naukowcami zajmujÄ…cymi siÄ™ danymi i twÃ³rcami AI, ktÃ³rzy nie dysponujÄ… odpowiednimi narzÄ™dziami do debugowania i oceny sprawiedliwoÅ›ci czy wiarygodnoÅ›ci modelu.

W tej lekcji nauczysz siÄ™ debugowania swoich modeli za pomocÄ…:

- **Analizy bÅ‚Ä™dÃ³w**: identyfikacja obszarÃ³w w rozkÅ‚adzie danych, gdzie model ma wysokie wskaÅºniki bÅ‚Ä™dÃ³w.
- **PrzeglÄ…du modelu**: przeprowadzenie analizy porÃ³wnawczej miÄ™dzy rÃ³Å¼nymi grupami danych w celu odkrycia rozbieÅ¼noÅ›ci w metrykach wydajnoÅ›ci modelu.
- **Analizy danych**: badanie, gdzie moÅ¼e wystÄ™powaÄ‡ nadmierna lub niedostateczna reprezentacja danych, ktÃ³ra moÅ¼e wpÅ‚ywaÄ‡ na faworyzowanie jednej grupy demograficznej wzglÄ™dem innej.
- **WaÅ¼noÅ›ci cech**: zrozumienie, ktÃ³re cechy napÄ™dzajÄ… prognozy modelu na poziomie globalnym lub lokalnym.

## Wymagania wstÄ™pne

Przed rozpoczÄ™ciem zapoznaj siÄ™ z materiaÅ‚em [NarzÄ™dzia odpowiedzialnej AI dla programistÃ³w](https://www.microsoft.com/ai/ai-lab-responsible-ai-dashboard)

> ![Gif dotyczÄ…cy narzÄ™dzi odpowiedzialnej AI](../../../../9-Real-World/2-Debugging-ML-Models/images/rai-overview.gif)

## Analiza bÅ‚Ä™dÃ³w

Tradycyjne metryki wydajnoÅ›ci modelu uÅ¼ywane do mierzenia dokÅ‚adnoÅ›ci to gÅ‚Ã³wnie obliczenia oparte na poprawnych i niepoprawnych prognozach. Na przykÅ‚ad stwierdzenie, Å¼e model jest dokÅ‚adny w 89% przypadkÃ³w przy stracie bÅ‚Ä™du wynoszÄ…cej 0,001, moÅ¼e byÄ‡ uznane za dobrÄ… wydajnoÅ›Ä‡. BÅ‚Ä™dy nie sÄ… jednak rÃ³wnomiernie rozÅ‚oÅ¼one w podstawowym zbiorze danych. MoÅ¼esz uzyskaÄ‡ wynik dokÅ‚adnoÅ›ci modelu na poziomie 89%, ale odkryÄ‡, Å¼e w rÃ³Å¼nych obszarach danych model zawodzi w 42% przypadkÃ³w. Konsekwencje takich wzorcÃ³w bÅ‚Ä™dÃ³w w okreÅ›lonych grupach danych mogÄ… prowadziÄ‡ do problemÃ³w ze sprawiedliwoÅ›ciÄ… lub wiarygodnoÅ›ciÄ…. WaÅ¼ne jest, aby zrozumieÄ‡ obszary, w ktÃ³rych model dziaÅ‚a dobrze lub Åºle. Obszary danych, w ktÃ³rych wystÄ™puje wysoka liczba nieÅ›cisÅ‚oÅ›ci w modelu, mogÄ… okazaÄ‡ siÄ™ istotnymi grupami danych.

![Analiza i debugowanie bÅ‚Ä™dÃ³w modelu](../../../../translated_images/ea-error-distribution.117452e1177c1dd84fab2369967a68bcde787c76c6ea7fdb92fcf15d1fce8206.pl.png)

Komponent Analizy BÅ‚Ä™dÃ³w na dashboardzie RAI ilustruje, jak poraÅ¼ki modelu sÄ… rozÅ‚oÅ¼one w rÃ³Å¼nych grupach danych za pomocÄ… wizualizacji drzewa. Jest to przydatne w identyfikacji cech lub obszarÃ³w, w ktÃ³rych wystÄ™puje wysoki wskaÅºnik bÅ‚Ä™dÃ³w w zbiorze danych. WidzÄ…c, skÄ…d pochodzi wiÄ™kszoÅ›Ä‡ nieÅ›cisÅ‚oÅ›ci modelu, moÅ¼esz zaczÄ…Ä‡ badaÄ‡ ich przyczynÄ™. MoÅ¼esz rÃ³wnieÅ¼ tworzyÄ‡ grupy danych do analizy. Te grupy danych pomagajÄ… w procesie debugowania, aby okreÅ›liÄ‡, dlaczego wydajnoÅ›Ä‡ modelu jest dobra w jednej grupie, a bÅ‚Ä™dna w innej.

![Analiza bÅ‚Ä™dÃ³w](../../../../translated_images/ea-error-cohort.6886209ea5d438c4daa8bfbf5ce3a7042586364dd3eccda4a4e3d05623ac702a.pl.png)

WskaÅºniki wizualne na mapie drzewa pomagajÄ… szybciej zlokalizowaÄ‡ problematyczne obszary. Na przykÅ‚ad im ciemniejszy odcieÅ„ czerwieni na wÄ™Åºle drzewa, tym wyÅ¼szy wskaÅºnik bÅ‚Ä™dÃ³w.

Mapa cieplna to kolejna funkcjonalnoÅ›Ä‡ wizualizacji, ktÃ³rÄ… uÅ¼ytkownicy mogÄ… wykorzystaÄ‡ do badania wskaÅºnika bÅ‚Ä™dÃ³w za pomocÄ… jednej lub dwÃ³ch cech, aby znaleÅºÄ‡ przyczynÄ™ bÅ‚Ä™dÃ³w modelu w caÅ‚ym zbiorze danych lub grupach.

![Mapa cieplna analizy bÅ‚Ä™dÃ³w](../../../../translated_images/ea-heatmap.8d27185e28cee3830c85e1b2e9df9d2d5e5c8c940f41678efdb68753f2f7e56c.pl.png)

UÅ¼yj analizy bÅ‚Ä™dÃ³w, gdy potrzebujesz:

* DogÅ‚Ä™bnego zrozumienia, jak poraÅ¼ki modelu sÄ… rozÅ‚oÅ¼one w zbiorze danych i w rÃ³Å¼nych wymiarach wejÅ›ciowych oraz cech.
* Rozbicia zsumowanych metryk wydajnoÅ›ci w celu automatycznego odkrycia bÅ‚Ä™dnych grup danych, ktÃ³re mogÄ… informowaÄ‡ o krokach naprawczych.

## PrzeglÄ…d modelu

Ocena wydajnoÅ›ci modelu uczenia maszynowego wymaga holistycznego zrozumienia jego zachowania. MoÅ¼na to osiÄ…gnÄ…Ä‡ poprzez przeglÄ…d wiÄ™cej niÅ¼ jednej metryki, takiej jak wskaÅºnik bÅ‚Ä™dÃ³w, dokÅ‚adnoÅ›Ä‡, recall, precyzja czy MAE (Å›redni bÅ‚Ä…d absolutny), aby znaleÅºÄ‡ rozbieÅ¼noÅ›ci miÄ™dzy metrykami wydajnoÅ›ci. Jedna metryka wydajnoÅ›ci moÅ¼e wyglÄ…daÄ‡ Å›wietnie, ale niedokÅ‚adnoÅ›ci mogÄ… ujawniÄ‡ siÄ™ w innej metryce. Dodatkowo, porÃ³wnanie metryk pod kÄ…tem rozbieÅ¼noÅ›ci w caÅ‚ym zbiorze danych lub grupach pomaga rzuciÄ‡ Å›wiatÅ‚o na to, gdzie model dziaÅ‚a dobrze, a gdzie nie. Jest to szczegÃ³lnie waÅ¼ne w ocenie wydajnoÅ›ci modelu wÅ›rÃ³d cech wraÅ¼liwych i niewraÅ¼liwych (np. rasa pacjenta, pÅ‚eÄ‡ czy wiek), aby odkryÄ‡ potencjalnÄ… niesprawiedliwoÅ›Ä‡ modelu. Na przykÅ‚ad odkrycie, Å¼e model jest bardziej bÅ‚Ä™dny w grupie danych zawierajÄ…cej cechy wraÅ¼liwe, moÅ¼e ujawniÄ‡ potencjalnÄ… niesprawiedliwoÅ›Ä‡ modelu.

Komponent PrzeglÄ…du Modelu na dashboardzie RAI pomaga nie tylko w analizie metryk wydajnoÅ›ci reprezentacji danych w grupie, ale daje uÅ¼ytkownikom moÅ¼liwoÅ›Ä‡ porÃ³wnania zachowania modelu w rÃ³Å¼nych grupach.

![Grupy danych - przeglÄ…d modelu na dashboardzie RAI](../../../../translated_images/model-overview-dataset-cohorts.dfa463fb527a35a0afc01b7b012fc87bf2cad756763f3652bbd810cac5d6cf33.pl.png)

FunkcjonalnoÅ›Ä‡ analizy oparta na cechach pozwala uÅ¼ytkownikom zawÄ™ziÄ‡ podgrupy danych w ramach konkretnej cechy, aby zidentyfikowaÄ‡ anomalie na poziomie szczegÃ³Å‚owym. Na przykÅ‚ad dashboard ma wbudowanÄ… inteligencjÄ™, ktÃ³ra automatycznie generuje grupy dla wybranej przez uÅ¼ytkownika cechy (np. *"time_in_hospital < 3"* lub *"time_in_hospital >= 7"*). UmoÅ¼liwia to uÅ¼ytkownikowi izolowanie konkretnej cechy z wiÄ™kszej grupy danych, aby sprawdziÄ‡, czy jest ona kluczowym czynnikiem wpÅ‚ywajÄ…cym na bÅ‚Ä™dne wyniki modelu.

![Grupy cech - przeglÄ…d modelu na dashboardzie RAI](../../../../translated_images/model-overview-feature-cohorts.c5104d575ffd0c80b7ad8ede7703fab6166bfc6f9125dd395dcc4ace2f522f70.pl.png)

Komponent PrzeglÄ…du Modelu obsÅ‚uguje dwa rodzaje metryk rozbieÅ¼noÅ›ci:

**RozbieÅ¼noÅ›Ä‡ w wydajnoÅ›ci modelu**: Te zestawy metryk obliczajÄ… rozbieÅ¼noÅ›Ä‡ (rÃ³Å¼nicÄ™) w wartoÅ›ciach wybranej metryki wydajnoÅ›ci w podgrupach danych. Oto kilka przykÅ‚adÃ³w:

* RozbieÅ¼noÅ›Ä‡ w wskaÅºniku dokÅ‚adnoÅ›ci
* RozbieÅ¼noÅ›Ä‡ w wskaÅºniku bÅ‚Ä™dÃ³w
* RozbieÅ¼noÅ›Ä‡ w precyzji
* RozbieÅ¼noÅ›Ä‡ w recall
* RozbieÅ¼noÅ›Ä‡ w Å›rednim bÅ‚Ä™dzie absolutnym (MAE)

**RozbieÅ¼noÅ›Ä‡ w wskaÅºniku selekcji**: Ta metryka zawiera rÃ³Å¼nicÄ™ w wskaÅºniku selekcji (korzystna prognoza) w podgrupach. PrzykÅ‚adem moÅ¼e byÄ‡ rozbieÅ¼noÅ›Ä‡ w wskaÅºnikach zatwierdzania kredytÃ³w. WskaÅºnik selekcji oznacza odsetek punktÃ³w danych w kaÅ¼dej klasie sklasyfikowanych jako 1 (w klasyfikacji binarnej) lub rozkÅ‚ad wartoÅ›ci prognoz (w regresji).

## Analiza danych

> "JeÅ›li wystarczajÄ…co dÅ‚ugo torturujesz dane, wyznajÄ… wszystko" - Ronald Coase

To stwierdzenie brzmi ekstremalnie, ale prawdÄ… jest, Å¼e dane mogÄ… byÄ‡ manipulowane, aby wspieraÄ‡ dowolny wniosek. Taka manipulacja moÅ¼e czasami zdarzyÄ‡ siÄ™ nieumyÅ›lnie. Jako ludzie wszyscy mamy uprzedzenia i czÄ™sto trudno jest Å›wiadomie wiedzieÄ‡, kiedy wprowadzamy uprzedzenia do danych. Zapewnienie sprawiedliwoÅ›ci w AI i uczeniu maszynowym pozostaje zÅ‚oÅ¼onym wyzwaniem.

Dane sÄ… ogromnym punktem Å›lepym dla tradycyjnych metryk wydajnoÅ›ci modelu. MoÅ¼esz mieÄ‡ wysokie wskaÅºniki dokÅ‚adnoÅ›ci, ale nie zawsze odzwierciedlajÄ… one ukryte uprzedzenia w danych, ktÃ³re mogÄ… znajdowaÄ‡ siÄ™ w twoim zbiorze danych. Na przykÅ‚ad, jeÅ›li zbiÃ³r danych pracownikÃ³w zawiera 27% kobiet na stanowiskach kierowniczych w firmie i 73% mÄ™Å¼czyzn na tym samym poziomie, model AI do reklamowania ofert pracy, ktÃ³ry zostaÅ‚ wytrenowany na tych danych, moÅ¼e kierowaÄ‡ siÄ™ gÅ‚Ã³wnie do mÄ™skiej grupy odbiorcÃ³w na stanowiska wyÅ¼szego szczebla. Taka nierÃ³wnowaga w danych wpÅ‚ynÄ™Å‚a na prognozy modelu, faworyzujÄ…c jednÄ… pÅ‚eÄ‡. To ujawnia problem ze sprawiedliwoÅ›ciÄ…, gdzie wystÄ™puje uprzedzenie pÅ‚ciowe w modelu AI.

Komponent Analizy Danych na dashboardzie RAI pomaga zidentyfikowaÄ‡ obszary, w ktÃ³rych wystÄ™puje nadmierna lub niedostateczna reprezentacja w zbiorze danych. Pomaga uÅ¼ytkownikom diagnozowaÄ‡ przyczyny bÅ‚Ä™dÃ³w i problemy ze sprawiedliwoÅ›ciÄ… wynikajÄ…ce z nierÃ³wnowagi danych lub braku reprezentacji okreÅ›lonej grupy danych. Daje uÅ¼ytkownikom moÅ¼liwoÅ›Ä‡ wizualizacji zbiorÃ³w danych na podstawie przewidywanych i rzeczywistych wynikÃ³w, grup bÅ‚Ä™dÃ³w oraz konkretnych cech. Czasami odkrycie niedoreprezentowanej grupy danych moÅ¼e rÃ³wnieÅ¼ ujawniÄ‡, Å¼e model nie uczy siÄ™ dobrze, co prowadzi do wysokich niedokÅ‚adnoÅ›ci. Model, ktÃ³ry ma uprzedzenia w danych, nie tylko ma problem ze sprawiedliwoÅ›ciÄ…, ale takÅ¼e pokazuje, Å¼e nie jest inkluzywny ani wiarygodny.

![Komponent Analizy Danych na dashboardzie RAI](../../../../translated_images/dataanalysis-cover.8d6d0683a70a5c1e274e5a94b27a71137e3d0a3b707761d7170eb340dd07f11d.pl.png)

UÅ¼yj analizy danych, gdy potrzebujesz:

* EksplorowaÄ‡ statystyki swojego zbioru danych, wybierajÄ…c rÃ³Å¼ne filtry, aby podzieliÄ‡ dane na rÃ³Å¼ne wymiary (znane rÃ³wnieÅ¼ jako grupy).
* ZrozumieÄ‡ rozkÅ‚ad swojego zbioru danych w rÃ³Å¼nych grupach i grupach cech.
* OkreÅ›liÄ‡, czy twoje odkrycia zwiÄ…zane ze sprawiedliwoÅ›ciÄ…, analizÄ… bÅ‚Ä™dÃ³w i przyczynowoÅ›ciÄ… (pochodzÄ…ce z innych komponentÃ³w dashboardu) sÄ… wynikiem rozkÅ‚adu twojego zbioru danych.
* ZdecydowaÄ‡, w ktÃ³rych obszarach naleÅ¼y zebraÄ‡ wiÄ™cej danych, aby zminimalizowaÄ‡ bÅ‚Ä™dy wynikajÄ…ce z problemÃ³w z reprezentacjÄ…, szumem etykiet, szumem cech, uprzedzeniami etykiet i podobnymi czynnikami.

## Interpretacja modelu

Modele uczenia maszynowego czÄ™sto sÄ… traktowane jako "czarne skrzynki". Zrozumienie, ktÃ³re kluczowe cechy danych napÄ™dzajÄ… prognozy modelu, moÅ¼e byÄ‡ trudne. WaÅ¼ne jest, aby zapewniÄ‡ przejrzystoÅ›Ä‡, dlaczego model dokonuje okreÅ›lonej prognozy. Na przykÅ‚ad, jeÅ›li system AI przewiduje, Å¼e pacjent z cukrzycÄ… jest zagroÅ¼ony ponownym przyjÄ™ciem do szpitala w ciÄ…gu mniej niÅ¼ 30 dni, powinien byÄ‡ w stanie dostarczyÄ‡ dane wspierajÄ…ce, ktÃ³re doprowadziÅ‚y do tej prognozy. Posiadanie wskaÅºnikÃ³w wspierajÄ…cych przynosi przejrzystoÅ›Ä‡, pomagajÄ…c klinikom lub szpitalom podejmowaÄ‡ dobrze poinformowane decyzje. Dodatkowo, moÅ¼liwoÅ›Ä‡ wyjaÅ›nienia, dlaczego model dokonaÅ‚ prognozy dla konkretnego pacjenta, umoÅ¼liwia odpowiedzialnoÅ›Ä‡ wobec regulacji zdrowotnych. Kiedy uÅ¼ywasz modeli uczenia maszynowego w sposÃ³b wpÅ‚ywajÄ…cy na Å¼ycie ludzi, kluczowe jest zrozumienie i wyjaÅ›nienie, co wpÅ‚ywa na zachowanie modelu. WyjaÅ›nialnoÅ›Ä‡ i interpretowalnoÅ›Ä‡ modelu pomagajÄ… odpowiedzieÄ‡ na pytania w scenariuszach takich jak:

* Debugowanie modelu: Dlaczego mÃ³j model popeÅ‚niÅ‚ ten bÅ‚Ä…d? Jak mogÄ™ go poprawiÄ‡?
* WspÃ³Å‚praca czÅ‚owiek-AI: Jak mogÄ™ zrozumieÄ‡ i zaufaÄ‡ decyzjom modelu?
* ZgodnoÅ›Ä‡ z regulacjami: Czy mÃ³j model speÅ‚nia wymagania prawne?

Komponent WaÅ¼noÅ›ci Cech na dashboardzie RAI pomaga debugowaÄ‡ i uzyskaÄ‡ kompleksowe zrozumienie, jak model dokonuje prognoz. Jest to rÃ³wnieÅ¼ przydatne narzÄ™dzie dla profesjonalistÃ³w zajmujÄ…cych siÄ™ uczeniem maszynowym oraz decydentÃ³w, aby wyjaÅ›niÄ‡ i pokazaÄ‡ dowody cech wpÅ‚ywajÄ…cych na zachowanie modelu w celu zgodnoÅ›ci z regulacjami. NastÄ™pnie uÅ¼ytkownicy mogÄ… eksplorowaÄ‡ zarÃ³wno globalne, jak i lokalne wyjaÅ›nienia, aby zweryfikowaÄ‡, ktÃ³re cechy napÄ™dzajÄ… prognozy modelu. Globalne wyjaÅ›nienia przedstawiajÄ… najwaÅ¼niejsze cechy, ktÃ³re wpÅ‚ynÄ™Å‚y na ogÃ³lnÄ… prognozÄ™ modelu. Lokalne wyjaÅ›nienia pokazujÄ…, ktÃ³re cechy doprowadziÅ‚y do prognozy modelu dla konkretnego przypadku. MoÅ¼liwoÅ›Ä‡ oceny lokalnych wyjaÅ›nieÅ„ jest rÃ³wnieÅ¼ pomocna w debugowaniu lub audytowaniu konkretnego przypadku, aby lepiej zrozumieÄ‡ i zinterpretowaÄ‡, dlaczego model dokonaÅ‚ poprawnej lub bÅ‚Ä™dnej prognozy.

![Komponent WaÅ¼noÅ›ci Cech na dashboardzie RAI](../../../../translated_images/9-feature-importance.cd3193b4bba3fd4bccd415f566c2437fb3298c4824a3dabbcab15270d783606e.pl.png)

* Globalne wyjaÅ›nienia: Na przykÅ‚ad, jakie cechy wpÅ‚ywajÄ… na ogÃ³lne zachowanie modelu przewidujÄ…cego ponowne przyjÄ™cie do szpitala pacjentÃ³w z cukrzycÄ…?
* Lokalne wyjaÅ›nienia: Na przykÅ‚ad, dlaczego pacjent z cukrzycÄ… powyÅ¼ej 60 roku Å¼ycia z wczeÅ›niejszymi hospitalizacjami zostaÅ‚ przewidziany jako ponownie przyjÄ™ty lub nieprzyjÄ™ty do szpitala w ciÄ…gu 30 dni?

W procesie debugowania wydajnoÅ›ci modelu w rÃ³Å¼nych grupach, WaÅ¼noÅ›Ä‡ Cech pokazuje, jaki poziom wpÅ‚ywu ma cecha w rÃ³Å¼nych grupach. Pomaga ujawniÄ‡ anomalie podczas porÃ³wnywania poziomu wpÅ‚ywu cechy na bÅ‚Ä™dne prognozy modelu. Komponent WaÅ¼noÅ›ci Cech moÅ¼e pokazaÄ‡, ktÃ³re wartoÅ›ci w cechach pozytywnie lub negatywnie wpÅ‚ynÄ™Å‚y na wynik modelu. Na przykÅ‚ad, jeÅ›li model dokonaÅ‚ bÅ‚Ä™dnej prognozy, komponent daje moÅ¼liwoÅ›Ä‡ zagÅ‚Ä™bienia siÄ™ i wskazania, ktÃ³re cechy lub wartoÅ›ci cech wpÅ‚ynÄ™Å‚y na prognozÄ™. Ten poziom szczegÃ³Å‚owoÅ›ci pomaga nie tylko w debugowaniu, ale takÅ¼e zapewnia przejrzystoÅ›Ä‡ i odpowiedzialnoÅ›Ä‡ w sytuacjach audytowych. Wreszcie, komponent moÅ¼e pomÃ³c w identyfikacji problemÃ³w ze sprawiedliwoÅ›ciÄ…. Na przykÅ‚ad, jeÅ›li wraÅ¼liwa cecha, taka jak pochodzenie etniczne lub pÅ‚eÄ‡, ma duÅ¼y wpÅ‚yw na prognozÄ™ modelu, moÅ¼e to byÄ‡ oznaka uprzedzeÅ„ ras
- **Nad- lub niedoreprezentowanie**. Chodzi o sytuacjÄ™, w ktÃ³rej pewna grupa nie jest widoczna w okreÅ›lonym zawodzie, a kaÅ¼da usÅ‚uga lub funkcja, ktÃ³ra to utrwala, przyczynia siÄ™ do szkody.

### Azure RAI dashboard

[Azure RAI dashboard](https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai-dashboard?WT.mc_id=aiml-90525-ruyakubu) opiera siÄ™ na narzÄ™dziach open-source opracowanych przez wiodÄ…ce instytucje akademickie i organizacje, w tym Microsoft. SÄ… one kluczowe dla data scientistÃ³w i twÃ³rcÃ³w AI, aby lepiej zrozumieÄ‡ zachowanie modeli, odkrywaÄ‡ i Å‚agodziÄ‡ niepoÅ¼Ä…dane problemy w modelach AI.

- Dowiedz siÄ™, jak korzystaÄ‡ z rÃ³Å¼nych komponentÃ³w, przeglÄ…dajÄ…c [dokumentacjÄ™ RAI dashboard.](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-responsible-ai-dashboard?WT.mc_id=aiml-90525-ruyakubu)

- SprawdÅº przykÅ‚adowe [notatniki RAI dashboard](https://github.com/Azure/RAI-vNext-Preview/tree/main/examples/notebooks) do debugowania bardziej odpowiedzialnych scenariuszy AI w Azure Machine Learning.

---
## ğŸš€ Wyzwanie

Aby zapobiec wprowadzaniu uprzedzeÅ„ statystycznych lub danych juÅ¼ na samym poczÄ…tku, powinniÅ›my:

- zapewniÄ‡ rÃ³Å¼norodnoÅ›Ä‡ Å›rodowisk i perspektyw wÅ›rÃ³d osÃ³b pracujÄ…cych nad systemami  
- inwestowaÄ‡ w zestawy danych odzwierciedlajÄ…ce rÃ³Å¼norodnoÅ›Ä‡ naszego spoÅ‚eczeÅ„stwa  
- rozwijaÄ‡ lepsze metody wykrywania i korygowania uprzedzeÅ„, gdy siÄ™ pojawiÄ…  

PomyÅ›l o rzeczywistych scenariuszach, w ktÃ³rych niesprawiedliwoÅ›Ä‡ jest widoczna podczas budowy i uÅ¼ytkowania modeli. Co jeszcze powinniÅ›my wziÄ…Ä‡ pod uwagÄ™?

## [Quiz po wykÅ‚adzie](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/6/)
## PrzeglÄ…d i samodzielna nauka

W tej lekcji poznaÅ‚eÅ› praktyczne narzÄ™dzia do wÅ‚Ä…czania odpowiedzialnej AI w uczeniu maszynowym.

Obejrzyj ten warsztat, aby zgÅ‚Ä™biÄ‡ temat:

- Responsible AI Dashboard: Jedno miejsce do wdraÅ¼ania odpowiedzialnej AI w praktyce, prowadzone przez BesmirÄ™ Nushi i Mehrnoosh Sameki

[![Responsible AI Dashboard: Jedno miejsce do wdraÅ¼ania odpowiedzialnej AI w praktyce](https://img.youtube.com/vi/f1oaDNl3djg/0.jpg)](https://www.youtube.com/watch?v=f1oaDNl3djg "Responsible AI Dashboard: Jedno miejsce do wdraÅ¼ania odpowiedzialnej AI w praktyce")

> ğŸ¥ Kliknij obrazek powyÅ¼ej, aby obejrzeÄ‡ wideo: Responsible AI Dashboard: Jedno miejsce do wdraÅ¼ania odpowiedzialnej AI w praktyce, prowadzone przez BesmirÄ™ Nushi i Mehrnoosh Sameki

Zapoznaj siÄ™ z poniÅ¼szymi materiaÅ‚ami, aby dowiedzieÄ‡ siÄ™ wiÄ™cej o odpowiedzialnej AI i jak budowaÄ‡ bardziej godne zaufania modele:

- NarzÄ™dzia Microsoft RAI dashboard do debugowania modeli ML: [Zasoby narzÄ™dzi Responsible AI](https://aka.ms/rai-dashboard)

- Odkryj zestaw narzÄ™dzi Responsible AI: [Github](https://github.com/microsoft/responsible-ai-toolbox)

- Centrum zasobÃ³w Microsoft RAI: [Responsible AI Resources â€“ Microsoft AI](https://www.microsoft.com/ai/responsible-ai-resources?activetab=pivot1%3aprimaryr4)

- Grupa badawcza Microsoft FATE: [FATE: Fairness, Accountability, Transparency, and Ethics in AI - Microsoft Research](https://www.microsoft.com/research/theme/fate/)

## Zadanie

[Zapoznaj siÄ™ z RAI dashboard](assignment.md)

---

**ZastrzeÅ¼enie**:  
Ten dokument zostaÅ‚ przetÅ‚umaczony za pomocÄ… usÅ‚ugi tÅ‚umaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). ChociaÅ¼ dokÅ‚adamy wszelkich staraÅ„, aby zapewniÄ‡ poprawnoÅ›Ä‡ tÅ‚umaczenia, prosimy pamiÄ™taÄ‡, Å¼e automatyczne tÅ‚umaczenia mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jego rodzimym jÄ™zyku powinien byÄ‡ uznawany za wiarygodne ÅºrÃ³dÅ‚o. W przypadku informacji o kluczowym znaczeniu zaleca siÄ™ skorzystanie z profesjonalnego tÅ‚umaczenia przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za jakiekolwiek nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z uÅ¼ycia tego tÅ‚umaczenia.