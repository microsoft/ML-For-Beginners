<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "df2b538e8fbb3e91cf0419ae2f858675",
  "translation_date": "2025-09-05T08:19:23+00:00",
  "source_file": "9-Real-World/2-Debugging-ML-Models/README.md",
  "language_code": "pl"
}
-->
# Postscript: Debugowanie modeli w uczeniu maszynowym za pomocÄ… komponentÃ³w pulpitu odpowiedzialnej AI

## [Quiz przed wykÅ‚adem](https://ff-quizzes.netlify.app/en/ml/)

## Wprowadzenie

Uczenie maszynowe wpÅ‚ywa na nasze codzienne Å¼ycie. Sztuczna inteligencja (AI) znajduje zastosowanie w jednych z najwaÅ¼niejszych systemÃ³w, ktÃ³re majÄ… wpÅ‚yw na nas jako jednostki i spoÅ‚eczeÅ„stwo, takich jak opieka zdrowotna, finanse, edukacja czy zatrudnienie. Na przykÅ‚ad systemy i modele sÄ… zaangaÅ¼owane w codzienne procesy decyzyjne, takie jak diagnozy medyczne czy wykrywanie oszustw. W zwiÄ…zku z tym postÄ™py w AI oraz jej przyspieszone wdraÅ¼anie spotykajÄ… siÄ™ z rosnÄ…cymi oczekiwaniami spoÅ‚ecznymi i regulacjami. WciÄ…Å¼ obserwujemy obszary, w ktÃ³rych systemy AI nie speÅ‚niajÄ… oczekiwaÅ„, ujawniajÄ… nowe wyzwania, a rzÄ…dy zaczynajÄ… regulowaÄ‡ rozwiÄ…zania AI. Dlatego waÅ¼ne jest, aby analizowaÄ‡ te modele, aby zapewniÄ‡ sprawiedliwe, wiarygodne, inkluzywne, przejrzyste i odpowiedzialne wyniki dla wszystkich.

W tym kursie przyjrzymy siÄ™ praktycznym narzÄ™dziom, ktÃ³re moÅ¼na wykorzystaÄ‡ do oceny, czy model ma problemy zwiÄ…zane z odpowiedzialnÄ… AI. Tradycyjne techniki debugowania uczenia maszynowego opierajÄ… siÄ™ gÅ‚Ã³wnie na obliczeniach iloÅ›ciowych, takich jak zagregowana dokÅ‚adnoÅ›Ä‡ czy Å›rednia strata bÅ‚Ä™du. WyobraÅº sobie, co moÅ¼e siÄ™ staÄ‡, gdy dane, ktÃ³rych uÅ¼ywasz do budowy tych modeli, nie uwzglÄ™dniajÄ… pewnych grup demograficznych, takich jak rasa, pÅ‚eÄ‡, poglÄ…dy polityczne, religia, lub gdy sÄ… one nadmiernie reprezentowane. Co w sytuacji, gdy wyniki modelu sÄ… interpretowane w sposÃ³b faworyzujÄ…cy pewne grupy demograficzne? MoÅ¼e to prowadziÄ‡ do nadmiernej lub niedostatecznej reprezentacji tych wraÅ¼liwych grup cech, co skutkuje problemami z uczciwoÅ›ciÄ…, inkluzywnoÅ›ciÄ… lub wiarygodnoÅ›ciÄ… modelu. Kolejnym wyzwaniem jest to, Å¼e modele uczenia maszynowego sÄ… czÄ™sto traktowane jako "czarne skrzynki", co utrudnia zrozumienie i wyjaÅ›nienie, co napÄ™dza ich przewidywania. Wszystkie te kwestie stanowiÄ… wyzwania dla naukowcÃ³w zajmujÄ…cych siÄ™ danymi i twÃ³rcÃ³w AI, ktÃ³rzy nie majÄ… odpowiednich narzÄ™dzi do debugowania i oceny uczciwoÅ›ci czy wiarygodnoÅ›ci modelu.

W tej lekcji dowiesz siÄ™, jak debugowaÄ‡ swoje modele, korzystajÄ…c z:

- **Analizy bÅ‚Ä™dÃ³w**: identyfikowanie obszarÃ³w w rozkÅ‚adzie danych, w ktÃ³rych model ma wysokie wskaÅºniki bÅ‚Ä™dÃ³w.
- **PrzeglÄ…du modelu**: przeprowadzanie analizy porÃ³wnawczej w rÃ³Å¼nych kohortach danych w celu wykrycia rozbieÅ¼noÅ›ci w metrykach wydajnoÅ›ci modelu.
- **Analizy danych**: badanie, gdzie moÅ¼e wystÄ™powaÄ‡ nadmierna lub niedostateczna reprezentacja danych, ktÃ³ra moÅ¼e wpÅ‚ywaÄ‡ na faworyzowanie jednej grupy demograficznej kosztem innej.
- **WaÅ¼noÅ›ci cech**: zrozumienie, ktÃ³re cechy napÄ™dzajÄ… przewidywania modelu na poziomie globalnym lub lokalnym.

## Wymagania wstÄ™pne

Jako wstÄ™p, zapoznaj siÄ™ z [narzÄ™dziami odpowiedzialnej AI dla programistÃ³w](https://www.microsoft.com/ai/ai-lab-responsible-ai-dashboard).

> ![Gif o narzÄ™dziach odpowiedzialnej AI](../../../../9-Real-World/2-Debugging-ML-Models/images/rai-overview.gif)

## Analiza bÅ‚Ä™dÃ³w

Tradycyjne metryki wydajnoÅ›ci modeli uÅ¼ywane do pomiaru dokÅ‚adnoÅ›ci to gÅ‚Ã³wnie obliczenia oparte na poprawnych i niepoprawnych przewidywaniach. Na przykÅ‚ad stwierdzenie, Å¼e model jest dokÅ‚adny w 89% przypadkÃ³w przy stracie bÅ‚Ä™du wynoszÄ…cej 0,001, moÅ¼e byÄ‡ uznane za dobrÄ… wydajnoÅ›Ä‡. Jednak bÅ‚Ä™dy czÄ™sto nie sÄ… rÃ³wnomiernie rozÅ‚oÅ¼one w podstawowym zbiorze danych. MoÅ¼esz uzyskaÄ‡ wynik dokÅ‚adnoÅ›ci modelu na poziomie 89%, ale odkryÄ‡, Å¼e w niektÃ³rych obszarach danych model zawodzi w 42% przypadkÃ³w. Konsekwencje takich wzorcÃ³w bÅ‚Ä™dÃ³w w okreÅ›lonych grupach danych mogÄ… prowadziÄ‡ do problemÃ³w z uczciwoÅ›ciÄ… lub wiarygodnoÅ›ciÄ…. WaÅ¼ne jest, aby zrozumieÄ‡, w jakich obszarach model dziaÅ‚a dobrze, a w jakich nie. Obszary danych, w ktÃ³rych wystÄ™puje wysoka liczba nieÅ›cisÅ‚oÅ›ci, mogÄ… okazaÄ‡ siÄ™ istotnymi grupami demograficznymi.

![Analiza i debugowanie bÅ‚Ä™dÃ³w modelu](../../../../9-Real-World/2-Debugging-ML-Models/images/ea-error-distribution.png)

Komponent Analizy BÅ‚Ä™dÃ³w na pulpicie RAI ilustruje, jak rozkÅ‚adajÄ… siÄ™ bÅ‚Ä™dy modelu w rÃ³Å¼nych kohortach za pomocÄ… wizualizacji drzewa. Jest to przydatne w identyfikowaniu cech lub obszarÃ³w, w ktÃ³rych wskaÅºnik bÅ‚Ä™dÃ³w w zbiorze danych jest wysoki. DziÄ™ki temu, Å¼e widzisz, skÄ…d pochodzÄ… najwiÄ™ksze nieÅ›cisÅ‚oÅ›ci modelu, moÅ¼esz zaczÄ…Ä‡ badaÄ‡ ich przyczyny. MoÅ¼esz rÃ³wnieÅ¼ tworzyÄ‡ kohorty danych do analizy. Te kohorty danych pomagajÄ… w procesie debugowania, aby okreÅ›liÄ‡, dlaczego wydajnoÅ›Ä‡ modelu jest dobra w jednej kohorcie, a bÅ‚Ä™dna w innej.

![Analiza bÅ‚Ä™dÃ³w](../../../../9-Real-World/2-Debugging-ML-Models/images/ea-error-cohort.png)

WskaÅºniki wizualne na mapie drzewa pomagajÄ… szybciej zlokalizowaÄ‡ problematyczne obszary. Na przykÅ‚ad im ciemniejszy odcieÅ„ czerwieni ma wÄ™zeÅ‚ drzewa, tym wyÅ¼szy wskaÅºnik bÅ‚Ä™dÃ³w.

Mapa cieplna to kolejna funkcjonalnoÅ›Ä‡ wizualizacji, ktÃ³rÄ… uÅ¼ytkownicy mogÄ… wykorzystaÄ‡ do badania wskaÅºnika bÅ‚Ä™dÃ³w przy uÅ¼yciu jednej lub dwÃ³ch cech, aby znaleÅºÄ‡ przyczynÄ™ bÅ‚Ä™dÃ³w modelu w caÅ‚ym zbiorze danych lub kohortach.

![Mapa cieplna analizy bÅ‚Ä™dÃ³w](../../../../9-Real-World/2-Debugging-ML-Models/images/ea-heatmap.png)

UÅ¼ywaj analizy bÅ‚Ä™dÃ³w, gdy potrzebujesz:

* DogÅ‚Ä™bnie zrozumieÄ‡, jak rozkÅ‚adajÄ… siÄ™ bÅ‚Ä™dy modelu w zbiorze danych oraz w rÃ³Å¼nych wymiarach wejÅ›ciowych i cech.
* RozÅ‚oÅ¼yÄ‡ zagregowane metryki wydajnoÅ›ci, aby automatycznie odkryÄ‡ bÅ‚Ä™dne kohorty i zaplanowaÄ‡ ukierunkowane kroki naprawcze.

## PrzeglÄ…d modelu

Ocena wydajnoÅ›ci modelu uczenia maszynowego wymaga holistycznego zrozumienia jego zachowania. MoÅ¼na to osiÄ…gnÄ…Ä‡, analizujÄ…c wiÄ™cej niÅ¼ jednÄ… metrykÄ™, takÄ… jak wskaÅºnik bÅ‚Ä™dÃ³w, dokÅ‚adnoÅ›Ä‡, czuÅ‚oÅ›Ä‡, precyzja czy MAE (Å›redni bÅ‚Ä…d bezwzglÄ™dny), aby znaleÅºÄ‡ rozbieÅ¼noÅ›ci miÄ™dzy metrykami wydajnoÅ›ci. Jedna metryka wydajnoÅ›ci moÅ¼e wyglÄ…daÄ‡ Å›wietnie, ale niedokÅ‚adnoÅ›ci mogÄ… ujawniÄ‡ siÄ™ w innej metryce. Ponadto porÃ³wnanie metryk pod kÄ…tem rozbieÅ¼noÅ›ci w caÅ‚ym zbiorze danych lub kohortach pomaga rzuciÄ‡ Å›wiatÅ‚o na to, gdzie model dziaÅ‚a dobrze, a gdzie nie. Jest to szczegÃ³lnie waÅ¼ne w analizie wydajnoÅ›ci modelu wÅ›rÃ³d cech wraÅ¼liwych i niewraÅ¼liwych (np. rasa pacjenta, pÅ‚eÄ‡ czy wiek), aby odkryÄ‡ potencjalnÄ… niesprawiedliwoÅ›Ä‡ modelu. Na przykÅ‚ad odkrycie, Å¼e model jest bardziej bÅ‚Ä™dny w kohorcie zawierajÄ…cej cechy wraÅ¼liwe, moÅ¼e ujawniÄ‡ potencjalnÄ… niesprawiedliwoÅ›Ä‡ modelu.

Komponent PrzeglÄ…du Modelu na pulpicie RAI pomaga nie tylko w analizie metryk wydajnoÅ›ci reprezentacji danych w kohorcie, ale takÅ¼e daje uÅ¼ytkownikom moÅ¼liwoÅ›Ä‡ porÃ³wnania zachowania modelu w rÃ³Å¼nych kohortach.

![Kohorty zbioru danych - przeglÄ…d modelu na pulpicie RAI](../../../../9-Real-World/2-Debugging-ML-Models/images/model-overview-dataset-cohorts.png)

FunkcjonalnoÅ›Ä‡ analizy opartej na cechach w tym komponencie pozwala uÅ¼ytkownikom zawÄ™ziÄ‡ podgrupy danych w ramach konkretnej cechy, aby zidentyfikowaÄ‡ anomalie na poziomie szczegÃ³Å‚owym. Na przykÅ‚ad pulpit ma wbudowanÄ… inteligencjÄ™, ktÃ³ra automatycznie generuje kohorty dla wybranej przez uÅ¼ytkownika cechy (np. *"time_in_hospital < 3"* lub *"time_in_hospital >= 7"*). UmoÅ¼liwia to uÅ¼ytkownikowi izolowanie konkretnej cechy z wiÄ™kszej grupy danych, aby sprawdziÄ‡, czy jest ona kluczowym czynnikiem wpÅ‚ywajÄ…cym na bÅ‚Ä™dne wyniki modelu.

![Kohorty cech - przeglÄ…d modelu na pulpicie RAI](../../../../9-Real-World/2-Debugging-ML-Models/images/model-overview-feature-cohorts.png)

Komponent PrzeglÄ…du Modelu obsÅ‚uguje dwie klasy metryk rozbieÅ¼noÅ›ci:

**RozbieÅ¼noÅ›Ä‡ w wydajnoÅ›ci modelu**: Te zestawy metryk obliczajÄ… rÃ³Å¼nicÄ™ w wartoÅ›ciach wybranej metryki wydajnoÅ›ci w rÃ³Å¼nych podgrupach danych. Oto kilka przykÅ‚adÃ³w:

* RozbieÅ¼noÅ›Ä‡ w wskaÅºniku dokÅ‚adnoÅ›ci
* RozbieÅ¼noÅ›Ä‡ w wskaÅºniku bÅ‚Ä™dÃ³w
* RozbieÅ¼noÅ›Ä‡ w precyzji
* RozbieÅ¼noÅ›Ä‡ w czuÅ‚oÅ›ci
* RozbieÅ¼noÅ›Ä‡ w Å›rednim bÅ‚Ä™dzie bezwzglÄ™dnym (MAE)

**RozbieÅ¼noÅ›Ä‡ w wskaÅºniku selekcji**: Ta metryka zawiera rÃ³Å¼nicÄ™ w wskaÅºniku selekcji (korzystne przewidywanie) w rÃ³Å¼nych podgrupach. PrzykÅ‚adem moÅ¼e byÄ‡ rozbieÅ¼noÅ›Ä‡ w wskaÅºnikach zatwierdzania kredytÃ³w. WskaÅºnik selekcji oznacza odsetek punktÃ³w danych w kaÅ¼dej klasie sklasyfikowanych jako 1 (w klasyfikacji binarnej) lub rozkÅ‚ad wartoÅ›ci przewidywaÅ„ (w regresji).

## Analiza danych

> "JeÅ›li wystarczajÄ…co dÅ‚ugo torturujesz dane, przyznajÄ… siÄ™ do wszystkiego" - Ronald Coase

To stwierdzenie brzmi ekstremalnie, ale prawdÄ… jest, Å¼e dane moÅ¼na manipulowaÄ‡, aby wspieraÅ‚y dowolny wniosek. Taka manipulacja moÅ¼e czasem zdarzyÄ‡ siÄ™ nieumyÅ›lnie. Jako ludzie wszyscy mamy uprzedzenia i czÄ™sto trudno jest Å›wiadomie zauwaÅ¼yÄ‡, kiedy wprowadzamy uprzedzenia do danych. Zapewnienie uczciwoÅ›ci w AI i uczeniu maszynowym pozostaje zÅ‚oÅ¼onym wyzwaniem.

Dane sÄ… ogromnym punktem Å›lepym dla tradycyjnych metryk wydajnoÅ›ci modeli. MoÅ¼esz mieÄ‡ wysokie wskaÅºniki dokÅ‚adnoÅ›ci, ale nie zawsze odzwierciedlajÄ… one ukryte uprzedzenia w danych. Na przykÅ‚ad, jeÅ›li zbiÃ³r danych pracownikÃ³w zawiera 27% kobiet na stanowiskach kierowniczych w firmie i 73% mÄ™Å¼czyzn na tym samym poziomie, model AI do ogÅ‚aszania ofert pracy przeszkolony na tych danych moÅ¼e kierowaÄ‡ swoje ogÅ‚oszenia gÅ‚Ã³wnie do mÄ™Å¼czyzn na stanowiska wyÅ¼szego szczebla. Taka nierÃ³wnowaga w danych wpÅ‚ynÄ™Å‚a na przewidywania modelu, faworyzujÄ…c jednÄ… pÅ‚eÄ‡. To ujawnia problem z uczciwoÅ›ciÄ…, gdzie model AI wykazuje uprzedzenia pÅ‚ciowe.

Komponent Analizy Danych na pulpicie RAI pomaga zidentyfikowaÄ‡ obszary, w ktÃ³rych wystÄ™puje nadmierna lub niedostateczna reprezentacja w zbiorze danych. Pomaga uÅ¼ytkownikom diagnozowaÄ‡ przyczyny bÅ‚Ä™dÃ³w i problemÃ³w z uczciwoÅ›ciÄ… wynikajÄ…cych z nierÃ³wnowagi danych lub braku reprezentacji okreÅ›lonej grupy danych. Daje uÅ¼ytkownikom moÅ¼liwoÅ›Ä‡ wizualizacji zbiorÃ³w danych na podstawie przewidywanych i rzeczywistych wynikÃ³w, grup bÅ‚Ä™dÃ³w i konkretnych cech. Czasami odkrycie niedostatecznie reprezentowanej grupy danych moÅ¼e rÃ³wnieÅ¼ ujawniÄ‡, Å¼e model nie uczy siÄ™ dobrze, co skutkuje wysokimi niedokÅ‚adnoÅ›ciami. Model, ktÃ³ry ma uprzedzenia w danych, nie tylko ma problem z uczciwoÅ›ciÄ…, ale takÅ¼e pokazuje, Å¼e nie jest inkluzywny ani wiarygodny.

![Komponent Analizy Danych na pulpicie RAI](../../../../9-Real-World/2-Debugging-ML-Models/images/dataanalysis-cover.png)

UÅ¼ywaj analizy danych, gdy potrzebujesz:

* EksplorowaÄ‡ statystyki swojego zbioru danych, wybierajÄ…c rÃ³Å¼ne filtry, aby podzieliÄ‡ dane na rÃ³Å¼ne wymiary (znane rÃ³wnieÅ¼ jako kohorty).
* ZrozumieÄ‡ rozkÅ‚ad swojego zbioru danych w rÃ³Å¼nych kohortach i grupach cech.
* OkreÅ›liÄ‡, czy Twoje ustalenia dotyczÄ…ce uczciwoÅ›ci, analizy bÅ‚Ä™dÃ³w i przyczynowoÅ›ci (pochodzÄ…ce z innych komponentÃ³w pulpitu) wynikajÄ… z rozkÅ‚adu Twojego zbioru danych.
* ZdecydowaÄ‡, w ktÃ³rych obszarach naleÅ¼y zebraÄ‡ wiÄ™cej danych, aby zminimalizowaÄ‡ bÅ‚Ä™dy wynikajÄ…ce z problemÃ³w z reprezentacjÄ…, szumem etykiet, szumem cech, uprzedzeniami etykiet i podobnymi czynnikami.

## InterpretowalnoÅ›Ä‡ modelu

Modele uczenia maszynowego czÄ™sto sÄ… traktowane jako "czarne skrzynki". Zrozumienie, ktÃ³re kluczowe cechy danych napÄ™dzajÄ… przewidywania modelu, moÅ¼e byÄ‡ wyzwaniem. WaÅ¼ne jest, aby zapewniÄ‡ przejrzystoÅ›Ä‡, dlaczego model dokonuje okreÅ›lonego przewidywania. Na przykÅ‚ad, jeÅ›li system AI przewiduje, Å¼e pacjent z cukrzycÄ… jest zagroÅ¼ony ponownym przyjÄ™ciem do szpitala w ciÄ…gu mniej niÅ¼ 30 dni, powinien byÄ‡ w stanie dostarczyÄ‡ dane wspierajÄ…ce, ktÃ³re doprowadziÅ‚y do tego przewidywania. Posiadanie takich wskaÅºnikÃ³w danych wprowadza przejrzystoÅ›Ä‡, ktÃ³ra pomaga klinikom lub szpitalom podejmowaÄ‡ Å›wiadome decyzje. Ponadto moÅ¼liwoÅ›Ä‡ wyjaÅ›nienia, dlaczego model dokonaÅ‚ przewidywania dla konkretnego pacjenta, umoÅ¼liwia zgodnoÅ›Ä‡ z regulacjami zdrowotnymi. Kiedy uÅ¼ywasz modeli uczenia maszynowego w sposÃ³b wpÅ‚ywajÄ…cy na Å¼ycie ludzi, kluczowe jest zrozumienie i wyjaÅ›nienie, co wpÅ‚ywa na zachowanie modelu. InterpretowalnoÅ›Ä‡ i wyjaÅ›nialnoÅ›Ä‡ modelu pomagajÄ… odpowiedzieÄ‡ na pytania w takich scenariuszach jak:

* Debugowanie modelu: Dlaczego mÃ³j model popeÅ‚niÅ‚ ten bÅ‚Ä…d? Jak mogÄ™ go poprawiÄ‡?
* WspÃ³Å‚praca czÅ‚owiek-AI: Jak mogÄ™ zrozumieÄ‡ i zaufaÄ‡ decyzjom modelu?
* ZgodnoÅ›Ä‡ z regulacjami: Czy mÃ³j model speÅ‚nia wymagania prawne?

Komponent WaÅ¼noÅ›ci Cech na pulpicie RAI pomaga debugowaÄ‡ i uzyskaÄ‡ kompleksowe zrozumienie, jak model dokonuje przewidywaÅ„. Jest to rÃ³wnieÅ¼ przydatne narzÄ™dzie dla specjalistÃ³w od uczenia maszynowego i decydentÃ³w, aby wyjaÅ›niaÄ‡ i przedstawiaÄ‡ dowody na cechy wpÅ‚ywajÄ…ce na zachowanie modelu w celu zgodnoÅ›ci z regulacjami. UÅ¼ytkownicy mogÄ… nastÄ™pnie eksplorowaÄ‡ zarÃ³wno globalne, jak i lokalne wyjaÅ›nienia, aby zweryfikowaÄ‡, ktÃ³re cechy napÄ™dzajÄ… przewidywania modelu. Globalne wyjaÅ›nienia wymieniajÄ… najwaÅ¼niejsze cechy, ktÃ³re wpÅ‚ynÄ™Å‚y na ogÃ³lne przewidywania modelu. Lokalne wyjaÅ›nienia pokazujÄ…, ktÃ³re cechy doprowadziÅ‚y do przewidywania modelu w indywidualnym przypadku. MoÅ¼liwoÅ›Ä‡ oceny lokalnych wyjaÅ›nieÅ„ jest rÃ³wnieÅ¼ pomocna w debugowaniu lub audycie konkretnego przypadku, aby lepiej zrozumieÄ‡ i zinterpretowaÄ‡, dlaczego model dokonaÅ‚ poprawnego lub bÅ‚Ä™dnego przewidywania.

![Komponent WaÅ¼noÅ›ci Cech na pulpicie RAI](../../../../9-Real-World/2-Debugging-ML-Models/images/9-feature-importance.png)

* Globalne wyjaÅ›nienia: Na przykÅ‚ad, jakie cechy wpÅ‚ywajÄ… na ogÃ³lne zachowanie modelu przewidujÄ…cego ponowne przyjÄ™cie do szpitala pacjentÃ³w z cukrzycÄ…?
* Lokalne wyjaÅ›nienia: Na przykÅ‚ad, dlaczego pacjent z cukrzycÄ… powyÅ¼ej 60 roku Å¼ycia z wczeÅ›niejszymi hospitalizacjami zostaÅ‚ przewidziany jako ponownie przyjÄ™ty lub nieprzyjÄ™ty do szpitala w ciÄ…gu 30 dni?

W procesie debugowania wydajnoÅ›ci modelu w rÃ³Å¼nych kohortach, WaÅ¼noÅ›Ä‡ Cech pokazuje, jaki wpÅ‚yw ma cecha w rÃ³Å¼nych kohortach. Pomaga ujawniÄ‡ anomalie podczas porÃ³wnywania poziomu wpÅ‚ywu cechy na bÅ‚Ä™dne przewidywania modelu. Komponent WaÅ¼noÅ›ci Cech moÅ¼e pokazaÄ‡, ktÃ³re wartoÅ›ci w cechach pozytywnie lub negatywnie wpÅ‚ynÄ™Å‚y na wynik modelu. Na przykÅ‚ad, jeÅ›li model dokonaÅ‚ bÅ‚Ä™dnego przewidywania, komponent daje moÅ¼liwoÅ›Ä‡ szczegÃ³Å‚owego zbadania i wskazania, ktÃ³re cechy lub wartoÅ›ci cech wpÅ‚ynÄ™Å‚y na przewidywanie. Ten poziom szczegÃ³Å‚owoÅ›ci pomaga nie tylko w debugowaniu, ale takÅ¼e zapewnia przejrzystoÅ›Ä‡ i odpowiedzialnoÅ›Ä‡ w sytuacjach audytowych. Wreszcie, komponent moÅ¼e pomÃ³c w identyfikacji
- **Nad- lub niedoreprezentowanie**. Chodzi o sytuacjÄ™, w ktÃ³rej okreÅ›lona grupa nie jest widoczna w danym zawodzie, a kaÅ¼da usÅ‚uga lub funkcja, ktÃ³ra to utrwala, przyczynia siÄ™ do szkody.

### Azure RAI dashboard

[Azure RAI dashboard](https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai-dashboard?WT.mc_id=aiml-90525-ruyakubu) opiera siÄ™ na narzÄ™dziach open-source opracowanych przez czoÅ‚owe instytucje akademickie i organizacje, w tym Microsoft. SÄ… one kluczowe dla naukowcÃ³w zajmujÄ…cych siÄ™ danymi i twÃ³rcÃ³w AI, aby lepiej zrozumieÄ‡ zachowanie modeli, odkrywaÄ‡ i Å‚agodziÄ‡ niepoÅ¼Ä…dane problemy zwiÄ…zane z modelami AI.

- Dowiedz siÄ™, jak korzystaÄ‡ z rÃ³Å¼nych komponentÃ³w, zapoznajÄ…c siÄ™ z dokumentacjÄ… RAI dashboard [docs.](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-responsible-ai-dashboard?WT.mc_id=aiml-90525-ruyakubu)

- SprawdÅº przykÅ‚adowe notatniki RAI dashboard [sample notebooks](https://github.com/Azure/RAI-vNext-Preview/tree/main/examples/notebooks) do debugowania bardziej odpowiedzialnych scenariuszy AI w Azure Machine Learning.

---
## ğŸš€ Wyzwanie

Aby zapobiec wprowadzaniu statystycznych lub danych uprzedzeÅ„, powinniÅ›my:

- zapewniÄ‡ rÃ³Å¼norodnoÅ›Ä‡ Å›rodowisk i perspektyw wÅ›rÃ³d osÃ³b pracujÄ…cych nad systemami
- inwestowaÄ‡ w zestawy danych odzwierciedlajÄ…ce rÃ³Å¼norodnoÅ›Ä‡ naszego spoÅ‚eczeÅ„stwa
- opracowywaÄ‡ lepsze metody wykrywania i korygowania uprzedzeÅ„, gdy siÄ™ pojawiÄ…

PomyÅ›l o rzeczywistych scenariuszach, w ktÃ³rych niesprawiedliwoÅ›Ä‡ jest widoczna w budowaniu i uÅ¼ytkowaniu modeli. Co jeszcze powinniÅ›my wziÄ…Ä‡ pod uwagÄ™?

## [Quiz po wykÅ‚adzie](https://ff-quizzes.netlify.app/en/ml/)
## PrzeglÄ…d i samodzielna nauka

W tej lekcji nauczyÅ‚eÅ› siÄ™ praktycznych narzÄ™dzi do wÅ‚Ä…czania odpowiedzialnej AI w uczeniu maszynowym.

Obejrzyj ten warsztat, aby zgÅ‚Ä™biÄ‡ temat:

- Responsible AI Dashboard: Kompleksowe narzÄ™dzie do wdraÅ¼ania RAI w praktyce, prowadzone przez BesmirÄ™ Nushi i Mehrnoosh Sameki

[![Responsible AI Dashboard: Kompleksowe narzÄ™dzie do wdraÅ¼ania RAI w praktyce](https://img.youtube.com/vi/f1oaDNl3djg/0.jpg)](https://www.youtube.com/watch?v=f1oaDNl3djg "Responsible AI Dashboard: Kompleksowe narzÄ™dzie do wdraÅ¼ania RAI w praktyce")

> ğŸ¥ Kliknij obrazek powyÅ¼ej, aby obejrzeÄ‡ wideo: Responsible AI Dashboard: Kompleksowe narzÄ™dzie do wdraÅ¼ania RAI w praktyce, prowadzone przez BesmirÄ™ Nushi i Mehrnoosh Sameki

Zapoznaj siÄ™ z poniÅ¼szymi materiaÅ‚ami, aby dowiedzieÄ‡ siÄ™ wiÄ™cej o odpowiedzialnej AI i jak budowaÄ‡ bardziej godne zaufania modele:

- NarzÄ™dzia Microsoft RAI dashboard do debugowania modeli ML: [Responsible AI tools resources](https://aka.ms/rai-dashboard)

- Odkryj zestaw narzÄ™dzi Responsible AI: [Github](https://github.com/microsoft/responsible-ai-toolbox)

- Centrum zasobÃ³w Microsoft RAI: [Responsible AI Resources â€“ Microsoft AI](https://www.microsoft.com/ai/responsible-ai-resources?activetab=pivot1%3aprimaryr4)

- Grupa badawcza Microsoft FATE: [FATE: Fairness, Accountability, Transparency, and Ethics in AI - Microsoft Research](https://www.microsoft.com/research/theme/fate/)

## Zadanie

[Zapoznaj siÄ™ z RAI dashboard](assignment.md)

---

**ZastrzeÅ¼enie**:  
Ten dokument zostaÅ‚ przetÅ‚umaczony za pomocÄ… usÅ‚ugi tÅ‚umaczeniowej AI [Co-op Translator](https://github.com/Azure/co-op-translator). ChociaÅ¼ dokÅ‚adamy wszelkich staraÅ„, aby tÅ‚umaczenie byÅ‚o precyzyjne, prosimy pamiÄ™taÄ‡, Å¼e automatyczne tÅ‚umaczenia mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jego rodzimym jÄ™zyku powinien byÄ‡ uznawany za wiarygodne ÅºrÃ³dÅ‚o. W przypadku informacji krytycznych zaleca siÄ™ skorzystanie z profesjonalnego tÅ‚umaczenia wykonanego przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za jakiekolwiek nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z korzystania z tego tÅ‚umaczenia.