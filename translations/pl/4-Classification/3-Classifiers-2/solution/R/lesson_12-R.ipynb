{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "lesson_12-R.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "ir",
   "display_name": "R"
  },
  "language_info": {
   "name": "R"
  },
  "coopTranslator": {
   "original_hash": "fab50046ca413a38939d579f8432274f",
   "translation_date": "2025-09-03T20:29:53+00:00",
   "source_file": "4-Classification/3-Classifiers-2/solution/R/lesson_12-R.ipynb",
   "language_code": "pl"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsFutf_ygqSx"
   },
   "source": [
    "# Zbuduj model klasyfikacji: Pyszne azjatyckie i indyjskie kuchnie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HD54bEefgtNO"
   },
   "source": [
    "## Klasyfikatory kuchni 2\n",
    "\n",
    "W tej drugiej lekcji dotyczÄ…cej klasyfikacji, zbadamy `wiÄ™cej sposobÃ³w` klasyfikowania danych kategorycznych. Dowiemy siÄ™ rÃ³wnieÅ¼, jakie konsekwencje niesie za sobÄ… wybÃ³r jednego klasyfikatora zamiast innego.\n",
    "\n",
    "### [**Quiz przed wykÅ‚adem**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/23/)\n",
    "\n",
    "### **Wymagania wstÄ™pne**\n",
    "\n",
    "ZakÅ‚adamy, Å¼e ukoÅ„czyÅ‚eÅ› poprzednie lekcje, poniewaÅ¼ bÄ™dziemy kontynuowaÄ‡ niektÃ³re wczeÅ›niej omÃ³wione pojÄ™cia.\n",
    "\n",
    "Do tej lekcji bÄ™dziemy potrzebowaÄ‡ nastÄ™pujÄ…cych pakietÃ³w:\n",
    "\n",
    "-   `tidyverse`: [tidyverse](https://www.tidyverse.org/) to [zbiÃ³r pakietÃ³w R](https://www.tidyverse.org/packages) zaprojektowany, aby uczyniÄ‡ analizÄ™ danych szybszÄ…, Å‚atwiejszÄ… i bardziej przyjemnÄ…!\n",
    "\n",
    "-   `tidymodels`: [tidymodels](https://www.tidymodels.org/) to [framework](https://www.tidymodels.org/packages/) skÅ‚adajÄ…cy siÄ™ z pakietÃ³w do modelowania i uczenia maszynowego.\n",
    "\n",
    "-   `themis`: [pakiet themis](https://themis.tidymodels.org/) dostarcza dodatkowe kroki w przepisach do radzenia sobie z niezrÃ³wnowaÅ¼onymi danymi.\n",
    "\n",
    "MoÅ¼esz je zainstalowaÄ‡ za pomocÄ…:\n",
    "\n",
    "`install.packages(c(\"tidyverse\", \"tidymodels\", \"kernlab\", \"themis\", \"ranger\", \"xgboost\", \"kknn\"))`\n",
    "\n",
    "Alternatywnie, poniÅ¼szy skrypt sprawdza, czy masz wymagane pakiety do ukoÅ„czenia tego moduÅ‚u i instaluje je, jeÅ›li ich brakuje.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vZ57IuUxgyQt"
   },
   "source": [
    "suppressWarnings(if (!require(\"pacman\"))install.packages(\"pacman\"))\n",
    "\n",
    "pacman::p_load(tidyverse, tidymodels, themis, kernlab, ranger, xgboost, kknn)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z22M-pj4g07x"
   },
   "source": [
    "## **1. Mapa klasyfikacji**\n",
    "\n",
    "W naszej [poprzedniej lekcji](https://github.com/microsoft/ML-For-Beginners/tree/main/4-Classification/2-Classifiers-1) prÃ³bowaliÅ›my odpowiedzieÄ‡ na pytanie: jak wybraÄ‡ pomiÄ™dzy wieloma modelami? W duÅ¼ej mierze zaleÅ¼y to od charakterystyki danych oraz rodzaju problemu, ktÃ³ry chcemy rozwiÄ…zaÄ‡ (na przykÅ‚ad klasyfikacja czy regresja?).\n",
    "\n",
    "WczeÅ›niej dowiedzieliÅ›my siÄ™ o rÃ³Å¼nych opcjach klasyfikacji danych, korzystajÄ…c z arkusza pomocy Microsoftu. Framework Machine Learning w Pythonie, Scikit-learn, oferuje podobny, ale bardziej szczegÃ³Å‚owy arkusz pomocy, ktÃ³ry moÅ¼e dodatkowo pomÃ³c w zawÄ™Å¼eniu wyboru estymatorÃ³w (inaczej klasyfikatorÃ³w):\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/map.png\"\n",
    "   width=\"700\"/>\n",
    "   <figcaption></figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1i3xRIVg7vG"
   },
   "source": [
    "> WskazÃ³wka: [odwiedÅº tÄ™ mapÄ™ online](https://scikit-learn.org/stable/tutorial/machine_learning_map/) i klikaj po Å›cieÅ¼kach, aby przeczytaÄ‡ dokumentacjÄ™.\n",
    ">\n",
    "> [Strona referencyjna Tidymodels](https://www.tidymodels.org/find/parsnip/#models) rÃ³wnieÅ¼ oferuje doskonaÅ‚Ä… dokumentacjÄ™ dotyczÄ…cÄ… rÃ³Å¼nych typÃ³w modeli.\n",
    "\n",
    "### **Plan** ğŸ—ºï¸\n",
    "\n",
    "Ta mapa jest bardzo pomocna, gdy dobrze rozumiesz swoje dane, poniewaÅ¼ moÅ¼esz â€przejÅ›Ä‡â€ jej Å›cieÅ¼kami, aby podjÄ…Ä‡ decyzjÄ™:\n",
    "\n",
    "-   Mamy \\>50 prÃ³bek\n",
    "\n",
    "-   Chcemy przewidzieÄ‡ kategoriÄ™\n",
    "\n",
    "-   Mamy dane z etykietami\n",
    "\n",
    "-   Mamy mniej niÅ¼ 100 tys. prÃ³bek\n",
    "\n",
    "-   âœ¨ MoÅ¼emy wybraÄ‡ Linear SVC\n",
    "\n",
    "-   JeÅ›li to siÄ™ nie sprawdzi, poniewaÅ¼ mamy dane numeryczne\n",
    "\n",
    "    -   MoÅ¼emy sprÃ³bowaÄ‡ âœ¨ KNeighbors Classifier\n",
    "\n",
    "        -   JeÅ›li to siÄ™ nie sprawdzi, sprÃ³buj âœ¨ SVC i âœ¨ Ensemble Classifiers\n",
    "\n",
    "To bardzo pomocna Å›cieÅ¼ka do podÄ…Å¼ania. Teraz przejdÅºmy do dziaÅ‚ania, korzystajÄ…c z frameworka modelowania [tidymodels](https://www.tidymodels.org/): spÃ³jnej i elastycznej kolekcji pakietÃ³w R, opracowanej w celu promowania dobrych praktyk statystycznych ğŸ˜Š.\n",
    "\n",
    "## 2. Podziel dane i zajmij siÄ™ niezrÃ³wnowaÅ¼onym zestawem danych.\n",
    "\n",
    "Z naszych poprzednich lekcji dowiedzieliÅ›my siÄ™, Å¼e istnieje zestaw wspÃ³lnych skÅ‚adnikÃ³w w rÃ³Å¼nych kuchniach. Ponadto zauwaÅ¼yliÅ›my nierÃ³wnomierny rozkÅ‚ad liczby kuchni.\n",
    "\n",
    "Poradzimy sobie z tym, wykonujÄ…c nastÄ™pujÄ…ce kroki:\n",
    "\n",
    "-   Usuniemy najbardziej popularne skÅ‚adniki, ktÃ³re powodujÄ… zamieszanie miÄ™dzy rÃ³Å¼nymi kuchniami, uÅ¼ywajÄ…c `dplyr::select()`.\n",
    "\n",
    "-   UÅ¼yjemy `recipe`, ktÃ³ry wstÄ™pnie przetwarza dane, aby przygotowaÄ‡ je do modelowania, stosujÄ…c algorytm `over-sampling`.\n",
    "\n",
    "OmÃ³wiliÅ›my powyÅ¼sze w poprzedniej lekcji, wiÄ™c to powinno byÄ‡ proste ğŸ¥³!\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6tj_rN00hClA"
   },
   "source": [
    "# Load the core Tidyverse and Tidymodels packages\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "\n",
    "# Load the original cuisines data\n",
    "df <- read_csv(file = \"https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/data/cuisines.csv\")\n",
    "\n",
    "# Drop id column, rice, garlic and ginger from our original data set\n",
    "df_select <- df %>% \n",
    "  select(-c(1, rice, garlic, ginger)) %>%\n",
    "  # Encode cuisine column as categorical\n",
    "  mutate(cuisine = factor(cuisine))\n",
    "\n",
    "\n",
    "# Create data split specification\n",
    "set.seed(2056)\n",
    "cuisines_split <- initial_split(data = df_select,\n",
    "                                strata = cuisine,\n",
    "                                prop = 0.7)\n",
    "\n",
    "# Extract the data in each split\n",
    "cuisines_train <- training(cuisines_split)\n",
    "cuisines_test <- testing(cuisines_split)\n",
    "\n",
    "# Display distribution of cuisines in the training set\n",
    "cuisines_train %>% \n",
    "  count(cuisine) %>% \n",
    "  arrange(desc(n))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFin5yw3hHb1"
   },
   "source": [
    "### Radzenie sobie z niezrÃ³wnowaÅ¼onymi danymi\n",
    "\n",
    "NiezrÃ³wnowaÅ¼one dane czÄ™sto negatywnie wpÅ‚ywajÄ… na wydajnoÅ›Ä‡ modelu. Wiele modeli dziaÅ‚a najlepiej, gdy liczba obserwacji jest rÃ³wna, przez co majÄ… trudnoÅ›ci z przetwarzaniem niezrÃ³wnowaÅ¼onych danych.\n",
    "\n",
    "IstniejÄ… dwa gÅ‚Ã³wne sposoby radzenia sobie z niezrÃ³wnowaÅ¼onymi zbiorami danych:\n",
    "\n",
    "-   dodawanie obserwacji do klasy mniejszoÅ›ciowej: `Over-sampling`, np. za pomocÄ… algorytmu SMOTE, ktÃ³ry syntetycznie generuje nowe przykÅ‚ady klasy mniejszoÅ›ciowej, wykorzystujÄ…c najbliÅ¼szych sÄ…siadÃ³w tych przypadkÃ³w.\n",
    "\n",
    "-   usuwanie obserwacji z klasy wiÄ™kszoÅ›ciowej: `Under-sampling`\n",
    "\n",
    "W naszej poprzedniej lekcji pokazaliÅ›my, jak radziÄ‡ sobie z niezrÃ³wnowaÅ¼onymi zbiorami danych, korzystajÄ…c z `recipe`. Recipe moÅ¼na traktowaÄ‡ jako plan dziaÅ‚ania, ktÃ³ry opisuje, jakie kroki naleÅ¼y zastosowaÄ‡ do zbioru danych, aby przygotowaÄ‡ go do analizy. W naszym przypadku chcemy uzyskaÄ‡ rÃ³wnomierny rozkÅ‚ad liczby naszych kuchni w `training set`. PrzejdÅºmy do dziaÅ‚ania.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cRzTnHolhLWd"
   },
   "source": [
    "# Load themis package for dealing with imbalanced data\n",
    "library(themis)\n",
    "\n",
    "# Create a recipe for preprocessing training data\n",
    "cuisines_recipe <- recipe(cuisine ~ ., data = cuisines_train) %>%\n",
    "  step_smote(cuisine) \n",
    "\n",
    "# Print recipe\n",
    "cuisines_recipe"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxOQ2ORhhO81"
   },
   "source": [
    "Teraz jesteÅ›my gotowi do trenowania modeli ğŸ‘©â€ğŸ’»ğŸ‘¨â€ğŸ’»!\n",
    "\n",
    "## 3. Poza modelami regresji wielomianowej\n",
    "\n",
    "W naszej poprzedniej lekcji przyjrzeliÅ›my siÄ™ modelom regresji wielomianowej. Zbadajmy teraz bardziej elastyczne modele klasyfikacji.\n",
    "\n",
    "### Maszyny wektorÃ³w noÅ›nych\n",
    "\n",
    "W kontekÅ›cie klasyfikacji, `Maszyny wektorÃ³w noÅ›nych` to technika uczenia maszynowego, ktÃ³ra stara siÄ™ znaleÅºÄ‡ *hiperpÅ‚aszczyznÄ™*, ktÃ³ra \"najlepiej\" oddziela klasy. SpÃ³jrzmy na prosty przykÅ‚ad:\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/svm.png\"\n",
    "   width=\"300\"/>\n",
    "   <figcaption>https://commons.wikimedia.org/w/index.php?curid=22877598</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4Wsd0vZhXYu"
   },
   "source": [
    "H1~ nie oddziela klas. H2~ oddziela je, ale tylko z maÅ‚ym marginesem. H3~ oddziela je z maksymalnym marginesem.\n",
    "\n",
    "#### Liniowy Klasyfikator WektorÃ³w NoÅ›nych\n",
    "\n",
    "Klasyfikacja za pomocÄ… wektorÃ³w noÅ›nych (SVC) jest czÄ™Å›ciÄ… rodziny metod uczenia maszynowego opartych na wektorach noÅ›nych. W SVC hiperpÅ‚aszczyzna jest wybierana tak, aby poprawnie oddzieliÄ‡ `wiÄ™kszoÅ›Ä‡` obserwacji treningowych, ale `moÅ¼e bÅ‚Ä™dnie sklasyfikowaÄ‡` kilka obserwacji. PozwalajÄ…c niektÃ³rym punktom znaleÅºÄ‡ siÄ™ po niewÅ‚aÅ›ciwej stronie, SVM staje siÄ™ bardziej odporny na wartoÅ›ci odstajÄ…ce, co prowadzi do lepszej uogÃ³lnienia na nowe dane. Parametr regulujÄ…cy to naruszenie nazywany jest `kosztem` i ma domyÅ›lnÄ… wartoÅ›Ä‡ 1 (zobacz `help(\"svm_poly\")`).\n",
    "\n",
    "StwÃ³rzmy liniowy SVC, ustawiajÄ…c `degree = 1` w modelu SVM z wielomianem.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vJpp6nuChlBz"
   },
   "source": [
    "# Make a linear SVC specification\n",
    "svc_linear_spec <- svm_poly(degree = 1) %>% \n",
    "  set_engine(\"kernlab\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle specification and recipe into a worklow\n",
    "svc_linear_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(svc_linear_spec)\n",
    "\n",
    "# Print out workflow\n",
    "svc_linear_wf"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDs8cWNkhoqu"
   },
   "source": [
    "Teraz, gdy uchwyciliÅ›my kroki wstÄ™pnego przetwarzania i specyfikacjÄ™ modelu w *workflow*, moÅ¼emy przejÅ›Ä‡ do trenowania liniowego SVC i jednoczeÅ›nie oceniÄ‡ wyniki. Aby uzyskaÄ‡ metryki wydajnoÅ›ci, stwÃ³rzmy zestaw metryk, ktÃ³ry oceni: `accuracy`, `sensitivity`, `Positive Predicted Value` oraz `F Measure`.\n",
    "\n",
    "> `augment()` doda kolumny z przewidywaniami do podanych danych.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "81wiqcwuhrnq"
   },
   "source": [
    "# Train a linear SVC model\n",
    "svc_linear_fit <- svc_linear_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "# Create a metric set\n",
    "eval_metrics <- metric_set(ppv, sens, accuracy, f_meas)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "svc_linear_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UFQvHf-huo3"
   },
   "source": [
    "#### Maszyna wektorÃ³w noÅ›nych\n",
    "\n",
    "Maszyna wektorÃ³w noÅ›nych (SVM) jest rozszerzeniem klasyfikatora wektorÃ³w noÅ›nych, ktÃ³re pozwala na uwzglÄ™dnienie nieliniowej granicy miÄ™dzy klasami. W istocie, SVM wykorzystujÄ… *sztuczkÄ™ z jÄ…drem*, aby powiÄ™kszyÄ‡ przestrzeÅ„ cech i dostosowaÄ‡ siÄ™ do nieliniowych zaleÅ¼noÅ›ci miÄ™dzy klasami. JednÄ… z popularnych i niezwykle elastycznych funkcji jÄ…dra stosowanych w SVM jest *funkcja bazowa radialna*. Zobaczmy, jak poradzi sobie z naszymi danymi.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-KX4S8mzhzmp"
   },
   "source": [
    "set.seed(2056)\n",
    "\n",
    "# Make an RBF SVM specification\n",
    "svm_rbf_spec <- svm_rbf() %>% \n",
    "  set_engine(\"kernlab\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle specification and recipe into a worklow\n",
    "svm_rbf_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(svm_rbf_spec)\n",
    "\n",
    "\n",
    "# Train an RBF model\n",
    "svm_rbf_fit <- svm_rbf_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "svm_rbf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBFSa7WSh4HQ"
   },
   "source": [
    "DuÅ¼o lepiej ğŸ¤©!\n",
    "\n",
    "> âœ… ProszÄ™ zobaczyÄ‡:\n",
    ">\n",
    "> -   [*Support Vector Machines*](https://bradleyboehmke.github.io/HOML/svm.html), Hands-on Machine Learning with R\n",
    ">\n",
    "> -   [*Support Vector Machines*](https://www.statlearning.com/), An Introduction to Statistical Learning with Applications in R\n",
    ">\n",
    "> dla dalszej lektury.\n",
    "\n",
    "### Klasyfikatory najbliÅ¼szego sÄ…siada\n",
    "\n",
    "Algorytm *K*-najbliÅ¼szych sÄ…siadÃ³w (KNN) przewiduje kaÅ¼dÄ… obserwacjÄ™ na podstawie jej *podobieÅ„stwa* do innych obserwacji.\n",
    "\n",
    "Dopasujmy go do naszych danych.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k4BxxBcdh9Ka"
   },
   "source": [
    "# Make a KNN specification\n",
    "knn_spec <- nearest_neighbor() %>% \n",
    "  set_engine(\"kknn\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "knn_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(knn_spec)\n",
    "\n",
    "# Train a boosted tree model\n",
    "knn_wf_fit <- knn_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "knn_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaegQseriAcj"
   },
   "source": [
    "Wydaje siÄ™, Å¼e ten model nie dziaÅ‚a zbyt dobrze. Prawdopodobnie zmiana argumentÃ³w modelu (zobacz `help(\"nearest_neighbor\")`) poprawi jego wydajnoÅ›Ä‡. Koniecznie wyprÃ³buj tÄ™ opcjÄ™.\n",
    "\n",
    "> âœ… Zobacz:\n",
    ">\n",
    "> -   [Hands-on Machine Learning with R](https://bradleyboehmke.github.io/HOML/)\n",
    ">\n",
    "> -   [An Introduction to Statistical Learning with Applications in R](https://www.statlearning.com/)\n",
    ">\n",
    "> aby dowiedzieÄ‡ siÄ™ wiÄ™cej o klasyfikatorach *K*-Nearest Neighbors.\n",
    "\n",
    "### Klasyfikatory zespoÅ‚owe\n",
    "\n",
    "Algorytmy zespoÅ‚owe dziaÅ‚ajÄ… poprzez Å‚Ä…czenie wielu bazowych estymatorÃ³w w celu stworzenia optymalnego modelu, wykorzystujÄ…c jednÄ… z dwÃ³ch metod:\n",
    "\n",
    "`bagging`: zastosowanie *funkcji uÅ›redniajÄ…cej* do zbioru modeli bazowych\n",
    "\n",
    "`boosting`: budowanie sekwencji modeli, ktÃ³re wzajemnie siÄ™ uzupeÅ‚niajÄ…, aby poprawiÄ‡ wydajnoÅ›Ä‡ predykcyjnÄ….\n",
    "\n",
    "Zacznijmy od wyprÃ³bowania modelu Random Forest, ktÃ³ry tworzy duÅ¼Ä… liczbÄ™ drzew decyzyjnych, a nastÄ™pnie stosuje funkcjÄ™ uÅ›redniajÄ…cÄ…, aby uzyskaÄ‡ lepszy model ogÃ³lny.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "49DPoVs6iK1M"
   },
   "source": [
    "# Make a random forest specification\n",
    "rf_spec <- rand_forest() %>% \n",
    "  set_engine(\"ranger\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "rf_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(rf_spec)\n",
    "\n",
    "# Train a random forest model\n",
    "rf_wf_fit <- rf_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "rf_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGVYwC_aiUWc"
   },
   "source": [
    "Dobra robota ğŸ‘!\n",
    "\n",
    "SprÃ³bujmy rÃ³wnieÅ¼ modelu Boosted Tree.\n",
    "\n",
    "Boosted Tree to metoda zespoÅ‚owa, ktÃ³ra tworzy seriÄ™ sekwencyjnych drzew decyzyjnych, gdzie kaÅ¼de drzewo zaleÅ¼y od wynikÃ³w poprzednich drzew, aby stopniowo zmniejszaÄ‡ bÅ‚Ä…d. Skupia siÄ™ na wagach bÅ‚Ä™dnie sklasyfikowanych elementÃ³w i dostosowuje dopasowanie dla kolejnego klasyfikatora, aby je poprawiÄ‡.\n",
    "\n",
    "IstniejÄ… rÃ³Å¼ne sposoby dopasowania tego modelu (zobacz `help(\"boost_tree\")`). W tym przykÅ‚adzie dopasujemy Boosted trees za pomocÄ… silnika `xgboost`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Py1YWo-micWs"
   },
   "source": [
    "# Make a boosted tree specification\n",
    "boost_spec <- boost_tree(trees = 200) %>% \n",
    "  set_engine(\"xgboost\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "boost_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(boost_spec)\n",
    "\n",
    "# Train a boosted tree model\n",
    "boost_wf_fit <- boost_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "boost_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNQnbuejigZM"
   },
   "source": [
    "> âœ… ProszÄ™ zobaczyÄ‡:\n",
    ">\n",
    "> -   [Machine Learning for Social Scientists](https://cimentadaj.github.io/ml_socsci/tree-based-methods.html#random-forests)\n",
    ">\n",
    "> -   [Hands-on Machine Learning with R](https://bradleyboehmke.github.io/HOML/)\n",
    ">\n",
    "> -   [An Introduction to Statistical Learning with Applications in R](https://www.statlearning.com/)\n",
    ">\n",
    "> -   <https://algotech.netlify.app/blog/xgboost/> - Omawia model AdaBoost, ktÃ³ry jest dobrÄ… alternatywÄ… dla xgboost.\n",
    ">\n",
    "> aby dowiedzieÄ‡ siÄ™ wiÄ™cej o klasyfikatorach zespoÅ‚owych.\n",
    "\n",
    "## 4. Dodatkowo - porÃ³wnanie wielu modeli\n",
    "\n",
    "W tym laboratorium dopasowaliÅ›my caÅ‚kiem sporo modeli ğŸ™Œ. MoÅ¼e to staÄ‡ siÄ™ Å¼mudne lub uciÄ…Å¼liwe, jeÅ›li musimy tworzyÄ‡ wiele przepÅ‚ywÃ³w pracy z rÃ³Å¼nych zestawÃ³w procesorÃ³w wstÄ™pnych i/lub specyfikacji modeli, a nastÄ™pnie obliczaÄ‡ metryki wydajnoÅ›ci jeden po drugim.\n",
    "\n",
    "Zobaczmy, czy moÅ¼emy rozwiÄ…zaÄ‡ ten problem, tworzÄ…c funkcjÄ™, ktÃ³ra dopasowuje listÄ™ przepÅ‚ywÃ³w pracy do zestawu treningowego, a nastÄ™pnie zwraca metryki wydajnoÅ›ci na podstawie zestawu testowego. Skorzystamy z `map()` i `map_dfr()` z pakietu [purrr](https://purrr.tidyverse.org/), aby zastosowaÄ‡ funkcje do kaÅ¼dego elementu w liÅ›cie.\n",
    "\n",
    "> Funkcje [`map()`](https://purrr.tidyverse.org/reference/map.html) pozwalajÄ… zastÄ…piÄ‡ wiele pÄ™tli for kodem, ktÃ³ry jest zarÃ³wno bardziej zwiÄ™zÅ‚y, jak i Å‚atwiejszy do odczytania. Najlepszym miejscem do nauki o funkcjach [`map()`](https://purrr.tidyverse.org/reference/map.html) jest [rozdziaÅ‚ o iteracji](http://r4ds.had.co.nz/iteration.html) w R for Data Science.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Qzb7LyZnimd2"
   },
   "source": [
    "set.seed(2056)\n",
    "\n",
    "# Create a metric set\n",
    "eval_metrics <- metric_set(ppv, sens, accuracy, f_meas)\n",
    "\n",
    "# Define a function that returns performance metrics\n",
    "compare_models <- function(workflow_list, train_set, test_set){\n",
    "  \n",
    "  suppressWarnings(\n",
    "    # Fit each model to the train_set\n",
    "    map(workflow_list, fit, data = train_set) %>% \n",
    "    # Make predictions on the test set\n",
    "      map_dfr(augment, new_data = test_set, .id = \"model\") %>%\n",
    "    # Select desired columns\n",
    "      select(model, cuisine, .pred_class) %>% \n",
    "    # Evaluate model performance\n",
    "      group_by(model) %>% \n",
    "      eval_metrics(truth = cuisine, estimate = .pred_class) %>% \n",
    "      ungroup()\n",
    "  )\n",
    "  \n",
    "} # End of function"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fwa712sNisDA"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3i4VJOi2iu-a"
   },
   "source": [
    "# Make a list of workflows\n",
    "workflow_list <- list(\n",
    "  \"svc\" = svc_linear_wf,\n",
    "  \"svm\" = svm_rbf_wf,\n",
    "  \"knn\" = knn_wf,\n",
    "  \"random_forest\" = rf_wf,\n",
    "  \"xgboost\" = boost_wf)\n",
    "\n",
    "# Call the function\n",
    "set.seed(2056)\n",
    "perf_metrics <- compare_models(workflow_list = workflow_list, train_set = cuisines_train, test_set = cuisines_test)\n",
    "\n",
    "# Print out performance metrics\n",
    "perf_metrics %>% \n",
    "  group_by(.metric) %>% \n",
    "  arrange(desc(.estimate)) %>% \n",
    "  slice_head(n=7)\n",
    "\n",
    "# Compare accuracy\n",
    "perf_metrics %>% \n",
    "  filter(.metric == \"accuracy\") %>% \n",
    "  arrange(desc(.estimate))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuWK_lEli4nW"
   },
   "source": [
    "[**workflowset**](https://workflowsets.tidymodels.org/) umoÅ¼liwia uÅ¼ytkownikom tworzenie i Å‚atwe dopasowywanie duÅ¼ej liczby modeli, ale jest gÅ‚Ã³wnie zaprojektowany do pracy z technikami resamplingu, takimi jak `cross-validation`, podejÅ›cie, ktÃ³re dopiero omÃ³wimy.\n",
    "\n",
    "## **ğŸš€Wyzwanie**\n",
    "\n",
    "KaÅ¼da z tych technik ma wiele parametrÃ³w, ktÃ³re moÅ¼na dostosowaÄ‡, na przykÅ‚ad `cost` w SVM, `neighbors` w KNN, `mtry` (losowo wybrane predyktory) w Random Forest.\n",
    "\n",
    "Zbadaj domyÅ›lne wartoÅ›ci parametrÃ³w dla kaÅ¼dej z nich i zastanÃ³w siÄ™, co zmiana tych parametrÃ³w oznaczaÅ‚aby dla jakoÅ›ci modelu.\n",
    "\n",
    "Aby dowiedzieÄ‡ siÄ™ wiÄ™cej o konkretnym modelu i jego parametrach, uÅ¼yj: `help(\"model\")`, np. `help(\"rand_forest\")`.\n",
    "\n",
    "> W praktyce zazwyczaj *szacujemy* *najlepsze wartoÅ›ci* tych parametrÃ³w, trenujÄ…c wiele modeli na `symulowanym zestawie danych` i mierzÄ…c, jak dobrze te modele siÄ™ sprawdzajÄ…. Ten proces nazywa siÄ™ **strojenie**.\n",
    "\n",
    "### [**Quiz po wykÅ‚adzie**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/24/)\n",
    "\n",
    "### **PrzeglÄ…d i samodzielna nauka**\n",
    "\n",
    "W tych lekcjach pojawia siÄ™ wiele specjalistycznych terminÃ³w, wiÄ™c poÅ›wiÄ™Ä‡ chwilÄ™ na przejrzenie [tej listy](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) przydatnej terminologii!\n",
    "\n",
    "#### PODZIÄ˜KOWANIA DLA:\n",
    "\n",
    "[`Allison Horst`](https://twitter.com/allison_horst/) za stworzenie niesamowitych ilustracji, ktÃ³re sprawiajÄ…, Å¼e R jest bardziej przyjazny i angaÅ¼ujÄ…cy. WiÄ™cej ilustracji znajdziesz w jej [galerii](https://www.google.com/url?q=https://github.com/allisonhorst/stats-illustrations&sa=D&source=editors&ust=1626380772530000&usg=AOvVaw3zcfyCizFQZpkSLzxiiQEM).\n",
    "\n",
    "[Cassie Breviu](https://www.twitter.com/cassieview) i [Jen Looper](https://www.twitter.com/jenlooper) za stworzenie oryginalnej wersji tego moduÅ‚u w Pythonie â™¥ï¸\n",
    "\n",
    "MiÅ‚ej nauki,\n",
    "\n",
    "[Eric](https://twitter.com/ericntay), ZÅ‚oty Ambasador StudentÃ³w Microsoft Learn.\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/r_learners_sm.jpeg\"\n",
    "   width=\"569\"/>\n",
    "   <figcaption>Ilustracja autorstwa @allison_horst</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**ZastrzeÅ¼enie**:  \nTen dokument zostaÅ‚ przetÅ‚umaczony za pomocÄ… usÅ‚ugi tÅ‚umaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). ChociaÅ¼ dokÅ‚adamy wszelkich staraÅ„, aby tÅ‚umaczenie byÅ‚o precyzyjne, prosimy pamiÄ™taÄ‡, Å¼e automatyczne tÅ‚umaczenia mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jego rodzimym jÄ™zyku powinien byÄ‡ uznawany za ÅºrÃ³dÅ‚o autorytatywne. W przypadku informacji o kluczowym znaczeniu zaleca siÄ™ skorzystanie z profesjonalnego tÅ‚umaczenia wykonanego przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za jakiekolwiek nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z korzystania z tego tÅ‚umaczenia.\n"
   ]
  }
 ]
}