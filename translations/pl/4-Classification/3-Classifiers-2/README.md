<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "49047911108adc49d605cddfb455749c",
  "translation_date": "2025-09-05T08:25:46+00:00",
  "source_file": "4-Classification/3-Classifiers-2/README.md",
  "language_code": "pl"
}
-->
# Klasyfikatory kuchni 2

W tej drugiej lekcji dotyczÄ…cej klasyfikacji poznasz wiÄ™cej sposobÃ³w klasyfikowania danych numerycznych. Dowiesz siÄ™ rÃ³wnieÅ¼, jakie sÄ… konsekwencje wyboru jednego klasyfikatora zamiast innego.

## [Quiz przed wykÅ‚adem](https://ff-quizzes.netlify.app/en/ml/)

### Wymagania wstÄ™pne

ZakÅ‚adamy, Å¼e ukoÅ„czyÅ‚eÅ› poprzednie lekcje i masz wyczyszczony zbiÃ³r danych w folderze `data`, nazwany _cleaned_cuisines.csv_, znajdujÄ…cy siÄ™ w gÅ‚Ã³wnym katalogu tego czteroczÄ™Å›ciowego kursu.

### Przygotowanie

ZaÅ‚adowaliÅ›my TwÃ³j plik _notebook.ipynb_ z wyczyszczonym zbiorem danych i podzieliliÅ›my go na ramki danych X i y, gotowe do procesu budowy modelu.

## Mapa klasyfikacji

WczeÅ›niej nauczyÅ‚eÅ› siÄ™ o rÃ³Å¼nych opcjach klasyfikacji danych, korzystajÄ…c z Å›ciÄ…gi Microsoftu. Scikit-learn oferuje podobnÄ…, ale bardziej szczegÃ³Å‚owÄ… Å›ciÄ…gÄ™, ktÃ³ra moÅ¼e pomÃ³c jeszcze bardziej zawÄ™ziÄ‡ wybÃ³r estymatorÃ³w (inaczej klasyfikatorÃ³w):

![Mapa ML ze Scikit-learn](../../../../4-Classification/3-Classifiers-2/images/map.png)
> WskazÃ³wka: [odwiedÅº tÄ™ mapÄ™ online](https://scikit-learn.org/stable/tutorial/machine_learning_map/) i klikaj po Å›cieÅ¼kach, aby przeczytaÄ‡ dokumentacjÄ™.

### Plan

Ta mapa jest bardzo pomocna, gdy masz jasne zrozumienie swoich danych, poniewaÅ¼ moÅ¼esz â€przechodziÄ‡â€ jej Å›cieÅ¼kami, aby podjÄ…Ä‡ decyzjÄ™:

- Mamy >50 prÃ³bek
- Chcemy przewidzieÄ‡ kategoriÄ™
- Mamy dane z etykietami
- Mamy mniej niÅ¼ 100 tys. prÃ³bek
- âœ¨ MoÅ¼emy wybraÄ‡ Linear SVC
- JeÅ›li to nie zadziaÅ‚a, poniewaÅ¼ mamy dane numeryczne:
    - MoÅ¼emy sprÃ³bowaÄ‡ âœ¨ KNeighbors Classifier 
      - JeÅ›li to nie zadziaÅ‚a, sprÃ³buj âœ¨ SVC i âœ¨ Ensemble Classifiers

To bardzo pomocna Å›cieÅ¼ka do naÅ›ladowania.

## Ä†wiczenie - podziel dane

PodÄ…Å¼ajÄ…c tÄ… Å›cieÅ¼kÄ…, powinniÅ›my zaczÄ…Ä‡ od zaimportowania potrzebnych bibliotek.

1. Zaimportuj potrzebne biblioteki:

    ```python
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    import numpy as np
    ```

1. Podziel dane na zestawy treningowe i testowe:

    ```python
    X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)
    ```

## Klasyfikator Linear SVC

Support-Vector Clustering (SVC) to metoda z rodziny maszyn wektorÃ³w noÅ›nych (Support-Vector Machines) w technikach uczenia maszynowego (wiÄ™cej o nich poniÅ¼ej). W tej metodzie moÅ¼esz wybraÄ‡ â€jÄ…droâ€ (kernel), aby zdecydowaÄ‡, jak grupowaÄ‡ etykiety. Parametr 'C' odnosi siÄ™ do 'regularyzacji', ktÃ³ra kontroluje wpÅ‚yw parametrÃ³w. JÄ…dro moÅ¼e byÄ‡ jednym z [kilku](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC); tutaj ustawiamy je na 'linear', aby wykorzystaÄ‡ liniowy SVC. DomyÅ›lnie prawdopodobieÅ„stwo jest ustawione na 'false'; tutaj ustawiamy je na 'true', aby uzyskaÄ‡ oszacowania prawdopodobieÅ„stwa. Parametr random state ustawiamy na '0', aby przetasowaÄ‡ dane i uzyskaÄ‡ prawdopodobieÅ„stwa.

### Ä†wiczenie - zastosuj Linear SVC

Zacznij od stworzenia tablicy klasyfikatorÃ³w. BÄ™dziesz stopniowo dodawaÄ‡ do tej tablicy, testujÄ…c rÃ³Å¼ne metody.

1. Zacznij od Linear SVC:

    ```python
    C = 10
    # Create different classifiers.
    classifiers = {
        'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0)
    }
    ```

2. Wytrenuj model, uÅ¼ywajÄ…c Linear SVC, i wyÅ›wietl raport:

    ```python
    n_classifiers = len(classifiers)
    
    for index, (name, classifier) in enumerate(classifiers.items()):
        classifier.fit(X_train, np.ravel(y_train))
    
        y_pred = classifier.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print("Accuracy (train) for %s: %0.1f%% " % (name, accuracy * 100))
        print(classification_report(y_test,y_pred))
    ```

    Wynik jest caÅ‚kiem dobry:

    ```output
    Accuracy (train) for Linear SVC: 78.6% 
                  precision    recall  f1-score   support
    
         chinese       0.71      0.67      0.69       242
          indian       0.88      0.86      0.87       234
        japanese       0.79      0.74      0.76       254
          korean       0.85      0.81      0.83       242
            thai       0.71      0.86      0.78       227
    
        accuracy                           0.79      1199
       macro avg       0.79      0.79      0.79      1199
    weighted avg       0.79      0.79      0.79      1199
    ```

## Klasyfikator K-Neighbors

K-Neighbors naleÅ¼y do rodziny metod ML â€sÄ…siadÃ³wâ€, ktÃ³re mogÄ… byÄ‡ uÅ¼ywane zarÃ³wno w uczeniu nadzorowanym, jak i nienadzorowanym. W tej metodzie tworzona jest z gÃ³ry okreÅ›lona liczba punktÃ³w, a dane sÄ… grupowane wokÃ³Å‚ tych punktÃ³w, aby moÅ¼na byÅ‚o przewidzieÄ‡ ogÃ³lne etykiety dla danych.

### Ä†wiczenie - zastosuj klasyfikator K-Neighbors

Poprzedni klasyfikator byÅ‚ dobry i dobrze dziaÅ‚aÅ‚ z danymi, ale moÅ¼e uda siÄ™ uzyskaÄ‡ lepszÄ… dokÅ‚adnoÅ›Ä‡. SprÃ³buj klasyfikatora K-Neighbors.

1. Dodaj liniÄ™ do swojej tablicy klasyfikatorÃ³w (dodaj przecinek po elemencie Linear SVC):

    ```python
    'KNN classifier': KNeighborsClassifier(C),
    ```

    Wynik jest trochÄ™ gorszy:

    ```output
    Accuracy (train) for KNN classifier: 73.8% 
                  precision    recall  f1-score   support
    
         chinese       0.64      0.67      0.66       242
          indian       0.86      0.78      0.82       234
        japanese       0.66      0.83      0.74       254
          korean       0.94      0.58      0.72       242
            thai       0.71      0.82      0.76       227
    
        accuracy                           0.74      1199
       macro avg       0.76      0.74      0.74      1199
    weighted avg       0.76      0.74      0.74      1199
    ```

    âœ… Dowiedz siÄ™ wiÄ™cej o [K-Neighbors](https://scikit-learn.org/stable/modules/neighbors.html#neighbors)

## Klasyfikator Support Vector

Klasyfikatory Support-Vector naleÅ¼Ä… do rodziny metod ML [Support-Vector Machine](https://wikipedia.org/wiki/Support-vector_machine), ktÃ³re sÄ… uÅ¼ywane do zadaÅ„ klasyfikacji i regresji. SVM â€mapuje przykÅ‚ady treningowe na punkty w przestrzeniâ€, aby zmaksymalizowaÄ‡ odlegÅ‚oÅ›Ä‡ miÄ™dzy dwiema kategoriami. Kolejne dane sÄ… mapowane w tej przestrzeni, aby przewidzieÄ‡ ich kategoriÄ™.

### Ä†wiczenie - zastosuj klasyfikator Support Vector

SprÃ³bujmy uzyskaÄ‡ nieco lepszÄ… dokÅ‚adnoÅ›Ä‡ za pomocÄ… klasyfikatora Support Vector.

1. Dodaj przecinek po elemencie K-Neighbors, a nastÄ™pnie dodaj tÄ™ liniÄ™:

    ```python
    'SVC': SVC(),
    ```

    Wynik jest caÅ‚kiem dobry!

    ```output
    Accuracy (train) for SVC: 83.2% 
                  precision    recall  f1-score   support
    
         chinese       0.79      0.74      0.76       242
          indian       0.88      0.90      0.89       234
        japanese       0.87      0.81      0.84       254
          korean       0.91      0.82      0.86       242
            thai       0.74      0.90      0.81       227
    
        accuracy                           0.83      1199
       macro avg       0.84      0.83      0.83      1199
    weighted avg       0.84      0.83      0.83      1199
    ```

    âœ… Dowiedz siÄ™ wiÄ™cej o [Support-Vectors](https://scikit-learn.org/stable/modules/svm.html#svm)

## Klasyfikatory zespoÅ‚owe (Ensemble Classifiers)

PodÄ…Å¼ajmy Å›cieÅ¼kÄ… do samego koÅ„ca, mimo Å¼e poprzedni test byÅ‚ caÅ‚kiem dobry. WyprÃ³bujmy kilka klasyfikatorÃ³w zespoÅ‚owych, w szczegÃ³lnoÅ›ci Random Forest i AdaBoost:

```python
  'RFST': RandomForestClassifier(n_estimators=100),
  'ADA': AdaBoostClassifier(n_estimators=100)
```

Wynik jest bardzo dobry, szczegÃ³lnie dla Random Forest:

```output
Accuracy (train) for RFST: 84.5% 
              precision    recall  f1-score   support

     chinese       0.80      0.77      0.78       242
      indian       0.89      0.92      0.90       234
    japanese       0.86      0.84      0.85       254
      korean       0.88      0.83      0.85       242
        thai       0.80      0.87      0.83       227

    accuracy                           0.84      1199
   macro avg       0.85      0.85      0.84      1199
weighted avg       0.85      0.84      0.84      1199

Accuracy (train) for ADA: 72.4% 
              precision    recall  f1-score   support

     chinese       0.64      0.49      0.56       242
      indian       0.91      0.83      0.87       234
    japanese       0.68      0.69      0.69       254
      korean       0.73      0.79      0.76       242
        thai       0.67      0.83      0.74       227

    accuracy                           0.72      1199
   macro avg       0.73      0.73      0.72      1199
weighted avg       0.73      0.72      0.72      1199
```

âœ… Dowiedz siÄ™ wiÄ™cej o [Klasyfikatorach zespoÅ‚owych](https://scikit-learn.org/stable/modules/ensemble.html)

Ta metoda uczenia maszynowego â€Å‚Ä…czy przewidywania kilku podstawowych estymatorÃ³wâ€, aby poprawiÄ‡ jakoÅ›Ä‡ modelu. W naszym przykÅ‚adzie uÅ¼yliÅ›my Random Trees i AdaBoost. 

- [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest), metoda uÅ›redniania, buduje â€lasâ€ â€drzew decyzyjnychâ€ z elementami losowoÅ›ci, aby uniknÄ…Ä‡ przeuczenia. Parametr n_estimators okreÅ›la liczbÄ™ drzew.

- [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) dopasowuje klasyfikator do zbioru danych, a nastÄ™pnie dopasowuje kopie tego klasyfikatora do tego samego zbioru danych. Skupia siÄ™ na wagach bÅ‚Ä™dnie sklasyfikowanych elementÃ³w i dostosowuje dopasowanie kolejnego klasyfikatora, aby je poprawiÄ‡.

---

## ğŸš€ Wyzwanie

KaÅ¼da z tych technik ma duÅ¼Ä… liczbÄ™ parametrÃ³w, ktÃ³re moÅ¼esz dostosowaÄ‡. Zbadaj domyÅ›lne parametry kaÅ¼dej z nich i zastanÃ³w siÄ™, co zmiana tych parametrÃ³w oznaczaÅ‚aby dla jakoÅ›ci modelu.

## [Quiz po wykÅ‚adzie](https://ff-quizzes.netlify.app/en/ml/)

## PrzeglÄ…d i samodzielna nauka

W tych lekcjach pojawia siÄ™ wiele Å¼argonu, wiÄ™c poÅ›wiÄ™Ä‡ chwilÄ™, aby przejrzeÄ‡ [tÄ™ listÄ™](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) przydatnej terminologii!

## Zadanie 

[Zabawa z parametrami](assignment.md)

---

**ZastrzeÅ¼enie**:  
Ten dokument zostaÅ‚ przetÅ‚umaczony za pomocÄ… usÅ‚ugi tÅ‚umaczeniowej AI [Co-op Translator](https://github.com/Azure/co-op-translator). ChociaÅ¼ dokÅ‚adamy wszelkich staraÅ„, aby tÅ‚umaczenie byÅ‚o precyzyjne, prosimy pamiÄ™taÄ‡, Å¼e automatyczne tÅ‚umaczenia mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jego rodzimym jÄ™zyku powinien byÄ‡ uznawany za wiarygodne ÅºrÃ³dÅ‚o. W przypadku informacji o krytycznym znaczeniu zaleca siÄ™ skorzystanie z profesjonalnego tÅ‚umaczenia wykonanego przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za jakiekolwiek nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z korzystania z tego tÅ‚umaczenia.