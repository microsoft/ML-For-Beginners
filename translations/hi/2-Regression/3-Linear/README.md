# Scikit-learn рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдПрдХ рд░рд┐рдЧреНрд░реЗрд╢рди рдореЙрдбрд▓ рдмрдирд╛рдПрдВ: рд░рд┐рдЧреНрд░реЗрд╢рди рдХреЗ рдЪрд╛рд░ рддрд░реАрдХреЗ

![Linear vs polynomial regression infographic](../../../../translated_images/linear-polynomial.5523c7cb6576ccab0fecbd0e3505986eb2d191d9378e785f82befcf3a578a6e7.hi.png)
> Infographic by [Dasani Madipalli](https://twitter.com/dasani_decoded)
## [Pre-lecture quiz](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/13/)

> ### [рдпрд╣ рдкрд╛рда R рдореЗрдВ рдЙрдкрд▓рдмреНрдз рд╣реИ!](../../../../2-Regression/3-Linear/solution/R/lesson_3.html)
### рдкрд░рд┐рдЪрдп

рдЕрдм рддрдХ рдЖрдкрдиреЗ рдЗрд╕ рдкрд╛рда рдореЗрдВ рдЙрдкрдпреЛрдЧ рдХрд┐рдП рдЬрд╛рдиреЗ рд╡рд╛рд▓реЗ рдХрджреНрджреВ рдореВрд▓реНрдп рдирд┐рд░реНрдзрд╛рд░рдг рдбреЗрдЯрд╛рд╕реЗрдЯ рд╕реЗ рдПрдХрддреНрд░ рдХрд┐рдП рдЧрдП рдирдореВрдирд╛ рдбреЗрдЯрд╛ рдХреЗ рд╕рд╛рде рд░рд┐рдЧреНрд░реЗрд╢рди рдХреНрдпрд╛ рд╣реИ, рдЗрд╕рдХрд╛ рдкрддрд╛ рд▓рдЧрд╛рдпрд╛ рд╣реИред рдЖрдкрдиреЗ рдЗрд╕реЗ Matplotlib рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рднреА рд╡рд┐рдЬрд╝реБрдЕрд▓рд╛рдЗрдЬрд╝ рдХрд┐рдпрд╛ рд╣реИред

рдЕрдм рдЖрдк рдПрдордПрд▓ рдХреЗ рд▓рд┐рдП рд░рд┐рдЧреНрд░реЗрд╢рди рдореЗрдВ рдЧрд╣рд░рд╛рдИ рд╕реЗ рдЧреЛрддрд╛ рд▓рдЧрд╛рдиреЗ рдХреЗ рд▓рд┐рдП рддреИрдпрд╛рд░ рд╣реИрдВред рдЬрдмрдХрд┐ рд╡рд┐рдЬрд╝реБрдЕрд▓рд╛рдЗрдЬрд╝реЗрд╢рди рдЖрдкрдХреЛ рдбреЗрдЯрд╛ рдХреЛ рд╕рдордЭрдиреЗ рдХреА рдЕрдиреБрдорддрд┐ рджреЗрддрд╛ рд╣реИ, рдорд╢реАрди рд▓рд░реНрдирд┐рдВрдЧ рдХреА рд╡рд╛рд╕реНрддрд╡рд┐рдХ рд╢рдХреНрддрд┐ _рдореЙрдбрд▓ рдкреНрд░рд╢рд┐рдХреНрд╖рдг_ рд╕реЗ рдЖрддреА рд╣реИред рдореЙрдбрд▓ рдРрддрд┐рд╣рд╛рд╕рд┐рдХ рдбреЗрдЯрд╛ рдкрд░ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рд╣реЛрддреЗ рд╣реИрдВ рддрд╛рдХрд┐ рдбреЗрдЯрд╛ рдирд┐рд░реНрднрд░рддрд╛рдУрдВ рдХреЛ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рд░реВрдк рд╕реЗ рдХреИрдкреНрдЪрд░ рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХреЗ, рдФрд░ рд╡реЗ рдЖрдкрдХреЛ рдирдП рдбреЗрдЯрд╛ рдХреЗ рд▓рд┐рдП рдкрд░рд┐рдгрд╛рдореЛрдВ рдХреА рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгреА рдХрд░рдиреЗ рдХреА рдЕрдиреБрдорддрд┐ рджреЗрддреЗ рд╣реИрдВ, рдЬрд┐рд╕реЗ рдореЙрдбрд▓ рдиреЗ рдкрд╣рд▓реЗ рдирд╣реАрдВ рджреЗрдЦрд╛ рд╣реИред

рдЗрд╕ рдкрд╛рда рдореЗрдВ, рдЖрдк рджреЛ рдкреНрд░рдХрд╛рд░ рдХреЗ рд░рд┐рдЧреНрд░реЗрд╢рди рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдЕрдзрд┐рдХ рдЬрд╛рдиреЗрдВрдЧреЗ: _рдмреЗрд╕рд┐рдХ рд▓реАрдирд┐рдпрд░ рд░рд┐рдЧреНрд░реЗрд╢рди_ рдФрд░ _рдкреЛрд▓рд┐рдиреЛрдорд┐рдпрд▓ рд░рд┐рдЧреНрд░реЗрд╢рди_, рд╕рд╛рде рд╣реА рдЗрди рддрдХрдиреАрдХреЛрдВ рдХреЗ рдЕрдВрддрд░реНрдирд┐рд╣рд┐рдд рдЧрдгрд┐рдд рдХреЗ рдХреБрдЫ рдкрд╣рд▓реВред рдпреЗ рдореЙрдбрд▓ рд╣рдореЗрдВ рд╡рд┐рднрд┐рдиреНрди рдЗрдирдкреБрдЯ рдбреЗрдЯрд╛ рдХреЗ рдЖрдзрд╛рд░ рдкрд░ рдХрджреНрджреВ рдХреА рдХреАрдорддреЛрдВ рдХреА рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгреА рдХрд░рдиреЗ рдХреА рдЕрдиреБрдорддрд┐ рджреЗрдВрдЧреЗред

[![ML for beginners - Understanding Linear Regression](https://img.youtube.com/vi/CRxFT8oTDMg/0.jpg)](https://youtu.be/CRxFT8oTDMg "ML for beginners - Understanding Linear Regression")

> ЁЯОе рдКрдкрд░ рджреА рдЧрдИ рдЫрд╡рд┐ рдкрд░ рдХреНрд▓рд┐рдХ рдХрд░реЗрдВ рд▓реАрдирд┐рдпрд░ рд░рд┐рдЧреНрд░реЗрд╢рди рдХрд╛ рдПрдХ рд╕рдВрдХреНрд╖рд┐рдкреНрдд рд╡реАрдбрд┐рдпреЛ рдЕрд╡рд▓реЛрдХрди рджреЗрдЦрдиреЗ рдХреЗ рд▓рд┐рдПред

> рдЗрд╕ рдкрд╛рдареНрдпрдХреНрд░рдо рдХреЗ рджреМрд░рд╛рди, рд╣рдо рдЧрдгрд┐рдд рдХрд╛ рдиреНрдпреВрдирддрдо рдЬреНрдЮрд╛рди рдорд╛рдирддреЗ рд╣реИрдВ рдФрд░ рдЕрдиреНрдп рдХреНрд╖реЗрддреНрд░реЛрдВ рд╕реЗ рдЖрдиреЗ рд╡рд╛рд▓реЗ рдЫрд╛рддреНрд░реЛрдВ рдХреЗ рд▓рд┐рдП рдЗрд╕реЗ рд╕реБрд▓рдн рдмрдирд╛рдиреЗ рдХрд╛ рдкреНрд░рдпрд╛рд╕ рдХрд░рддреЗ рд╣реИрдВ, рдЗрд╕рд▓рд┐рдП рд╕рдордЭ рдореЗрдВ рд╕рд╣рд╛рдпрддрд╛ рдХреЗ рд▓рд┐рдП рдиреЛрдЯреНрд╕, ЁЯзо рдХреЙрд▓рдЖрдЙрдЯреНрд╕, рдЖрд░реЗрдЦ рдФрд░ рдЕрдиреНрдп рд╢рд┐рдХреНрд╖рдг рдЙрдкрдХрд░рдг рджреЗрдЦреЗрдВред

### рдЖрд╡рд╢реНрдпрдХрддрд╛рдПрдБ

рдЕрдм рддрдХ рдЖрдкрдХреЛ рдХрджреНрджреВ рдбреЗрдЯрд╛ рдХреА рд╕рдВрд░рдЪрдирд╛ рд╕реЗ рдкрд░рд┐рдЪрд┐рдд рд╣реЛрдирд╛ рдЪрд╛рд╣рд┐рдП рдЬрд┐рд╕реЗ рд╣рдо рдЬрд╛рдВрдЪ рд░рд╣реЗ рд╣реИрдВред рдЖрдк рдЗрд╕реЗ рдЗрд╕ рдкрд╛рда рдХреЗ _notebook.ipynb_ рдлрд╝рд╛рдЗрд▓ рдореЗрдВ рдкрд╣рд▓реЗ рд╕реЗ рд▓реЛрдб рдФрд░ рдкрд╣рд▓реЗ рд╕реЗ рд╕рд╛рдлрд╝ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред рдлрд╝рд╛рдЗрд▓ рдореЗрдВ, рдХрджреНрджреВ рдХреА рдХреАрдордд рдПрдХ рдирдП рдбреЗрдЯрд╛ рдлреНрд░реЗрдо рдореЗрдВ рдкреНрд░рддрд┐ рдмреБрд╢рд▓ рдкреНрд░рджрд░реНрд╢рд┐рдд рд╣реЛрддреА рд╣реИред рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░реЗрдВ рдХрд┐ рдЖрдк рдЗрди рдиреЛрдЯрдмреБрдХреНрд╕ рдХреЛ Visual Studio Code рдХреЗ рдХрд░реНрдиреЗрд▓реНрд╕ рдореЗрдВ рдЪрд▓рд╛ рд╕рдХрддреЗ рд╣реИрдВред

### рддреИрдпрд╛рд░реА

рдпрд╛рдж рджрд┐рд▓рд╛рдиреЗ рдХреЗ рд▓рд┐рдП, рдЖрдк рдЗрд╕ рдбреЗрдЯрд╛ рдХреЛ рд▓реЛрдб рдХрд░ рд░рд╣реЗ рд╣реИрдВ рддрд╛рдХрд┐ рдЗрд╕рд╕реЗ рд╕рд╡рд╛рд▓ рдкреВрдЫ рд╕рдХреЗрдВред

- рдХрджреНрджреВ рдЦрд░реАрджрдиреЗ рдХрд╛ рд╕рдмрд╕реЗ рдЕрдЪреНрдЫрд╛ рд╕рдордп рдХрдм рд╣реИ?
- рдПрдХ рдорд┐рдирд┐рдПрдЪрд░ рдХрджреНрджреВ рдХреЗ рдХреЗрд╕ рдХреА рдХреАрдордд рдХрд┐рддрдиреА рд╣реЛ рд╕рдХрддреА рд╣реИ?
- рдХреНрдпрд╛ рдореБрдЭреЗ рдЙрдиреНрд╣реЗрдВ рдЖрдзреЗ-рдмреБрд╢рд▓ рдмрд╛рд╕реНрдХреЗрдЯ рдореЗрдВ рдЦрд░реАрджрдирд╛ рдЪрд╛рд╣рд┐рдП рдпрд╛ 1 1/9 рдмреБрд╢рд▓ рдмреЙрдХреНрд╕ рдореЗрдВ?
рдЖрдЗрдП рдЗрд╕ рдбреЗрдЯрд╛ рдореЗрдВ рдФрд░ рдЧрд╣рд░рд╛рдИ рд╕реЗ рдЬрд╛рдВрдЪ рдХрд░реЗрдВред

рдкрд┐рдЫрд▓реЗ рдкрд╛рда рдореЗрдВ, рдЖрдкрдиреЗ рдПрдХ Pandas рдбреЗрдЯрд╛ рдлреНрд░реЗрдо рдмрдирд╛рдпрд╛ рдФрд░ рдЗрд╕реЗ рдореВрд▓ рдбреЗрдЯрд╛рд╕реЗрдЯ рдХреЗ рдПрдХ рд╣рд┐рд╕реНрд╕реЗ рд╕реЗ рдЖрдмрд╛рдж рдХрд┐рдпрд╛, рдмреБрд╢рд▓ рджреНрд╡рд╛рд░рд╛ рдореВрд▓реНрдп рдирд┐рд░реНрдзрд╛рд░рдг рдХреЛ рдорд╛рдирдХреАрдХреГрдд рдХрд┐рдпрд╛ред рдРрд╕рд╛ рдХрд░рдиреЗ рд╕реЗ, рд╣рд╛рд▓рд╛рдВрдХрд┐, рдЖрдк рдХреЗрд╡рд▓ рд▓рдЧрднрдЧ 400 рдбреЗрдЯрд╛ рдкреЙрдЗрдВрдЯреНрд╕ рдПрдХрддреНрд░ рдХрд░рдиреЗ рдореЗрдВ рд╕рдХреНрд╖рдо рдереЗ рдФрд░ рдХреЗрд╡рд▓ рдкрддрдЭрдбрд╝ рдХреЗ рдорд╣реАрдиреЛрдВ рдХреЗ рд▓рд┐рдПред

рдЗрд╕ рдкрд╛рда рдХреЗ рд╕рд╛рде рдЖрдиреЗ рд╡рд╛рд▓реА рдиреЛрдЯрдмреБрдХ рдореЗрдВ рд╣рдордиреЗ рдЬреЛ рдбреЗрдЯрд╛ рдкрд╣рд▓реЗ рд╕реЗ рд▓реЛрдб рдХрд┐рдпрд╛ рд╣реИ, рдЙрд╕ рдкрд░ рдПрдХ рдирдЬрд╝рд░ рдбрд╛рд▓реЗрдВред рдбреЗрдЯрд╛ рдкрд╣рд▓реЗ рд╕реЗ рд▓реЛрдб рд╣реИ рдФрд░ рдПрдХ рдкреНрд░рд╛рд░рдВрднрд┐рдХ рдмрд┐рдЦрд░рд╛рд╡ рдкреНрд▓реЙрдЯ рдорд╣реАрдиреЗ рдХреЗ рдбреЗрдЯрд╛ рдХреЛ рджрд┐рдЦрд╛рдиреЗ рдХреЗ рд▓рд┐рдП рдЪрд╛рд░реНрдЯ рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИред рд╣реЛ рд╕рдХрддрд╛ рд╣реИ рдХрд┐ рд╣рдо рдЗрд╕реЗ рдФрд░ рдЕрдзрд┐рдХ рд╕рд╛рдл рдХрд░рдХреЗ рдбреЗрдЯрд╛ рдХреА рдкреНрд░рдХреГрддрд┐ рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рдереЛрдбрд╝реА рдЕрдзрд┐рдХ рдЬрд╛рдирдХрд╛рд░реА рдкреНрд░рд╛рдкреНрдд рдХрд░ рд╕рдХреЗрдВред

## рдПрдХ рд▓реАрдирд┐рдпрд░ рд░рд┐рдЧреНрд░реЗрд╢рди рд░реЗрдЦрд╛

рдЬреИрд╕рд╛ рдХрд┐ рдЖрдкрдиреЗ рдкрд╛рда 1 рдореЗрдВ рд╕реАрдЦрд╛, рд▓реАрдирд┐рдпрд░ рд░рд┐рдЧреНрд░реЗрд╢рди рдЕрднреНрдпрд╛рд╕ рдХрд╛ рд▓рдХреНрд╖реНрдп рдПрдХ рд░реЗрдЦрд╛ рдХреЛ рдкреНрд▓реЙрдЯ рдХрд░рдиреЗ рдореЗрдВ рд╕рдХреНрд╖рдо рд╣реЛрдирд╛ рд╣реИ:

- **рдЪрд░ рд╕рдВрдмрдВрдз рджрд┐рдЦрд╛рдПрдВ**ред рдЪрд░ рдХреЗ рдмреАрдЪ рд╕рдВрдмрдВрдз рджрд┐рдЦрд╛рдПрдВ
- **рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгрд┐рдпрд╛рдБ рдХрд░реЗрдВ**ред рдпрд╣ рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгреА рдХрд░реЗрдВ рдХрд┐ рдПрдХ рдирдпрд╛ рдбреЗрдЯрд╛ рдкреЙрдЗрдВрдЯ рдЙрд╕ рд░реЗрдЦрд╛ рдХреЗ рд╕рдВрдмрдВрдз рдореЗрдВ рдХрд╣рд╛рдБ рдЧрд┐рд░ рд╕рдХрддрд╛ рд╣реИред

рдЗрд╕ рдкреНрд░рдХрд╛рд░ рдХреА рд░реЗрдЦрд╛ рдЦреАрдВрдЪрдиреЗ рдХреЗ рд▓рд┐рдП **рд▓реАрд╕реНрдЯ-рд╕реНрдХреНрд╡реЗрд░реНрд╕ рд░рд┐рдЧреНрд░реЗрд╢рди** рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд┐рдпрд╛ рдЬрд╛рддрд╛ рд╣реИред 'рд▓реАрд╕реНрдЯ-рд╕реНрдХреНрд╡реЗрд░реНрд╕' рд╢рдмреНрдж рдХрд╛ рдЕрд░реНрде рд╣реИ рдХрд┐ рд░рд┐рдЧреНрд░реЗрд╢рди рд░реЗрдЦрд╛ рдХреЗ рдЪрд╛рд░реЛрдВ рдУрд░ рдХреЗ рд╕рднреА рдбреЗрдЯрд╛ рдкреЙрдЗрдВрдЯреНрд╕ рдХреЛ рд╡рд░реНрдЧрд╛рдХрд╛рд░ рдХрд┐рдпрд╛ рдЬрд╛рддрд╛ рд╣реИ рдФрд░ рдлрд┐рд░ рдЬреЛрдбрд╝рд╛ рдЬрд╛рддрд╛ рд╣реИред рдЖрджрд░реНрд╢ рд░реВрдк рд╕реЗ, рд╡рд╣ рдЕрдВрддрд┐рдо рдпреЛрдЧ рдЬрд┐рддрдирд╛ рд╕рдВрднрд╡ рд╣реЛ рдЙрддрдирд╛ рдЫреЛрдЯрд╛ рд╣реЛрддрд╛ рд╣реИ, рдХреНрдпреЛрдВрдХрд┐ рд╣рдо рдХрдо рд╕рдВрдЦреНрдпрд╛ рдореЗрдВ рддреНрд░реБрдЯрд┐рдпреЛрдВ, рдпрд╛ `least-squares` рдЪрд╛рд╣рддреЗ рд╣реИрдВред

рд╣рдо рдРрд╕рд╛ рдЗрд╕рд▓рд┐рдП рдХрд░рддреЗ рд╣реИрдВ рдХреНрдпреЛрдВрдХрд┐ рд╣рдо рдПрдХ рдРрд╕реА рд░реЗрдЦрд╛ рдХреЛ рдореЙрдбрд▓ рдмрдирд╛рдирд╛ рдЪрд╛рд╣рддреЗ рд╣реИрдВ рдЬрд┐рд╕рдореЗрдВ рд╣рдорд╛рд░реЗ рд╕рднреА рдбреЗрдЯрд╛ рдкреЙрдЗрдВрдЯреНрд╕ рд╕реЗ рд╕рдмрд╕реЗ рдХрдо рд╕рдВрдЪрдпреА рджреВрд░реА рд╣реЛред рд╣рдо рдЙрдиреНрд╣реЗрдВ рдЬреЛрдбрд╝рдиреЗ рд╕реЗ рдкрд╣рд▓реЗ рд╢рдмреНрджреЛрдВ рдХреЛ рд╡рд░реНрдЧрд╛рдХрд╛рд░ рднреА рдХрд░рддреЗ рд╣реИрдВ рдХреНрдпреЛрдВрдХрд┐ рд╣рдо рдЗрд╕рдХреА рджрд┐рд╢рд╛ рдХреЗ рдмрдЬрд╛рдп рдЗрд╕рдХреЗ рдкрд░рд┐рдорд╛рдг рд╕реЗ рдЪрд┐рдВрддрд┐рдд рд╣реИрдВред

> **ЁЯзо рдЧрдгрд┐рдд рджрд┐рдЦрд╛рдПрдВ**
> 
> рдЗрд╕ рд░реЗрдЦрд╛ рдХреЛ, рдЬрд┐рд╕реЗ _рд╕рдмрд╕реЗ рдЕрдЪреНрдЫрд╛ рдлрд┐рдЯ_ рдХрд╣рд╛ рдЬрд╛рддрд╛ рд╣реИ, [рдПрдХ рд╕рдореАрдХрд░рдг](https://en.wikipedia.org/wiki/Simple_linear_regression) рджреНрд╡рд╛рд░рд╛ рд╡реНрдпрдХреНрдд рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИ:
> 
> ```
> Y = a + bX
> ```
>
> `X` is the 'explanatory variable'. `Y` is the 'dependent variable'. The slope of the line is `b` and `a` is the y-intercept, which refers to the value of `Y` when `X = 0`. 
>
>![calculate the slope](../../../../translated_images/slope.f3c9d5910ddbfcf9096eb5564254ba22c9a32d7acd7694cab905d29ad8261db3.hi.png)
>
> First, calculate the slope `b`. Infographic by [Jen Looper](https://twitter.com/jenlooper)
>
> In other words, and referring to our pumpkin data's original question: "predict the price of a pumpkin per bushel by month", `X` would refer to the price and `Y` would refer to the month of sale. 
>
>![complete the equation](../../../../translated_images/calculation.a209813050a1ddb141cdc4bc56f3af31e67157ed499e16a2ecf9837542704c94.hi.png)
>
> Calculate the value of Y. If you're paying around $4, it must be April! Infographic by [Jen Looper](https://twitter.com/jenlooper)
>
> The math that calculates the line must demonstrate the slope of the line, which is also dependent on the intercept, or where `Y` is situated when `X = 0`.
>
> You can observe the method of calculation for these values on the [Math is Fun](https://www.mathsisfun.com/data/least-squares-regression.html) web site. Also visit [this Least-squares calculator](https://www.mathsisfun.com/data/least-squares-calculator.html) to watch how the numbers' values impact the line.

## Correlation

One more term to understand is the **Correlation Coefficient** between given X and Y variables. Using a scatterplot, you can quickly visualize this coefficient. A plot with datapoints scattered in a neat line have high correlation, but a plot with datapoints scattered everywhere between X and Y have a low correlation.

A good linear regression model will be one that has a high (nearer to 1 than 0) Correlation Coefficient using the Least-Squares Regression method with a line of regression.

тЬЕ Run the notebook accompanying this lesson and look at the Month to Price scatterplot. Does the data associating Month to Price for pumpkin sales seem to have high or low correlation, according to your visual interpretation of the scatterplot? Does that change if you use more fine-grained measure instead of `Month`, eg. *day of the year* (i.e. number of days since the beginning of the year)?

In the code below, we will assume that we have cleaned up the data, and obtained a data frame called `new_pumpkins`, similar to the following:

ID | Month | DayOfYear | Variety | City | Package | Low Price | High Price | Price
---|-------|-----------|---------|------|---------|-----------|------------|-------
70 | 9 | 267 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 15.0 | 15.0 | 13.636364
71 | 9 | 267 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 18.0 | 18.0 | 16.363636
72 | 10 | 274 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 18.0 | 18.0 | 16.363636
73 | 10 | 274 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 17.0 | 17.0 | 15.454545
74 | 10 | 281 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 15.0 | 15.0 | 13.636364

> The code to clean the data is available in [`notebook.ipynb`](../../../../2-Regression/3-Linear/notebook.ipynb). We have performed the same cleaning steps as in the previous lesson, and have calculated `DayOfYear` рдХреЙрд▓рдо рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдирд┐рдореНрдирд▓рд┐рдЦрд┐рдд рдЕрднрд┐рд╡реНрдпрдХреНрддрд┐ рдХреЗ рд╕рд╛рде:

```python
day_of_year = pd.to_datetime(pumpkins['Date']).apply(lambda dt: (dt-datetime(dt.year,1,1)).days)
```

рдЕрдм рдЬрдм рдЖрдкрдХреЗ рдкрд╛рд╕ рд▓реАрдирд┐рдпрд░ рд░рд┐рдЧреНрд░реЗрд╢рди рдХреЗ рдкреАрдЫреЗ рдХреЗ рдЧрдгрд┐рдд рдХреА рд╕рдордЭ рд╣реИ, рддреЛ рдЖрдЗрдП рдПрдХ рд░рд┐рдЧреНрд░реЗрд╢рди рдореЙрдбрд▓ рдмрдирд╛рдПрдВ рдпрд╣ рджреЗрдЦрдиреЗ рдХреЗ рд▓рд┐рдП рдХрд┐ рд╣рдо рдХреМрди рд╕рд╛ рдХрджреНрджреВ рдкреИрдХреЗрдЬ рд╕рдмрд╕реЗ рдЕрдЪреНрдЫреА рдХрджреНрджреВ рдХреАрдорддреЛрдВ рдХреЗ рд╕рд╛рде рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгреА рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред рдХреЛрдИ рд╡реНрдпрдХреНрддрд┐ рдЬреЛ рдЫреБрдЯреНрдЯреА рдХреЗ рдХрджреНрджреВ рдкреИрдЪ рдХреЗ рд▓рд┐рдП рдХрджреНрджреВ рдЦрд░реАрдж рд░рд╣рд╛ рд╣реИ, рд╡рд╣ рдЗрд╕ рдЬрд╛рдирдХрд╛рд░реА рдХреЛ рдХрджреНрджреВ рдкреИрдЪ рдХреЗ рд▓рд┐рдП рдХрджреНрджреВ рдкреИрдХреЗрдЬреЛрдВ рдХреА рдЦрд░реАрдж рдХреЛ рдЕрдиреБрдХреВрд▓рд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдЙрдкрдпреЛрдЧ рдХрд░рдирд╛ рдЪрд╛рд╣ рд╕рдХрддрд╛ рд╣реИред

## рд╕рд╣рд╕рдВрдмрдВрдз рдХреА рддрд▓рд╛рд╢ рдореЗрдВ

[![ML for beginners - Looking for Correlation: The Key to Linear Regression](https://img.youtube.com/vi/uoRq-lW2eQo/0.jpg)](https://youtu.be/uoRq-lW2eQo "ML for beginners - Looking for Correlation: The Key to Linear Regression")

> ЁЯОе рдКрдкрд░ рджреА рдЧрдИ рдЫрд╡рд┐ рдкрд░ рдХреНрд▓рд┐рдХ рдХрд░реЗрдВ рд╕рд╣рд╕рдВрдмрдВрдз рдХрд╛ рдПрдХ рд╕рдВрдХреНрд╖рд┐рдкреНрдд рд╡реАрдбрд┐рдпреЛ рдЕрд╡рд▓реЛрдХрди рджреЗрдЦрдиреЗ рдХреЗ рд▓рд┐рдПред

рдкрд┐рдЫрд▓реЗ рдкрд╛рда рд╕реЗ рдЖрдкрдиреЗ рд╢рд╛рдпрдж рджреЗрдЦрд╛ рд╣реИ рдХрд┐ рд╡рд┐рднрд┐рдиреНрди рдорд╣реАрдиреЛрдВ рдХреЗ рд▓рд┐рдП рдФрд╕рдд рдХреАрдордд рдЗрд╕ рдкреНрд░рдХрд╛рд░ рджрд┐рдЦрддреА рд╣реИ:

<img alt="Average price by month" src="../2-Data/images/barchart.png" width="50%"/>

рдпрд╣ рд╕реБрдЭрд╛рд╡ рджреЗрддрд╛ рд╣реИ рдХрд┐ рдХреБрдЫ рд╕рд╣рд╕рдВрдмрдВрдз рд╣реЛрдирд╛ рдЪрд╛рд╣рд┐рдП, рдФрд░ рд╣рдо `Month` and `Price`, or between `DayOfYear` and `Price`. Here is the scatter plot that shows the latter relationship:

<img alt="Scatter plot of Price vs. Day of Year" src="images/scatter-dayofyear.png" width="50%" /> 

Let's see if there is a correlation using the `corr` рдлрд╝рдВрдХреНрд╢рди рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ `Month` and `Price` рдХреЗ рдмреАрдЪ рд╕рдВрдмрдВрдз рдХреА рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгреА рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рд▓реАрдирд┐рдпрд░ рд░рд┐рдЧреНрд░реЗрд╢рди рдореЙрдбрд▓ рдХреЛ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд░рдиреЗ рдХрд╛ рдкреНрд░рдпрд╛рд╕ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ:

```python
print(new_pumpkins['Month'].corr(new_pumpkins['Price']))
print(new_pumpkins['DayOfYear'].corr(new_pumpkins['Price']))
```

рдРрд╕рд╛ рд▓рдЧрддрд╛ рд╣реИ рдХрд┐ рд╕рд╣рд╕рдВрдмрдВрдз рдХрд╛рдлреА рдЫреЛрдЯрд╛ рд╣реИ, -0.15 `Month` and -0.17 by the `DayOfMonth`, but there could be another important relationship. It looks like there are different clusters of prices corresponding to different pumpkin varieties. To confirm this hypothesis, let's plot each pumpkin category using a different color. By passing an `ax` parameter to the `scatter` рдкреНрд▓реЙрдЯрд┐рдВрдЧ рдлрд╝рдВрдХреНрд╢рди рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рд╣рдо рд╕рднреА рдкреЙрдЗрдВрдЯреНрд╕ рдХреЛ рдПрдХ рд╣реА рдЧреНрд░рд╛рдл рдкрд░ рдкреНрд▓реЙрдЯ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ:

```python
ax=None
colors = ['red','blue','green','yellow']
for i,var in enumerate(new_pumpkins['Variety'].unique()):
    df = new_pumpkins[new_pumpkins['Variety']==var]
    ax = df.plot.scatter('DayOfYear','Price',ax=ax,c=colors[i],label=var)
```

<img alt="Scatter plot of Price vs. Day of Year" src="images/scatter-dayofyear-color.png" width="50%" /> 

рд╣рдорд╛рд░реА рдЬрд╛рдВрдЪ рд╕реЗ рдкрддрд╛ рдЪрд▓рддрд╛ рд╣реИ рдХрд┐ рд╡рд┐рд╡рд┐рдзрддрд╛ рдХрд╛ рд╡рд╛рд╕реНрддрд╡рд┐рдХ рдмрд┐рдХреНрд░реА рддрд┐рдерд┐ рдХреА рддреБрд▓рдирд╛ рдореЗрдВ рд╕рдордЧреНрд░ рдореВрд▓реНрдп рдкрд░ рдЕрдзрд┐рдХ рдкреНрд░рднрд╛рд╡ рд╣реИред рд╣рдо рдЗрд╕реЗ рдПрдХ рдмрд╛рд░ рдЧреНрд░рд╛рдл рдХреЗ рд╕рд╛рде рджреЗрдЦ рд╕рдХрддреЗ рд╣реИрдВ:

```python
new_pumpkins.groupby('Variety')['Price'].mean().plot(kind='bar')
```

<img alt="Bar graph of price vs variety" src="images/price-by-variety.png" width="50%" /> 

рдЖрдЗрдП рдлрд┐рд▓рд╣рд╛рд▓ рдХреЗрд╡рд▓ рдПрдХ рдХрджреНрджреВ рдХреА рдХрд┐рд╕реНрдо, 'рдкрд╛рдИ рдкреНрд░рдХрд╛рд░', рдкрд░ рдзреНрдпрд╛рди рдХреЗрдВрджреНрд░рд┐рдд рдХрд░реЗрдВ рдФрд░ рджреЗрдЦреЗрдВ рдХрд┐ рддрд╛рд░реАрдЦ рдХрд╛ рдореВрд▓реНрдп рдкрд░ рдХреНрдпрд╛ рдкреНрд░рднрд╛рд╡ рдкрдбрд╝рддрд╛ рд╣реИ:

```python
pie_pumpkins = new_pumpkins[new_pumpkins['Variety']=='PIE TYPE']
pie_pumpkins.plot.scatter('DayOfYear','Price') 
```
<img alt="Scatter plot of Price vs. Day of Year" src="images/pie-pumpkins-scatter.png" width="50%" /> 

рдпрджрд┐ рд╣рдо рдЕрдм `Price` and `DayOfYear` using `corr` function, we will get something like `-0.27` рдХреЗ рдмреАрдЪ рд╕рд╣рд╕рдВрдмрдВрдз рдХреА рдЧрдгрдирд╛ рдХрд░рддреЗ рд╣реИрдВ - рдЬрд┐рд╕рдХрд╛ рдЕрд░реНрде рд╣реИ рдХрд┐ рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгреА рдореЙрдбрд▓ рдХреЛ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд░рдирд╛ рд╕рдордЭ рдореЗрдВ рдЖрддрд╛ рд╣реИред

> рдПрдХ рд▓реАрдирд┐рдпрд░ рд░рд┐рдЧреНрд░реЗрд╢рди рдореЙрдбрд▓ рдХреЛ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд░рдиреЗ рд╕реЗ рдкрд╣рд▓реЗ, рдпрд╣ рд╕реБрдирд┐рд╢реНрдЪрд┐рдд рдХрд░рдирд╛ рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╣реИ рдХрд┐ рд╣рдорд╛рд░рд╛ рдбреЗрдЯрд╛ рд╕рд╛рдлрд╝ рд╣реИред рд▓реАрдирд┐рдпрд░ рд░рд┐рдЧреНрд░реЗрд╢рди рд▓рд╛рдкрддрд╛ рдореВрд▓реНрдпреЛрдВ рдХреЗ рд╕рд╛рде рдЕрдЪреНрдЫреА рддрд░рд╣ рд╕реЗ рдХрд╛рдо рдирд╣реАрдВ рдХрд░рддрд╛ рд╣реИ, рдЗрд╕рд▓рд┐рдП рд╕рднреА рдЦрд╛рд▓реА рдХреЛрд╢рд┐рдХрд╛рдУрдВ рд╕реЗ рдЫреБрдЯрдХрд╛рд░рд╛ рдкрд╛рдирд╛ рд╕рдордЭ рдореЗрдВ рдЖрддрд╛ рд╣реИ:

```python
pie_pumpkins.dropna(inplace=True)
pie_pumpkins.info()
```

рдПрдХ рдФрд░ рджреГрд╖реНрдЯрд┐рдХреЛрдг рдпрд╣ рд╣реЛрдЧрд╛ рдХрд┐ рдЙрди рдЦрд╛рд▓реА рдореВрд▓реНрдпреЛрдВ рдХреЛ рд╕рдВрдмрдВрдзрд┐рдд рдХреЙрд▓рдо рд╕реЗ рдФрд╕рдд рдорд╛рдиреЛрдВ рд╕реЗ рднрд░ рджрд┐рдпрд╛ рдЬрд╛рдПред

## рд╕рд░рд▓ рд▓реАрдирд┐рдпрд░ рд░рд┐рдЧреНрд░реЗрд╢рди

[![ML for beginners - Linear and Polynomial Regression using Scikit-learn](https://img.youtube.com/vi/e4c_UP2fSjg/0.jpg)](https://youtu.be/e4c_UP2fSjg "ML for beginners - Linear and Polynomial Regression using Scikit-learn")

> ЁЯОе рдКрдкрд░ рджреА рдЧрдИ рдЫрд╡рд┐ рдкрд░ рдХреНрд▓рд┐рдХ рдХрд░реЗрдВ рд▓реАрдирд┐рдпрд░ рдФрд░ рдкреЛрд▓рд┐рдиреЛрдорд┐рдпрд▓ рд░рд┐рдЧреНрд░реЗрд╢рди рдХрд╛ рдПрдХ рд╕рдВрдХреНрд╖рд┐рдкреНрдд рд╡реАрдбрд┐рдпреЛ рдЕрд╡рд▓реЛрдХрди рджреЗрдЦрдиреЗ рдХреЗ рд▓рд┐рдПред

рд╣рдорд╛рд░реЗ рд▓реАрдирд┐рдпрд░ рд░рд┐рдЧреНрд░реЗрд╢рди рдореЙрдбрд▓ рдХреЛ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП, рд╣рдо **Scikit-learn** рд▓рд╛рдЗрдмреНрд░реЗрд░реА рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░реЗрдВрдЧреЗред

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
```

рд╣рдо рдЗрдирдкреБрдЯ рдорд╛рдиреЛрдВ (рдлреАрдЪрд░реНрд╕) рдФрд░ рдЕрдкреЗрдХреНрд╖рд┐рдд рдЖрдЙрдЯрдкреБрдЯ (рд▓реЗрдмрд▓) рдХреЛ рдЕрд▓рдЧ-рдЕрд▓рдЧ numpy arrays рдореЗрдВ рдЕрд▓рдЧ рдХрд░рдХреЗ рд╢реБрд░реВ рдХрд░рддреЗ рд╣реИрдВ:

```python
X = pie_pumpkins['DayOfYear'].to_numpy().reshape(-1,1)
y = pie_pumpkins['Price']
```

> рдзреНрдпрд╛рди рджреЗрдВ рдХрд┐ рд╣рдореЗрдВ рдЗрдирдкреБрдЯ рдбреЗрдЯрд╛ рдкрд░ `reshape` рдХрд░рдирд╛ рдкрдбрд╝рд╛ рддрд╛рдХрд┐ рд▓реАрдирд┐рдпрд░ рд░рд┐рдЧреНрд░реЗрд╢рди рдкреИрдХреЗрдЬ рдЗрд╕реЗ рд╕рд╣реА рдврдВрдЧ рд╕реЗ рд╕рдордЭ рд╕рдХреЗред рд▓реАрдирд┐рдпрд░ рд░рд┐рдЧреНрд░реЗрд╢рди рдПрдХ рдЗрдирдкреБрдЯ рдХреЗ рд░реВрдк рдореЗрдВ 2D-array рдХреА рдЕрдкреЗрдХреНрд╖рд╛ рдХрд░рддрд╛ рд╣реИ, рдЬрд╣рд╛рдВ array рдХреА рдкреНрд░рддреНрдпреЗрдХ рдкрдВрдХреНрддрд┐ рдЗрдирдкреБрдЯ рдлреАрдЪрд░реНрд╕ рдХреЗ рд╡реЗрдХреНрдЯрд░ рдХреЗ рдЕрдиреБрд░реВрдк рд╣реЛрддреА рд╣реИред рд╣рдорд╛рд░реЗ рдорд╛рдорд▓реЗ рдореЗрдВ, рдЪреВрдВрдХрд┐ рд╣рдорд╛рд░реЗ рдкрд╛рд╕ рдХреЗрд╡рд▓ рдПрдХ рдЗрдирдкреБрдЯ рд╣реИ - рд╣рдореЗрдВ рдЖрдХрд╛рд░ N├Ч1 рдХреЗ рд╕рд╛рде рдПрдХ array рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╣реИ, рдЬрд╣рд╛рдВ N рдбреЗрдЯрд╛рд╕реЗрдЯ рдХрд╛ рдЖрдХрд╛рд░ рд╣реИред

рдлрд┐рд░, рд╣рдореЗрдВ рдбреЗрдЯрд╛ рдХреЛ рдЯреНрд░реЗрди рдФрд░ рдЯреЗрд╕реНрдЯ рдбреЗрдЯрд╛рд╕реЗрдЯреНрд╕ рдореЗрдВ рд╡рд┐рднрд╛рдЬрд┐рдд рдХрд░рдиреЗ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╣реИ, рддрд╛рдХрд┐ рд╣рдо рдкреНрд░рд╢рд┐рдХреНрд╖рдг рдХреЗ рдмрд╛рдж рдЕрдкрдиреЗ рдореЙрдбрд▓ рдХреЛ рдорд╛рдиреНрдп рдХрд░ рд╕рдХреЗрдВ:

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
```

рдЕрдВрдд рдореЗрдВ, рд╡рд╛рд╕реНрддрд╡рд┐рдХ рд▓реАрдирд┐рдпрд░ рд░рд┐рдЧреНрд░реЗрд╢рди рдореЙрдбрд▓ рдХреЛ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд░рдирд╛ рдХреЗрд╡рд▓ рджреЛ рдкрдВрдХреНрддрд┐рдпреЛрдВ рдХрд╛ рдХреЛрдб рд▓реЗрддрд╛ рд╣реИред рд╣рдо `LinearRegression` object, and fit it to our data using the `fit` рдореЗрдердб рдХреЛ рдкрд░рд┐рднрд╛рд╖рд┐рдд рдХрд░рддреЗ рд╣реИрдВ:

```python
lin_reg = LinearRegression()
lin_reg.fit(X_train,y_train)
```

`LinearRegression` object after `fit`-ting contains all the coefficients of the regression, which can be accessed using `.coef_` property. In our case, there is just one coefficient, which should be around `-0.017`. It means that prices seem to drop a bit with time, but not too much, around 2 cents per day. We can also access the intersection point of the regression with Y-axis using `lin_reg.intercept_` - it will be around `21` рд╣рдорд╛рд░реЗ рдорд╛рдорд▓реЗ рдореЗрдВ, рд╡рд░реНрд╖ рдХреА рд╢реБрд░реБрдЖрдд рдореЗрдВ рдХреАрдордд рдХреЛ рдЗрдВрдЧрд┐рдд рдХрд░рддрд╛ рд╣реИред

рдпрд╣ рджреЗрдЦрдиреЗ рдХреЗ рд▓рд┐рдП рдХрд┐ рд╣рдорд╛рд░рд╛ рдореЙрдбрд▓ рдХрд┐рддрдирд╛ рд╕рдЯреАрдХ рд╣реИ, рд╣рдо рдПрдХ рдЯреЗрд╕реНрдЯ рдбреЗрдЯрд╛рд╕реЗрдЯ рдкрд░ рдХреАрдорддреЛрдВ рдХреА рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгреА рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ, рдФрд░ рдлрд┐рд░ рдпрд╣ рдорд╛рдк рд╕рдХрддреЗ рд╣реИрдВ рдХрд┐ рд╣рдорд╛рд░реА рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгрд┐рдпрд╛рдБ рдЕрдкреЗрдХреНрд╖рд┐рдд рдорд╛рдиреЛрдВ рдХреЗ рдХрд┐рддрдиреЗ рдХрд░реАрдм рд╣реИрдВред рдпрд╣ рдореАрди рд╕реНрдХреНрд╡рд╛рдпрд░ рдПрд░рд░ (MSE) рдореЗрдЯреНрд░рд┐рдХреНрд╕ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИ, рдЬреЛ рдЕрдкреЗрдХреНрд╖рд┐рдд рдФрд░ рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгреА рдХрд┐рдП рдЧрдП рдореВрд▓реНрдп рдХреЗ рдмреАрдЪ рд╕рднреА рд╡рд░реНрдЧрд╛рдХрд╛рд░ рдЕрдВрддрд░реЛрдВ рдХрд╛ рдФрд╕рдд рд╣реИред

```python
pred = lin_reg.predict(X_test)

mse = np.sqrt(mean_squared_error(y_test,pred))
print(f'Mean error: {mse:3.3} ({mse/np.mean(pred)*100:3.3}%)')
```

рд╣рдорд╛рд░реА рддреНрд░реБрдЯрд┐ рд▓рдЧрднрдЧ 2 рдЕрдВрдХ рдХреЗ рдЖрд╕рдкрд╛рд╕ рд▓рдЧрддреА рд╣реИ, рдЬреЛ ~17% рд╣реИред рдореЙрдбрд▓ рдЧреБрдгрд╡рддреНрддрд╛ рдХрд╛ рдПрдХ рдФрд░ рд╕рдВрдХреЗрддрдХ **рдирд┐рд░реНрдзрд╛рд░рдг рдХрд╛ рдЧреБрдгрд╛рдВрдХ** рд╣реИ, рдЬрд┐рд╕реЗ рдЗрд╕ рддрд░рд╣ рд╕реЗ рдкреНрд░рд╛рдкреНрдд рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИ:

```python
score = lin_reg.score(X_train,y_train)
print('Model determination: ', score)
```
рдпрджрд┐ рдорд╛рди 0 рд╣реИ, рддреЛ рдЗрд╕рдХрд╛ рдорддрд▓рдм рд╣реИ рдХрд┐ рдореЙрдбрд▓ рдЗрдирдкреБрдЯ рдбреЗрдЯрд╛ рдХреЛ рдзреНрдпрд╛рди рдореЗрдВ рдирд╣реАрдВ рд░рдЦрддрд╛ рд╣реИ, рдФрд░ *рд╕рдмрд╕реЗ рдЦрд░рд╛рдм рд▓реАрдирд┐рдпрд░ рдкреНрд░реЗрдбрд┐рдХреНрдЯрд░* рдХреЗ рд░реВрдк рдореЗрдВ рдХрд╛рд░реНрдп рдХрд░рддрд╛ рд╣реИ, рдЬреЛ рдкрд░рд┐рдгрд╛рдо рдХрд╛ рдХреЗрд╡рд▓ рдПрдХ рдФрд╕рдд рдорд╛рди рд╣реИред рдорд╛рди 1 рдХрд╛ рдЕрд░реНрде рд╣реИ рдХрд┐ рд╣рдо рд╕рднреА рдЕрдкреЗрдХреНрд╖рд┐рдд рдЖрдЙрдЯрдкреБрдЯ рдХреЛ рдкреВрд░реА рддрд░рд╣ рд╕реЗ рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгреА рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред рд╣рдорд╛рд░реЗ рдорд╛рдорд▓реЗ рдореЗрдВ, рдЧреБрдгрд╛рдВрдХ рд▓рдЧрднрдЧ 0.06 рд╣реИ, рдЬреЛ рдХрд╛рдлреА рдХрдо рд╣реИред

рд╣рдо рдкрд░реАрдХреНрд╖рдг рдбреЗрдЯрд╛ рдХреЛ рд░рд┐рдЧреНрд░реЗрд╢рди рд▓рд╛рдЗрди рдХреЗ рд╕рд╛рде рдкреНрд▓реЙрдЯ рднреА рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ рддрд╛рдХрд┐ рдпрд╣ рдмреЗрд╣рддрд░ рддрд░реАрдХреЗ рд╕реЗ рджреЗрдЦрд╛ рдЬрд╛ рд╕рдХреЗ рдХрд┐ рд╣рдорд╛рд░реЗ рдорд╛рдорд▓реЗ рдореЗрдВ рд░рд┐рдЧреНрд░реЗрд╢рди рдХреИрд╕реЗ рдХрд╛рдо рдХрд░рддрд╛ рд╣реИ:

```python
plt.scatter(X_test,y_test)
plt.plot(X_test,pred)
```

<img alt="Linear regression" src="images/linear-results.png" width="50%" />

## рдкреЛрд▓рд┐рдиреЛрдорд┐рдпрд▓ рд░рд┐рдЧреНрд░реЗрд╢рди

рд▓реАрдирд┐рдпрд░ рд░рд┐рдЧреНрд░реЗрд╢рди рдХрд╛ рдПрдХ рдФрд░ рдкреНрд░рдХрд╛рд░ рдкреЛрд▓рд┐рдиреЛрдорд┐рдпрд▓ рд░рд┐рдЧреНрд░реЗрд╢рди рд╣реИред рдЬрдмрдХрд┐ рдХрднреА-рдХрднреА рдЪрд░ рдХреЗ рдмреАрдЪ рдПрдХ рд▓реАрдирд┐рдпрд░ рд╕рдВрдмрдВрдз рд╣реЛрддрд╛ рд╣реИ - рдХрджреНрджреВ рдХрд╛ рдЖрдХрд╛рд░ рдЬрд┐рддрдирд╛ рдмрдбрд╝рд╛ рд╣реЛрддрд╛ рд╣реИ, рдХреАрдордд рдЙрддрдиреА рд╣реА рдЕрдзрд┐рдХ рд╣реЛрддреА рд╣реИ - рдХрднреА-рдХрднреА рдЗрди рд╕рдВрдмрдВрдзреЛрдВ рдХреЛ рдПрдХ рд╡рд┐рдорд╛рди рдпрд╛ рд╕реАрдзреА рд░реЗрдЦрд╛ рдХреЗ рд░реВрдк рдореЗрдВ рдкреНрд▓реЙрдЯ рдирд╣реАрдВ рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИред

тЬЕ рдпрд╣рд╛рдВ [рдХреБрдЫ рдФрд░ рдЙрджрд╛рд╣рд░рдг](https://online.stat.psu.edu/stat501/lesson/9/9.8) рд╣реИрдВ рдЬрд┐рдирдореЗрдВ рдкреЛрд▓рд┐рдиреЛрдорд┐рдпрд▓ рд░рд┐рдЧреНрд░реЗрд╢рди рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХрддрд╛ рд╣реИред

рдбреЗрдЯ рдФрд░ рдХреАрдордд рдХреЗ рдмреАрдЪ рд╕рдВрдмрдВрдз рдкрд░ рдлрд┐рд░ рд╕реЗ рдПрдХ рдирдЬрд╝рд░ рдбрд╛рд▓реЗрдВред рдХреНрдпрд╛ рдпрд╣ рдмрд┐рдЦрд░рд╛рд╡ рдкреНрд▓реЙрдЯ рдРрд╕рд╛ рд▓рдЧрддрд╛ рд╣реИ рдХрд┐ рдЗрд╕реЗ рд╕реАрдзреЗ рд░реЗрдЦрд╛ рджреНрд╡рд╛рд░рд╛ рд╡рд┐рд╢реНрд▓реЗрд╖рд┐рдд рдХрд┐рдпрд╛ рдЬрд╛рдирд╛ рдЪрд╛рд╣рд┐рдП? рдХреНрдпрд╛ рдХреАрдорддреЗрдВ рдирд╣реАрдВ рдмрджрд▓ рд╕рдХрддреАрдВ? рдЗрд╕ рдорд╛рдорд▓реЗ рдореЗрдВ, рдЖрдк рдкреЛрд▓рд┐рдиреЛрдорд┐рдпрд▓ рд░рд┐рдЧреНрд░реЗрд╢рди рдХрд╛ рдкреНрд░рдпрд╛рд╕ рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред

тЬЕ рдкреЛрд▓рд┐рдиреЛрдорд┐рдпрд▓ рдЧрдгрд┐рддреАрдп рдЕрднрд┐рд╡реНрдпрдХреНрддрд┐рдпрд╛рдБ рд╣реИрдВ рдЬрд┐рдирдореЗрдВ рдПрдХ рдпрд╛ рдЕрдзрд┐рдХ рдЪрд░ рдФрд░ рдЧреБрдгрд╛рдВрдХ рд╢рд╛рдорд┐рд▓ рд╣реЛ рд╕рдХрддреЗ рд╣реИрдВ

рдкреЛрд▓рд┐рдиреЛрдорд┐рдпрд▓ рд░рд┐рдЧреНрд░реЗрд╢рди рдПрдХ рдШреБрдорд╛рд╡рджрд╛рд░ рд░реЗрдЦрд╛ рдмрдирд╛рддрд╛ рд╣реИ рддрд╛рдХрд┐ рдЧреИрд░-рд▓реАрдирд┐рдпрд░ рдбреЗрдЯрд╛ рдХреЛ рдмреЗрд╣рддрд░ рддрд░реАрдХреЗ рд╕реЗ рдлрд┐рдЯ рдХрд┐рдпрд╛ рдЬрд╛ рд╕рдХреЗред рд╣рдорд╛рд░реЗ рдорд╛рдорд▓реЗ рдореЗрдВ, рдпрджрд┐ рд╣рдо рдЗрдирдкреБрдЯ рдбреЗрдЯрд╛ рдореЗрдВ рдПрдХ рд╡рд░реНрдЧреАрдп `DayOfYear` рдЪрд░ рд╢рд╛рдорд┐рд▓ рдХрд░рддреЗ рд╣реИрдВ, рддреЛ рд╣рдореЗрдВ рдЕрдкрдиреЗ рдбреЗрдЯрд╛ рдХреЛ рдПрдХ рдкрд░рд╡рд▓рдпрд┐рдХ рд╡рдХреНрд░ рдХреЗ рд╕рд╛рде рдлрд┐рдЯ рдХрд░рдиреЗ рдореЗрдВ рд╕рдХреНрд╖рдо рд╣реЛрдирд╛ рдЪрд╛рд╣рд┐рдП, рдЬрд┐рд╕рдореЗрдВ рд╡рд░реНрд╖ рдХреЗ рдПрдХ рдирд┐рд╢реНрдЪрд┐рдд рдмрд┐рдВрджреБ рдкрд░ рдиреНрдпреВрдирддрдо рд╣реЛрдЧрд╛ред

Scikit-learn рдореЗрдВ рд╡рд┐рднрд┐рдиреНрди рдбреЗрдЯрд╛ рдкреНрд░реЛрд╕реЗрд╕рд┐рдВрдЧ рдЪрд░рдгреЛрдВ рдХреЛ рдПрдХ рд╕рд╛рде рд╕рдВрдпреЛрдЬрд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдПрдХ рдЙрдкрдпреЛрдЧреА [pipeline API](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html?highlight=pipeline#sklearn.pipeline.make_pipeline) рд╢рд╛рдорд┐рд▓ рд╣реИред рдПрдХ **pipeline** **рдЕрдиреБрдорд╛рдирдХреЛрдВ** рдХреА рдПрдХ рд╢реНрд░реГрдВрдЦрд▓рд╛ рд╣реИред рд╣рдорд╛рд░реЗ рдорд╛рдорд▓реЗ рдореЗрдВ, рд╣рдо рдПрдХ pipeline рдмрдирд╛рдПрдВрдЧреЗ рдЬреЛ рдкрд╣рд▓реЗ рд╣рдорд╛рд░реЗ рдореЙрдбрд▓ рдореЗрдВ рдкреЛрд▓рд┐рдиреЛрдорд┐рдпрд▓ рдлреАрдЪрд░реНрд╕ рдЬреЛрдбрд╝рддрд╛ рд╣реИ, рдФрд░ рдлрд┐рд░ рд░рд┐рдЧреНрд░реЗрд╢рди рдХреЛ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд░рддрд╛ рд╣реИ:

```python
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

pipeline = make_pipeline(PolynomialFeatures(2), LinearRegression())

pipeline.fit(X_train,y_train)
```

`PolynomialFeatures(2)` means that we will include all second-degree polynomials from the input data. In our case it will just mean `DayOfYear`<sup>2</sup>, but given two input variables X and Y, this will add X<sup>2</sup>, XY and Y<sup>2</sup>. We may also use higher degree polynomials if we want.

Pipelines can be used in the same manner as the original `LinearRegression` object, i.e. we can `fit` the pipeline, and then use `predict` to get the prediction results. Here is the graph showing test data, and the approximation curve:

<img alt="Polynomial regression" src="images/poly-results.png" width="50%" />

Using Polynomial Regression, we can get slightly lower MSE and higher determination, but not significantly. We need to take into account other features!

> You can see that the minimal pumpkin prices are observed somewhere around Halloween. How can you explain this? 

ЁЯОГ Congratulations, you just created a model that can help predict the price of pie pumpkins. You can probably repeat the same procedure for all pumpkin types, but that would be tedious. Let's learn now how to take pumpkin variety into account in our model!

## Categorical Features

In the ideal world, we want to be able to predict prices for different pumpkin varieties using the same model. However, the `Variety` column is somewhat different from columns like `Month`, because it contains non-numeric values. Such columns are called **categorical**.

[![ML for beginners - Categorical Feature Predictions with Linear Regression](https://img.youtube.com/vi/DYGliioIAE0/0.jpg)](https://youtu.be/DYGliioIAE0 "ML for beginners - Categorical Feature Predictions with Linear Regression")

> ЁЯОе Click the image above for a short video overview of using categorical features.

Here you can see how average price depends on variety:

<img alt="Average price by variety" src="images/price-by-variety.png" width="50%" />

To take variety into account, we first need to convert it to numeric form, or **encode** it. There are several way we can do it:

* Simple **numeric encoding** will build a table of different varieties, and then replace the variety name by an index in that table. This is not the best idea for linear regression, because linear regression takes the actual numeric value of the index, and adds it to the result, multiplying by some coefficient. In our case, the relationship between the index number and the price is clearly non-linear, even if we make sure that indices are ordered in some specific way.
* **One-hot encoding** will replace the `Variety` column by 4 different columns, one for each variety. Each column will contain `1` if the corresponding row is of a given variety, and `0` рдЕрдиреНрдпрдерд╛ред рдЗрд╕рдХрд╛ рдорддрд▓рдм рд╣реИ рдХрд┐ рд▓реАрдирд┐рдпрд░ рд░рд┐рдЧреНрд░реЗрд╢рди рдореЗрдВ рдЪрд╛рд░ рдЧреБрдгрд╛рдВрдХ рд╣реЛрдВрдЧреЗ, рдкреНрд░рддреНрдпреЗрдХ рдХрджреНрджреВ рдХреА рдХрд┐рд╕реНрдо рдХреЗ рд▓рд┐рдП рдПрдХ, рдЬреЛ рдЙрд╕ рд╡рд┐рд╢реЗрд╖ рдХрд┐рд╕реНрдо рдХреЗ рд▓рд┐рдП "рд╢реБрд░реБрдЖрддреА рдХреАрдордд" (рдпрд╛ рдмрд▓реНрдХрд┐ "рдЕрддрд┐рд░рд┐рдХреНрдд рдХреАрдордд") рдХреЗ рд▓рд┐рдП рдЬрд┐рдореНрдореЗрджрд╛рд░ рд╣реИред

рдиреАрдЪреЗ рджрд┐рдпрд╛ рдЧрдпрд╛ рдХреЛрдб рджрд┐рдЦрд╛рддрд╛ рд╣реИ рдХрд┐ рд╣рдо рдПрдХ рд╡реЗрд░рд╛рдЗрдЯреА рдХреЛ рдХреИрд╕реЗ рд╡рди-рд╣реЙрдЯ рдПрдиреНрдХреЛрдб рдХрд░ рд╕рдХрддреЗ рд╣реИрдВ:

```python
pd.get_dummies(new_pumpkins['Variety'])
```

 ID | FAIRYTALE | MINIATURE | MIXED HEIRLOOM VARIETIES | PIE TYPE
----|-----------|-----------|--------------------------|----------
70 | 0 | 0 | 0 | 1
71 | 0 | 0 | 0 | 1
... | ... | ... | ... | ...
1738 | 0 | 1 | 0 | 0
1739 | 0 | 1 | 0 | 0
1740 | 0 | 1 | 0 | 0
1741 | 0 | 1 | 0 | 0
1742 | 0 | 1 | 0 | 0

рд╡рди-рд╣реЙрдЯ рдПрдиреНрдХреЛрдб рд╡реЗрд░рд╛рдЗрдЯреА рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рд▓реАрдирд┐рдпрд░ рд░рд┐рдЧреНрд░реЗрд╢рди рдХреЛ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП, рд╣рдореЗрдВ рдмрд╕ `X` and `y` рдбреЗрдЯрд╛ рдХреЛ рд╕рд╣реА рдврдВрдЧ рд╕реЗ рдкреНрд░рд╛рд░рдВрдн рдХрд░рдиреЗ рдХреА рдЖрд╡рд╢реНрдпрдХрддрд╛ рд╣реИ:

```python
X = pd.get_dummies(new_pumpkins['Variety'])
y = new_pumpkins['Price']
```

рдмрд╛рдХреА рдХреЛрдб рд╡рд╣реА рд╣реИ рдЬреЛ рд╣рдордиреЗ рд▓реАрдирд┐рдпрд░ рд░рд┐рдЧреНрд░реЗрд╢рди рдХреЛ рдкреНрд░рд╢рд┐рдХреНрд╖рд┐рдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП рдКрдкрд░ рдЙрдкрдпреЛрдЧ рдХрд┐рдпрд╛ рдерд╛ред рдпрджрд┐ рдЖрдк рдЗрд╕реЗ рдЖрдЬрдорд╛рддреЗ рд╣реИрдВ, рддреЛ рдЖрдк рджреЗрдЦреЗрдВрдЧреЗ рдХрд┐ рдореАрди рд╕реНрдХреНрд╡рд╛рдпрд░ рдПрд░рд░ рд▓рдЧрднрдЧ рд╕рдорд╛рди рд╣реИ, рд▓реЗрдХрд┐рди рд╣рдореЗрдВ рдмрд╣реБрдд рдЕрдзрд┐рдХ рдирд┐рд░реНрдзрд╛рд░рдг рдЧреБрдгрд╛рдВрдХ (~77%) рдорд┐рд▓рддрд╛ рд╣реИред рдФрд░ рдЕрдзрд┐рдХ рд╕рдЯреАрдХ рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгрд┐рдпрд╛рдБ рдкреНрд░рд╛рдкреНрдд рдХрд░рдиреЗ рдХреЗ рд▓рд┐рдП, рд╣рдо рдЕрдзрд┐рдХ рд╢реНрд░реЗрдгреАрдмрджреНрдз рдлреАрдЪрд░реНрд╕ рдХреЛ рдзреНрдпрд╛рди рдореЗрдВ рд░рдЦ рд╕рдХрддреЗ рд╣реИрдВ, рд╕рд╛рде рд╣реА рд╕рдВрдЦреНрдпрд╛рддреНрдордХ рдлреАрдЪрд░реНрд╕, рдЬреИрд╕реЗ `Month` or `DayOfYear`. To get one large array of features, we can use `join`:

```python
X = pd.get_dummies(new_pumpkins['Variety']) \
        .join(new_pumpkins['Month']) \
        .join(pd.get_dummies(new_pumpkins['City'])) \
        .join(pd.get_dummies(new_pumpkins['Package']))
y = new_pumpkins['Price']
```

рдпрд╣рд╛рдВ рд╣рдо `City` and `Package` рдкреНрд░рдХрд╛рд░ рдХреЛ рднреА рдзреНрдпрд╛рди рдореЗрдВ рд░рдЦрддреЗ рд╣реИрдВ, рдЬреЛ рд╣рдореЗрдВ MSE 2.84 (10%) рдФрд░ рдирд┐рд░реНрдзрд╛рд░рдг 0.94 рджреЗрддрд╛ рд╣реИ!

## рд╕рдм рдХреБрдЫ рдПрдХ рд╕рд╛рде рд░рдЦрдирд╛

рд╕рд░реНрд╡рд╢реНрд░реЗрд╖реНрда рдореЙрдбрд▓ рдмрдирд╛рдиреЗ рдХреЗ рд▓рд┐рдП, рд╣рдо рдКрдкрд░ рджрд┐рдП рдЧрдП рдЙрджрд╛рд╣рд░рдг рд╕реЗ рд╕рдВрдпреБрдХреНрдд (рд╡рди-рд╣реЙрдЯ рдПрдиреНрдХреЛрдб рд╢реНрд░реЗрдгреАрдмрджреНрдз + рд╕рдВрдЦреНрдпрд╛рддреНрдордХ) рдбреЗрдЯрд╛ рдХрд╛ рдЙрдкрдпреЛрдЧ рдкреЛрд▓рд┐рдиреЛрдорд┐рдпрд▓ рд░рд┐рдЧреНрд░реЗрд╢рди рдХреЗ рд╕рд╛рде рдХрд░ рд╕рдХрддреЗ рд╣реИрдВред рдЖрдкрдХреА рд╕реБрд╡рд┐рдзрд╛ рдХреЗ рд▓рд┐рдП рдпрд╣рд╛рдВ рдкреВрд░рд╛ рдХреЛрдб рджрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИ:

```python
# set up training data
X = pd.get_dummies(new_pumpkins['Variety']) \
        .join(new_pumpkins['Month']) \
        .join(pd.get_dummies(new_pumpkins['City'])) \
        .join(pd.get_dummies(new_pumpkins['Package']))
y = new_pumpkins['Price']

# make train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# setup and train the pipeline
pipeline = make_pipeline(PolynomialFeatures(2), LinearRegression())
pipeline.fit(X_train,y_train)

# predict results for test data
pred = pipeline.predict(X_test)

# calculate MSE and determination
mse = np.sqrt(mean_squared_error(y_test,pred))
print(f'Mean error: {mse:3.3} ({mse/np.mean(pred)*100:3.3}%)')

score = pipeline.score(X_train,y_train)
print('Model determination: ', score)
```

рдпрд╣ рд╣рдореЗрдВ рд▓рдЧрднрдЧ 97% рдХрд╛ рд╕рд░реНрд╡реЛрддреНрддрдо рдирд┐рд░реНрдзрд╛рд░рдг рдЧреБрдгрд╛рдВрдХ рдФрд░ MSE=2.23 (~8% рднрд╡рд┐рд╖реНрдпрд╡рд╛рдгреА рддреНрд░реБрдЯрд┐) рджреЗрдирд╛ рдЪрд╛рд╣рд┐рдПред

| рдореЙрдбрд▓ | MSE | рдирд┐рд░реНрдзрд╛рд░рдг |
|-------|-----|---------------|
| `DayOfYear@@INLINE_CODE

**рдЕрд╕реНрд╡реАрдХрд░рдг**:
рдпрд╣ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рдорд╢реАрди-рдЖрдзрд╛рд░рд┐рдд рдПрдЖрдИ рдЕрдиреБрд╡рд╛рдж рд╕реЗрд╡рд╛рдУрдВ рдХрд╛ рдЙрдкрдпреЛрдЧ рдХрд░рдХреЗ рдЕрдиреБрд╡рд╛рджрд┐рдд рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реИред рдЬрдмрдХрд┐ рд╣рдо рд╕рдЯреАрдХрддрд╛ рдХреЗ рд▓рд┐рдП рдкреНрд░рдпрд╛рд╕рд░рдд рд╣реИрдВ, рдХреГрдкрдпрд╛ рдзреНрдпрд╛рди рджреЗрдВ рдХрд┐ рд╕реНрд╡рдЪрд╛рд▓рд┐рдд рдЕрдиреБрд╡рд╛рджреЛрдВ рдореЗрдВ рддреНрд░реБрдЯрд┐рдпрд╛рдБ рдпрд╛ рдЕрд╢реБрджреНрдзрд┐рдпрд╛рдБ рд╣реЛ рд╕рдХрддреА рд╣реИрдВред рдЗрд╕рдХреА рдореВрд▓ рднрд╛рд╖рд╛ рдореЗрдВ рдореВрд▓ рджрд╕реНрддрд╛рд╡реЗрдЬрд╝ рдХреЛ рдкреНрд░рд╛рдзрд┐рдХреГрдд рд╕реНрд░реЛрдд рдорд╛рдирд╛ рдЬрд╛рдирд╛ рдЪрд╛рд╣рд┐рдПред рдорд╣рддреНрд╡рдкреВрд░реНрдг рдЬрд╛рдирдХрд╛рд░реА рдХреЗ рд▓рд┐рдП, рдкреЗрд╢реЗрд╡рд░ рдорд╛рдирд╡ рдЕрдиреБрд╡рд╛рдж рдХреА рд╕рд┐рдлрд╛рд░рд┐рд╢ рдХреА рдЬрд╛рддреА рд╣реИред рдЗрд╕ рдЕрдиреБрд╡рд╛рдж рдХреЗ рдЙрдкрдпреЛрдЧ рд╕реЗ рдЙрддреНрдкрдиреНрди рдХрд┐рд╕реА рднреА рдЧрд▓рддрдлрд╣рдореА рдпрд╛ рдЧрд▓рдд рд╡реНрдпрд╛рдЦреНрдпрд╛ рдХреЗ рд▓рд┐рдП рд╣рдо рдЙрддреНрддрд░рджрд╛рдпреА рдирд╣реАрдВ рд╣реИрдВред