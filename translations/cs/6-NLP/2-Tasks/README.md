<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "5f3cb462e3122e1afe7ab0050ccf2bd3",
  "translation_date": "2025-09-05T01:21:18+00:00",
  "source_file": "6-NLP/2-Tasks/README.md",
  "language_code": "cs"
}
-->
# BÄ›Å¾nÃ© Ãºlohy a techniky zpracovÃ¡nÃ­ pÅ™irozenÃ©ho jazyka

Pro vÄ›tÅ¡inu Ãºloh *zpracovÃ¡nÃ­ pÅ™irozenÃ©ho jazyka* je nutnÃ© text rozdÄ›lit, analyzovat a vÃ½sledky uloÅ¾it nebo porovnat s pravidly a datovÃ½mi sadami. Tyto Ãºlohy umoÅ¾ÅˆujÃ­ programÃ¡torovi odvodit _vÃ½znam_, _zÃ¡mÄ›r_ nebo pouze _Äetnost_ termÃ­nÅ¯ a slov v textu.

## [KvÃ­z pÅ™ed pÅ™ednÃ¡Å¡kou](https://ff-quizzes.netlify.app/en/ml/)

PojÄme objevit bÄ›Å¾nÃ© techniky pouÅ¾Ã­vanÃ© pÅ™i zpracovÃ¡nÃ­ textu. V kombinaci se strojovÃ½m uÄenÃ­m vÃ¡m tyto techniky pomohou efektivnÄ› analyzovat velkÃ© mnoÅ¾stvÃ­ textu. NeÅ¾ vÅ¡ak tyto Ãºlohy aplikujete na ML, je dÅ¯leÅ¾itÃ© pochopit problÃ©my, se kterÃ½mi se odbornÃ­k na NLP setkÃ¡vÃ¡.

## BÄ›Å¾nÃ© Ãºlohy v NLP

Existuje nÄ›kolik zpÅ¯sobÅ¯, jak analyzovat text, na kterÃ©m pracujete. ExistujÃ­ Ãºlohy, kterÃ© mÅ¯Å¾ete provÃ¡dÄ›t, a dÃ­ky nim zÃ­skÃ¡te porozumÄ›nÃ­ textu a mÅ¯Å¾ete vyvodit zÃ¡vÄ›ry. Tyto Ãºlohy obvykle provÃ¡dÃ­te v urÄitÃ©m poÅ™adÃ­.

### Tokenizace

PravdÄ›podobnÄ› prvnÃ­ vÄ›c, kterou vÄ›tÅ¡ina algoritmÅ¯ NLP musÃ­ udÄ›lat, je rozdÄ›lit text na tokeny, tedy slova. I kdyÅ¾ to znÃ­ jednoduÅ¡e, zohlednÄ›nÃ­ interpunkce a rÅ¯znÃ½ch jazykovÃ½ch oddÄ›lovaÄÅ¯ slov a vÄ›t mÅ¯Å¾e bÃ½t sloÅ¾itÃ©. MoÅ¾nÃ¡ budete muset pouÅ¾Ã­t rÅ¯znÃ© metody k urÄenÃ­ hranic.

![tokenizace](../../../../6-NLP/2-Tasks/images/tokenization.png)
> Tokenizace vÄ›ty z **PÃ½chy a pÅ™edsudku**. Infografika od [Jen Looper](https://twitter.com/jenlooper)

### Vektorizace (Embeddings)

[Word embeddings](https://wikipedia.org/wiki/Word_embedding) jsou zpÅ¯sob, jak pÅ™evÃ©st textovÃ¡ data na ÄÃ­selnou podobu. Vektorizace se provÃ¡dÃ­ tak, aby slova s podobnÃ½m vÃ½znamem nebo slova pouÅ¾Ã­vanÃ¡ spoleÄnÄ› byla seskupena.

![word embeddings](../../../../6-NLP/2-Tasks/images/embedding.png)
> "MÃ¡m nejvyÅ¡Å¡Ã­ respekt k vaÅ¡im nervÅ¯m, jsou to moji staÅ™Ã­ pÅ™Ã¡telÃ©." - Vektorizace vÄ›ty z **PÃ½chy a pÅ™edsudku**. Infografika od [Jen Looper](https://twitter.com/jenlooper)

âœ… VyzkouÅ¡ejte [tento zajÃ­mavÃ½ nÃ¡stroj](https://projector.tensorflow.org/) pro experimentovÃ¡nÃ­ s vektorizacÃ­ slov. KliknutÃ­m na jedno slovo zobrazÃ­te shluky podobnÃ½ch slov: 'toy' se shlukuje s 'disney', 'lego', 'playstation' a 'console'.

### SyntaktickÃ¡ analÃ½za a oznaÄovÃ¡nÃ­ ÄÃ¡stÃ­ Å™eÄi

KaÅ¾dÃ© slovo, kterÃ© bylo tokenizovÃ¡no, mÅ¯Å¾e bÃ½t oznaÄeno jako ÄÃ¡st Å™eÄi - podstatnÃ© jmÃ©no, sloveso nebo pÅ™Ã­davnÃ© jmÃ©no. VÄ›ta `rychlÃ¡ ÄervenÃ¡ liÅ¡ka pÅ™eskoÄila lÃ­nÃ©ho hnÄ›dÃ©ho psa` mÅ¯Å¾e bÃ½t oznaÄena jako liÅ¡ka = podstatnÃ© jmÃ©no, pÅ™eskoÄila = sloveso.

![syntaktickÃ¡ analÃ½za](../../../../6-NLP/2-Tasks/images/parse.png)

> SyntaktickÃ¡ analÃ½za vÄ›ty z **PÃ½chy a pÅ™edsudku**. Infografika od [Jen Looper](https://twitter.com/jenlooper)

SyntaktickÃ¡ analÃ½za znamenÃ¡ rozpoznÃ¡nÃ­, kterÃ¡ slova jsou ve vÄ›tÄ› vzÃ¡jemnÄ› propojena - napÅ™Ã­klad `rychlÃ¡ ÄervenÃ¡ liÅ¡ka pÅ™eskoÄila` je sekvence pÅ™Ã­davnÃ© jmÃ©no-podstatnÃ© jmÃ©no-sloveso, kterÃ¡ je oddÄ›lenÃ¡ od sekvence `lÃ­nÃ½ hnÄ›dÃ½ pes`.

### ÄŒetnost slov a frÃ¡zÃ­

UÅ¾iteÄnÃ½m postupem pÅ™i analÃ½ze velkÃ©ho mnoÅ¾stvÃ­ textu je vytvoÅ™enÃ­ slovnÃ­ku kaÅ¾dÃ©ho slova nebo frÃ¡ze, kterÃ¡ nÃ¡s zajÃ­mÃ¡, a jak Äasto se v textu objevuje. FrÃ¡ze `rychlÃ¡ ÄervenÃ¡ liÅ¡ka pÅ™eskoÄila lÃ­nÃ©ho hnÄ›dÃ©ho psa` mÃ¡ Äetnost slova "the" 2.

PodÃ­vejme se na pÅ™Ã­klad textu, kde poÄÃ­tÃ¡me Äetnost slov. BÃ¡seÅˆ The Winners od Rudyarda Kiplinga obsahuje nÃ¡sledujÃ­cÃ­ verÅ¡:

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

ProtoÅ¾e Äetnost frÃ¡zÃ­ mÅ¯Å¾e bÃ½t citlivÃ¡ na velikost pÃ­smen nebo naopak, frÃ¡ze `a friend` mÃ¡ Äetnost 2, `the` mÃ¡ Äetnost 6 a `travels` mÃ¡ Äetnost 2.

### N-gramy

Text mÅ¯Å¾e bÃ½t rozdÄ›len na sekvence slov urÄitÃ© dÃ©lky, jedno slovo (unigram), dvÄ› slova (bigramy), tÅ™i slova (trigramy) nebo libovolnÃ½ poÄet slov (n-gramy).

NapÅ™Ã­klad `rychlÃ¡ ÄervenÃ¡ liÅ¡ka pÅ™eskoÄila lÃ­nÃ©ho hnÄ›dÃ©ho psa` s n-gram skÃ³re 2 vytvoÅ™Ã­ nÃ¡sledujÃ­cÃ­ n-gramy:

1. rychlÃ¡ ÄervenÃ¡  
2. ÄervenÃ¡ liÅ¡ka  
3. liÅ¡ka pÅ™eskoÄila  
4. pÅ™eskoÄila lÃ­nÃ©ho  
5. lÃ­nÃ©ho hnÄ›dÃ©ho  
6. hnÄ›dÃ©ho psa  

MÅ¯Å¾e bÃ½t snazÅ¡Ã­ si to pÅ™edstavit jako posuvnÃ© okno nad vÄ›tou. Zde je to pro n-gramy o 3 slovech, n-gram je tuÄnÄ› v kaÅ¾dÃ© vÄ›tÄ›:

1.   <u>**rychlÃ¡ ÄervenÃ¡ liÅ¡ka**</u> pÅ™eskoÄila lÃ­nÃ©ho hnÄ›dÃ©ho psa  
2.   rychlÃ¡ **<u>ÄervenÃ¡ liÅ¡ka pÅ™eskoÄila</u>** lÃ­nÃ©ho hnÄ›dÃ©ho psa  
3.   rychlÃ¡ ÄervenÃ¡ **<u>liÅ¡ka pÅ™eskoÄila lÃ­nÃ©ho</u>** hnÄ›dÃ©ho psa  
4.   rychlÃ¡ ÄervenÃ¡ liÅ¡ka **<u>pÅ™eskoÄila lÃ­nÃ©ho hnÄ›dÃ©ho</u>** psa  
5.   rychlÃ¡ ÄervenÃ¡ liÅ¡ka pÅ™eskoÄila **<u>lÃ­nÃ©ho hnÄ›dÃ©ho psa</u>**  

![posuvnÃ© okno n-gramÅ¯](../../../../6-NLP/2-Tasks/images/n-grams.gif)

> N-gram hodnota 3: Infografika od [Jen Looper](https://twitter.com/jenlooper)

### Extrakce podstatnÃ½ch jmennÃ½ch frÃ¡zÃ­

VÄ›tÅ¡ina vÄ›t obsahuje podstatnÃ© jmÃ©no, kterÃ© je pÅ™edmÄ›tem nebo objektem vÄ›ty. V angliÄtinÄ› je Äasto identifikovatelnÃ© dÃ­ky pÅ™edchÃ¡zejÃ­cÃ­mu 'a', 'an' nebo 'the'. Identifikace pÅ™edmÄ›tu nebo objektu vÄ›ty pomocÃ­ 'extrakce podstatnÃ© jmennÃ© frÃ¡ze' je bÄ›Å¾nou Ãºlohou v NLP pÅ™i pokusu o pochopenÃ­ vÃ½znamu vÄ›ty.

âœ… Ve vÄ›tÄ› "Nemohu si vzpomenout na hodinu, mÃ­sto, pohled nebo slova, kterÃ¡ poloÅ¾ila zÃ¡klad. Je to pÅ™Ã­liÅ¡ dÃ¡vno. Byl jsem uprostÅ™ed, neÅ¾ jsem si uvÄ›domil, Å¾e jsem zaÄal." dokÃ¡Å¾ete identifikovat podstatnÃ© jmennÃ© frÃ¡ze?

Ve vÄ›tÄ› `rychlÃ¡ ÄervenÃ¡ liÅ¡ka pÅ™eskoÄila lÃ­nÃ©ho hnÄ›dÃ©ho psa` jsou 2 podstatnÃ© jmennÃ© frÃ¡ze: **rychlÃ¡ ÄervenÃ¡ liÅ¡ka** a **lÃ­nÃ½ hnÄ›dÃ½ pes**.

### AnalÃ½za sentimentu

VÄ›ta nebo text mÅ¯Å¾e bÃ½t analyzovÃ¡n z hlediska sentimentu, tedy jak *pozitivnÃ­* nebo *negativnÃ­* je. Sentiment se mÄ›Å™Ã­ pomocÃ­ *polarizace* a *objektivity/subjektivity*. Polarizace se mÄ›Å™Ã­ od -1.0 do 1.0 (negativnÃ­ aÅ¾ pozitivnÃ­) a 0.0 do 1.0 (nejvÃ­ce objektivnÃ­ aÅ¾ nejvÃ­ce subjektivnÃ­).

âœ… PozdÄ›ji se nauÄÃ­te, Å¾e existujÃ­ rÅ¯znÃ© zpÅ¯soby, jak urÄit sentiment pomocÃ­ strojovÃ©ho uÄenÃ­, ale jednÃ­m ze zpÅ¯sobÅ¯ je mÃ­t seznam slov a frÃ¡zÃ­, kterÃ© jsou lidskÃ½m expertem kategorizovÃ¡ny jako pozitivnÃ­ nebo negativnÃ­, a aplikovat tento model na text k vÃ½poÄtu skÃ³re polarizace. VidÃ­te, jak by to mohlo fungovat v nÄ›kterÃ½ch situacÃ­ch a mÃ©nÄ› dobÅ™e v jinÃ½ch?

### Inflekce

Inflekce umoÅ¾Åˆuje vzÃ­t slovo a zÃ­skat jeho jednotnÃ© nebo mnoÅ¾nÃ© ÄÃ­slo.

### Lemmatizace

*Lemma* je koÅ™enovÃ© nebo zÃ¡kladnÃ­ slovo pro sadu slov, napÅ™Ã­klad *letÄ›l*, *letÃ­*, *lÃ©tÃ¡nÃ­* majÃ­ lemma slovesa *letÄ›t*.

ExistujÃ­ takÃ© uÅ¾iteÄnÃ© databÃ¡ze dostupnÃ© pro vÃ½zkumnÃ­ka NLP, zejmÃ©na:

### WordNet

[WordNet](https://wordnet.princeton.edu/) je databÃ¡ze slov, synonym, antonym a mnoha dalÅ¡Ã­ch detailÅ¯ pro kaÅ¾dÃ© slovo v mnoha rÅ¯znÃ½ch jazycÃ­ch. Je neuvÄ›Å™itelnÄ› uÅ¾iteÄnÃ¡ pÅ™i pokusu o vytvÃ¡Å™enÃ­ pÅ™ekladÅ¯, kontrolu pravopisu nebo jazykovÃ½ch nÃ¡strojÅ¯ jakÃ©hokoli typu.

## Knihovny NLP

NaÅ¡tÄ›stÃ­ nemusÃ­te vÅ¡echny tyto techniky vytvÃ¡Å™et sami, protoÅ¾e existujÃ­ vynikajÃ­cÃ­ knihovny v Pythonu, kterÃ© je zpÅ™Ã­stupÅˆujÃ­ vÃ½vojÃ¡Å™Å¯m, kteÅ™Ã­ nejsou specializovanÃ­ na zpracovÃ¡nÃ­ pÅ™irozenÃ©ho jazyka nebo strojovÃ© uÄenÃ­. V dalÅ¡Ã­ch lekcÃ­ch najdete vÃ­ce pÅ™Ã­kladÅ¯, ale zde se nauÄÃ­te nÄ›kolik uÅ¾iteÄnÃ½ch pÅ™Ã­kladÅ¯, kterÃ© vÃ¡m pomohou s dalÅ¡Ã­m Ãºkolem.

### CviÄenÃ­ - pouÅ¾itÃ­ knihovny `TextBlob`

PouÅ¾ijme knihovnu TextBlob, protoÅ¾e obsahuje uÅ¾iteÄnÃ¡ API pro Å™eÅ¡enÃ­ tÄ›chto typÅ¯ Ãºloh. TextBlob "stojÃ­ na obrovskÃ½ch ramenou [NLTK](https://nltk.org) a [pattern](https://github.com/clips/pattern) a dobÅ™e spolupracuje s obÄ›ma." MÃ¡ znaÄnÃ© mnoÅ¾stvÃ­ ML zabudovanÃ© ve svÃ©m API.

> PoznÃ¡mka: DoporuÄuje se [rychlÃ½ prÅ¯vodce](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart) pro TextBlob, kterÃ½ je urÄen pro zkuÅ¡enÃ© vÃ½vojÃ¡Å™e v Pythonu.

PÅ™i pokusu o identifikaci *podstatnÃ½ch jmennÃ½ch frÃ¡zÃ­* nabÃ­zÃ­ TextBlob nÄ›kolik moÅ¾nostÃ­ extraktorÅ¯ pro nalezenÃ­ podstatnÃ½ch jmennÃ½ch frÃ¡zÃ­.

1. PodÃ­vejte se na `ConllExtractor`.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > Co se zde dÄ›je? [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) je "extraktor podstatnÃ½ch jmennÃ½ch frÃ¡zÃ­, kterÃ½ pouÅ¾Ã­vÃ¡ chunk parsing trÃ©novanÃ½ na korpusu ConLL-2000." ConLL-2000 odkazuje na konferenci o zpracovÃ¡nÃ­ pÅ™irozenÃ©ho jazyka z roku 2000. KaÅ¾dÃ½ rok konference poÅ™Ã¡dala workshop na Å™eÅ¡enÃ­ obtÃ­Å¾nÃ©ho problÃ©mu NLP, a v roce 2000 to bylo chunkovÃ¡nÃ­ podstatnÃ½ch jmennÃ½ch frÃ¡zÃ­. Model byl trÃ©novÃ¡n na Wall Street Journal, s "sekcemi 15-18 jako trÃ©novacÃ­ data (211727 tokenÅ¯) a sekcÃ­ 20 jako testovacÃ­ data (47377 tokenÅ¯)". Postupy pouÅ¾itÃ© mÅ¯Å¾ete najÃ­t [zde](https://www.clips.uantwerpen.be/conll2000/chunking/) a [vÃ½sledky](https://ifarm.nl/erikt/research/np-chunking.html).

### VÃ½zva - zlepÅ¡enÃ­ vaÅ¡eho bota pomocÃ­ NLP

V pÅ™edchozÃ­ lekci jste vytvoÅ™ili velmi jednoduchÃ©ho Q&A bota. NynÃ­ udÄ›lÃ¡te Marvina trochu empatiÄtÄ›jÅ¡Ã­ho tÃ­m, Å¾e analyzujete vÃ¡Å¡ vstup na sentiment a vytisknete odpovÄ›Ä odpovÃ­dajÃ­cÃ­ sentimentu. Budete takÃ© muset identifikovat `noun_phrase` a zeptat se na ni.

VaÅ¡e kroky pÅ™i vytvÃ¡Å™enÃ­ lepÅ¡Ã­ho konverzaÄnÃ­ho bota:

1. VytisknÄ›te instrukce, jak komunikovat s botem
2. SpusÅ¥te smyÄku 
   1. PÅ™ijmÄ›te uÅ¾ivatelskÃ½ vstup
   2. Pokud uÅ¾ivatel poÅ¾Ã¡dal o ukonÄenÃ­, ukonÄete
   3. Zpracujte uÅ¾ivatelskÃ½ vstup a urÄete odpovÃ­dajÃ­cÃ­ odpovÄ›Ä na sentiment
   4. Pokud je v sentimentu detekovÃ¡na podstatnÃ¡ jmennÃ¡ frÃ¡ze, vytvoÅ™te jejÃ­ mnoÅ¾nÃ© ÄÃ­slo a poÅ¾Ã¡dejte o dalÅ¡Ã­ vstup na toto tÃ©ma
   5. VytisknÄ›te odpovÄ›Ä
3. VraÅ¥te se zpÄ›t ke kroku 2

Zde je ukÃ¡zka kÃ³du pro urÄenÃ­ sentimentu pomocÃ­ TextBlob. VÅ¡imnÄ›te si, Å¾e existujÃ­ pouze ÄtyÅ™i *stupnÄ›* odpovÄ›di na sentiment (mÅ¯Å¾ete jich mÃ­t vÃ­ce, pokud chcete):

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

Zde je ukÃ¡zkovÃ½ vÃ½stup, kterÃ½ vÃ¡s mÅ¯Å¾e vÃ©st (uÅ¾ivatelskÃ½ vstup je na Å™Ã¡dcÃ­ch zaÄÃ­najÃ­cÃ­ch >):

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

Jedno moÅ¾nÃ© Å™eÅ¡enÃ­ Ãºkolu je [zde](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/2-Tasks/solution/bot.py)

âœ… Kontrola znalostÃ­

1. MyslÃ­te si, Å¾e empatickÃ© odpovÄ›di by mohly 'oklamat' nÄ›koho, aby si myslel, Å¾e bot skuteÄnÄ› rozumÃ­?  
2. DÄ›lÃ¡ identifikace podstatnÃ© jmennÃ© frÃ¡ze bota vÃ­ce 'uvÄ›Å™itelnÃ½m'?  
3. ProÄ by extrakce 'podstatnÃ© jmennÃ© frÃ¡ze' z vÄ›ty byla uÅ¾iteÄnÃ¡ vÄ›c?  

---

Implementujte bota z pÅ™edchozÃ­ kontroly znalostÃ­ a otestujte ho na pÅ™Ã­teli. DokÃ¡Å¾e je oklamat? DokÃ¡Å¾ete udÄ›lat svÃ©ho bota vÃ­ce 'uvÄ›Å™itelnÃ½m'?

## ğŸš€VÃ½zva

VezmÄ›te Ãºkol z pÅ™edchozÃ­ kontroly znalostÃ­ a zkuste ho implementovat. Otestujte bota na pÅ™Ã­teli. DokÃ¡Å¾e je oklamat? DokÃ¡Å¾ete udÄ›lat svÃ©ho bota vÃ­ce 'uvÄ›Å™itelnÃ½m'?

## [KvÃ­z po pÅ™ednÃ¡Å¡ce](https://ff-quizzes.netlify.app/en/ml/)

## PÅ™ehled & Samostudium

V nÃ¡sledujÃ­cÃ­ch lekcÃ­ch se dozvÃ­te vÃ­ce o analÃ½ze sentimentu. Prozkoumejte tuto zajÃ­mavou techniku v ÄlÃ¡ncÃ­ch, jako jsou tyto na [KDNuggets](https://www.kdnuggets.com/tag/nlp)

## Ãškol 

[Nechte bota odpovÃ­dat](assignment.md)

---

**ProhlÃ¡Å¡enÃ­**:  
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ sluÅ¾by pro automatickÃ½ pÅ™eklad [Co-op Translator](https://github.com/Azure/co-op-translator). AÄkoli se snaÅ¾Ã­me o pÅ™esnost, mÄ›jte prosÃ­m na pamÄ›ti, Å¾e automatickÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. PÅ¯vodnÃ­ dokument v jeho pÅ¯vodnÃ­m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za zÃ¡vaznÃ½ zdroj. Pro dÅ¯leÅ¾itÃ© informace doporuÄujeme profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. NeodpovÃ­dÃ¡me za Å¾Ã¡dnÃ¡ nedorozumÄ›nÃ­ nebo nesprÃ¡vnÃ© interpretace vyplÃ½vajÃ­cÃ­ z pouÅ¾itÃ­ tohoto pÅ™ekladu.