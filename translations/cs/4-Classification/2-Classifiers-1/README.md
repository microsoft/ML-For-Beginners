<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1a6e9e46b34a2e559fbbfc1f95397c7b",
  "translation_date": "2025-09-05T00:42:34+00:00",
  "source_file": "4-Classification/2-Classifiers-1/README.md",
  "language_code": "cs"
}
-->
# KlasifikÃ¡tory kuchynÃ­ 1

V tÃ©to lekci pouÅ¾ijete dataset, kterÃ½ jste si uloÅ¾ili z minulÃ© lekce, plnÃ½ vyvÃ¡Å¾enÃ½ch a ÄistÃ½ch dat o kuchynÃ­ch.

Tento dataset pouÅ¾ijete s rÅ¯znÃ½mi klasifikÃ¡tory k _predikci nÃ¡rodnÃ­ kuchynÄ› na zÃ¡kladÄ› skupiny ingrediencÃ­_. PÅ™itom se dozvÃ­te vÃ­ce o nÄ›kterÃ½ch zpÅ¯sobech, jak lze algoritmy vyuÅ¾Ã­t pro klasifikaÄnÃ­ Ãºlohy.

## [KvÃ­z pÅ™ed lekcÃ­](https://ff-quizzes.netlify.app/en/ml/)
# PÅ™Ã­prava

Za pÅ™edpokladu, Å¾e jste dokonÄili [Lekci 1](../1-Introduction/README.md), ujistÄ›te se, Å¾e soubor _cleaned_cuisines.csv_ existuje v koÅ™enovÃ© sloÅ¾ce `/data` pro tyto ÄtyÅ™i lekce.

## CviÄenÃ­ - predikce nÃ¡rodnÃ­ kuchynÄ›

1. Pracujte ve sloÅ¾ce _notebook.ipynb_ tÃ©to lekce, importujte tento soubor spolu s knihovnou Pandas:

    ```python
    import pandas as pd
    cuisines_df = pd.read_csv("../data/cleaned_cuisines.csv")
    cuisines_df.head()
    ```

    Data vypadajÃ­ takto:

|     | Unnamed: 0 | cuisine | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood | yam | yeast | yogurt | zucchini |
| --- | ---------- | ------- | ------ | -------- | ----- | ---------- | ----- | ------------ | ------- | -------- | --- | ------- | ----------- | ---------- | ----------------------- | ---- | ---- | --- | ----- | ------ | -------- |
| 0   | 0          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 1   | 1          | indian  | 1      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 2   | 2          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 3   | 3          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 4   | 4          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 1      | 0        |
  

1. NynÃ­ importujte nÄ›kolik dalÅ¡Ã­ch knihoven:

    ```python
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    from sklearn.svm import SVC
    import numpy as np
    ```

1. RozdÄ›lte souÅ™adnice X a y do dvou datovÃ½ch rÃ¡mcÅ¯ pro trÃ©novÃ¡nÃ­. `cuisine` mÅ¯Å¾e bÃ½t datovÃ½ rÃ¡mec s oznaÄenÃ­mi:

    ```python
    cuisines_label_df = cuisines_df['cuisine']
    cuisines_label_df.head()
    ```

    Bude vypadat takto:

    ```output
    0    indian
    1    indian
    2    indian
    3    indian
    4    indian
    Name: cuisine, dtype: object
    ```

1. OdstraÅˆte sloupec `Unnamed: 0` a sloupec `cuisine` pomocÃ­ `drop()`. Zbytek dat uloÅ¾te jako trÃ©novacÃ­ vlastnosti:

    ```python
    cuisines_feature_df = cuisines_df.drop(['Unnamed: 0', 'cuisine'], axis=1)
    cuisines_feature_df.head()
    ```

    VaÅ¡e vlastnosti vypadajÃ­ takto:

|      | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | artemisia | artichoke |  ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood |  yam | yeast | yogurt | zucchini |
| ---: | -----: | -------: | ----: | ---------: | ----: | -----------: | ------: | -------: | --------: | --------: | ---: | ------: | ----------: | ---------: | ----------------------: | ---: | ---: | ---: | ----: | -----: | -------: |
|    0 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    1 |      1 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    2 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    3 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    4 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      1 |        0 | 0 |

NynÃ­ jste pÅ™ipraveni trÃ©novat svÅ¯j model!

## VÃ½bÄ›r klasifikÃ¡toru

NynÃ­, kdyÅ¾ jsou vaÅ¡e data ÄistÃ¡ a pÅ™ipravenÃ¡ k trÃ©novÃ¡nÃ­, musÃ­te se rozhodnout, jakÃ½ algoritmus pouÅ¾Ã­t.

Scikit-learn zaÅ™azuje klasifikaci pod Supervised Learning, a v tÃ©to kategorii najdete mnoho zpÅ¯sobÅ¯ klasifikace. [Rozmanitost](https://scikit-learn.org/stable/supervised_learning.html) je na prvnÃ­ pohled docela ohromujÃ­cÃ­. NÃ¡sledujÃ­cÃ­ metody zahrnujÃ­ techniky klasifikace:

- LineÃ¡rnÃ­ modely
- Support Vector Machines
- Stochastic Gradient Descent
- NejbliÅ¾Å¡Ã­ sousedÃ©
- GaussovskÃ© procesy
- RozhodovacÃ­ stromy
- Ensemble metody (hlasovacÃ­ klasifikÃ¡tor)
- Multiclass a multioutput algoritmy (multiclass a multilabel klasifikace, multiclass-multioutput klasifikace)

> MÅ¯Å¾ete takÃ© pouÅ¾Ã­t [neuronovÃ© sÃ­tÄ› k klasifikaci dat](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#classification), ale to je mimo rozsah tÃ©to lekce.

### JakÃ½ klasifikÃ¡tor zvolit?

TakÅ¾e, jakÃ½ klasifikÃ¡tor byste mÄ›li zvolit? ÄŒasto je dobrÃ© vyzkouÅ¡et nÄ›kolik a hledat dobrÃ½ vÃ½sledek. Scikit-learn nabÃ­zÃ­ [srovnÃ¡nÃ­ vedle sebe](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) na vytvoÅ™enÃ©m datasetu, kde porovnÃ¡vÃ¡ KNeighbors, SVC dvÄ›ma zpÅ¯soby, GaussianProcessClassifier, DecisionTreeClassifier, RandomForestClassifier, MLPClassifier, AdaBoostClassifier, GaussianNB a QuadraticDiscriminationAnalysis, a vizualizuje vÃ½sledky:

![srovnÃ¡nÃ­ klasifikÃ¡torÅ¯](../../../../4-Classification/2-Classifiers-1/images/comparison.png)
> Grafy generovanÃ© na dokumentaci Scikit-learn

> AutoML tento problÃ©m elegantnÄ› Å™eÅ¡Ã­ tÃ­m, Å¾e provÃ¡dÃ­ tato srovnÃ¡nÃ­ v cloudu, coÅ¾ vÃ¡m umoÅ¾Åˆuje vybrat nejlepÅ¡Ã­ algoritmus pro vaÅ¡e data. VyzkouÅ¡ejte to [zde](https://docs.microsoft.com/learn/modules/automate-model-selection-with-azure-automl/?WT.mc_id=academic-77952-leestott)

### LepÅ¡Ã­ pÅ™Ã­stup

LepÅ¡Ã­ zpÅ¯sob neÅ¾ nÃ¡hodnÃ© hÃ¡dÃ¡nÃ­ je vÅ¡ak Å™Ã­dit se nÃ¡pady z tÃ©to stahovatelnÃ© [ML Cheat Sheet](https://docs.microsoft.com/azure/machine-learning/algorithm-cheat-sheet?WT.mc_id=academic-77952-leestott). Zde zjistÃ­me, Å¾e pro nÃ¡Å¡ problÃ©m s vÃ­ce tÅ™Ã­dami mÃ¡me nÄ›kolik moÅ¾nostÃ­:

![cheatsheet pro problÃ©my s vÃ­ce tÅ™Ã­dami](../../../../4-Classification/2-Classifiers-1/images/cheatsheet.png)
> ÄŒÃ¡st Microsoft Algorithm Cheat Sheet, popisujÃ­cÃ­ moÅ¾nosti klasifikace s vÃ­ce tÅ™Ã­dami

âœ… StÃ¡hnÄ›te si tento cheat sheet, vytisknÄ›te ho a povÄ›ste na zeÄ!

### Ãšvahy

PodÃ­vejme se, jestli dokÃ¡Å¾eme logicky projÃ­t rÅ¯znÃ© pÅ™Ã­stupy vzhledem k omezenÃ­m, kterÃ¡ mÃ¡me:

- **NeuronovÃ© sÃ­tÄ› jsou pÅ™Ã­liÅ¡ nÃ¡roÄnÃ©**. Vzhledem k naÅ¡emu ÄistÃ©mu, ale minimÃ¡lnÃ­mu datasetu a skuteÄnosti, Å¾e trÃ©novÃ¡nÃ­ provÃ¡dÃ­me lokÃ¡lnÄ› pomocÃ­ notebookÅ¯, jsou neuronovÃ© sÃ­tÄ› pro tuto Ãºlohu pÅ™Ã­liÅ¡ nÃ¡roÄnÃ©.
- **Å½Ã¡dnÃ½ klasifikÃ¡tor pro dvÄ› tÅ™Ã­dy**. NepouÅ¾Ã­vÃ¡me klasifikÃ¡tor pro dvÄ› tÅ™Ã­dy, takÅ¾e to vyluÄuje one-vs-all.
- **RozhodovacÃ­ strom nebo logistickÃ¡ regrese by mohly fungovat**. RozhodovacÃ­ strom by mohl fungovat, nebo logistickÃ¡ regrese pro data s vÃ­ce tÅ™Ã­dami.
- **Multiclass Boosted Decision Trees Å™eÅ¡Ã­ jinÃ½ problÃ©m**. Multiclass Boosted Decision Tree je nejvhodnÄ›jÅ¡Ã­ pro neparametrickÃ© Ãºlohy, napÅ™. Ãºlohy urÄenÃ© k vytvÃ¡Å™enÃ­ poÅ™adÃ­, takÅ¾e pro nÃ¡s nenÃ­ uÅ¾iteÄnÃ½.

### PouÅ¾itÃ­ Scikit-learn 

Budeme pouÅ¾Ã­vat Scikit-learn k analÃ½ze naÅ¡ich dat. Existuje vÅ¡ak mnoho zpÅ¯sobÅ¯, jak pouÅ¾Ã­t logistickou regresi v Scikit-learn. PodÃ­vejte se na [parametry k pÅ™edÃ¡nÃ­](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regressio#sklearn.linear_model.LogisticRegression).  

V podstatÄ› existujÃ­ dva dÅ¯leÅ¾itÃ© parametry - `multi_class` a `solver` - kterÃ© musÃ­me specifikovat, kdyÅ¾ poÅ¾Ã¡dÃ¡me Scikit-learn o provedenÃ­ logistickÃ© regrese. Hodnota `multi_class` aplikuje urÄitÃ© chovÃ¡nÃ­. Hodnota solveru urÄuje, jakÃ½ algoritmus pouÅ¾Ã­t. Ne vÅ¡echny solvery lze kombinovat se vÅ¡emi hodnotami `multi_class`.

Podle dokumentace v pÅ™Ã­padÄ› klasifikace s vÃ­ce tÅ™Ã­dami trÃ©novacÃ­ algoritmus:

- **PouÅ¾Ã­vÃ¡ schÃ©ma one-vs-rest (OvR)**, pokud je moÅ¾nost `multi_class` nastavena na `ovr`
- **PouÅ¾Ã­vÃ¡ ztrÃ¡tu kÅ™Ã­Å¾ovÃ© entropie**, pokud je moÅ¾nost `multi_class` nastavena na `multinomial`. (V souÄasnÃ© dobÄ› je moÅ¾nost `multinomial` podporovÃ¡na pouze solvery â€˜lbfgsâ€™, â€˜sagâ€™, â€˜sagaâ€™ a â€˜newton-cgâ€™.)

> ğŸ“ 'SchÃ©ma' zde mÅ¯Å¾e bÃ½t buÄ 'ovr' (one-vs-rest) nebo 'multinomial'. Vzhledem k tomu, Å¾e logistickÃ¡ regrese je skuteÄnÄ› navrÅ¾ena pro podporu binÃ¡rnÃ­ klasifikace, tato schÃ©mata jÃ­ umoÅ¾ÅˆujÃ­ lÃ©pe zvlÃ¡dat Ãºlohy klasifikace s vÃ­ce tÅ™Ã­dami. [zdroj](https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/)

> ğŸ“ 'Solver' je definovÃ¡n jako "algoritmus pouÅ¾itÃ½ v optimalizaÄnÃ­m problÃ©mu". [zdroj](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regressio#sklearn.linear_model.LogisticRegression).

Scikit-learn nabÃ­zÃ­ tuto tabulku, kterÃ¡ vysvÄ›tluje, jak solvery zvlÃ¡dajÃ­ rÅ¯znÃ© vÃ½zvy, kterÃ© pÅ™edstavujÃ­ rÅ¯znÃ© typy datovÃ½ch struktur:

![solvery](../../../../4-Classification/2-Classifiers-1/images/solvers.png)

## CviÄenÃ­ - rozdÄ›lenÃ­ dat

MÅ¯Å¾eme se zamÄ›Å™it na logistickou regresi pro nÃ¡Å¡ prvnÃ­ pokus o trÃ©novÃ¡nÃ­, protoÅ¾e jste se o nÃ­ nedÃ¡vno uÄili v pÅ™edchozÃ­ lekci.
RozdÄ›lte svÃ¡ data na trÃ©novacÃ­ a testovacÃ­ skupiny pomocÃ­ `train_test_split()`:

```python
X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)
```

## CviÄenÃ­ - aplikace logistickÃ© regrese

Vzhledem k tomu, Å¾e pouÅ¾Ã­vÃ¡te pÅ™Ã­pad s vÃ­ce tÅ™Ã­dami, musÃ­te si vybrat, jakÃ© _schÃ©ma_ pouÅ¾Ã­t a jakÃ½ _solver_ nastavit. PouÅ¾ijte LogisticRegression s nastavenÃ­m multi_class na `ovr` a solverem na **liblinear** pro trÃ©novÃ¡nÃ­.

1. VytvoÅ™te logistickou regresi s multi_class nastavenÃ½m na `ovr` a solverem nastavenÃ½m na `liblinear`:

    ```python
    lr = LogisticRegression(multi_class='ovr',solver='liblinear')
    model = lr.fit(X_train, np.ravel(y_train))
    
    accuracy = model.score(X_test, y_test)
    print ("Accuracy is {}".format(accuracy))
    ```

    âœ… VyzkouÅ¡ejte jinÃ½ solver, napÅ™Ã­klad `lbfgs`, kterÃ½ je Äasto nastaven jako vÃ½chozÃ­
> PoznÃ¡mka: PouÅ¾ijte funkci Pandas [`ravel`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.ravel.html) k vyrovnÃ¡nÃ­ vaÅ¡ich dat, kdyÅ¾ je to potÅ™eba.
PÅ™esnost je dobrÃ¡ na vÃ­ce neÅ¾ **80 %**!

1. MÅ¯Å¾ete vidÄ›t tento model v akci testovÃ¡nÃ­m jednoho Å™Ã¡dku dat (#50):

    ```python
    print(f'ingredients: {X_test.iloc[50][X_test.iloc[50]!=0].keys()}')
    print(f'cuisine: {y_test.iloc[50]}')
    ```

    VÃ½sledek je vytiÅ¡tÄ›n:

   ```output
   ingredients: Index(['cilantro', 'onion', 'pea', 'potato', 'tomato', 'vegetable_oil'], dtype='object')
   cuisine: indian
   ```

   âœ… VyzkouÅ¡ejte jinÃ½ ÄÃ­slo Å™Ã¡dku a zkontrolujte vÃ½sledky.

1. Pokud se ponoÅ™Ã­te hloubÄ›ji, mÅ¯Å¾ete ovÄ›Å™it pÅ™esnost tÃ©to predikce:

    ```python
    test= X_test.iloc[50].values.reshape(-1, 1).T
    proba = model.predict_proba(test)
    classes = model.classes_
    resultdf = pd.DataFrame(data=proba, columns=classes)
    
    topPrediction = resultdf.T.sort_values(by=[0], ascending = [False])
    topPrediction.head()
    ```

    VÃ½sledek je vytiÅ¡tÄ›n - indickÃ¡ kuchynÄ› je nejlepÅ¡Ã­ odhad s dobrou pravdÄ›podobnostÃ­:

    |          |        0 |
    | -------: | -------: |
    |   indian | 0.715851 |
    |  chinese | 0.229475 |
    | japanese | 0.029763 |
    |   korean | 0.017277 |
    |     thai | 0.007634 |

    âœ… DokÃ¡Å¾ete vysvÄ›tlit, proÄ si model je docela jistÃ½, Å¾e se jednÃ¡ o indickou kuchyni?

1. ZÃ­skejte vÃ­ce detailÅ¯ vytiÅ¡tÄ›nÃ­m klasifikaÄnÃ­ zprÃ¡vy, stejnÄ› jako jste to udÄ›lali v lekcÃ­ch o regresi:

    ```python
    y_pred = model.predict(X_test)
    print(classification_report(y_test,y_pred))
    ```

    |              | precision | recall | f1-score | support |
    | ------------ | --------- | ------ | -------- | ------- |
    | chinese      | 0.73      | 0.71   | 0.72     | 229     |
    | indian       | 0.91      | 0.93   | 0.92     | 254     |
    | japanese     | 0.70      | 0.75   | 0.72     | 220     |
    | korean       | 0.86      | 0.76   | 0.81     | 242     |
    | thai         | 0.79      | 0.85   | 0.82     | 254     |
    | accuracy     | 0.80      | 1199   |          |         |
    | macro avg    | 0.80      | 0.80   | 0.80     | 1199    |
    | weighted avg | 0.80      | 0.80   | 0.80     | 1199    |

## ğŸš€VÃ½zva

V tÃ©to lekci jste pouÅ¾ili svÃ¡ vyÄiÅ¡tÄ›nÃ¡ data k vytvoÅ™enÃ­ modelu strojovÃ©ho uÄenÃ­, kterÃ½ dokÃ¡Å¾e pÅ™edpovÄ›dÄ›t nÃ¡rodnÃ­ kuchyni na zÃ¡kladÄ› sÃ©rie ingrediencÃ­. VÄ›nujte nÄ›jakÃ½ Äas prozkoumÃ¡nÃ­ mnoha moÅ¾nostÃ­, kterÃ© Scikit-learn nabÃ­zÃ­ pro klasifikaci dat. PonoÅ™te se hloubÄ›ji do konceptu 'solver', abyste pochopili, co se dÄ›je v zÃ¡kulisÃ­.

## [KvÃ­z po pÅ™ednÃ¡Å¡ce](https://ff-quizzes.netlify.app/en/ml/)

## PÅ™ehled & Samostudium

Prozkoumejte trochu vÃ­ce matematiku za logistickou regresÃ­ v [tÃ©to lekci](https://people.eecs.berkeley.edu/~russell/classes/cs194/f11/lectures/CS194%20Fall%202011%20Lecture%2006.pdf)
## Ãškol 

[Prostudujte solvery](assignment.md)

---

**ProhlÃ¡Å¡enÃ­**:  
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ sluÅ¾by pro automatickÃ½ pÅ™eklad [Co-op Translator](https://github.com/Azure/co-op-translator). AÄkoli se snaÅ¾Ã­me o pÅ™esnost, mÄ›jte prosÃ­m na pamÄ›ti, Å¾e automatickÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. PÅ¯vodnÃ­ dokument v jeho pÅ¯vodnÃ­m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za autoritativnÃ­ zdroj. Pro dÅ¯leÅ¾itÃ© informace doporuÄujeme profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. NeodpovÃ­dÃ¡me za Å¾Ã¡dnÃ¡ nedorozumÄ›nÃ­ nebo nesprÃ¡vnÃ© interpretace vyplÃ½vajÃ­cÃ­ z pouÅ¾itÃ­ tohoto pÅ™ekladu.