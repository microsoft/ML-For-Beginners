<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "49047911108adc49d605cddfb455749c",
  "translation_date": "2025-09-05T00:49:40+00:00",
  "source_file": "4-Classification/3-Classifiers-2/README.md",
  "language_code": "cs"
}
-->
# KlasifikÃ¡tory kuchynÃ­ 2

V tÃ©to druhÃ© lekci o klasifikaci se podÃ­vÃ¡te na dalÅ¡Ã­ zpÅ¯soby klasifikace ÄÃ­selnÃ½ch dat. TakÃ© se dozvÃ­te o dÅ¯sledcÃ­ch volby jednoho klasifikÃ¡toru oproti jinÃ©mu.

## [KvÃ­z pÅ™ed pÅ™ednÃ¡Å¡kou](https://ff-quizzes.netlify.app/en/ml/)

### PÅ™edpoklady

PÅ™edpoklÃ¡dÃ¡me, Å¾e jste dokonÄili pÅ™edchozÃ­ lekce a mÃ¡te vyÄiÅ¡tÄ›nÃ½ dataset ve sloÅ¾ce `data` s nÃ¡zvem _cleaned_cuisines.csv_ v koÅ™enovÃ©m adresÃ¡Å™i tÃ©to ÄtyÅ™lekÄnÃ­ sloÅ¾ky.

### PÅ™Ã­prava

NaÄtenÃ½ soubor _notebook.ipynb_ obsahuje vyÄiÅ¡tÄ›nÃ½ dataset, kterÃ½ jsme rozdÄ›lili na datovÃ© rÃ¡mce X a y, pÅ™ipravenÃ© pro proces tvorby modelu.

## Mapa klasifikace

DÅ™Ã­ve jste se nauÄili o rÅ¯znÃ½ch moÅ¾nostech klasifikace dat pomocÃ­ cheat sheetu od Microsoftu. Scikit-learn nabÃ­zÃ­ podobnÃ½, ale podrobnÄ›jÅ¡Ã­ cheat sheet, kterÃ½ vÃ¡m mÅ¯Å¾e pomoci jeÅ¡tÄ› vÃ­ce zÃºÅ¾it vÃ½bÄ›r odhadovaÄÅ¯ (dalÅ¡Ã­ termÃ­n pro klasifikÃ¡tory):

![ML Map from Scikit-learn](../../../../4-Classification/3-Classifiers-2/images/map.png)
> Tip: [navÅ¡tivte tuto mapu online](https://scikit-learn.org/stable/tutorial/machine_learning_map/) a kliknÄ›te na cestu, abyste si pÅ™eÄetli dokumentaci.

### PlÃ¡n

Tato mapa je velmi uÅ¾iteÄnÃ¡, jakmile mÃ¡te jasnou pÅ™edstavu o svÃ½ch datech, protoÅ¾e se mÅ¯Å¾ete â€prochÃ¡zetâ€œ jejÃ­mi cestami k rozhodnutÃ­:

- MÃ¡me >50 vzorkÅ¯
- Chceme pÅ™edpovÄ›dÄ›t kategorii
- MÃ¡me oznaÄenÃ¡ data
- MÃ¡me mÃ©nÄ› neÅ¾ 100K vzorkÅ¯
- âœ¨ MÅ¯Å¾eme zvolit Linear SVC
- Pokud to nefunguje, protoÅ¾e mÃ¡me ÄÃ­selnÃ¡ data
    - MÅ¯Å¾eme zkusit âœ¨ KNeighbors Classifier 
      - Pokud to nefunguje, zkusÃ­me âœ¨ SVC a âœ¨ Ensemble Classifiers

Toto je velmi uÅ¾iteÄnÃ¡ cesta, kterou se mÅ¯Å¾eme Å™Ã­dit.

## CviÄenÃ­ - rozdÄ›lenÃ­ dat

Podle tÃ©to cesty bychom mÄ›li zaÄÃ­t importem nÄ›kterÃ½ch knihoven, kterÃ© budeme pouÅ¾Ã­vat.

1. Importujte potÅ™ebnÃ© knihovny:

    ```python
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    import numpy as np
    ```

1. RozdÄ›lte svÃ¡ trÃ©ninkovÃ¡ a testovacÃ­ data:

    ```python
    X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)
    ```

## Linear SVC klasifikÃ¡tor

Support-Vector clustering (SVC) je souÄÃ¡stÃ­ rodiny technik strojovÃ©ho uÄenÃ­ Support-Vector Machines (vÃ­ce o nich nÃ­Å¾e). V tÃ©to metodÄ› mÅ¯Å¾ete zvolit â€kernelâ€œ, kterÃ½ urÄuje, jak se budou Å¡tÃ­tky seskupovat. Parametr 'C' se tÃ½kÃ¡ 'regularizace', kterÃ¡ reguluje vliv parametrÅ¯. Kernel mÅ¯Å¾e bÃ½t jeden z [nÄ›kolika](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC); zde jej nastavÃ­me na 'linear', abychom vyuÅ¾ili lineÃ¡rnÃ­ SVC. PravdÄ›podobnost je ve vÃ½chozÃ­m nastavenÃ­ 'false'; zde ji nastavÃ­me na 'true', abychom zÃ­skali odhady pravdÄ›podobnosti. NÃ¡hodnÃ½ stav nastavÃ­me na '0', abychom data zamÃ­chali a zÃ­skali pravdÄ›podobnosti.

### CviÄenÃ­ - aplikace lineÃ¡rnÃ­ho SVC

ZaÄnÄ›te vytvoÅ™enÃ­m pole klasifikÃ¡torÅ¯. Do tohoto pole budete postupnÄ› pÅ™idÃ¡vat, jak budeme testovat.

1. ZaÄnÄ›te s Linear SVC:

    ```python
    C = 10
    # Create different classifiers.
    classifiers = {
        'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0)
    }
    ```

2. NatrÃ©nujte svÅ¯j model pomocÃ­ Linear SVC a vytisknÄ›te zprÃ¡vu:

    ```python
    n_classifiers = len(classifiers)
    
    for index, (name, classifier) in enumerate(classifiers.items()):
        classifier.fit(X_train, np.ravel(y_train))
    
        y_pred = classifier.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print("Accuracy (train) for %s: %0.1f%% " % (name, accuracy * 100))
        print(classification_report(y_test,y_pred))
    ```

    VÃ½sledek je docela dobrÃ½:

    ```output
    Accuracy (train) for Linear SVC: 78.6% 
                  precision    recall  f1-score   support
    
         chinese       0.71      0.67      0.69       242
          indian       0.88      0.86      0.87       234
        japanese       0.79      0.74      0.76       254
          korean       0.85      0.81      0.83       242
            thai       0.71      0.86      0.78       227
    
        accuracy                           0.79      1199
       macro avg       0.79      0.79      0.79      1199
    weighted avg       0.79      0.79      0.79      1199
    ```

## K-Neighbors klasifikÃ¡tor

K-Neighbors je souÄÃ¡stÃ­ rodiny metod strojovÃ©ho uÄenÃ­ â€neighborsâ€œ, kterÃ© lze pouÅ¾Ã­t pro Å™Ã­zenÃ© i neÅ™Ã­zenÃ© uÄenÃ­. V tÃ©to metodÄ› je vytvoÅ™en pÅ™edem definovanÃ½ poÄet bodÅ¯ a data se shromaÅ¾ÄujÃ­ kolem tÄ›chto bodÅ¯ tak, aby bylo moÅ¾nÃ© pÅ™edpovÄ›dÄ›t obecnÃ© Å¡tÃ­tky pro data.

### CviÄenÃ­ - aplikace K-Neighbors klasifikÃ¡toru

PÅ™edchozÃ­ klasifikÃ¡tor byl dobrÃ½ a fungoval dobÅ™e s daty, ale moÅ¾nÃ¡ mÅ¯Å¾eme dosÃ¡hnout lepÅ¡Ã­ pÅ™esnosti. Zkuste K-Neighbors klasifikÃ¡tor.

1. PÅ™idejte Å™Ã¡dek do svÃ©ho pole klasifikÃ¡torÅ¯ (pÅ™idejte ÄÃ¡rku za poloÅ¾ku Linear SVC):

    ```python
    'KNN classifier': KNeighborsClassifier(C),
    ```

    VÃ½sledek je o nÄ›co horÅ¡Ã­:

    ```output
    Accuracy (train) for KNN classifier: 73.8% 
                  precision    recall  f1-score   support
    
         chinese       0.64      0.67      0.66       242
          indian       0.86      0.78      0.82       234
        japanese       0.66      0.83      0.74       254
          korean       0.94      0.58      0.72       242
            thai       0.71      0.82      0.76       227
    
        accuracy                           0.74      1199
       macro avg       0.76      0.74      0.74      1199
    weighted avg       0.76      0.74      0.74      1199
    ```

    âœ… NauÄte se vÃ­ce o [K-Neighbors](https://scikit-learn.org/stable/modules/neighbors.html#neighbors)

## Support Vector Classifier

Support-Vector klasifikÃ¡tory jsou souÄÃ¡stÃ­ rodiny metod strojovÃ©ho uÄenÃ­ [Support-Vector Machine](https://wikipedia.org/wiki/Support-vector_machine), kterÃ© se pouÅ¾Ã­vajÃ­ pro klasifikaÄnÃ­ a regresnÃ­ Ãºlohy. SVM â€mapujÃ­ trÃ©ninkovÃ© pÅ™Ã­klady na body v prostoruâ€œ, aby maximalizovaly vzdÃ¡lenost mezi dvÄ›ma kategoriemi. NÃ¡slednÃ¡ data jsou mapovÃ¡na do tohoto prostoru, aby bylo moÅ¾nÃ© pÅ™edpovÄ›dÄ›t jejich kategorii.

### CviÄenÃ­ - aplikace Support Vector Classifier

Zkusme dosÃ¡hnout o nÄ›co lepÅ¡Ã­ pÅ™esnosti pomocÃ­ Support Vector Classifier.

1. PÅ™idejte ÄÃ¡rku za poloÅ¾ku K-Neighbors a potÃ© pÅ™idejte tento Å™Ã¡dek:

    ```python
    'SVC': SVC(),
    ```

    VÃ½sledek je velmi dobrÃ½!

    ```output
    Accuracy (train) for SVC: 83.2% 
                  precision    recall  f1-score   support
    
         chinese       0.79      0.74      0.76       242
          indian       0.88      0.90      0.89       234
        japanese       0.87      0.81      0.84       254
          korean       0.91      0.82      0.86       242
            thai       0.74      0.90      0.81       227
    
        accuracy                           0.83      1199
       macro avg       0.84      0.83      0.83      1199
    weighted avg       0.84      0.83      0.83      1199
    ```

    âœ… NauÄte se vÃ­ce o [Support-Vectors](https://scikit-learn.org/stable/modules/svm.html#svm)

## Ensemble Classifiers

PojÄme se vydat cestou aÅ¾ na konec, i kdyÅ¾ pÅ™edchozÃ­ test byl velmi dobrÃ½. Zkusme nÄ›kterÃ© â€Ensemble Classifiersâ€œ, konkrÃ©tnÄ› Random Forest a AdaBoost:

```python
  'RFST': RandomForestClassifier(n_estimators=100),
  'ADA': AdaBoostClassifier(n_estimators=100)
```

VÃ½sledek je velmi dobrÃ½, zejmÃ©na u Random Forest:

```output
Accuracy (train) for RFST: 84.5% 
              precision    recall  f1-score   support

     chinese       0.80      0.77      0.78       242
      indian       0.89      0.92      0.90       234
    japanese       0.86      0.84      0.85       254
      korean       0.88      0.83      0.85       242
        thai       0.80      0.87      0.83       227

    accuracy                           0.84      1199
   macro avg       0.85      0.85      0.84      1199
weighted avg       0.85      0.84      0.84      1199

Accuracy (train) for ADA: 72.4% 
              precision    recall  f1-score   support

     chinese       0.64      0.49      0.56       242
      indian       0.91      0.83      0.87       234
    japanese       0.68      0.69      0.69       254
      korean       0.73      0.79      0.76       242
        thai       0.67      0.83      0.74       227

    accuracy                           0.72      1199
   macro avg       0.73      0.73      0.72      1199
weighted avg       0.73      0.72      0.72      1199
```

âœ… NauÄte se vÃ­ce o [Ensemble Classifiers](https://scikit-learn.org/stable/modules/ensemble.html)

Tato metoda strojovÃ©ho uÄenÃ­ â€kombinuje pÅ™edpovÄ›di nÄ›kolika zÃ¡kladnÃ­ch odhadovaÄÅ¯â€œ, aby zlepÅ¡ila kvalitu modelu. V naÅ¡em pÅ™Ã­kladu jsme pouÅ¾ili Random Trees a AdaBoost. 

- [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest), metoda prÅ¯mÄ›rovÃ¡nÃ­, vytvÃ¡Å™Ã­ â€lesâ€œ â€rozhodovacÃ­ch stromÅ¯â€œ naplnÄ›nÃ½ch nÃ¡hodnostÃ­, aby se zabrÃ¡nilo pÅ™euÄenÃ­. Parametr n_estimators je nastaven na poÄet stromÅ¯.

- [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) pÅ™izpÅ¯sobÃ­ klasifikÃ¡tor datasetu a potÃ© pÅ™izpÅ¯sobÃ­ kopie tohoto klasifikÃ¡toru stejnÃ©mu datasetu. ZamÄ›Å™uje se na vÃ¡hy nesprÃ¡vnÄ› klasifikovanÃ½ch poloÅ¾ek a upravuje fit pro dalÅ¡Ã­ klasifikÃ¡tor, aby provedl opravu.

---

## ğŸš€VÃ½zva

KaÅ¾dÃ¡ z tÄ›chto technik mÃ¡ velkÃ© mnoÅ¾stvÃ­ parametrÅ¯, kterÃ© mÅ¯Å¾ete upravit. Prozkoumejte vÃ½chozÃ­ parametry kaÅ¾dÃ© z nich a pÅ™emÃ½Å¡lejte o tom, co by znamenalo upravenÃ­ tÄ›chto parametrÅ¯ pro kvalitu modelu.

## [KvÃ­z po pÅ™ednÃ¡Å¡ce](https://ff-quizzes.netlify.app/en/ml/)

## PÅ™ehled & Samostudium

V tÄ›chto lekcÃ­ch je hodnÄ› odbornÃ½ch termÃ­nÅ¯, takÅ¾e si udÄ›lejte chvÃ­li na pÅ™ehled [tohoto seznamu](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) uÅ¾iteÄnÃ© terminologie!

## ZadÃ¡nÃ­ 

[Hra s parametry](assignment.md)

---

**ProhlÃ¡Å¡enÃ­**:  
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ sluÅ¾by pro automatickÃ½ pÅ™eklad [Co-op Translator](https://github.com/Azure/co-op-translator). AÄkoli se snaÅ¾Ã­me o pÅ™esnost, mÄ›jte prosÃ­m na pamÄ›ti, Å¾e automatickÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. PÅ¯vodnÃ­ dokument v jeho pÅ¯vodnÃ­m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za autoritativnÃ­ zdroj. Pro dÅ¯leÅ¾itÃ© informace se doporuÄuje profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. NeodpovÃ­dÃ¡me za Å¾Ã¡dnÃ¡ nedorozumÄ›nÃ­ nebo nesprÃ¡vnÃ© interpretace vyplÃ½vajÃ­cÃ­ z pouÅ¾itÃ­ tohoto pÅ™ekladu.