<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "df2b538e8fbb3e91cf0419ae2f858675",
  "translation_date": "2025-09-05T00:15:11+00:00",
  "source_file": "9-Real-World/2-Debugging-ML-Models/README.md",
  "language_code": "cs"
}
-->
# Postscript: LadÄ›nÃ­ modelÅ¯ strojovÃ©ho uÄenÃ­ pomocÃ­ komponent Responsible AI dashboardu

## [KvÃ­z pÅ™ed pÅ™ednÃ¡Å¡kou](https://ff-quizzes.netlify.app/en/ml/)

## Ãšvod

StrojovÃ© uÄenÃ­ ovlivÅˆuje nÃ¡Å¡ kaÅ¾dodennÃ­ Å¾ivot. AI se dostÃ¡vÃ¡ do nÄ›kterÃ½ch z nejdÅ¯leÅ¾itÄ›jÅ¡Ã­ch systÃ©mÅ¯, kterÃ© ovlivÅˆujÃ­ nÃ¡s jako jednotlivce i naÅ¡i spoleÄnost, od zdravotnictvÃ­, financÃ­, vzdÄ›lÃ¡vÃ¡nÃ­ aÅ¾ po zamÄ›stnanost. NapÅ™Ã­klad systÃ©my a modely se podÃ­lejÃ­ na kaÅ¾dodennÃ­ch rozhodovacÃ­ch ÃºlohÃ¡ch, jako jsou diagnÃ³zy ve zdravotnictvÃ­ nebo odhalovÃ¡nÃ­ podvodÅ¯. V dÅ¯sledku toho jsou pokroky v AI spolu s rychlou adopcÃ­ doprovÃ¡zeny mÄ›nÃ­cÃ­mi se spoleÄenskÃ½mi oÄekÃ¡vÃ¡nÃ­mi a rostoucÃ­ regulacÃ­. NeustÃ¡le vidÃ­me oblasti, kde systÃ©my AI nesplÅˆujÃ­ oÄekÃ¡vÃ¡nÃ­, odhalujÃ­ novÃ© vÃ½zvy a vlÃ¡dy zaÄÃ­najÃ­ regulovat AI Å™eÅ¡enÃ­. Je tedy dÅ¯leÅ¾itÃ©, aby tyto modely byly analyzovÃ¡ny tak, aby poskytovaly spravedlivÃ©, spolehlivÃ©, inkluzivnÃ­, transparentnÃ­ a odpovÄ›dnÃ© vÃ½sledky pro vÅ¡echny.

V tomto kurzu se podÃ­vÃ¡me na praktickÃ© nÃ¡stroje, kterÃ© lze pouÅ¾Ã­t k posouzenÃ­, zda mÃ¡ model problÃ©my s odpovÄ›dnou AI. TradiÄnÃ­ techniky ladÄ›nÃ­ strojovÃ©ho uÄenÃ­ bÃ½vajÃ­ zaloÅ¾eny na kvantitativnÃ­ch vÃ½poÄtech, jako je agregovanÃ¡ pÅ™esnost nebo prÅ¯mÄ›rnÃ¡ ztrÃ¡ta chyb. PÅ™edstavte si, co se mÅ¯Å¾e stÃ¡t, kdyÅ¾ data, kterÃ¡ pouÅ¾Ã­vÃ¡te k vytvÃ¡Å™enÃ­ tÄ›chto modelÅ¯, postrÃ¡dajÃ­ urÄitÃ© demografickÃ© skupiny, jako je rasa, pohlavÃ­, politickÃ½ nÃ¡zor, nÃ¡boÅ¾enstvÃ­, nebo naopak nepÅ™imÄ›Å™enÄ› zastupujÃ­ tyto demografickÃ© skupiny. Co kdyÅ¾ je vÃ½stup modelu interpretovÃ¡n tak, Å¾e upÅ™ednostÅˆuje urÄitou demografickou skupinu? To mÅ¯Å¾e vÃ©st k nadmÄ›rnÃ©mu nebo nedostateÄnÃ©mu zastoupenÃ­ tÄ›chto citlivÃ½ch skupin, coÅ¾ zpÅ¯sobÃ­ problÃ©my se spravedlnostÃ­, inkluzivitou nebo spolehlivostÃ­ modelu. DalÅ¡Ã­m faktorem je, Å¾e modely strojovÃ©ho uÄenÃ­ jsou povaÅ¾ovÃ¡ny za "ÄernÃ© skÅ™Ã­Åˆky", coÅ¾ ztÄ›Å¾uje pochopenÃ­ a vysvÄ›tlenÃ­ toho, co ovlivÅˆuje predikce modelu. VÅ¡echny tyto vÃ½zvy ÄelÃ­ datovÃ­ vÄ›dci a vÃ½vojÃ¡Å™i AI, pokud nemajÃ­ dostateÄnÃ© nÃ¡stroje k ladÄ›nÃ­ a posouzenÃ­ spravedlnosti nebo dÅ¯vÄ›ryhodnosti modelu.

V tÃ©to lekci se nauÄÃ­te ladit svÃ© modely pomocÃ­:

- **AnalÃ½zy chyb**: identifikace oblastÃ­ v distribuci dat, kde mÃ¡ model vysokou mÃ­ru chyb.
- **PÅ™ehledu modelu**: provÃ¡dÄ›nÃ­ srovnÃ¡vacÃ­ analÃ½zy mezi rÅ¯znÃ½mi datovÃ½mi kohortami k odhalenÃ­ rozdÃ­lÅ¯ ve vÃ½konnostnÃ­ch metrikÃ¡ch modelu.
- **AnalÃ½zy dat**: zkoumÃ¡nÃ­, kde mÅ¯Å¾e dochÃ¡zet k nadmÄ›rnÃ©mu nebo nedostateÄnÃ©mu zastoupenÃ­ dat, coÅ¾ mÅ¯Å¾e zkreslit model ve prospÄ›ch jednÃ© demografickÃ© skupiny oproti jinÃ©.
- **DÅ¯leÅ¾itosti vlastnostÃ­**: pochopenÃ­, kterÃ© vlastnosti ovlivÅˆujÃ­ predikce modelu na globÃ¡lnÃ­ nebo lokÃ¡lnÃ­ Ãºrovni.

## PÅ™edpoklady

Jako pÅ™edpoklad si prosÃ­m projdÄ›te [NÃ¡stroje odpovÄ›dnÃ© AI pro vÃ½vojÃ¡Å™e](https://www.microsoft.com/ai/ai-lab-responsible-ai-dashboard)

> ![Gif o nÃ¡strojÃ­ch odpovÄ›dnÃ© AI](../../../../9-Real-World/2-Debugging-ML-Models/images/rai-overview.gif)

## AnalÃ½za chyb

TradiÄnÃ­ metriky vÃ½konnosti modelu pouÅ¾Ã­vanÃ© k mÄ›Å™enÃ­ pÅ™esnosti jsou vÄ›tÅ¡inou vÃ½poÄty zaloÅ¾enÃ© na sprÃ¡vnÃ½ch vs nesprÃ¡vnÃ½ch predikcÃ­ch. NapÅ™Ã­klad urÄenÃ­, Å¾e model je pÅ™esnÃ½ z 89 % s chybovou ztrÃ¡tou 0,001, mÅ¯Å¾e bÃ½t povaÅ¾ovÃ¡no za dobrÃ½ vÃ½kon. Chyby vÅ¡ak nejsou v zÃ¡kladnÃ­m datovÃ©m souboru rozloÅ¾eny rovnomÄ›rnÄ›. MÅ¯Å¾ete zÃ­skat skÃ³re pÅ™esnosti modelu 89 %, ale zjistit, Å¾e existujÃ­ rÅ¯znÃ© oblasti vaÅ¡ich dat, kde model selhÃ¡vÃ¡ ve 42 % pÅ™Ã­padÅ¯. DÅ¯sledky tÄ›chto vzorcÅ¯ selhÃ¡nÃ­ u urÄitÃ½ch datovÃ½ch skupin mohou vÃ©st k problÃ©mÅ¯m se spravedlnostÃ­ nebo spolehlivostÃ­. Je zÃ¡sadnÃ­ pochopit oblasti, kde model funguje dobÅ™e nebo ne. DatovÃ© oblasti, kde mÃ¡ vÃ¡Å¡ model vysokÃ½ poÄet nepÅ™esnostÃ­, se mohou ukÃ¡zat jako dÅ¯leÅ¾itÃ¡ demografickÃ¡ data.

![Analyzujte a ladÄ›te chyby modelu](../../../../9-Real-World/2-Debugging-ML-Models/images/ea-error-distribution.png)

Komponenta AnalÃ½za chyb na RAI dashboardu ukazuje, jak jsou selhÃ¡nÃ­ modelu rozloÅ¾ena napÅ™Ã­Ä rÅ¯znÃ½mi kohortami pomocÃ­ vizualizace stromu. To je uÅ¾iteÄnÃ© pÅ™i identifikaci vlastnostÃ­ nebo oblastÃ­, kde je vysokÃ¡ mÃ­ra chyb ve vaÅ¡em datovÃ©m souboru. DÃ­ky tomu, Å¾e vidÃ­te, odkud pochÃ¡zÃ­ vÄ›tÅ¡ina nepÅ™esnostÃ­ modelu, mÅ¯Å¾ete zaÄÃ­t zkoumat jejich pÅ™Ã­Äinu. MÅ¯Å¾ete takÃ© vytvoÅ™it datovÃ© kohorty pro provÃ¡dÄ›nÃ­ analÃ½zy. Tyto datovÃ© kohorty pomÃ¡hajÃ­ v procesu ladÄ›nÃ­ urÄit, proÄ je vÃ½kon modelu dobrÃ½ v jednÃ© kohortÄ›, ale chybnÃ½ v jinÃ©.

![AnalÃ½za chyb](../../../../9-Real-World/2-Debugging-ML-Models/images/ea-error-cohort.png)

VizualizaÄnÃ­ indikÃ¡tory na mapÄ› stromu pomÃ¡hajÃ­ rychleji lokalizovat problÃ©movÃ© oblasti. NapÅ™Ã­klad ÄÃ­m tmavÅ¡Ã­ odstÃ­n ÄervenÃ© barvy mÃ¡ uzel stromu, tÃ­m vyÅ¡Å¡Ã­ je mÃ­ra chyb.

Heatmapa je dalÅ¡Ã­ vizualizaÄnÃ­ funkce, kterou mohou uÅ¾ivatelÃ© pouÅ¾Ã­t k vyÅ¡etÅ™ovÃ¡nÃ­ mÃ­ry chyb pomocÃ­ jednÃ© nebo dvou vlastnostÃ­, aby naÅ¡li pÅ™ispÄ›vatele k chybÃ¡m modelu napÅ™Ã­Ä celÃ½m datovÃ½m souborem nebo kohortami.

![Heatmapa analÃ½zy chyb](../../../../9-Real-World/2-Debugging-ML-Models/images/ea-heatmap.png)

PouÅ¾ijte analÃ½zu chyb, kdyÅ¾ potÅ™ebujete:

* ZÃ­skat hlubokÃ© pochopenÃ­ toho, jak jsou selhÃ¡nÃ­ modelu rozloÅ¾ena napÅ™Ã­Ä datovÃ½m souborem a nÄ›kolika vstupnÃ­mi a vlastnostnÃ­mi dimenzemi.
* RozloÅ¾it agregovanÃ© metriky vÃ½konu a automaticky objevit chybnÃ© kohorty, kterÃ© informujÃ­ o vaÅ¡ich cÃ­lenÃ½ch krocÃ­ch k nÃ¡pravÄ›.

## PÅ™ehled modelu

HodnocenÃ­ vÃ½konu modelu strojovÃ©ho uÄenÃ­ vyÅ¾aduje zÃ­skÃ¡nÃ­ komplexnÃ­ho pochopenÃ­ jeho chovÃ¡nÃ­. Toho lze dosÃ¡hnout pÅ™ezkoumÃ¡nÃ­m vÃ­ce neÅ¾ jednÃ© metriky, jako je mÃ­ra chyb, pÅ™esnost, recall, precision nebo MAE (Mean Absolute Error), aby se odhalily rozdÃ­ly mezi vÃ½konnostnÃ­mi metrikami. Jedna metrika vÃ½konu mÅ¯Å¾e vypadat skvÄ›le, ale nepÅ™esnosti mohou bÃ½t odhaleny v jinÃ© metrice. NavÃ­c porovnÃ¡nÃ­ metrik pro rozdÃ­ly napÅ™Ã­Ä celÃ½m datovÃ½m souborem nebo kohortami pomÃ¡hÃ¡ osvÄ›tlit, kde model funguje dobÅ™e nebo ne. To je obzvlÃ¡Å¡tÄ› dÅ¯leÅ¾itÃ© pÅ™i sledovÃ¡nÃ­ vÃ½konu modelu mezi citlivÃ½mi vs necitlivÃ½mi vlastnostmi (napÅ™. rasa pacienta, pohlavÃ­ nebo vÄ›k), aby se odhalila potenciÃ¡lnÃ­ nespravedlnost modelu. NapÅ™Ã­klad zjiÅ¡tÄ›nÃ­, Å¾e model je vÃ­ce chybnÃ½ v kohortÄ›, kterÃ¡ mÃ¡ citlivÃ© vlastnosti, mÅ¯Å¾e odhalit potenciÃ¡lnÃ­ nespravedlnost modelu.

Komponenta PÅ™ehled modelu na RAI dashboardu pomÃ¡hÃ¡ nejen pÅ™i analÃ½ze vÃ½konnostnÃ­ch metrik reprezentace dat v kohortÄ›, ale dÃ¡vÃ¡ uÅ¾ivatelÅ¯m moÅ¾nost porovnÃ¡vat chovÃ¡nÃ­ modelu napÅ™Ã­Ä rÅ¯znÃ½mi kohortami.

![DatovÃ© kohorty - pÅ™ehled modelu na RAI dashboardu](../../../../9-Real-World/2-Debugging-ML-Models/images/model-overview-dataset-cohorts.png)

Funkce analÃ½zy zaloÅ¾enÃ© na vlastnostech komponenty umoÅ¾Åˆuje uÅ¾ivatelÅ¯m zÃºÅ¾it podskupiny dat v rÃ¡mci konkrÃ©tnÃ­ vlastnosti, aby identifikovali anomÃ¡lie na granulÃ¡rnÃ­ Ãºrovni. NapÅ™Ã­klad dashboard mÃ¡ vestavÄ›nou inteligenci, kterÃ¡ automaticky generuje kohorty pro uÅ¾ivatelem vybranou vlastnost (napÅ™. *"time_in_hospital < 3"* nebo *"time_in_hospital >= 7"*). To umoÅ¾Åˆuje uÅ¾ivateli izolovat konkrÃ©tnÃ­ vlastnost z vÄ›tÅ¡Ã­ skupiny dat, aby zjistil, zda je klÃ­ÄovÃ½m ovlivÅˆovatelem chybnÃ½ch vÃ½sledkÅ¯ modelu.

![Kohorty vlastnostÃ­ - pÅ™ehled modelu na RAI dashboardu](../../../../9-Real-World/2-Debugging-ML-Models/images/model-overview-feature-cohorts.png)

Komponenta PÅ™ehled modelu podporuje dvÄ› tÅ™Ã­dy metrik rozdÃ­lÅ¯:

**RozdÃ­ly ve vÃ½konnosti modelu**: Tyto sady metrik vypoÄÃ­tÃ¡vajÃ­ rozdÃ­ly (disparity) ve hodnotÃ¡ch vybranÃ© vÃ½konnostnÃ­ metriky napÅ™Ã­Ä podskupinami dat. Zde je nÄ›kolik pÅ™Ã­kladÅ¯:

* RozdÃ­ly v mÃ­Å™e pÅ™esnosti
* RozdÃ­ly v mÃ­Å™e chyb
* RozdÃ­ly v precision
* RozdÃ­ly v recall
* RozdÃ­ly v prÅ¯mÄ›rnÃ© absolutnÃ­ chybÄ› (MAE)

**RozdÃ­ly v mÃ­Å™e vÃ½bÄ›ru**: Tato metrika obsahuje rozdÃ­ly v mÃ­Å™e vÃ½bÄ›ru (pÅ™Ã­znivÃ¡ predikce) mezi podskupinami. PÅ™Ã­kladem je rozdÃ­l v mÃ­Å™e schvalovÃ¡nÃ­ pÅ¯jÄek. MÃ­ra vÃ½bÄ›ru znamenÃ¡ podÃ­l datovÃ½ch bodÅ¯ v kaÅ¾dÃ© tÅ™Ã­dÄ› klasifikovanÃ½ch jako 1 (v binÃ¡rnÃ­ klasifikaci) nebo rozloÅ¾enÃ­ hodnot predikce (v regresi).

## AnalÃ½za dat

> "Pokud budete data muÄit dostateÄnÄ› dlouho, pÅ™iznajÃ­ cokoliv" - Ronald Coase

Toto tvrzenÃ­ znÃ­ extrÃ©mnÄ›, ale je pravda, Å¾e data mohou bÃ½t manipulovÃ¡na tak, aby podporovala jakÃ½koliv zÃ¡vÄ›r. TakovÃ¡ manipulace se nÄ›kdy mÅ¯Å¾e stÃ¡t neÃºmyslnÄ›. Jako lidÃ© mÃ¡me vÅ¡ichni pÅ™edsudky a Äasto je obtÃ­Å¾nÃ© vÄ›domÄ› vÄ›dÄ›t, kdy do dat zavÃ¡dÃ­me pÅ™edsudky. ZajiÅ¡tÄ›nÃ­ spravedlnosti v AI a strojovÃ©m uÄenÃ­ zÅ¯stÃ¡vÃ¡ sloÅ¾itou vÃ½zvou.

Data jsou velkÃ½m slepÃ½m mÃ­stem pro tradiÄnÃ­ metriky vÃ½konnosti modelu. MÅ¯Å¾ete mÃ­t vysokÃ© skÃ³re pÅ™esnosti, ale to ne vÅ¾dy odrÃ¡Å¾Ã­ zÃ¡kladnÃ­ pÅ™edsudky v datech, kterÃ© mohou bÃ½t ve vaÅ¡em datovÃ©m souboru. NapÅ™Ã­klad pokud datovÃ½ soubor zamÄ›stnancÅ¯ obsahuje 27 % Å¾en na vÃ½konnÃ½ch pozicÃ­ch ve firmÄ› a 73 % muÅ¾Å¯ na stejnÃ© Ãºrovni, model AI pro inzerci pracovnÃ­ch mÃ­st vyÅ¡kolenÃ½ na tÄ›chto datech mÅ¯Å¾e cÃ­lit pÅ™evÃ¡Å¾nÄ› na muÅ¾skÃ© publikum pro seniornÃ­ pracovnÃ­ pozice. Tato nerovnovÃ¡ha v datech zkreslila predikci modelu ve prospÄ›ch jednoho pohlavÃ­. To odhaluje problÃ©m spravedlnosti, kde je v modelu AI pÅ™Ã­tomna genderovÃ¡ pÅ™edpojatost.

Komponenta AnalÃ½za dat na RAI dashboardu pomÃ¡hÃ¡ identifikovat oblasti, kde je v datovÃ©m souboru nadmÄ›rnÃ© nebo nedostateÄnÃ© zastoupenÃ­. PomÃ¡hÃ¡ uÅ¾ivatelÅ¯m diagnostikovat pÅ™Ã­Äinu chyb a problÃ©mÅ¯ se spravedlnostÃ­, kterÃ© jsou zpÅ¯sobeny nerovnovÃ¡hou dat nebo nedostateÄnÃ½m zastoupenÃ­m urÄitÃ© datovÃ© skupiny. To dÃ¡vÃ¡ uÅ¾ivatelÅ¯m moÅ¾nost vizualizovat datovÃ© soubory na zÃ¡kladÄ› predikovanÃ½ch a skuteÄnÃ½ch vÃ½sledkÅ¯, skupin chyb a konkrÃ©tnÃ­ch vlastnostÃ­. NÄ›kdy objevenÃ­ nedostateÄnÄ› zastoupenÃ© datovÃ© skupiny mÅ¯Å¾e takÃ© odhalit, Å¾e model se dobÅ™e neuÄÃ­, coÅ¾ vede k vysokÃ½m nepÅ™esnostem. Model, kterÃ½ mÃ¡ pÅ™edsudky v datech, nenÃ­ jen problÃ©mem spravedlnosti, ale ukazuje, Å¾e model nenÃ­ inkluzivnÃ­ nebo spolehlivÃ½.

![Komponenta AnalÃ½za dat na RAI dashboardu](../../../../9-Real-World/2-Debugging-ML-Models/images/dataanalysis-cover.png)

PouÅ¾ijte analÃ½zu dat, kdyÅ¾ potÅ™ebujete:

* Prozkoumat statistiky svÃ©ho datovÃ©ho souboru vÃ½bÄ›rem rÅ¯znÃ½ch filtrÅ¯ pro rozdÄ›lenÃ­ dat do rÅ¯znÃ½ch dimenzÃ­ (znÃ¡mÃ½ch jako kohorty).
* Pochopit rozloÅ¾enÃ­ svÃ©ho datovÃ©ho souboru napÅ™Ã­Ä rÅ¯znÃ½mi kohortami a skupinami vlastnostÃ­.
* UrÄit, zda vaÅ¡e zjiÅ¡tÄ›nÃ­ tÃ½kajÃ­cÃ­ se spravedlnosti, analÃ½zy chyb a kauzality (odvozenÃ© z jinÃ½ch komponent dashboardu) jsou vÃ½sledkem rozloÅ¾enÃ­ vaÅ¡eho datovÃ©ho souboru.
* Rozhodnout, v jakÃ½ch oblastech sbÃ­rat vÃ­ce dat, aby se zmÃ­rnily chyby zpÅ¯sobenÃ© problÃ©my s reprezentacÃ­, Å¡umem v oznaÄenÃ­, Å¡umem ve vlastnostech, pÅ™edsudky v oznaÄenÃ­ a podobnÃ½mi faktory.

## Interpretace modelu

Modely strojovÃ©ho uÄenÃ­ majÃ­ tendenci bÃ½t "ÄernÃ½mi skÅ™Ã­Åˆkami". PochopenÃ­, kterÃ© klÃ­ÄovÃ© vlastnosti dat ovlivÅˆujÃ­ predikci modelu, mÅ¯Å¾e bÃ½t nÃ¡roÄnÃ©. Je dÅ¯leÅ¾itÃ© poskytnout transparentnost ohlednÄ› toho, proÄ model dÄ›lÃ¡ urÄitou predikci. NapÅ™Ã­klad pokud systÃ©m AI pÅ™edpovÃ­dÃ¡, Å¾e diabetickÃ½ pacient je ohroÅ¾en opÄ›tovnÃ½m pÅ™ijetÃ­m do nemocnice bÄ›hem mÃ©nÄ› neÅ¾ 30 dnÅ¯, mÄ›l by bÃ½t schopen poskytnout podpÅ¯rnÃ¡ data, kterÃ¡ vedla k jeho predikci. MÃ­t podpÅ¯rnÃ© datovÃ© indikÃ¡tory pÅ™inÃ¡Å¡Ã­ transparentnost, kterÃ¡ pomÃ¡hÃ¡ lÃ©kaÅ™Å¯m nebo nemocnicÃ­m Äinit dobÅ™e informovanÃ¡ rozhodnutÃ­. NavÃ­c schopnost vysvÄ›tlit, proÄ model uÄinil predikci pro konkrÃ©tnÃ­ho pacienta, umoÅ¾Åˆuje odpovÄ›dnost vÅ¯Äi zdravotnÃ­m regulacÃ­m. KdyÅ¾ pouÅ¾Ã­vÃ¡te modely strojovÃ©ho uÄenÃ­ zpÅ¯soby, kterÃ© ovlivÅˆujÃ­ Å¾ivoty lidÃ­, je zÃ¡sadnÃ­ pochopit a vysvÄ›tlit, co ovlivÅˆuje chovÃ¡nÃ­ modelu. VysvÄ›tlitelnost a interpretace modelu pomÃ¡hÃ¡ odpovÄ›dÄ›t na otÃ¡zky v situacÃ­ch, jako jsou:

* LadÄ›nÃ­ modelu: ProÄ mÅ¯j model udÄ›lal tuto chybu? Jak mohu svÅ¯j model zlepÅ¡it?
* SpoluprÃ¡ce ÄlovÄ›k-AI: Jak mohu pochopit a dÅ¯vÄ›Å™ovat rozhodnutÃ­m modelu?
* RegulativnÃ­ shoda: SplÅˆuje mÅ¯j model prÃ¡vnÃ­ poÅ¾adavky?

Komponenta DÅ¯leÅ¾itost vlastnostÃ­ na RAI dashboardu vÃ¡m pomÃ¡hÃ¡ ladit a zÃ­skat komplexnÃ­ pochopenÃ­ toho, jak model dÄ›lÃ¡ predikce. Je to takÃ© uÅ¾iteÄnÃ½ nÃ¡stroj pro profesionÃ¡ly v oblasti strojovÃ©ho uÄenÃ­ a rozhodovacÃ­ Äinitele, kteÅ™Ã­ potÅ™ebujÃ­ vysvÄ›tlit a ukÃ¡zat dÅ¯kazy o vlastnostech ovlivÅˆujÃ­cÃ­ch chovÃ¡nÃ­ modelu pro regulativnÃ­ shodu. UÅ¾ivatelÃ© mohou dÃ¡le zkoumat globÃ¡lnÃ­ i lokÃ¡lnÃ­ vysvÄ›tlenÃ­, aby ovÄ›Å™ili, kterÃ© vlastnosti ovlivÅˆujÃ­ predikce modelu. GlobÃ¡lnÃ­ vysvÄ›tlenÃ­ uvÃ¡dÃ­ hlavnÃ­ vlastnosti, kterÃ© ovlivnily celkovou predikci modelu. LokÃ¡lnÃ­ vysvÄ›tlenÃ­ ukazuje, kterÃ© vlastnosti vedly k predikci modelu pro konkrÃ©tnÃ­ pÅ™Ã­pad. Schopnost hodnotit lokÃ¡lnÃ­ vysvÄ›tlenÃ­ je takÃ© uÅ¾iteÄnÃ¡ pÅ™i ladÄ›nÃ­ nebo auditu konkrÃ©tnÃ­ho pÅ™Ã­padu, aby bylo moÅ¾nÃ© lÃ©pe pochopit a interpretovat, proÄ model uÄinil pÅ™esnou nebo nepÅ™esnou predikci.

![Komponenta DÅ¯leÅ¾itost vlastnostÃ­ na RAI dashboardu](../../../../9-Real-World/2-Debugging-ML-Models/images/9-feature-importance.png)

* GlobÃ¡lnÃ­ vysvÄ›tlenÃ­: NapÅ™Ã­klad, kterÃ© vlastnosti ovlivÅˆujÃ­ celkovÃ© chovÃ¡nÃ­ modelu pro opÄ›tovnÃ© pÅ™ijetÃ­ diabetickÃ½ch pacientÅ¯ do nemocnice?
* LokÃ¡lnÃ­ vysvÄ›tlenÃ­: NapÅ™Ã­klad, proÄ byl diabetickÃ½ pacient starÅ¡Ã­ 60 let s pÅ™edchozÃ­mi hospitalizacemi pÅ™edpovÄ›zen jako opÄ›tovnÄ› pÅ™ijatÃ½ nebo nepÅ™ijatÃ½ do nemocnice bÄ›hem 30 dnÅ¯?

V procesu ladÄ›nÃ­ vÃ½konu modelu napÅ™Ã­Ä rÅ¯znÃ½mi kohortami DÅ¯leÅ¾itost vlastnostÃ­ ukazuje, jakou ÃºroveÅˆ vlivu mÃ¡ vlastnost napÅ™Ã­Ä kohortami. PomÃ¡hÃ¡ odhalit anomÃ¡lie pÅ™i porovnÃ¡vÃ¡nÃ­ ÃºrovnÄ› vlivu vlastnosti na chybnÃ© predikce modelu. Komponenta DÅ¯leÅ¾itost vlastnostÃ­ mÅ¯Å¾e ukÃ¡zat, kterÃ© hodnoty ve vlastnosti pozitivnÄ› nebo negativnÄ› ovlivnily vÃ½sledek modelu. NapÅ™Ã­klad pokud model uÄinil nepÅ™esnou predikci, komponenta vÃ¡m umoÅ¾Åˆuje podrobnÄ›ji prozkoumat a urÄit, kterÃ© vlastnosti nebo hodnoty vlastnostÃ­ ovlivnily predikci. Tato ÃºroveÅˆ detailu pomÃ¡hÃ¡ nejen pÅ™i ladÄ›nÃ­, ale poskytuje transparentnost a odpovÄ›dnost v auditnÃ­ch situacÃ­ch. Nakonec komponenta mÅ¯Å¾e pomoci identifikovat problÃ©my se spravedlnostÃ­. NapÅ™Ã­klad pokud citlivÃ¡ vlastnost, jako je etnicita nebo pohlavÃ­, mÃ¡ vysokÃ½ vliv na predikci modelu, mÅ¯Å¾e to bÃ½t znÃ¡mka rasovÃ© nebo
- **Nad- nebo pod-reprezentace**. MyÅ¡lenka spoÄÃ­vÃ¡ v tom, Å¾e urÄitÃ¡ skupina nenÃ­ zastoupena v urÄitÃ© profesi, a jakÃ¡koli sluÅ¾ba nebo funkce, kterÃ¡ toto nadÃ¡le podporuje, pÅ™ispÃ­vÃ¡ k poÅ¡kozenÃ­.

### Azure RAI dashboard

[Azure RAI dashboard](https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai-dashboard?WT.mc_id=aiml-90525-ruyakubu) je postaven na open-source nÃ¡strojÃ­ch vyvinutÃ½ch pÅ™ednÃ­mi akademickÃ½mi institucemi a organizacemi, vÄetnÄ› Microsoftu. Tyto nÃ¡stroje jsou klÃ­ÄovÃ© pro datovÃ© vÄ›dce a vÃ½vojÃ¡Å™e AI, aby lÃ©pe porozumÄ›li chovÃ¡nÃ­ modelÅ¯, objevovali a zmÃ­rÅˆovali neÅ¾Ã¡doucÃ­ problÃ©my v modelech AI.

- NauÄte se, jak pouÅ¾Ã­vat rÅ¯znÃ© komponenty, pÅ™eÄtenÃ­m dokumentace k RAI dashboardu [docs.](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-responsible-ai-dashboard?WT.mc_id=aiml-90525-ruyakubu)

- PodÃ­vejte se na nÄ›kterÃ© ukÃ¡zkovÃ© [notebooky RAI dashboardu](https://github.com/Azure/RAI-vNext-Preview/tree/main/examples/notebooks) pro ladÄ›nÃ­ odpovÄ›dnÄ›jÅ¡Ã­ch scÃ©nÃ¡Å™Å¯ AI v Azure Machine Learning.

---
## ğŸš€ VÃ½zva

Abychom zabrÃ¡nili zavÃ¡dÄ›nÃ­ statistickÃ½ch nebo datovÃ½ch pÅ™edsudkÅ¯, mÄ›li bychom:

- zajistit rozmanitost zÃ¡zemÃ­ a perspektiv mezi lidmi pracujÃ­cÃ­mi na systÃ©mech
- investovat do datovÃ½ch sad, kterÃ© odrÃ¡Å¾ejÃ­ rozmanitost naÅ¡Ã­ spoleÄnosti
- vyvÃ­jet lepÅ¡Ã­ metody pro detekci a nÃ¡pravu pÅ™edsudkÅ¯, kdyÅ¾ k nim dojde

PÅ™emÃ½Å¡lejte o reÃ¡lnÃ½ch situacÃ­ch, kde je nespravedlnost zÅ™ejmÃ¡ pÅ™i vytvÃ¡Å™enÃ­ a pouÅ¾Ã­vÃ¡nÃ­ modelÅ¯. Co dalÅ¡Ã­ho bychom mÄ›li zvÃ¡Å¾it?

## [KvÃ­z po pÅ™ednÃ¡Å¡ce](https://ff-quizzes.netlify.app/en/ml/)
## PÅ™ehled a samostudium

V tÃ©to lekci jste se nauÄili nÄ›kterÃ© praktickÃ© nÃ¡stroje pro zaÄlenÄ›nÃ­ odpovÄ›dnÃ© AI do strojovÃ©ho uÄenÃ­.

PodÃ­vejte se na tento workshop, abyste se ponoÅ™ili hloubÄ›ji do tÃ©mat:

- Responsible AI Dashboard: JednotnÃ© mÃ­sto pro operacionalizaci RAI v praxi od Besmiry Nushi a Mehrnoosh Sameki

[![Responsible AI Dashboard: JednotnÃ© mÃ­sto pro operacionalizaci RAI v praxi](https://img.youtube.com/vi/f1oaDNl3djg/0.jpg)](https://www.youtube.com/watch?v=f1oaDNl3djg "Responsible AI Dashboard: JednotnÃ© mÃ­sto pro operacionalizaci RAI v praxi")

> ğŸ¥ KliknÄ›te na obrÃ¡zek vÃ½Å¡e pro video: Responsible AI Dashboard: JednotnÃ© mÃ­sto pro operacionalizaci RAI v praxi od Besmiry Nushi a Mehrnoosh Sameki

Odkazujte na nÃ¡sledujÃ­cÃ­ materiÃ¡ly, abyste se dozvÄ›dÄ›li vÃ­ce o odpovÄ›dnÃ© AI a jak vytvÃ¡Å™et dÅ¯vÄ›ryhodnÄ›jÅ¡Ã­ modely:

- Microsoftovy nÃ¡stroje RAI dashboardu pro ladÄ›nÃ­ modelÅ¯ ML: [Responsible AI tools resources](https://aka.ms/rai-dashboard)

- Prozkoumejte sadu nÃ¡strojÅ¯ Responsible AI: [Github](https://github.com/microsoft/responsible-ai-toolbox)

- Microsoftovo centrum zdrojÅ¯ RAI: [Responsible AI Resources â€“ Microsoft AI](https://www.microsoft.com/ai/responsible-ai-resources?activetab=pivot1%3aprimaryr4)

- Microsoftova vÃ½zkumnÃ¡ skupina FATE: [FATE: Fairness, Accountability, Transparency, and Ethics in AI - Microsoft Research](https://www.microsoft.com/research/theme/fate/)

## Ãškol

[Prozkoumejte RAI dashboard](assignment.md)

---

**ProhlÃ¡Å¡enÃ­**:  
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ sluÅ¾by pro automatickÃ½ pÅ™eklad [Co-op Translator](https://github.com/Azure/co-op-translator). AÄkoli se snaÅ¾Ã­me o pÅ™esnost, mÄ›jte na pamÄ›ti, Å¾e automatickÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. PÅ¯vodnÃ­ dokument v jeho pÅ¯vodnÃ­m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za autoritativnÃ­ zdroj. Pro dÅ¯leÅ¾itÃ© informace se doporuÄuje profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. NeodpovÃ­dÃ¡me za Å¾Ã¡dnÃ© nedorozumÄ›nÃ­ nebo nesprÃ¡vnÃ© interpretace vyplÃ½vajÃ­cÃ­ z pouÅ¾itÃ­ tohoto pÅ™ekladu.