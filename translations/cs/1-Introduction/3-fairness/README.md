<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "9a6b702d1437c0467e3c5c28d763dac2",
  "translation_date": "2025-09-05T00:21:33+00:00",
  "source_file": "1-Introduction/3-fairness/README.md",
  "language_code": "cs"
}
-->
# BudovÃ¡nÃ­ Å™eÅ¡enÃ­ strojovÃ©ho uÄenÃ­ s odpovÄ›dnou AI

![ShrnutÃ­ odpovÄ›dnÃ© AI ve strojovÃ©m uÄenÃ­ ve sketchnote](../../../../sketchnotes/ml-fairness.png)
> Sketchnote od [Tomomi Imura](https://www.twitter.com/girlie_mac)

## [KvÃ­z pÅ™ed lekcÃ­](https://ff-quizzes.netlify.app/en/ml/)

## Ãšvod

V tomto kurzu zaÄnete objevovat, jak strojovÃ© uÄenÃ­ ovlivÅˆuje a mÅ¯Å¾e ovlivÅˆovat nÃ¡Å¡ kaÅ¾dodennÃ­ Å¾ivot. JiÅ¾ nynÃ­ jsou systÃ©my a modely zapojeny do kaÅ¾dodennÃ­ch rozhodovacÃ­ch ÃºkolÅ¯, jako jsou diagnÃ³zy ve zdravotnictvÃ­, schvalovÃ¡nÃ­ pÅ¯jÄek nebo odhalovÃ¡nÃ­ podvodÅ¯. Je tedy dÅ¯leÅ¾itÃ©, aby tyto modely fungovaly dobÅ™e a poskytovaly dÅ¯vÄ›ryhodnÃ© vÃ½sledky. StejnÄ› jako u jakÃ©koli softwarovÃ© aplikace, i systÃ©my AI mohou selhat nebo mÃ­t neÅ¾Ã¡doucÃ­ vÃ½sledek. Proto je zÃ¡sadnÃ­ bÃ½t schopen porozumÄ›t a vysvÄ›tlit chovÃ¡nÃ­ modelu AI.

PÅ™edstavte si, co se mÅ¯Å¾e stÃ¡t, kdyÅ¾ data, kterÃ¡ pouÅ¾Ã­vÃ¡te k vytvÃ¡Å™enÃ­ tÄ›chto modelÅ¯, postrÃ¡dajÃ­ urÄitÃ© demografickÃ© Ãºdaje, jako je rasa, pohlavÃ­, politickÃ½ nÃ¡zor, nÃ¡boÅ¾enstvÃ­, nebo naopak nepÅ™imÄ›Å™enÄ› zastupujÃ­ urÄitÃ© demografickÃ© skupiny. Co kdyÅ¾ je vÃ½stup modelu interpretovÃ¡n tak, Å¾e upÅ™ednostÅˆuje urÄitou demografickou skupinu? JakÃ© to mÃ¡ dÅ¯sledky pro aplikaci? A co se stane, kdyÅ¾ model mÃ¡ nepÅ™Ã­znivÃ½ vÃ½sledek a je Å¡kodlivÃ½ pro lidi? Kdo je odpovÄ›dnÃ½ za chovÃ¡nÃ­ systÃ©mu AI? To jsou nÄ›kterÃ© otÃ¡zky, kterÃ© budeme v tomto kurzu zkoumat.

V tÃ©to lekci se nauÄÃ­te:

- ZvÃ½Å¡it povÄ›domÃ­ o dÅ¯leÅ¾itosti spravedlnosti ve strojovÃ©m uÄenÃ­ a o Å¡kodÃ¡ch spojenÃ½ch s nespravedlnostÃ­.
- SeznÃ¡mit se s praxÃ­ zkoumÃ¡nÃ­ odlehlÃ½ch hodnot a neobvyklÃ½ch scÃ©nÃ¡Å™Å¯ pro zajiÅ¡tÄ›nÃ­ spolehlivosti a bezpeÄnosti.
- PorozumÄ›t potÅ™ebÄ› posilovat vÅ¡echny tÃ­m, Å¾e navrhujete inkluzivnÃ­ systÃ©my.
- Prozkoumat, jak je dÅ¯leÅ¾itÃ© chrÃ¡nit soukromÃ­ a bezpeÄnost dat a lidÃ­.
- UvÄ›domit si vÃ½znam pÅ™Ã­stupu â€sklenÄ›nÃ© krabiceâ€œ pro vysvÄ›tlenÃ­ chovÃ¡nÃ­ modelÅ¯ AI.
- BÃ½t si vÄ›domi toho, jak je odpovÄ›dnost klÃ­ÄovÃ¡ pro budovÃ¡nÃ­ dÅ¯vÄ›ry v systÃ©my AI.

## PÅ™edpoklady

Jako pÅ™edpoklad si projdÄ›te â€Principy odpovÄ›dnÃ© AIâ€œ na Learn Path a podÃ­vejte se na nÃ­Å¾e uvedenÃ© video na toto tÃ©ma:

ZjistÄ›te vÃ­ce o odpovÄ›dnÃ© AI prostÅ™ednictvÃ­m tohoto [Learning Path](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77952-leestott)

[![PÅ™Ã­stup Microsoftu k odpovÄ›dnÃ© AI](https://img.youtube.com/vi/dnC8-uUZXSc/0.jpg)](https://youtu.be/dnC8-uUZXSc "PÅ™Ã­stup Microsoftu k odpovÄ›dnÃ© AI")

> ğŸ¥ KliknÄ›te na obrÃ¡zek vÃ½Å¡e pro video: PÅ™Ã­stup Microsoftu k odpovÄ›dnÃ© AI

## Spravedlnost

SystÃ©my AI by mÄ›ly zachÃ¡zet se vÅ¡emi spravedlivÄ› a vyhnout se tomu, aby ovlivÅˆovaly podobnÃ© skupiny lidÃ­ rÅ¯znÃ½mi zpÅ¯soby. NapÅ™Ã­klad kdyÅ¾ systÃ©my AI poskytujÃ­ doporuÄenÃ­ ohlednÄ› lÃ©kaÅ™skÃ© pÃ©Äe, Å¾Ã¡dostÃ­ o pÅ¯jÄky nebo zamÄ›stnÃ¡nÃ­, mÄ›ly by dÃ¡vat stejnÃ¡ doporuÄenÃ­ vÅ¡em s podobnÃ½mi symptomy, finanÄnÃ­mi podmÃ­nkami nebo profesnÃ­mi kvalifikacemi. KaÅ¾dÃ½ z nÃ¡s jako ÄlovÄ›k mÃ¡ vrozenÃ© pÅ™edsudky, kterÃ© ovlivÅˆujÃ­ naÅ¡e rozhodnutÃ­ a jednÃ¡nÃ­. Tyto pÅ™edsudky se mohou projevit v datech, kterÃ¡ pouÅ¾Ã­vÃ¡me k trÃ©novÃ¡nÃ­ systÃ©mÅ¯ AI. TakovÃ¡ manipulace mÅ¯Å¾e nÄ›kdy nastat neÃºmyslnÄ›. ÄŒasto je obtÃ­Å¾nÃ© vÄ›domÄ› rozpoznat, kdy do dat zavÃ¡dÃ­te pÅ™edsudky.

**â€Nespravedlnostâ€œ** zahrnuje negativnÃ­ dopady, nebo â€Å¡kodyâ€œ, na skupinu lidÃ­, napÅ™Ã­klad definovanou podle rasy, pohlavÃ­, vÄ›ku nebo zdravotnÃ­ho postiÅ¾enÃ­. HlavnÃ­ Å¡kody spojenÃ© se spravedlnostÃ­ lze klasifikovat jako:

- **Alokace**, pokud je napÅ™Ã­klad upÅ™ednostÅˆovÃ¡no jedno pohlavÃ­ nebo etnickÃ¡ skupina pÅ™ed jinou.
- **Kvalita sluÅ¾by**. Pokud trÃ©nujete data pro jeden konkrÃ©tnÃ­ scÃ©nÃ¡Å™, ale realita je mnohem sloÅ¾itÄ›jÅ¡Ã­, vede to k Å¡patnÄ› fungujÃ­cÃ­ sluÅ¾bÄ›. NapÅ™Ã­klad dÃ¡vkovaÄ mÃ½dla, kterÃ½ nedokÃ¡zal rozpoznat lidi s tmavou pletÃ­. [Reference](https://gizmodo.com/why-cant-this-soap-dispenser-identify-dark-skin-1797931773)
- **OÄernÄ›nÃ­**. NespravedlivÃ© kritizovÃ¡nÃ­ a oznaÄovÃ¡nÃ­ nÄ›Äeho nebo nÄ›koho. NapÅ™Ã­klad technologie oznaÄovÃ¡nÃ­ obrÃ¡zkÅ¯ nesprÃ¡vnÄ› oznaÄila obrÃ¡zky lidÃ­ s tmavou pletÃ­ jako gorily.
- **Nad- nebo podreprezentace**. MyÅ¡lenka, Å¾e urÄitÃ¡ skupina nenÃ­ vidÄ›t v urÄitÃ© profesi, a jakÃ¡koli sluÅ¾ba nebo funkce, kterÃ¡ to nadÃ¡le podporuje, pÅ™ispÃ­vÃ¡ ke Å¡kodÄ›.
- **Stereotypizace**. SpojovÃ¡nÃ­ urÄitÃ© skupiny s pÅ™edem pÅ™iÅ™azenÃ½mi atributy. NapÅ™Ã­klad systÃ©m pÅ™ekladu mezi angliÄtinou a tureÄtinou mÅ¯Å¾e mÃ­t nepÅ™esnosti kvÅ¯li slovÅ¯m se stereotypnÃ­mi asociacemi k pohlavÃ­.

![pÅ™eklad do tureÄtiny](../../../../1-Introduction/3-fairness/images/gender-bias-translate-en-tr.png)
> pÅ™eklad do tureÄtiny

![pÅ™eklad zpÄ›t do angliÄtiny](../../../../1-Introduction/3-fairness/images/gender-bias-translate-tr-en.png)
> pÅ™eklad zpÄ›t do angliÄtiny

PÅ™i navrhovÃ¡nÃ­ a testovÃ¡nÃ­ systÃ©mÅ¯ AI musÃ­me zajistit, Å¾e AI je spravedlivÃ¡ a nenÃ­ naprogramovÃ¡na tak, aby Äinila zaujatÃ¡ nebo diskriminaÄnÃ­ rozhodnutÃ­, kterÃ¡ jsou zakÃ¡zÃ¡na i lidem. ZajiÅ¡tÄ›nÃ­ spravedlnosti v AI a strojovÃ©m uÄenÃ­ zÅ¯stÃ¡vÃ¡ sloÅ¾itou sociotechnickou vÃ½zvou.

### Spolehlivost a bezpeÄnost

Pro budovÃ¡nÃ­ dÅ¯vÄ›ry musÃ­ bÃ½t systÃ©my AI spolehlivÃ©, bezpeÄnÃ© a konzistentnÃ­ za normÃ¡lnÃ­ch i neoÄekÃ¡vanÃ½ch podmÃ­nek. Je dÅ¯leÅ¾itÃ© vÄ›dÄ›t, jak se systÃ©my AI budou chovat v rÅ¯znÃ½ch situacÃ­ch, zejmÃ©na kdyÅ¾ se jednÃ¡ o odlehlÃ© hodnoty. PÅ™i budovÃ¡nÃ­ Å™eÅ¡enÃ­ AI je tÅ™eba vÄ›novat znaÄnou pozornost tomu, jak zvlÃ¡dnout Å¡irokou Å¡kÃ¡lu okolnostÃ­, se kterÃ½mi se Å™eÅ¡enÃ­ AI mÅ¯Å¾e setkat. NapÅ™Ã­klad samoÅ™Ã­dÃ­cÃ­ auto musÃ­ klÃ¡st bezpeÄnost lidÃ­ na prvnÃ­ mÃ­sto. VÃ½sledkem je, Å¾e AI pohÃ¡nÄ›jÃ­cÃ­ auto musÃ­ zohlednit vÅ¡echny moÅ¾nÃ© scÃ©nÃ¡Å™e, se kterÃ½mi se auto mÅ¯Å¾e setkat, jako je noc, bouÅ™ky nebo snÄ›hovÃ© bouÅ™e, dÄ›ti bÄ›Å¾Ã­cÃ­ pÅ™es ulici, domÃ¡cÃ­ mazlÃ­Äci, silniÄnÃ­ stavby atd. Jak dobÅ™e systÃ©m AI dokÃ¡Å¾e spolehlivÄ› a bezpeÄnÄ› zvlÃ¡dnout Å¡irokou Å¡kÃ¡lu podmÃ­nek, odrÃ¡Å¾Ã­ ÃºroveÅˆ pÅ™edvÃ­davosti, kterou datovÃ½ vÄ›dec nebo vÃ½vojÃ¡Å™ AI zohlednil pÅ™i nÃ¡vrhu nebo testovÃ¡nÃ­ systÃ©mu.

> [ğŸ¥ KliknÄ›te zde pro video: ](https://www.microsoft.com/videoplayer/embed/RE4vvIl)

### Inkluzivita

SystÃ©my AI by mÄ›ly bÃ½t navrÅ¾eny tak, aby zapojily a posÃ­lily vÅ¡echny. PÅ™i navrhovÃ¡nÃ­ a implementaci systÃ©mÅ¯ AI datovÃ­ vÄ›dci a vÃ½vojÃ¡Å™i AI identifikujÃ­ a Å™eÅ¡Ã­ potenciÃ¡lnÃ­ bariÃ©ry v systÃ©mu, kterÃ© by mohly neÃºmyslnÄ› vylouÄit lidi. NapÅ™Ã­klad na svÄ›tÄ› je 1 miliarda lidÃ­ s postiÅ¾enÃ­m. DÃ­ky pokroku v AI mohou snadnÄ›ji pÅ™istupovat k Å¡irokÃ© Å¡kÃ¡le informacÃ­ a pÅ™Ã­leÅ¾itostÃ­ ve svÃ©m kaÅ¾dodennÃ­m Å¾ivotÄ›. Å˜eÅ¡enÃ­m bariÃ©r vznikajÃ­ pÅ™Ã­leÅ¾itosti k inovacÃ­m a vÃ½voji produktÅ¯ AI s lepÅ¡Ã­mi zkuÅ¡enostmi, kterÃ© pÅ™inÃ¡Å¡ejÃ­ uÅ¾itek vÅ¡em.

> [ğŸ¥ KliknÄ›te zde pro video: inkluzivita v AI](https://www.microsoft.com/videoplayer/embed/RE4vl9v)

### BezpeÄnost a soukromÃ­

SystÃ©my AI by mÄ›ly bÃ½t bezpeÄnÃ© a respektovat soukromÃ­ lidÃ­. LidÃ© majÃ­ menÅ¡Ã­ dÅ¯vÄ›ru v systÃ©my, kterÃ© ohroÅ¾ujÃ­ jejich soukromÃ­, informace nebo Å¾ivoty. PÅ™i trÃ©novÃ¡nÃ­ modelÅ¯ strojovÃ©ho uÄenÃ­ se spolÃ©hÃ¡me na data, abychom dosÃ¡hli co nejlepÅ¡Ã­ch vÃ½sledkÅ¯. PÅ™i tom je tÅ™eba zohlednit pÅ¯vod dat a jejich integritu. NapÅ™Ã­klad byla data poskytnuta uÅ¾ivateli nebo byla veÅ™ejnÄ› dostupnÃ¡? DÃ¡le je pÅ™i prÃ¡ci s daty zÃ¡sadnÃ­ vyvÃ­jet systÃ©my AI, kterÃ© dokÃ¡Å¾ou chrÃ¡nit dÅ¯vÄ›rnÃ© informace a odolÃ¡vat ÃºtokÅ¯m. Jak se AI stÃ¡vÃ¡ rozÅ¡Ã­Å™enÄ›jÅ¡Ã­, ochrana soukromÃ­ a zabezpeÄenÃ­ dÅ¯leÅ¾itÃ½ch osobnÃ­ch a obchodnÃ­ch informacÃ­ se stÃ¡vÃ¡ stÃ¡le dÅ¯leÅ¾itÄ›jÅ¡Ã­ a sloÅ¾itÄ›jÅ¡Ã­. OtÃ¡zky soukromÃ­ a bezpeÄnosti dat vyÅ¾adujÃ­ zvlÃ¡Å¡tnÃ­ pozornost u AI, protoÅ¾e pÅ™Ã­stup k datÅ¯m je nezbytnÃ½ pro to, aby systÃ©my AI mohly Äinit pÅ™esnÃ© a informovanÃ© pÅ™edpovÄ›di a rozhodnutÃ­ o lidech.

> [ğŸ¥ KliknÄ›te zde pro video: bezpeÄnost v AI](https://www.microsoft.com/videoplayer/embed/RE4voJF)

- Jako prÅ¯mysl jsme dosÃ¡hli vÃ½znamnÃ©ho pokroku v oblasti soukromÃ­ a bezpeÄnosti, vÃ½raznÄ› podpoÅ™enÃ©ho regulacemi, jako je GDPR (ObecnÃ© naÅ™Ã­zenÃ­ o ochranÄ› osobnÃ­ch ÃºdajÅ¯).
- PÅ™esto u systÃ©mÅ¯ AI musÃ­me uznat napÄ›tÃ­ mezi potÅ™ebou vÃ­ce osobnÃ­ch dat pro zlepÅ¡enÃ­ personalizace a efektivity systÃ©mÅ¯ â€“ a ochranou soukromÃ­.
- StejnÄ› jako pÅ™i vzniku propojenÃ½ch poÄÃ­taÄÅ¯ s internetem, vidÃ­me takÃ© obrovskÃ½ nÃ¡rÅ¯st poÄtu bezpeÄnostnÃ­ch problÃ©mÅ¯ souvisejÃ­cÃ­ch s AI.
- ZÃ¡roveÅˆ jsme vidÄ›li, Å¾e AI je vyuÅ¾Ã­vÃ¡na ke zlepÅ¡enÃ­ bezpeÄnosti. NapÅ™Ã­klad vÄ›tÅ¡ina modernÃ­ch antivirovÃ½ch skenerÅ¯ je dnes pohÃ¡nÄ›na heuristikou AI.
- MusÃ­me zajistit, aby naÅ¡e procesy datovÃ© vÄ›dy harmonicky zapadaly do nejnovÄ›jÅ¡Ã­ch postupÅ¯ v oblasti soukromÃ­ a bezpeÄnosti.

### Transparentnost

SystÃ©my AI by mÄ›ly bÃ½t srozumitelnÃ©. KlÃ­Äovou souÄÃ¡stÃ­ transparentnosti je vysvÄ›tlenÃ­ chovÃ¡nÃ­ systÃ©mÅ¯ AI a jejich komponent. ZlepÅ¡enÃ­ porozumÄ›nÃ­ systÃ©mÅ¯m AI vyÅ¾aduje, aby zainteresovanÃ© strany pochopily, jak a proÄ fungujÃ­, aby mohly identifikovat potenciÃ¡lnÃ­ problÃ©my s vÃ½konem, obavy o bezpeÄnost a soukromÃ­, pÅ™edsudky, vyluÄujÃ­cÃ­ praktiky nebo nechtÄ›nÃ© vÃ½sledky. VÄ›Å™Ã­me takÃ©, Å¾e ti, kdo pouÅ¾Ã­vajÃ­ systÃ©my AI, by mÄ›li bÃ½t upÅ™Ã­mnÃ­ a otevÅ™enÃ­ ohlednÄ› toho, kdy, proÄ a jak se rozhodnou je nasadit. StejnÄ› tak o omezenÃ­ch systÃ©mÅ¯, kterÃ© pouÅ¾Ã­vajÃ­. NapÅ™Ã­klad pokud banka pouÅ¾Ã­vÃ¡ systÃ©m AI k podpoÅ™e svÃ½ch rozhodnutÃ­ o spotÅ™ebitelskÃ½ch pÅ¯jÄkÃ¡ch, je dÅ¯leÅ¾itÃ© zkoumat vÃ½sledky a pochopit, kterÃ¡ data ovlivÅˆujÃ­ doporuÄenÃ­ systÃ©mu. VlÃ¡dy zaÄÃ­najÃ­ regulovat AI napÅ™Ã­Ä odvÄ›tvÃ­mi, takÅ¾e datovÃ­ vÄ›dci a organizace musÃ­ vysvÄ›tlit, zda systÃ©m AI splÅˆuje regulaÄnÃ­ poÅ¾adavky, zejmÃ©na kdyÅ¾ dojde k neÅ¾Ã¡doucÃ­mu vÃ½sledku.

> [ğŸ¥ KliknÄ›te zde pro video: transparentnost v AI](https://www.microsoft.com/videoplayer/embed/RE4voJF)

- ProtoÅ¾e systÃ©my AI jsou tak sloÅ¾itÃ©, je tÄ›Å¾kÃ© pochopit, jak fungujÃ­ a interpretovat vÃ½sledky.
- Tento nedostatek porozumÄ›nÃ­ ovlivÅˆuje zpÅ¯sob, jakÃ½m jsou tyto systÃ©my spravovÃ¡ny, provozovÃ¡ny a dokumentovÃ¡ny.
- Tento nedostatek porozumÄ›nÃ­ pÅ™edevÅ¡Ã­m ovlivÅˆuje rozhodnutÃ­ uÄinÄ›nÃ¡ na zÃ¡kladÄ› vÃ½sledkÅ¯, kterÃ© tyto systÃ©my produkujÃ­.

### OdpovÄ›dnost

LidÃ©, kteÅ™Ã­ navrhujÃ­ a nasazujÃ­ systÃ©my AI, musÃ­ bÃ½t odpovÄ›dnÃ­ za to, jak jejich systÃ©my fungujÃ­. PotÅ™eba odpovÄ›dnosti je obzvlÃ¡Å¡tÄ› dÅ¯leÅ¾itÃ¡ u technologiÃ­ citlivÃ©ho pouÅ¾itÃ­, jako je rozpoznÃ¡vÃ¡nÃ­ obliÄeje. V poslednÃ­ dobÄ› roste poptÃ¡vka po technologii rozpoznÃ¡vÃ¡nÃ­ obliÄeje, zejmÃ©na ze strany orgÃ¡nÅ¯ ÄinnÃ½ch v trestnÃ­m Å™Ã­zenÃ­, kterÃ© vidÃ­ potenciÃ¡l tÃ©to technologie napÅ™Ã­klad pÅ™i hledÃ¡nÃ­ pohÅ™eÅ¡ovanÃ½ch dÄ›tÃ­. Tyto technologie vÅ¡ak mohou bÃ½t potenciÃ¡lnÄ› vyuÅ¾Ã­vÃ¡ny vlÃ¡dou k ohroÅ¾enÃ­ zÃ¡kladnÃ­ch svobod obÄanÅ¯, napÅ™Ã­klad umoÅ¾nÄ›nÃ­m nepÅ™etrÅ¾itÃ©ho sledovÃ¡nÃ­ konkrÃ©tnÃ­ch jednotlivcÅ¯. Proto musÃ­ bÃ½t datovÃ­ vÄ›dci a organizace odpovÄ›dnÃ­ za to, jak jejich systÃ©m AI ovlivÅˆuje jednotlivce nebo spoleÄnost.

[![PÅ™ednÃ­ vÃ½zkumnÃ­k AI varuje pÅ™ed masovÃ½m sledovÃ¡nÃ­m prostÅ™ednictvÃ­m rozpoznÃ¡vÃ¡nÃ­ obliÄeje](../../../../1-Introduction/3-fairness/images/accountability.png)](https://www.youtube.com/watch?v=Wldt8P5V6D0 "PÅ™Ã­stup Microsoftu k odpovÄ›dnÃ© AI")

> ğŸ¥ KliknÄ›te na obrÃ¡zek vÃ½Å¡e pro video: VarovÃ¡nÃ­ pÅ™ed masovÃ½m sledovÃ¡nÃ­m prostÅ™ednictvÃ­m rozpoznÃ¡vÃ¡nÃ­ obliÄeje

Nakonec jednou z nejvÄ›tÅ¡Ã­ch otÃ¡zek pro naÅ¡i generaci, jako prvnÃ­ generaci, kterÃ¡ pÅ™inÃ¡Å¡Ã­ AI do spoleÄnosti, je, jak zajistit, aby poÄÃ­taÄe zÅ¯staly odpovÄ›dnÃ© vÅ¯Äi lidem a jak zajistit, aby lidÃ©, kteÅ™Ã­ poÄÃ­taÄe navrhujÃ­, zÅ¯stali odpovÄ›dnÃ­ vÅ¯Äi vÅ¡em ostatnÃ­m.

## PosouzenÃ­ dopadu

PÅ™ed trÃ©novÃ¡nÃ­m modelu strojovÃ©ho uÄenÃ­ je dÅ¯leÅ¾itÃ© provÃ©st posouzenÃ­ dopadu, abyste pochopili ÃºÄel systÃ©mu AI; jakÃ© je zamÃ½Å¡lenÃ© pouÅ¾itÃ­; kde bude nasazen; a kdo bude se systÃ©mem interagovat. Tyto informace jsou uÅ¾iteÄnÃ© pro recenzenty nebo testery, kteÅ™Ã­ hodnotÃ­ systÃ©m, aby vÄ›dÄ›li, jakÃ© faktory je tÅ™eba vzÃ­t v Ãºvahu pÅ™i identifikaci potenciÃ¡lnÃ­ch rizik a oÄekÃ¡vanÃ½ch dÅ¯sledkÅ¯.

NÃ¡sledujÃ­cÃ­ oblasti jsou klÃ­ÄovÃ© pÅ™i provÃ¡dÄ›nÃ­ posouzenÃ­ dopadu:

* **NepÅ™Ã­znivÃ½ dopad na jednotlivce**. BÃ½t si vÄ›dom jakÃ½chkoli omezenÃ­ nebo poÅ¾adavkÅ¯, nepodporovanÃ©ho pouÅ¾itÃ­ nebo znÃ¡mÃ½ch omezenÃ­, kterÃ¡ brÃ¡nÃ­ vÃ½konu systÃ©mu, je zÃ¡sadnÃ­ pro zajiÅ¡tÄ›nÃ­ toho, Å¾e systÃ©m nebude pouÅ¾Ã­vÃ¡n zpÅ¯sobem, kterÃ½ by mohl zpÅ¯sobit Å¡kodu jednotlivcÅ¯m.
* **PoÅ¾adavky na data**. ZÃ­skÃ¡nÃ­ porozumÄ›nÃ­ tomu, jak a kde systÃ©m bude pouÅ¾Ã­vat data, umoÅ¾Åˆuje recenzentÅ¯m prozkoumat jakÃ©koli poÅ¾adavky na data, na kterÃ© byste mÄ›li bÃ½t ohleduplnÃ­ (napÅ™. GDPR nebo HIPPA regulace dat). DÃ¡le je tÅ™eba zkoumat, zda je zdroj nebo mnoÅ¾stvÃ­ dat dostateÄnÃ© pro trÃ©novÃ¡nÃ­.
* **ShrnutÃ­ dopadu**. Sestavte seznam potenciÃ¡lnÃ­ch Å¡kod, kterÃ© by mohly vzniknout pÅ™i pouÅ¾Ã­vÃ¡nÃ­ systÃ©mu. BÄ›hem Å¾ivotnÃ­ho cyklu ML zkontrolujte, zda byly identifikovanÃ© problÃ©my zmÃ­rnÄ›ny nebo vyÅ™eÅ¡eny.
* **PlatnÃ© cÃ­le** pro kaÅ¾dou ze Å¡esti zÃ¡kladnÃ­ch zÃ¡sad. PosuÄte, zda byly cÃ­le z kaÅ¾dÃ© zÃ¡sady splnÄ›ny a zda existujÃ­ nÄ›jakÃ© mezery.

## LadÄ›nÃ­ s odpovÄ›dnou AI

PodobnÄ› jako ladÄ›nÃ­ softwarovÃ© aplikace je ladÄ›nÃ­ systÃ©mu AI nezbytnÃ½m procesem identifikace a Å™eÅ¡enÃ­ problÃ©mÅ¯ v systÃ©mu. Existuje mnoho faktorÅ¯, kterÃ© mohou ovlivnit, Å¾e model nefunguje podle oÄekÃ¡vÃ¡nÃ­ nebo odpovÄ›dnÄ›. VÄ›tÅ¡ina tradiÄnÃ­ch metrik vÃ½konu modelu jsou kvantitativnÃ­ agregÃ¡ty vÃ½konu modelu, kterÃ© nejsou dostateÄnÃ© k analÃ½ze, jak model poruÅ¡uje zÃ¡sady odpovÄ›dnÃ© AI. NavÃ­c je model strojovÃ©ho uÄenÃ­ Äernou skÅ™Ã­Åˆkou, coÅ¾ ztÄ›Å¾uje pochopenÃ­, co ovlivÅˆuje jeho vÃ½stup, nebo poskytovÃ¡nÃ­ vysvÄ›tlenÃ­, kdyÅ¾ udÄ›lÃ¡ chybu. PozdÄ›ji v tomto kurzu se nauÄÃ­me, jak pouÅ¾Ã­vat dashboard odpovÄ›dnÃ© AI k ladÄ›nÃ­ systÃ©mÅ¯ AI. Dashboard poskytuje komplexnÃ­ nÃ¡stroj pro datovÃ© vÄ›dce a vÃ½vojÃ¡Å™e AI k provÃ¡dÄ›nÃ­:

* **AnalÃ½zy chyb**. Identifikace rozloÅ¾enÃ­ chyb modelu, kterÃ© mohou ovlivnit spravedlnost nebo spolehlivost systÃ©mu.
* **PÅ™ehledu modelu**. ObjevovÃ¡nÃ­, kde jsou rozdÃ­ly ve vÃ½konu modelu napÅ™Ã­Ä datovÃ½mi kohortami.
* **AnalÃ½zy dat**. PorozumÄ›nÃ­ rozloÅ¾enÃ­ dat a identifikace jakÃ©hokoli potenciÃ¡lnÃ­ho pÅ™edsudku v datech, kterÃ½ by mohl vÃ©st k problÃ©mÅ¯m se spravedlnostÃ­
PodÃ­vejte se na tento workshop, abyste se ponoÅ™ili hloubÄ›ji do tÃ©mat:

- V hledÃ¡nÃ­ odpovÄ›dnÃ© AI: PÅ™enesenÃ­ principÅ¯ do praxe od Besmiry Nushi, Mehrnoosh Sameki a Amita Sharmy

[![Responsible AI Toolbox: Open-source rÃ¡mec pro budovÃ¡nÃ­ odpovÄ›dnÃ© AI](https://img.youtube.com/vi/tGgJCrA-MZU/0.jpg)](https://www.youtube.com/watch?v=tGgJCrA-MZU "RAI Toolbox: Open-source rÃ¡mec pro budovÃ¡nÃ­ odpovÄ›dnÃ© AI")

> ğŸ¥ KliknÄ›te na obrÃ¡zek vÃ½Å¡e pro video: RAI Toolbox: Open-source rÃ¡mec pro budovÃ¡nÃ­ odpovÄ›dnÃ© AI od Besmiry Nushi, Mehrnoosh Sameki a Amita Sharmy

TakÃ© si pÅ™eÄtÄ›te:

- MicrosoftÅ¯v RAI zdrojovÃ½ centrum: [Responsible AI Resources â€“ Microsoft AI](https://www.microsoft.com/ai/responsible-ai-resources?activetab=pivot1%3aprimaryr4)

- Microsoftova vÃ½zkumnÃ¡ skupina FATE: [FATE: Fairness, Accountability, Transparency, and Ethics in AI - Microsoft Research](https://www.microsoft.com/research/theme/fate/)

RAI Toolbox:

- [GitHub repozitÃ¡Å™ Responsible AI Toolbox](https://github.com/microsoft/responsible-ai-toolbox)

PÅ™eÄtÄ›te si o nÃ¡strojÃ­ch Azure Machine Learning pro zajiÅ¡tÄ›nÃ­ spravedlnosti:

- [Azure Machine Learning](https://docs.microsoft.com/azure/machine-learning/concept-fairness-ml?WT.mc_id=academic-77952-leestott)

## Ãškol

[Prozkoumejte RAI Toolbox](assignment.md)

---

**ProhlÃ¡Å¡enÃ­**:  
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ sluÅ¾by pro automatickÃ½ pÅ™eklad [Co-op Translator](https://github.com/Azure/co-op-translator). AÄkoli se snaÅ¾Ã­me o pÅ™esnost, mÄ›jte na pamÄ›ti, Å¾e automatickÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. PÅ¯vodnÃ­ dokument v jeho pÅ¯vodnÃ­m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za autoritativnÃ­ zdroj. Pro dÅ¯leÅ¾itÃ© informace doporuÄujeme profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. NeodpovÃ­dÃ¡me za Å¾Ã¡dnÃ¡ nedorozumÄ›nÃ­ nebo nesprÃ¡vnÃ© interpretace vyplÃ½vajÃ­cÃ­ z pouÅ¾itÃ­ tohoto pÅ™ekladu.