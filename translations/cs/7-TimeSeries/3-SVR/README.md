<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "482bccabe1df958496ea71a3667995cd",
  "translation_date": "2025-09-04T23:54:21+00:00",
  "source_file": "7-TimeSeries/3-SVR/README.md",
  "language_code": "cs"
}
-->
# PÅ™edpovÄ›Ä ÄasovÃ½ch Å™ad pomocÃ­ Support Vector Regressor

V pÅ™edchozÃ­ lekci jste se nauÄili pouÅ¾Ã­vat model ARIMA k pÅ™edpovÄ›di ÄasovÃ½ch Å™ad. NynÃ­ se podÃ­vÃ¡me na model Support Vector Regressor, coÅ¾ je regresnÃ­ model pouÅ¾Ã­vanÃ½ k pÅ™edpovÄ›di spojitÃ½ch dat.

## [KvÃ­z pÅ™ed lekcÃ­](https://ff-quizzes.netlify.app/en/ml/) 

## Ãšvod

V tÃ©to lekci objevÃ­te specifickÃ½ zpÅ¯sob, jak vytvÃ¡Å™et modely pomocÃ­ [**SVM**: **S**upport **V**ector **M**achine](https://en.wikipedia.org/wiki/Support-vector_machine) pro regresi, tedy **SVR: Support Vector Regressor**. 

### SVR v kontextu ÄasovÃ½ch Å™ad [^1]

NeÅ¾ pochopÃ­te vÃ½znam SVR pÅ™i pÅ™edpovÄ›di ÄasovÃ½ch Å™ad, je dÅ¯leÅ¾itÃ© se seznÃ¡mit s nÃ¡sledujÃ­cÃ­mi koncepty:

- **Regrese:** Technika uÄenÃ­ s uÄitelem, kterÃ¡ pÅ™edpovÃ­dÃ¡ spojitÃ© hodnoty na zÃ¡kladÄ› danÃ© sady vstupÅ¯. CÃ­lem je najÃ­t kÅ™ivku (nebo pÅ™Ã­mku) v prostoru vlastnostÃ­, kterÃ¡ obsahuje maximÃ¡lnÃ­ poÄet datovÃ½ch bodÅ¯. [KliknÄ›te zde](https://en.wikipedia.org/wiki/Regression_analysis) pro vÃ­ce informacÃ­.
- **Support Vector Machine (SVM):** Typ modelu strojovÃ©ho uÄenÃ­ s uÄitelem pouÅ¾Ã­vanÃ½ pro klasifikaci, regresi a detekci odlehlÃ½ch hodnot. Model je hyperrovina v prostoru vlastnostÃ­, kterÃ¡ v pÅ™Ã­padÄ› klasifikace funguje jako hranice a v pÅ™Ã­padÄ› regrese jako nejlepÅ¡Ã­ pÅ™Ã­mka. V SVM se obvykle pouÅ¾Ã­vÃ¡ funkce jÃ¡dra k transformaci datovÃ© sady do prostoru s vyÅ¡Å¡Ã­m poÄtem dimenzÃ­, aby byly snadnÄ›ji oddÄ›litelnÃ©. [KliknÄ›te zde](https://en.wikipedia.org/wiki/Support-vector_machine) pro vÃ­ce informacÃ­ o SVM.
- **Support Vector Regressor (SVR):** Typ SVM, kterÃ½ hledÃ¡ nejlepÅ¡Ã­ pÅ™Ã­mku (v pÅ™Ã­padÄ› SVM hyperrovinu), kterÃ¡ obsahuje maximÃ¡lnÃ­ poÄet datovÃ½ch bodÅ¯.

### ProÄ SVR? [^1]

V minulÃ© lekci jste se nauÄili o ARIMA, coÅ¾ je velmi ÃºspÄ›Å¡nÃ¡ statistickÃ¡ lineÃ¡rnÃ­ metoda pro pÅ™edpovÄ›Ä ÄasovÃ½ch Å™ad. NicmÃ©nÄ› v mnoha pÅ™Ã­padech majÃ­ ÄasovÃ© Å™ady *nelinearitu*, kterou nelze mapovat pomocÃ­ lineÃ¡rnÃ­ch modelÅ¯. V takovÃ½ch pÅ™Ã­padech schopnost SVM zohlednit nelinearitu dat pÅ™i regresnÃ­ch ÃºlohÃ¡ch ÄinÃ­ SVR ÃºspÄ›Å¡nÃ½m pÅ™i pÅ™edpovÄ›di ÄasovÃ½ch Å™ad.

## CviÄenÃ­ - vytvoÅ™enÃ­ modelu SVR

PrvnÃ­ kroky pÅ™Ã­pravy dat jsou stejnÃ© jako v pÅ™edchozÃ­ lekci o [ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA). 

OtevÅ™ete sloÅ¾ku [_/working_](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/3-SVR/working) v tÃ©to lekci a najdÄ›te soubor [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/7-TimeSeries/3-SVR/working/notebook.ipynb). [^2]

1. SpusÅ¥te notebook a importujte potÅ™ebnÃ© knihovny: [^2]

   ```python
   import sys
   sys.path.append('../../')
   ```

   ```python
   import os
   import warnings
   import matplotlib.pyplot as plt
   import numpy as np
   import pandas as pd
   import datetime as dt
   import math
   
   from sklearn.svm import SVR
   from sklearn.preprocessing import MinMaxScaler
   from common.utils import load_data, mape
   ```

2. NaÄtÄ›te data ze souboru `/data/energy.csv` do Pandas dataframe a podÃ­vejte se na nÄ›: [^2]

   ```python
   energy = load_data('../../data')[['load']]
   ```

3. Vykreslete vÅ¡echna dostupnÃ¡ data o energii od ledna 2012 do prosince 2014: [^2]

   ```python
   energy.plot(y='load', subplots=True, figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![full data](../../../../7-TimeSeries/3-SVR/images/full-data.png)

   NynÃ­ vytvoÅ™Ã­me model SVR.

### VytvoÅ™enÃ­ trÃ©novacÃ­ch a testovacÃ­ch datovÃ½ch sad

NynÃ­ mÃ¡te data naÄtenÃ¡, takÅ¾e je mÅ¯Å¾ete rozdÄ›lit na trÃ©novacÃ­ a testovacÃ­ sady. PotÃ© data upravÃ­te tak, aby vytvoÅ™ila datovou sadu zaloÅ¾enou na ÄasovÃ½ch krocÃ­ch, coÅ¾ bude potÅ™eba pro SVR. Model budete trÃ©novat na trÃ©novacÃ­ sadÄ›. Po dokonÄenÃ­ trÃ©novÃ¡nÃ­ modelu vyhodnotÃ­te jeho pÅ™esnost na trÃ©novacÃ­ sadÄ›, testovacÃ­ sadÄ› a potÃ© na celÃ© datovÃ© sadÄ›, abyste vidÄ›li celkovÃ½ vÃ½kon. MusÃ­te zajistit, aby testovacÃ­ sada pokrÃ½vala pozdÄ›jÅ¡Ã­ obdobÃ­ neÅ¾ trÃ©novacÃ­ sada, aby model nezÃ­skal informace z budoucÃ­ch ÄasovÃ½ch obdobÃ­ [^2] (situace znÃ¡mÃ¡ jako *pÅ™euÄenÃ­*).

1. VyÄleÅˆte dvoumÄ›sÃ­ÄnÃ­ obdobÃ­ od 1. zÃ¡Å™Ã­ do 31. Å™Ã­jna 2014 pro trÃ©novacÃ­ sadu. TestovacÃ­ sada bude zahrnovat dvoumÄ›sÃ­ÄnÃ­ obdobÃ­ od 1. listopadu do 31. prosince 2014: [^2]

   ```python
   train_start_dt = '2014-11-01 00:00:00'
   test_start_dt = '2014-12-30 00:00:00'
   ```

2. Vizualizujte rozdÃ­ly: [^2]

   ```python
   energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)][['load']].rename(columns={'load':'train'}) \
       .join(energy[test_start_dt:][['load']].rename(columns={'load':'test'}), how='outer') \
       .plot(y=['train', 'test'], figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![training and testing data](../../../../7-TimeSeries/3-SVR/images/train-test.png)

### PÅ™Ã­prava dat pro trÃ©novÃ¡nÃ­

NynÃ­ je potÅ™eba pÅ™ipravit data pro trÃ©novÃ¡nÃ­ provedenÃ­m filtrovÃ¡nÃ­ a Å¡kÃ¡lovÃ¡nÃ­ dat. Filtrovat budete datovou sadu tak, aby zahrnovala pouze potÅ™ebnÃ¡ ÄasovÃ¡ obdobÃ­ a sloupce, a Å¡kÃ¡lovat, aby byla data projektovÃ¡na do intervalu 0,1.

1. Filtrovat pÅ¯vodnÃ­ datovou sadu tak, aby zahrnovala pouze zmÃ­nÄ›nÃ¡ ÄasovÃ¡ obdobÃ­ na sadu a pouze potÅ™ebnÃ½ sloupec 'load' plus datum: [^2]

   ```python
   train = energy.copy()[(energy.index >= train_start_dt) & (energy.index < test_start_dt)][['load']]
   test = energy.copy()[energy.index >= test_start_dt][['load']]
   
   print('Training data shape: ', train.shape)
   print('Test data shape: ', test.shape)
   ```

   ```output
   Training data shape:  (1416, 1)
   Test data shape:  (48, 1)
   ```
   
2. Å kÃ¡lovat trÃ©novacÃ­ data do rozsahu (0, 1): [^2]

   ```python
   scaler = MinMaxScaler()
   train['load'] = scaler.fit_transform(train)
   ```
   
4. NynÃ­ Å¡kÃ¡lujte testovacÃ­ data: [^2]

   ```python
   test['load'] = scaler.transform(test)
   ```

### VytvoÅ™enÃ­ dat s ÄasovÃ½mi kroky [^1]

Pro SVR transformujete vstupnÃ­ data do formy `[batch, timesteps]`. TakÅ¾e upravÃ­te existujÃ­cÃ­ `train_data` a `test_data` tak, aby existovala novÃ¡ dimenze, kterÃ¡ odkazuje na ÄasovÃ© kroky.

```python
# Converting to numpy arrays
train_data = train.values
test_data = test.values
```

Pro tento pÅ™Ã­klad bereme `timesteps = 5`. Vstupy do modelu jsou tedy data pro prvnÃ­ 4 ÄasovÃ© kroky a vÃ½stup budou data pro 5. ÄasovÃ½ krok.

```python
timesteps=5
```

Konverze trÃ©novacÃ­ch dat na 2D tensor pomocÃ­ vnoÅ™enÃ© list comprehension:

```python
train_data_timesteps=np.array([[j for j in train_data[i:i+timesteps]] for i in range(0,len(train_data)-timesteps+1)])[:,:,0]
train_data_timesteps.shape
```

```output
(1412, 5)
```

Konverze testovacÃ­ch dat na 2D tensor:

```python
test_data_timesteps=np.array([[j for j in test_data[i:i+timesteps]] for i in range(0,len(test_data)-timesteps+1)])[:,:,0]
test_data_timesteps.shape
```

```output
(44, 5)
```

VÃ½bÄ›r vstupÅ¯ a vÃ½stupÅ¯ z trÃ©novacÃ­ch a testovacÃ­ch dat:

```python
x_train, y_train = train_data_timesteps[:,:timesteps-1],train_data_timesteps[:,[timesteps-1]]
x_test, y_test = test_data_timesteps[:,:timesteps-1],test_data_timesteps[:,[timesteps-1]]

print(x_train.shape, y_train.shape)
print(x_test.shape, y_test.shape)
```

```output
(1412, 4) (1412, 1)
(44, 4) (44, 1)
```

### Implementace SVR [^1]

NynÃ­ je Äas implementovat SVR. Pro vÃ­ce informacÃ­ o tÃ©to implementaci mÅ¯Å¾ete navÅ¡tÃ­vit [tuto dokumentaci](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html). Pro naÅ¡i implementaci postupujeme podle tÄ›chto krokÅ¯:

  1. Definujte model volÃ¡nÃ­m `SVR()` a pÅ™edÃ¡nÃ­m hyperparametrÅ¯ modelu: kernel, gamma, c a epsilon
  2. PÅ™ipravte model pro trÃ©novacÃ­ data volÃ¡nÃ­m funkce `fit()`
  3. ProveÄte pÅ™edpovÄ›di volÃ¡nÃ­m funkce `predict()`

NynÃ­ vytvoÅ™Ã­me model SVR. PouÅ¾ijeme [RBF kernel](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel) a nastavÃ­me hyperparametry gamma, C a epsilon na hodnoty 0.5, 10 a 0.05.

```python
model = SVR(kernel='rbf',gamma=0.5, C=10, epsilon = 0.05)
```

#### TrÃ©novÃ¡nÃ­ modelu na trÃ©novacÃ­ch datech [^1]

```python
model.fit(x_train, y_train[:,0])
```

```output
SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.05, gamma=0.5,
    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)
```

#### PÅ™edpovÄ›di modelu [^1]

```python
y_train_pred = model.predict(x_train).reshape(-1,1)
y_test_pred = model.predict(x_test).reshape(-1,1)

print(y_train_pred.shape, y_test_pred.shape)
```

```output
(1412, 1) (44, 1)
```

Postavili jste svÅ¯j SVR! NynÃ­ je potÅ™eba jej vyhodnotit.

### VyhodnocenÃ­ modelu [^1]

Pro vyhodnocenÃ­ nejprve Å¡kÃ¡lujeme data zpÄ›t na pÅ¯vodnÃ­ mÄ›Å™Ã­tko. PotÃ©, abychom zkontrolovali vÃ½kon, vykreslÃ­me pÅ¯vodnÃ­ a pÅ™edpovÄ›zenÃ½ graf ÄasovÃ½ch Å™ad a takÃ© vytiskneme vÃ½sledek MAPE.

Å kÃ¡lovÃ¡nÃ­ pÅ™edpovÄ›zenÃ½ch a pÅ¯vodnÃ­ch vÃ½stupÅ¯:

```python
# Scaling the predictions
y_train_pred = scaler.inverse_transform(y_train_pred)
y_test_pred = scaler.inverse_transform(y_test_pred)

print(len(y_train_pred), len(y_test_pred))
```

```python
# Scaling the original values
y_train = scaler.inverse_transform(y_train)
y_test = scaler.inverse_transform(y_test)

print(len(y_train), len(y_test))
```

#### Kontrola vÃ½konu modelu na trÃ©novacÃ­ch a testovacÃ­ch datech [^1]

Z datovÃ© sady extrahujeme ÄasovÃ© znaÄky, kterÃ© zobrazÃ­me na ose x naÅ¡eho grafu. VÅ¡imnÄ›te si, Å¾e pouÅ¾Ã­vÃ¡me prvnÃ­ch ```timesteps-1``` hodnot jako vstup pro prvnÃ­ vÃ½stup, takÅ¾e ÄasovÃ© znaÄky pro vÃ½stup zaÄnou aÅ¾ potÃ©.

```python
train_timestamps = energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)].index[timesteps-1:]
test_timestamps = energy[test_start_dt:].index[timesteps-1:]

print(len(train_timestamps), len(test_timestamps))
```

```output
1412 44
```

VykreslenÃ­ pÅ™edpovÄ›dÃ­ pro trÃ©novacÃ­ data:

```python
plt.figure(figsize=(25,6))
plt.plot(train_timestamps, y_train, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(train_timestamps, y_train_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.title("Training data prediction")
plt.show()
```

![training data prediction](../../../../7-TimeSeries/3-SVR/images/train-data-predict.png)

Tisk MAPE pro trÃ©novacÃ­ data

```python
print('MAPE for training data: ', mape(y_train_pred, y_train)*100, '%')
```

```output
MAPE for training data: 1.7195710200875551 %
```

VykreslenÃ­ pÅ™edpovÄ›dÃ­ pro testovacÃ­ data

```python
plt.figure(figsize=(10,3))
plt.plot(test_timestamps, y_test, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(test_timestamps, y_test_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![testing data prediction](../../../../7-TimeSeries/3-SVR/images/test-data-predict.png)

Tisk MAPE pro testovacÃ­ data

```python
print('MAPE for testing data: ', mape(y_test_pred, y_test)*100, '%')
```

```output
MAPE for testing data:  1.2623790187854018 %
```

ğŸ† MÃ¡te velmi dobrÃ½ vÃ½sledek na testovacÃ­ datovÃ© sadÄ›!

### Kontrola vÃ½konu modelu na celÃ© datovÃ© sadÄ› [^1]

```python
# Extracting load values as numpy array
data = energy.copy().values

# Scaling
data = scaler.transform(data)

# Transforming to 2D tensor as per model input requirement
data_timesteps=np.array([[j for j in data[i:i+timesteps]] for i in range(0,len(data)-timesteps+1)])[:,:,0]
print("Tensor shape: ", data_timesteps.shape)

# Selecting inputs and outputs from data
X, Y = data_timesteps[:,:timesteps-1],data_timesteps[:,[timesteps-1]]
print("X shape: ", X.shape,"\nY shape: ", Y.shape)
```

```output
Tensor shape:  (26300, 5)
X shape:  (26300, 4) 
Y shape:  (26300, 1)
```

```python
# Make model predictions
Y_pred = model.predict(X).reshape(-1,1)

# Inverse scale and reshape
Y_pred = scaler.inverse_transform(Y_pred)
Y = scaler.inverse_transform(Y)
```

```python
plt.figure(figsize=(30,8))
plt.plot(Y, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(Y_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![full data prediction](../../../../7-TimeSeries/3-SVR/images/full-data-predict.png)

```python
print('MAPE: ', mape(Y_pred, Y)*100, '%')
```

```output
MAPE:  2.0572089029888656 %
```

ğŸ† Velmi pÄ›knÃ© grafy, ukazujÃ­cÃ­ model s dobrou pÅ™esnostÃ­. SkvÄ›lÃ¡ prÃ¡ce!

---

## ğŸš€VÃ½zva

- Zkuste upravit hyperparametry (gamma, C, epsilon) pÅ™i vytvÃ¡Å™enÃ­ modelu a vyhodnoÅ¥te data, abyste zjistili, kterÃ¡ sada hyperparametrÅ¯ poskytuje nejlepÅ¡Ã­ vÃ½sledky na testovacÃ­ch datech. VÃ­ce o tÄ›chto hyperparametrech se dozvÃ­te v [dokumentaci zde](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel). 
- Zkuste pouÅ¾Ã­t rÅ¯znÃ© funkce jÃ¡dra pro model a analyzujte jejich vÃ½kon na datovÃ© sadÄ›. UÅ¾iteÄnÃ½ dokument najdete [zde](https://scikit-learn.org/stable/modules/svm.html#kernel-functions).
- Zkuste pouÅ¾Ã­t rÅ¯znÃ© hodnoty `timesteps`, aby model mohl zpÄ›tnÄ› pÅ™edpovÃ­dat.

## [KvÃ­z po lekci](https://ff-quizzes.netlify.app/en/ml/)

## PÅ™ehled & Samostudium

Tato lekce mÄ›la za cÃ­l pÅ™edstavit aplikaci SVR pro pÅ™edpovÄ›Ä ÄasovÃ½ch Å™ad. Pro vÃ­ce informacÃ­ o SVR mÅ¯Å¾ete navÅ¡tÃ­vit [tento blog](https://www.analyticsvidhya.com/blog/2020/03/support-vector-regression-tutorial-for-machine-learning/). Tato [dokumentace na scikit-learn](https://scikit-learn.org/stable/modules/svm.html) poskytuje komplexnÄ›jÅ¡Ã­ vysvÄ›tlenÃ­ o SVM obecnÄ›, [SVR](https://scikit-learn.org/stable/modules/svm.html#regression) a takÃ© dalÅ¡Ã­ detaily implementace, jako jsou rÅ¯znÃ© [funkce jÃ¡dra](https://scikit-learn.org/stable/modules/svm.html#kernel-functions), kterÃ© lze pouÅ¾Ã­t, a jejich parametry.

## ZadÃ¡nÃ­

[NovÃ½ model SVR](assignment.md)

## PodÄ›kovÃ¡nÃ­

[^1]: Text, kÃ³d a vÃ½stup v tÃ©to sekci pÅ™ispÄ›l [@AnirbanMukherjeeXD](https://github.com/AnirbanMukherjeeXD)
[^2]: Text, kÃ³d a vÃ½stup v tÃ©to sekci byl pÅ™evzat z [ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA)

---

**ProhlÃ¡Å¡enÃ­**:  
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ sluÅ¾by pro automatickÃ½ pÅ™eklad [Co-op Translator](https://github.com/Azure/co-op-translator). I kdyÅ¾ se snaÅ¾Ã­me o pÅ™esnost, mÄ›jte prosÃ­m na pamÄ›ti, Å¾e automatickÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. PÅ¯vodnÃ­ dokument v jeho pÅ¯vodnÃ­m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za autoritativnÃ­ zdroj. Pro dÅ¯leÅ¾itÃ© informace se doporuÄuje profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. NeodpovÃ­dÃ¡me za Å¾Ã¡dnÃ© nedorozumÄ›nÃ­ nebo nesprÃ¡vnÃ© interpretace vyplÃ½vajÃ­cÃ­ z pouÅ¾itÃ­ tohoto pÅ™ekladu.