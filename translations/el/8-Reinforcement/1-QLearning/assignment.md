<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "68394b2102d3503882e5e914bd0ff5c1",
  "translation_date": "2025-09-05T01:12:58+00:00",
  "source_file": "8-Reinforcement/1-QLearning/assignment.md",
  "language_code": "el"
}
-->
# Ένας Πιο Ρεαλιστικός Κόσμος

Στην περίπτωσή μας, ο Πέτρος μπορούσε να κινείται σχεδόν χωρίς να κουράζεται ή να πεινάει. Σε έναν πιο ρεαλιστικό κόσμο, πρέπει να κάθεται και να ξεκουράζεται από καιρό σε καιρό, καθώς και να τρέφεται. Ας κάνουμε τον κόσμο μας πιο ρεαλιστικό, εφαρμόζοντας τους παρακάτω κανόνες:

1. Μετακινούμενος από ένα μέρος σε άλλο, ο Πέτρος χάνει **ενέργεια** και αποκτά **κούραση**.
2. Ο Πέτρος μπορεί να αποκτήσει περισσότερη ενέργεια τρώγοντας μήλα.
3. Ο Πέτρος μπορεί να απαλλαγεί από την κούραση ξεκουραζόμενος κάτω από το δέντρο ή στο γρασίδι (δηλαδή περπατώντας σε μια θέση του πίνακα που έχει δέντρο ή γρασίδι - πράσινο πεδίο).
4. Ο Πέτρος πρέπει να βρει και να σκοτώσει τον λύκο.
5. Για να σκοτώσει τον λύκο, ο Πέτρος πρέπει να έχει συγκεκριμένα επίπεδα ενέργειας και κούρασης, διαφορετικά χάνει τη μάχη.

## Οδηγίες

Χρησιμοποιήστε το αρχικό [notebook.ipynb](../../../../8-Reinforcement/1-QLearning/notebook.ipynb) ως σημείο εκκίνησης για τη λύση σας.

Τροποποιήστε τη συνάρτηση ανταμοιβής σύμφωνα με τους κανόνες του παιχνιδιού, εκτελέστε τον αλγόριθμο ενισχυτικής μάθησης για να μάθετε την καλύτερη στρατηγική για να κερδίσετε το παιχνίδι και συγκρίνετε τα αποτελέσματα της τυχαίας περιήγησης με τον αλγόριθμό σας όσον αφορά τον αριθμό των παιχνιδιών που κερδήθηκαν και χάθηκαν.

> **Note**: Στον νέο σας κόσμο, η κατάσταση είναι πιο σύνθετη και, εκτός από τη θέση του ανθρώπου, περιλαμβάνει επίσης επίπεδα κούρασης και ενέργειας. Μπορείτε να επιλέξετε να εκπροσωπήσετε την κατάσταση ως μια πλειάδα (Πίνακας, ενέργεια, κούραση), να ορίσετε μια κλάση για την κατάσταση (μπορείτε επίσης να την παραγάγετε από την `Board`), ή ακόμα και να τροποποιήσετε την αρχική κλάση `Board` μέσα στο [rlboard.py](../../../../8-Reinforcement/1-QLearning/rlboard.py).

Στη λύση σας, παρακαλώ διατηρήστε τον κώδικα που είναι υπεύθυνος για τη στρατηγική τυχαίας περιήγησης και συγκρίνετε τα αποτελέσματα του αλγορίθμου σας με την τυχαία περιήγηση στο τέλος.

> **Note**: Ίσως χρειαστεί να προσαρμόσετε τις υπερπαραμέτρους για να λειτουργήσει, ειδικά τον αριθμό των εποχών. Επειδή η επιτυχία του παιχνιδιού (η μάχη με τον λύκο) είναι ένα σπάνιο γεγονός, μπορείτε να περιμένετε πολύ μεγαλύτερο χρόνο εκπαίδευσης.

## Κριτήρια Αξιολόγησης

| Κριτήριο | Εξαιρετικό                                                                                                                                                                                             | Επαρκές                                                                                                                                                                                | Χρειάζεται Βελτίωση                                                                                                                          |
| -------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------ |
|          | Παρουσιάζεται ένα σημειωματάριο με τον ορισμό των νέων κανόνων του κόσμου, τον αλγόριθμο Q-Learning και κάποιες κειμενικές εξηγήσεις. Το Q-Learning βελτιώνει σημαντικά τα αποτελέσματα σε σύγκριση με την τυχαία περιήγηση. | Παρουσιάζεται σημειωματάριο, το Q-Learning υλοποιείται και βελτιώνει τα αποτελέσματα σε σύγκριση με την τυχαία περιήγηση, αλλά όχι σημαντικά· ή το σημειωματάριο είναι κακώς τεκμηριωμένο και ο κώδικας δεν είναι καλά δομημένος. | Γίνεται κάποια προσπάθεια να επαναπροσδιοριστούν οι κανόνες του κόσμου, αλλά ο αλγόριθμος Q-Learning δεν λειτουργεί ή η συνάρτηση ανταμοιβής δεν είναι πλήρως ορισμένη. |

---

**Αποποίηση ευθύνης**:  
Αυτό το έγγραφο έχει μεταφραστεί χρησιμοποιώντας την υπηρεσία αυτόματης μετάφρασης [Co-op Translator](https://github.com/Azure/co-op-translator). Παρόλο που καταβάλλουμε προσπάθειες για ακρίβεια, παρακαλούμε να έχετε υπόψη ότι οι αυτοματοποιημένες μεταφράσεις ενδέχεται να περιέχουν λάθη ή ανακρίβειες. Το πρωτότυπο έγγραφο στη μητρική του γλώσσα θα πρέπει να θεωρείται η αυθεντική πηγή. Για κρίσιμες πληροφορίες, συνιστάται επαγγελματική ανθρώπινη μετάφραση. Δεν φέρουμε ευθύνη για τυχόν παρεξηγήσεις ή εσφαλμένες ερμηνείες που προκύπτουν από τη χρήση αυτής της μετάφρασης.