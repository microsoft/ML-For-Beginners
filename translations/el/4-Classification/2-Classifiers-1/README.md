<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1a6e9e46b34a2e559fbbfc1f95397c7b",
  "translation_date": "2025-09-05T00:43:55+00:00",
  "source_file": "4-Classification/2-Classifiers-1/README.md",
  "language_code": "el"
}
-->
# Ταξινομητές κουζινών 1

Σε αυτό το μάθημα, θα χρησιμοποιήσετε το σύνολο δεδομένων που αποθηκεύσατε από το προηγούμενο μάθημα, γεμάτο ισορροπημένα και καθαρά δεδομένα σχετικά με κουζίνες.

Θα χρησιμοποιήσετε αυτό το σύνολο δεδομένων με μια ποικιλία ταξινομητών για να _προβλέψετε μια εθνική κουζίνα βάσει μιας ομάδας συστατικών_. Κατά τη διάρκεια αυτής της διαδικασίας, θα μάθετε περισσότερα για τους τρόπους με τους οποίους οι αλγόριθμοι μπορούν να αξιοποιηθούν για εργασίες ταξινόμησης.

## [Προ-μάθημα κουίζ](https://ff-quizzes.netlify.app/en/ml/)
# Προετοιμασία

Υποθέτοντας ότι ολοκληρώσατε το [Μάθημα 1](../1-Introduction/README.md), βεβαιωθείτε ότι υπάρχει ένα αρχείο _cleaned_cuisines.csv_ στον βασικό φάκελο `/data` για αυτά τα τέσσερα μαθήματα.

## Άσκηση - πρόβλεψη εθνικής κουζίνας

1. Εργαζόμενοι στον φάκελο _notebook.ipynb_ αυτού του μαθήματος, εισάγετε αυτό το αρχείο μαζί με τη βιβλιοθήκη Pandas:

    ```python
    import pandas as pd
    cuisines_df = pd.read_csv("../data/cleaned_cuisines.csv")
    cuisines_df.head()
    ```

    Τα δεδομένα φαίνονται έτσι:

|     | Unnamed: 0 | cuisine | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood | yam | yeast | yogurt | zucchini |
| --- | ---------- | ------- | ------ | -------- | ----- | ---------- | ----- | ------------ | ------- | -------- | --- | ------- | ----------- | ---------- | ----------------------- | ---- | ---- | --- | ----- | ------ | -------- |
| 0   | 0          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 1   | 1          | indian  | 1      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 2   | 2          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 3   | 3          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 4   | 4          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 1      | 0        |
  

1. Τώρα, εισάγετε μερικές ακόμα βιβλιοθήκες:

    ```python
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    from sklearn.svm import SVC
    import numpy as np
    ```

1. Χωρίστε τις συντεταγμένες X και y σε δύο dataframes για εκπαίδευση. Το `cuisine` μπορεί να είναι το dataframe ετικετών:

    ```python
    cuisines_label_df = cuisines_df['cuisine']
    cuisines_label_df.head()
    ```

    Θα φαίνεται έτσι:

    ```output
    0    indian
    1    indian
    2    indian
    3    indian
    4    indian
    Name: cuisine, dtype: object
    ```

1. Αφαιρέστε τη στήλη `Unnamed: 0` και τη στήλη `cuisine`, χρησιμοποιώντας τη μέθοδο `drop()`. Αποθηκεύστε τα υπόλοιπα δεδομένα ως χαρακτηριστικά προς εκπαίδευση:

    ```python
    cuisines_feature_df = cuisines_df.drop(['Unnamed: 0', 'cuisine'], axis=1)
    cuisines_feature_df.head()
    ```

    Τα χαρακτηριστικά σας φαίνονται έτσι:

|      | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | artemisia | artichoke |  ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood |  yam | yeast | yogurt | zucchini |
| ---: | -----: | -------: | ----: | ---------: | ----: | -----------: | ------: | -------: | --------: | --------: | ---: | ------: | ----------: | ---------: | ----------------------: | ---: | ---: | ---: | ----: | -----: | -------: |
|    0 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    1 |      1 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    2 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    3 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    4 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      1 |        0 | 0 |

Τώρα είστε έτοιμοι να εκπαιδεύσετε το μοντέλο σας!

## Επιλογή ταξινομητή

Τώρα που τα δεδομένα σας είναι καθαρά και έτοιμα για εκπαίδευση, πρέπει να αποφασίσετε ποιον αλγόριθμο θα χρησιμοποιήσετε για τη δουλειά.

Το Scikit-learn κατατάσσει την ταξινόμηση στην κατηγορία της Εποπτευόμενης Μάθησης, και σε αυτήν την κατηγορία θα βρείτε πολλούς τρόπους για ταξινόμηση. [Η ποικιλία](https://scikit-learn.org/stable/supervised_learning.html) είναι αρκετά εντυπωσιακή με την πρώτη ματιά. Οι παρακάτω μέθοδοι περιλαμβάνουν τεχνικές ταξινόμησης:

- Γραμμικά Μοντέλα
- Μηχανές Υποστήριξης Διανυσμάτων
- Στοχαστική Κατάβαση Κλίσης
- Πλησιέστεροι Γείτονες
- Γκαουσιανές Διαδικασίες
- Δέντρα Αποφάσεων
- Μέθοδοι Συνόλου (ταξινομητής ψηφοφορίας)
- Αλγόριθμοι πολυκατηγορίας και πολλαπλών εξόδων (ταξινόμηση πολυκατηγορίας και πολυετικετών, ταξινόμηση πολυκατηγορίας-πολλαπλών εξόδων)

> Μπορείτε επίσης να χρησιμοποιήσετε [νευρωνικά δίκτυα για ταξινόμηση δεδομένων](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#classification), αλλά αυτό είναι εκτός του πεδίου αυτού του μαθήματος.

### Ποιον ταξινομητή να επιλέξετε;

Λοιπόν, ποιον ταξινομητή πρέπει να επιλέξετε; Συχνά, η δοκιμή πολλών και η αναζήτηση ενός καλού αποτελέσματος είναι ένας τρόπος να δοκιμάσετε. Το Scikit-learn προσφέρει μια [σύγκριση δίπλα-δίπλα](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) σε ένα δημιουργημένο σύνολο δεδομένων, συγκρίνοντας τους KNeighbors, SVC με δύο τρόπους, GaussianProcessClassifier, DecisionTreeClassifier, RandomForestClassifier, MLPClassifier, AdaBoostClassifier, GaussianNB και QuadraticDiscriminationAnalysis, δείχνοντας τα αποτελέσματα οπτικοποιημένα:

![σύγκριση ταξινομητών](../../../../4-Classification/2-Classifiers-1/images/comparison.png)
> Γραφήματα που δημιουργήθηκαν από την τεκμηρίωση του Scikit-learn

> Το AutoML λύνει αυτό το πρόβλημα εύκολα, εκτελώντας αυτές τις συγκρίσεις στο cloud, επιτρέποντάς σας να επιλέξετε τον καλύτερο αλγόριθμο για τα δεδομένα σας. Δοκιμάστε το [εδώ](https://docs.microsoft.com/learn/modules/automate-model-selection-with-azure-automl/?WT.mc_id=academic-77952-leestott)

### Μια καλύτερη προσέγγιση

Ένας καλύτερος τρόπος από το να μαντεύετε τυχαία είναι να ακολουθήσετε τις ιδέες που περιγράφονται σε αυτό το [ML Cheat Sheet](https://docs.microsoft.com/azure/machine-learning/algorithm-cheat-sheet?WT.mc_id=academic-77952-leestott). Εδώ, ανακαλύπτουμε ότι, για το πρόβλημα πολυκατηγορίας μας, έχουμε κάποιες επιλογές:

![cheatsheet για προβλήματα πολυκατηγορίας](../../../../4-Classification/2-Classifiers-1/images/cheatsheet.png)
> Ένα τμήμα του Algorithm Cheat Sheet της Microsoft, που περιγράφει επιλογές ταξινόμησης πολυκατηγορίας

✅ Κατεβάστε αυτό το cheat sheet, εκτυπώστε το και κρεμάστε το στον τοίχο σας!

### Λογική

Ας δούμε αν μπορούμε να σκεφτούμε διαφορετικές προσεγγίσεις δεδομένων των περιορισμών που έχουμε:

- **Τα νευρωνικά δίκτυα είναι πολύ βαριά**. Δεδομένου του καθαρού αλλά ελάχιστου συνόλου δεδομένων μας και του γεγονότος ότι εκτελούμε την εκπαίδευση τοπικά μέσω notebooks, τα νευρωνικά δίκτυα είναι υπερβολικά βαριά για αυτήν την εργασία.
- **Δεν χρησιμοποιούμε ταξινομητή δύο κατηγοριών**. Δεν χρησιμοποιούμε ταξινομητή δύο κατηγοριών, οπότε αυτό αποκλείει το one-vs-all.
- **Το δέντρο αποφάσεων ή η λογιστική παλινδρόμηση θα μπορούσαν να λειτουργήσουν**. Ένα δέντρο αποφάσεων θα μπορούσε να λειτουργήσει, ή η λογιστική παλινδρόμηση για δεδομένα πολυκατηγορίας.
- **Τα πολυκατηγορικά ενισχυμένα δέντρα αποφάσεων λύνουν διαφορετικό πρόβλημα**. Το πολυκατηγορικό ενισχυμένο δέντρο αποφάσεων είναι πιο κατάλληλο για μη παραμετρικές εργασίες, π.χ. εργασίες σχεδιασμένες για δημιουργία κατατάξεων, οπότε δεν είναι χρήσιμο για εμάς.

### Χρήση του Scikit-learn 

Θα χρησιμοποιήσουμε το Scikit-learn για να αναλύσουμε τα δεδομένα μας. Ωστόσο, υπάρχουν πολλοί τρόποι να χρησιμοποιήσετε τη λογιστική παλινδρόμηση στο Scikit-learn. Ρίξτε μια ματιά στις [παραμέτρους που μπορείτε να περάσετε](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regressio#sklearn.linear_model.LogisticRegression).  

Ουσιαστικά υπάρχουν δύο σημαντικές παράμετροι - `multi_class` και `solver` - που πρέπει να καθορίσουμε όταν ζητάμε από το Scikit-learn να εκτελέσει λογιστική παλινδρόμηση. Η τιμή του `multi_class` εφαρμόζει μια συγκεκριμένη συμπεριφορά. Η τιμή του solver καθορίζει ποιον αλγόριθμο θα χρησιμοποιήσει. Δεν μπορούν όλοι οι solvers να συνδυαστούν με όλες τις τιμές του `multi_class`.

Σύμφωνα με την τεκμηρίωση, στην περίπτωση πολυκατηγορίας, ο αλγόριθμος εκπαίδευσης:

- **Χρησιμοποιεί το σχήμα one-vs-rest (OvR)**, αν η επιλογή `multi_class` έχει οριστεί σε `ovr`
- **Χρησιμοποιεί την απώλεια cross-entropy**, αν η επιλογή `multi_class` έχει οριστεί σε `multinomial`. (Επί του παρόντος η επιλογή `multinomial` υποστηρίζεται μόνο από τους solvers ‘lbfgs’, ‘sag’, ‘saga’ και ‘newton-cg’.)"

> 🎓 Το 'σχήμα' εδώ μπορεί να είναι είτε 'ovr' (one-vs-rest) είτε 'multinomial'. Δεδομένου ότι η λογιστική παλινδρόμηση έχει σχεδιαστεί για να υποστηρίζει δυαδική ταξινόμηση, αυτά τα σχήματα της επιτρέπουν να χειρίζεται καλύτερα εργασίες ταξινόμησης πολυκατηγορίας. [πηγή](https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/)

> 🎓 Ο 'solver' ορίζεται ως "ο αλγόριθμος που θα χρησιμοποιηθεί στο πρόβλημα βελτιστοποίησης". [πηγή](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regressio#sklearn.linear_model.LogisticRegression).

Το Scikit-learn προσφέρει αυτόν τον πίνακα για να εξηγήσει πώς οι solvers χειρίζονται διαφορετικές προκλήσεις που παρουσιάζονται από διαφορετικές δομές δεδομένων:

![solvers](../../../../4-Classification/2-Classifiers-1/images/solvers.png)

## Άσκηση - χωρίστε τα δεδομένα

Μπορούμε να επικεντρωθούμε στη λογιστική παλινδρόμηση για την πρώτη μας δοκιμή εκπαίδευσης, καθώς μάθατε πρόσφατα για αυτήν στο προηγούμενο μάθημα.
Χωρίστε τα δεδομένα σας σε ομάδες εκπαίδευσης και δοκιμής καλώντας τη μέθοδο `train_test_split()`:

```python
X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)
```

## Άσκηση - εφαρμόστε λογιστική παλινδρόμηση

Δεδομένου ότι χρησιμοποιείτε την περίπτωση πολυκατηγορίας, πρέπει να επιλέξετε ποιο _σχήμα_ θα χρησιμοποιήσετε και ποιον _solver_ θα ορίσετε. Χρησιμοποιήστε τη LogisticRegression με ρύθμιση multiclass και τον solver **liblinear** για εκπαίδευση.

1. Δημιουργήστε μια λογιστική παλινδρόμηση με το multi_class ορισμένο σε `ovr` και τον solver ορισμένο σε `liblinear`:

    ```python
    lr = LogisticRegression(multi_class='ovr',solver='liblinear')
    model = lr.fit(X_train, np.ravel(y_train))
    
    accuracy = model.score(X_test, y_test)
    print ("Accuracy is {}".format(accuracy))
    ```

    ✅ Δοκιμάστε έναν διαφορετικό solver όπως το `lbfgs`, που συχνά ορίζεται ως προεπιλογή
> Σημείωση, χρησιμοποιήστε τη συνάρτηση Pandas [`ravel`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.ravel.html) για να ισοπεδώσετε τα δεδομένα σας όταν χρειάζεται.
Η ακρίβεια είναι καλή, πάνω από **80%**!

1. Μπορείτε να δείτε αυτό το μοντέλο σε δράση δοκιμάζοντας μία γραμμή δεδομένων (#50):

    ```python
    print(f'ingredients: {X_test.iloc[50][X_test.iloc[50]!=0].keys()}')
    print(f'cuisine: {y_test.iloc[50]}')
    ```

    Το αποτέλεσμα εκτυπώνεται:

   ```output
   ingredients: Index(['cilantro', 'onion', 'pea', 'potato', 'tomato', 'vegetable_oil'], dtype='object')
   cuisine: indian
   ```

   ✅ Δοκιμάστε έναν διαφορετικό αριθμό γραμμής και ελέγξτε τα αποτελέσματα.

1. Εξετάζοντας πιο βαθιά, μπορείτε να ελέγξετε την ακρίβεια αυτής της πρόβλεψης:

    ```python
    test= X_test.iloc[50].values.reshape(-1, 1).T
    proba = model.predict_proba(test)
    classes = model.classes_
    resultdf = pd.DataFrame(data=proba, columns=classes)
    
    topPrediction = resultdf.T.sort_values(by=[0], ascending = [False])
    topPrediction.head()
    ```

    Το αποτέλεσμα εκτυπώνεται - η ινδική κουζίνα είναι η καλύτερη πρόβλεψη, με καλή πιθανότητα:

    |          |        0 |
    | -------: | -------: |
    |   indian | 0.715851 |
    |  chinese | 0.229475 |
    | japanese | 0.029763 |
    |   korean | 0.017277 |
    |     thai | 0.007634 |

    ✅ Μπορείτε να εξηγήσετε γιατί το μοντέλο είναι αρκετά σίγουρο ότι πρόκειται για ινδική κουζίνα;

1. Αποκτήστε περισσότερες λεπτομέρειες εκτυπώνοντας μια αναφορά ταξινόμησης, όπως κάνατε στα μαθήματα παλινδρόμησης:

    ```python
    y_pred = model.predict(X_test)
    print(classification_report(y_test,y_pred))
    ```

    |              | precision | recall | f1-score | support |
    | ------------ | --------- | ------ | -------- | ------- |
    | chinese      | 0.73      | 0.71   | 0.72     | 229     |
    | indian       | 0.91      | 0.93   | 0.92     | 254     |
    | japanese     | 0.70      | 0.75   | 0.72     | 220     |
    | korean       | 0.86      | 0.76   | 0.81     | 242     |
    | thai         | 0.79      | 0.85   | 0.82     | 254     |
    | accuracy     | 0.80      | 1199   |          |         |
    | macro avg    | 0.80      | 0.80   | 0.80     | 1199    |
    | weighted avg | 0.80      | 0.80   | 0.80     | 1199    |

## 🚀Πρόκληση

Σε αυτό το μάθημα, χρησιμοποιήσατε τα καθαρισμένα δεδομένα σας για να δημιουργήσετε ένα μοντέλο μηχανικής μάθησης που μπορεί να προβλέψει μια εθνική κουζίνα βάσει μιας σειράς συστατικών. Αφιερώστε λίγο χρόνο για να διαβάσετε τις πολλές επιλογές που παρέχει το Scikit-learn για την ταξινόμηση δεδομένων. Εξετάστε πιο βαθιά την έννοια του 'solver' για να κατανοήσετε τι συμβαίνει πίσω από τις σκηνές.

## [Κουίζ μετά το μάθημα](https://ff-quizzes.netlify.app/en/ml/)

## Ανασκόπηση & Αυτομελέτη

Εξετάστε λίγο περισσότερο τα μαθηματικά πίσω από την λογιστική παλινδρόμηση σε [αυτό το μάθημα](https://people.eecs.berkeley.edu/~russell/classes/cs194/f11/lectures/CS194%20Fall%202011%20Lecture%2006.pdf)
## Εργασία 

[Μελετήστε τους solvers](assignment.md)

---

**Αποποίηση ευθύνης**:  
Αυτό το έγγραφο έχει μεταφραστεί χρησιμοποιώντας την υπηρεσία μετάφρασης AI [Co-op Translator](https://github.com/Azure/co-op-translator). Παρόλο που καταβάλλουμε προσπάθειες για ακρίβεια, παρακαλούμε να έχετε υπόψη ότι οι αυτοματοποιημένες μεταφράσεις ενδέχεται να περιέχουν λάθη ή ανακρίβειες. Το πρωτότυπο έγγραφο στη μητρική του γλώσσα θα πρέπει να θεωρείται η αυθεντική πηγή. Για κρίσιμες πληροφορίες, συνιστάται επαγγελματική ανθρώπινη μετάφραση. Δεν φέρουμε ευθύνη για τυχόν παρεξηγήσεις ή εσφαλμένες ερμηνείες που προκύπτουν από τη χρήση αυτής της μετάφρασης.