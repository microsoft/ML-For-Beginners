<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "df2b538e8fbb3e91cf0419ae2f858675",
  "translation_date": "2025-09-06T06:12:09+00:00",
  "source_file": "9-Real-World/2-Debugging-ML-Models/README.md",
  "language_code": "mr"
}
-->
# पोस्टस्क्रिप्ट: मशीन लर्निंगमध्ये जबाबदार AI डॅशबोर्ड घटकांचा वापर करून मॉडेल डीबगिंग

## [पूर्व-व्याख्यान प्रश्नमंजूषा](https://ff-quizzes.netlify.app/en/ml/)

## परिचय

मशीन लर्निंग आपल्या दैनंदिन जीवनावर प्रभाव टाकते. AI आरोग्यसेवा, वित्त, शिक्षण आणि रोजगार यांसारख्या महत्त्वाच्या प्रणालींमध्ये प्रवेश करत आहे, ज्या आपल्याला व्यक्ती म्हणून तसेच समाज म्हणून प्रभावित करतात. उदाहरणार्थ, आरोग्यसेवा निदान किंवा फसवणूक शोधण्यासारख्या दैनंदिन निर्णय घेण्याच्या कार्यांमध्ये प्रणाली आणि मॉडेल्स सहभागी असतात. परिणामी, AI मधील प्रगती आणि वेगाने स्वीकारण्यासोबतच समाजाच्या अपेक्षा विकसित होत आहेत आणि त्याला प्रतिसाद म्हणून नियमन वाढत आहे. आपल्याला सतत असे क्षेत्र दिसतात जिथे AI प्रणाली अपेक्षांवर खरे उतरू शकत नाहीत; त्या नवीन आव्हाने उघड करतात; आणि सरकार AI उपाययोजनांचे नियमन करण्यास सुरुवात करत आहेत. त्यामुळे, या मॉडेल्सचे विश्लेषण करणे महत्त्वाचे आहे जेणेकरून सर्वांसाठी न्याय्य, विश्वासार्ह, समावेशक, पारदर्शक आणि जबाबदार परिणाम मिळतील.

या अभ्यासक्रमात, आम्ही काही व्यावहारिक साधनांचा अभ्यास करू जे मॉडेलमध्ये जबाबदार AI संबंधित समस्या आहेत का हे तपासण्यासाठी वापरले जाऊ शकतात. पारंपरिक मशीन लर्निंग डीबगिंग तंत्रे प्रामुख्याने संख्यात्मक गणनांवर आधारित असतात, जसे की एकत्रित अचूकता किंवा सरासरी त्रुटी नुकसान. कल्पना करा की तुम्ही मॉडेल तयार करण्यासाठी वापरत असलेल्या डेटामध्ये विशिष्ट लोकसंख्येचा अभाव आहे, जसे की वंश, लिंग, राजकीय दृष्टिकोन, धर्म, किंवा अशा लोकसंख्येचे असमान प्रतिनिधित्व आहे. मॉडेलचा आउटपुट काही लोकसंख्येला प्राधान्य देण्यासाठी व्याख्या केला जातो तेव्हा काय होते? हे संवेदनशील वैशिष्ट्य गटांच्या अति किंवा कमी प्रतिनिधित्वाचा परिचय देऊ शकते, ज्यामुळे मॉडेलमधून न्याय, समावेश किंवा विश्वासार्हतेच्या समस्या निर्माण होतात. आणखी एक घटक म्हणजे, मशीन लर्निंग मॉडेल्स "ब्लॅक बॉक्स" मानले जातात, ज्यामुळे मॉडेलच्या अंदाजामागील कारणे समजणे आणि स्पष्ट करणे कठीण होते. डेटा वैज्ञानिक आणि AI विकसकांना मॉडेलच्या न्याय्यतेचे किंवा विश्वासार्हतेचे मूल्यांकन करण्यासाठी पुरेसे साधने नसल्यास हे सर्व आव्हाने निर्माण होतात.

या धड्यात, तुम्ही तुमचे मॉडेल डीबग करण्यासाठी खालील गोष्टी शिकाल:

- **त्रुटी विश्लेषण**: तुमच्या डेटाच्या वितरणामध्ये जिथे मॉडेलचे त्रुटी दर जास्त आहेत ते ओळखा.
- **मॉडेल विहंगावलोकन**: विविध डेटा गटांमध्ये तुलना करून तुमच्या मॉडेलच्या कार्यप्रदर्शन मेट्रिक्समधील विसंगती शोधा.
- **डेटा विश्लेषण**: तुमच्या डेटामध्ये अति किंवा कमी प्रतिनिधित्व असलेल्या ठिकाणी तपास करा, ज्यामुळे तुमचे मॉडेल एका डेटा लोकसंख्येला दुसऱ्याच्या तुलनेत प्राधान्य देऊ शकते.
- **वैशिष्ट्य महत्त्व**: जागतिक स्तरावर किंवा स्थानिक स्तरावर तुमच्या मॉडेलच्या अंदाजांवर कोणती वैशिष्ट्ये प्रभाव टाकत आहेत ते समजून घ्या.

## पूर्वतयारी

पूर्वतयारी म्हणून, कृपया [विकसकांसाठी जबाबदार AI साधने](https://www.microsoft.com/ai/ai-lab-responsible-ai-dashboard) याचा आढावा घ्या.

> ![जबाबदार AI साधनांवरील GIF](../../../../9-Real-World/2-Debugging-ML-Models/images/rai-overview.gif)

## त्रुटी विश्लेषण

पारंपरिक मॉडेल कार्यप्रदर्शन मेट्रिक्स अचूकता मोजण्यासाठी वापरले जातात आणि प्रामुख्याने योग्य विरुद्ध चुकीच्या अंदाजांवर आधारित गणना असतात. उदाहरणार्थ, एखाद्या मॉडेलने 89% वेळा अचूक अंदाज लावला आणि 0.001 चा त्रुटी नुकसान आहे असे ठरवणे चांगले कार्यप्रदर्शन मानले जाऊ शकते. त्रुटी तुमच्या अंतर्निहित डेटासेटमध्ये समान रीतीने वितरित केल्या जात नाहीत. तुम्हाला 89% मॉडेल अचूकता स्कोअर मिळू शकतो, परंतु असे आढळते की तुमच्या डेटाच्या वेगवेगळ्या भागांमध्ये मॉडेल 42% वेळा अयशस्वी होत आहे. विशिष्ट डेटा गटांसह या अपयशाच्या नमुन्यांचे परिणाम न्याय किंवा विश्वासार्हतेच्या समस्यांकडे नेऊ शकतात. मॉडेल चांगले कार्य करत आहे किंवा नाही अशा क्षेत्रांना समजून घेणे आवश्यक आहे. तुमच्या मॉडेलमध्ये जिथे अचूकतेचा अभाव आहे अशा डेटा क्षेत्रे महत्त्वपूर्ण डेटा लोकसंख्या ठरू शकतात.

![मॉडेल त्रुटींचे विश्लेषण आणि डीबग करा](../../../../9-Real-World/2-Debugging-ML-Models/images/ea-error-distribution.png)

RAI डॅशबोर्डवरील त्रुटी विश्लेषण घटक विविध गटांमध्ये मॉडेल अपयश कसे वितरित केले जाते हे ट्री व्हिज्युअलायझेशनसह दर्शवितो. तुमच्या डेटासेटसह जिथे त्रुटी दर जास्त आहे अशा वैशिष्ट्ये किंवा क्षेत्रे ओळखण्यासाठी हे उपयुक्त आहे. मॉडेलच्या अचूकतेचा अभाव जिथून येत आहे ते पाहून तुम्ही मूळ कारण तपासण्यास सुरुवात करू शकता. तुम्ही विश्लेषण करण्यासाठी डेटा गट तयार करू शकता. हे डेटा गट डीबगिंग प्रक्रियेत मदत करतात, जिथे एक गट चांगले कार्य करत आहे, तर दुसऱ्या गटात त्रुटी आहेत.

![त्रुटी विश्लेषण](../../../../9-Real-World/2-Debugging-ML-Models/images/ea-error-cohort.png)

ट्री मॅपवरील व्हिज्युअल इंडिकेटर्स समस्या क्षेत्रे लवकर शोधण्यात मदत करतात. उदाहरणार्थ, ट्री नोडचा गडद लाल रंग जितका गडद असेल तितका त्रुटी दर जास्त.

हीट मॅप हे आणखी एक व्हिज्युअलायझेशन कार्यक्षमता आहे ज्याचा वापर वापरकर्ते एक किंवा दोन वैशिष्ट्यांचा वापर करून त्रुटी दर तपासण्यासाठी करू शकतात, ज्यामुळे संपूर्ण डेटासेट किंवा गटांमध्ये मॉडेल त्रुटींचे योगदानकर्ता शोधता येते.

![त्रुटी विश्लेषण हीटमॅप](../../../../9-Real-World/2-Debugging-ML-Models/images/ea-heatmap.png)

त्रुटी विश्लेषण वापरा जेव्हा तुम्हाला:

* मॉडेल अपयश तुमच्या डेटासेटमध्ये आणि अनेक इनपुट आणि वैशिष्ट्य परिमाणांमध्ये कसे वितरित केले जाते याची सखोल समज मिळवा.
* एकत्रित कार्यप्रदर्शन मेट्रिक्सचे विघटन करा आणि लक्ष्यित सुधारणा पावले सूचित करण्यासाठी त्रुटी गट आपोआप शोधा.

## मॉडेल विहंगावलोकन

मशीन लर्निंग मॉडेलचे कार्यप्रदर्शन मूल्यांकन करण्यासाठी त्याच्या वर्तनाची समग्र समज मिळवणे आवश्यक आहे. हे त्रुटी दर, अचूकता, पुनर्प्राप्ती, अचूकता किंवा MAE (मीन अॅब्सोल्यूट एरर) यासारख्या एकापेक्षा जास्त मेट्रिक्सचे पुनरावलोकन करून साध्य केले जाऊ शकते, जेणेकरून कार्यप्रदर्शन मेट्रिक्समधील विसंगती शोधता येतील. एक कार्यप्रदर्शन मेट्रिक चांगले दिसू शकते, परंतु दुसऱ्या मेट्रिकमध्ये अचूकतेचा अभाव उघड होऊ शकतो. याशिवाय, संपूर्ण डेटासेट किंवा गटांमध्ये मेट्रिक्सची तुलना करणे मॉडेल चांगले कार्य करत आहे किंवा नाही हे स्पष्ट करण्यात मदत करते. हे विशेषतः संवेदनशील विरुद्ध असंवेदनशील वैशिष्ट्यांमध्ये (उदा., रुग्णाचा वंश, लिंग किंवा वय) मॉडेलचे कार्यप्रदर्शन पाहणे महत्त्वाचे आहे, जेणेकरून मॉडेलमध्ये संभाव्य अन्याय उघड होऊ शकतो. उदाहरणार्थ, संवेदनशील वैशिष्ट्य असलेल्या गटामध्ये मॉडेल अधिक त्रुटीपूर्ण असल्याचे आढळल्यास मॉडेलमध्ये संभाव्य अन्याय उघड होऊ शकतो.

RAI डॅशबोर्डवरील मॉडेल विहंगावलोकन घटक केवळ डेटा गटांमधील कार्यप्रदर्शन मेट्रिक्सचे विश्लेषण करण्यात मदत करत नाही, तर ते वापरकर्त्यांना विविध गटांमध्ये मॉडेलच्या वर्तनाची तुलना करण्याची क्षमता देते.

![डेटासेट गट - RAI डॅशबोर्डवरील मॉडेल विहंगावलोकन](../../../../9-Real-World/2-Debugging-ML-Models/images/model-overview-dataset-cohorts.png)

घटकाची वैशिष्ट्य-आधारित विश्लेषण कार्यक्षमता वापरकर्त्यांना विशिष्ट वैशिष्ट्यांमध्ये डेटा उपगट कमी करण्याची परवानगी देते, जेणेकरून सूक्ष्म स्तरावर विसंगती ओळखता येतील. उदाहरणार्थ, डॅशबोर्डमध्ये वापरकर्त्याने निवडलेल्या वैशिष्ट्यासाठी (उदा., *"time_in_hospital < 3"* किंवा *"time_in_hospital >= 7"*) स्वयंचलितपणे गट तयार करण्यासाठी अंतर्गत बुद्धिमत्ता आहे. यामुळे वापरकर्त्याला मोठ्या डेटा गटातून विशिष्ट वैशिष्ट्य वेगळे करण्यास सक्षम होते, जेणेकरून ते मॉडेलच्या त्रुटीपूर्ण परिणामांवर प्रभाव टाकणारे प्रमुख घटक आहे का हे पाहता येईल.

![वैशिष्ट्य गट - RAI डॅशबोर्डवरील मॉडेल विहंगावलोकन](../../../../9-Real-World/2-Debugging-ML-Models/images/model-overview-feature-cohorts.png)

मॉडेल विहंगावलोकन घटक दोन प्रकारच्या विसंगती मेट्रिक्सला समर्थन देतो:

**मॉडेल कार्यप्रदर्शनातील विसंगती**: या मेट्रिक्सचा संच डेटा उपगटांमध्ये निवडलेल्या कार्यप्रदर्शन मेट्रिकच्या मूल्यांमधील विसंगती (फरक) मोजतो. काही उदाहरणे:

* अचूकता दरातील विसंगती
* त्रुटी दरातील विसंगती
* अचूकतेतील विसंगती
* पुनर्प्राप्तीतील विसंगती
* मीन अॅब्सोल्यूट एरर (MAE) मधील विसंगती

**निवड दरातील विसंगती**: हा मेट्रिक उपगटांमध्ये निवड दर (अनुकूल अंदाज) मधील फरक समाविष्ट करतो. याचे एक उदाहरण म्हणजे कर्ज मंजुरी दरातील विसंगती. निवड दर म्हणजे प्रत्येक वर्गातील डेटा पॉइंट्सचा अंश जो 1 म्हणून वर्गीकृत केला जातो (बायनरी वर्गीकरणामध्ये) किंवा अंदाज मूल्यांचे वितरण (प्रत्यावर्तनामध्ये).

## डेटा विश्लेषण

> "जर तुम्ही डेटा पुरेसा त्रास दिला, तर तो काहीही कबूल करेल" - रोनाल्ड कोस

हे विधान अतिशयोक्तीपूर्ण वाटते, परंतु हे खरे आहे की डेटा कोणत्याही निष्कर्षाला समर्थन देण्यासाठी हेरफेर केला जाऊ शकतो. अशा प्रकारचे हेरफेर कधीकधी अनवधानाने होऊ शकते. मानव म्हणून, आपल्याला सर्वांनाच पूर्वग्रह असतो आणि डेटा तयार करताना आपण पूर्वग्रह कधी ओळखतो हे जाणून घेणे कठीण असते. AI आणि मशीन लर्निंगमध्ये न्याय्यतेची हमी देणे ही एक गुंतागुंतीची समस्या आहे.

पारंपरिक मॉडेल कार्यप्रदर्शन मेट्रिक्ससाठी डेटा हा एक मोठा अंध भाग आहे. तुम्हाला उच्च अचूकता स्कोअर मिळू शकतो, परंतु याचा नेहमीच अर्थ असा नाही की तुमच्या डेटासेटमध्ये अंतर्निहित डेटा पूर्वग्रह आहे. उदाहरणार्थ, जर एखाद्या कंपनीतील कार्यकारी पदांवरील महिलांचे प्रमाण 27% आणि पुरुषांचे प्रमाण 73% असेल, तर या डेटावर प्रशिक्षित केलेला नोकरी जाहिरात AI मॉडेल वरिष्ठ स्तरावरील नोकरीसाठी प्रामुख्याने पुरुष प्रेक्षकांना लक्ष्य करू शकतो. डेटामध्ये असलेल्या या असंतुलनामुळे मॉडेलचा अंदाज एका लिंगाला प्राधान्य देण्यासाठी वाकवला गेला. यामुळे न्याय्यतेची समस्या उघड होते जिथे AI मॉडेलमध्ये लिंग पूर्वग्रह आहे.

RAI डॅशबोर्डवरील डेटा विश्लेषण घटक डेटासेटमध्ये जिथे अति- आणि कमी-प्रतिनिधित्व आहे अशा क्षेत्रांची ओळख करण्यात मदत करतो. डेटा असंतुलन किंवा विशिष्ट डेटा गटाच्या प्रतिनिधित्वाच्या अभावामुळे त्रुटी आणि न्याय्यतेच्या समस्यांचे मूळ कारण शोधण्यात हे वापरकर्त्यांना मदत करते. हे वापरकर्त्यांना अंदाजित आणि वास्तविक परिणाम, त्रुटी गट आणि विशिष्ट वैशिष्ट्यांवर आधारित डेटासेट व्हिज्युअलाइझ करण्याची क्षमता देते. कधीकधी कमी प्रतिनिधित्व असलेल्या डेटा गटाचा शोध घेतल्याने मॉडेल चांगले शिकत नाही हे देखील उघड होऊ शकते, त्यामुळे अचूकतेचा अभाव असतो. डेटा पूर्वग्रह असलेला मॉडेल असणे ही केवळ न्याय्यतेची समस्या नाही तर मॉडेल समावेशक किंवा विश्वासार्ह नाही हे देखील दर्शवते.

![RAI डॅशबोर्डवरील डेटा विश्लेषण घटक](../../../../9-Real-World/2-Debugging-ML-Models/images/dataanalysis-cover.png)

डेटा विश्लेषण वापरा जेव्हा तुम्हाला:

* तुमच्या डेटासेटच्या आकडेवारीचा शोध घ्या, विविध परिमाणांमध्ये (गटांमध्ये) तुमचा डेटा विभाजित करण्यासाठी विविध फिल्टर निवडा.
* विविध गट आणि वैशिष्ट्य गटांमध्ये तुमच्या डेटासेटचे वितरण समजून घ्या.
* न्याय्यतेशी संबंधित तुमच्या निष्कर्ष, त्रुटी विश्लेषण आणि कारणात्मकता (इतर डॅशबोर्ड घटकांमधून प्राप्त) तुमच्या डेटासेटच्या वितरणाचा परिणाम आहेत का हे ठरवा.
* प्रतिनिधित्वाच्या समस्यांमुळे, लेबल आवाज, वैशिष्ट्य आवाज, लेबल पूर्वग्रह आणि अशा घटकांमुळे त्रुटी कमी करण्यासाठी कोणत्या क्षेत्रांमध्ये अधिक डेटा गोळा करायचा आहे हे ठरवा.

## मॉडेल समज

मशीन लर्निंग मॉडेल्स "ब्लॅक बॉक्स" असतात. मॉडेलचा अंदाज कोणत्या प्रमुख डेटा वैशिष्ट्यांवर आधारित आहे हे समजणे आव्हानात्मक असते. मॉडेलने विशिष्ट अंदाज का लावला याबद्दल पारदर्शकता प्रदान करणे महत्त्वाचे आहे. उदाहरणार्थ, जर एखाद्या AI प्रणालीने अंदाज लावला की मधुमेह असलेल्या रुग्णाला 30 दिवसांच्या आत पुन्हा रुग्णालयात दाखल होण्याचा धोका आहे, तर त्याच्या अंदाजामागील समर्थन डेटा प्रदान करणे आवश्यक आहे. समर्थन डेटा निर्देशक असणे पारदर्शकता आणते, ज्यामुळे क्लिनिशियन किंवा रुग्णालयांना चांगले निर्णय घेता येतात. याशिवाय, एखाद्या रुग्णासाठी मॉडेलने अंदाज का लावला हे स्पष्ट करण्याची क्षमता आरोग्य नियमांसह जबाबदारी सक्षम करते. जेव्हा तुम्ही मशीन लर्निंग मॉडेल्सचा वापर लोकांच्या जीवनावर परिणाम करणाऱ्या पद्धतींमध्ये करत असता, तेव्हा मॉडेलच्या वर्तनावर काय प्रभाव पडतो हे समजून घेणे आणि स्पष्ट करणे महत्त्वाचे आहे. मॉडेल स्पष्टता आणि समज खालील परिस्थितींमध्ये प्रश्नांची उत्तरे देण्यास मदत करते:

* मॉडेल डीबगिंग: माझ्या मॉडेलने ही चूक का केली? मी माझे मॉडेल कसे सुधारू शकतो?
* मानव-AI सहकार्य: मी मॉडेलच्या निर्णयांना कसे समजून घेऊ आणि विश्वास ठेवू शकतो?
* नियामक अनुपालन: माझे मॉडेल कायदेशीर आवश्यकता पूर्ण करते का?

RAI डॅशबोर्डवरील वैशिष्ट्य महत्त्व घटक तुम्हाला डीबग करण्यासाठी आणि मॉडेल अंदाज कसे लावते याची व्यापक समज मिळविण्यास मदत करते. मशीन लर्निंग व्यावसायिक आणि निर्णय घेणाऱ्यांसाठी हे एक उपयुक्त साधन आहे, जे मॉडेलच्या वर्तनावर प्रभाव टाकणाऱ्या वैशिष्ट्यांचे पुरावे स्पष्ट करण्यासाठी आणि दाखवण्यासाठी नियामक अनुपालनासाठी उपयुक्त आहे. पुढे, वापरकर्ते जागतिक आणि स्थानिक स्पष्टीकरणे शोधू शकतात, जे वैशिष्ट्ये मॉडेलच्या अंदाजांवर प्रभाव टाकतात ते सत्यापित करण्यासाठी. जागतिक स्पष्टीकरणे मॉडेलच्या एकूण अंदाजावर परिणाम करणाऱ्या शीर्ष वैशिष्ट्यांची यादी करतात. स्थानिक स्पष्टीकरणे विशिष्ट प्रकरणासाठी मॉडेलच्या अंदाजामागील वैशिष्ट्ये दर्शवतात. स्थानिक स्पष्टीकरणे मूल्यांकन करण्याची क्षमता विशिष्ट प्रकरण डीबग किंवा ऑडिट करण्यासाठी उपयुक्त आहे, जेणेकरून मॉडेलने अचूक किंवा अचूक अंदाज का लावला हे चांगल्या प्रकारे समजून घेता येईल.

![RAI डॅशबोर्डवरील
- **अतिरिक्त किंवा अपुरे प्रतिनिधित्व**. कल्पना अशी आहे की एखाद्या विशिष्ट गटाला एखाद्या व्यवसायात दिसत नाही, आणि कोणतीही सेवा किंवा कार्य जे हे पुढे चालू ठेवते ते नुकसान पोहोचवण्यास हातभार लावते.

### Azure RAI डॅशबोर्ड

[Azure RAI डॅशबोर्ड](https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai-dashboard?WT.mc_id=aiml-90525-ruyakubu) हे ओपन-सोर्स टूल्सवर आधारित आहे जे प्रमुख शैक्षणिक संस्थांनी आणि Microsoftसह संस्थांनी विकसित केले आहे. हे डेटा वैज्ञानिक आणि AI विकसकांना मॉडेलचे वर्तन अधिक चांगल्या प्रकारे समजून घेण्यासाठी, AI मॉडेल्समधील अवांछित समस्या शोधण्यासाठी आणि कमी करण्यासाठी उपयुक्त आहे.

- RAI डॅशबोर्ड [डॉक्युमेंट्स](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-responsible-ai-dashboard?WT.mc_id=aiml-90525-ruyakubu) तपासून वेगवेगळ्या घटकांचा वापर कसा करायचा ते शिका.

- Azure Machine Learning मध्ये अधिक जबाबदार AI परिस्थितींसाठी डीबगिंगसाठी काही RAI डॅशबोर्ड [नमुन्य नोटबुक्स](https://github.com/Azure/RAI-vNext-Preview/tree/main/examples/notebooks) तपासा.

---
## 🚀 आव्हान

सांख्यिकीय किंवा डेटा पक्षपात टाळण्यासाठी, आपल्याला खालील गोष्टी कराव्या लागतील:

- प्रणालींवर काम करणाऱ्या लोकांमध्ये विविध पार्श्वभूमी आणि दृष्टिकोन असणे आवश्यक आहे.
- आपल्या समाजातील विविधता प्रतिबिंबित करणाऱ्या डेटासेट्समध्ये गुंतवणूक करणे.
- पक्षपात ओळखण्यासाठी आणि तो सुधारण्यासाठी चांगल्या पद्धती विकसित करणे.

मॉडेल तयार करणे आणि वापरण्यात अन्याय स्पष्टपणे दिसतो अशा वास्तविक जीवनातील परिस्थितींचा विचार करा. आणखी काय विचारात घ्यायला हवे?

## [पाठानंतरचा क्विझ](https://ff-quizzes.netlify.app/en/ml/)
## पुनरावलोकन आणि स्व-अभ्यास

या धड्यात, तुम्ही मशीन लर्निंगमध्ये जबाबदार AI समाविष्ट करण्यासाठी काही व्यावहारिक साधने शिकली आहेत.

या कार्यशाळेचे निरीक्षण करा आणि विषयांमध्ये अधिक खोलवर जा:

- जबाबदार AI डॅशबोर्ड: Besmira Nushi आणि Mehrnoosh Sameki यांच्याकडून RAI प्रत्यक्षात कार्यान्वित करण्यासाठी एकाच ठिकाणी सुविधा.

[![जबाबदार AI डॅशबोर्ड: प्रत्यक्षात RAI कार्यान्वित करण्यासाठी एकाच ठिकाणी सुविधा](https://img.youtube.com/vi/f1oaDNl3djg/0.jpg)](https://www.youtube.com/watch?v=f1oaDNl3djg "जबाबदार AI डॅशबोर्ड: प्रत्यक्षात RAI कार्यान्वित करण्यासाठी एकाच ठिकाणी सुविधा")

> 🎥 वरील प्रतिमेवर क्लिक करा: जबाबदार AI डॅशबोर्ड: प्रत्यक्षात RAI कार्यान्वित करण्यासाठी एकाच ठिकाणी सुविधा Besmira Nushi आणि Mehrnoosh Sameki यांच्याकडून.

जबाबदार AI आणि अधिक विश्वासार्ह मॉडेल्स तयार करण्याबद्दल अधिक जाणून घेण्यासाठी खालील साहित्याचा संदर्भ घ्या:

- ML मॉडेल्स डीबग करण्यासाठी Microsoftचे RAI डॅशबोर्ड टूल्स: [जबाबदार AI टूल्स संसाधने](https://aka.ms/rai-dashboard)

- जबाबदार AI टूलकिट एक्सप्लोर करा: [Github](https://github.com/microsoft/responsible-ai-toolbox)

- Microsoftचे RAI संसाधन केंद्र: [जबाबदार AI संसाधने – Microsoft AI](https://www.microsoft.com/ai/responsible-ai-resources?activetab=pivot1%3aprimaryr4)

- Microsoftचे FATE संशोधन गट: [FATE: AI मध्ये न्याय, जबाबदारी, पारदर्शकता आणि नैतिकता - Microsoft Research](https://www.microsoft.com/research/theme/fate/)

## असाइनमेंट

[RAI डॅशबोर्ड एक्सप्लोर करा](assignment.md)

---

**अस्वीकरण**:  
हा दस्तऐवज AI भाषांतर सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) चा वापर करून भाषांतरित करण्यात आला आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी, कृपया लक्षात घ्या की स्वयंचलित भाषांतरांमध्ये त्रुटी किंवा अचूकतेचा अभाव असू शकतो. मूळ भाषेतील मूळ दस्तऐवज हा अधिकृत स्रोत मानला जावा. महत्त्वाच्या माहितीसाठी व्यावसायिक मानवी भाषांतराची शिफारस केली जाते. या भाषांतराचा वापर केल्यामुळे उद्भवणाऱ्या कोणत्याही गैरसमज किंवा चुकीच्या अर्थासाठी आम्ही जबाबदार राहणार नाही.