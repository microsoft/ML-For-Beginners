<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1a6e9e46b34a2e559fbbfc1f95397c7b",
  "translation_date": "2025-09-06T07:58:54+00:00",
  "source_file": "4-Classification/2-Classifiers-1/README.md",
  "language_code": "tr"
}
-->
# Yemek KÃ¼ltÃ¼rÃ¼ SÄ±nÄ±flandÄ±rÄ±cÄ±larÄ± 1

Bu derste, Ã¶nceki derste kaydettiÄŸiniz dengeli ve temiz yemek kÃ¼ltÃ¼rleri verileriyle dolu veri setini kullanacaksÄ±nÄ±z.

Bu veri setini, _bir grup malzemeye dayanarak belirli bir ulusal yemek kÃ¼ltÃ¼rÃ¼nÃ¼ tahmin etmek_ iÃ§in Ã§eÅŸitli sÄ±nÄ±flandÄ±rÄ±cÄ±larla kullanacaksÄ±nÄ±z. Bunu yaparken, algoritmalarÄ±n sÄ±nÄ±flandÄ±rma gÃ¶revlerinde nasÄ±l kullanÄ±labileceÄŸi hakkÄ±nda daha fazla bilgi edineceksiniz.

## [Ders Ã–ncesi Testi](https://ff-quizzes.netlify.app/en/ml/)
# HazÄ±rlÄ±k

[1. Ders](../1-Introduction/README.md)'i tamamladÄ±ÄŸÄ±nÄ±zÄ± varsayarak, bu dÃ¶rt ders iÃ§in kÃ¶k `/data` klasÃ¶rÃ¼nde _cleaned_cuisines.csv_ dosyasÄ±nÄ±n bulunduÄŸundan emin olun.

## AlÄ±ÅŸtÄ±rma - ulusal bir yemek kÃ¼ltÃ¼rÃ¼nÃ¼ tahmin etme

1. Bu dersin _notebook.ipynb_ klasÃ¶rÃ¼nde Ã§alÄ±ÅŸarak, Pandas kÃ¼tÃ¼phanesiyle birlikte bu dosyayÄ± iÃ§e aktarÄ±n:

    ```python
    import pandas as pd
    cuisines_df = pd.read_csv("../data/cleaned_cuisines.csv")
    cuisines_df.head()
    ```

    Veriler ÅŸu ÅŸekilde gÃ¶rÃ¼nÃ¼yor:

|     | Unnamed: 0 | cuisine | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood | yam | yeast | yogurt | zucchini |
| --- | ---------- | ------- | ------ | -------- | ----- | ---------- | ----- | ------------ | ------- | -------- | --- | ------- | ----------- | ---------- | ----------------------- | ---- | ---- | --- | ----- | ------ | -------- |
| 0   | 0          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 1   | 1          | indian  | 1      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 2   | 2          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 3   | 3          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 4   | 4          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 1      | 0        |

1. Åimdi birkaÃ§ kÃ¼tÃ¼phane daha iÃ§e aktarÄ±n:

    ```python
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    from sklearn.svm import SVC
    import numpy as np
    ```

1. X ve y koordinatlarÄ±nÄ± eÄŸitim iÃ§in iki veri Ã§erÃ§evesine ayÄ±rÄ±n. `cuisine` etiketler veri Ã§erÃ§evesi olabilir:

    ```python
    cuisines_label_df = cuisines_df['cuisine']
    cuisines_label_df.head()
    ```

    ÅÃ¶yle gÃ¶rÃ¼necek:

    ```output
    0    indian
    1    indian
    2    indian
    3    indian
    4    indian
    Name: cuisine, dtype: object
    ```

1. `Unnamed: 0` sÃ¼tununu ve `cuisine` sÃ¼tununu `drop()` kullanarak kaldÄ±rÄ±n. Geri kalan verileri eÄŸitilebilir Ã¶zellikler olarak kaydedin:

    ```python
    cuisines_feature_df = cuisines_df.drop(['Unnamed: 0', 'cuisine'], axis=1)
    cuisines_feature_df.head()
    ```

    Ã–zellikleriniz ÅŸu ÅŸekilde gÃ¶rÃ¼necek:

|      | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | artemisia | artichoke |  ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood |  yam | yeast | yogurt | zucchini |
| ---: | -----: | -------: | ----: | ---------: | ----: | -----------: | ------: | -------: | --------: | --------: | ---: | ------: | ----------: | ---------: | ----------------------: | ---: | ---: | ---: | ----: | -----: | -------: |
|    0 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    1 |      1 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    2 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    3 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    4 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      1 |        0 | 0 |

ArtÄ±k modelinizi eÄŸitmeye hazÄ±rsÄ±nÄ±z!

## SÄ±nÄ±flandÄ±rÄ±cÄ± SeÃ§imi

Verileriniz temiz ve eÄŸitime hazÄ±r olduÄŸuna gÃ¶re, iÅŸ iÃ§in hangi algoritmayÄ± kullanacaÄŸÄ±nÄ±za karar vermelisiniz.

Scikit-learn, sÄ±nÄ±flandÄ±rmayÄ± Denetimli Ã–ÄŸrenme altÄ±nda gruplandÄ±rÄ±r ve bu kategoride birÃ§ok sÄ±nÄ±flandÄ±rma yÃ¶ntemi bulabilirsiniz. [Ã‡eÅŸitlilik](https://scikit-learn.org/stable/supervised_learning.html) ilk bakÄ±ÅŸta oldukÃ§a kafa karÄ±ÅŸtÄ±rÄ±cÄ± olabilir. AÅŸaÄŸÄ±daki yÃ¶ntemlerin tÃ¼mÃ¼ sÄ±nÄ±flandÄ±rma tekniklerini iÃ§erir:

- DoÄŸrusal Modeller
- Destek VektÃ¶r Makineleri
- Stokastik Gradyan Ä°niÅŸi
- En YakÄ±n KomÅŸular
- Gauss SÃ¼reÃ§leri
- Karar AÄŸaÃ§larÄ±
- Toplu yÃ¶ntemler (oylama sÄ±nÄ±flandÄ±rÄ±cÄ±)
- Ã‡ok sÄ±nÄ±flÄ± ve Ã§ok Ã§Ä±kÄ±ÅŸlÄ± algoritmalar (Ã§ok sÄ±nÄ±flÄ± ve Ã§ok etiketli sÄ±nÄ±flandÄ±rma, Ã§ok sÄ±nÄ±flÄ±-Ã§ok Ã§Ä±kÄ±ÅŸlÄ± sÄ±nÄ±flandÄ±rma)

> Verileri sÄ±nÄ±flandÄ±rmak iÃ§in [sinir aÄŸlarÄ±nÄ±](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#classification) da kullanabilirsiniz, ancak bu dersin kapsamÄ± dÄ±ÅŸÄ±ndadÄ±r.

### Hangi sÄ±nÄ±flandÄ±rÄ±cÄ±yÄ± seÃ§meli?

Peki, hangi sÄ±nÄ±flandÄ±rÄ±cÄ±yÄ± seÃ§melisiniz? Ã‡oÄŸu zaman, birkaÃ§Ä±nÄ± deneyip iyi bir sonuÃ§ aramak bir test yÃ¶ntemi olabilir. Scikit-learn, oluÅŸturulmuÅŸ bir veri setinde KNeighbors, SVC iki ÅŸekilde, GaussianProcessClassifier, DecisionTreeClassifier, RandomForestClassifier, MLPClassifier, AdaBoostClassifier, GaussianNB ve QuadraticDiscriminationAnalysis'Ä± karÅŸÄ±laÅŸtÄ±ran bir [yan yana karÅŸÄ±laÅŸtÄ±rma](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) sunar ve sonuÃ§larÄ± gÃ¶rselleÅŸtirir:

![sÄ±nÄ±flandÄ±rÄ±cÄ±larÄ±n karÅŸÄ±laÅŸtÄ±rmasÄ±](../../../../4-Classification/2-Classifiers-1/images/comparison.png)
> Grafikler Scikit-learn belgelerinde oluÅŸturulmuÅŸtur

> AutoML, bu karÅŸÄ±laÅŸtÄ±rmalarÄ± bulutta Ã§alÄ±ÅŸtÄ±rarak ve verileriniz iÃ§in en iyi algoritmayÄ± seÃ§menize olanak tanÄ±yarak bu sorunu kolayca Ã§Ã¶zer. [Buradan deneyin](https://docs.microsoft.com/learn/modules/automate-model-selection-with-azure-automl/?WT.mc_id=academic-77952-leestott)

### Daha iyi bir yaklaÅŸÄ±m

Ancak rastgele tahmin etmekten daha iyi bir yol, bu indirilebilir [ML Cheat Sheet](https://docs.microsoft.com/azure/machine-learning/algorithm-cheat-sheet?WT.mc_id=academic-77952-leestott) Ã¼zerindeki fikirleri takip etmektir. Burada, Ã§ok sÄ±nÄ±flÄ± problemimiz iÃ§in bazÄ± seÃ§eneklerimiz olduÄŸunu keÅŸfediyoruz:

![Ã§ok sÄ±nÄ±flÄ± problemler iÃ§in cheat sheet](../../../../4-Classification/2-Classifiers-1/images/cheatsheet.png)
> Microsoft'un Algoritma Cheat Sheet'inin bir bÃ¶lÃ¼mÃ¼, Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma seÃ§eneklerini detaylandÄ±rÄ±yor

âœ… Bu cheat sheet'i indirin, yazdÄ±rÄ±n ve duvarÄ±nÄ±za asÄ±n!

### MantÄ±k YÃ¼rÃ¼tme

KÄ±sÄ±tlamalarÄ±mÄ±zÄ± gÃ¶z Ã¶nÃ¼nde bulundurarak farklÄ± yaklaÅŸÄ±mlarÄ± mantÄ±kla deÄŸerlendirelim:

- **Sinir aÄŸlarÄ± Ã§ok aÄŸÄ±r**. Temiz ama minimal veri setimiz ve eÄŸitimi yerel olarak notebooklar Ã¼zerinden Ã§alÄ±ÅŸtÄ±rdÄ±ÄŸÄ±mÄ±z gerÃ§eÄŸi gÃ¶z Ã¶nÃ¼ne alÄ±ndÄ±ÄŸÄ±nda, sinir aÄŸlarÄ± bu gÃ¶rev iÃ§in Ã§ok aÄŸÄ±rdÄ±r.
- **Ä°ki sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rÄ±cÄ± yok**. Ä°ki sÄ±nÄ±flÄ± bir sÄ±nÄ±flandÄ±rÄ±cÄ± kullanmÄ±yoruz, bu nedenle one-vs-all seÃ§eneÄŸi eleniyor.
- **Karar aÄŸacÄ± veya lojistik regresyon iÅŸe yarayabilir**. Ã‡ok sÄ±nÄ±flÄ± veriler iÃ§in bir karar aÄŸacÄ± veya lojistik regresyon iÅŸe yarayabilir.
- **Ã‡ok sÄ±nÄ±flÄ± Boosted Karar AÄŸaÃ§larÄ± farklÄ± bir problemi Ã§Ã¶zer**. Ã‡ok sÄ±nÄ±flÄ± Boosted Karar AÄŸacÄ±, sÄ±ralamalar oluÅŸturmak iÃ§in tasarlanmÄ±ÅŸ parametrik olmayan gÃ¶revler iÃ§in en uygundur, bu nedenle bizim iÃ§in kullanÄ±ÅŸlÄ± deÄŸildir.

### Scikit-learn KullanÄ±mÄ±

Verilerimizi analiz etmek iÃ§in Scikit-learn kullanacaÄŸÄ±z. Ancak, Scikit-learn'de lojistik regresyonu kullanmanÄ±n birÃ§ok yolu vardÄ±r. GeÃ§ilecek [parametrelere](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regressio#sklearn.linear_model.LogisticRegression) bir gÃ¶z atÄ±n.

Temelde, Scikit-learn'den lojistik regresyon yapmasÄ±nÄ± istediÄŸimizde belirtmemiz gereken iki Ã¶nemli parametre vardÄ±r - `multi_class` ve `solver`. `multi_class` deÄŸeri belirli bir davranÄ±ÅŸÄ± uygular. Solver'Ä±n deÄŸeri ise hangi algoritmanÄ±n kullanÄ±lacaÄŸÄ±nÄ± belirler. TÃ¼m solver'lar tÃ¼m `multi_class` deÄŸerleriyle eÅŸleÅŸtirilemez.

Belgelerden Ã¶ÄŸrendiÄŸimize gÃ¶re, Ã§ok sÄ±nÄ±flÄ± durumda eÄŸitim algoritmasÄ±:

- **one-vs-rest (OvR) ÅŸemasÄ±nÄ± kullanÄ±r**, eÄŸer `multi_class` seÃ§eneÄŸi `ovr` olarak ayarlanmÄ±ÅŸsa
- **Ã§apraz entropi kaybÄ±nÄ± kullanÄ±r**, eÄŸer `multi_class` seÃ§eneÄŸi `multinomial` olarak ayarlanmÄ±ÅŸsa. (Åu anda `multinomial` seÃ§eneÄŸi yalnÄ±zca â€˜lbfgsâ€™, â€˜sagâ€™, â€˜sagaâ€™ ve â€˜newton-cgâ€™ solver'larÄ± tarafÄ±ndan desteklenmektedir.)

> ğŸ“ Buradaki 'ÅŸema', 'ovr' (one-vs-rest) veya 'multinomial' olabilir. Lojistik regresyon aslÄ±nda ikili sÄ±nÄ±flandÄ±rmayÄ± desteklemek iÃ§in tasarlandÄ±ÄŸÄ±ndan, bu ÅŸemalar onun Ã§ok sÄ±nÄ±flÄ± sÄ±nÄ±flandÄ±rma gÃ¶revlerini daha iyi ele almasÄ±na olanak tanÄ±r. [kaynak](https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/)

> ğŸ“ 'solver', "optimizasyon probleminde kullanÄ±lacak algoritma" olarak tanÄ±mlanÄ±r. [kaynak](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regressio#sklearn.linear_model.LogisticRegression).

Scikit-learn, solver'larÄ±n farklÄ± veri yapÄ±larÄ±nÄ±n sunduÄŸu zorluklarÄ± nasÄ±l ele aldÄ±ÄŸÄ±nÄ± aÃ§Ä±klamak iÃ§in ÅŸu tabloyu sunar:

![solver'lar](../../../../4-Classification/2-Classifiers-1/images/solvers.png)

## AlÄ±ÅŸtÄ±rma - veriyi bÃ¶lmek

Son dersinizde lojistik regresyon hakkÄ±nda bilgi edindiÄŸiniz iÃ§in, ilk eÄŸitim denemeniz iÃ§in lojistik regresyona odaklanabiliriz.
Verilerinizi `train_test_split()` Ã§aÄŸÄ±rarak eÄŸitim ve test gruplarÄ±na ayÄ±rÄ±n:

```python
X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)
```

## AlÄ±ÅŸtÄ±rma - lojistik regresyon uygulamak

Ã‡ok sÄ±nÄ±flÄ± durumu kullandÄ±ÄŸÄ±nÄ±z iÃ§in hangi _ÅŸemayÄ±_ kullanacaÄŸÄ±nÄ±zÄ± ve hangi _solver'Ä±_ ayarlayacaÄŸÄ±nÄ±zÄ± seÃ§meniz gerekiyor. Multi_class ayarÄ± `ovr` ve solver ayarÄ± `liblinear` olan LogisticRegression kullanarak eÄŸitin.

1. Multi_class `ovr` ve solver `liblinear` olarak ayarlanmÄ±ÅŸ bir lojistik regresyon oluÅŸturun:

    ```python
    lr = LogisticRegression(multi_class='ovr',solver='liblinear')
    model = lr.fit(X_train, np.ravel(y_train))
    
    accuracy = model.score(X_test, y_test)
    print ("Accuracy is {}".format(accuracy))
    ```

    âœ… VarsayÄ±lan olarak sÄ±kÃ§a ayarlanan `lbfgs` gibi farklÄ± bir solver deneyin
Not: Verilerinizi dÃ¼zleÅŸtirmeniz gerektiÄŸinde Pandas [`ravel`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.ravel.html) fonksiyonunu kullanÄ±n.
DoÄŸruluk oranÄ± **%80**'in Ã¼zerinde oldukÃ§a iyi!

1. Bu modeli bir veri satÄ±rÄ±nÄ± test ederek (#50) Ã§alÄ±ÅŸÄ±rken gÃ¶rebilirsiniz:

    ```python
    print(f'ingredients: {X_test.iloc[50][X_test.iloc[50]!=0].keys()}')
    print(f'cuisine: {y_test.iloc[50]}')
    ```

    SonuÃ§ yazdÄ±rÄ±lÄ±r:

   ```output
   ingredients: Index(['cilantro', 'onion', 'pea', 'potato', 'tomato', 'vegetable_oil'], dtype='object')
   cuisine: indian
   ```

   âœ… FarklÄ± bir satÄ±r numarasÄ± deneyin ve sonuÃ§larÄ± kontrol edin.

1. Daha derine inerek, bu tahminin doÄŸruluÄŸunu kontrol edebilirsiniz:

    ```python
    test= X_test.iloc[50].values.reshape(-1, 1).T
    proba = model.predict_proba(test)
    classes = model.classes_
    resultdf = pd.DataFrame(data=proba, columns=classes)
    
    topPrediction = resultdf.T.sort_values(by=[0], ascending = [False])
    topPrediction.head()
    ```

    SonuÃ§ yazdÄ±rÄ±lÄ±r - Hint mutfaÄŸÄ± en iyi tahmin olarak, yÃ¼ksek bir olasÄ±lÄ±kla:

    |          |        0 |
    | -------: | -------: |
    |   indian | 0.715851 |
    |  chinese | 0.229475 |
    | japanese | 0.029763 |
    |   korean | 0.017277 |
    |     thai | 0.007634 |

    âœ… Modelin neden Hint mutfaÄŸÄ± olduÄŸundan bu kadar emin olduÄŸunu aÃ§Ä±klayabilir misiniz?

1. Regresyon derslerinde yaptÄ±ÄŸÄ±nÄ±z gibi bir sÄ±nÄ±flandÄ±rma raporu yazdÄ±rarak daha fazla ayrÄ±ntÄ± elde edin:

    ```python
    y_pred = model.predict(X_test)
    print(classification_report(y_test,y_pred))
    ```

    |              | precision | recall | f1-score | support |
    | ------------ | --------- | ------ | -------- | ------- |
    | chinese      | 0.73      | 0.71   | 0.72     | 229     |
    | indian       | 0.91      | 0.93   | 0.92     | 254     |
    | japanese     | 0.70      | 0.75   | 0.72     | 220     |
    | korean       | 0.86      | 0.76   | 0.81     | 242     |
    | thai         | 0.79      | 0.85   | 0.82     | 254     |
    | accuracy     | 0.80      | 1199   |          |         |
    | macro avg    | 0.80      | 0.80   | 0.80     | 1199    |
    | weighted avg | 0.80      | 0.80   | 0.80     | 1199    |

## ğŸš€Meydan Okuma

Bu derste, temizlenmiÅŸ verilerinizi kullanarak bir dizi malzemeye dayanarak ulusal bir mutfaÄŸÄ± tahmin edebilen bir makine Ã¶ÄŸrenimi modeli oluÅŸturdunuz. Scikit-learn'Ã¼n verileri sÄ±nÄ±flandÄ±rmak iÃ§in sunduÄŸu birÃ§ok seÃ§eneÄŸi incelemek iÃ§in biraz zaman ayÄ±rÄ±n. Sahne arkasÄ±nda neler olduÄŸunu anlamak iÃ§in 'solver' kavramÄ±nÄ± daha derinlemesine araÅŸtÄ±rÄ±n.

## [Ders sonrasÄ± test](https://ff-quizzes.netlify.app/en/ml/)

## GÃ¶zden GeÃ§irme ve Kendi Kendine Ã‡alÄ±ÅŸma

Lojistik regresyonun matematiÄŸini biraz daha derinlemesine inceleyin: [bu derste](https://people.eecs.berkeley.edu/~russell/classes/cs194/f11/lectures/CS194%20Fall%202011%20Lecture%2006.pdf)
## Ã–dev 

[Solver'larÄ± inceleyin](assignment.md)

---

**Feragatname**:  
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±k iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalardan sorumlu deÄŸiliz.