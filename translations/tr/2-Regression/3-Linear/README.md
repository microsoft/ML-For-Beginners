<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "40e64f004f3cb50aa1d8661672d3cd92",
  "translation_date": "2025-09-06T07:44:07+00:00",
  "source_file": "2-Regression/3-Linear/README.md",
  "language_code": "tr"
}
-->
# Scikit-learn ile regresyon modeli oluÅŸturma: dÃ¶rt farklÄ± regresyon yÃ¶ntemi

![DoÄŸrusal ve polinomial regresyon infografiÄŸi](../../../../2-Regression/3-Linear/images/linear-polynomial.png)
> Ä°nfografik: [Dasani Madipalli](https://twitter.com/dasani_decoded)
## [Ders Ã¶ncesi sÄ±nav](https://ff-quizzes.netlify.app/en/ml/)

> ### [Bu ders R dilinde de mevcut!](../../../../2-Regression/3-Linear/solution/R/lesson_3.html)
### GiriÅŸ 

Åimdiye kadar, bu derste kullanacaÄŸÄ±mÄ±z kabak fiyatlandÄ±rma veri setinden toplanan Ã¶rnek verilerle regresyonun ne olduÄŸunu keÅŸfettiniz. AyrÄ±ca bunu Matplotlib kullanarak gÃ¶rselleÅŸtirdiniz.

ArtÄ±k ML iÃ§in regresyonu daha derinlemesine incelemeye hazÄ±rsÄ±nÄ±z. GÃ¶rselleÅŸtirme, verileri anlamlandÄ±rmanÄ±za olanak tanÄ±rken, Makine Ã–ÄŸrenimi'nin gerÃ§ek gÃ¼cÃ¼ _modelleri eÄŸitmekten_ gelir. Modeller, veri baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± otomatik olarak yakalamak iÃ§in geÃ§miÅŸ verilere dayanarak eÄŸitilir ve modelin daha Ã¶nce gÃ¶rmediÄŸi yeni veriler iÃ§in sonuÃ§larÄ± tahmin etmenize olanak tanÄ±r.

Bu derste, regresyonun iki tÃ¼rÃ¼ hakkÄ±nda daha fazla bilgi edineceksiniz: _temel doÄŸrusal regresyon_ ve _polinomial regresyon_, bu tekniklerin altÄ±nda yatan bazÄ± matematiksel kavramlarla birlikte. Bu modeller, farklÄ± giriÅŸ verilerine baÄŸlÄ± olarak kabak fiyatlarÄ±nÄ± tahmin etmemize olanak tanÄ±yacak.

[![BaÅŸlangÄ±Ã§ seviyesinde ML - DoÄŸrusal Regresyonu Anlamak](https://img.youtube.com/vi/CRxFT8oTDMg/0.jpg)](https://youtu.be/CRxFT8oTDMg "BaÅŸlangÄ±Ã§ seviyesinde ML - DoÄŸrusal Regresyonu Anlamak")

> ğŸ¥ DoÄŸrusal regresyonun kÄ±sa bir video Ã¶zeti iÃ§in yukarÄ±daki gÃ¶rsele tÄ±klayÄ±n.

> Bu mÃ¼fredat boyunca, matematik bilgisi minimum dÃ¼zeyde varsayÄ±lmaktadÄ±r ve diÄŸer alanlardan gelen Ã¶ÄŸrenciler iÃ§in eriÅŸilebilir hale getirmeyi amaÃ§lÄ±yoruz. Bu nedenle, notlar, ğŸ§® matematiksel aÃ§Ä±klamalar, diyagramlar ve diÄŸer Ã¶ÄŸrenme araÃ§larÄ±na dikkat edin.

### Ã–n KoÅŸul

Åimdiye kadar, incelediÄŸimiz kabak verilerinin yapÄ±sÄ±na aÅŸina olmalÄ±sÄ±nÄ±z. Bu dersin _notebook.ipynb_ dosyasÄ±nda Ã¶nceden yÃ¼klenmiÅŸ ve temizlenmiÅŸ olarak bulabilirsiniz. Dosyada, kabak fiyatÄ± yeni bir veri Ã§erÃ§evesinde bushel baÅŸÄ±na gÃ¶sterilmektedir. Bu not defterlerini Visual Studio Code'daki Ã§ekirdeklerde Ã§alÄ±ÅŸtÄ±rabildiÄŸinizden emin olun.

### HazÄ±rlÄ±k

Bu verileri yÃ¼klediÄŸinizi hatÄ±rlatmak isteriz, bÃ¶ylece sorular sorabilirsiniz.

- Kabak almak iÃ§in en iyi zaman ne zaman?
- Mini kabaklarÄ±n bir kutusunun fiyatÄ± ne kadar olabilir?
- KabaklarÄ± yarÄ±m bushel sepetlerde mi yoksa 1 1/9 bushel kutularÄ±nda mÄ± almalÄ±yÄ±m?
Bu verileri daha fazla incelemeye devam edelim.

Ã–nceki derste, bir Pandas veri Ã§erÃ§evesi oluÅŸturdunuz ve orijinal veri setinin bir kÄ±smÄ±nÄ± bushel baÅŸÄ±na fiyatlandÄ±rmayÄ± standartlaÅŸtÄ±rarak doldurdunuz. Ancak bunu yaparak, yalnÄ±zca sonbahar aylarÄ± iÃ§in yaklaÅŸÄ±k 400 veri noktasÄ± toplayabildiniz.

Bu dersin eÅŸlik eden not defterinde Ã¶nceden yÃ¼klenmiÅŸ verilere bir gÃ¶z atÄ±n. Veriler Ã¶nceden yÃ¼klenmiÅŸ ve ay verilerini gÃ¶stermek iÃ§in ilk bir saÃ§Ä±lÄ±m grafiÄŸi Ã§izilmiÅŸtir. Belki verileri daha fazla temizleyerek verilerin doÄŸasÄ± hakkÄ±nda biraz daha ayrÄ±ntÄ± elde edebiliriz.

## DoÄŸrusal regresyon Ã§izgisi

1. Derste Ã¶ÄŸrendiÄŸiniz gibi, doÄŸrusal regresyon Ã§alÄ±ÅŸmasÄ±nÄ±n amacÄ± bir Ã§izgi Ã§izmek ve:

- **DeÄŸiÅŸken iliÅŸkilerini gÃ¶stermek**. DeÄŸiÅŸkenler arasÄ±ndaki iliÅŸkiyi gÃ¶stermek
- **Tahminler yapmak**. Yeni bir veri noktasÄ±nÄ±n bu Ã§izgiyle iliÅŸkili olarak nerede yer alacaÄŸÄ±nÄ± doÄŸru bir ÅŸekilde tahmin etmek.

Bu tÃ¼r bir Ã§izgi Ã§izmek iÃ§in **En KÃ¼Ã§Ã¼k Kareler Regresyonu** kullanÄ±lmasÄ± yaygÄ±ndÄ±r. 'En kÃ¼Ã§Ã¼k kareler' terimi, regresyon Ã§izgisinin etrafÄ±ndaki tÃ¼m veri noktalarÄ±nÄ±n karelerinin alÄ±nmasÄ± ve ardÄ±ndan toplanmasÄ± anlamÄ±na gelir. Ä°deal olarak, bu son toplamÄ±n mÃ¼mkÃ¼n olduÄŸunca kÃ¼Ã§Ã¼k olmasÄ± gerekir, Ã§Ã¼nkÃ¼ dÃ¼ÅŸÃ¼k hata sayÄ±sÄ± veya `en kÃ¼Ã§Ã¼k kareler` istiyoruz.

Bunu yapmamÄ±zÄ±n nedeni, tÃ¼m veri noktalarÄ±mÄ±zdan en az toplam mesafeye sahip bir Ã§izgi modellemek istememizdir. AyrÄ±ca terimleri toplamadan Ã¶nce karelerini alÄ±rÄ±z Ã§Ã¼nkÃ¼ yÃ¶nÃ¼nden ziyade bÃ¼yÃ¼klÃ¼ÄŸÃ¼yle ilgileniyoruz.

> **ğŸ§® MatematiÄŸi gÃ¶ster**
> 
> Bu Ã§izgi, _en iyi uyum Ã§izgisi_ olarak adlandÄ±rÄ±lÄ±r ve [bir denklemle](https://en.wikipedia.org/wiki/Simple_linear_regression) ifade edilebilir: 
> 
> ```
> Y = a + bX
> ```
>
> `X` 'aÃ§Ä±klayÄ±cÄ± deÄŸiÅŸken'dir. `Y` 'baÄŸÄ±mlÄ± deÄŸiÅŸken'dir. Ã‡izginin eÄŸimi `b` ve `a` y-kesiÅŸimidir, bu da `X = 0` olduÄŸunda `Y` deÄŸerine karÅŸÄ±lÄ±k gelir.
>
>![eÄŸimi hesapla](../../../../2-Regression/3-Linear/images/slope.png)
>
> Ä°lk olarak, eÄŸim `b` hesaplanÄ±r. Ä°nfografik: [Jen Looper](https://twitter.com/jenlooper)
>
> BaÅŸka bir deyiÅŸle, kabak verilerinin orijinal sorusuna atÄ±fta bulunarak: "aylara gÃ¶re bushel baÅŸÄ±na kabak fiyatÄ±nÄ± tahmin et", `X` fiyatÄ± ifade ederken `Y` satÄ±ÅŸ ayÄ±nÄ± ifade eder.
>
>![denklemi tamamla](../../../../2-Regression/3-Linear/images/calculation.png)
>
> `Y` deÄŸerini hesaplayÄ±n. EÄŸer yaklaÅŸÄ±k 4 dolar Ã¶dÃ¼yorsanÄ±z, bu Nisan olmalÄ±! Ä°nfografik: [Jen Looper](https://twitter.com/jenlooper)
>
> Ã‡izgiyi hesaplayan matematik, Ã§izginin eÄŸimini gÃ¶stermelidir, bu da aynÄ± zamanda y-kesiÅŸimine baÄŸlÄ±dÄ±r, yani `X = 0` olduÄŸunda `Y`'nin konumlandÄ±ÄŸÄ± yer.
>
> Bu deÄŸerlerin hesaplama yÃ¶ntemini [Math is Fun](https://www.mathsisfun.com/data/least-squares-regression.html) web sitesinde gÃ¶zlemleyebilirsiniz. AyrÄ±ca, sayÄ±larÄ±n deÄŸerlerinin Ã§izgiyi nasÄ±l etkilediÄŸini gÃ¶rmek iÃ§in [bu En KÃ¼Ã§Ã¼k Kareler hesaplayÄ±cÄ±sÄ±nÄ±](https://www.mathsisfun.com/data/least-squares-calculator.html) ziyaret edin.

## Korelasyon

AnlamanÄ±z gereken bir diÄŸer terim, verilen X ve Y deÄŸiÅŸkenleri arasÄ±ndaki **Korelasyon KatsayÄ±sÄ±**dÄ±r. Bir saÃ§Ä±lÄ±m grafiÄŸi kullanarak bu katsayÄ±yÄ± hÄ±zlÄ±ca gÃ¶rselleÅŸtirebilirsiniz. Veri noktalarÄ±nÄ±n dÃ¼zgÃ¼n bir Ã§izgide daÄŸÄ±ldÄ±ÄŸÄ± bir grafik yÃ¼ksek korelasyona sahiptir, ancak X ve Y arasÄ±nda her yerde daÄŸÄ±lmÄ±ÅŸ veri noktalarÄ±na sahip bir grafik dÃ¼ÅŸÃ¼k korelasyona sahiptir.

Ä°yi bir doÄŸrusal regresyon modeli, En KÃ¼Ã§Ã¼k Kareler Regresyonu yÃ¶ntemiyle bir regresyon Ã§izgisi kullanarak 1'e yakÄ±n (0'dan uzak) bir Korelasyon KatsayÄ±sÄ±na sahip olan modeldir.

âœ… Bu dersin eÅŸlik eden not defterini Ã§alÄ±ÅŸtÄ±rÄ±n ve Ay ile Fiyat arasÄ±ndaki saÃ§Ä±lÄ±m grafiÄŸine bakÄ±n. Kabak satÄ±ÅŸlarÄ± iÃ§in Ay ile Fiyat arasÄ±ndaki veri, saÃ§Ä±lÄ±m grafiÄŸine gÃ¶re gÃ¶rsel yorumunuza gÃ¶re yÃ¼ksek veya dÃ¼ÅŸÃ¼k korelasyona sahip gibi gÃ¶rÃ¼nÃ¼yor mu? Bu durum, `Ay` yerine daha ince bir Ã¶lÃ§Ã¼m kullanÄ±rsanÄ±z, Ã¶rneÄŸin *yÄ±lÄ±n gÃ¼nÃ¼* (yÄ±lÄ±n baÅŸlangÄ±cÄ±ndan itibaren geÃ§en gÃ¼n sayÄ±sÄ±) deÄŸiÅŸir mi?

AÅŸaÄŸÄ±daki kodda, verileri temizlediÄŸimizi ve aÅŸaÄŸÄ±daki gibi bir veri Ã§erÃ§evesi elde ettiÄŸimizi varsayacaÄŸÄ±z:

ID | Ay | YÄ±lÄ±nGÃ¼nÃ¼ | Ã‡eÅŸit | Åehir | Paket | DÃ¼ÅŸÃ¼k Fiyat | YÃ¼ksek Fiyat | Fiyat
---|----|-----------|-------|-------|-------|-------------|--------------|------
70 | 9 | 267 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 15.0 | 15.0 | 13.636364
71 | 9 | 267 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 18.0 | 18.0 | 16.363636
72 | 10 | 274 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 18.0 | 18.0 | 16.363636
73 | 10 | 274 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 17.0 | 17.0 | 15.454545
74 | 10 | 281 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 15.0 | 15.0 | 13.636364

> Verileri temizleme kodu [`notebook.ipynb`](../../../../2-Regression/3-Linear/notebook.ipynb) dosyasÄ±nda mevcuttur. Ã–nceki derste yapÄ±lan aynÄ± temizleme adÄ±mlarÄ±nÄ± uyguladÄ±k ve aÅŸaÄŸÄ±daki ifadeyi kullanarak `YÄ±lÄ±nGÃ¼nÃ¼` sÃ¼tununu hesapladÄ±k:

```python
day_of_year = pd.to_datetime(pumpkins['Date']).apply(lambda dt: (dt-datetime(dt.year,1,1)).days)
```

ArtÄ±k doÄŸrusal regresyonun arkasÄ±ndaki matematiÄŸi anladÄ±ÄŸÄ±nÄ±za gÃ¶re, bir Regresyon modeli oluÅŸturarak hangi kabak paketinin en iyi kabak fiyatlarÄ±na sahip olacaÄŸÄ±nÄ± tahmin edip edemeyeceÄŸimizi gÃ¶relim. Bir tatil kabak bahÃ§esi iÃ§in kabak satÄ±n alan biri, bahÃ§e iÃ§in kabak paketlerini optimize etmek amacÄ±yla bu bilgiye ihtiyaÃ§ duyabilir.

## Korelasyon ArayÄ±ÅŸÄ±

[![BaÅŸlangÄ±Ã§ seviyesinde ML - Korelasyon ArayÄ±ÅŸÄ±: DoÄŸrusal Regresyonun AnahtarÄ±](https://img.youtube.com/vi/uoRq-lW2eQo/0.jpg)](https://youtu.be/uoRq-lW2eQo "BaÅŸlangÄ±Ã§ seviyesinde ML - Korelasyon ArayÄ±ÅŸÄ±: DoÄŸrusal Regresyonun AnahtarÄ±")

> ğŸ¥ Korelasyonun kÄ±sa bir video Ã¶zeti iÃ§in yukarÄ±daki gÃ¶rsele tÄ±klayÄ±n.

Ã–nceki dersten muhtemelen farklÄ± aylar iÃ§in ortalama fiyatÄ±n ÅŸu ÅŸekilde gÃ¶rÃ¼ndÃ¼ÄŸÃ¼nÃ¼ gÃ¶rdÃ¼nÃ¼z:

<img alt="Ay bazÄ±nda ortalama fiyat" src="../2-Data/images/barchart.png" width="50%"/>

Bu, bir korelasyon olmasÄ± gerektiÄŸini ve `Ay` ile `Fiyat` veya `YÄ±lÄ±nGÃ¼nÃ¼` ile `Fiyat` arasÄ±ndaki iliÅŸkiyi tahmin etmek iÃ§in doÄŸrusal regresyon modeli eÄŸitmeye Ã§alÄ±ÅŸabileceÄŸimizi gÃ¶steriyor. Ä°ÅŸte ikinci iliÅŸkiyi gÃ¶steren saÃ§Ä±lÄ±m grafiÄŸi:

<img alt="Fiyat vs. YÄ±lÄ±n GÃ¼nÃ¼ saÃ§Ä±lÄ±m grafiÄŸi" src="images/scatter-dayofyear.png" width="50%" /> 

`corr` fonksiyonunu kullanarak bir korelasyon olup olmadÄ±ÄŸÄ±nÄ± gÃ¶relim:

```python
print(new_pumpkins['Month'].corr(new_pumpkins['Price']))
print(new_pumpkins['DayOfYear'].corr(new_pumpkins['Price']))
```

GÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re korelasyon oldukÃ§a kÃ¼Ã§Ã¼k, `Ay` iÃ§in -0.15 ve `YÄ±lÄ±nGÃ¼nÃ¼` iÃ§in -0.17, ancak baÅŸka Ã¶nemli bir iliÅŸki olabilir. FarklÄ± kabak Ã§eÅŸitlerine karÅŸÄ±lÄ±k gelen farklÄ± fiyat kÃ¼meleri var gibi gÃ¶rÃ¼nÃ¼yor. Bu hipotezi doÄŸrulamak iÃ§in, her kabak kategorisini farklÄ± bir renkle Ã§izelim. `scatter` Ã§izim fonksiyonuna bir `ax` parametresi geÃ§irerek tÃ¼m noktalarÄ± aynÄ± grafikte Ã§izebiliriz:

```python
ax=None
colors = ['red','blue','green','yellow']
for i,var in enumerate(new_pumpkins['Variety'].unique()):
    df = new_pumpkins[new_pumpkins['Variety']==var]
    ax = df.plot.scatter('DayOfYear','Price',ax=ax,c=colors[i],label=var)
```

<img alt="Fiyat vs. YÄ±lÄ±n GÃ¼nÃ¼ saÃ§Ä±lÄ±m grafiÄŸi" src="images/scatter-dayofyear-color.png" width="50%" /> 

AraÅŸtÄ±rmamÄ±z, Ã§eÅŸidin genel fiyat Ã¼zerinde satÄ±ÅŸ tarihinden daha fazla etkisi olduÄŸunu Ã¶ne sÃ¼rÃ¼yor. Bunu bir Ã§ubuk grafikle gÃ¶rebiliriz:

```python
new_pumpkins.groupby('Variety')['Price'].mean().plot(kind='bar')
```

<img alt="Ã‡eÅŸide gÃ¶re fiyat Ã§ubuk grafiÄŸi" src="images/price-by-variety.png" width="50%" /> 

Åimdi bir sÃ¼reliÄŸine yalnÄ±zca bir kabak Ã§eÅŸidine, 'pie type' Ã§eÅŸidine odaklanalÄ±m ve tarihin fiyat Ã¼zerindeki etkisini gÃ¶relim:

```python
pie_pumpkins = new_pumpkins[new_pumpkins['Variety']=='PIE TYPE']
pie_pumpkins.plot.scatter('DayOfYear','Price') 
```
<img alt="Fiyat vs. YÄ±lÄ±n GÃ¼nÃ¼ saÃ§Ä±lÄ±m grafiÄŸi" src="images/pie-pumpkins-scatter.png" width="50%" /> 

Åimdi `corr` fonksiyonunu kullanarak `Fiyat` ile `YÄ±lÄ±nGÃ¼nÃ¼` arasÄ±ndaki korelasyonu hesaplasak, yaklaÅŸÄ±k `-0.27` gibi bir deÄŸer elde ederiz - bu da tahmin edici bir model eÄŸitmenin mantÄ±klÄ± olduÄŸunu gÃ¶sterir.

> DoÄŸrusal regresyon modeli eÄŸitmeden Ã¶nce, verilerimizin temiz olduÄŸundan emin olmak Ã¶nemlidir. DoÄŸrusal regresyon eksik deÄŸerlerle iyi Ã§alÄ±ÅŸmaz, bu nedenle tÃ¼m boÅŸ hÃ¼crelerden kurtulmak mantÄ±klÄ±dÄ±r:

```python
pie_pumpkins.dropna(inplace=True)
pie_pumpkins.info()
```

Bir diÄŸer yaklaÅŸÄ±m, bu boÅŸ deÄŸerleri ilgili sÃ¼tunun ortalama deÄŸerleriyle doldurmak olabilir.

## Basit DoÄŸrusal Regresyon

[![BaÅŸlangÄ±Ã§ seviyesinde ML - Scikit-learn ile DoÄŸrusal ve Polinomial Regresyon](https://img.youtube.com/vi/e4c_UP2fSjg/0.jpg)](https://youtu.be/e4c_UP2fSjg "BaÅŸlangÄ±Ã§ seviyesinde ML - Scikit-learn ile DoÄŸrusal ve Polinomial Regresyon")

> ğŸ¥ DoÄŸrusal ve polinomial regresyonun kÄ±sa bir video Ã¶zeti iÃ§in yukarÄ±daki gÃ¶rsele tÄ±klayÄ±n.

DoÄŸrusal Regresyon modelimizi eÄŸitmek iÃ§in **Scikit-learn** kÃ¼tÃ¼phanesini kullanacaÄŸÄ±z.

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
```

BaÅŸlangÄ±Ã§ta, giriÅŸ deÄŸerlerini (Ã¶zellikler) ve beklenen Ã§Ä±ktÄ±yÄ± (etiket) ayrÄ± numpy dizilerine ayÄ±rÄ±yoruz:

```python
X = pie_pumpkins['DayOfYear'].to_numpy().reshape(-1,1)
y = pie_pumpkins['Price']
```

> GiriÅŸ verilerinde `reshape` iÅŸlemi yapmamÄ±z gerektiÄŸini unutmayÄ±n, bÃ¶ylece DoÄŸrusal Regresyon paketi bunu doÄŸru ÅŸekilde anlayabilir. DoÄŸrusal Regresyon, her bir satÄ±rÄ±n giriÅŸ Ã¶zelliklerinin bir vektÃ¶rÃ¼ne karÅŸÄ±lÄ±k geldiÄŸi bir 2D-dizi bekler. Bizim durumumuzda, yalnÄ±zca bir giriÅŸimiz olduÄŸu iÃ§in, NÃ—1 ÅŸekline sahip bir diziye ihtiyacÄ±mÄ±z var, burada N veri setinin boyutudur.

Daha sonra, verileri eÄŸitim ve test veri setlerine ayÄ±rmamÄ±z gerekiyor, bÃ¶ylece modelimizi eÄŸittikten sonra doÄŸrulayabiliriz:

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
```

Son olarak, gerÃ§ek DoÄŸrusal Regresyon modelini eÄŸitmek yalnÄ±zca iki satÄ±r kod alÄ±r. `LinearRegression` nesnesini tanÄ±mlarÄ±z ve `fit` yÃ¶ntemiyle verilerimize uyarlarÄ±z:

```python
lin_reg = LinearRegression()
lin_reg.fit(X_train,y_train)
```

`LinearRegression` nesnesi, `fit` iÅŸleminden sonra regresyonun tÃ¼m katsayÄ±larÄ±nÄ± iÃ§erir ve bunlara `.coef_` Ã¶zelliÄŸi ile eriÅŸilebilir. Bizim durumumuzda, yalnÄ±zca bir katsayÄ± vardÄ±r ve bu yaklaÅŸÄ±k `-0.017` olmalÄ±dÄ±r. Bu, fiyatlarÄ±n zamanla biraz dÃ¼ÅŸtÃ¼ÄŸÃ¼nÃ¼, ancak Ã§ok fazla olmadÄ±ÄŸÄ±nÄ±, gÃ¼nde yaklaÅŸÄ±k 2 sent olduÄŸunu gÃ¶sterir. AyrÄ±ca, regresyonun Y ekseniyle kesiÅŸim noktasÄ±na `lin_reg.intercept_` kullanarak eriÅŸebiliriz - bu bizim durumumuzda yaklaÅŸÄ±k `21` olacaktÄ±r, yÄ±lÄ±n baÅŸÄ±ndaki fiyatÄ± gÃ¶sterir.

Modelimizin ne kadar doÄŸru olduÄŸunu gÃ¶rmek iÃ§in test veri setinde fiyatlarÄ± tahmin edebilir ve ardÄ±ndan tahminlerimizin beklenen deÄŸerlere ne kadar yakÄ±n olduÄŸunu Ã¶lÃ§ebiliriz. Bu, beklenen ve tahmin edilen deÄŸerler arasÄ±ndaki tÃ¼m kare farklarÄ±nÄ±n ortalamasÄ± olan ortalama kare hata (MSE) metriÄŸi kullanÄ±larak yapÄ±labilir.

```python
pred = lin_reg.predict(X_test)

mse = np.sqrt(mean_squared_error(y_test,pred))
print(f'Mean error: {mse:3.3} ({mse/np.mean(pred)*100:3.3}%)')
```
HatalarÄ±mÄ±z yaklaÅŸÄ±k %17 oranÄ±nda, yani pek iyi deÄŸil. Model kalitesinin bir diÄŸer gÃ¶stergesi **determinasyon katsayÄ±sÄ±dÄ±r** ve ÅŸu ÅŸekilde elde edilebilir:

```python
score = lin_reg.score(X_train,y_train)
print('Model determination: ', score)
```
EÄŸer deÄŸer 0 ise, bu modelin girdi verilerini dikkate almadÄ±ÄŸÄ± ve *en kÃ¶tÃ¼ doÄŸrusal tahmin edici* olarak hareket ettiÄŸi anlamÄ±na gelir; bu da sonuÃ§larÄ±n basit bir ortalamasÄ±dÄ±r. DeÄŸer 1 olduÄŸunda, tÃ¼m beklenen Ã§Ä±ktÄ±larÄ± mÃ¼kemmel bir ÅŸekilde tahmin edebileceÄŸimiz anlamÄ±na gelir. Bizim durumumuzda, katsayÄ± yaklaÅŸÄ±k 0.06 civarÄ±nda, bu da oldukÃ§a dÃ¼ÅŸÃ¼k.

Regresyonun bizim durumumuzda nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± daha iyi gÃ¶rmek iÃ§in test verilerini regresyon Ã§izgisiyle birlikte gÃ¶rselleÅŸtirebiliriz:

```python
plt.scatter(X_test,y_test)
plt.plot(X_test,pred)
```

<img alt="DoÄŸrusal regresyon" src="images/linear-results.png" width="50%" />

## Polinom Regresyon

DoÄŸrusal Regresyon'un bir diÄŸer tÃ¼rÃ¼ Polinom Regresyon'dur. Bazen deÄŸiÅŸkenler arasÄ±nda doÄŸrusal bir iliÅŸki olabilir - Ã¶rneÄŸin, kabak hacmi bÃ¼yÃ¼dÃ¼kÃ§e fiyatÄ±n artmasÄ± - ancak bazen bu iliÅŸkiler bir dÃ¼zlem veya doÄŸru olarak Ã§izilemez.

âœ… Ä°ÅŸte [Polinom Regresyon](https://online.stat.psu.edu/stat501/lesson/9/9.8) kullanabilecek veri tÃ¼rlerine dair bazÄ± Ã¶rnekler.

Tarih ve Fiyat arasÄ±ndaki iliÅŸkiye tekrar bakÄ±n. Bu daÄŸÄ±lÄ±m grafiÄŸi mutlaka bir doÄŸru ile analiz edilmeli mi? Fiyatlar dalgalanamaz mÄ±? Bu durumda polinom regresyonu deneyebilirsiniz.

âœ… Polinomlar, bir veya daha fazla deÄŸiÅŸken ve katsayÄ± iÃ§erebilen matematiksel ifadelerdir.

Polinom regresyon, doÄŸrusal olmayan veriye daha iyi uyum saÄŸlamak iÃ§in eÄŸri bir Ã§izgi oluÅŸturur. Bizim durumumuzda, girdi verilerine kare `DayOfYear` deÄŸiÅŸkenini eklersek, verilerimizi yÄ±l iÃ§inde belirli bir noktada minimuma sahip olan parabolik bir eÄŸri ile uyumlu hale getirebiliriz.

Scikit-learn, veri iÅŸleme adÄ±mlarÄ±nÄ± bir araya getirmek iÃ§in kullanÄ±ÅŸlÄ± bir [pipeline API](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html?highlight=pipeline#sklearn.pipeline.make_pipeline) iÃ§erir. **Pipeline**, bir dizi **tahmin ediciden** oluÅŸur. Bizim durumumuzda, Ã¶nce modelimize polinom Ã¶zellikler ekleyen ve ardÄ±ndan regresyonu eÄŸiten bir pipeline oluÅŸturacaÄŸÄ±z:

```python
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

pipeline = make_pipeline(PolynomialFeatures(2), LinearRegression())

pipeline.fit(X_train,y_train)
```

`PolynomialFeatures(2)` kullanmak, girdi verilerinden tÃ¼m ikinci derece polinomlarÄ± dahil edeceÄŸimiz anlamÄ±na gelir. Bizim durumumuzda bu sadece `DayOfYear`<sup>2</sup> anlamÄ±na gelir, ancak iki girdi deÄŸiÅŸkeni X ve Y verildiÄŸinde, bu X<sup>2</sup>, XY ve Y<sup>2</sup> ekleyecektir. Daha yÃ¼ksek dereceli polinomlar kullanmak istersek bunu da yapabiliriz.

Pipeline'lar, orijinal `LinearRegression` nesnesi gibi kullanÄ±labilir, yani pipeline'Ä± `fit` edebilir ve ardÄ±ndan tahmin sonuÃ§larÄ±nÄ± almak iÃ§in `predict` kullanabiliriz. Ä°ÅŸte test verilerini ve yaklaÅŸÄ±k eÄŸriyi gÃ¶steren grafik:

<img alt="Polinom regresyon" src="images/poly-results.png" width="50%" />

Polinom Regresyon kullanarak biraz daha dÃ¼ÅŸÃ¼k MSE ve daha yÃ¼ksek determinasyon elde edebiliriz, ancak fark Ã§ok bÃ¼yÃ¼k deÄŸil. DiÄŸer Ã¶zellikleri de dikkate almamÄ±z gerekiyor!

> Kabak fiyatlarÄ±nÄ±n minimum seviyede olduÄŸu zamanÄ±n CadÄ±lar BayramÄ± civarÄ±nda olduÄŸunu gÃ¶rebilirsiniz. Bunu nasÄ±l aÃ§Ä±klarsÄ±nÄ±z?

ğŸƒ Tebrikler, kabak turtasÄ± fiyatÄ±nÄ± tahmin etmeye yardÄ±mcÄ± olabilecek bir model oluÅŸturdunuz. Muhtemelen aynÄ± prosedÃ¼rÃ¼ tÃ¼m kabak tÃ¼rleri iÃ§in tekrarlayabilirsiniz, ancak bu oldukÃ§a zahmetli olur. Åimdi modelimizde kabak Ã§eÅŸitlerini nasÄ±l dikkate alacaÄŸÄ±mÄ±zÄ± Ã¶ÄŸrenelim!

## Kategorik Ã–zellikler

Ä°deal bir dÃ¼nyada, aynÄ± modeli kullanarak farklÄ± kabak Ã§eÅŸitlerinin fiyatlarÄ±nÄ± tahmin edebilmek isteriz. Ancak `Variety` sÃ¼tunu, `Month` gibi sÃ¼tunlardan biraz farklÄ±dÄ±r, Ã§Ã¼nkÃ¼ sayÄ±sal olmayan deÄŸerler iÃ§erir. Bu tÃ¼r sÃ¼tunlara **kategorik** denir.

[![BaÅŸlangÄ±Ã§ Seviyesi ML - DoÄŸrusal Regresyon ile Kategorik Ã–zellik Tahminleri](https://img.youtube.com/vi/DYGliioIAE0/0.jpg)](https://youtu.be/DYGliioIAE0 "BaÅŸlangÄ±Ã§ Seviyesi ML - DoÄŸrusal Regresyon ile Kategorik Ã–zellik Tahminleri")

> ğŸ¥ YukarÄ±daki gÃ¶rsele tÄ±klayarak kategorik Ã¶zelliklerin kullanÄ±mÄ±na dair kÄ±sa bir video izleyebilirsiniz.

Burada ortalama fiyatÄ±n Ã§eÅŸitliliÄŸe baÄŸlÄ± olarak nasÄ±l deÄŸiÅŸtiÄŸini gÃ¶rebilirsiniz:

<img alt="Ã‡eÅŸide gÃ¶re ortalama fiyat" src="images/price-by-variety.png" width="50%" />

Ã‡eÅŸidi dikkate almak iÃ§in Ã¶nce bunu sayÄ±sal bir forma dÃ¶nÃ¼ÅŸtÃ¼rmemiz, yani **kodlamamÄ±z** gerekir. Bunu yapmanÄ±n birkaÃ§ yolu vardÄ±r:

* Basit **sayÄ±sal kodlama**, farklÄ± Ã§eÅŸitlerin bir tablosunu oluÅŸturur ve ardÄ±ndan Ã§eÅŸit adÄ±nÄ± bu tablodaki bir indeksle deÄŸiÅŸtirir. Bu, doÄŸrusal regresyon iÃ§in en iyi fikir deÄŸildir, Ã§Ã¼nkÃ¼ doÄŸrusal regresyon indeksin gerÃ§ek sayÄ±sal deÄŸerini alÄ±r ve bunu bir katsayÄ± ile Ã§arparak sonuca ekler. Bizim durumumuzda, indeks numarasÄ± ile fiyat arasÄ±ndaki iliÅŸki aÃ§Ä±kÃ§a doÄŸrusal deÄŸildir, indekslerin belirli bir ÅŸekilde sÄ±ralandÄ±ÄŸÄ±ndan emin olsak bile.
* **One-hot kodlama**, `Variety` sÃ¼tununu dÃ¶rt farklÄ± sÃ¼tunla deÄŸiÅŸtirir, her biri bir Ã§eÅŸit iÃ§in. Her sÃ¼tun, ilgili satÄ±rÄ±n belirli bir Ã§eÅŸide ait olup olmadÄ±ÄŸÄ±nÄ± gÃ¶stermek iÃ§in `1` veya `0` iÃ§erir. Bu, doÄŸrusal regresyonda her kabak Ã§eÅŸidi iÃ§in bir katsayÄ± oluÅŸturur ve bu katsayÄ± o Ã§eÅŸidin "baÅŸlangÄ±Ã§ fiyatÄ±" (veya "ek fiyatÄ±") iÃ§in sorumludur.

AÅŸaÄŸÄ±daki kod, bir Ã§eÅŸidi nasÄ±l one-hot kodlayabileceÄŸimizi gÃ¶sterir:

```python
pd.get_dummies(new_pumpkins['Variety'])
```

 ID | FAIRYTALE | MINIATURE | MIXED HEIRLOOM VARIETIES | PIE TYPE
----|-----------|-----------|--------------------------|----------
70 | 0 | 0 | 0 | 1
71 | 0 | 0 | 0 | 1
... | ... | ... | ... | ...
1738 | 0 | 1 | 0 | 0
1739 | 0 | 1 | 0 | 0
1740 | 0 | 1 | 0 | 0
1741 | 0 | 1 | 0 | 0
1742 | 0 | 1 | 0 | 0

One-hot kodlanmÄ±ÅŸ Ã§eÅŸidi girdi olarak kullanarak doÄŸrusal regresyonu eÄŸitmek iÃ§in, sadece `X` ve `y` verilerini doÄŸru ÅŸekilde baÅŸlatmamÄ±z gerekir:

```python
X = pd.get_dummies(new_pumpkins['Variety'])
y = new_pumpkins['Price']
```

Kodun geri kalanÄ±, yukarÄ±da DoÄŸrusal Regresyonu eÄŸitmek iÃ§in kullandÄ±ÄŸÄ±mÄ±z kodla aynÄ±dÄ±r. EÄŸer denerseniz, ortalama kare hata (MSE) yaklaÅŸÄ±k aynÄ± kalÄ±r, ancak determinasyon katsayÄ±sÄ± Ã§ok daha yÃ¼ksek (~%77) olur. Daha doÄŸru tahminler elde etmek iÃ§in daha fazla kategorik Ã¶zelliÄŸi ve `Month` veya `DayOfYear` gibi sayÄ±sal Ã¶zellikleri dikkate alabiliriz. Daha bÃ¼yÃ¼k bir Ã¶zellik dizisi oluÅŸturmak iÃ§in `join` kullanabiliriz:

```python
X = pd.get_dummies(new_pumpkins['Variety']) \
        .join(new_pumpkins['Month']) \
        .join(pd.get_dummies(new_pumpkins['City'])) \
        .join(pd.get_dummies(new_pumpkins['Package']))
y = new_pumpkins['Price']
```

Burada ayrÄ±ca `City` ve `Package` tÃ¼rÃ¼nÃ¼ de dikkate alÄ±yoruz, bu da bize MSE 2.84 (%10) ve determinasyon 0.94 saÄŸlar!

## Hepsini Bir Araya Getirmek

En iyi modeli oluÅŸturmak iÃ§in yukarÄ±daki Ã¶rnekten birleÅŸtirilmiÅŸ (one-hot kodlanmÄ±ÅŸ kategorik + sayÄ±sal) verileri Polinom Regresyon ile birlikte kullanabiliriz. Ä°ÅŸte tÃ¼m kodun tamamÄ±:

```python
# set up training data
X = pd.get_dummies(new_pumpkins['Variety']) \
        .join(new_pumpkins['Month']) \
        .join(pd.get_dummies(new_pumpkins['City'])) \
        .join(pd.get_dummies(new_pumpkins['Package']))
y = new_pumpkins['Price']

# make train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# setup and train the pipeline
pipeline = make_pipeline(PolynomialFeatures(2), LinearRegression())
pipeline.fit(X_train,y_train)

# predict results for test data
pred = pipeline.predict(X_test)

# calculate MSE and determination
mse = np.sqrt(mean_squared_error(y_test,pred))
print(f'Mean error: {mse:3.3} ({mse/np.mean(pred)*100:3.3}%)')

score = pipeline.score(X_train,y_train)
print('Model determination: ', score)
```

Bu, bize yaklaÅŸÄ±k %97'lik en iyi determinasyon katsayÄ±sÄ±nÄ± ve MSE=2.23 (~%8 tahmin hatasÄ±) saÄŸlar.

| Model | MSE | Determinasyon |
|-------|-----|---------------|
| `DayOfYear` DoÄŸrusal | 2.77 (%17.2) | 0.07 |
| `DayOfYear` Polinom | 2.73 (%17.0) | 0.08 |
| `Variety` DoÄŸrusal | 5.24 (%19.7) | 0.77 |
| TÃ¼m Ã¶zellikler DoÄŸrusal | 2.84 (%10.5) | 0.94 |
| TÃ¼m Ã¶zellikler Polinom | 2.23 (%8.25) | 0.97 |

ğŸ† Tebrikler! Bu derste dÃ¶rt farklÄ± Regresyon modeli oluÅŸturdunuz ve model kalitesini %97'ye Ã§Ä±kardÄ±nÄ±z. Regresyon ile ilgili son bÃ¶lÃ¼mde, kategorileri belirlemek iÃ§in Lojistik Regresyonu Ã¶ÄŸreneceksiniz.

---
## ğŸš€Meydan Okuma

Bu not defterinde farklÄ± deÄŸiÅŸkenleri test ederek korelasyonun model doÄŸruluÄŸuyla nasÄ±l iliÅŸkili olduÄŸunu inceleyin.

## [Ders sonrasÄ± test](https://ff-quizzes.netlify.app/en/ml/)

## GÃ¶zden GeÃ§irme ve Kendi Kendine Ã‡alÄ±ÅŸma

Bu derste DoÄŸrusal Regresyon hakkÄ±nda bilgi edindik. Regresyonun diÄŸer Ã¶nemli tÃ¼rleri de vardÄ±r. Stepwise, Ridge, Lasso ve Elasticnet tekniklerini okuyun. Daha fazla bilgi edinmek iÃ§in iyi bir kurs [Stanford Ä°statistiksel Ã–ÄŸrenme kursu](https://online.stanford.edu/courses/sohs-ystatslearning-statistical-learning) olabilir.

## Ã–dev 

[Bir Model OluÅŸturun](assignment.md)

---

**Feragatname**:  
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±k iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalar iÃ§in sorumluluk kabul edilmez.