# Scikit-learn kullanarak bir regresyon modeli oluÅŸturun: dÃ¶rt farklÄ± regresyon yÃ¶ntemi

![DoÄŸrusal ve polinomial regresyon infografiÄŸi](../../../../translated_images/linear-polynomial.5523c7cb6576ccab0fecbd0e3505986eb2d191d9378e785f82befcf3a578a6e7.tr.png)
> Ä°nfografik [Dasani Madipalli](https://twitter.com/dasani_decoded) tarafÄ±ndan
## [Ders Ã¶ncesi sÄ±nav](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/13/)

> ### [Bu ders R dilinde de mevcut!](../../../../2-Regression/3-Linear/solution/R/lesson_3.html)
### GiriÅŸ 

Åu ana kadar, bu derste kullanacaÄŸÄ±mÄ±z kabak fiyatlandÄ±rma veri setinden toplanan Ã¶rnek verilerle regresyonun ne olduÄŸunu keÅŸfettiniz. AyrÄ±ca Matplotlib kullanarak bu veriyi gÃ¶rselleÅŸtirdiniz.

Åimdi, ML iÃ§in regresyonun derinliklerine dalmaya hazÄ±rsÄ±nÄ±z. GÃ¶rselleÅŸtirme, veriyi anlamlandÄ±rmanÄ±za yardÄ±mcÄ± olurken, Makine Ã–ÄŸreniminin gerÃ§ek gÃ¼cÃ¼ _modellerin eÄŸitilmesinden_ gelir. Modeller, tarihi veriler Ã¼zerinde eÄŸitilir ve veri baÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± otomatik olarak yakalar, bÃ¶ylece modelin daha Ã¶nce gÃ¶rmediÄŸi yeni veriler iÃ§in sonuÃ§larÄ± tahmin etmenizi saÄŸlar.

Bu derste, _temel doÄŸrusal regresyon_ ve _polinomial regresyon_ olmak Ã¼zere iki tÃ¼r regresyon hakkÄ±nda daha fazla bilgi edineceksiniz ve bu tekniklerin altÄ±nda yatan bazÄ± matematiksel temelleri Ã¶ÄŸreneceksiniz. Bu modeller, farklÄ± girdi verilerine baÄŸlÄ± olarak kabak fiyatlarÄ±nÄ± tahmin etmemize olanak tanÄ±yacak.

[![Yeni baÅŸlayanlar iÃ§in ML - DoÄŸrusal Regresyonu Anlamak](https://img.youtube.com/vi/CRxFT8oTDMg/0.jpg)](https://youtu.be/CRxFT8oTDMg "Yeni baÅŸlayanlar iÃ§in ML - DoÄŸrusal Regresyonu Anlamak")

> ğŸ¥ DoÄŸrusal regresyon hakkÄ±nda kÄ±sa bir video Ã¶zet iÃ§in yukarÄ±daki resme tÄ±klayÄ±n.

> Bu mÃ¼fredat boyunca, matematik bilgisi minimum dÃ¼zeyde varsayÄ±lmakta ve diÄŸer alanlardan gelen Ã¶ÄŸrenciler iÃ§in eriÅŸilebilir hale getirilmek istenmektedir, bu yÃ¼zden notlar, ğŸ§® Ã§aÄŸrÄ±lar, diyagramlar ve diÄŸer Ã¶ÄŸrenme araÃ§larÄ±na dikkat edin.

### Ã–nkoÅŸul

Åu ana kadar incelediÄŸimiz kabak verisinin yapÄ±sÄ±na aÅŸina olmalÄ±sÄ±nÄ±z. Bu dersin _notebook.ipynb_ dosyasÄ±nda Ã¶nceden yÃ¼klenmiÅŸ ve temizlenmiÅŸ olarak bulabilirsiniz. Dosyada, kabak fiyatÄ± yeni bir veri Ã§erÃ§evesinde bushel baÅŸÄ±na gÃ¶sterilmektedir. Bu not defterlerini Visual Studio Code'daki Ã§ekirdeklerde Ã§alÄ±ÅŸtÄ±rabildiÄŸinizden emin olun.

### HazÄ±rlÄ±k

HatÄ±rlatma olarak, bu veriyi sorular sormak iÃ§in yÃ¼klÃ¼yorsunuz.

- Kabak almak iÃ§in en iyi zaman ne zaman?
- Mini kabaklarÄ±n bir kutusunun fiyatÄ± ne olabilir?
- YarÄ±m bushel sepetlerde mi yoksa 1 1/9 bushel kutularda mÄ± almalÄ±yÄ±m?
Bu veriyi incelemeye devam edelim.

Ã–nceki derste, bir Pandas veri Ã§erÃ§evesi oluÅŸturup, orijinal veri setinin bir kÄ±smÄ±yla doldurmuÅŸtunuz, bushel baÅŸÄ±na fiyatlandÄ±rmayÄ± standartlaÅŸtÄ±rmÄ±ÅŸtÄ±nÄ±z. Ancak, bunu yaparak sadece yaklaÅŸÄ±k 400 veri noktasÄ± toplayabildiniz ve sadece sonbahar aylarÄ± iÃ§in.

Bu dersin eÅŸlik eden not defterinde Ã¶nceden yÃ¼klenmiÅŸ verilere bir gÃ¶z atÄ±n. Veriler Ã¶nceden yÃ¼klenmiÅŸ ve ay verilerini gÃ¶stermek iÃ§in baÅŸlangÄ±Ã§ta bir saÃ§Ä±lma grafiÄŸi Ã§izilmiÅŸtir. Belki verinin doÄŸasÄ± hakkÄ±nda daha fazla ayrÄ±ntÄ± elde edebiliriz, daha fazla temizleyerek.

## DoÄŸrusal regresyon Ã§izgisi

1. Derste Ã¶ÄŸrendiÄŸiniz gibi, bir doÄŸrusal regresyon egzersizinin amacÄ±, bir Ã§izgi Ã§izerek:

- **DeÄŸiÅŸken iliÅŸkilerini gÃ¶sterin**. DeÄŸiÅŸkenler arasÄ±ndaki iliÅŸkiyi gÃ¶sterin.
- **Tahminler yapÄ±n**. Yeni bir veri noktasÄ±nÄ±n bu Ã§izgiye gÃ¶re nereye dÃ¼ÅŸeceÄŸini doÄŸru bir ÅŸekilde tahmin edin.

Bu tÃ¼r bir Ã§izgi Ã§izmek iÃ§in **En KÃ¼Ã§Ã¼k Kareler Regresyonu** tipiktir. 'En kÃ¼Ã§Ã¼k kareler' terimi, regresyon Ã§izgisinin etrafÄ±ndaki tÃ¼m veri noktalarÄ±nÄ±n karelerinin alÄ±nÄ±p toplanmasÄ± anlamÄ±na gelir. Ä°dealde, bu nihai toplam mÃ¼mkÃ¼n olduÄŸunca kÃ¼Ã§Ã¼k olmalÄ±dÄ±r, Ã§Ã¼nkÃ¼ dÃ¼ÅŸÃ¼k hata sayÄ±sÄ± veya `least-squares` istiyoruz.

Bunu yaparÄ±z Ã§Ã¼nkÃ¼ tÃ¼m veri noktalarÄ±mÄ±zdan en az toplam mesafeye sahip bir Ã§izgi modellemek istiyoruz. AyrÄ±ca terimleri toplarken karelerini alÄ±rÄ±z Ã§Ã¼nkÃ¼ yÃ¶nÃ¼nden ziyade bÃ¼yÃ¼klÃ¼ÄŸÃ¼ ile ilgileniriz.

> **ğŸ§® Bana matematiÄŸi gÃ¶ster**
>
> Bu Ã§izgi, _en iyi uyum Ã§izgisi_ olarak adlandÄ±rÄ±lÄ±r ve [bir denklemle](https://en.wikipedia.org/wiki/Simple_linear_regression) ifade edilebilir:
>
> ```
> Y = a + bX
> ```
>
> `X` is the 'explanatory variable'. `Y` is the 'dependent variable'. The slope of the line is `b` and `a` is the y-intercept, which refers to the value of `Y` when `X = 0`. 
>
>![calculate the slope](../../../../translated_images/slope.f3c9d5910ddbfcf9096eb5564254ba22c9a32d7acd7694cab905d29ad8261db3.tr.png)
>
> First, calculate the slope `b`. Infographic by [Jen Looper](https://twitter.com/jenlooper)
>
> In other words, and referring to our pumpkin data's original question: "predict the price of a pumpkin per bushel by month", `X` would refer to the price and `Y` would refer to the month of sale. 
>
>![complete the equation](../../../../translated_images/calculation.a209813050a1ddb141cdc4bc56f3af31e67157ed499e16a2ecf9837542704c94.tr.png)
>
> Calculate the value of Y. If you're paying around $4, it must be April! Infographic by [Jen Looper](https://twitter.com/jenlooper)
>
> The math that calculates the line must demonstrate the slope of the line, which is also dependent on the intercept, or where `Y` is situated when `X = 0`.
>
> You can observe the method of calculation for these values on the [Math is Fun](https://www.mathsisfun.com/data/least-squares-regression.html) web site. Also visit [this Least-squares calculator](https://www.mathsisfun.com/data/least-squares-calculator.html) to watch how the numbers' values impact the line.

## Correlation

One more term to understand is the **Correlation Coefficient** between given X and Y variables. Using a scatterplot, you can quickly visualize this coefficient. A plot with datapoints scattered in a neat line have high correlation, but a plot with datapoints scattered everywhere between X and Y have a low correlation.

A good linear regression model will be one that has a high (nearer to 1 than 0) Correlation Coefficient using the Least-Squares Regression method with a line of regression.

âœ… Run the notebook accompanying this lesson and look at the Month to Price scatterplot. Does the data associating Month to Price for pumpkin sales seem to have high or low correlation, according to your visual interpretation of the scatterplot? Does that change if you use more fine-grained measure instead of `Month`, eg. *day of the year* (i.e. number of days since the beginning of the year)?

In the code below, we will assume that we have cleaned up the data, and obtained a data frame called `new_pumpkins`, similar to the following:

ID | Month | DayOfYear | Variety | City | Package | Low Price | High Price | Price
---|-------|-----------|---------|------|---------|-----------|------------|-------
70 | 9 | 267 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 15.0 | 15.0 | 13.636364
71 | 9 | 267 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 18.0 | 18.0 | 16.363636
72 | 10 | 274 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 18.0 | 18.0 | 16.363636
73 | 10 | 274 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 17.0 | 17.0 | 15.454545
74 | 10 | 281 | PIE TYPE | BALTIMORE | 1 1/9 bushel cartons | 15.0 | 15.0 | 13.636364

> The code to clean the data is available in [`notebook.ipynb`](../../../../2-Regression/3-Linear/notebook.ipynb). We have performed the same cleaning steps as in the previous lesson, and have calculated `DayOfYear` sÃ¼tununu aÅŸaÄŸÄ±daki ifade kullanarak hesaplayÄ±n:

```python
day_of_year = pd.to_datetime(pumpkins['Date']).apply(lambda dt: (dt-datetime(dt.year,1,1)).days)
```

Åimdi doÄŸrusal regresyonun ardÄ±ndaki matematiÄŸi anladÄ±ÄŸÄ±nÄ±za gÃ¶re, hangi kabak paketinin en iyi fiyatlara sahip olacaÄŸÄ±nÄ± tahmin edip edemeyeceÄŸimizi gÃ¶rmek iÃ§in bir Regresyon modeli oluÅŸturalÄ±m. Tatil kabak bahÃ§esi iÃ§in kabak satÄ±n alan biri, bahÃ§e iÃ§in kabak paketlerini optimize edebilmek iÃ§in bu bilgiye sahip olmak isteyebilir.

## Korelasyon ArayÄ±ÅŸÄ±

[![Yeni baÅŸlayanlar iÃ§in ML - Korelasyon ArayÄ±ÅŸÄ±: DoÄŸrusal Regresyonun AnahtarÄ±](https://img.youtube.com/vi/uoRq-lW2eQo/0.jpg)](https://youtu.be/uoRq-lW2eQo "Yeni baÅŸlayanlar iÃ§in ML - Korelasyon ArayÄ±ÅŸÄ±: DoÄŸrusal Regresyonun AnahtarÄ±")

> ğŸ¥ Korelasyon hakkÄ±nda kÄ±sa bir video Ã¶zet iÃ§in yukarÄ±daki resme tÄ±klayÄ±n.

Ã–nceki dersten, farklÄ± aylar iÃ§in ortalama fiyatÄ±n ÅŸu ÅŸekilde gÃ¶rÃ¼ndÃ¼ÄŸÃ¼nÃ¼ muhtemelen gÃ¶rmÃ¼ÅŸsÃ¼nÃ¼zdÃ¼r:

<img alt="Aylara gÃ¶re ortalama fiyat" src="../2-Data/images/barchart.png" width="50%"/>

Bu, bazÄ± korelasyonlar olmasÄ± gerektiÄŸini ve `Month` and `Price`, or between `DayOfYear` and `Price`. Here is the scatter plot that shows the latter relationship:

<img alt="Scatter plot of Price vs. Day of Year" src="images/scatter-dayofyear.png" width="50%" /> 

Let's see if there is a correlation using the `corr` fonksiyonunu kullanarak lineer regresyon modeli eÄŸitmeye Ã§alÄ±ÅŸabileceÄŸimizi gÃ¶steriyor:

```python
print(new_pumpkins['Month'].corr(new_pumpkins['Price']))
print(new_pumpkins['DayOfYear'].corr(new_pumpkins['Price']))
```

GÃ¶rÃ¼nÃ¼ÅŸe gÃ¶re korelasyon oldukÃ§a kÃ¼Ã§Ã¼k, `-0.15` `Month` and -0.17 by the `DayOfMonth`, but there could be another important relationship. It looks like there are different clusters of prices corresponding to different pumpkin varieties. To confirm this hypothesis, let's plot each pumpkin category using a different color. By passing an `ax` parameter to the `scatter` Ã§izim fonksiyonunu kullanarak tÃ¼m noktalarÄ± aynÄ± grafikte Ã§izebiliriz:

```python
ax=None
colors = ['red','blue','green','yellow']
for i,var in enumerate(new_pumpkins['Variety'].unique()):
    df = new_pumpkins[new_pumpkins['Variety']==var]
    ax = df.plot.scatter('DayOfYear','Price',ax=ax,c=colors[i],label=var)
```

<img alt="Fiyat vs. YÄ±lÄ±n GÃ¼nÃ¼ SaÃ§Ä±lma GrafiÄŸi" src="images/scatter-dayofyear-color.png" width="50%" />

AraÅŸtÄ±rmamÄ±z, Ã§eÅŸidin genel fiyat Ã¼zerinde satÄ±ÅŸ tarihinden daha fazla etkisi olduÄŸunu Ã¶ne sÃ¼rÃ¼yor. Bunu bir Ã§ubuk grafikle gÃ¶rebiliriz:

```python
new_pumpkins.groupby('Variety')['Price'].mean().plot(kind='bar')
```

<img alt="Ã‡eÅŸide gÃ¶re fiyat Ã§ubuk grafiÄŸi" src="images/price-by-variety.png" width="50%" />

Åu an iÃ§in sadece bir kabak Ã§eÅŸidine, 'turta tipi'ne odaklanalÄ±m ve tarihin fiyat Ã¼zerindeki etkisini gÃ¶relim:

```python
pie_pumpkins = new_pumpkins[new_pumpkins['Variety']=='PIE TYPE']
pie_pumpkins.plot.scatter('DayOfYear','Price') 
```
<img alt="Fiyat vs. YÄ±lÄ±n GÃ¼nÃ¼ SaÃ§Ä±lma GrafiÄŸi" src="images/pie-pumpkins-scatter.png" width="50%" />

Åimdi `Price` and `DayOfYear` using `corr` function, we will get something like `-0.27` arasÄ±ndaki korelasyonu hesaplasak, bu da tahmin edici bir model eÄŸitmenin mantÄ±klÄ± olduÄŸunu gÃ¶sterir.

> DoÄŸrusal regresyon modeli eÄŸitmeden Ã¶nce, verimizin temiz olduÄŸundan emin olmak Ã¶nemlidir. DoÄŸrusal regresyon eksik deÄŸerlerle iyi Ã§alÄ±ÅŸmaz, bu yÃ¼zden tÃ¼m boÅŸ hÃ¼crelerden kurtulmak mantÄ±klÄ±dÄ±r:

```python
pie_pumpkins.dropna(inplace=True)
pie_pumpkins.info()
```

BaÅŸka bir yaklaÅŸÄ±m, bu boÅŸ deÄŸerleri ilgili sÃ¼tunun ortalama deÄŸerleriyle doldurmak olabilir.

## Basit DoÄŸrusal Regresyon

[![Yeni baÅŸlayanlar iÃ§in ML - Scikit-learn kullanarak DoÄŸrusal ve Polinomial Regresyon](https://img.youtube.com/vi/e4c_UP2fSjg/0.jpg)](https://youtu.be/e4c_UP2fSjg "Yeni baÅŸlayanlar iÃ§in ML - Scikit-learn kullanarak DoÄŸrusal ve Polinomial Regresyon")

> ğŸ¥ DoÄŸrusal ve polinomial regresyon hakkÄ±nda kÄ±sa bir video Ã¶zet iÃ§in yukarÄ±daki resme tÄ±klayÄ±n.

DoÄŸrusal Regresyon modelimizi eÄŸitmek iÃ§in **Scikit-learn** kÃ¼tÃ¼phanesini kullanacaÄŸÄ±z.

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
```

BaÅŸlangÄ±Ã§ta, giriÅŸ deÄŸerlerini (Ã¶zellikler) ve beklenen Ã§Ä±ktÄ±yÄ± (etiket) ayrÄ± numpy dizilerine ayÄ±rÄ±yoruz:

```python
X = pie_pumpkins['DayOfYear'].to_numpy().reshape(-1,1)
y = pie_pumpkins['Price']
```

> GiriÅŸ verisi Ã¼zerinde `reshape` iÅŸlemi yapmamÄ±z gerektiÄŸini unutmayÄ±n, Ã§Ã¼nkÃ¼ DoÄŸrusal Regresyon paketi bunu doÄŸru anlamalÄ±dÄ±r. DoÄŸrusal Regresyon, her satÄ±rÄ±n bir giriÅŸ Ã¶zellikleri vektÃ¶rÃ¼ne karÅŸÄ±lÄ±k geldiÄŸi 2D bir dizi bekler. Bizim durumumuzda, sadece bir giriÅŸ olduÄŸundan, NÃ—1 ÅŸeklinde bir diziye ihtiyacÄ±mÄ±z var, burada N veri setinin boyutudur.

Daha sonra, veriyi eÄŸitim ve test veri setlerine ayÄ±rmamÄ±z gerekiyor, bÃ¶ylece modeli eÄŸittikten sonra doÄŸrulayabiliriz:

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
```

Son olarak, gerÃ§ek DoÄŸrusal Regresyon modelini eÄŸitmek sadece iki satÄ±r kod alÄ±r. `LinearRegression` object, and fit it to our data using the `fit` yÃ¶ntemini tanÄ±mlarÄ±z:

```python
lin_reg = LinearRegression()
lin_reg.fit(X_train,y_train)
```

`LinearRegression` object after `fit`-ting contains all the coefficients of the regression, which can be accessed using `.coef_` property. In our case, there is just one coefficient, which should be around `-0.017`. It means that prices seem to drop a bit with time, but not too much, around 2 cents per day. We can also access the intersection point of the regression with Y-axis using `lin_reg.intercept_` - it will be around `21` bizim durumumuzda, yÄ±lÄ±n baÅŸÄ±ndaki fiyatÄ± gÃ¶sterir.

Modelimizin ne kadar doÄŸru olduÄŸunu gÃ¶rmek iÃ§in, test veri setinde fiyatlarÄ± tahmin edebilir ve ardÄ±ndan tahminlerimizin beklenen deÄŸerlere ne kadar yakÄ±n olduÄŸunu Ã¶lÃ§ebiliriz. Bu, beklenen ve tahmin edilen deÄŸerler arasÄ±ndaki tÃ¼m kare farklarÄ±nÄ±n ortalamasÄ± olan ortalama kare hata (MSE) metrikleri kullanÄ±larak yapÄ±labilir.

```python
pred = lin_reg.predict(X_test)

mse = np.sqrt(mean_squared_error(y_test,pred))
print(f'Mean error: {mse:3.3} ({mse/np.mean(pred)*100:3.3}%)')
```

HatalarÄ±mÄ±z yaklaÅŸÄ±k 2 puan gibi gÃ¶rÃ¼nÃ¼yor, bu da ~%17. Ã‡ok iyi deÄŸil. Model kalitesinin baÅŸka bir gÃ¶stergesi **belirleme katsayÄ±sÄ±**dÄ±r ve ÅŸu ÅŸekilde elde edilebilir:

```python
score = lin_reg.score(X_train,y_train)
print('Model determination: ', score)
```
DeÄŸer 0 ise, modelin girdi verilerini dikkate almadÄ±ÄŸÄ± ve *en kÃ¶tÃ¼ doÄŸrusal tahminci* olarak davrandÄ±ÄŸÄ± anlamÄ±na gelir, bu da basitÃ§e sonucun ortalama deÄŸeridir. DeÄŸer 1 ise, tÃ¼m beklenen Ã§Ä±ktÄ±larÄ± mÃ¼kemmel bir ÅŸekilde tahmin edebildiÄŸimiz anlamÄ±na gelir. Bizim durumumuzda, katsayÄ± yaklaÅŸÄ±k 0.06, bu oldukÃ§a dÃ¼ÅŸÃ¼k.

AyrÄ±ca test verilerini regresyon Ã§izgisi ile birlikte Ã§izerek, regresyonun bizim durumumuzda nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± daha iyi gÃ¶rebiliriz:

```python
plt.scatter(X_test,y_test)
plt.plot(X_test,pred)
```

<img alt="DoÄŸrusal regresyon" src="images/linear-results.png" width="50%" />

## Polinomial Regresyon

DoÄŸrusal Regresyonun baÅŸka bir tÃ¼rÃ¼ Polinomial Regresyondur. Bazen deÄŸiÅŸkenler arasÄ±nda doÄŸrusal bir iliÅŸki vardÄ±r - kabak hacmi bÃ¼yÃ¼dÃ¼kÃ§e fiyat artar - bazen bu iliÅŸkiler bir dÃ¼zlem veya dÃ¼z bir Ã§izgi olarak Ã§izilemez.

âœ… Ä°ÅŸte [bazÄ± Ã¶rnekler](https://online.stat.psu.edu/stat501/lesson/9/9.8) Polinomial Regresyonun kullanÄ±labileceÄŸi veriler

Tarih ve Fiyat arasÄ±ndaki iliÅŸkiye bir kez daha bakÄ±n. Bu saÃ§Ä±lma grafiÄŸi mutlaka dÃ¼z bir Ã§izgi ile analiz edilmeli mi? Fiyatlar dalgalanamaz mÄ±? Bu durumda, polinomial regresyonu deneyebilirsiniz.

âœ… Polinomlar, bir veya daha fazla deÄŸiÅŸken ve katsayÄ±dan oluÅŸan matematiksel ifadelerdir

Polinomial regresyon, doÄŸrusal olmayan veriyi daha iyi uyacak ÅŸekilde eÄŸri bir Ã§izgi oluÅŸturur. Bizim durumumuzda, girdi verisine kare `DayOfYear` deÄŸiÅŸkenini eklersek, verimizi yÄ±l iÃ§inde belirli bir noktada minimuma sahip olacak parabolik bir eÄŸri ile uyarlayabiliriz.

Scikit-learn, veri iÅŸleme adÄ±mlarÄ±nÄ± bir araya getirmek iÃ§in kullanÄ±ÅŸlÄ± bir [pipeline API](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html?highlight=pipeline#sklearn.pipeline.make_pipeline) iÃ§erir. Bir **pipeline**, bir **estimators** zinciridir. Bizim durumumuzda, modelimize Ã¶nce polinomial Ã¶zellikler ekleyen ve ardÄ±ndan regresyonu eÄŸiten bir pipeline oluÅŸturacaÄŸÄ±z:

```python
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

pipeline = make_pipeline(PolynomialFeatures(2), LinearRegression())

pipeline.fit(X_train,y_train)
```

`PolynomialFeatures(2)` means that we will include all second-degree polynomials from the input data. In our case it will just mean `DayOfYear`<sup>2</sup>, but given two input variables X and Y, this will add X<sup>2</sup>, XY and Y<sup>2</sup>. We may also use higher degree polynomials if we want.

Pipelines can be used in the same manner as the original `LinearRegression` object, i.e. we can `fit` the pipeline, and then use `predict` to get the prediction results. Here is the graph showing test data, and the approximation curve:

<img alt="Polynomial regression" src="images/poly-results.png" width="50%" />

Using Polynomial Regression, we can get slightly lower MSE and higher determination, but not significantly. We need to take into account other features!

> You can see that the minimal pumpkin prices are observed somewhere around Halloween. How can you explain this? 

ğŸƒ Congratulations, you just created a model that can help predict the price of pie pumpkins. You can probably repeat the same procedure for all pumpkin types, but that would be tedious. Let's learn now how to take pumpkin variety into account in our model!

## Categorical Features

In the ideal world, we want to be able to predict prices for different pumpkin varieties using the same model. However, the `Variety` column is somewhat different from columns like `Month`, because it contains non-numeric values. Such columns are called **categorical**.

[![ML for beginners - Categorical Feature Predictions with Linear Regression](https://img.youtube.com/vi/DYGliioIAE0/0.jpg)](https://youtu.be/DYGliioIAE0 "ML for beginners - Categorical Feature Predictions with Linear Regression")

> ğŸ¥ Click the image above for a short video overview of using categorical features.

Here you can see how average price depends on variety:

<img alt="Average price by variety" src="images/price-by-variety.png" width="50%" />

To take variety into account, we first need to convert it to numeric form, or **encode** it. There are several way we can do it:

* Simple **numeric encoding** will build a table of different varieties, and then replace the variety name by an index in that table. This is not the best idea for linear regression, because linear regression takes the actual numeric value of the index, and adds it to the result, multiplying by some coefficient. In our case, the relationship between the index number and the price is clearly non-linear, even if we make sure that indices are ordered in some specific way.
* **One-hot encoding** will replace the `Variety` column by 4 different columns, one for each variety. Each column will contain `1` if the corresponding row is of a given variety, and `0` aksi halde. Bu, doÄŸrusal regresyonda dÃ¶rt katsayÄ± olacaÄŸÄ± anlamÄ±na gelir, her biri belirli bir kabak Ã§eÅŸidi iÃ§in "baÅŸlangÄ±Ã§ fiyatÄ±ndan" (veya "ek fiyat") sorumlu olacaktÄ±r.

AÅŸaÄŸÄ±daki kod, bir Ã§eÅŸidi nasÄ±l tek sÄ±cak kodlayabileceÄŸimizi gÃ¶sterir:

```python
pd.get_dummies(new_pumpkins['Variety'])
```

 ID | FAIRYTALE | MINIATURE | MIXED HEIRLOOM VARIETIES | PIE TYPE
----|-----------|-----------|--------------------------|----------
70 | 0 | 0 | 0 | 1
71 | 0 | 0 | 0 | 1
... | ... | ... | ... | ...
1738 | 0 | 1 | 0 | 0
1739 | 0 | 1 | 0 | 0
1740 | 0 | 1 | 0 | 0
1741 | 0 | 1 | 0 | 0
1742 | 0 | 1 | 0 | 0

Tek sÄ±cak kodlanmÄ±ÅŸ Ã§eÅŸidi giriÅŸ olarak kullanarak doÄŸrusal regresyon eÄŸitmek iÃ§in, sadece `X` and `y` verisini doÄŸru ÅŸekilde baÅŸlatmamÄ±z yeterlidir:

```python
X = pd.get_dummies(new_pumpkins['Variety'])
y = new_pumpkins['Price']
```

Kodun geri kalanÄ±, DoÄŸrusal Regresyon eÄŸitmek iÃ§in yukarÄ±da kullandÄ±ÄŸÄ±mÄ±zla aynÄ±dÄ±r. Dener iseniz, ortalama kare hatanÄ±n yaklaÅŸÄ±k aynÄ± olduÄŸunu, ancak belirleme katsayÄ±sÄ±nÄ±n (~%77) Ã§ok daha yÃ¼ksek olduÄŸunu gÃ¶receksiniz. Daha doÄŸru tahminler elde etmek iÃ§in, daha fazla kategorik Ã¶zelliÄŸi, ayrÄ±ca `Month` or `DayOfYear`. To get one large array of features, we can use `join` gibi sayÄ±sal Ã¶zellikleri de dikkate alabiliriz:

```python
X = pd.get_dummies(new_pumpkins['Variety']) \
        .join(new_pumpkins['Month']) \
        .join(pd.get_dummies(new_pumpkins['City'])) \
        .join(pd.get_dummies(new_pumpkins['Package']))
y = new_pumpkins['Price']
```

Burada ayrÄ±ca `City` and `Package` tÃ¼rÃ¼nÃ¼ de dikkate alÄ±yoruz, bu bize MSE 2.84 (%10) ve belirleme 0.94 verir!

## Hepsini bir araya getirmek

En iyi modeli oluÅŸturmak iÃ§in, yukarÄ±daki Ã¶rnekten birleÅŸtirilmiÅŸ (tek sÄ±cak kodlanmÄ±ÅŸ kategorik + sayÄ±sal) veriyi Polinomial Regresyon ile birlikte kullanabiliriz. Ä°ÅŸte kolaylÄ±k saÄŸlamak iÃ§in tam kod:

```python
# set up training data
X = pd.get_dummies(new_pumpkins['Variety']) \
        .join(new_pumpkins['Month']) \
        .join(pd.get_dummies(new_pumpkins['City'])) \
        .join(pd.get_dummies(new_pumpkins['Package']))
y = new_pumpkins['Price']

# make train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# setup and train the pipeline
pipeline = make_pipeline(PolynomialFeatures(2), LinearRegression())
pipeline.fit(X_train,y_train)

# predict results for test data
pred = pipeline.predict(X_test)

# calculate MSE and determination
mse = np.sqrt(mean_squared_error(y_test,pred))
print(f'Mean error: {mse:3.3} ({mse/np.mean(pred)*100:3.3}%)')

score = pipeline.score(X_train,y_train)
print('Model determination: ', score)
```

Bu, yaklaÅŸÄ±k %97'lik en iyi belirleme katsayÄ±sÄ±nÄ± ve MSE=2.23 (~%8 tahmin hatasÄ±) vermelidir.

| Model | MSE | Belirleme |
|-------|-----|-----------|
| `DayOfYear` Linear | 2.77 (17.2%) | 0.07 |
| `DayOfYear` Polynomial | 2.73 (17.0%) | 0.08 |
| `Variety` DoÄŸrusal | 5.24 (%19.7) | 0.77 |
| TÃ¼m Ã¶zellikler DoÄŸrusal | 2.84 (%10.5) | 0.94 |
| TÃ¼m Ã¶zellikler Polinomial | 2.23 (%8.25) | 0.97 |

ğŸ† Tebrikler! Bir derste dÃ¶rt Regresyon modeli oluÅŸturdunuz ve model kalitesini %97'ye Ã§Ä±kardÄ±nÄ±z. Regresyon Ã¼zerine son bÃ¶lÃ¼mde, kategorileri belirlemek iÃ§in Lojistik Regresyon hakkÄ±nda bilgi edineceksiniz.

---
## ğŸš€Meydan Okuma

Bu not defterinde birkaÃ§ farklÄ± deÄŸiÅŸkeni test edin ve korelasyonun model doÄŸruluÄŸuyla nasÄ±l iliÅŸkili olduÄŸunu gÃ¶rÃ¼n.

## [Ders sonrasÄ± sÄ±nav](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/14/)

## GÃ¶zden GeÃ§irme ve Kendi Kendine Ã‡alÄ±ÅŸma

Bu derste DoÄŸrusal Regresyon hakkÄ±nda bilgi edindik. DiÄŸer Ã¶nemli Regresyon tÃ¼rleri de vardÄ±r. AdÄ±m adÄ±m, Ridge, Lasso ve Elasticnet teknikleri hakkÄ±nda bilgi edinin. Daha fazla bilgi edinmek iÃ§in iyi bir kurs [Stanford Statistical Learning course](https://online.stanford.edu/courses/sohs-ystatslearning-statistical-learning).

## Ã–dev 

[Bir Model OluÅŸturun](assignment.md)

**Feragatname**:
Bu belge, makine tabanlÄ± yapay zeka Ã§eviri hizmetleri kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluÄŸu saÄŸlamak iÃ§in Ã§aba sarf etsek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan doÄŸabilecek yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalardan sorumlu deÄŸiliz.