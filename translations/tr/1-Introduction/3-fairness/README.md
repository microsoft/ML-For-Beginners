<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "9a6b702d1437c0467e3c5c28d763dac2",
  "translation_date": "2025-09-06T07:54:44+00:00",
  "source_file": "1-Introduction/3-fairness/README.md",
  "language_code": "tr"
}
-->
# Sorumlu Yapay Zeka ile Makine Ã–ÄŸrenimi Ã‡Ã¶zÃ¼mleri OluÅŸturma

![Makine Ã–ÄŸreniminde sorumlu yapay zekanÄ±n Ã¶zetini iÃ§eren bir sketchnote](../../../../sketchnotes/ml-fairness.png)
> Sketchnote: [Tomomi Imura](https://www.twitter.com/girlie_mac)

## [Ders Ã–ncesi Test](https://ff-quizzes.netlify.app/en/ml/)

## GiriÅŸ

Bu mÃ¼fredatta, makine Ã¶ÄŸreniminin gÃ¼nlÃ¼k hayatÄ±mÄ±zÄ± nasÄ±l etkilediÄŸini ve etkilemeye devam ettiÄŸini keÅŸfetmeye baÅŸlayacaksÄ±nÄ±z. Åu anda bile, sistemler ve modeller saÄŸlÄ±k teÅŸhisleri, kredi onaylarÄ± veya dolandÄ±rÄ±cÄ±lÄ±ÄŸÄ± tespit etme gibi gÃ¼nlÃ¼k karar verme gÃ¶revlerinde yer alÄ±yor. Bu nedenle, bu modellerin gÃ¼venilir sonuÃ§lar sunmak iÃ§in iyi Ã§alÄ±ÅŸmasÄ± Ã¶nemlidir. Her yazÄ±lÄ±m uygulamasÄ± gibi, yapay zeka sistemleri de beklentileri karÅŸÄ±lamayabilir veya istenmeyen sonuÃ§lar doÄŸurabilir. Bu yÃ¼zden bir yapay zeka modelinin davranÄ±ÅŸÄ±nÄ± anlamak ve aÃ§Ä±klamak Ã§ok Ã¶nemlidir.

Bu modelleri oluÅŸturmak iÃ§in kullandÄ±ÄŸÄ±nÄ±z veriler belirli demografik gruplarÄ± (Ä±rk, cinsiyet, siyasi gÃ¶rÃ¼ÅŸ, din gibi) iÃ§ermediÄŸinde veya bu demografik gruplarÄ± orantÄ±sÄ±z bir ÅŸekilde temsil ettiÄŸinde neler olabileceÄŸini hayal edin. Peki ya modelin Ã§Ä±ktÄ±sÄ± bazÄ± demografik gruplarÄ± kayÄ±racak ÅŸekilde yorumlandÄ±ÄŸÄ±nda ne olur? Uygulama iÃ§in sonuÃ§larÄ± nelerdir? AyrÄ±ca, modelin olumsuz bir sonucu olduÄŸunda ve insanlara zarar verdiÄŸinde ne olur? Yapay zeka sistemlerinin davranÄ±ÅŸÄ±ndan kim sorumludur? Bu mÃ¼fredatta bu tÃ¼r sorularÄ± inceleyeceÄŸiz.

Bu derste ÅŸunlarÄ± Ã¶ÄŸreneceksiniz:

- Makine Ã¶ÄŸreniminde adaletin Ã¶nemi ve adaletle ilgili zararlar hakkÄ±nda farkÄ±ndalÄ±k oluÅŸturmak.
- GÃ¼venilirlik ve gÃ¼venliÄŸi saÄŸlamak iÃ§in aykÄ±rÄ± deÄŸerleri ve olaÄŸandÄ±ÅŸÄ± senaryolarÄ± keÅŸfetme pratiÄŸini Ã¶ÄŸrenmek.
- Herkesin kapsayÄ±cÄ± sistemler tasarlayarak gÃ¼Ã§lendirilmesi gerektiÄŸini anlamak.
- Verilerin ve insanlarÄ±n gizliliÄŸini ve gÃ¼venliÄŸini korumanÄ±n ne kadar Ã¶nemli olduÄŸunu keÅŸfetmek.
- Yapay zeka modellerinin davranÄ±ÅŸÄ±nÄ± aÃ§Ä±klamak iÃ§in ÅŸeffaf bir yaklaÅŸÄ±mÄ±n Ã¶nemini gÃ¶rmek.
- Yapay zeka sistemlerinde gÃ¼ven oluÅŸturmak iÃ§in hesap verebilirliÄŸin ne kadar Ã¶nemli olduÄŸunu anlamak.

## Ã–n KoÅŸul

Ã–n koÅŸul olarak, "Sorumlu Yapay Zeka Ä°lkeleri" Ã¶ÄŸrenme yolunu tamamlayÄ±n ve aÅŸaÄŸÄ±daki videoyu izleyin:

Sorumlu Yapay Zeka hakkÄ±nda daha fazla bilgi edinmek iÃ§in bu [Ã–ÄŸrenme Yolunu](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77952-leestott) takip edin.

[![Microsoft'un Sorumlu Yapay Zeka YaklaÅŸÄ±mÄ±](https://img.youtube.com/vi/dnC8-uUZXSc/0.jpg)](https://youtu.be/dnC8-uUZXSc "Microsoft'un Sorumlu Yapay Zeka YaklaÅŸÄ±mÄ±")

> ğŸ¥ YukarÄ±daki gÃ¶rÃ¼ntÃ¼ye tÄ±klayarak videoyu izleyin: Microsoft'un Sorumlu Yapay Zeka YaklaÅŸÄ±mÄ±

## Adalet

Yapay zeka sistemleri herkese adil davranmalÄ± ve benzer gruplarÄ± farklÄ± ÅŸekillerde etkilemekten kaÃ§Ä±nmalÄ±dÄ±r. Ã–rneÄŸin, yapay zeka sistemleri tÄ±bbi tedavi, kredi baÅŸvurularÄ± veya istihdam konusunda rehberlik saÄŸladÄ±ÄŸÄ±nda, benzer semptomlara, finansal koÅŸullara veya mesleki niteliklere sahip herkese aynÄ± Ã¶nerileri sunmalÄ±dÄ±r. Hepimiz, kararlarÄ±mÄ±zÄ± ve eylemlerimizi etkileyen kalÄ±tsal Ã¶nyargÄ±lar taÅŸÄ±rÄ±z. Bu Ã¶nyargÄ±lar, yapay zeka sistemlerini eÄŸitmek iÃ§in kullandÄ±ÄŸÄ±mÄ±z verilere yansÄ±yabilir. Bu tÃ¼r manipÃ¼lasyonlar bazen istemeden gerÃ§ekleÅŸebilir. Verilere Ã¶nyargÄ± eklediÄŸinizi bilinÃ§li olarak fark etmek genellikle zordur.

**â€œAdaletsizlikâ€**, bir grup insan iÃ§in (Ã¶rneÄŸin Ä±rk, cinsiyet, yaÅŸ veya engellilik durumu aÃ§Ä±sÄ±ndan tanÄ±mlanan) olumsuz etkileri veya â€œzararlarÄ±â€ kapsar. Adaletle ilgili baÅŸlÄ±ca zararlar ÅŸu ÅŸekilde sÄ±nÄ±flandÄ±rÄ±labilir:

- **Tahsis**: Ã–rneÄŸin, bir cinsiyet veya etnik kÃ¶kenin diÄŸerine tercih edilmesi.
- **Hizmet kalitesi**: Verileri yalnÄ±zca belirli bir senaryo iÃ§in eÄŸitmek, ancak gerÃ§ekliÄŸin Ã§ok daha karmaÅŸÄ±k olmasÄ±, kÃ¶tÃ¼ performans gÃ¶steren bir hizmete yol aÃ§ar. Ã–rneÄŸin, koyu tenli insanlarÄ± algÄ±layamayan bir el sabunu daÄŸÄ±tÄ±cÄ±sÄ±. [Referans](https://gizmodo.com/why-cant-this-soap-dispenser-identify-dark-skin-1797931773)
- **AÅŸaÄŸÄ±lama**: Bir ÅŸeyi veya birini haksÄ±z yere eleÅŸtirmek ve etiketlemek. Ã–rneÄŸin, bir gÃ¶rÃ¼ntÃ¼ etiketleme teknolojisi koyu tenli insanlarÄ± goril olarak yanlÄ±ÅŸ etiketlemiÅŸtir.
- **AÅŸÄ±rÄ± veya yetersiz temsil**: Belirli bir grubun belirli bir meslekte gÃ¶rÃ¼lmemesi fikri ve bu durumu sÃ¼rekli olarak teÅŸvik eden herhangi bir hizmet veya iÅŸlev zarara katkÄ±da bulunur.
- **Stereotipleme**: Belirli bir grubu Ã¶nceden atanmÄ±ÅŸ Ã¶zelliklerle iliÅŸkilendirme. Ã–rneÄŸin, Ä°ngilizce ve TÃ¼rkÃ§e arasÄ±nda Ã§eviri yapan bir dil sistemi, cinsiyetle ilgili stereotipik iliÅŸkilere dayalÄ± hatalar iÃ§erebilir.

![TÃ¼rkÃ§eye Ã§eviri](../../../../1-Introduction/3-fairness/images/gender-bias-translate-en-tr.png)
> TÃ¼rkÃ§eye Ã§eviri

![Ä°ngilizceye geri Ã§eviri](../../../../1-Introduction/3-fairness/images/gender-bias-translate-tr-en.png)
> Ä°ngilizceye geri Ã§eviri

Yapay zeka sistemlerini tasarlarken ve test ederken, yapay zekanÄ±n adil olmasÄ±nÄ± ve Ã¶nyargÄ±lÄ± veya ayrÄ±mcÄ± kararlar vermek Ã¼zere programlanmamasÄ±nÄ± saÄŸlamamÄ±z gerekir. Yapay zekada ve makine Ã¶ÄŸreniminde adaleti garanti altÄ±na almak, karmaÅŸÄ±k bir sosyo-teknik zorluk olmaya devam ediyor.

### GÃ¼venilirlik ve GÃ¼venlik

GÃ¼ven oluÅŸturmak iÃ§in yapay zeka sistemlerinin normal ve beklenmedik koÅŸullar altÄ±nda gÃ¼venilir, gÃ¼venli ve tutarlÄ± olmasÄ± gerekir. Yapay zeka sistemlerinin Ã§eÅŸitli durumlarda nasÄ±l davranacaÄŸÄ±nÄ± bilmek Ã¶nemlidir, Ã¶zellikle de aykÄ±rÄ± deÄŸerler sÃ¶z konusu olduÄŸunda. Yapay zeka Ã§Ã¶zÃ¼mleri oluÅŸtururken, yapay zeka Ã§Ã¶zÃ¼mlerinin karÅŸÄ±laÅŸabileceÄŸi Ã§eÅŸitli koÅŸullarÄ± ele alma konusunda Ã¶nemli bir odaklanma gereklidir. Ã–rneÄŸin, bir otonom araÃ§ insanlarÄ±n gÃ¼venliÄŸini en Ã¶ncelikli olarak ele almalÄ±dÄ±r. SonuÃ§ olarak, aracÄ± Ã§alÄ±ÅŸtÄ±ran yapay zeka, gece, fÄ±rtÄ±na, kar fÄ±rtÄ±nasÄ±, yola koÅŸan Ã§ocuklar, evcil hayvanlar, yol Ã§alÄ±ÅŸmalarÄ± gibi aracÄ±n karÅŸÄ±laÅŸabileceÄŸi tÃ¼m olasÄ± senaryolarÄ± dikkate almalÄ±dÄ±r. Bir yapay zeka sisteminin geniÅŸ bir koÅŸul yelpazesini ne kadar gÃ¼venilir ve gÃ¼venli bir ÅŸekilde ele alabildiÄŸi, veri bilimci veya yapay zeka geliÅŸtiricisinin tasarÄ±m veya test sÄ±rasÄ±nda ne kadar Ã¶ngÃ¶rÃ¼de bulunduÄŸunu yansÄ±tÄ±r.

> [ğŸ¥ Video iÃ§in buraya tÄ±klayÄ±n: ](https://www.microsoft.com/videoplayer/embed/RE4vvIl)

### KapsayÄ±cÄ±lÄ±k

Yapay zeka sistemleri herkesin katÄ±lÄ±mÄ±nÄ± saÄŸlamalÄ± ve gÃ¼Ã§lendirmelidir. Yapay zeka sistemlerini tasarlarken ve uygularken, veri bilimciler ve yapay zeka geliÅŸtiriciler, sistemi istemeden insanlarÄ± dÄ±ÅŸlayabilecek potansiyel engelleri belirler ve ele alÄ±r. Ã–rneÄŸin, dÃ¼nya genelinde 1 milyar engelli insan bulunmaktadÄ±r. Yapay zekanÄ±n ilerlemesiyle, gÃ¼nlÃ¼k yaÅŸamlarÄ±nda bilgiye ve fÄ±rsatlara daha kolay eriÅŸebilirler. Engelleri ele alarak, herkes iÃ§in daha iyi deneyimler sunan yapay zeka Ã¼rÃ¼nlerini yenilikÃ§i bir ÅŸekilde geliÅŸtirme fÄ±rsatlarÄ± yaratÄ±lÄ±r.

> [ğŸ¥ Video iÃ§in buraya tÄ±klayÄ±n: yapay zekada kapsayÄ±cÄ±lÄ±k](https://www.microsoft.com/videoplayer/embed/RE4vl9v)

### GÃ¼venlik ve Gizlilik

Yapay zeka sistemleri gÃ¼venli olmalÄ± ve insanlarÄ±n gizliliÄŸine saygÄ± gÃ¶stermelidir. GizliliÄŸi, bilgileri veya hayatlarÄ± riske atan sistemlere insanlar daha az gÃ¼venir. Makine Ã¶ÄŸrenimi modellerini eÄŸitirken, en iyi sonuÃ§larÄ± elde etmek iÃ§in verilere gÃ¼veniriz. Bunu yaparken, verilerin kaynaÄŸÄ± ve bÃ¼tÃ¼nlÃ¼ÄŸÃ¼ dikkate alÄ±nmalÄ±dÄ±r. Ã–rneÄŸin, veriler kullanÄ±cÄ± tarafÄ±ndan mÄ± gÃ¶nderildi yoksa kamuya aÃ§Ä±k mÄ±ydÄ±? ArdÄ±ndan, verilerle Ã§alÄ±ÅŸÄ±rken, gizli bilgileri koruyabilen ve saldÄ±rÄ±lara karÅŸÄ± direnÃ§li yapay zeka sistemleri geliÅŸtirmek Ã¶nemlidir. Yapay zeka daha yaygÄ±n hale geldikÃ§e, gizliliÄŸi korumak ve Ã¶nemli kiÅŸisel ve iÅŸ bilgilerini gÃ¼vence altÄ±na almak giderek daha kritik ve karmaÅŸÄ±k hale geliyor. Gizlilik ve veri gÃ¼venliÄŸi sorunlarÄ±, yapay zeka iÃ§in Ã¶zellikle dikkat gerektirir Ã§Ã¼nkÃ¼ verilere eriÅŸim, yapay zeka sistemlerinin insanlar hakkÄ±nda doÄŸru ve bilgilendirilmiÅŸ tahminler ve kararlar vermesi iÃ§in gereklidir.

> [ğŸ¥ Video iÃ§in buraya tÄ±klayÄ±n: yapay zekada gÃ¼venlik](https://www.microsoft.com/videoplayer/embed/RE4voJF)

- EndÃ¼stri olarak, GDPR (Genel Veri Koruma YÃ¶netmeliÄŸi) gibi dÃ¼zenlemelerle Ã¶nemli ilerlemeler kaydettik.
- Ancak yapay zeka sistemleriyle, sistemleri daha kiÅŸisel ve etkili hale getirmek iÃ§in daha fazla kiÅŸisel veri ihtiyacÄ± ile gizlilik arasÄ±ndaki gerilimi kabul etmeliyiz.
- Ä°nternetle baÄŸlantÄ±lÄ± bilgisayarlarÄ±n doÄŸuÅŸunda olduÄŸu gibi, yapay zeka ile ilgili gÃ¼venlik sorunlarÄ±nda da bÃ¼yÃ¼k bir artÄ±ÅŸ gÃ¶rÃ¼yoruz.
- AynÄ± zamanda, yapay zekanÄ±n gÃ¼venliÄŸi artÄ±rmak iÃ§in kullanÄ±ldÄ±ÄŸÄ±nÄ± da gÃ¶rÃ¼yoruz. Ã–rneÄŸin, modern antivirÃ¼s tarayÄ±cÄ±larÄ±nÄ±n Ã§oÄŸu bugÃ¼n yapay zeka sezgileriyle Ã§alÄ±ÅŸÄ±yor.
- Veri Bilimi sÃ¼reÃ§lerimizin en son gizlilik ve gÃ¼venlik uygulamalarÄ±yla uyum iÃ§inde olmasÄ±nÄ± saÄŸlamalÄ±yÄ±z.

### ÅeffaflÄ±k

Yapay zeka sistemleri anlaÅŸÄ±labilir olmalÄ±dÄ±r. ÅeffaflÄ±ÄŸÄ±n Ã¶nemli bir kÄ±smÄ±, yapay zeka sistemlerinin ve bileÅŸenlerinin davranÄ±ÅŸÄ±nÄ± aÃ§Ä±klamaktÄ±r. Yapay zeka sistemlerinin anlaÅŸÄ±lmasÄ±nÄ± geliÅŸtirmek, paydaÅŸlarÄ±n nasÄ±l ve neden Ã§alÄ±ÅŸtÄ±klarÄ±nÄ± anlamalarÄ±nÄ± gerektirir, bÃ¶ylece potansiyel performans sorunlarÄ±nÄ±, gÃ¼venlik ve gizlilik endiÅŸelerini, Ã¶nyargÄ±larÄ±, dÄ±ÅŸlayÄ±cÄ± uygulamalarÄ± veya istenmeyen sonuÃ§larÄ± belirleyebilirler. AyrÄ±ca, yapay zeka sistemlerini kullananlarÄ±n, bunlarÄ± ne zaman, neden ve nasÄ±l kullanmayÄ± seÃ§tikleri konusunda dÃ¼rÃ¼st ve aÃ§Ä±k olmalarÄ± gerektiÄŸine inanÄ±yoruz. KullandÄ±klarÄ± sistemlerin sÄ±nÄ±rlamalarÄ± hakkÄ±nda da bilgi vermelidirler. Ã–rneÄŸin, bir banka tÃ¼ketici kredi kararlarÄ±nÄ± desteklemek iÃ§in bir yapay zeka sistemi kullanÄ±yorsa, sonuÃ§larÄ± incelemek ve sistemin Ã¶nerilerini hangi verilerin etkilediÄŸini anlamak Ã¶nemlidir. HÃ¼kÃ¼metler, endÃ¼strilerde yapay zekayÄ± dÃ¼zenlemeye baÅŸladÄ±ÄŸÄ±ndan, veri bilimciler ve kuruluÅŸlar, bir yapay zeka sisteminin dÃ¼zenleyici gereklilikleri karÅŸÄ±layÄ±p karÅŸÄ±lamadÄ±ÄŸÄ±nÄ±, Ã¶zellikle istenmeyen bir sonuÃ§ olduÄŸunda aÃ§Ä±klamalÄ±dÄ±r.

> [ğŸ¥ Video iÃ§in buraya tÄ±klayÄ±n: yapay zekada ÅŸeffaflÄ±k](https://www.microsoft.com/videoplayer/embed/RE4voJF)

- Yapay zeka sistemleri Ã§ok karmaÅŸÄ±k olduÄŸu iÃ§in nasÄ±l Ã§alÄ±ÅŸtÄ±klarÄ±nÄ± anlamak ve sonuÃ§larÄ± yorumlamak zordur.
- Bu anlayÄ±ÅŸ eksikliÄŸi, bu sistemlerin nasÄ±l yÃ¶netildiÄŸini, iÅŸletildiÄŸini ve belgelenmesini etkiler.
- Daha da Ã¶nemlisi, bu anlayÄ±ÅŸ eksikliÄŸi, bu sistemlerin Ã¼rettiÄŸi sonuÃ§lara dayanarak alÄ±nan kararlarÄ± etkiler.

### Hesap Verebilirlik

Yapay zeka sistemlerini tasarlayan ve uygulayan kiÅŸiler, sistemlerinin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ± konusunda hesap verebilir olmalÄ±dÄ±r. Hesap verebilirlik ihtiyacÄ±, Ã¶zellikle yÃ¼z tanÄ±ma gibi hassas teknolojilerde Ã§ok Ã¶nemlidir. Son zamanlarda, Ã¶zellikle kayÄ±p Ã§ocuklarÄ± bulmak gibi kullanÄ±mlarda teknolojinin potansiyelini gÃ¶ren kolluk kuvvetleri tarafÄ±ndan yÃ¼z tanÄ±ma teknolojisine olan talep artmÄ±ÅŸtÄ±r. Ancak, bu teknolojiler bir hÃ¼kÃ¼met tarafÄ±ndan vatandaÅŸlarÄ±nÄ±n temel Ã¶zgÃ¼rlÃ¼klerini riske atmak iÃ§in kullanÄ±labilir, Ã¶rneÄŸin belirli bireylerin sÃ¼rekli gÃ¶zetimini saÄŸlamak iÃ§in. Bu nedenle, veri bilimciler ve kuruluÅŸlar, yapay zeka sistemlerinin bireyler veya toplum Ã¼zerindeki etkisinden sorumlu olmalÄ±dÄ±r.

[![Ã–nde Gelen Yapay Zeka AraÅŸtÄ±rmacÄ±sÄ± YÃ¼z TanÄ±ma Yoluyla Toplu GÃ¶zetim UyarÄ±sÄ±](../../../../1-Introduction/3-fairness/images/accountability.png)](https://www.youtube.com/watch?v=Wldt8P5V6D0 "Microsoft'un Sorumlu Yapay Zeka YaklaÅŸÄ±mÄ±")

> ğŸ¥ YukarÄ±daki gÃ¶rÃ¼ntÃ¼ye tÄ±klayarak videoyu izleyin: YÃ¼z TanÄ±ma Yoluyla Toplu GÃ¶zetim UyarÄ±sÄ±

SonuÃ§ olarak, yapay zekayÄ± topluma getiren ilk nesil olarak, bilgisayarlarÄ±n insanlara karÅŸÄ± hesap verebilir olmasÄ±nÄ± nasÄ±l saÄŸlayacaÄŸÄ±mÄ±z ve bilgisayarlarÄ± tasarlayan insanlarÄ±n diÄŸer herkese karÅŸÄ± hesap verebilir olmasÄ±nÄ± nasÄ±l saÄŸlayacaÄŸÄ±mÄ±z, neslimizin en bÃ¼yÃ¼k sorularÄ±ndan biridir.

## Etki DeÄŸerlendirmesi

Bir makine Ã¶ÄŸrenimi modelini eÄŸitmeden Ã¶nce, yapay zeka sisteminin amacÄ±nÄ±, planlanan kullanÄ±mÄ±nÄ±, nerede uygulanacaÄŸÄ±nÄ± ve sistemle kimlerin etkileÅŸimde bulunacaÄŸÄ±nÄ± anlamak iÃ§in bir etki deÄŸerlendirmesi yapmak Ã¶nemlidir. Bunlar, sistemi deÄŸerlendiren inceleyiciler veya test edenler iÃ§in potansiyel riskleri ve beklenen sonuÃ§larÄ± belirlerken dikkate alÄ±nmasÄ± gereken faktÃ¶rleri anlamalarÄ±na yardÄ±mcÄ± olur.

Etki deÄŸerlendirmesi yaparken odaklanÄ±lmasÄ± gereken alanlar ÅŸunlardÄ±r:

* **Bireyler Ã¼zerindeki olumsuz etkiler**. Sistemin performansÄ±nÄ± engelleyen herhangi bir kÄ±sÄ±tlama veya gereklilik, desteklenmeyen kullanÄ±m veya bilinen sÄ±nÄ±rlamalarÄ±n farkÄ±nda olmak, sistemin bireylere zarar verebilecek ÅŸekilde kullanÄ±lmamasÄ±nÄ± saÄŸlamak iÃ§in Ã¶nemlidir.
* **Veri gereksinimleri**. Sistemin verileri nasÄ±l ve nerede kullanacaÄŸÄ±nÄ± anlamak, inceleyicilerin dikkate almasÄ± gereken veri gereksinimlerini (Ã¶rneÄŸin, GDPR veya HIPPA veri dÃ¼zenlemeleri) keÅŸfetmelerini saÄŸlar. AyrÄ±ca, verilerin kaynaÄŸÄ± veya miktarÄ±nÄ±n eÄŸitim iÃ§in yeterli olup olmadÄ±ÄŸÄ±nÄ± inceleyin.
* **Etki Ã¶zeti**. Sistemin kullanÄ±mÄ±ndan kaynaklanabilecek potansiyel zararlarÄ±n bir listesini toplayÄ±n. Makine Ã¶ÄŸrenimi yaÅŸam dÃ¶ngÃ¼sÃ¼ boyunca, belirlenen sorunlarÄ±n azaltÄ±lÄ±p azaltÄ±lmadÄ±ÄŸÄ±nÄ± veya ele alÄ±nÄ±p alÄ±nmadÄ±ÄŸÄ±nÄ± gÃ¶zden geÃ§irin.
* **AltÄ± temel ilke iÃ§in uygulanabilir hedefler**. Her bir ilkenin hedeflerinin karÅŸÄ±lanÄ±p karÅŸÄ±lanmadÄ±ÄŸÄ±nÄ± ve herhangi bir boÅŸluk olup olmadÄ±ÄŸÄ±nÄ± deÄŸerlendirin.

## Sorumlu Yapay Zeka ile Hata AyÄ±klama

Bir yazÄ±lÄ±m uygulamasÄ±nÄ± hata ayÄ±klamak gibi, bir yapay zeka sistemini hata ayÄ±klamak, sistemdeki sorunlarÄ± belirleme ve Ã§Ã¶zme sÃ¼recidir. Bir modelin beklenildiÄŸi gibi veya sorumlu bir ÅŸekilde performans gÃ¶stermemesine neden olan birÃ§ok faktÃ¶r vardÄ±r. Ã‡oÄŸu geleneksel model performans metriÄŸi, bir modelin performansÄ±nÄ±n nicel toplamlarÄ±dÄ±r ve bir modelin sorumlu yapay zeka ilkelerini nasÄ±l ihlal ettiÄŸini analiz etmek iÃ§in yeterli deÄŸildir. AyrÄ±ca, bir makine Ã¶ÄŸrenimi modeli, sonuÃ§larÄ±nÄ± neyin yÃ¶nlendirdiÄŸini anlamayÄ± veya hata yaptÄ±ÄŸÄ±nda aÃ§Ä±klama saÄŸlamayÄ± zorlaÅŸtÄ±ran bir kara kutudur. Bu kursta daha sonra, yapay zeka sistemlerini hata ayÄ±klamak iÃ§in Sorumlu Yapay Zeka panosunu nasÄ±l kullanacaÄŸÄ±mÄ±zÄ± Ã¶ÄŸreneceÄŸiz. Pano, veri bilimciler ve yapay zeka geliÅŸtiriciler iÃ§in ÅŸu iÅŸlemleri gerÃ§ekleÅŸtirmek Ã¼zere kapsamlÄ± bir araÃ§ saÄŸlar:

* **Hata analizi**. Modelin adalet veya gÃ¼venilirliÄŸi etkileyebilecek hata daÄŸÄ±lÄ±mÄ±nÄ± belirlemek.
* **Model genel gÃ¶rÃ¼nÃ¼mÃ¼**. Modelin performansÄ±nda veri gruplarÄ± arasÄ±nda nerede farklÄ±lÄ±klar olduÄŸunu keÅŸfetmek.
* **Veri analizi**. Veri daÄŸÄ±lÄ±mÄ±nÄ± anlamak ve adalet, kapsayÄ±cÄ±lÄ±k ve gÃ¼venilirlik sorunlarÄ±na yol aÃ§abilecek olasÄ± Ã¶nyargÄ±larÄ± belirlemek.
* **Model yorumlanabilirliÄŸi**. Modelin tahminlerini neyin etkilediÄŸini veya yÃ¶nlendirdiÄŸini anlamak. Bu, modelin davranÄ±ÅŸÄ±nÄ± aÃ§Ä±klamak iÃ§in Ã¶nemlidir ve ÅŸeffaflÄ±k ve hesap verebilirlik aÃ§Ä±sÄ±ndan kritiktir.

## ğŸš€ Zorluk

ZararlarÄ±n baÅŸtan Ã¶nlenmesi iÃ§in ÅŸunlarÄ± yapmalÄ±yÄ±z:

- sistemler Ã¼zerinde Ã§alÄ±ÅŸan insanlar arasÄ±nda farklÄ± geÃ§miÅŸlere ve bakÄ±ÅŸ aÃ§Ä±larÄ±na sahip olmak
- toplumumuzun Ã§eÅŸitliliÄŸini yansÄ±tan veri setlerine yatÄ±rÄ±m yapmak
- makine Ã¶ÄŸrenimi yaÅŸam dÃ¶ngÃ¼sÃ¼ boyunca sorumlu yapay zekayÄ± tespit etmek ve dÃ¼zeltmek iÃ§in daha iyi yÃ¶ntemler geliÅŸtirmek

Model oluÅŸturma ve kullanÄ±mÄ± sÄ±rasÄ±nda bir modelin gÃ¼venilmezliÄŸinin aÃ§Ä±kÃ§a gÃ¶rÃ¼ldÃ¼ÄŸÃ¼ gerÃ§ek yaÅŸam senaryolarÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼n. BaÅŸka neleri dikkate almalÄ±yÄ±z?

## [Ders SonrasÄ± Test](https://ff-quizzes.netlify.app/en/ml/)

## GÃ¶zden GeÃ§irme ve Kendi Kendine Ã‡alÄ±ÅŸma

Bu derste, makine Ã¶ÄŸreniminde adalet ve adaletsizlik kavramlarÄ±nÄ±n temellerini Ã¶ÄŸrendiniz.
Bu atÃ¶lyeyi izleyerek konulara daha derinlemesine dalÄ±n: 

- Sorumlu yapay zeka arayÄ±ÅŸÄ±: Ä°lkeleri uygulamaya dÃ¶kmek - Besmira Nushi, Mehrnoosh Sameki ve Amit Sharma tarafÄ±ndan

[![Sorumlu AI AraÃ§ Kutusu: Sorumlu yapay zeka oluÅŸturmak iÃ§in aÃ§Ä±k kaynaklÄ± bir Ã§erÃ§eve](https://img.youtube.com/vi/tGgJCrA-MZU/0.jpg)](https://www.youtube.com/watch?v=tGgJCrA-MZU "RAI Toolbox: Sorumlu yapay zeka oluÅŸturmak iÃ§in aÃ§Ä±k kaynaklÄ± bir Ã§erÃ§eve")


> ğŸ¥ YukarÄ±daki gÃ¶rsele tÄ±klayarak videoyu izleyin: RAI Toolbox: Sorumlu yapay zeka oluÅŸturmak iÃ§in aÃ§Ä±k kaynaklÄ± bir Ã§erÃ§eve - Besmira Nushi, Mehrnoosh Sameki ve Amit Sharma tarafÄ±ndan

AyrÄ±ca okuyun: 

- Microsoftâ€™un Sorumlu AI kaynak merkezi: [Responsible AI Resources â€“ Microsoft AI](https://www.microsoft.com/ai/responsible-ai-resources?activetab=pivot1%3aprimaryr4) 

- Microsoftâ€™un FATE araÅŸtÄ±rma grubu: [FATE: Fairness, Accountability, Transparency, and Ethics in AI - Microsoft Research](https://www.microsoft.com/research/theme/fate/) 

RAI AraÃ§ Kutusu: 

- [Responsible AI Toolbox GitHub deposu](https://github.com/microsoft/responsible-ai-toolbox)

Azure Machine Learning'in adalet saÄŸlama araÃ§larÄ± hakkÄ±nda okuyun:

- [Azure Machine Learning](https://docs.microsoft.com/azure/machine-learning/concept-fairness-ml?WT.mc_id=academic-77952-leestott) 

## Ã–dev

[RAI Toolboxâ€™u KeÅŸfedin](assignment.md)

---

**Feragatname**:  
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluÄŸu saÄŸlamak iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±k iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalar iÃ§in sorumluluk kabul etmiyoruz.