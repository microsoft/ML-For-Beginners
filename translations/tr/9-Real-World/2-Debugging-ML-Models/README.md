<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "df2b538e8fbb3e91cf0419ae2f858675",
  "translation_date": "2025-09-06T07:53:42+00:00",
  "source_file": "9-Real-World/2-Debugging-ML-Models/README.md",
  "language_code": "tr"
}
-->
# Postscript: Makine Ã–ÄŸreniminde Model Hata AyÄ±klama ve Sorumlu AI Panosu BileÅŸenleri KullanÄ±mÄ±

## [Ders Ã–ncesi Test](https://ff-quizzes.netlify.app/en/ml/)

## GiriÅŸ

Makine Ã¶ÄŸrenimi gÃ¼nlÃ¼k hayatÄ±mÄ±zÄ± etkiliyor. Yapay zeka, saÄŸlÄ±k, finans, eÄŸitim ve istihdam gibi bireyler ve toplum Ã¼zerinde etkili olan en Ã¶nemli sistemlere giderek daha fazla entegre oluyor. Ã–rneÄŸin, saÄŸlÄ±k teÅŸhisleri veya dolandÄ±rÄ±cÄ±lÄ±k tespiti gibi gÃ¼nlÃ¼k karar verme gÃ¶revlerinde sistemler ve modeller kullanÄ±lÄ±yor. Bu nedenle, yapay zekadaki ilerlemeler ve hÄ±zla artan benimseme oranÄ±, geliÅŸen toplumsal beklentiler ve buna yanÄ±t olarak artan dÃ¼zenlemelerle karÅŸÄ±laÅŸÄ±yor. Yapay zeka sistemlerinin beklentileri karÅŸÄ±lamadÄ±ÄŸÄ±, yeni zorluklar ortaya Ã§Ä±kardÄ±ÄŸÄ± ve hÃ¼kÃ¼metlerin yapay zeka Ã§Ã¶zÃ¼mlerini dÃ¼zenlemeye baÅŸladÄ±ÄŸÄ± alanlarÄ± sÃ¼rekli olarak gÃ¶rÃ¼yoruz. Bu nedenle, bu modellerin herkes iÃ§in adil, gÃ¼venilir, kapsayÄ±cÄ±, ÅŸeffaf ve hesap verebilir sonuÃ§lar saÄŸlamak amacÄ±yla analiz edilmesi Ã¶nemlidir.

Bu mÃ¼fredatta, bir modelin sorumlu yapay zeka sorunlarÄ±na sahip olup olmadÄ±ÄŸÄ±nÄ± deÄŸerlendirmek iÃ§in kullanÄ±labilecek pratik araÃ§lara bakacaÄŸÄ±z. Geleneksel makine Ã¶ÄŸrenimi hata ayÄ±klama teknikleri genellikle toplu doÄŸruluk veya ortalama hata kaybÄ± gibi nicel hesaplamalara dayanÄ±r. Bu modelleri oluÅŸturmak iÃ§in kullandÄ±ÄŸÄ±nÄ±z verilerin belirli demografik Ã¶zelliklerden (Ã¶rneÄŸin, Ä±rk, cinsiyet, siyasi gÃ¶rÃ¼ÅŸ, din) yoksun olduÄŸunu veya bu demografik Ã¶zellikleri orantÄ±sÄ±z bir ÅŸekilde temsil ettiÄŸini hayal edin. Peki ya modelin Ã§Ä±ktÄ±sÄ± bazÄ± demografik gruplarÄ± kayÄ±racak ÅŸekilde yorumlanÄ±rsa? Bu, hassas Ã¶zellik gruplarÄ±nÄ±n aÅŸÄ±rÄ± veya yetersiz temsil edilmesine yol aÃ§arak modelde adalet, kapsayÄ±cÄ±lÄ±k veya gÃ¼venilirlik sorunlarÄ±na neden olabilir. AyrÄ±ca, makine Ã¶ÄŸrenimi modelleri genellikle "kara kutu" olarak kabul edilir, bu da bir modelin tahminlerini neyin yÃ¶nlendirdiÄŸini anlamayÄ± ve aÃ§Ä±klamayÄ± zorlaÅŸtÄ±rÄ±r. Veri bilimciler ve yapay zeka geliÅŸtiricileri, bir modelin adaletini veya gÃ¼venilirliÄŸini deÄŸerlendirmek ve hata ayÄ±klamak iÃ§in yeterli araÃ§lara sahip olmadÄ±klarÄ±nda bu tÃ¼r zorluklarla karÅŸÄ±laÅŸÄ±rlar.

Bu derste, modellerinizi aÅŸaÄŸÄ±daki yÃ¶ntemlerle hata ayÄ±klamayÄ± Ã¶ÄŸreneceksiniz:

- **Hata Analizi**: Modelin veri daÄŸÄ±lÄ±mÄ±nda yÃ¼ksek hata oranlarÄ±na sahip olduÄŸu yerleri belirleyin.
- **Model Genel BakÄ±ÅŸÄ±**: Modelinizin performans metriklerindeki farklÄ±lÄ±klarÄ± keÅŸfetmek iÃ§in farklÄ± veri gruplarÄ± arasÄ±nda karÅŸÄ±laÅŸtÄ±rmalÄ± analiz yapÄ±n.
- **Veri Analizi**: Modelinizin bir veri demografisini diÄŸerine kayÄ±rmasÄ±na neden olabilecek veri aÅŸÄ±rÄ± veya yetersiz temsilini araÅŸtÄ±rÄ±n.
- **Ã–zellik Ã–nem Derecesi**: Modelinizin tahminlerini kÃ¼resel veya yerel dÃ¼zeyde yÃ¶nlendiren Ã¶zellikleri anlayÄ±n.

## Ã–n KoÅŸul

Ã–n koÅŸul olarak, [GeliÅŸtiriciler iÃ§in Sorumlu AI AraÃ§larÄ±](https://www.microsoft.com/ai/ai-lab-responsible-ai-dashboard) incelemesini tamamlayÄ±n.

> ![Sorumlu AI AraÃ§larÄ± ile ilgili Gif](../../../../9-Real-World/2-Debugging-ML-Models/images/rai-overview.gif)

## Hata Analizi

DoÄŸruluÄŸu Ã¶lÃ§mek iÃ§in kullanÄ±lan geleneksel model performans metrikleri genellikle doÄŸru ve yanlÄ±ÅŸ tahminlere dayalÄ± hesaplamalardÄ±r. Ã–rneÄŸin, bir modelin %89 oranÄ±nda doÄŸru olduÄŸunu ve 0.001 hata kaybÄ±na sahip olduÄŸunu belirlemek iyi bir performans olarak kabul edilebilir. Ancak hatalar, temel veri kÃ¼menizde eÅŸit olarak daÄŸÄ±lmayabilir. %89 model doÄŸruluk puanÄ± alabilirsiniz, ancak modelin veri gruplarÄ±nÄ±n belirli bÃ¶lgelerinde %42 oranÄ±nda baÅŸarÄ±sÄ±z olduÄŸunu keÅŸfedebilirsiniz. Belirli veri gruplarÄ±ndaki bu hata kalÄ±plarÄ±nÄ±n sonuÃ§larÄ±, adalet veya gÃ¼venilirlik sorunlarÄ±na yol aÃ§abilir. Modelin iyi veya kÃ¶tÃ¼ performans gÃ¶sterdiÄŸi alanlarÄ± anlamak Ã¶nemlidir. Modelinizdeki yÃ¼ksek hata oranlarÄ±na sahip veri bÃ¶lgeleri, Ã¶nemli bir veri demografisi olabilir.

![Model hatalarÄ±nÄ± analiz etme ve hata ayÄ±klama](../../../../9-Real-World/2-Debugging-ML-Models/images/ea-error-distribution.png)

RAI panosundaki Hata Analizi bileÅŸeni, model hatalarÄ±nÄ±n Ã§eÅŸitli gruplar arasÄ±nda nasÄ±l daÄŸÄ±ldÄ±ÄŸÄ±nÄ± bir aÄŸaÃ§ gÃ¶rselleÅŸtirmesiyle gÃ¶sterir. Bu, veri kÃ¼menizde yÃ¼ksek hata oranÄ±na sahip Ã¶zellikleri veya alanlarÄ± belirlemede faydalÄ±dÄ±r. Modelin hatalarÄ±nÄ±n Ã§oÄŸunun nereden geldiÄŸini gÃ¶rerek, sorunun kÃ¶k nedenini araÅŸtÄ±rmaya baÅŸlayabilirsiniz. AyrÄ±ca veri gruplarÄ± oluÅŸturarak analiz yapabilirsiniz. Bu veri gruplarÄ±, modelin bir grupta neden iyi performans gÃ¶sterdiÄŸini, ancak diÄŸerinde hatalÄ± olduÄŸunu belirlemek iÃ§in hata ayÄ±klama sÃ¼recinde yardÄ±mcÄ± olur.

![Hata Analizi](../../../../9-Real-World/2-Debugging-ML-Models/images/ea-error-cohort.png)

AÄŸaÃ§ haritasÄ±ndaki gÃ¶rsel gÃ¶stergeler, sorunlu alanlarÄ± daha hÄ±zlÄ± bulmaya yardÄ±mcÄ± olur. Ã–rneÄŸin, bir aÄŸaÃ§ dÃ¼ÄŸÃ¼mÃ¼nÃ¼n daha koyu kÄ±rmÄ±zÄ± tonuna sahip olmasÄ±, daha yÃ¼ksek hata oranÄ±nÄ± gÃ¶sterir.

IsÄ± haritasÄ±, kullanÄ±cÄ±larÄ±n bir veya iki Ã¶zelliÄŸi kullanarak hata oranÄ±nÄ± araÅŸtÄ±rmasÄ± iÃ§in baÅŸka bir gÃ¶rselleÅŸtirme iÅŸlevselliÄŸidir. Bu, model hatalarÄ±na katkÄ±da bulunan Ã¶zellikleri tÃ¼m veri kÃ¼mesi veya gruplar arasÄ±nda bulmaya yardÄ±mcÄ± olur.

![Hata Analizi IsÄ± HaritasÄ±](../../../../9-Real-World/2-Debugging-ML-Models/images/ea-heatmap.png)

Hata analizini ÅŸu durumlarda kullanÄ±n:

* Model hatalarÄ±nÄ±n bir veri kÃ¼mesi ve Ã§eÅŸitli giriÅŸ ve Ã¶zellik boyutlarÄ± arasÄ±nda nasÄ±l daÄŸÄ±ldÄ±ÄŸÄ±nÄ± derinlemesine anlamak.
* Toplu performans metriklerini bÃ¶lerek, hedeflenen iyileÅŸtirme adÄ±mlarÄ±nÄ±zÄ± bilgilendirmek iÃ§in hatalÄ± gruplarÄ± otomatik olarak keÅŸfetmek.

## Model Genel BakÄ±ÅŸÄ±

Bir makine Ã¶ÄŸrenimi modelinin performansÄ±nÄ± deÄŸerlendirmek, davranÄ±ÅŸÄ±nÄ± bÃ¼tÃ¼nsel bir ÅŸekilde anlamayÄ± gerektirir. Bu, hata oranÄ±, doÄŸruluk, geri Ã§aÄŸÄ±rma, hassasiyet veya MAE (Ortalama Mutlak Hata) gibi birden fazla metriÄŸi gÃ¶zden geÃ§irerek performans metrikleri arasÄ±ndaki farklÄ±lÄ±klarÄ± bulmakla saÄŸlanabilir. Bir performans metriÄŸi harika gÃ¶rÃ¼nebilir, ancak baÅŸka bir metrikteki yanlÄ±ÅŸlÄ±klar ortaya Ã§Ä±kabilir. AyrÄ±ca, metrikleri tÃ¼m veri kÃ¼mesi veya gruplar arasÄ±nda karÅŸÄ±laÅŸtÄ±rmak, modelin nerede iyi veya kÃ¶tÃ¼ performans gÃ¶sterdiÄŸini anlamaya yardÄ±mcÄ± olur. Bu, Ã¶zellikle hassas ve hassas olmayan Ã¶zellikler (Ã¶rneÄŸin, hastanÄ±n Ä±rkÄ±, cinsiyeti veya yaÅŸÄ±) arasÄ±nda modelin performansÄ±nÄ± gÃ¶rerek modelin potansiyel adaletsizliÄŸini ortaya Ã§Ä±karmak iÃ§in Ã¶nemlidir. Ã–rneÄŸin, modelin hassas Ã¶zelliklere sahip bir grupta daha hatalÄ± olduÄŸunu keÅŸfetmek, modelin potansiyel adaletsizliÄŸini ortaya Ã§Ä±karabilir.

RAI panosundaki Model Genel BakÄ±ÅŸÄ± bileÅŸeni, yalnÄ±zca bir veri grubundaki performans metriklerini analiz etmekle kalmaz, aynÄ± zamanda kullanÄ±cÄ±larÄ±n modelin davranÄ±ÅŸÄ±nÄ± farklÄ± gruplar arasÄ±nda karÅŸÄ±laÅŸtÄ±rma yeteneÄŸi saÄŸlar.

![Veri gruplarÄ± - RAI panosunda model genel bakÄ±ÅŸÄ±](../../../../9-Real-World/2-Debugging-ML-Models/images/model-overview-dataset-cohorts.png)

BileÅŸenin Ã¶zellik tabanlÄ± analiz iÅŸlevselliÄŸi, kullanÄ±cÄ±larÄ±n belirli bir Ã¶zellik iÃ§inde veri alt gruplarÄ±nÄ± daraltarak anormallikleri daha ayrÄ±ntÄ±lÄ± bir dÃ¼zeyde belirlemesine olanak tanÄ±r. Ã–rneÄŸin, pano, kullanÄ±cÄ± tarafÄ±ndan seÃ§ilen bir Ã¶zellik iÃ§in (Ã¶rneÄŸin, *"hastanede geÃ§irilen sÃ¼re < 3"* veya *"hastanede geÃ§irilen sÃ¼re >= 7"*) otomatik olarak gruplar oluÅŸturmak iÃ§in yerleÅŸik zekaya sahiptir. Bu, kullanÄ±cÄ±larÄ±n daha bÃ¼yÃ¼k bir veri grubundan belirli bir Ã¶zelliÄŸi izole ederek modelin hatalÄ± sonuÃ§larÄ±nÄ±n anahtar bir etkileyicisi olup olmadÄ±ÄŸÄ±nÄ± gÃ¶rmesini saÄŸlar.

![Ã–zellik gruplarÄ± - RAI panosunda model genel bakÄ±ÅŸÄ±](../../../../9-Real-World/2-Debugging-ML-Models/images/model-overview-feature-cohorts.png)

Model Genel BakÄ±ÅŸÄ± bileÅŸeni iki tÃ¼r farklÄ±lÄ±k metriÄŸini destekler:

**Model performansÄ±ndaki farklÄ±lÄ±k**: Bu metrikler, seÃ§ilen performans metriÄŸinin deÄŸerlerindeki farklÄ±lÄ±klarÄ± veri alt gruplarÄ± arasÄ±nda hesaplar. Ä°ÅŸte birkaÃ§ Ã¶rnek:

* DoÄŸruluk oranÄ±ndaki farklÄ±lÄ±k
* Hata oranÄ±ndaki farklÄ±lÄ±k
* Hassasiyetteki farklÄ±lÄ±k
* Geri Ã§aÄŸÄ±rmadaki farklÄ±lÄ±k
* Ortalama mutlak hatadaki (MAE) farklÄ±lÄ±k

**SeÃ§im oranÄ±ndaki farklÄ±lÄ±k**: Bu metrik, veri alt gruplarÄ± arasÄ±ndaki seÃ§im oranÄ±ndaki (olumlu tahmin) farkÄ± iÃ§erir. Buna bir Ã¶rnek, kredi onay oranlarÄ±ndaki farklÄ±lÄ±ktÄ±r. SeÃ§im oranÄ±, her sÄ±nÄ±ftaki veri noktalarÄ±nÄ±n 1 olarak sÄ±nÄ±flandÄ±rÄ±lma oranÄ±nÄ± (ikili sÄ±nÄ±flandÄ±rmada) veya tahmin deÄŸerlerinin daÄŸÄ±lÄ±mÄ±nÄ± (regresyonda) ifade eder.

## Veri Analizi

> "Veriyi yeterince zorlayÄ±n, her ÅŸeyi itiraf eder" - Ronald Coase

Bu ifade aÅŸÄ±rÄ± gÃ¶rÃ¼nebilir, ancak verilerin herhangi bir sonucu desteklemek iÃ§in manipÃ¼le edilebileceÄŸi doÄŸrudur. Bu tÃ¼r manipÃ¼lasyon bazen istemeden gerÃ§ekleÅŸebilir. Ä°nsanlar olarak hepimiz Ã¶nyargÄ±ya sahibiz ve verilerde Ã¶nyargÄ± oluÅŸturduÄŸumuzda bunu bilinÃ§li olarak fark etmek genellikle zordur. Yapay zekada ve makine Ã¶ÄŸreniminde adaleti saÄŸlamak karmaÅŸÄ±k bir zorluk olmaya devam ediyor.

Veri, geleneksel model performans metrikleri iÃ§in bÃ¼yÃ¼k bir kÃ¶r noktadÄ±r. YÃ¼ksek doÄŸruluk puanlarÄ±na sahip olabilirsiniz, ancak bu her zaman veri kÃ¼menizdeki temel veri Ã¶nyargÄ±sÄ±nÄ± yansÄ±tmaz. Ã–rneÄŸin, bir ÅŸirketteki Ã§alÄ±ÅŸanlarÄ±n %27'sinin kadÄ±n, %73'Ã¼nÃ¼n erkek olduÄŸu bir veri kÃ¼mesi, bir iÅŸ ilanÄ± yapay zeka modeli bu verilerle eÄŸitildiÄŸinde, Ã¼st dÃ¼zey iÅŸ pozisyonlarÄ± iÃ§in Ã§oÄŸunlukla erkek bir kitleyi hedefleyebilir. Bu tÃ¼r bir veri dengesizliÄŸi, modelin tahminini bir cinsiyeti kayÄ±racak ÅŸekilde Ã§arpÄ±ttÄ±. Bu, yapay zeka modelinde bir adalet sorunu olduÄŸunu ve cinsiyet Ã¶nyargÄ±sÄ± bulunduÄŸunu gÃ¶sterir.

RAI panosundaki Veri Analizi bileÅŸeni, veri kÃ¼mesinde aÅŸÄ±rÄ± ve yetersiz temsil edilen alanlarÄ± belirlemeye yardÄ±mcÄ± olur. KullanÄ±cÄ±lara veri dengesizliklerinden veya belirli bir veri grubunun temsil eksikliÄŸinden kaynaklanan hatalarÄ±n ve adalet sorunlarÄ±nÄ±n kÃ¶k nedenini teÅŸhis etme olanaÄŸÄ± saÄŸlar. Bu, kullanÄ±cÄ±larÄ±n veri kÃ¼melerini tahmin edilen ve gerÃ§ek sonuÃ§lara, hata gruplarÄ±na ve belirli Ã¶zelliklere gÃ¶re gÃ¶rselleÅŸtirmesine olanak tanÄ±r. Bazen yetersiz temsil edilen bir veri grubunu keÅŸfetmek, modelin iyi Ã¶ÄŸrenmediÄŸini ve dolayÄ±sÄ±yla yÃ¼ksek yanlÄ±ÅŸlÄ±klar olduÄŸunu da ortaya Ã§Ä±karabilir. Veri Ã¶nyargÄ±sÄ±na sahip bir model, yalnÄ±zca bir adalet sorunu deÄŸil, aynÄ± zamanda modelin kapsayÄ±cÄ± veya gÃ¼venilir olmadÄ±ÄŸÄ±nÄ± gÃ¶sterir.

![RAI Panosundaki Veri Analizi bileÅŸeni](../../../../9-Real-World/2-Debugging-ML-Models/images/dataanalysis-cover.png)

Veri analizini ÅŸu durumlarda kullanÄ±n:

* Veri kÃ¼mesi istatistiklerini farklÄ± boyutlara (gruplara) ayÄ±rmak iÃ§in farklÄ± filtreler seÃ§erek keÅŸfetmek.
* Veri kÃ¼menizin farklÄ± gruplar ve Ã¶zellik gruplarÄ± arasÄ±ndaki daÄŸÄ±lÄ±mÄ±nÄ± anlamak.
* Adalet, hata analizi ve nedensellik ile ilgili bulgularÄ±nÄ±zÄ±n (diÄŸer pano bileÅŸenlerinden tÃ¼retilen) veri kÃ¼menizin daÄŸÄ±lÄ±mÄ±ndan kaynaklanÄ±p kaynaklanmadÄ±ÄŸÄ±nÄ± belirlemek.
* Temsil sorunlarÄ±ndan, etiket gÃ¼rÃ¼ltÃ¼sÃ¼nden, Ã¶zellik gÃ¼rÃ¼ltÃ¼sÃ¼nden, etiket Ã¶nyargÄ±sÄ±ndan ve benzeri faktÃ¶rlerden kaynaklanan hatalarÄ± azaltmak iÃ§in daha fazla veri toplamanÄ±z gereken alanlarÄ± belirlemek.

## Model YorumlanabilirliÄŸi

Makine Ã¶ÄŸrenimi modelleri genellikle "kara kutu" olarak kabul edilir. Bir modelin tahminini yÃ¶nlendiren temel veri Ã¶zelliklerini anlamak zor olabilir. Bir modelin belirli bir tahmini neden yaptÄ±ÄŸÄ±nÄ± aÃ§Ä±klamak Ã¶nemlidir. Ã–rneÄŸin, bir yapay zeka sistemi, bir diyabet hastasÄ±nÄ±n 30 gÃ¼n iÃ§inde hastaneye yeniden yatma riski taÅŸÄ±dÄ±ÄŸÄ±nÄ± tahmin ederse, tahminine yol aÃ§an destekleyici verileri saÄŸlamalÄ±dÄ±r. Destekleyici veri gÃ¶stergelerine sahip olmak, klinisyenlerin veya hastanelerin iyi bilgilendirilmiÅŸ kararlar almasÄ±na yardÄ±mcÄ± olmak iÃ§in ÅŸeffaflÄ±k saÄŸlar. AyrÄ±ca, bir modelin bireysel bir hasta iÃ§in neden bir tahminde bulunduÄŸunu aÃ§Ä±klayabilmek, saÄŸlÄ±k dÃ¼zenlemeleriyle hesap verebilirlik saÄŸlar. Ä°nsanlarÄ±n hayatlarÄ±nÄ± etkileyen ÅŸekillerde makine Ã¶ÄŸrenimi modelleri kullanÄ±yorsanÄ±z, bir modelin davranÄ±ÅŸÄ±nÄ± neyin etkilediÄŸini anlamak ve aÃ§Ä±klamak Ã§ok Ã¶nemlidir. Model aÃ§Ä±klanabilirliÄŸi ve yorumlanabilirliÄŸi, aÅŸaÄŸÄ±daki senaryolarda sorularÄ± yanÄ±tlamaya yardÄ±mcÄ± olur:

* Model hata ayÄ±klama: Modelim neden bu hatayÄ± yaptÄ±? Modelimi nasÄ±l geliÅŸtirebilirim?
* Ä°nsan-Yapay Zeka iÅŸ birliÄŸi: Modelin kararlarÄ±nÄ± nasÄ±l anlayabilir ve gÃ¼venebilirim?
* DÃ¼zenleyici uyumluluk: Modelim yasal gereklilikleri karÅŸÄ±lÄ±yor mu?

RAI panosundaki Ã–zellik Ã–nem Derecesi bileÅŸeni, bir modelin tahminlerini nasÄ±l yaptÄ±ÄŸÄ±nÄ± anlamak ve hata ayÄ±klamak iÃ§in kapsamlÄ± bir araÃ§tÄ±r. AyrÄ±ca, makine Ã¶ÄŸrenimi profesyonelleri ve karar vericiler iÃ§in modelin davranÄ±ÅŸÄ±nÄ± etkileyen Ã¶zelliklerin kanÄ±tlarÄ±nÄ± aÃ§Ä±klamak ve dÃ¼zenleyici uyumluluk iÃ§in gÃ¶stermek adÄ±na faydalÄ± bir araÃ§tÄ±r. KullanÄ±cÄ±lar, modelin tahminlerini yÃ¶nlendiren Ã¶zellikleri doÄŸrulamak iÃ§in hem kÃ¼resel hem de yerel aÃ§Ä±klamalarÄ± keÅŸfedebilir. KÃ¼resel aÃ§Ä±klamalar, bir modelin genel tahminini etkileyen en Ã¶nemli Ã¶zellikleri listeler. Yerel aÃ§Ä±klamalar, bir modelin bireysel bir vaka iÃ§in tahminine yol aÃ§an Ã¶zellikleri gÃ¶sterir. Yerel aÃ§Ä±klamalarÄ± deÄŸerlendirme yeteneÄŸi, bir modelin doÄŸru veya yanlÄ±ÅŸ bir tahminde bulunmasÄ±nÄ±n nedenini daha iyi anlamak ve yorumlamak iÃ§in belirli bir vakayÄ± hata ayÄ±klama veya denetleme aÃ§Ä±sÄ±ndan da faydalÄ±dÄ±r.

![RAI panosundaki Ã–zellik Ã–nem Derecesi bileÅŸeni](../../../../9-Real-World/2-Debugging-ML-Models/images/9-feature-importance.png)

* KÃ¼resel aÃ§Ä±klamalar: Ã–rneÄŸin, diyabet hastaneye yeniden yatÄ±ÅŸ modelinin genel davranÄ±ÅŸÄ±nÄ± hangi Ã¶zellikler etkiliyor?
* Yerel aÃ§Ä±klamalar: Ã–rneÄŸin, neden 60 yaÅŸÄ±ndan bÃ¼yÃ¼k, Ã¶nceki hastane yatÄ±ÅŸlarÄ± olan bir diyabet hastasÄ± 30 gÃ¼n iÃ§inde hastaneye yeniden yatacak veya yatmayacak ÅŸekilde tahmin edildi?

Modelin performansÄ±nÄ± farklÄ± gruplar arasÄ±nda inceleme sÃ¼recinde, Ã–zellik Ã–nem Derecesi bir Ã¶zelliÄŸin gruplar arasÄ±nda modelin hatalÄ± tahminlerini yÃ¶nlendirmedeki etkisini gÃ¶sterir. Ã–zelliklerin modelin sonuÃ§larÄ±nÄ± olumlu veya olumsuz etkilediÄŸi deÄŸerleri gÃ¶sterebilir. Ã–rneÄŸin, bir model yanlÄ±ÅŸ bir tahminde bulunduysa, bileÅŸen, tahmini yÃ¶nlendiren Ã¶zellikleri veya Ã¶zellik deÄŸerlerini belirlemenize olanak tanÄ±r. Bu ayrÄ±ntÄ± dÃ¼zeyi, yalnÄ±zca hata ayÄ±klamada deÄŸil, aynÄ± zamanda denetim durumlarÄ±nda ÅŸeffaflÄ±k ve hesap verebilirlik saÄŸlamada da yardÄ±mcÄ± olur. Son olarak, bileÅŸen adalet sorunlarÄ±nÄ± belirlemenize yardÄ±mcÄ± olabilir. Ã–rneÄŸin, etnik kÃ¶ken veya cinsiyet gibi hassas bir Ã¶zellik modelin tahminini yÃ¶nlendirmede Ã§ok etkiliyse, bu modelde Ä±rk veya cinsiyet Ã¶nyargÄ±sÄ±nÄ±n bir iÅŸareti olabilir.

![Ã–zellik Ã¶nem derecesi](../../../../9-Real-World/2-Debugging-ML-Models/images/9-features-influence.png)

YorumlanabilirliÄŸi ÅŸu durumlarda kullanÄ±n:

* Modelinizin tahminlerinin ne kadar gÃ¼venilir olduÄŸunu belirlemek iÃ§in tahminler iÃ§in en Ã¶nemli Ã¶zelliklerin neler olduÄŸunu anlamak.
* Modelinizi Ã¶nce anlayarak ve modelin saÄŸlÄ±klÄ± Ã¶zellikler mi yoksa yalnÄ±zca yanlÄ±ÅŸ korelasyonlar mÄ± kullandÄ±ÄŸÄ±nÄ± belirleyerek hata ayÄ±klama sÃ¼recine yaklaÅŸmak.
* Modelin tahminlerini hassas Ã¶zelliklere veya onlarla yÃ¼ksek korelasyona sahip Ã¶zelliklere dayandÄ±rÄ±p dayandÄ±rmadÄ±ÄŸÄ±nÄ± anlayarak adaletsizlik kaynaklarÄ±nÄ± ortaya Ã§Ä±karmak.
* Yerel aÃ§Ä±klamalar oluÅŸturarak modelinizin kararlarÄ±na kullanÄ±cÄ± gÃ¼veni oluÅŸturmak.
* Ä°nsanlar Ã¼zerindeki model kararlarÄ±nÄ±n etkisini izlemek ve modelleri doÄŸrulamak iÃ§in bir yapay zeka sisteminin dÃ¼zenleyici denetimini tamamlamak.

## SonuÃ§

RAI panosundaki tÃ¼m bileÅŸenler, topluma daha az zarar veren ve daha gÃ¼venilir makine Ã¶ÄŸrenimi modelleri oluÅŸturmanÄ±za yardÄ±mcÄ± olacak pratik araÃ§lardÄ±r. Ä°nsan haklarÄ±na yÃ¶nelik tehditlerin Ã¶nlenmesini, belirli gruplarÄ±n yaÅŸam fÄ±rsatlarÄ±ndan dÄ±ÅŸlanmasÄ±nÄ± veya ayrÄ±mcÄ±lÄ±ÄŸa uÄŸramasÄ±nÄ± ve fiziksel veya psikolojik zarar riskini azaltÄ±r. AyrÄ±ca, modelinizin kararlarÄ±na gÃ¼ven oluÅŸturmak iÃ§in yerel aÃ§Ä±klamalar oluÅŸturarak sonuÃ§larÄ±nÄ± gÃ¶stermenize yardÄ±mcÄ± olur. Potansiyel zararlar ÅŸu ÅŸekilde sÄ±nÄ±flandÄ±rÄ±labilir:

- **Tahsis**: Ã–rneÄŸin, bir cinsiyet veya etnik kÃ¶kenin diÄŸerine kayÄ±rÄ±lmasÄ±.
- **Hizmet kalitesi**: Verileri belirli bir senaryo iÃ§in eÄŸitmek, ancak gerÃ§ekliÄŸin Ã§ok daha karmaÅŸÄ±k olmasÄ±, kÃ¶tÃ¼ performans gÃ¶steren bir hizmete yol aÃ§ar.
- **Stereotipleme**: Belirli bir grubu Ã¶nceden atanmÄ±ÅŸ Ã¶zelliklerle iliÅŸkilendirme.
- **KÃ¼Ã§Ã¼mseme**: Bir ÅŸey veya birini haksÄ±z yere eleÅŸtirme ve etiketleme.
- **AÅŸÄ±rÄ± veya yetersiz temsil**. Belirli bir grubun belirli bir meslek alanÄ±nda gÃ¶rÃ¼lmemesi fikri, ve bu durumu teÅŸvik eden herhangi bir hizmet veya iÅŸlev zarara katkÄ±da bulunuyor demektir.

### Azure RAI panosu

[Azure RAI panosu](https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai-dashboard?WT.mc_id=aiml-90525-ruyakubu), Microsoft dahil olmak Ã¼zere Ã¶nde gelen akademik kurumlar ve organizasyonlar tarafÄ±ndan geliÅŸtirilen aÃ§Ä±k kaynaklÄ± araÃ§lar Ã¼zerine inÅŸa edilmiÅŸtir. Bu araÃ§lar, veri bilimciler ve yapay zeka geliÅŸtiricilerinin model davranÄ±ÅŸÄ±nÄ± daha iyi anlamalarÄ±na, yapay zeka modellerindeki istenmeyen sorunlarÄ± keÅŸfetmelerine ve hafifletmelerine yardÄ±mcÄ± olur.

- RAI panosunun farklÄ± bileÅŸenlerini nasÄ±l kullanacaÄŸÄ±nÄ±zÄ± Ã¶ÄŸrenmek iÃ§in [dokÃ¼manlara](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-responsible-ai-dashboard?WT.mc_id=aiml-90525-ruyakubu) gÃ¶z atÄ±n.

- Azure Machine Learning'de daha sorumlu yapay zeka senaryolarÄ±nÄ± hata ayÄ±klamak iÃ§in bazÄ± RAI panosu [Ã¶rnek not defterlerini](https://github.com/Azure/RAI-vNext-Preview/tree/main/examples/notebooks) inceleyin.

---
## ğŸš€ Zorluk

Ä°statistiksel veya veri Ã¶nyargÄ±larÄ±nÄ±n en baÅŸtan ortaya Ã§Ä±kmasÄ±nÄ± Ã¶nlemek iÃ§in ÅŸunlarÄ± yapmalÄ±yÄ±z:

- sistemler Ã¼zerinde Ã§alÄ±ÅŸan kiÅŸiler arasÄ±nda farklÄ± geÃ§miÅŸlere ve bakÄ±ÅŸ aÃ§Ä±larÄ±na sahip olmak
- toplumumuzun Ã§eÅŸitliliÄŸini yansÄ±tan veri setlerine yatÄ±rÄ±m yapmak
- Ã¶nyargÄ±yÄ± tespit etmek ve dÃ¼zeltmek iÃ§in daha iyi yÃ¶ntemler geliÅŸtirmek

Model oluÅŸturma ve kullanÄ±mÄ± sÄ±rasÄ±nda adaletsizliÄŸin aÃ§Ä±kÃ§a gÃ¶rÃ¼ldÃ¼ÄŸÃ¼ gerÃ§ek yaÅŸam senaryolarÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼n. BaÅŸka neleri dikkate almalÄ±yÄ±z?

## [Ders sonrasÄ± test](https://ff-quizzes.netlify.app/en/ml/)
## GÃ¶zden GeÃ§irme ve Kendi Kendine Ã‡alÄ±ÅŸma

Bu derste, makine Ã¶ÄŸreniminde sorumlu yapay zekayÄ± dahil etmenin bazÄ± pratik araÃ§larÄ±nÄ± Ã¶ÄŸrendiniz.

Konulara daha derinlemesine dalmak iÃ§in bu atÃ¶lye Ã§alÄ±ÅŸmasÄ±nÄ± izleyin:

- Sorumlu Yapay Zeka Panosu: Besmira Nushi ve Mehrnoosh Sameki tarafÄ±ndan pratikte RAI'yi operasyonelleÅŸtirmek iÃ§in tek durak noktasÄ±

[![Sorumlu Yapay Zeka Panosu: Pratikte RAI'yi operasyonelleÅŸtirmek iÃ§in tek durak noktasÄ±](https://img.youtube.com/vi/f1oaDNl3djg/0.jpg)](https://www.youtube.com/watch?v=f1oaDNl3djg "Sorumlu Yapay Zeka Panosu: Pratikte RAI'yi operasyonelleÅŸtirmek iÃ§in tek durak noktasÄ±")

> ğŸ¥ YukarÄ±daki gÃ¶rÃ¼ntÃ¼ye tÄ±klayarak video izleyin: Besmira Nushi ve Mehrnoosh Sameki tarafÄ±ndan Sorumlu Yapay Zeka Panosu: Pratikte RAI'yi operasyonelleÅŸtirmek iÃ§in tek durak noktasÄ±

Sorumlu yapay zeka hakkÄ±nda daha fazla bilgi edinmek ve daha gÃ¼venilir modeller oluÅŸturmak iÃ§in aÅŸaÄŸÄ±daki materyallere baÅŸvurun:

- ML modellerini hata ayÄ±klamak iÃ§in Microsoftâ€™un RAI panosu araÃ§larÄ±: [Sorumlu Yapay Zeka araÃ§larÄ± kaynaklarÄ±](https://aka.ms/rai-dashboard)

- Sorumlu Yapay Zeka araÃ§ setini keÅŸfedin: [Github](https://github.com/microsoft/responsible-ai-toolbox)

- Microsoftâ€™un RAI kaynak merkezi: [Sorumlu Yapay Zeka KaynaklarÄ± â€“ Microsoft AI](https://www.microsoft.com/ai/responsible-ai-resources?activetab=pivot1%3aprimaryr4)

- Microsoftâ€™un FATE araÅŸtÄ±rma grubu: [FATE: Yapay Zekada Adalet, Hesap Verebilirlik, ÅeffaflÄ±k ve Etik - Microsoft Research](https://www.microsoft.com/research/theme/fate/)

## Ã–dev

[RAI panosunu keÅŸfedin](assignment.md)

---

**Feragatname**:  
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±k iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalardan sorumlu deÄŸiliz.