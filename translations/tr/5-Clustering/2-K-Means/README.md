<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7cdd17338d9bbd7e2171c2cd462eb081",
  "translation_date": "2025-09-06T07:52:05+00:00",
  "source_file": "5-Clustering/2-K-Means/README.md",
  "language_code": "tr"
}
-->
# K-Means KÃ¼meleme

## [Ders Ã–ncesi Test](https://ff-quizzes.netlify.app/en/ml/)

Bu derste, daha Ã¶nce iÃ§e aktardÄ±ÄŸÄ±nÄ±z Nijerya mÃ¼zik veri setini kullanarak Scikit-learn ile nasÄ±l kÃ¼meler oluÅŸturacaÄŸÄ±nÄ±zÄ± Ã¶ÄŸreneceksiniz. K-Means ile KÃ¼meleme'nin temel konularÄ±nÄ± ele alacaÄŸÄ±z. Daha Ã¶nceki derste Ã¶ÄŸrendiÄŸiniz gibi, kÃ¼melerle Ã§alÄ±ÅŸmanÄ±n birÃ§ok yolu vardÄ±r ve kullandÄ±ÄŸÄ±nÄ±z yÃ¶ntem verinize baÄŸlÄ±dÄ±r. En yaygÄ±n kÃ¼meleme tekniÄŸi olduÄŸu iÃ§in K-Means yÃ¶ntemini deneyeceÄŸiz. Haydi baÅŸlayalÄ±m!

Ã–ÄŸreneceÄŸiniz terimler:

- Silhouette skoru
- Dirsek yÃ¶ntemi
- Atalet
- Varyans

## GiriÅŸ

[K-Means KÃ¼meleme](https://wikipedia.org/wiki/K-means_clustering), sinyal iÅŸleme alanÄ±ndan tÃ¼retilmiÅŸ bir yÃ¶ntemdir. Verileri 'k' kÃ¼mesine ayÄ±rmak ve gruplandÄ±rmak iÃ§in bir dizi gÃ¶zlem kullanÄ±lÄ±r. Her gÃ¶zlem, bir veri noktasÄ±nÄ± en yakÄ±n 'ortalama'ya, yani bir kÃ¼menin merkez noktasÄ±na gruplandÄ±rmaya Ã§alÄ±ÅŸÄ±r.

KÃ¼meler, bir nokta (veya 'tohum') ve buna karÅŸÄ±lÄ±k gelen bÃ¶lgeyi iÃ§eren [Voronoi diyagramlarÄ±](https://wikipedia.org/wiki/Voronoi_diagram) olarak gÃ¶rselleÅŸtirilebilir.

![voronoi diagram](../../../../5-Clustering/2-K-Means/images/voronoi.png)

> infographic by [Jen Looper](https://twitter.com/jenlooper)

K-Means kÃ¼meleme sÃ¼reci [Ã¼Ã§ adÄ±mlÄ± bir sÃ¼reÃ§te gerÃ§ekleÅŸtirilir](https://scikit-learn.org/stable/modules/clustering.html#k-means):

1. Algoritma, veri setinden Ã¶rnekleme yaparak k sayÄ±da merkez noktasÄ± seÃ§er. ArdÄ±ndan ÅŸu dÃ¶ngÃ¼yÃ¼ gerÃ§ekleÅŸtirir:
    1. Her Ã¶rneÄŸi en yakÄ±n merkez noktaya atar.
    2. Ã–nceki merkez noktalarÄ±na atanan tÃ¼m Ã¶rneklerin ortalama deÄŸerini alarak yeni merkez noktalarÄ± oluÅŸturur.
    3. Daha sonra yeni ve eski merkez noktalarÄ± arasÄ±ndaki farkÄ± hesaplar ve merkez noktalar sabitlenene kadar tekrar eder.

K-Means kullanmanÄ±n bir dezavantajÄ±, 'k' yani merkez noktalarÄ±nÄ±n sayÄ±sÄ±nÄ± belirlemeniz gerektiÄŸidir. Neyse ki, 'dirsek yÃ¶ntemi' 'k' iÃ§in iyi bir baÅŸlangÄ±Ã§ deÄŸeri tahmin etmenize yardÄ±mcÄ± olur. Bunu birazdan deneyeceksiniz.

## Ã–n KoÅŸul

Bu derste, Ã¶nceki derste veri iÃ§e aktarma ve Ã¶n temizlik iÅŸlemlerini yaptÄ±ÄŸÄ±nÄ±z [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/2-K-Means/notebook.ipynb) dosyasÄ±nda Ã§alÄ±ÅŸacaksÄ±nÄ±z.

## AlÄ±ÅŸtÄ±rma - HazÄ±rlÄ±k

ÅarkÄ± verilerine tekrar bir gÃ¶z atarak baÅŸlayÄ±n.

1. Her sÃ¼tun iÃ§in `boxplot()` Ã§aÄŸÄ±rarak bir kutu grafiÄŸi oluÅŸturun:

    ```python
    plt.figure(figsize=(20,20), dpi=200)
    
    plt.subplot(4,3,1)
    sns.boxplot(x = 'popularity', data = df)
    
    plt.subplot(4,3,2)
    sns.boxplot(x = 'acousticness', data = df)
    
    plt.subplot(4,3,3)
    sns.boxplot(x = 'energy', data = df)
    
    plt.subplot(4,3,4)
    sns.boxplot(x = 'instrumentalness', data = df)
    
    plt.subplot(4,3,5)
    sns.boxplot(x = 'liveness', data = df)
    
    plt.subplot(4,3,6)
    sns.boxplot(x = 'loudness', data = df)
    
    plt.subplot(4,3,7)
    sns.boxplot(x = 'speechiness', data = df)
    
    plt.subplot(4,3,8)
    sns.boxplot(x = 'tempo', data = df)
    
    plt.subplot(4,3,9)
    sns.boxplot(x = 'time_signature', data = df)
    
    plt.subplot(4,3,10)
    sns.boxplot(x = 'danceability', data = df)
    
    plt.subplot(4,3,11)
    sns.boxplot(x = 'length', data = df)
    
    plt.subplot(4,3,12)
    sns.boxplot(x = 'release_date', data = df)
    ```

    Bu veri biraz gÃ¼rÃ¼ltÃ¼lÃ¼: Her sÃ¼tunu bir kutu grafiÄŸi olarak gÃ¶zlemleyerek aykÄ±rÄ± deÄŸerleri gÃ¶rebilirsiniz.

    ![outliers](../../../../5-Clustering/2-K-Means/images/boxplots.png)

Veri setini gÃ¶zden geÃ§irip bu aykÄ±rÄ± deÄŸerleri kaldÄ±rabilirsiniz, ancak bu veri setini oldukÃ§a minimal hale getirir.

1. Åimdi kÃ¼meleme alÄ±ÅŸtÄ±rmanÄ±z iÃ§in hangi sÃ¼tunlarÄ± kullanacaÄŸÄ±nÄ±zÄ± seÃ§in. Benzer aralÄ±klara sahip olanlarÄ± seÃ§in ve `artist_top_genre` sÃ¼tununu sayÄ±sal veri olarak kodlayÄ±n:

    ```python
    from sklearn.preprocessing import LabelEncoder
    le = LabelEncoder()
    
    X = df.loc[:, ('artist_top_genre','popularity','danceability','acousticness','loudness','energy')]
    
    y = df['artist_top_genre']
    
    X['artist_top_genre'] = le.fit_transform(X['artist_top_genre'])
    
    y = le.transform(y)
    ```

1. Åimdi hedefleyeceÄŸiniz kÃ¼me sayÄ±sÄ±nÄ± seÃ§meniz gerekiyor. Veri setinden 3 ÅŸarkÄ± tÃ¼rÃ¼ ayÄ±rdÄ±ÄŸÄ±nÄ±zÄ± biliyorsunuz, o yÃ¼zden 3'Ã¼ deneyelim:

    ```python
    from sklearn.cluster import KMeans
    
    nclusters = 3 
    seed = 0
    
    km = KMeans(n_clusters=nclusters, random_state=seed)
    km.fit(X)
    
    # Predict the cluster for each data point
    
    y_cluster_kmeans = km.predict(X)
    y_cluster_kmeans
    ```

Bir veri Ã§erÃ§evesinin her satÄ±rÄ± iÃ§in tahmin edilen kÃ¼meler (0, 1 veya 2) ile bir dizi Ã§Ä±ktÄ±sÄ± gÃ¶rÃ¼yorsunuz.

1. Bu diziyi kullanarak bir 'silhouette skoru' hesaplayÄ±n:

    ```python
    from sklearn import metrics
    score = metrics.silhouette_score(X, y_cluster_kmeans)
    score
    ```

## Silhouette Skoru

1'e yakÄ±n bir silhouette skoru arayÄ±n. Bu skor -1 ile 1 arasÄ±nda deÄŸiÅŸir ve skor 1 ise kÃ¼me yoÄŸun ve diÄŸer kÃ¼melerden iyi ayrÄ±lmÄ±ÅŸtÄ±r. 0'a yakÄ±n bir deÄŸer, komÅŸu kÃ¼melerin karar sÄ±nÄ±rÄ±na Ã§ok yakÄ±n Ã¶rneklerle Ã¶rtÃ¼ÅŸen kÃ¼meleri temsil eder. [(Kaynak)](https://dzone.com/articles/kmeans-silhouette-score-explained-with-python-exam)

Skorumuz **.53**, yani ortada. Bu, verimizin bu tÃ¼r bir kÃ¼meleme iÃ§in pek uygun olmadÄ±ÄŸÄ±nÄ± gÃ¶steriyor, ancak devam edelim.

### AlÄ±ÅŸtÄ±rma - Model OluÅŸturma

1. `KMeans`'i iÃ§e aktarÄ±n ve kÃ¼meleme sÃ¼recini baÅŸlatÄ±n.

    ```python
    from sklearn.cluster import KMeans
    wcss = []
    
    for i in range(1, 11):
        kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)
        kmeans.fit(X)
        wcss.append(kmeans.inertia_)
    
    ```

    Burada aÃ§Ä±klamaya deÄŸer birkaÃ§ bÃ¶lÃ¼m var.

    > ğŸ“ range: KÃ¼meleme sÃ¼recinin yinelemeleri

    > ğŸ“ random_state: "Merkez noktasÄ± baÅŸlatma iÃ§in rastgele sayÄ± Ã¼retimini belirler." [Kaynak](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)

    > ğŸ“ WCSS: "kÃ¼me iÃ§i kareler toplamÄ±", bir kÃ¼me iÃ§indeki tÃ¼m noktalarÄ±n kÃ¼me merkezine olan ortalama kare mesafesini Ã¶lÃ§er. [Kaynak](https://medium.com/@ODSC/unsupervised-learning-evaluating-clusters-bd47eed175ce). 

    > ğŸ“ Atalet: K-Means algoritmalarÄ±, 'ataleti' minimize etmek iÃ§in merkez noktalarÄ±nÄ± seÃ§meye Ã§alÄ±ÅŸÄ±r, "kÃ¼melerin ne kadar iÃ§sel olarak tutarlÄ± olduÄŸunu Ã¶lÃ§en bir deÄŸer." [Kaynak](https://scikit-learn.org/stable/modules/clustering.html). DeÄŸer, her yinelemede wcss deÄŸiÅŸkenine eklenir.

    > ğŸ“ k-means++: [Scikit-learn](https://scikit-learn.org/stable/modules/clustering.html#k-means)'de 'k-means++' optimizasyonunu kullanabilirsiniz, bu "merkez noktalarÄ±nÄ± genellikle birbirinden uzak olacak ÅŸekilde baÅŸlatÄ±r, rastgele baÅŸlatmaya gÃ¶re muhtemelen daha iyi sonuÃ§lar verir."

### Dirsek YÃ¶ntemi

Daha Ã¶nce, 3 ÅŸarkÄ± tÃ¼rÃ¼nÃ¼ hedeflediÄŸiniz iÃ§in 3 kÃ¼me seÃ§meniz gerektiÄŸini varsaydÄ±nÄ±z. Ama gerÃ§ekten Ã¶yle mi?

1. Emin olmak iÃ§in 'dirsek yÃ¶ntemini' kullanÄ±n.

    ```python
    plt.figure(figsize=(10,5))
    sns.lineplot(x=range(1, 11), y=wcss, marker='o', color='red')
    plt.title('Elbow')
    plt.xlabel('Number of clusters')
    plt.ylabel('WCSS')
    plt.show()
    ```

    Ã–nceki adÄ±mda oluÅŸturduÄŸunuz `wcss` deÄŸiÅŸkenini kullanarak, optimum kÃ¼me sayÄ±sÄ±nÄ± gÃ¶steren 'dirsek' eÄŸrisini iÃ§eren bir grafik oluÅŸturun. Belki gerÃ§ekten **3**!

    ![elbow method](../../../../5-Clustering/2-K-Means/images/elbow.png)

## AlÄ±ÅŸtÄ±rma - KÃ¼meleri GÃ¶rÃ¼ntÃ¼leme

1. SÃ¼reci tekrar deneyin, bu sefer Ã¼Ã§ kÃ¼me ayarlayÄ±n ve kÃ¼meleri bir saÃ§Ä±lÄ±m grafiÄŸi olarak gÃ¶rÃ¼ntÃ¼leyin:

    ```python
    from sklearn.cluster import KMeans
    kmeans = KMeans(n_clusters = 3)
    kmeans.fit(X)
    labels = kmeans.predict(X)
    plt.scatter(df['popularity'],df['danceability'],c = labels)
    plt.xlabel('popularity')
    plt.ylabel('danceability')
    plt.show()
    ```

1. Modelin doÄŸruluÄŸunu kontrol edin:

    ```python
    labels = kmeans.labels_
    
    correct_labels = sum(y == labels)
    
    print("Result: %d out of %d samples were correctly labeled." % (correct_labels, y.size))
    
    print('Accuracy score: {0:0.2f}'. format(correct_labels/float(y.size)))
    ```

    Bu modelin doÄŸruluÄŸu pek iyi deÄŸil ve kÃ¼melerin ÅŸekli nedenini anlamanÄ±z iÃ§in ipucu veriyor.

    ![clusters](../../../../5-Clustering/2-K-Means/images/clusters.png)

    Bu veri Ã§ok dengesiz, Ã§ok az korelasyonlu ve sÃ¼tun deÄŸerleri arasÄ±nda Ã§ok fazla varyans var, bu yÃ¼zden iyi bir ÅŸekilde kÃ¼melenemiyor. AslÄ±nda, oluÅŸan kÃ¼meler muhtemelen yukarÄ±da tanÄ±mladÄ±ÄŸÄ±mÄ±z Ã¼Ã§ tÃ¼r kategorisi tarafÄ±ndan aÄŸÄ±r ÅŸekilde etkileniyor veya Ã§arpÄ±tÄ±lÄ±yor. Bu bir Ã¶ÄŸrenme sÃ¼reciydi!

    Scikit-learn belgelerinde, bu model gibi, iyi ayrÄ±lmamÄ±ÅŸ kÃ¼melerle bir modelin 'varyans' problemi olduÄŸu gÃ¶rÃ¼lebilir:

    ![problem models](../../../../5-Clustering/2-K-Means/images/problems.png)
    > Infographic from Scikit-learn

## Varyans

Varyans, "Ortalama'dan olan kare farklarÄ±n ortalamasÄ±" olarak tanÄ±mlanÄ±r [(Kaynak)](https://www.mathsisfun.com/data/standard-deviation.html). Bu kÃ¼meleme problemi baÄŸlamÄ±nda, veri setimizin sayÄ±larÄ±nÄ±n ortalamadan biraz fazla sapma eÄŸiliminde olduÄŸunu ifade eder.

âœ… Bu, bu sorunu dÃ¼zeltmek iÃ§in tÃ¼m yollarÄ± dÃ¼ÅŸÃ¼nmek iÃ§in harika bir an. Veriyi biraz daha dÃ¼zenlemek mi? FarklÄ± sÃ¼tunlar mÄ± kullanmak? FarklÄ± bir algoritma mÄ± denemek? Ä°pucu: Verinizi [Ã¶lÃ§eklendirmeyi](https://www.mygreatlearning.com/blog/learning-data-science-with-k-means-clustering/) deneyin, normalleÅŸtirin ve diÄŸer sÃ¼tunlarÄ± test edin.

> Bu '[varyans hesaplayÄ±cÄ±yÄ±](https://www.calculatorsoup.com/calculators/statistics/variance-calculator.php)' kullanarak kavramÄ± biraz daha anlayabilirsiniz.

---

## ğŸš€Meydan Okuma

Bu notebook ile biraz zaman geÃ§irin, parametreleri deÄŸiÅŸtirin. Veriyi daha fazla temizleyerek (Ã¶rneÄŸin aykÄ±rÄ± deÄŸerleri kaldÄ±rarak) modelin doÄŸruluÄŸunu artÄ±rabilir misiniz? Belirli veri Ã¶rneklerine daha fazla aÄŸÄ±rlÄ±k vermek iÃ§in aÄŸÄ±rlÄ±klar kullanabilirsiniz. Daha iyi kÃ¼meler oluÅŸturmak iÃ§in baÅŸka ne yapabilirsiniz?

Ä°pucu: Verinizi Ã¶lÃ§eklendirmeyi deneyin. Notebook'ta, veri sÃ¼tunlarÄ±nÄ±n aralÄ±k aÃ§Ä±sÄ±ndan birbirine daha yakÄ±n gÃ¶rÃ¼nmesini saÄŸlamak iÃ§in standart Ã¶lÃ§eklendirme ekleyen yorumlanmÄ±ÅŸ kodlar var. Veriyi Ã¶lÃ§eklendirilmemiÅŸ bÄ±rakmak, daha az varyansa sahip verilerin daha fazla aÄŸÄ±rlÄ±k taÅŸÄ±masÄ±na izin verdiÄŸi iÃ§in, silhouette skoru dÃ¼ÅŸerken dirsek grafiÄŸindeki 'kink' yumuÅŸar. Bu sorun hakkÄ±nda biraz daha okuyun [burada](https://stats.stackexchange.com/questions/21222/are-mean-normalization-and-feature-scaling-needed-for-k-means-clustering/21226#21226).

## [Ders SonrasÄ± Test](https://ff-quizzes.netlify.app/en/ml/)

## GÃ¶zden GeÃ§irme ve Kendi Kendine Ã‡alÄ±ÅŸma

Bir K-Means SimÃ¼latÃ¶rÃ¼ne [buradan](https://user.ceng.metu.edu.tr/~akifakkus/courses/ceng574/k-means/) gÃ¶z atÄ±n. Bu aracÄ± kullanarak Ã¶rnek veri noktalarÄ±nÄ± gÃ¶rselleÅŸtirebilir ve merkez noktalarÄ±nÄ± belirleyebilirsiniz. Verinin rastgeleliÄŸini, kÃ¼me sayÄ±larÄ±nÄ± ve merkez noktasÄ± sayÄ±larÄ±nÄ± dÃ¼zenleyebilirsiniz. Bu, verinin nasÄ±l gruplandÄ±rÄ±labileceÄŸi hakkÄ±nda bir fikir edinmenize yardÄ±mcÄ± oluyor mu?

AyrÄ±ca Stanford'dan [bu K-Means el kitabÄ±na](https://stanford.edu/~cpiech/cs221/handouts/kmeans.html) gÃ¶z atÄ±n.

## Ã–dev

[FarklÄ± kÃ¼meleme yÃ¶ntemlerini deneyin](assignment.md)

---

**Feragatname**:  
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±k iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalardan sorumlu deÄŸiliz.