# K-Means kÃ¼meleme

## [Ders Ã–ncesi Test](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/29/)

Bu derste, daha Ã¶nce iÃ§e aktardÄ±ÄŸÄ±nÄ±z Nijerya mÃ¼zik veri kÃ¼mesini kullanarak Scikit-learn ile nasÄ±l kÃ¼meler oluÅŸturacaÄŸÄ±nÄ±zÄ± Ã¶ÄŸreneceksiniz. K-Means ile KÃ¼meleme'nin temellerini ele alacaÄŸÄ±z. Daha Ã¶nceki derste Ã¶ÄŸrendiÄŸiniz gibi, kÃ¼melerle Ã§alÄ±ÅŸmanÄ±n birÃ§ok yolu vardÄ±r ve kullandÄ±ÄŸÄ±nÄ±z yÃ¶ntem verilerinize baÄŸlÄ±dÄ±r. En yaygÄ±n kÃ¼meleme tekniÄŸi olduÄŸu iÃ§in K-Means'Ä± deneyeceÄŸiz. Hadi baÅŸlayalÄ±m!

Ã–ÄŸreneceÄŸiniz terimler:

- Siluet skoru
- Dirsek yÃ¶ntemi
- Eylemsizlik
- Varyans

## GiriÅŸ

[K-Means KÃ¼meleme](https://wikipedia.org/wiki/K-means_clustering), sinyal iÅŸleme alanÄ±ndan tÃ¼retilmiÅŸ bir yÃ¶ntemdir. Bir dizi gÃ¶zlem kullanarak veri gruplarÄ±nÄ± 'k' kÃ¼melere bÃ¶lmek ve ayÄ±rmak iÃ§in kullanÄ±lÄ±r. Her gÃ¶zlem, verilen bir veri noktasÄ±nÄ± en yakÄ±n 'ortalama'ya veya bir kÃ¼menin merkez noktasÄ±na en yakÄ±n olacak ÅŸekilde gruplar.

KÃ¼meler, bir nokta (veya 'tohum') ve karÅŸÄ±lÄ±k gelen bÃ¶lgesini iÃ§eren [Voronoi diyagramlarÄ±](https://wikipedia.org/wiki/Voronoi_diagram) olarak gÃ¶rselleÅŸtirilebilir.

![voronoi diagram](../../../../translated_images/voronoi.1dc1613fb0439b9564615eca8df47a4bcd1ce06217e7e72325d2406ef2180795.tr.png)

> infographic by [Jen Looper](https://twitter.com/jenlooper)

K-Means kÃ¼meleme sÃ¼reci [Ã¼Ã§ adÄ±mlÄ± bir sÃ¼reÃ§te Ã§alÄ±ÅŸÄ±r](https://scikit-learn.org/stable/modules/clustering.html#k-means):

1. Algoritma, veri kÃ¼mesinden Ã¶rnekleme yaparak k sayÄ±da merkez noktasÄ± seÃ§er. Bundan sonra, dÃ¶ngÃ¼ye girer:
    1. Her Ã¶rneÄŸi en yakÄ±n merkez noktaya atar.
    2. Ã–nceki merkez noktalara atanan tÃ¼m Ã¶rneklerin ortalama deÄŸerini alarak yeni merkez noktalar oluÅŸturur.
    3. ArdÄ±ndan, yeni ve eski merkez noktalar arasÄ±ndaki farkÄ± hesaplar ve merkez noktalar stabilize olana kadar tekrarlar.

K-Means kullanmanÄ±n bir dezavantajÄ±, 'k' yani merkez noktalarÄ±nÄ±n sayÄ±sÄ±nÄ± belirlemeniz gerektiÄŸidir. Neyse ki, 'dirsek yÃ¶ntemi' 'k' iÃ§in iyi bir baÅŸlangÄ±Ã§ deÄŸeri tahmin etmenize yardÄ±mcÄ± olur. Birazdan deneyeceksiniz.

## Ã–nkoÅŸul

Bu dersin [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/2-K-Means/notebook.ipynb) dosyasÄ±nda Ã§alÄ±ÅŸacaksÄ±nÄ±z, bu dosya Ã¶nceki derste yaptÄ±ÄŸÄ±nÄ±z veri iÃ§e aktarma ve Ã¶n temizleme iÅŸlemlerini iÃ§erir.

## AlÄ±ÅŸtÄ±rma - hazÄ±rlÄ±k

ÅarkÄ± verilerine tekrar bir gÃ¶z atarak baÅŸlayÄ±n.

1. Her sÃ¼tun iÃ§in `boxplot()` Ã§aÄŸÄ±rarak bir kutu grafiÄŸi oluÅŸturun:

    ```python
    plt.figure(figsize=(20,20), dpi=200)
    
    plt.subplot(4,3,1)
    sns.boxplot(x = 'popularity', data = df)
    
    plt.subplot(4,3,2)
    sns.boxplot(x = 'acousticness', data = df)
    
    plt.subplot(4,3,3)
    sns.boxplot(x = 'energy', data = df)
    
    plt.subplot(4,3,4)
    sns.boxplot(x = 'instrumentalness', data = df)
    
    plt.subplot(4,3,5)
    sns.boxplot(x = 'liveness', data = df)
    
    plt.subplot(4,3,6)
    sns.boxplot(x = 'loudness', data = df)
    
    plt.subplot(4,3,7)
    sns.boxplot(x = 'speechiness', data = df)
    
    plt.subplot(4,3,8)
    sns.boxplot(x = 'tempo', data = df)
    
    plt.subplot(4,3,9)
    sns.boxplot(x = 'time_signature', data = df)
    
    plt.subplot(4,3,10)
    sns.boxplot(x = 'danceability', data = df)
    
    plt.subplot(4,3,11)
    sns.boxplot(x = 'length', data = df)
    
    plt.subplot(4,3,12)
    sns.boxplot(x = 'release_date', data = df)
    ```

    Bu veri biraz gÃ¼rÃ¼ltÃ¼lÃ¼: her sÃ¼tunu kutu grafiÄŸi olarak gÃ¶zlemleyerek aykÄ±rÄ± deÄŸerleri gÃ¶rebilirsiniz.

    ![outliers](../../../../translated_images/boxplots.8228c29dabd0f29227dd38624231a175f411f1d8d4d7c012cb770e00e4fdf8b6.tr.png)

Veri kÃ¼mesinden bu aykÄ±rÄ± deÄŸerleri Ã§Ä±karabilirsiniz, ancak bu veriyi oldukÃ§a minimal hale getirir.

1. Åimdi, kÃ¼meleme egzersiziniz iÃ§in hangi sÃ¼tunlarÄ± kullanacaÄŸÄ±nÄ±za karar verin. Benzer aralÄ±klara sahip olanlarÄ± seÃ§in ve `artist_top_genre` sÃ¼tununu sayÄ±sal veriler olarak kodlayÄ±n:

    ```python
    from sklearn.preprocessing import LabelEncoder
    le = LabelEncoder()
    
    X = df.loc[:, ('artist_top_genre','popularity','danceability','acousticness','loudness','energy')]
    
    y = df['artist_top_genre']
    
    X['artist_top_genre'] = le.fit_transform(X['artist_top_genre'])
    
    y = le.transform(y)
    ```

1. Åimdi kaÃ§ kÃ¼me hedefleyeceÄŸinizi seÃ§meniz gerekiyor. Veri kÃ¼mesinden 3 ÅŸarkÄ± tÃ¼rÃ¼ Ã§Ä±kardÄ±ÄŸÄ±nÄ±zÄ± biliyorsunuz, bu yÃ¼zden 3'Ã¼ deneyelim:

    ```python
    from sklearn.cluster import KMeans
    
    nclusters = 3 
    seed = 0
    
    km = KMeans(n_clusters=nclusters, random_state=seed)
    km.fit(X)
    
    # Predict the cluster for each data point
    
    y_cluster_kmeans = km.predict(X)
    y_cluster_kmeans
    ```

Dataframe'in her satÄ±rÄ± iÃ§in tahmin edilen kÃ¼meler (0, 1 veya 2) ile basÄ±lmÄ±ÅŸ bir dizi gÃ¶rÃ¼yorsunuz.

1. Bu diziyi kullanarak bir 'siluet skoru' hesaplayÄ±n:

    ```python
    from sklearn import metrics
    score = metrics.silhouette_score(X, y_cluster_kmeans)
    score
    ```

## Siluet skoru

1'e yakÄ±n bir siluet skoru arayÄ±n. Bu skor -1 ile 1 arasÄ±nda deÄŸiÅŸir ve eÄŸer skor 1 ise, kÃ¼me yoÄŸundur ve diÄŸer kÃ¼melerden iyi ayrÄ±lmÄ±ÅŸtÄ±r. 0'a yakÄ±n bir deÄŸer, Ã¶rneklerin komÅŸu kÃ¼melerin karar sÄ±nÄ±rÄ±na Ã§ok yakÄ±n olduÄŸu Ã¶rtÃ¼ÅŸen kÃ¼meleri temsil eder. [(Kaynak)](https://dzone.com/articles/kmeans-silhouette-score-explained-with-python-exam)

Bizim skor **.53**, yani ortada. Bu, verilerimizin bu tÃ¼r bir kÃ¼meleme iÃ§in pek uygun olmadÄ±ÄŸÄ±nÄ± gÃ¶steriyor, ancak devam edelim.

### AlÄ±ÅŸtÄ±rma - bir model oluÅŸturma

1. `KMeans`'i iÃ§e aktarÄ±n ve kÃ¼meleme sÃ¼recine baÅŸlayÄ±n.

    ```python
    from sklearn.cluster import KMeans
    wcss = []
    
    for i in range(1, 11):
        kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)
        kmeans.fit(X)
        wcss.append(kmeans.inertia_)
    
    ```

    Burada aÃ§Ä±klamaya deÄŸer birkaÃ§ bÃ¶lÃ¼m var.

    > ğŸ“ range: Bunlar kÃ¼meleme sÃ¼recinin iterasyonlarÄ±dÄ±r

    > ğŸ“ random_state: "Merkez noktasÄ± baÅŸlatma iÃ§in rastgele sayÄ± Ã¼retimini belirler." [Kaynak](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html#sklearn.cluster.KMeans)

    > ğŸ“ WCSS: "kÃ¼me iÃ§i kareler toplamÄ±" bir kÃ¼me iÃ§indeki tÃ¼m noktalarÄ±n kÃ¼me merkezine olan kareli ortalama mesafesini Ã¶lÃ§er. [Kaynak](https://medium.com/@ODSC/unsupervised-learning-evaluating-clusters-bd47eed175ce). 

    > ğŸ“ Inertia: K-Means algoritmalarÄ±, 'inertia'yÄ± minimize edecek merkez noktalarÄ± seÃ§meye Ã§alÄ±ÅŸÄ±r, "kÃ¼melerin ne kadar iÃ§sel olarak tutarlÄ± olduÄŸunu Ã¶lÃ§en bir Ã¶lÃ§Ã¼ttÃ¼r." [Kaynak](https://scikit-learn.org/stable/modules/clustering.html). DeÄŸer her iterasyonda wcss deÄŸiÅŸkenine eklenir.

    > ğŸ“ k-means++: [Scikit-learn](https://scikit-learn.org/stable/modules/clustering.html#k-means)'de 'k-means++' optimizasyonunu kullanabilirsiniz, bu "merkez noktalarÄ±nÄ± genellikle birbirinden uzak olacak ÅŸekilde baÅŸlatÄ±r, bu da rastgele baÅŸlatmadan muhtemelen daha iyi sonuÃ§lar verir.

### Dirsek yÃ¶ntemi

Daha Ã¶nce, 3 ÅŸarkÄ± tÃ¼rÃ¼nÃ¼ hedeflediÄŸiniz iÃ§in 3 kÃ¼me seÃ§meniz gerektiÄŸini varsaymÄ±ÅŸtÄ±nÄ±z. Ama gerÃ§ekten Ã¶yle mi?

1. Emin olmak iÃ§in 'dirsek yÃ¶ntemini' kullanÄ±n.

    ```python
    plt.figure(figsize=(10,5))
    sns.lineplot(x=range(1, 11), y=wcss, marker='o', color='red')
    plt.title('Elbow')
    plt.xlabel('Number of clusters')
    plt.ylabel('WCSS')
    plt.show()
    ```

    Ã–nceki adÄ±mda oluÅŸturduÄŸunuz `wcss` deÄŸiÅŸkenini kullanarak 'dirsek' bÃ¼kÃ¼mÃ¼nÃ¼n nerede olduÄŸunu gÃ¶steren bir grafik oluÅŸturun, bu optimum kÃ¼me sayÄ±sÄ±nÄ± gÃ¶sterir. Belki gerÃ§ekten **3**!

    ![elbow method](../../../../translated_images/elbow.72676169eed744ff03677e71334a16c6b8f751e9e716e3d7f40dd7cdef674cca.tr.png)

## AlÄ±ÅŸtÄ±rma - kÃ¼meleri gÃ¶sterme

1. SÃ¼reci tekrar deneyin, bu sefer Ã¼Ã§ kÃ¼me ayarlayÄ±n ve kÃ¼meleri bir daÄŸÄ±lÄ±m grafiÄŸi olarak gÃ¶sterin:

    ```python
    from sklearn.cluster import KMeans
    kmeans = KMeans(n_clusters = 3)
    kmeans.fit(X)
    labels = kmeans.predict(X)
    plt.scatter(df['popularity'],df['danceability'],c = labels)
    plt.xlabel('popularity')
    plt.ylabel('danceability')
    plt.show()
    ```

1. Modelin doÄŸruluÄŸunu kontrol edin:

    ```python
    labels = kmeans.labels_
    
    correct_labels = sum(y == labels)
    
    print("Result: %d out of %d samples were correctly labeled." % (correct_labels, y.size))
    
    print('Accuracy score: {0:0.2f}'. format(correct_labels/float(y.size)))
    ```

    Bu modelin doÄŸruluÄŸu pek iyi deÄŸil ve kÃ¼melerin ÅŸekli nedenini size ipucu veriyor.

    ![clusters](../../../../translated_images/clusters.b635354640d8e4fd4a49ef545495518e7be76172c97c13bd748f5b79f171f69a.tr.png)

    Bu veri Ã§ok dengesiz, Ã§ok az korelasyonlu ve sÃ¼tun deÄŸerleri arasÄ±nda Ã§ok fazla varyans var, bu yÃ¼zden iyi kÃ¼melenmiyor. AslÄ±nda, oluÅŸan kÃ¼meler muhtemelen yukarÄ±da tanÄ±mladÄ±ÄŸÄ±mÄ±z Ã¼Ã§ tÃ¼r kategorisinden bÃ¼yÃ¼k Ã¶lÃ§Ã¼de etkileniyor veya eÄŸiliyor. Bu bir Ã¶ÄŸrenme sÃ¼reciydi!

    Scikit-learn belgelerinde, bu model gibi, iyi belirlenmemiÅŸ kÃ¼meleri olan bir modelin 'varyans' problemi olduÄŸunu gÃ¶rebilirsiniz:

    ![problem models](../../../../translated_images/problems.f7fb539ccd80608e1f35c319cf5e3ad1809faa3c08537aead8018c6b5ba2e33a.tr.png)
    > Infographic from Scikit-learn

## Varyans

Varyans, "OrtalamanÄ±n kareli farklarÄ±nÄ±n ortalamasÄ±" olarak tanÄ±mlanÄ±r [(Kaynak)](https://www.mathsisfun.com/data/standard-deviation.html). Bu kÃ¼meleme problemi baÄŸlamÄ±nda, veri kÃ¼mesindeki sayÄ±larÄ±n ortalamadan biraz fazla sapma eÄŸiliminde olduÄŸunu ifade eder. 

âœ… Bu, bu sorunu dÃ¼zeltmenin tÃ¼m yollarÄ±nÄ± dÃ¼ÅŸÃ¼nmek iÃ§in harika bir an. Verileri biraz daha dÃ¼zenlemek mi? FarklÄ± sÃ¼tunlar kullanmak mÄ±? FarklÄ± bir algoritma kullanmak mÄ±? Ä°pucu: Verilerinizi normalleÅŸtirmek iÃ§in [Ã¶lÃ§eklendirmeyi deneyin](https://www.mygreatlearning.com/blog/learning-data-science-with-k-means-clustering/) ve diÄŸer sÃ¼tunlarÄ± test edin.

> Bu '[varyans hesaplayÄ±cÄ±sÄ±](https://www.calculatorsoup.com/calculators/statistics/variance-calculator.php)'nÄ± deneyerek kavramÄ± biraz daha iyi anlayÄ±n.

---

## ğŸš€Meydan Okuma

Bu notebook ile biraz zaman geÃ§irin, parametreleri ayarlayÄ±n. Verileri daha fazla temizleyerek (Ã¶rneÄŸin aykÄ±rÄ± deÄŸerleri Ã§Ä±kararak) modelin doÄŸruluÄŸunu artÄ±rabilir misiniz? Belirli veri Ã¶rneklerine daha fazla aÄŸÄ±rlÄ±k vermek iÃ§in aÄŸÄ±rlÄ±klar kullanabilirsiniz. Daha iyi kÃ¼meler oluÅŸturmak iÃ§in baÅŸka ne yapabilirsiniz?

Ä°pucu: Verilerinizi Ã¶lÃ§eklendirmeyi deneyin. Notebook'ta, veri sÃ¼tunlarÄ±nÄ± aralÄ±k aÃ§Ä±sÄ±ndan daha benzer hale getirmek iÃ§in standart Ã¶lÃ§eklendirme ekleyen yorumlanmÄ±ÅŸ kod bulacaksÄ±nÄ±z. Siluet skoru dÃ¼ÅŸse de, dirsek grafiÄŸindeki 'bÃ¼kÃ¼m' yumuÅŸar. Bunun nedeni, verileri Ã¶lÃ§eklendirilmemiÅŸ bÄ±rakmanÄ±n, daha az varyansa sahip verilerin daha fazla aÄŸÄ±rlÄ±k taÅŸÄ±masÄ±na izin vermesidir. Bu sorun hakkÄ±nda biraz daha okuyun [burada](https://stats.stackexchange.com/questions/21222/are-mean-normalization-and-feature-scaling-needed-for-k-means-clustering/21226#21226).

## [Ders SonrasÄ± Test](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/30/)

## GÃ¶zden GeÃ§irme ve Kendi Kendine Ã‡alÄ±ÅŸma

Bir K-Means SimÃ¼latÃ¶rÃ¼ne [bu gibi](https://user.ceng.metu.edu.tr/~akifakkus/courses/ceng574/k-means/) gÃ¶z atÄ±n. Bu aracÄ± kullanarak Ã¶rnek veri noktalarÄ±nÄ± gÃ¶rselleÅŸtirebilir ve merkez noktalarÄ±nÄ± belirleyebilirsiniz. Verilerin rastgeleliÄŸini, kÃ¼me sayÄ±larÄ±nÄ± ve merkez noktalarÄ±nÄ± dÃ¼zenleyebilirsiniz. Bu, verilerin nasÄ±l gruplanabileceÄŸi hakkÄ±nda bir fikir edinmenize yardÄ±mcÄ± olur mu?

AyrÄ±ca Stanford'dan [bu K-Means el kitabÄ±na](https://stanford.edu/~cpiech/cs221/handouts/kmeans.html) gÃ¶z atÄ±n.

## Ã–dev

[FarklÄ± kÃ¼meleme yÃ¶ntemlerini deneyin](assignment.md)

**Feragatname**:
Bu belge, makine tabanlÄ± yapay zeka Ã§eviri hizmetleri kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba sarf etsek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan herhangi bir yanlÄ±ÅŸ anlama veya yanlÄ±ÅŸ yorumlamadan sorumlu deÄŸiliz.