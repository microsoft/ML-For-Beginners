# PekiÅŸtirmeli Ã–ÄŸrenmeye GiriÅŸ

PekiÅŸtirmeli Ã¶ÄŸrenme, RL, denetimli Ã¶ÄŸrenme ve denetimsiz Ã¶ÄŸrenmenin yanÄ±nda temel makine Ã¶ÄŸrenme paradigmalarÄ±ndan biri olarak gÃ¶rÃ¼lÃ¼r. RL, kararlarla ilgilidir: doÄŸru kararlarÄ± vermek veya en azÄ±ndan onlardan Ã¶ÄŸrenmek.

Bir simÃ¼le edilmiÅŸ ortamÄ±nÄ±z olduÄŸunu hayal edin, Ã¶rneÄŸin borsa. Belirli bir dÃ¼zenleme getirirseniz ne olur? Olumlu veya olumsuz bir etkisi var mÄ±? Olumsuz bir ÅŸey olursa, bu _olumsuz pekiÅŸtirmeyi_ almalÄ±, ondan Ã¶ÄŸrenmeli ve rotanÄ±zÄ± deÄŸiÅŸtirmelisiniz. EÄŸer olumlu bir sonuÃ§ olursa, bu _olumlu pekiÅŸtirmeyi_ geliÅŸtirmelisiniz.

![peter ve kurt](../../../translated_images/peter.779730f9ba3a8a8d9290600dcf55f2e491c0640c785af7ac0d64f583c49b8864.tr.png)

> Peter ve arkadaÅŸlarÄ±nÄ±n aÃ§ kurttan kaÃ§masÄ± gerekiyor! GÃ¶rsel [Jen Looper](https://twitter.com/jenlooper) tarafÄ±ndan

## BÃ¶lgesel Konu: Peter ve Kurt (Rusya)

[Peter ve Kurt](https://en.wikipedia.org/wiki/Peter_and_the_Wolf), Rus besteci [Sergei Prokofiev](https://en.wikipedia.org/wiki/Sergei_Prokofiev) tarafÄ±ndan yazÄ±lmÄ±ÅŸ bir mÃ¼zikli peri masalÄ±dÄ±r. Bu, genÃ§ Ã¶ncÃ¼ Peter'in cesurca evinden Ã§Ä±kÄ±p ormanda kurtu kovalamaya gittiÄŸi bir hikayedir. Bu bÃ¶lÃ¼mde, Peter'e yardÄ±mcÄ± olacak makine Ã¶ÄŸrenme algoritmalarÄ±nÄ± eÄŸiteceÄŸiz:

- Ã‡evreyi **keÅŸfetmek** ve optimal bir navigasyon haritasÄ± oluÅŸturmak
- Daha hÄ±zlÄ± hareket edebilmek iÃ§in kaykay kullanmayÄ± ve Ã¼zerinde denge kurmayÄ± **Ã¶ÄŸrenmek**.

[![Peter ve Kurt](https://img.youtube.com/vi/Fmi5zHg4QSM/0.jpg)](https://www.youtube.com/watch?v=Fmi5zHg4QSM)

> ğŸ¥ Peter ve Kurt'u dinlemek iÃ§in yukarÄ±daki gÃ¶rsele tÄ±klayÄ±n

## PekiÅŸtirmeli Ã–ÄŸrenme

Ã–nceki bÃ¶lÃ¼mlerde, iki tÃ¼r makine Ã¶ÄŸrenme problemi Ã¶rneÄŸi gÃ¶rdÃ¼nÃ¼z:

- **Denetimli**, Ã§Ã¶zmek istediÄŸimiz probleme Ã¶rnek Ã§Ã¶zÃ¼mler Ã¶neren veri kÃ¼melerimiz olduÄŸunda. [SÄ±nÄ±flandÄ±rma](../4-Classification/README.md) ve [regresyon](../2-Regression/README.md) denetimli Ã¶ÄŸrenme gÃ¶revleridir.
- **Denetimsiz**, etiketlenmiÅŸ eÄŸitim verilerimizin olmadÄ±ÄŸÄ± durumlarda. Denetimsiz Ã¶ÄŸrenmenin ana Ã¶rneÄŸi [KÃ¼meleme](../5-Clustering/README.md)'dir.

Bu bÃ¶lÃ¼mde, etiketlenmiÅŸ eÄŸitim verileri gerektirmeyen yeni bir Ã¶ÄŸrenme problem tÃ¼rÃ¼yle tanÄ±ÅŸacaksÄ±nÄ±z. Bu tÃ¼r problemlerin birkaÃ§ tÃ¼rÃ¼ vardÄ±r:

- **[YarÄ± denetimli Ã¶ÄŸrenme](https://wikipedia.org/wiki/Semi-supervised_learning)**, Ã§ok sayÄ±da etiketlenmemiÅŸ verinin modeli Ã¶nceden eÄŸitmek iÃ§in kullanÄ±labileceÄŸi durumlar.
- **[PekiÅŸtirmeli Ã¶ÄŸrenme](https://wikipedia.org/wiki/Reinforcement_learning)**, bir ajanÄ±nÄ±n simÃ¼le edilmiÅŸ bir ortamda deneyler yaparak nasÄ±l davranacaÄŸÄ±nÄ± Ã¶ÄŸrendiÄŸi durumlar.

### Ã–rnek - Bilgisayar Oyunu

Bir bilgisayara bir oyun, Ã¶rneÄŸin satranÃ§ veya [Super Mario](https://wikipedia.org/wiki/Super_Mario) oynamayÄ± Ã¶ÄŸretmek istediÄŸinizi varsayalÄ±m. BilgisayarÄ±n oyun oynamasÄ± iÃ§in, her oyun durumunda hangi hamleyi yapacaÄŸÄ±nÄ± tahmin etmesi gerekir. Bu bir sÄ±nÄ±flandÄ±rma problemi gibi gÃ¶rÃ¼nse de, deÄŸildir - Ã§Ã¼nkÃ¼ durumlar ve karÅŸÄ±lÄ±k gelen eylemlerle ilgili bir veri kÃ¼mesine sahip deÄŸiliz. Mevcut satranÃ§ maÃ§larÄ± veya Super Mario oynayan oyuncularÄ±n kayÄ±tlarÄ± gibi bazÄ± verilere sahip olsak da, bu verilerin yeterince geniÅŸ bir durumu kapsamayacaÄŸÄ± muhtemeldir.

Mevcut oyun verilerini aramak yerine, **PekiÅŸtirmeli Ã–ÄŸrenme** (RL), *bilgisayarÄ± birÃ§ok kez oynamaya ve sonucu gÃ¶zlemlemeye* dayalÄ±dÄ±r. Bu nedenle, PekiÅŸtirmeli Ã–ÄŸrenmeyi uygulamak iÃ§in iki ÅŸeye ihtiyacÄ±mÄ±z var:

- **Bir ortam** ve **bir simÃ¼latÃ¶r**, bu da oyunu birÃ§ok kez oynamamÄ±za izin verir. Bu simÃ¼latÃ¶r, tÃ¼m oyun kurallarÄ±nÄ±, olasÄ± durumlarÄ± ve eylemleri tanÄ±mlar.

- **Bir Ã¶dÃ¼l fonksiyonu**, bu da her hamle veya oyun sÄ±rasÄ±nda ne kadar iyi olduÄŸumuzu bize sÃ¶yler.

DiÄŸer makine Ã¶ÄŸrenme tÃ¼rleri ile RL arasÄ±ndaki temel fark, RL'de genellikle oyunu bitirene kadar kazanÄ±p kazanmadÄ±ÄŸÄ±mÄ±zÄ± bilmememizdir. Bu nedenle, belirli bir hamlenin tek baÅŸÄ±na iyi olup olmadÄ±ÄŸÄ±nÄ± sÃ¶yleyemeyiz - sadece oyunun sonunda bir Ã¶dÃ¼l alÄ±rÄ±z. AmacÄ±mÄ±z, belirsiz koÅŸullar altÄ±nda bir modeli eÄŸitmemizi saÄŸlayacak algoritmalar tasarlamaktÄ±r. **Q-learning** adÄ± verilen bir RL algoritmasÄ±nÄ± Ã¶ÄŸreneceÄŸiz.

## Dersler

1. [PekiÅŸtirmeli Ã¶ÄŸrenme ve Q-Learning'e giriÅŸ](1-QLearning/README.md)
2. [Gym simÃ¼lasyon ortamÄ±nÄ± kullanma](2-Gym/README.md)

## KatkÄ±da Bulunanlar

"PekiÅŸtirmeli Ã–ÄŸrenmeye GiriÅŸ" [Dmitry Soshnikov](http://soshnikov.com) tarafÄ±ndan â™¥ï¸ ile yazÄ±lmÄ±ÅŸtÄ±r.

**Feragatname**: 
Bu belge, makine tabanlÄ± yapay zeka Ã§eviri hizmetleri kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in, profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan herhangi bir yanlÄ±ÅŸ anlama veya yanlÄ±ÅŸ yorumlamadan sorumlu deÄŸiliz.