<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "abf86d845c84330bce205a46b382ec88",
  "translation_date": "2025-09-05T18:46:04+00:00",
  "source_file": "2-Regression/4-Logistic/README.md",
  "language_code": "he"
}
-->
# רגרסיה לוגיסטית לחיזוי קטגוריות

![אינפוגרפיקה של רגרסיה לוגיסטית מול רגרסיה ליניארית](../../../../2-Regression/4-Logistic/images/linear-vs-logistic.png)

## [מבחן מקדים להרצאה](https://ff-quizzes.netlify.app/en/ml/)

> ### [השיעור הזה זמין גם ב-R!](../../../../2-Regression/4-Logistic/solution/R/lesson_4.html)

## מבוא

בשיעור האחרון על רגרסיה, אחת מטכניקות ה-ML הקלאסיות הבסיסיות, נבחן את הרגרסיה הלוגיסטית. תשתמשו בטכניקה זו כדי לגלות דפוסים לחיזוי קטגוריות בינאריות. האם הממתק הזה הוא שוקולד או לא? האם המחלה הזו מדבקת או לא? האם הלקוח הזה יבחר במוצר הזה או לא?

בשיעור הזה תלמדו:

- ספרייה חדשה להדמיית נתונים
- טכניקות לרגרסיה לוגיסטית

✅ העמיקו את ההבנה שלכם בעבודה עם סוג זה של רגרסיה במודול [Learn](https://docs.microsoft.com/learn/modules/train-evaluate-classification-models?WT.mc_id=academic-77952-leestott)

## דרישות מקדימות

לאחר שעבדנו עם נתוני הדלעת, אנחנו כבר מספיק מכירים אותם כדי להבין שיש קטגוריה בינארית אחת שאפשר לעבוד איתה: `Color`.

בואו נבנה מודל רגרסיה לוגיסטית כדי לחזות, בהתבסס על משתנים מסוימים, _איזה צבע צפוי להיות לדלעת מסוימת_ (כתום 🎃 או לבן 👻).

> למה אנחנו מדברים על סיווג בינארי בשיעור שמקושר לרגרסיה? רק מטעמי נוחות לשונית, שכן רגרסיה לוגיסטית היא [בעצם שיטת סיווג](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression), אם כי מבוססת על ליניאריות. למדו על דרכים אחרות לסווג נתונים בקבוצת השיעורים הבאה.

## הגדרת השאלה

למטרותינו, נבטא זאת כבינארי: 'לבן' או 'לא לבן'. יש גם קטגוריה 'מפוספסת' במאגר הנתונים שלנו, אבל יש מעט מקרים שלה, ולכן לא נשתמש בה. היא נעלמת בכל מקרה ברגע שמסירים ערכים חסרים מהמאגר.

> 🎃 עובדה מעניינת: לפעמים אנחנו קוראים לדלעות לבנות 'דלעות רפאים'. הן לא קלות לגילוף, ולכן הן פחות פופולריות מהכתומות, אבל הן נראות מגניבות! אז אפשר גם לנסח מחדש את השאלה שלנו כ: 'רפאים' או 'לא רפאים'. 👻

## על רגרסיה לוגיסטית

רגרסיה לוגיסטית שונה מרגרסיה ליניארית, שלמדתם עליה קודם, בכמה דרכים חשובות.

[![ML למתחילים - הבנת רגרסיה לוגיסטית לסיווג בלמידת מכונה](https://img.youtube.com/vi/KpeCT6nEpBY/0.jpg)](https://youtu.be/KpeCT6nEpBY "ML למתחילים - הבנת רגרסיה לוגיסטית לסיווג בלמידת מכונה")

> 🎥 לחצו על התמונה למעלה לסרטון קצר על רגרסיה לוגיסטית.

### סיווג בינארי

רגרסיה לוגיסטית לא מציעה את אותן תכונות כמו רגרסיה ליניארית. הראשונה מציעה חיזוי של קטגוריה בינארית ("לבן או לא לבן"), בעוד שהאחרונה מסוגלת לחזות ערכים רציפים, למשל בהתבסס על מקור הדלעת וזמן הקטיף, _כמה המחיר שלה יעלה_.

![מודל סיווג דלעות](../../../../2-Regression/4-Logistic/images/pumpkin-classifier.png)
> אינפוגרפיקה מאת [Dasani Madipalli](https://twitter.com/dasani_decoded)

### סיווגים אחרים

ישנם סוגים אחרים של רגרסיה לוגיסטית, כולל מולטינומיאלית ואורדינלית:

- **מולטינומיאלית**, שכוללת יותר מקטגוריה אחת - "כתום, לבן ומפוספס".
- **אורדינלית**, שכוללת קטגוריות מסודרות, שימושית אם נרצה לסדר את התוצאות שלנו באופן לוגי, כמו הדלעות שלנו שמסודרות לפי מספר סופי של גדלים (מיני, קטן, בינוני, גדול, XL, XXL).

![רגרסיה מולטינומיאלית מול אורדינלית](../../../../2-Regression/4-Logistic/images/multinomial-vs-ordinal.png)

### המשתנים לא חייבים להיות מתואמים

זוכרים איך רגרסיה ליניארית עבדה טוב יותר עם משתנים מתואמים? רגרסיה לוגיסטית היא ההפך - המשתנים לא חייבים להיות מתואמים. זה עובד עבור הנתונים האלה שיש להם מתאמים חלשים יחסית.

### צריך הרבה נתונים נקיים

רגרסיה לוגיסטית תיתן תוצאות מדויקות יותר אם תשתמשו ביותר נתונים; מאגר הנתונים הקטן שלנו אינו אופטימלי למשימה זו, אז קחו זאת בחשבון.

[![ML למתחילים - ניתוח והכנת נתונים לרגרסיה לוגיסטית](https://img.youtube.com/vi/B2X4H9vcXTs/0.jpg)](https://youtu.be/B2X4H9vcXTs "ML למתחילים - ניתוח והכנת נתונים לרגרסיה לוגיסטית")

> 🎥 לחצו על התמונה למעלה לסרטון קצר על הכנת נתונים לרגרסיה ליניארית.

✅ חשבו על סוגי הנתונים שיתאימו לרגרסיה לוגיסטית.

## תרגיל - ניקוי הנתונים

ראשית, ננקה את הנתונים מעט, נסיר ערכים חסרים ונבחר רק חלק מהעמודות:

1. הוסיפו את הקוד הבא:

    ```python
  
    columns_to_select = ['City Name','Package','Variety', 'Origin','Item Size', 'Color']
    pumpkins = full_pumpkins.loc[:, columns_to_select]

    pumpkins.dropna(inplace=True)
    ```

    תמיד אפשר להציץ במאגר הנתונים החדש שלכם:

    ```python
    pumpkins.info
    ```

### הדמיה - תרשים קטגוריאלי

עד עכשיו טענתם את [מחברת ההתחלה](../../../../2-Regression/4-Logistic/notebook.ipynb) עם נתוני הדלעות שוב וניקיתם אותה כך שתשמר מאגר נתונים המכיל כמה משתנים, כולל `Color`. בואו נדמיין את מאגר הנתונים במחברת באמצעות ספרייה אחרת: [Seaborn](https://seaborn.pydata.org/index.html), שנבנתה על Matplotlib שבה השתמשנו קודם.

Seaborn מציעה דרכים מעניינות להדמיית הנתונים שלכם. לדוגמה, אפשר להשוות את התפלגות הנתונים עבור כל `Variety` ו-`Color` בתרשים קטגוריאלי.

1. צרו תרשים כזה באמצעות הפונקציה `catplot`, תוך שימוש בנתוני הדלעות שלנו `pumpkins`, והגדירו מיפוי צבעים לכל קטגוריית דלעת (כתום או לבן):

    ```python
    import seaborn as sns
    
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }

    sns.catplot(
    data=pumpkins, y="Variety", hue="Color", kind="count",
    palette=palette, 
    )
    ```

    ![רשת של נתונים מדומיינים](../../../../2-Regression/4-Logistic/images/pumpkins_catplot_1.png)

    בהתבוננות בנתונים, אפשר לראות כיצד נתוני הצבע קשורים לזן.

    ✅ בהתבסס על התרשים הקטגוריאלי הזה, אילו חקירות מעניינות אתם יכולים לדמיין?

### עיבוד נתונים: קידוד תכונות ותוויות

מאגר הנתונים של הדלעות שלנו מכיל ערכי מחרוזת עבור כל העמודות שלו. עבודה עם נתונים קטגוריאליים היא אינטואיטיבית עבור בני אדם אך לא עבור מכונות. אלגוריתמים של למידת מכונה עובדים טוב עם מספרים. לכן קידוד הוא שלב חשוב מאוד בשלב עיבוד הנתונים, מכיוון שהוא מאפשר לנו להפוך נתונים קטגוריאליים לנתונים מספריים, מבלי לאבד מידע. קידוד טוב מוביל לבניית מודל טוב.

לקידוד תכונות יש שני סוגים עיקריים של מקודדים:

1. מקודד אורדינלי: מתאים היטב למשתנים אורדינליים, שהם משתנים קטגוריאליים שבהם הנתונים שלהם עוקבים אחר סדר לוגי, כמו עמודת `Item Size` במאגר הנתונים שלנו. הוא יוצר מיפוי כך שכל קטגוריה מיוצגת על ידי מספר, שהוא הסדר של הקטגוריה בעמודה.

    ```python
    from sklearn.preprocessing import OrdinalEncoder

    item_size_categories = [['sml', 'med', 'med-lge', 'lge', 'xlge', 'jbo', 'exjbo']]
    ordinal_features = ['Item Size']
    ordinal_encoder = OrdinalEncoder(categories=item_size_categories)
    ```

2. מקודד קטגוריאלי: מתאים היטב למשתנים נומינליים, שהם משתנים קטגוריאליים שבהם הנתונים שלהם אינם עוקבים אחר סדר לוגי, כמו כל התכונות השונות מ-`Item Size` במאגר הנתונים שלנו. זהו קידוד one-hot, כלומר כל קטגוריה מיוצגת על ידי עמודה בינארית: המשתנה המקודד שווה ל-1 אם הדלעת שייכת לזן הזה ול-0 אחרת.

    ```python
    from sklearn.preprocessing import OneHotEncoder

    categorical_features = ['City Name', 'Package', 'Variety', 'Origin']
    categorical_encoder = OneHotEncoder(sparse_output=False)
    ```

לאחר מכן, משתמשים ב-`ColumnTransformer` כדי לשלב מספר מקודדים לשלב אחד וליישם אותם על העמודות המתאימות.

```python
    from sklearn.compose import ColumnTransformer
    
    ct = ColumnTransformer(transformers=[
        ('ord', ordinal_encoder, ordinal_features),
        ('cat', categorical_encoder, categorical_features)
        ])
    
    ct.set_output(transform='pandas')
    encoded_features = ct.fit_transform(pumpkins)
```

מצד שני, לקידוד התווית, משתמשים במחלקת `LabelEncoder` של scikit-learn, שהיא מחלקת עזר לנרמל תוויות כך שיכילו רק ערכים בין 0 ל-n_classes-1 (כאן, 0 ו-1).

```python
    from sklearn.preprocessing import LabelEncoder

    label_encoder = LabelEncoder()
    encoded_label = label_encoder.fit_transform(pumpkins['Color'])
```

לאחר שקידדנו את התכונות והתווית, אפשר למזג אותן למאגר נתונים חדש `encoded_pumpkins`.

```python
    encoded_pumpkins = encoded_features.assign(Color=encoded_label)
```

✅ מה היתרונות של שימוש במקודד אורדינלי עבור עמודת `Item Size`?

### ניתוח קשרים בין משתנים

עכשיו, לאחר שעיבדנו את הנתונים שלנו, אפשר לנתח את הקשרים בין התכונות לתווית כדי להבין עד כמה המודל יוכל לחזות את התווית בהתבסס על התכונות. הדרך הטובה ביותר לבצע ניתוח כזה היא באמצעות הדמיית הנתונים. נשתמש שוב בפונקציה `catplot` של Seaborn, כדי להמחיש את הקשרים בין `Item Size`, `Variety` ו-`Color` בתרשים קטגוריאלי. כדי להמחיש את הנתונים טוב יותר נשתמש בעמודת `Item Size` המקודדת ובעמודת `Variety` הלא מקודדת.

```python
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }
    pumpkins['Item Size'] = encoded_pumpkins['ord__Item Size']

    g = sns.catplot(
        data=pumpkins,
        x="Item Size", y="Color", row='Variety',
        kind="box", orient="h",
        sharex=False, margin_titles=True,
        height=1.8, aspect=4, palette=palette,
    )
    g.set(xlabel="Item Size", ylabel="").set(xlim=(0,6))
    g.set_titles(row_template="{row_name}")
```

![תרשים קטגוריאלי של נתונים מדומיינים](../../../../2-Regression/4-Logistic/images/pumpkins_catplot_2.png)

### שימוש בתרשים swarm

מכיוון ש-Color הוא קטגוריה בינארית (לבן או לא), הוא דורש '[גישה מיוחדת](https://seaborn.pydata.org/tutorial/categorical.html?highlight=bar) להדמיה'. יש דרכים אחרות להמחיש את הקשר של קטגוריה זו עם משתנים אחרים.

אפשר להמחיש משתנים זה לצד זה עם תרשימי Seaborn.

1. נסו תרשים 'swarm' כדי להראות את התפלגות הערכים:

    ```python
    palette = {
    0: 'orange',
    1: 'wheat'
    }
    sns.swarmplot(x="Color", y="ord__Item Size", data=encoded_pumpkins, palette=palette)
    ```

    ![swarm של נתונים מדומיינים](../../../../2-Regression/4-Logistic/images/swarm_2.png)

**שימו לב**: הקוד למעלה עשוי ליצור אזהרה, מכיוון ש-Seaborn מתקשה לייצג כמות כזו של נקודות נתונים בתרשים swarm. פתרון אפשרי הוא להקטין את גודל הסמן, באמצעות הפרמטר 'size'. עם זאת, שימו לב שזה משפיע על קריאות התרשים.

> **🧮 תראו לי את המתמטיקה**
>
> רגרסיה לוגיסטית מתבססת על הרעיון של 'סבירות מרבית' באמצעות [פונקציות סיגמואיד](https://wikipedia.org/wiki/Sigmoid_function). פונקציית סיגמואיד על תרשים נראית כמו צורת 'S'. היא לוקחת ערך וממפה אותו למקום בין 0 ל-1. העקומה שלה נקראת גם 'עקומה לוגיסטית'. הנוסחה שלה נראית כך:
>
> ![פונקציה לוגיסטית](../../../../2-Regression/4-Logistic/images/sigmoid.png)
>
> כאשר נקודת האמצע של הסיגמואיד נמצאת בנקודת ה-0 של x, L הוא הערך המרבי של העקומה, ו-k הוא תלילות העקומה. אם תוצאת הפונקציה היא יותר מ-0.5, התווית המדוברת תינתן למעמד '1' של הבחירה הבינארית. אם לא, היא תסווג כ-'0'.

## בניית המודל שלכם

בניית מודל למציאת סיווגים בינאריים היא פשוטה באופן מפתיע ב-Scikit-learn.

[![ML למתחילים - רגרסיה לוגיסטית לסיווג נתונים](https://img.youtube.com/vi/MmZS2otPrQ8/0.jpg)](https://youtu.be/MmZS2otPrQ8 "ML למתחילים - רגרסיה לוגיסטית לסיווג נתונים")

> 🎥 לחצו על התמונה למעלה לסרטון קצר על בניית מודל רגרסיה ליניארית.

1. בחרו את המשתנים שתרצו להשתמש בהם במודל הסיווג שלכם וחלקו את קבוצות האימון והבדיקה באמצעות קריאה ל-`train_test_split()`:

    ```python
    from sklearn.model_selection import train_test_split
    
    X = encoded_pumpkins[encoded_pumpkins.columns.difference(['Color'])]
    y = encoded_pumpkins['Color']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
    
    ```

2. עכשיו אפשר לאמן את המודל, באמצעות קריאה ל-`fit()` עם נתוני האימון שלכם, ולהדפיס את התוצאה שלו:

    ```python
    from sklearn.metrics import f1_score, classification_report 
    from sklearn.linear_model import LogisticRegression

    model = LogisticRegression()
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)

    print(classification_report(y_test, predictions))
    print('Predicted labels: ', predictions)
    print('F1-score: ', f1_score(y_test, predictions))
    ```

    הסתכלו על לוח התוצאות של המודל שלכם. הוא לא רע, בהתחשב בכך שיש לכם רק כ-1000 שורות נתונים:

    ```output
                       precision    recall  f1-score   support
    
                    0       0.94      0.98      0.96       166
                    1       0.85      0.67      0.75        33
    
        accuracy                                0.92       199
        macro avg           0.89      0.82      0.85       199
        weighted avg        0.92      0.92      0.92       199
    
        Predicted labels:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0
        0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
        1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0
        0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0
        0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
        0 0 0 1 0 0 0 0 0 0 0 0 1 1]
        F1-score:  0.7457627118644068
    ```

## הבנה טובה יותר באמצעות מטריצת בלבול

בעוד שאפשר לקבל דוח תוצאות [מונחים](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html?highlight=classification_report#sklearn.metrics.classification_report) על ידי הדפסת הפריטים למעלה, ייתכן שתוכלו להבין את המודל שלכם ביתר קלות באמצעות [מטריצת בלבול](https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix) שתעזור לנו להבין כיצד המודל מתפקד.

> 🎓 '[מטריצת בלבול](https://wikipedia.org/wiki/Confusion_matrix)' (או 'מטריצת שגיאות') היא טבלה שמבטאת את החיוביים והשליליים האמיתיים מול השגויים של המודל שלכם, ובכך מעריכה את דיוק התחזיות.

1. כדי להשתמש במטריצת בלבול, קראו ל-`confusion_matrix()`:

    ```python
    from sklearn.metrics import confusion_matrix
    confusion_matrix(y_test, predictions)
    ```

    הסתכלו על מטריצת הבלבול של המודל שלכם:

    ```output
    array([[162,   4],
           [ 11,  22]])
    ```

ב-Scikit-learn, שורות (axis 0) הן תוויות אמיתיות ועמודות (axis 1) הן תוויות חזויות.

|       |   0   |   1   |
| :---: | :---: | :---: |
|   0   |  TN   |  FP   |
|   1   |  FN   |  TP   |

מה קורה כאן? נניח שהמודל שלנו מתבקש לסווג דלעות בין שתי קטגוריות בינאריות, קטגוריה 'לבן' וקטגוריה 'לא-לבן'.

- אם המודל שלכם חוזה דלעת כלא לבנה והיא שייכת לקטגוריה 'לא-לבן' במציאות, אנחנו קוראים לזה שלילי אמיתי (True Negative), שמוצג על ידי המספר בפינה השמאלית העליונה.
- אם המודל שלכם חוזה דלעת כלבנה והיא שייכת לקטגוריה 'לא-לבן' במציאות, אנחנו קוראים לזה שלילי שגוי (False Negative), שמוצג על ידי המספר בפינה השמאלית התחתונה.
- אם המודל שלכם חוזה דלעת כלא לבנה והיא שייכת לקטגוריה 'לבן' במציאות, אנחנו קוראים לזה חיובי שגוי (False Positive), שמוצג על ידי המספר בפינה הימנית העליונה.
- אם המודל שלכם חוזה דלעת כלבנה והיא שייכת לקטגוריה 'לבן' במציאות, אנחנו קוראים לזה חיובי אמיתי (True Positive), שמוצג על ידי המספר בפינה הימנית התחתונה.

כפי שכנראה ניחשתם, עדיף שיהיו יותר חיוביים אמיתיים ושליליים אמיתיים ומספר נמוך יותר של חיוביים שגויים ושליליים שגויים, מה שמעיד על כך שהמודל מתפקד טוב יותר.
כיצד מטריצת הבלבול קשורה לדיוק ולשליפה? זכרו, דוח הסיווג שהודפס למעלה הציג דיוק (0.85) ושליפה (0.67).

דיוק = tp / (tp + fp) = 22 / (22 + 4) = 0.8461538461538461

שליפה = tp / (tp + fn) = 22 / (22 + 11) = 0.6666666666666666

✅ ש: לפי מטריצת הבלבול, איך המודל ביצע? ת: לא רע; יש מספר טוב של שליליים אמיתיים אבל גם כמה שליליים שגויים.

בואו נחזור למונחים שראינו קודם בעזרת המיפוי של TP/TN ו-FP/FN במטריצת הבלבול:

🎓 דיוק: TP/(TP + FP) החלק של המקרים הרלוונטיים מתוך המקרים שנמצאו (לדוגמה, אילו תוויות סווגו היטב).

🎓 שליפה: TP/(TP + FN) החלק של המקרים הרלוונטיים שנמצאו, בין אם סווגו היטב או לא.

🎓 ציון f1: (2 * דיוק * שליפה)/(דיוק + שליפה) ממוצע משוקלל של דיוק ושליפה, כאשר הטוב ביותר הוא 1 והגרוע ביותר הוא 0.

🎓 תמיכה: מספר המופעים של כל תווית שנמצאה.

🎓 דיוק כללי: (TP + TN)/(TP + TN + FP + FN) אחוז התוויות שסווגו בצורה מדויקת עבור דגימה.

🎓 ממוצע מאקרו: חישוב הממוצע הלא משוקלל של המדדים עבור כל תווית, מבלי להתחשב באי-איזון בין התוויות.

🎓 ממוצע משוקלל: חישוב הממוצע של המדדים עבור כל תווית, תוך התחשבות באי-איזון בין התוויות על ידי שקילתן לפי התמיכה (מספר המקרים האמיתיים עבור כל תווית).

✅ האם אתם יכולים לחשוב על איזה מדד כדאי להתמקד אם אתם רוצים שהמודל יפחית את מספר השליליים השגויים?

## ויזואליזציה של עקומת ROC של המודל הזה

[![ML למתחילים - ניתוח ביצועי רגרסיה לוגיסטית עם עקומות ROC](https://img.youtube.com/vi/GApO575jTA0/0.jpg)](https://youtu.be/GApO575jTA0 "ML למתחילים - ניתוח ביצועי רגרסיה לוגיסטית עם עקומות ROC")

> 🎥 לחצו על התמונה למעלה לצפייה בסרטון קצר על עקומות ROC

בואו נעשה ויזואליזציה נוספת כדי לראות את מה שנקרא 'עקומת ROC':

```python
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline

y_scores = model.predict_proba(X_test)
fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])

fig = plt.figure(figsize=(6, 6))
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.show()
```

באמצעות Matplotlib, שרטטו את [Receiving Operating Characteristic](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html?highlight=roc) או ROC של המודל. עקומות ROC משמשות לעיתים קרובות כדי לקבל מבט על תוצאות מסווג במונחים של חיוביים אמיתיים מול חיוביים שגויים. "עקומות ROC מציגות בדרך כלל את שיעור החיוביים האמיתיים על ציר ה-Y, ואת שיעור החיוביים השגויים על ציר ה-X." לכן, תלילות העקומה והמרחק בין קו האמצע לעקומה חשובים: אתם רוצים עקומה שמתקדמת במהירות למעלה ומעל הקו. במקרה שלנו, יש חיוביים שגויים בהתחלה, ואז הקו מתקדם למעלה ומעל בצורה נכונה:

![ROC](../../../../2-Regression/4-Logistic/images/ROC_2.png)

לבסוף, השתמשו ב-API של [`roc_auc_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html?highlight=roc_auc#sklearn.metrics.roc_auc_score) של Scikit-learn כדי לחשב את 'שטח מתחת לעקומה' (AUC):

```python
auc = roc_auc_score(y_test,y_scores[:,1])
print(auc)
```  
התוצאה היא `0.9749908725812341`. מכיוון ש-AUC נע בין 0 ל-1, אתם רוצים ציון גבוה, שכן מודל שמנבא בצורה נכונה ב-100% יקבל AUC של 1; במקרה הזה, המודל _די טוב_.

בשיעורים עתידיים על סיווגים, תלמדו כיצד לשפר את ציוני המודל שלכם. אבל לעת עתה, ברכות! סיימתם את שיעורי הרגרסיה האלה!

---
## 🚀אתגר

יש עוד הרבה ללמוד על רגרסיה לוגיסטית! אבל הדרך הטובה ביותר ללמוד היא להתנסות. מצאו מערך נתונים שמתאים לסוג זה של ניתוח ובנו מודל איתו. מה אתם לומדים? טיפ: נסו [Kaggle](https://www.kaggle.com/search?q=logistic+regression+datasets) עבור מערכי נתונים מעניינים.

## [מבחן לאחר השיעור](https://ff-quizzes.netlify.app/en/ml/)

## סקירה ולימוד עצמי

קראו את העמודים הראשונים של [המאמר הזה מסטנפורד](https://web.stanford.edu/~jurafsky/slp3/5.pdf) על שימושים מעשיים לרגרסיה לוגיסטית. חשבו על משימות שמתאימות יותר לאחד מסוגי הרגרסיה שלמדנו עד כה. מה יעבוד הכי טוב?

## משימה

[נסו שוב את הרגרסיה הזו](assignment.md)

---

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירות תרגום מבוסס בינה מלאכותית [Co-op Translator](https://github.com/Azure/co-op-translator). למרות שאנו שואפים לדיוק, יש לקחת בחשבון שתרגומים אוטומטיים עשויים להכיל שגיאות או אי דיוקים. המסמך המקורי בשפתו המקורית צריך להיחשב כמקור סמכותי. עבור מידע קריטי, מומלץ להשתמש בתרגום מקצועי על ידי אדם. איננו נושאים באחריות לאי הבנות או לפרשנויות שגויות הנובעות משימוש בתרגום זה.