<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "5f3cb462e3122e1afe7ab0050ccf2bd3",
  "translation_date": "2025-09-05T20:25:32+00:00",
  "source_file": "6-NLP/2-Tasks/README.md",
  "language_code": "he"
}
-->
# משימות וטכניקות נפוצות בעיבוד שפה טבעית

ברוב המשימות של *עיבוד שפה טבעית*, הטקסט שיש לעבד חייב להיות מפורק, נבדק, והתוצאות נשמרות או מושוות עם חוקים ומאגרי נתונים. משימות אלו מאפשרות למתכנת להסיק את _המשמעות_ או _הכוונה_ או רק את _תדירות_ המונחים והמילים בטקסט.

## [שאלון לפני ההרצאה](https://ff-quizzes.netlify.app/en/ml/)

בואו נגלה טכניקות נפוצות המשמשות לעיבוד טקסט. בשילוב עם למידת מכונה, טכניקות אלו עוזרות לנתח כמויות גדולות של טקסט בצורה יעילה. לפני שמיישמים למידת מכונה למשימות אלו, עם זאת, חשוב להבין את הבעיות שבהן נתקל מומחה NLP.

## משימות נפוצות בעיבוד שפה טבעית

ישנן דרכים שונות לנתח טקסט שבו אתם עובדים. ישנן משימות שניתן לבצע, ודרך משימות אלו ניתן להבין את הטקסט ולהסיק מסקנות. בדרך כלל מבצעים את המשימות הללו ברצף.

### טוקניזציה

כנראה הדבר הראשון שרוב האלגוריתמים של NLP צריכים לעשות הוא לפצל את הטקסט לטוקנים, או מילים. למרות שזה נשמע פשוט, התחשבות בסימני פיסוק ובמפרידי מילים ומשפטים בשפות שונות יכולה להפוך את המשימה למורכבת. ייתכן שתצטרכו להשתמש בשיטות שונות כדי לקבוע את הגבולות.

![טוקניזציה](../../../../6-NLP/2-Tasks/images/tokenization.png)
> טוקניזציה של משפט מתוך **גאווה ודעה קדומה**. אינפוגרפיקה מאת [Jen Looper](https://twitter.com/jenlooper)

### אמבדינגים

[אמבדינגים של מילים](https://wikipedia.org/wiki/Word_embedding) הם דרך להמיר את נתוני הטקסט שלכם למספרים. אמבדינגים נעשים בצורה כזו שמילים עם משמעות דומה או מילים שמשתמשים בהן יחד מתרכזות יחד.

![אמבדינגים של מילים](../../../../6-NLP/2-Tasks/images/embedding.png)
> "יש לי את הכבוד הרב ביותר לעצבים שלך, הם חברים ותיקים שלי." - אמבדינגים של מילים למשפט מתוך **גאווה ודעה קדומה**. אינפוגרפיקה מאת [Jen Looper](https://twitter.com/jenlooper)

✅ נסו [את הכלי המעניין הזה](https://projector.tensorflow.org/) להתנסות באמבדינגים של מילים. לחיצה על מילה אחת מציגה קבוצות של מילים דומות: 'toy' מתרכז עם 'disney', 'lego', 'playstation', ו-'console'.

### ניתוח תחבירי ותיוג חלקי דיבר

כל מילה שעברה טוקניזציה יכולה להיות מתויגת כחלק דיבר - שם עצם, פועל או תואר. המשפט `השועל האדום המהיר קפץ מעל הכלב החום העצלן` עשוי להיות מתויג כך: שועל = שם עצם, קפץ = פועל.

![ניתוח תחבירי](../../../../6-NLP/2-Tasks/images/parse.png)

> ניתוח תחבירי של משפט מתוך **גאווה ודעה קדומה**. אינפוגרפיקה מאת [Jen Looper](https://twitter.com/jenlooper)

ניתוח תחבירי הוא זיהוי אילו מילים קשורות זו לזו במשפט - למשל `השועל האדום המהיר קפץ` הוא רצף של תואר-שם עצם-פועל שנפרד מהרצף `הכלב החום העצלן`.

### תדירות מילים וביטויים

הליך שימושי בעת ניתוח גוף טקסט גדול הוא לבנות מילון של כל מילה או ביטוי מעניין וכמה פעמים הם מופיעים. המשפט `השועל האדום המהיר קפץ מעל הכלב החום העצלן` מכיל תדירות של 2 עבור המילה "ה".

בואו נסתכל על טקסט לדוגמה שבו נספור את תדירות המילים. השיר "The Winners" של רודיארד קיפלינג מכיל את הבית הבא:

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

מכיוון שתדירות ביטויים יכולה להיות רגישה או לא רגישה לאותיות גדולות, הביטוי `a friend` מופיע בתדירות של 2, `the` מופיע בתדירות של 6, ו-`travels` מופיע בתדירות של 2.

### N-grams

ניתן לפצל טקסט לרצפים של מילים באורך קבוע, מילה אחת (unigram), שתי מילים (bigram), שלוש מילים (trigram) או כל מספר מילים (n-grams).

לדוגמה, המשפט `השועל האדום המהיר קפץ מעל הכלב החום העצלן` עם ערך n-gram של 2 יפיק את ה-n-grams הבאים:

1. השועל האדום  
2. האדום המהיר  
3. המהיר קפץ  
4. קפץ מעל  
5. מעל הכלב  
6. הכלב החום  
7. החום העצלן  

ניתן לדמיין זאת כקופסה מחליקה על פני המשפט. הנה זה עבור n-grams של 3 מילים, ה-n-gram מודגש בכל משפט:

1.   <u>**השועל האדום המהיר**</u> קפץ מעל הכלב החום העצלן  
2.   השועל **<u>האדום המהיר קפץ</u>** מעל הכלב החום העצלן  
3.   השועל האדום **<u>המהיר קפץ מעל</u>** הכלב החום העצלן  
4.   השועל האדום המהיר **<u>קפץ מעל הכלב</u>** החום העצלן  
5.   השועל האדום המהיר קפץ **<u>מעל הכלב החום</u>** העצלן  
6.   השועל האדום המהיר קפץ מעל <u>**הכלב החום העצלן**</u>  

![חלון מחליק של n-grams](../../../../6-NLP/2-Tasks/images/n-grams.gif)

> ערך n-gram של 3: אינפוגרפיקה מאת [Jen Looper](https://twitter.com/jenlooper)

### חילוץ ביטויי שם עצם

ברוב המשפטים יש שם עצם שהוא הנושא או המושא של המשפט. באנגלית, ניתן לזהות אותו לעיתים קרובות ככזה שמקדים אותו 'a', 'an' או 'the'. זיהוי הנושא או המושא של משפט על ידי 'חילוץ ביטוי שם עצם' הוא משימה נפוצה ב-NLP כאשר מנסים להבין את משמעות המשפט.

✅ במשפט "I cannot fix on the hour, or the spot, or the look or the words, which laid the foundation. It is too long ago. I was in the middle before I knew that I had begun.", האם תוכלו לזהות את ביטויי שם העצם?

במשפט `השועל האדום המהיר קפץ מעל הכלב החום העצלן` ישנם 2 ביטויי שם עצם: **השועל האדום המהיר** ו-**הכלב החום העצלן**.

### ניתוח רגשות

ניתן לנתח משפט או טקסט כדי לקבוע את הרגש שבו, או עד כמה הוא *חיובי* או *שלילי*. רגש נמדד ב-*קוטביות* וב-*אובייקטיביות/סובייקטיביות*. קוטביות נמדדת מ-1.0- עד 1.0 (שלילי עד חיובי) ו-0.0 עד 1.0 (הכי אובייקטיבי עד הכי סובייקטיבי).

✅ בהמשך תלמדו שיש דרכים שונות לקבוע רגש באמצעות למידת מכונה, אך דרך אחת היא להחזיק רשימה של מילים וביטויים שמסווגים כחיוביים או שליליים על ידי מומחה אנושי וליישם את המודל הזה על טקסט כדי לחשב ציון קוטביות. האם אתם יכולים לראות כיצד זה יעבוד בנסיבות מסוימות ופחות טוב באחרות?

### נטייה

נטייה מאפשרת לכם לקחת מילה ולקבל את הצורה היחידית או הרבים שלה.

### לממטיזציה

*למה* היא השורש או המילה הראשית עבור קבוצת מילים, למשל *flew*, *flies*, *flying* יש להן למה של הפועל *fly*.

ישנם גם מאגרי נתונים שימושיים זמינים לחוקר NLP, במיוחד:

### WordNet

[WordNet](https://wordnet.princeton.edu/) הוא מאגר נתונים של מילים, מילים נרדפות, מילים מנוגדות ועוד פרטים רבים עבור כל מילה בשפות רבות ושונות. הוא שימושי מאוד כאשר מנסים לבנות תרגומים, בודקי איות או כלים לשפה מכל סוג.

## ספריות NLP

למזלכם, אין צורך לבנות את כל הטכניקות הללו בעצמכם, שכן ישנן ספריות Python מצוינות שמקלות מאוד על מפתחים שאינם מתמחים בעיבוד שפה טבעית או למידת מכונה. השיעורים הבאים כוללים דוגמאות נוספות לכך, אך כאן תלמדו כמה דוגמאות שימושיות שיעזרו לכם במשימה הבאה.

### תרגיל - שימוש בספריית `TextBlob`

בואו נשתמש בספרייה בשם TextBlob שכן היא מכילה APIs מועילים להתמודדות עם סוגי משימות אלו. TextBlob "עומדת על כתפיהם של ענקים כמו [NLTK](https://nltk.org) ו-[pattern](https://github.com/clips/pattern), ומשתלבת היטב עם שניהם." יש לה כמות משמעותית של למידת מכונה מובנית ב-API שלה.

> הערה: מדריך [Quick Start](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart) שימושי זמין עבור TextBlob ומומלץ למפתחי Python מנוסים.

בעת ניסיון לזהות *ביטויי שם עצם*, TextBlob מציעה מספר אפשרויות של מחלצים למציאת ביטויי שם עצם.

1. הסתכלו על `ConllExtractor`.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > מה קורה כאן? [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) הוא "מחלץ ביטויי שם עצם שמשתמש בניתוח תחבירי מבוסס על קורפוס האימון ConLL-2000." ConLL-2000 מתייחס לוועידת Computational Natural Language Learning בשנת 2000. בכל שנה הוועידה אירחה סדנה להתמודד עם בעיית NLP מורכבת, ובשנת 2000 זו הייתה חלוקת שמות עצם. מודל אומן על עיתון Wall Street Journal, עם "סעיפים 15-18 כנתוני אימון (211727 טוקנים) וסעיף 20 כנתוני בדיקה (47377 טוקנים)". תוכלו לראות את ההליכים ששימשו [כאן](https://www.clips.uantwerpen.be/conll2000/chunking/) ואת [התוצאות](https://ifarm.nl/erikt/research/np-chunking.html).

### אתגר - שיפור הבוט שלכם עם NLP

בשיעור הקודם בניתם בוט שאלות ותשובות פשוט מאוד. עכשיו, תשפרו את מרווין ותגרמו לו להיות קצת יותר אמפתי על ידי ניתוח הקלט שלכם לרגש והדפסת תגובה שתתאים לרגש. תצטרכו גם לזהות `noun_phrase` ולשאול עליו.

השלבים שלכם בבניית בוט שיחה טוב יותר:

1. הדפיסו הוראות שמייעצות למשתמש כיצד לתקשר עם הבוט  
2. התחילו לולאה  
   1. קבלו קלט מהמשתמש  
   2. אם המשתמש ביקש לצאת, צאו  
   3. עבדו את קלט המשתמש וקבעו תגובת רגש מתאימה  
   4. אם זוהה ביטוי שם עצם ברגש, הפכו אותו לרבים ושאלו על הנושא  
   5. הדפיסו תגובה  
3. חזרו לשלב 2  

הנה קטע קוד לקביעת רגש באמצעות TextBlob. שימו לב שיש רק ארבע *דרגות* של תגובת רגש (אתם יכולים להוסיף יותר אם תרצו):

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

הנה דוגמת פלט שתנחה אתכם (קלט המשתמש מופיע בשורות שמתחילות ב->):

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

פתרון אפשרי למשימה נמצא [כאן](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/2-Tasks/solution/bot.py)

✅ בדיקת ידע

1. האם אתם חושבים שהתגובות האמפתיות יגרמו למישהו לחשוב שהבוט באמת מבין אותו?  
2. האם זיהוי ביטוי שם עצם הופך את הבוט ליותר 'אמין'?  
3. מדוע חילוץ 'ביטוי שם עצם' ממשפט הוא דבר שימושי לעשות?  

---

ממשו את הבוט בבדיקת הידע הקודמת ונסו אותו על חבר. האם הוא יכול להטעות אותם? האם תוכלו להפוך את הבוט שלכם ליותר 'אמין'?

## 🚀אתגר

קחו משימה בבדיקת הידע הקודמת ונסו לממש אותה. נסו את הבוט על חבר. האם הוא יכול להטעות אותם? האם תוכלו להפוך את הבוט שלכם ליותר 'אמין'?

## [שאלון לאחר ההרצאה](https://ff-quizzes.netlify.app/en/ml/)

## סקירה ולימוד עצמי

בשיעורים הבאים תלמדו יותר על ניתוח רגשות. חקרו את הטכניקה המעניינת הזו במאמרים כמו אלו ב-[KDNuggets](https://www.kdnuggets.com/tag/nlp)

## משימה 

[גרמו לבוט לדבר בחזרה](assignment.md)

---

**כתב ויתור**:  
מסמך זה תורגם באמצעות שירות תרגום מבוסס בינה מלאכותית [Co-op Translator](https://github.com/Azure/co-op-translator). למרות שאנו שואפים לדיוק, יש לקחת בחשבון שתרגומים אוטומטיים עשויים להכיל שגיאות או אי דיוקים. המסמך המקורי בשפתו המקורית צריך להיחשב כמקור סמכותי. עבור מידע קריטי, מומלץ להשתמש בתרגום מקצועי על ידי אדם. איננו נושאים באחריות לאי הבנות או לפרשנויות שגויות הנובעות משימוש בתרגום זה.