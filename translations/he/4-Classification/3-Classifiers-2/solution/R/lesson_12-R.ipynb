{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "lesson_12-R.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "ir",
   "display_name": "R"
  },
  "language_info": {
   "name": "R"
  },
  "coopTranslator": {
   "original_hash": "fab50046ca413a38939d579f8432274f",
   "translation_date": "2025-09-04T08:39:45+00:00",
   "source_file": "4-Classification/3-Classifiers-2/solution/R/lesson_12-R.ipynb",
   "language_code": "he"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsFutf_ygqSx"
   },
   "source": [
    "# בנה מודל סיווג: מטבחים אסייתיים והודיים טעימים\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HD54bEefgtNO"
   },
   "source": [
    "## מסווגי מטבחים 2\n",
    "\n",
    "בשיעור הסיווג השני, נחקור `דרכים נוספות` לסווג נתונים קטגוריים. בנוסף, נלמד על ההשלכות של בחירת מסווג אחד על פני אחר.\n",
    "\n",
    "### [**שאלון לפני השיעור**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/23/)\n",
    "\n",
    "### **דרישות מוקדמות**\n",
    "\n",
    "אנו מניחים שסיימתם את השיעורים הקודמים, שכן נשתמש בכמה מושגים שלמדנו בעבר.\n",
    "\n",
    "לשיעור זה נזדקק לחבילות הבאות:\n",
    "\n",
    "-   `tidyverse`: [tidyverse](https://www.tidyverse.org/) הוא [אוסף של חבילות R](https://www.tidyverse.org/packages) שנועד להפוך את מדע הנתונים למהיר, קל ומהנה יותר!\n",
    "\n",
    "-   `tidymodels`: [מסגרת tidymodels](https://www.tidymodels.org/) היא [אוסף של חבילות](https://www.tidymodels.org/packages/) למידול ולמידת מכונה.\n",
    "\n",
    "-   `themis`: [חבילת themis](https://themis.tidymodels.org/) מספקת שלבים נוספים במתכונים להתמודדות עם נתונים לא מאוזנים.\n",
    "\n",
    "ניתן להתקין אותן כך:\n",
    "\n",
    "`install.packages(c(\"tidyverse\", \"tidymodels\", \"kernlab\", \"themis\", \"ranger\", \"xgboost\", \"kknn\"))`\n",
    "\n",
    "לחילופין, הסקריפט הבא בודק אם יש לכם את החבילות הנדרשות להשלמת המודול ומתקין אותן עבורכם במקרה שהן חסרות.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vZ57IuUxgyQt"
   },
   "source": [
    "suppressWarnings(if (!require(\"pacman\"))install.packages(\"pacman\"))\n",
    "\n",
    "pacman::p_load(tidyverse, tidymodels, themis, kernlab, ranger, xgboost, kknn)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z22M-pj4g07x"
   },
   "source": [
    "## **1. מפת סיווג**\n",
    "\n",
    "בשיעור [הקודם שלנו](https://github.com/microsoft/ML-For-Beginners/tree/main/4-Classification/2-Classifiers-1), ניסינו להתמודד עם השאלה: איך בוחרים בין מספר מודלים? במידה רבה, זה תלוי במאפייני הנתונים ובסוג הבעיה שאנחנו רוצים לפתור (למשל סיווג או רגרסיה?).\n",
    "\n",
    "בעבר, למדנו על האפשרויות השונות שיש לכם בעת סיווג נתונים באמצעות דף העזר של מיקרוסופט. מסגרת הלמידה החישובית של Python, Scikit-learn, מציעה דף עזר דומה אך מפורט יותר שיכול לעזור לצמצם את הבחירה במעריכים שלכם (מונח נוסף למסווגים):\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/map.png\"\n",
    "   width=\"700\"/>\n",
    "   <figcaption></figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1i3xRIVg7vG"
   },
   "source": [
    "> טיפ: [בקרו במפה הזו אונליין](https://scikit-learn.org/stable/tutorial/machine_learning_map/) ולחצו לאורך המסלול כדי לקרוא את התיעוד.  \n",
    ">  \n",
    "> אתר [Tidymodels reference](https://www.tidymodels.org/find/parsnip/#models) מספק גם הוא תיעוד מצוין על סוגים שונים של מודלים.\n",
    "\n",
    "### **התוכנית** 🗺️\n",
    "\n",
    "המפה הזו מאוד מועילה ברגע שיש לכם הבנה ברורה של הנתונים שלכם, כיוון שניתן 'ללכת' לאורך המסלולים שלה כדי להגיע להחלטה:\n",
    "\n",
    "-   יש לנו יותר מ-50 דגימות  \n",
    "\n",
    "-   אנחנו רוצים לחזות קטגוריה  \n",
    "\n",
    "-   יש לנו נתונים מתויגים  \n",
    "\n",
    "-   יש לנו פחות מ-100,000 דגימות  \n",
    "\n",
    "-   ✨ אנחנו יכולים לבחור ב-Linear SVC  \n",
    "\n",
    "-   אם זה לא עובד, מכיוון שיש לנו נתונים מספריים  \n",
    "\n",
    "    -   נוכל לנסות ✨ KNeighbors Classifier  \n",
    "\n",
    "        -   אם זה לא עובד, ננסה ✨ SVC ו-✨ Ensemble Classifiers  \n",
    "\n",
    "זהו מסלול מאוד מועיל לעקוב אחריו. עכשיו, בואו נצלול ישר לתוך זה באמצעות מסגרת המידול של [tidymodels](https://www.tidymodels.org/): אוסף עקבי וגמיש של חבילות R שפותחו לעידוד פרקטיקה סטטיסטית טובה 😊.\n",
    "\n",
    "## 2. פיצול הנתונים והתמודדות עם מערך נתונים לא מאוזן.\n",
    "\n",
    "מהשיעורים הקודמים שלנו, למדנו שהיו סט של מרכיבים נפוצים בין המטבחים שלנו. בנוסף, הייתה חלוקה לא שוויונית במספר המטבחים.\n",
    "\n",
    "נתמודד עם זה על ידי:\n",
    "\n",
    "-   הסרת המרכיבים הנפוצים ביותר שיוצרים בלבול בין מטבחים שונים, באמצעות `dplyr::select()`.  \n",
    "\n",
    "-   שימוש ב-`recipe` שמכין את הנתונים למידול על ידי יישום אלגוריתם של `over-sampling`.  \n",
    "\n",
    "כבר הסתכלנו על זה בשיעור הקודם, כך שזה אמור להיות קליל 🥳!  \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6tj_rN00hClA"
   },
   "source": [
    "# Load the core Tidyverse and Tidymodels packages\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "\n",
    "# Load the original cuisines data\n",
    "df <- read_csv(file = \"https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/data/cuisines.csv\")\n",
    "\n",
    "# Drop id column, rice, garlic and ginger from our original data set\n",
    "df_select <- df %>% \n",
    "  select(-c(1, rice, garlic, ginger)) %>%\n",
    "  # Encode cuisine column as categorical\n",
    "  mutate(cuisine = factor(cuisine))\n",
    "\n",
    "\n",
    "# Create data split specification\n",
    "set.seed(2056)\n",
    "cuisines_split <- initial_split(data = df_select,\n",
    "                                strata = cuisine,\n",
    "                                prop = 0.7)\n",
    "\n",
    "# Extract the data in each split\n",
    "cuisines_train <- training(cuisines_split)\n",
    "cuisines_test <- testing(cuisines_split)\n",
    "\n",
    "# Display distribution of cuisines in the training set\n",
    "cuisines_train %>% \n",
    "  count(cuisine) %>% \n",
    "  arrange(desc(n))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFin5yw3hHb1"
   },
   "source": [
    "### התמודדות עם נתונים לא מאוזנים\n",
    "\n",
    "נתונים לא מאוזנים משפיעים לעיתים קרובות באופן שלילי על ביצועי המודל. רבים מהמודלים עובדים בצורה הטובה ביותר כאשר מספר התצפיות שווה, ולכן נוטים להתקשות עם נתונים לא מאוזנים.\n",
    "\n",
    "ישנן שתי דרכים עיקריות להתמודד עם מערכי נתונים לא מאוזנים:\n",
    "\n",
    "-   הוספת תצפיות לקבוצה המיעוט: `דגימה יתרה` לדוגמה, שימוש באלגוריתם SMOTE שמייצר באופן סינתטי דוגמאות חדשות לקבוצת המיעוט באמצעות שכנים קרובים של המקרים הללו.\n",
    "\n",
    "-   הסרת תצפיות מקבוצת הרוב: `דגימה חסרה`\n",
    "\n",
    "בשיעור הקודם שלנו, הדגמנו כיצד להתמודד עם מערכי נתונים לא מאוזנים באמצעות `recipe`. ניתן לחשוב על recipe כעל תבנית שמתארת אילו שלבים יש ליישם על מערך נתונים כדי להכין אותו לניתוח נתונים. במקרה שלנו, אנו רוצים להשיג חלוקה שווה במספר המטבחים עבור `מערך האימון` שלנו. בואו נצלול ישר לתוך זה.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cRzTnHolhLWd"
   },
   "source": [
    "# Load themis package for dealing with imbalanced data\n",
    "library(themis)\n",
    "\n",
    "# Create a recipe for preprocessing training data\n",
    "cuisines_recipe <- recipe(cuisine ~ ., data = cuisines_train) %>%\n",
    "  step_smote(cuisine) \n",
    "\n",
    "# Print recipe\n",
    "cuisines_recipe"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxOQ2ORhhO81"
   },
   "source": [
    "עכשיו אנחנו מוכנים לאמן מודלים 👩‍💻👨‍💻!\n",
    "\n",
    "## 3. מעבר למודלים של רגרסיה מולטינומית\n",
    "\n",
    "בשיעור הקודם, הסתכלנו על מודלים של רגרסיה מולטינומית. בואו נחקור כמה מודלים גמישים יותר לסיווג.\n",
    "\n",
    "### מכונות וקטור תמיכה\n",
    "\n",
    "בהקשר של סיווג, `מכונות וקטור תמיכה` הן טכניקת למידת מכונה שמנסה למצוא *היפר-מישור* שמפריד בצורה \"הטובה ביותר\" בין הקטגוריות. בואו נסתכל על דוגמה פשוטה:\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/svm.png\"\n",
    "   width=\"300\"/>\n",
    "   <figcaption>https://commons.wikimedia.org/w/index.php?curid=22877598</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4Wsd0vZhXYu"
   },
   "source": [
    "H1~ אינו מפריד בין הקבוצות. H2~ כן מפריד, אך רק עם שוליים קטנים. H3~ מפריד ביניהן עם השוליים המקסימליים.\n",
    "\n",
    "#### מסווג וקטור תומך לינארי\n",
    "\n",
    "קלאסיפיקציה באמצעות וקטור תומך (SVC) היא חלק ממשפחת טכניקות למידת המכונה של מכונות וקטור תומך. ב-SVC, ההיפר-מישור נבחר כך שיפריד בצורה נכונה את `רוב` התצפיות באימון, אך `עשוי לסווג שגוי` כמה תצפיות. על ידי מתן אפשרות לכמה נקודות להיות בצד הלא נכון, ה-SVM הופך לעמיד יותר לנקודות חריגות ולכן משפר את היכולת להכליל על נתונים חדשים. הפרמטר שמווסת את ההפרה הזו נקרא `cost`, והערך ברירת המחדל שלו הוא 1 (ראו `help(\"svm_poly\")`).\n",
    "\n",
    "בואו ניצור SVC לינארי על ידי הגדרת `degree = 1` במודל SVM פולינומי.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vJpp6nuChlBz"
   },
   "source": [
    "# Make a linear SVC specification\n",
    "svc_linear_spec <- svm_poly(degree = 1) %>% \n",
    "  set_engine(\"kernlab\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle specification and recipe into a worklow\n",
    "svc_linear_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(svc_linear_spec)\n",
    "\n",
    "# Print out workflow\n",
    "svc_linear_wf"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDs8cWNkhoqu"
   },
   "source": [
    "עכשיו, כשאנו כבר הגדרנו את שלבי העיבוד המוקדם ואת מפרט המודל בתוך *workflow*, נוכל להמשיך ולאמן את ה-SVC הליניארי ולהעריך את התוצאות תוך כדי. עבור מדדי ביצועים, בואו ניצור סט מדדים שיעריך: `accuracy`, `sensitivity`, `Positive Predicted Value` ו-`F Measure`.\n",
    "\n",
    "> `augment()` יוסיף עמודה/עמודות עבור תחזיות לנתונים שניתנו.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "81wiqcwuhrnq"
   },
   "source": [
    "# Train a linear SVC model\n",
    "svc_linear_fit <- svc_linear_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "# Create a metric set\n",
    "eval_metrics <- metric_set(ppv, sens, accuracy, f_meas)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "svc_linear_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UFQvHf-huo3"
   },
   "source": [
    "#### מכונת וקטורים תומכת\n",
    "\n",
    "מכונת וקטורים תומכת (SVM) היא הרחבה של מסווג וקטורים תומך במטרה להתאים גבול לא-ליניארי בין הקטגוריות. למעשה, SVMs משתמשות ב*טריק הגרעין* כדי להרחיב את מרחב התכונות ולהתאים את עצמן לקשרים לא-ליניאריים בין הקטגוריות. אחת הפונקציות גרעין הפופולריות והגמישות ביותר שבהן משתמשות SVMs היא *פונקציית בסיס רדיאלי.* בואו נראה איך היא תבצע על הנתונים שלנו.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-KX4S8mzhzmp"
   },
   "source": [
    "set.seed(2056)\n",
    "\n",
    "# Make an RBF SVM specification\n",
    "svm_rbf_spec <- svm_rbf() %>% \n",
    "  set_engine(\"kernlab\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle specification and recipe into a worklow\n",
    "svm_rbf_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(svm_rbf_spec)\n",
    "\n",
    "\n",
    "# Train an RBF model\n",
    "svm_rbf_fit <- svm_rbf_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "svm_rbf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBFSa7WSh4HQ"
   },
   "source": [
    "הרבה יותר טוב 🤩!\n",
    "\n",
    "> ✅ נא עיין:\n",
    ">\n",
    "> -   [*Support Vector Machines*](https://bradleyboehmke.github.io/HOML/svm.html), Hands-on Machine Learning with R\n",
    ">\n",
    "> -   [*Support Vector Machines*](https://www.statlearning.com/), An Introduction to Statistical Learning with Applications in R\n",
    ">\n",
    "> לקריאה נוספת.\n",
    "\n",
    "### מסווגי השכן הקרוב\n",
    "\n",
    "*K*-nearest neighbor (KNN) הוא אלגוריתם שבו כל תצפית נחזית על בסיס *הדמיון* שלה לתצפיות אחרות.\n",
    "\n",
    "בואו נתאים אחד לנתונים שלנו.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k4BxxBcdh9Ka"
   },
   "source": [
    "# Make a KNN specification\n",
    "knn_spec <- nearest_neighbor() %>% \n",
    "  set_engine(\"kknn\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "knn_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(knn_spec)\n",
    "\n",
    "# Train a boosted tree model\n",
    "knn_wf_fit <- knn_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "knn_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaegQseriAcj"
   },
   "source": [
    "נראה שהמודל הזה לא מתפקד בצורה מיטבית. כנראה ששינוי הפרמטרים של המודל (ראו `help(\"nearest_neighbor\")`) ישפר את ביצועי המודל. כדאי לנסות זאת.\n",
    "\n",
    "> ✅ אנא ראו:\n",
    ">\n",
    "> -   [Hands-on Machine Learning with R](https://bradleyboehmke.github.io/HOML/)\n",
    ">\n",
    "> -   [An Introduction to Statistical Learning with Applications in R](https://www.statlearning.com/)\n",
    ">\n",
    "> כדי ללמוד עוד על מסווגי *K*-Nearest Neighbors.\n",
    "\n",
    "### מסווגי אנמבל\n",
    "\n",
    "אלגוריתמי אנמבל פועלים על ידי שילוב של מספר מעריכים בסיסיים ליצירת מודל אופטימלי, באמצעות:\n",
    "\n",
    "`bagging`: יישום *פונקציית ממוצע* על אוסף של מודלים בסיסיים\n",
    "\n",
    "`boosting`: בניית רצף של מודלים שמבוססים אחד על השני כדי לשפר את ביצועי התחזית.\n",
    "\n",
    "בואו נתחיל בלנסות מודל Random Forest, שמבנה אוסף גדול של עצי החלטה ואז מיישם פונקציית ממוצע כדי ליצור מודל כולל טוב יותר.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "49DPoVs6iK1M"
   },
   "source": [
    "# Make a random forest specification\n",
    "rf_spec <- rand_forest() %>% \n",
    "  set_engine(\"ranger\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "rf_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(rf_spec)\n",
    "\n",
    "# Train a random forest model\n",
    "rf_wf_fit <- rf_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "rf_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGVYwC_aiUWc"
   },
   "source": [
    "עבודה טובה 👏!\n",
    "\n",
    "בואו גם ננסה מודל Boosted Tree.\n",
    "\n",
    "Boosted Tree מגדיר שיטה משולבת שיוצרת סדרה של עצי החלטה עוקבים, כאשר כל עץ תלוי בתוצאות של העצים הקודמים במטרה להפחית בהדרגה את השגיאה. השיטה מתמקדת במשקלים של פריטים שסווגו באופן שגוי ומתאימה את ההתאמה עבור הסיווג הבא כדי לתקן.\n",
    "\n",
    "ישנן דרכים שונות להתאים את המודל הזה (ראו `help(\"boost_tree\")`). בדוגמה הזו, נתאים את Boosted trees באמצעות מנוע `xgboost`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Py1YWo-micWs"
   },
   "source": [
    "# Make a boosted tree specification\n",
    "boost_spec <- boost_tree(trees = 200) %>% \n",
    "  set_engine(\"xgboost\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "boost_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(boost_spec)\n",
    "\n",
    "# Train a boosted tree model\n",
    "boost_wf_fit <- boost_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "boost_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNQnbuejigZM"
   },
   "source": [
    "> ✅ נא עיין:\n",
    ">\n",
    "> -   [Machine Learning for Social Scientists](https://cimentadaj.github.io/ml_socsci/tree-based-methods.html#random-forests)\n",
    ">\n",
    "> -   [Hands-on Machine Learning with R](https://bradleyboehmke.github.io/HOML/)\n",
    ">\n",
    "> -   [An Introduction to Statistical Learning with Applications in R](https://www.statlearning.com/)\n",
    ">\n",
    "> -   <https://algotech.netlify.app/blog/xgboost/> - בוחן את מודל AdaBoost, שהוא חלופה טובה ל-xgboost.\n",
    ">\n",
    "> כדי ללמוד עוד על מסווגים מסוג Ensemble.\n",
    "\n",
    "## 4. נוסף - השוואת מספר מודלים\n",
    "\n",
    "התאמנו לא מעט מודלים במעבדה הזו 🙌. זה יכול להיות מתיש או מסורבל ליצור הרבה תהליכי עבודה (workflows) משילובים שונים של מעבדים מקדימים ו/או מפרטי מודלים, ואז לחשב את מדדי הביצועים אחד-אחד.\n",
    "\n",
    "בואו נראה אם נוכל להתמודד עם זה על ידי יצירת פונקציה שמתאימה רשימה של תהליכי עבודה על קבוצת האימון ואז מחזירה את מדדי הביצועים בהתבסס על קבוצת המבחן. נשתמש ב-`map()` וב-`map_dfr()` מהחבילה [purrr](https://purrr.tidyverse.org/) כדי להחיל פונקציות על כל אלמנט ברשימה.\n",
    "\n",
    "> [`map()`](https://purrr.tidyverse.org/reference/map.html) מאפשרת להחליף הרבה לולאות for בקוד שהוא גם תמציתי יותר וגם קל יותר לקריאה. המקום הטוב ביותר ללמוד על [`map()`](https://purrr.tidyverse.org/reference/map.html) הוא [הפרק על איטרציה](http://r4ds.had.co.nz/iteration.html) בספר R for Data Science.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Qzb7LyZnimd2"
   },
   "source": [
    "set.seed(2056)\n",
    "\n",
    "# Create a metric set\n",
    "eval_metrics <- metric_set(ppv, sens, accuracy, f_meas)\n",
    "\n",
    "# Define a function that returns performance metrics\n",
    "compare_models <- function(workflow_list, train_set, test_set){\n",
    "  \n",
    "  suppressWarnings(\n",
    "    # Fit each model to the train_set\n",
    "    map(workflow_list, fit, data = train_set) %>% \n",
    "    # Make predictions on the test set\n",
    "      map_dfr(augment, new_data = test_set, .id = \"model\") %>%\n",
    "    # Select desired columns\n",
    "      select(model, cuisine, .pred_class) %>% \n",
    "    # Evaluate model performance\n",
    "      group_by(model) %>% \n",
    "      eval_metrics(truth = cuisine, estimate = .pred_class) %>% \n",
    "      ungroup()\n",
    "  )\n",
    "  \n",
    "} # End of function"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fwa712sNisDA"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3i4VJOi2iu-a"
   },
   "source": [
    "# Make a list of workflows\n",
    "workflow_list <- list(\n",
    "  \"svc\" = svc_linear_wf,\n",
    "  \"svm\" = svm_rbf_wf,\n",
    "  \"knn\" = knn_wf,\n",
    "  \"random_forest\" = rf_wf,\n",
    "  \"xgboost\" = boost_wf)\n",
    "\n",
    "# Call the function\n",
    "set.seed(2056)\n",
    "perf_metrics <- compare_models(workflow_list = workflow_list, train_set = cuisines_train, test_set = cuisines_test)\n",
    "\n",
    "# Print out performance metrics\n",
    "perf_metrics %>% \n",
    "  group_by(.metric) %>% \n",
    "  arrange(desc(.estimate)) %>% \n",
    "  slice_head(n=7)\n",
    "\n",
    "# Compare accuracy\n",
    "perf_metrics %>% \n",
    "  filter(.metric == \"accuracy\") %>% \n",
    "  arrange(desc(.estimate))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuWK_lEli4nW"
   },
   "source": [
    "חבילת [**workflowset**](https://workflowsets.tidymodels.org/) מאפשרת למשתמשים ליצור ולהתאים בקלות מספר רב של מודלים, אך היא מיועדת בעיקר לעבודה עם טכניקות דגימה חוזרת כמו `cross-validation`, גישה שעדיין לא כיסינו.\n",
    "\n",
    "## **🚀אתגר**\n",
    "\n",
    "לכל אחת מהטכניקות הללו יש מספר רב של פרמטרים שניתן לכוונן, לדוגמה `cost` ב-SVMs, `neighbors` ב-KNN, ו-`mtry` (משתנים נבחרים באקראי) ב-Random Forest.\n",
    "\n",
    "חקרו את הפרמטרים המוגדרים כברירת מחדל עבור כל אחת מהטכניקות וחשבו מה המשמעות של כוונון הפרמטרים הללו עבור איכות המודל.\n",
    "\n",
    "כדי ללמוד עוד על מודל מסוים והפרמטרים שלו, השתמשו ב: `help(\"model\")` לדוגמה `help(\"rand_forest\")`.\n",
    "\n",
    "> בפועל, אנו בדרך כלל *מעריכים* את *הערכים הטובים ביותר* על ידי אימון של מספר רב של מודלים על `מערך נתונים מדומה` ומדידת הביצועים של כל המודלים הללו. תהליך זה נקרא **כוונון**.\n",
    "\n",
    "### [**שאלון לאחר ההרצאה**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/24/)\n",
    "\n",
    "### **סקירה ולמידה עצמית**\n",
    "\n",
    "יש הרבה מונחים מקצועיים בשיעורים הללו, אז קחו רגע לעיין ב-[רשימה הזו](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) של מונחים שימושיים!\n",
    "\n",
    "#### תודה ל:\n",
    "\n",
    "[`אליסון הורסט`](https://twitter.com/allison_horst/) על יצירת האיורים המדהימים שהופכים את R לנגישה ומזמינה יותר. ניתן למצוא עוד איורים בגלריה שלה [כאן](https://www.google.com/url?q=https://github.com/allisonhorst/stats-illustrations&sa=D&source=editors&ust=1626380772530000&usg=AOvVaw3zcfyCizFQZpkSLzxiiQEM).\n",
    "\n",
    "[קסי ברביו](https://www.twitter.com/cassieview) ו-[ג'ן לופר](https://www.twitter.com/jenlooper) על יצירת הגרסה המקורית של המודול הזה ב-Python ♥️\n",
    "\n",
    "למידה מהנה,\n",
    "\n",
    "[אריק](https://twitter.com/ericntay), שגריר סטודנט זהב של Microsoft Learn.\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/r_learners_sm.jpeg\"\n",
    "   width=\"569\"/>\n",
    "   <figcaption>איור מאת @allison_horst</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**כתב ויתור**:  \nמסמך זה תורגם באמצעות שירות תרגום מבוסס בינה מלאכותית [Co-op Translator](https://github.com/Azure/co-op-translator). בעוד שאנו שואפים לדיוק, יש לקחת בחשבון שתרגומים אוטומטיים עשויים להכיל שגיאות או אי-דיוקים. המסמך המקורי בשפתו המקורית נחשב למקור הסמכותי. למידע קריטי, מומלץ להשתמש בתרגום מקצועי על ידי מתרגם אנושי. איננו נושאים באחריות לכל אי-הבנה או פרשנות שגויה הנובעת משימוש בתרגום זה.\n"
   ]
  }
 ]
}