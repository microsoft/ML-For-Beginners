{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## **Musica Nigeriana estratta da Spotify - un'analisi**\n",
    "\n",
    "Il clustering √® un tipo di [Apprendimento Non Supervisionato](https://wikipedia.org/wiki/Apprendimento_non_supervisionato) che presuppone che un dataset non sia etichettato o che i suoi input non siano associati a output predefiniti. Utilizza vari algoritmi per analizzare dati non etichettati e fornire raggruppamenti basati sui pattern individuati nei dati.\n",
    "\n",
    "[**Quiz pre-lezione**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/27/)\n",
    "\n",
    "### **Introduzione**\n",
    "\n",
    "Il [clustering](https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-30164-8_124) √® molto utile per l'esplorazione dei dati. Vediamo se pu√≤ aiutarci a scoprire tendenze e pattern nel modo in cui il pubblico nigeriano consuma musica.\n",
    "\n",
    "> ‚úÖ Prenditi un minuto per riflettere sugli utilizzi del clustering. Nella vita quotidiana, il clustering avviene ogni volta che hai un mucchio di bucato da smistare tra i vestiti dei membri della tua famiglia üß¶üëïüëñü©≤. In data science, il clustering avviene quando si cerca di analizzare le preferenze di un utente o di determinare le caratteristiche di un dataset non etichettato. In un certo senso, il clustering aiuta a dare un senso al caos, come un cassetto di calzini.\n",
    "\n",
    "In un contesto professionale, il clustering pu√≤ essere utilizzato per determinare, ad esempio, la segmentazione del mercato, identificando quali fasce d'et√† acquistano determinati prodotti. Un altro utilizzo potrebbe essere il rilevamento di anomalie, ad esempio per individuare frodi in un dataset di transazioni con carta di credito. Oppure potresti usarlo per identificare tumori in un lotto di scansioni mediche.\n",
    "\n",
    "‚úÖ Rifletti un momento su come potresti aver incontrato il clustering \"nel mondo reale\", in un contesto bancario, di e-commerce o aziendale.\n",
    "\n",
    "> üéì Curiosamente, l'analisi dei cluster ha avuto origine nei campi dell'Antropologia e della Psicologia negli anni '30. Riesci a immaginare come potrebbe essere stata utilizzata?\n",
    "\n",
    "In alternativa, potresti usarla per raggruppare risultati di ricerca - ad esempio per link di shopping, immagini o recensioni. Il clustering √® utile quando hai un grande dataset che vuoi ridurre e su cui vuoi eseguire un'analisi pi√π dettagliata, quindi questa tecnica pu√≤ essere utilizzata per comprendere i dati prima di costruire altri modelli.\n",
    "\n",
    "‚úÖ Una volta che i tuoi dati sono organizzati in cluster, assegni loro un Id di cluster, e questa tecnica pu√≤ essere utile per preservare la privacy di un dataset; puoi fare riferimento a un punto dati tramite il suo Id di cluster, piuttosto che tramite dati identificativi pi√π rivelatori. Riesci a pensare ad altri motivi per cui potresti preferire fare riferimento a un Id di cluster piuttosto che ad altri elementi del cluster per identificarlo?\n",
    "\n",
    "### Iniziare con il clustering\n",
    "\n",
    "> üéì Il modo in cui creiamo i cluster dipende molto da come raggruppiamo i punti dati in gruppi. Esploriamo un po' di vocabolario:\n",
    ">\n",
    "> üéì ['Transduttivo' vs. 'induttivo'](https://wikipedia.org/wiki/Transduction_(machine_learning))\n",
    ">\n",
    "> L'inferenza transduttiva √® derivata da casi di addestramento osservati che si mappano a casi di test specifici. L'inferenza induttiva √® derivata da casi di addestramento che si mappano a regole generali, applicate solo successivamente ai casi di test.\n",
    ">\n",
    "> Un esempio: Immagina di avere un dataset parzialmente etichettato. Alcuni elementi sono 'dischi', altri 'cd', e altri sono vuoti. Il tuo compito √® fornire etichette per i vuoti. Se scegli un approccio induttivo, addestreresti un modello cercando 'dischi' e 'cd', e applicheresti quelle etichette ai dati non etichettati. Questo approccio avrebbe difficolt√† a classificare elementi che in realt√† sono 'cassette'. Un approccio transduttivo, invece, gestisce questi dati sconosciuti in modo pi√π efficace, lavorando per raggruppare elementi simili e poi applicando un'etichetta a un gruppo. In questo caso, i cluster potrebbero riflettere 'oggetti musicali rotondi' e 'oggetti musicali quadrati'.\n",
    ">\n",
    "> üéì ['Geometria non piatta' vs. 'piatta'](https://datascience.stackexchange.com/questions/52260/terminology-flat-geometry-in-the-context-of-clustering)\n",
    ">\n",
    "> Derivata dalla terminologia matematica, la geometria non piatta vs. piatta si riferisce alla misura delle distanze tra punti utilizzando metodi geometrici 'piatti' ([Euclidei](https://wikipedia.org/wiki/Geometria_euclidea)) o 'non piatti' (non Euclidei).\n",
    ">\n",
    "> 'Piatta' in questo contesto si riferisce alla geometria euclidea (insegnata in parte come 'geometria piana'), mentre 'non piatta' si riferisce alla geometria non euclidea. Cosa c'entra la geometria con il machine learning? Bene, essendo due campi radicati nella matematica, deve esserci un modo comune per misurare le distanze tra punti nei cluster, e ci√≤ pu√≤ essere fatto in modo 'piatto' o 'non piatto', a seconda della natura dei dati. Le [distanze euclidee](https://wikipedia.org/wiki/Distanza_euclidea) sono misurate come la lunghezza di un segmento di linea tra due punti. Le [distanze non euclidee](https://wikipedia.org/wiki/Geometria_non_euclidea) sono misurate lungo una curva. Se i tuoi dati, visualizzati, sembrano non esistere su un piano, potresti dover utilizzare un algoritmo specializzato per gestirli.\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/flat-nonflat.png\"\n",
    "   width=\"600\"/>\n",
    "   <figcaption>Infografica di Dasani Madipalli</figcaption>\n",
    "\n",
    "> üéì ['Distanze'](https://web.stanford.edu/class/cs345a/slides/12-clustering.pdf)\n",
    ">\n",
    "> I cluster sono definiti dalla loro matrice di distanze, ad esempio le distanze tra punti. Questa distanza pu√≤ essere misurata in diversi modi. I cluster euclidei sono definiti dalla media dei valori dei punti e contengono un 'centroide' o punto centrale. Le distanze sono quindi misurate rispetto al centroide. Le distanze non euclidee si riferiscono ai 'clustroidi', il punto pi√π vicino agli altri punti. I clustroidi possono essere definiti in vari modi.\n",
    ">\n",
    "> üéì ['Vincolato'](https://wikipedia.org/wiki/Constrained_clustering)\n",
    ">\n",
    "> Il [clustering vincolato](https://web.cs.ucdavis.edu/~davidson/Publications/ICDMTutorial.pdf) introduce l'apprendimento 'semi-supervisionato' in questo metodo non supervisionato. Le relazioni tra punti sono contrassegnate come 'non collegabili' o 'devono essere collegate', quindi alcune regole vengono imposte al dataset.\n",
    ">\n",
    "> Un esempio: Se un algoritmo viene lasciato libero su un lotto di dati non etichettati o semi-etichettati, i cluster che produce potrebbero essere di scarsa qualit√†. Nell'esempio sopra, i cluster potrebbero raggruppare 'oggetti musicali rotondi', 'oggetti musicali quadrati', 'oggetti triangolari' e 'biscotti'. Se vengono forniti alcuni vincoli o regole da seguire (\"l'oggetto deve essere fatto di plastica\", \"l'oggetto deve essere in grado di produrre musica\"), ci√≤ pu√≤ aiutare a 'vincolare' l'algoritmo a fare scelte migliori.\n",
    ">\n",
    "> üéì 'Densit√†'\n",
    ">\n",
    "> I dati che sono 'rumorosi' sono considerati 'densi'. Le distanze tra i punti in ciascuno dei suoi cluster possono risultare, all'esame, pi√π o meno dense, o 'affollate', e quindi questi dati devono essere analizzati con il metodo di clustering appropriato. [Questo articolo](https://www.kdnuggets.com/2020/02/understanding-density-based-clustering.html) dimostra la differenza tra l'utilizzo del clustering K-Means e degli algoritmi HDBSCAN per esplorare un dataset rumoroso con densit√† di cluster irregolare.\n",
    "\n",
    "Approfondisci la tua comprensione delle tecniche di clustering in questo [modulo di apprendimento](https://docs.microsoft.com/learn/modules/train-evaluate-cluster-models?WT.mc_id=academic-77952-leestott)\n",
    "\n",
    "### **Algoritmi di clustering**\n",
    "\n",
    "Esistono oltre 100 algoritmi di clustering, e il loro utilizzo dipende dalla natura dei dati a disposizione. Discutiamo alcuni dei principali:\n",
    "\n",
    "-   **Clustering gerarchico**. Se un oggetto viene classificato in base alla sua prossimit√† a un oggetto vicino, piuttosto che a uno pi√π lontano, i cluster si formano in base alla distanza dei loro membri da e verso altri oggetti. Il clustering gerarchico si caratterizza per la combinazione ripetuta di due cluster.\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/hierarchical.png\"\n",
    "   width=\"600\"/>\n",
    "   <figcaption>Infografica di Dasani Madipalli</figcaption>\n",
    "\n",
    "-   **Clustering basato sul centroide**. Questo algoritmo popolare richiede la scelta di 'k', ovvero il numero di cluster da formare, dopodich√© l'algoritmo determina il punto centrale di un cluster e raccoglie i dati attorno a quel punto. Il [clustering K-means](https://wikipedia.org/wiki/K-means_clustering) √® una versione popolare del clustering basato sul centroide che separa un dataset in K gruppi predefiniti. Il centro √® determinato dalla media pi√π vicina, da cui il nome. La distanza quadrata dal cluster viene minimizzata.\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/centroid.png\"\n",
    "   width=\"600\"/>\n",
    "   <figcaption>Infografica di Dasani Madipalli</figcaption>\n",
    "\n",
    "-   **Clustering basato sulla distribuzione**. Basato sulla modellazione statistica, il clustering basato sulla distribuzione si concentra sulla determinazione della probabilit√† che un punto dati appartenga a un cluster, assegnandolo di conseguenza. I metodi di miscelazione gaussiana appartengono a questo tipo.\n",
    "\n",
    "-   **Clustering basato sulla densit√†**. I punti dati vengono assegnati ai cluster in base alla loro densit√†, o al loro raggruppamento reciproco. I punti dati lontani dal gruppo sono considerati outlier o rumore. DBSCAN, Mean-shift e OPTICS appartengono a questo tipo di clustering.\n",
    "\n",
    "-   **Clustering basato su griglia**. Per dataset multidimensionali, viene creata una griglia e i dati vengono divisi tra le celle della griglia, creando cos√¨ cluster.\n",
    "\n",
    "Il modo migliore per imparare il clustering √® provarlo tu stesso, ed √® proprio quello che farai in questo esercizio.\n",
    "\n",
    "Avremo bisogno di alcuni pacchetti per completare questo modulo. Puoi installarli con: `install.packages(c('tidyverse', 'tidymodels', 'DataExplorer', 'summarytools', 'plotly', 'paletteer', 'corrplot', 'patchwork'))`\n",
    "\n",
    "In alternativa, lo script seguente verifica se hai i pacchetti necessari per completare questo modulo e li installa per te nel caso in cui ne manchi qualcuno.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "suppressWarnings(if(!require(\"pacman\")) install.packages(\"pacman\"))\r\n",
    "\r\n",
    "pacman::p_load('tidyverse', 'tidymodels', 'DataExplorer', 'summarytools', 'plotly', 'paletteer', 'corrplot', 'patchwork')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Esercizio - raggruppa i tuoi dati\n",
    "\n",
    "Il clustering, come tecnica, √® notevolmente facilitato da una corretta visualizzazione, quindi iniziamo visualizzando i nostri dati musicali. Questo esercizio ci aiuter√† a decidere quale metodo di clustering utilizzare in modo pi√π efficace in base alla natura di questi dati.\n",
    "\n",
    "Iniziamo subito importando i dati.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load the core tidyverse and make it available in your current R session\r\n",
    "library(tidyverse)\r\n",
    "\r\n",
    "# Import the data into a tibble\r\n",
    "df <- read_csv(file = \"https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/5-Clustering/data/nigerian-songs.csv\")\r\n",
    "\r\n",
    "# View the first 5 rows of the data set\r\n",
    "df %>% \r\n",
    "  slice_head(n = 5)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A volte potremmo desiderare qualche informazione in pi√π sui nostri dati. Possiamo dare un'occhiata ai `dati` e alla `loro struttura` utilizzando la funzione [*glimpse()*](https://pillar.r-lib.org/reference/glimpse.html):\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Glimpse into the data set\r\n",
    "df %>% \r\n",
    "  glimpse()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ottimo lavoro!üí™\n",
    "\n",
    "Possiamo osservare che `glimpse()` ti fornir√† il numero totale di righe (osservazioni) e colonne (variabili), poi, i primi valori di ciascuna variabile in una riga dopo il nome della variabile. Inoltre, il *tipo di dato* della variabile viene indicato immediatamente dopo il nome della variabile all'interno di `< >`.\n",
    "\n",
    "`DataExplorer::introduce()` pu√≤ riassumere queste informazioni in modo ordinato:\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Describe basic information for our data\r\n",
    "df %>% \r\n",
    "  introduce()\r\n",
    "\r\n",
    "# A visual display of the same\r\n",
    "df %>% \r\n",
    "  plot_intro()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fantastico! Abbiamo appena scoperto che i nostri dati non hanno valori mancanti.\n",
    "\n",
    "Gi√† che ci siamo, possiamo esplorare le statistiche comuni di tendenza centrale (ad esempio [media](https://en.wikipedia.org/wiki/Arithmetic_mean) e [mediana](https://en.wikipedia.org/wiki/Median)) e le misure di dispersione (ad esempio [deviazione standard](https://en.wikipedia.org/wiki/Standard_deviation)) utilizzando `summarytools::descr()`.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Describe common statistics\r\n",
    "df %>% \r\n",
    "  descr(stats = \"common\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Diamo un'occhiata ai valori generali dei dati. Nota che la popolarit√† pu√≤ essere `0`, il che indica canzoni che non hanno una classifica. Le rimuoveremo a breve.\n",
    "\n",
    "> ü§î Se stiamo lavorando con il clustering, un metodo non supervisionato che non richiede dati etichettati, perch√© stiamo mostrando questi dati con etichette? Nella fase di esplorazione dei dati, possono essere utili, ma non sono necessari affinch√© gli algoritmi di clustering funzionino.\n",
    "\n",
    "### 1. Esplora i generi pi√π popolari\n",
    "\n",
    "Andiamo avanti e scopriamo i generi pi√π popolari üé∂ contando quante volte compaiono.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Popular genres\r\n",
    "top_genres <- df %>% \r\n",
    "  count(artist_top_genre, sort = TRUE) %>% \r\n",
    "# Encode to categorical and reorder the according to count\r\n",
    "  mutate(artist_top_genre = factor(artist_top_genre) %>% fct_inorder())\r\n",
    "\r\n",
    "# Print the top genres\r\n",
    "top_genres\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "√à andata bene! Dicono che un'immagine valga pi√π di mille righe di un data frame (in realt√† nessuno lo dice mai üòÖ). Ma hai capito l'idea, giusto?\n",
    "\n",
    "Un modo per visualizzare i dati categorici (variabili di tipo carattere o fattore) √® utilizzare i grafici a barre. Creiamo un grafico a barre dei primi 10 generi:\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Change the default gray theme\r\n",
    "theme_set(theme_light())\r\n",
    "\r\n",
    "# Visualize popular genres\r\n",
    "top_genres %>%\r\n",
    "  slice(1:10) %>% \r\n",
    "  ggplot(mapping = aes(x = artist_top_genre, y = n,\r\n",
    "                       fill = artist_top_genre)) +\r\n",
    "  geom_col(alpha = 0.8) +\r\n",
    "  paletteer::scale_fill_paletteer_d(\"rcartocolor::Vivid\") +\r\n",
    "  ggtitle(\"Top genres\") +\r\n",
    "  theme(plot.title = element_text(hjust = 0.5),\r\n",
    "        # Rotates the X markers (so we can read them)\r\n",
    "    axis.text.x = element_text(angle = 90))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ora √® molto pi√π facile identificare che abbiamo generi `mancanti` üßê!\n",
    "\n",
    "> Una buona visualizzazione ti mostrer√† cose che non ti aspettavi, o sollever√† nuove domande sui dati - Hadley Wickham e Garrett Grolemund, [R For Data Science](https://r4ds.had.co.nz/introduction.html)\n",
    "\n",
    "Nota, quando il genere principale √® descritto come `Mancante`, significa che Spotify non lo ha classificato, quindi eliminiamolo.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Visualize popular genres\r\n",
    "top_genres %>%\r\n",
    "  filter(artist_top_genre != \"Missing\") %>% \r\n",
    "  slice(1:10) %>% \r\n",
    "  ggplot(mapping = aes(x = artist_top_genre, y = n,\r\n",
    "                       fill = artist_top_genre)) +\r\n",
    "  geom_col(alpha = 0.8) +\r\n",
    "  paletteer::scale_fill_paletteer_d(\"rcartocolor::Vivid\") +\r\n",
    "  ggtitle(\"Top genres\") +\r\n",
    "  theme(plot.title = element_text(hjust = 0.5),\r\n",
    "        # Rotates the X markers (so we can read them)\r\n",
    "    axis.text.x = element_text(angle = 90))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Dalla piccola esplorazione dei dati, apprendiamo che i primi tre generi dominano questo dataset. Concentriamoci su `afro dancehall`, `afropop` e `nigerian pop`, filtrando inoltre il dataset per rimuovere tutto ci√≤ che ha un valore di popolarit√† pari a 0 (il che significa che non √® stato classificato con una popolarit√† nel dataset e pu√≤ essere considerato rumore per i nostri scopi):\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nigerian_songs <- df %>% \r\n",
    "  # Concentrate on top 3 genres\r\n",
    "  filter(artist_top_genre %in% c(\"afro dancehall\", \"afropop\",\"nigerian pop\")) %>% \r\n",
    "  # Remove unclassified observations\r\n",
    "  filter(popularity != 0)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# Visualize popular genres\r\n",
    "nigerian_songs %>%\r\n",
    "  count(artist_top_genre) %>%\r\n",
    "  ggplot(mapping = aes(x = artist_top_genre, y = n,\r\n",
    "                       fill = artist_top_genre)) +\r\n",
    "  geom_col(alpha = 0.8) +\r\n",
    "  paletteer::scale_fill_paletteer_d(\"ggsci::category10_d3\") +\r\n",
    "  ggtitle(\"Top genres\") +\r\n",
    "  theme(plot.title = element_text(hjust = 0.5))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vediamo se esiste una relazione lineare evidente tra le variabili numeriche nel nostro set di dati. Questa relazione √® quantificata matematicamente dalla [statistica di correlazione](https://en.wikipedia.org/wiki/Correlation).\n",
    "\n",
    "La statistica di correlazione √® un valore compreso tra -1 e 1 che indica la forza di una relazione. Valori superiori a 0 indicano una correlazione *positiva* (valori alti di una variabile tendono a coincidere con valori alti dell'altra), mentre valori inferiori a 0 indicano una correlazione *negativa* (valori alti di una variabile tendono a coincidere con valori bassi dell'altra).\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Narrow down to numeric variables and fid correlation\r\n",
    "corr_mat <- nigerian_songs %>% \r\n",
    "  select(where(is.numeric)) %>% \r\n",
    "  cor()\r\n",
    "\r\n",
    "# Visualize correlation matrix\r\n",
    "corrplot(corr_mat, order = 'AOE', col = c('white', 'black'), bg = 'gold2')  \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "I dati non sono fortemente correlati, tranne che tra `energy` e `loudness`, il che ha senso, dato che la musica ad alto volume √® solitamente piuttosto energica. `Popularity` ha una corrispondenza con la `release date`, il che √® logico, poich√© le canzoni pi√π recenti sono probabilmente pi√π popolari. Anche la lunghezza e l'energia sembrano avere una correlazione.\n",
    "\n",
    "Sar√† interessante vedere cosa pu√≤ fare un algoritmo di clustering con questi dati!\n",
    "\n",
    "> üéì Nota che la correlazione non implica causalit√†! Abbiamo la prova di una correlazione, ma non di una causalit√†. Un [sito web divertente](https://tylervigen.com/spurious-correlations) offre alcune visualizzazioni che sottolineano questo concetto.\n",
    "\n",
    "### 2. Esplorare la distribuzione dei dati\n",
    "\n",
    "Poniamoci alcune domande pi√π sottili. I generi sono significativamente diversi nella percezione della loro ballabilit√†, in base alla loro popolarit√†? Esaminiamo la distribuzione dei dati dei nostri tre generi principali per popolarit√† e ballabilit√† lungo un dato asse x e y utilizzando i [grafici di densit√†](https://www.khanacademy.org/math/ap-statistics/density-curves-normal-distribution-ap/density-curves/v/density-curves).\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Perform 2D kernel density estimation\r\n",
    "density_estimate_2d <- nigerian_songs %>% \r\n",
    "  ggplot(mapping = aes(x = popularity, y = danceability, color = artist_top_genre)) +\r\n",
    "  geom_density_2d(bins = 5, size = 1) +\r\n",
    "  paletteer::scale_color_paletteer_d(\"RSkittleBrewer::wildberry\") +\r\n",
    "  xlim(-20, 80) +\r\n",
    "  ylim(0, 1.2)\r\n",
    "\r\n",
    "# Density plot based on the popularity\r\n",
    "density_estimate_pop <- nigerian_songs %>% \r\n",
    "  ggplot(mapping = aes(x = popularity, fill = artist_top_genre, color = artist_top_genre)) +\r\n",
    "  geom_density(size = 1, alpha = 0.5) +\r\n",
    "  paletteer::scale_fill_paletteer_d(\"RSkittleBrewer::wildberry\") +\r\n",
    "  paletteer::scale_color_paletteer_d(\"RSkittleBrewer::wildberry\") +\r\n",
    "  theme(legend.position = \"none\")\r\n",
    "\r\n",
    "# Density plot based on the danceability\r\n",
    "density_estimate_dance <- nigerian_songs %>% \r\n",
    "  ggplot(mapping = aes(x = danceability, fill = artist_top_genre, color = artist_top_genre)) +\r\n",
    "  geom_density(size = 1, alpha = 0.5) +\r\n",
    "  paletteer::scale_fill_paletteer_d(\"RSkittleBrewer::wildberry\") +\r\n",
    "  paletteer::scale_color_paletteer_d(\"RSkittleBrewer::wildberry\")\r\n",
    "\r\n",
    "\r\n",
    "# Patch everything together\r\n",
    "library(patchwork)\r\n",
    "density_estimate_2d / (density_estimate_pop + density_estimate_dance)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vediamo che ci sono cerchi concentrici che si allineano, indipendentemente dal genere. Potrebbe essere che i gusti nigeriani convergano a un certo livello di ballabilit√† per questo genere?\n",
    "\n",
    "In generale, i tre generi si allineano in termini di popolarit√† e ballabilit√†. Determinare dei cluster in questi dati debolmente allineati sar√† una sfida. Vediamo se un grafico a dispersione pu√≤ supportare questa analisi.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# A scatter plot of popularity and danceability\r\n",
    "scatter_plot <- nigerian_songs %>% \r\n",
    "  ggplot(mapping = aes(x = popularity, y = danceability, color = artist_top_genre, shape = artist_top_genre)) +\r\n",
    "  geom_point(size = 2, alpha = 0.8) +\r\n",
    "  paletteer::scale_color_paletteer_d(\"futurevisions::mars\")\r\n",
    "\r\n",
    "# Add a touch of interactivity\r\n",
    "ggplotly(scatter_plot)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Un grafico a dispersione degli stessi assi mostra un modello simile di convergenza.\n",
    "\n",
    "In generale, per il clustering, puoi utilizzare i grafici a dispersione per mostrare i cluster di dati, quindi padroneggiare questo tipo di visualizzazione √® molto utile. Nella prossima lezione, prenderemo questi dati filtrati e utilizzeremo il clustering k-means per scoprire gruppi in questi dati che sembrano sovrapporsi in modi interessanti.\n",
    "\n",
    "##  **üöÄ Sfida**\n",
    "\n",
    "In preparazione per la prossima lezione, crea un grafico sui vari algoritmi di clustering che potresti scoprire e utilizzare in un ambiente di produzione. Quali tipi di problemi il clustering cerca di affrontare?\n",
    "\n",
    "## [**Quiz post-lezione**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/28/)\n",
    "\n",
    "## **Revisione e Studio Autonomo**\n",
    "\n",
    "Prima di applicare gli algoritmi di clustering, come abbiamo appreso, √® una buona idea comprendere la natura del tuo dataset. Leggi di pi√π su questo argomento [qui](https://www.kdnuggets.com/2019/10/right-clustering-algorithm.html)\n",
    "\n",
    "Approfondisci la tua comprensione delle tecniche di clustering:\n",
    "\n",
    "-   [Addestra e valuta modelli di clustering usando Tidymodels e amici](https://rpubs.com/eR_ic/clustering)\n",
    "\n",
    "-   Bradley Boehmke & Brandon Greenwell, [*Hands-On Machine Learning with R*](https://bradleyboehmke.github.io/HOML/)*.*\n",
    "\n",
    "## **Compito**\n",
    "\n",
    "[Esplora altre visualizzazioni per il clustering](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/1-Visualize/assignment.md)\n",
    "\n",
    "## GRAZIE A:\n",
    "\n",
    "[Jen Looper](https://www.twitter.com/jenlooper) per aver creato la versione originale in Python di questo modulo ‚ô•Ô∏è\n",
    "\n",
    "[`Dasani Madipalli`](https://twitter.com/dasani_decoded) per aver creato le straordinarie illustrazioni che rendono i concetti di machine learning pi√π comprensibili e facili da capire.\n",
    "\n",
    "Buono studio,\n",
    "\n",
    "[Eric](https://twitter.com/ericntay), Gold Microsoft Learn Student Ambassador.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Disclaimer**:  \nQuesto documento √® stato tradotto utilizzando il servizio di traduzione automatica [Co-op Translator](https://github.com/Azure/co-op-translator). Sebbene ci impegniamo per garantire l'accuratezza, si prega di notare che le traduzioni automatiche possono contenere errori o imprecisioni. Il documento originale nella sua lingua nativa dovrebbe essere considerato la fonte autorevole. Per informazioni critiche, si raccomanda una traduzione professionale effettuata da un traduttore umano. Non siamo responsabili per eventuali incomprensioni o interpretazioni errate derivanti dall'uso di questa traduzione.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": "",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  },
  "coopTranslator": {
   "original_hash": "99c36449cad3708a435f6798cfa39972",
   "translation_date": "2025-08-29T23:32:20+00:00",
   "source_file": "5-Clustering/1-Visualize/solution/R/lesson_14-R.ipynb",
   "language_code": "it"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}