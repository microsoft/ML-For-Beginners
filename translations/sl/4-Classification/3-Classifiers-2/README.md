<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "49047911108adc49d605cddfb455749c",
  "translation_date": "2025-09-05T13:14:38+00:00",
  "source_file": "4-Classification/3-Classifiers-2/README.md",
  "language_code": "sl"
}
-->
# RazvrÅ¡Äevalniki kuhinj 2

V tej drugi lekciji o razvrÅ¡Äanju boste raziskali veÄ naÄinov za razvrÅ¡Äanje numeriÄnih podatkov. Prav tako boste spoznali posledice izbire enega razvrÅ¡Äevalnika namesto drugega.

## [Predhodni kviz](https://ff-quizzes.netlify.app/en/ml/)

### Predpogoji

Predvidevamo, da ste zakljuÄili prejÅ¡nje lekcije in imate oÄiÅ¡Äen nabor podatkov v svoji mapi `data`, imenovan _cleaned_cuisines.csv_, ki se nahaja v korenski mapi tega 4-lekcijskega sklopa.

### Priprava

VaÅ¡a datoteka _notebook.ipynb_ je bila naloÅ¾ena z oÄiÅ¡Äenim naborom podatkov, ki je razdeljen na podatkovna okvira X in y, pripravljena za proces gradnje modela.

## Zemljevid razvrÅ¡Äanja

Prej ste se nauÄili o razliÄnih moÅ¾nostih razvrÅ¡Äanja podatkov z uporabo Microsoftovega priroÄnika. Scikit-learn ponuja podoben, vendar bolj podroben priroÄnik, ki vam lahko dodatno pomaga zoÅ¾iti izbiro ocenjevalnikov (drugi izraz za razvrÅ¡Äevalnike):

![ML Zemljevid iz Scikit-learn](../../../../4-Classification/3-Classifiers-2/images/map.png)
> Nasvet: [obiskujte ta zemljevid na spletu](https://scikit-learn.org/stable/tutorial/machine_learning_map/) in kliknite po poti za branje dokumentacije.

### NaÄrt

Ta zemljevid je zelo koristen, ko imate jasno predstavo o svojih podatkih, saj lahko 'hodite' po njegovih poteh do odloÄitve:

- Imamo >50 vzorcev
- Å½elimo napovedati kategorijo
- Imamo oznaÄene podatke
- Imamo manj kot 100K vzorcev
- âœ¨ Lahko izberemo Linear SVC
- ÄŒe to ne deluje, ker imamo numeriÄne podatke
    - Lahko poskusimo âœ¨ KNeighbors Classifier 
      - ÄŒe to ne deluje, poskusimo âœ¨ SVC in âœ¨ Ensemble Classifiers

To je zelo koristna pot za sledenje.

## Naloga - razdelite podatke

Sledimo tej poti in zaÄnemo z uvozom nekaterih knjiÅ¾nic za uporabo.

1. Uvozite potrebne knjiÅ¾nice:

    ```python
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    import numpy as np
    ```

1. Razdelite svoje podatke na trening in test:

    ```python
    X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)
    ```

## Linearni SVC razvrÅ¡Äevalnik

Support-Vector clustering (SVC) je del druÅ¾ine tehnik strojnega uÄenja Support-Vector Machines (veÄ o tem spodaj). Pri tej metodi lahko izberete 'jedro' za odloÄanje, kako razvrstiti oznake. Parameter 'C' se nanaÅ¡a na 'regularizacijo', ki uravnava vpliv parametrov. Jedro je lahko eno izmed [veÄ moÅ¾nosti](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC); tukaj ga nastavimo na 'linearno', da zagotovimo uporabo linearnega SVC. Privzeta vrednost za verjetnost je 'false'; tukaj jo nastavimo na 'true', da pridobimo ocene verjetnosti. NakljuÄno stanje nastavimo na '0', da premeÅ¡amo podatke za pridobitev verjetnosti.

### Naloga - uporabite linearni SVC

ZaÄnite z ustvarjanjem matrike razvrÅ¡Äevalnikov. Postopoma boste dodajali tej matriki, ko bomo testirali.

1. ZaÄnite z Linearnim SVC:

    ```python
    C = 10
    # Create different classifiers.
    classifiers = {
        'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0)
    }
    ```

2. Natrenirajte svoj model z Linearnim SVC in natisnite poroÄilo:

    ```python
    n_classifiers = len(classifiers)
    
    for index, (name, classifier) in enumerate(classifiers.items()):
        classifier.fit(X_train, np.ravel(y_train))
    
        y_pred = classifier.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print("Accuracy (train) for %s: %0.1f%% " % (name, accuracy * 100))
        print(classification_report(y_test,y_pred))
    ```

    Rezultat je precej dober:

    ```output
    Accuracy (train) for Linear SVC: 78.6% 
                  precision    recall  f1-score   support
    
         chinese       0.71      0.67      0.69       242
          indian       0.88      0.86      0.87       234
        japanese       0.79      0.74      0.76       254
          korean       0.85      0.81      0.83       242
            thai       0.71      0.86      0.78       227
    
        accuracy                           0.79      1199
       macro avg       0.79      0.79      0.79      1199
    weighted avg       0.79      0.79      0.79      1199
    ```

## K-Neighbors razvrÅ¡Äevalnik

K-Neighbors je del druÅ¾ine metod strojnega uÄenja "neighbors", ki se lahko uporablja za nadzorovano in nenadzorovano uÄenje. Pri tej metodi se ustvari vnaprej doloÄeno Å¡tevilo toÄk, okoli katerih se zbirajo podatki, da se lahko za podatke napovejo posploÅ¡ene oznake.

### Naloga - uporabite K-Neighbors razvrÅ¡Äevalnik

PrejÅ¡nji razvrÅ¡Äevalnik je bil dober in je dobro deloval s podatki, vendar morda lahko doseÅ¾emo boljÅ¡o natanÄnost. Poskusite K-Neighbors razvrÅ¡Äevalnik.

1. Dodajte vrstico v svojo matriko razvrÅ¡Äevalnikov (dodajte vejico za element Linear SVC):

    ```python
    'KNN classifier': KNeighborsClassifier(C),
    ```

    Rezultat je nekoliko slabÅ¡i:

    ```output
    Accuracy (train) for KNN classifier: 73.8% 
                  precision    recall  f1-score   support
    
         chinese       0.64      0.67      0.66       242
          indian       0.86      0.78      0.82       234
        japanese       0.66      0.83      0.74       254
          korean       0.94      0.58      0.72       242
            thai       0.71      0.82      0.76       227
    
        accuracy                           0.74      1199
       macro avg       0.76      0.74      0.74      1199
    weighted avg       0.76      0.74      0.74      1199
    ```

    âœ… Preberite veÄ o [K-Neighbors](https://scikit-learn.org/stable/modules/neighbors.html#neighbors)

## Support Vector razvrÅ¡Äevalnik

Support-Vector razvrÅ¡Äevalniki so del druÅ¾ine metod strojnega uÄenja [Support-Vector Machine](https://wikipedia.org/wiki/Support-vector_machine), ki se uporabljajo za naloge razvrÅ¡Äanja in regresije. SVM "preslika primere treninga v toÄke v prostoru", da maksimizira razdaljo med dvema kategorijama. Naknadni podatki so preslikani v ta prostor, da se lahko napove njihova kategorija.

### Naloga - uporabite Support Vector razvrÅ¡Äevalnik

Poskusimo doseÄi nekoliko boljÅ¡o natanÄnost s Support Vector razvrÅ¡Äevalnikom.

1. Dodajte vejico za element K-Neighbors in nato dodajte to vrstico:

    ```python
    'SVC': SVC(),
    ```

    Rezultat je zelo dober!

    ```output
    Accuracy (train) for SVC: 83.2% 
                  precision    recall  f1-score   support
    
         chinese       0.79      0.74      0.76       242
          indian       0.88      0.90      0.89       234
        japanese       0.87      0.81      0.84       254
          korean       0.91      0.82      0.86       242
            thai       0.74      0.90      0.81       227
    
        accuracy                           0.83      1199
       macro avg       0.84      0.83      0.83      1199
    weighted avg       0.84      0.83      0.83      1199
    ```

    âœ… Preberite veÄ o [Support-Vectors](https://scikit-learn.org/stable/modules/svm.html#svm)

## Ensemble razvrÅ¡Äevalniki

Sledimo poti do samega konca, Äeprav je bil prejÅ¡nji test zelo dober. Poskusimo nekaj 'Ensemble razvrÅ¡Äevalnikov', natanÄneje Random Forest in AdaBoost:

```python
  'RFST': RandomForestClassifier(n_estimators=100),
  'ADA': AdaBoostClassifier(n_estimators=100)
```

Rezultat je zelo dober, Å¡e posebej za Random Forest:

```output
Accuracy (train) for RFST: 84.5% 
              precision    recall  f1-score   support

     chinese       0.80      0.77      0.78       242
      indian       0.89      0.92      0.90       234
    japanese       0.86      0.84      0.85       254
      korean       0.88      0.83      0.85       242
        thai       0.80      0.87      0.83       227

    accuracy                           0.84      1199
   macro avg       0.85      0.85      0.84      1199
weighted avg       0.85      0.84      0.84      1199

Accuracy (train) for ADA: 72.4% 
              precision    recall  f1-score   support

     chinese       0.64      0.49      0.56       242
      indian       0.91      0.83      0.87       234
    japanese       0.68      0.69      0.69       254
      korean       0.73      0.79      0.76       242
        thai       0.67      0.83      0.74       227

    accuracy                           0.72      1199
   macro avg       0.73      0.73      0.72      1199
weighted avg       0.73      0.72      0.72      1199
```

âœ… Preberite veÄ o [Ensemble razvrÅ¡Äevalnikih](https://scikit-learn.org/stable/modules/ensemble.html)

Ta metoda strojnega uÄenja "zdruÅ¾uje napovedi veÄ osnovnih ocenjevalnikov", da izboljÅ¡a kakovost modela. V naÅ¡em primeru smo uporabili Random Trees in AdaBoost. 

- [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest), metoda povpreÄenja, gradi 'gozd' 'odloÄilnih dreves', ki so preÅ¾eta z nakljuÄnostjo, da se izogne prekomernemu prileganju. Parameter n_estimators je nastavljen na Å¡tevilo dreves.

- [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) prilagodi razvrÅ¡Äevalnik naboru podatkov in nato prilagodi kopije tega razvrÅ¡Äevalnika istemu naboru podatkov. OsredotoÄa se na uteÅ¾i nepravilno razvrÅ¡Äenih elementov in prilagodi prileganje za naslednji razvrÅ¡Äevalnik, da jih popravi.

---

## ğŸš€Izziv

Vsaka od teh tehnik ima veliko Å¡tevilo parametrov, ki jih lahko prilagodite. Raziskujte privzete parametre vsake metode in razmislite, kaj bi pomenilo prilagajanje teh parametrov za kakovost modela.

## [ZakljuÄni kviz](https://ff-quizzes.netlify.app/en/ml/)

## Pregled in samostojno uÄenje

V teh lekcijah je veliko Å¾argona, zato si vzemite trenutek za pregled [tega seznama](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) uporabne terminologije!

## Naloga 

[Parameter play](assignment.md)

---

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve za prevajanje z umetno inteligenco [Co-op Translator](https://github.com/Azure/co-op-translator). ÄŒeprav si prizadevamo za natanÄnost, vas prosimo, da upoÅ¡tevate, da lahko avtomatizirani prevodi vsebujejo napake ali netoÄnosti. Izvirni dokument v njegovem izvirnem jeziku je treba obravnavati kot avtoritativni vir. Za kljuÄne informacije priporoÄamo profesionalni prevod s strani Äloveka. Ne prevzemamo odgovornosti za morebitna napaÄna razumevanja ali napaÄne interpretacije, ki bi nastale zaradi uporabe tega prevoda.