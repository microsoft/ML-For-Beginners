{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "lesson_12-R.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "ir",
   "display_name": "R"
  },
  "language_info": {
   "name": "R"
  },
  "coopTranslator": {
   "original_hash": "fab50046ca413a38939d579f8432274f",
   "translation_date": "2025-09-06T14:45:06+00:00",
   "source_file": "4-Classification/3-Classifiers-2/solution/R/lesson_12-R.ipynb",
   "language_code": "sl"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsFutf_ygqSx"
   },
   "source": [
    "# Zgradite klasifikacijski model: Slastne azijske in indijske kuhinje\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HD54bEefgtNO"
   },
   "source": [
    "## RazvrÅ¡Äevalniki kuhinj 2\n",
    "\n",
    "V tej drugi lekciji o razvrÅ¡Äanju bomo raziskali `veÄ naÄinov` za razvrÅ¡Äanje kategorijskih podatkov. Prav tako se bomo nauÄili o posledicah izbire enega razvrÅ¡Äevalnika namesto drugega.\n",
    "\n",
    "### [**Predhodni kviz**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/23/)\n",
    "\n",
    "### **Predpogoji**\n",
    "\n",
    "Predvidevamo, da ste zakljuÄili prejÅ¡nje lekcije, saj bomo nadaljevali z nekaterimi koncepti, ki smo jih Å¾e obravnavali.\n",
    "\n",
    "Za to lekcijo bomo potrebovali naslednje pakete:\n",
    "\n",
    "-   `tidyverse`: [tidyverse](https://www.tidyverse.org/) je [zbirka paketov za R](https://www.tidyverse.org/packages), zasnovana za hitrejÅ¡e, enostavnejÅ¡e in bolj zabavno podatkovno znanost!\n",
    "\n",
    "-   `tidymodels`: [tidymodels](https://www.tidymodels.org/) je okvir [zbirke paketov](https://www.tidymodels.org/packages/) za modeliranje in strojno uÄenje.\n",
    "\n",
    "-   `themis`: [paket themis](https://themis.tidymodels.org/) ponuja dodatne korake receptov za obravnavo neuravnoteÅ¾enih podatkov.\n",
    "\n",
    "Pakete lahko namestite z naslednjim ukazom:\n",
    "\n",
    "`install.packages(c(\"tidyverse\", \"tidymodels\", \"kernlab\", \"themis\", \"ranger\", \"xgboost\", \"kknn\"))`\n",
    "\n",
    "Alternativno, spodnji skript preveri, ali imate nameÅ¡Äene potrebne pakete za dokonÄanje tega modula, in jih namesti, Äe manjkajo.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vZ57IuUxgyQt"
   },
   "source": [
    "suppressWarnings(if (!require(\"pacman\"))install.packages(\"pacman\"))\n",
    "\n",
    "pacman::p_load(tidyverse, tidymodels, themis, kernlab, ranger, xgboost, kknn)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z22M-pj4g07x"
   },
   "source": [
    "## **1. Zemljevid klasifikacije**\n",
    "\n",
    "V naÅ¡i [prejÅ¡nji lekciji](https://github.com/microsoft/ML-For-Beginners/tree/main/4-Classification/2-Classifiers-1) smo poskuÅ¡ali odgovoriti na vpraÅ¡anje: kako izbrati med veÄ modeli? V veliki meri je to odvisno od znaÄilnosti podatkov in vrste problema, ki ga Å¾elimo reÅ¡iti (na primer klasifikacija ali regresija?).\n",
    "\n",
    "Prej smo se nauÄili o razliÄnih moÅ¾nostih, ki jih imate pri klasifikaciji podatkov, z uporabo Microsoftovega pripomoÄka. Pythonov okvir za strojno uÄenje, Scikit-learn, ponuja podoben, vendar bolj podroben pripomoÄek, ki vam lahko dodatno pomaga zoÅ¾iti izbiro vaÅ¡ih ocenjevalnikov (drugi izraz za klasifikatorje):\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/map.png\"\n",
    "   width=\"700\"/>\n",
    "   <figcaption></figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1i3xRIVg7vG"
   },
   "source": [
    "> Nasvet: [obiÅ¡Äite ta zemljevid na spletu](https://scikit-learn.org/stable/tutorial/machine_learning_map/) in kliknite po poti, da preberete dokumentacijo.\n",
    ">\n",
    "> [ReferenÄna stran Tidymodels](https://www.tidymodels.org/find/parsnip/#models) prav tako ponuja odliÄno dokumentacijo o razliÄnih vrstah modelov.\n",
    "\n",
    "### **NaÄrt** ğŸ—ºï¸\n",
    "\n",
    "Ta zemljevid je zelo koristen, ko imate jasno predstavo o svojih podatkih, saj lahko 'hodite' po njegovih poteh do odloÄitve:\n",
    "\n",
    "-   Imamo \\>50 vzorcev\n",
    "\n",
    "-   Å½elimo napovedati kategorijo\n",
    "\n",
    "-   Imamo oznaÄene podatke\n",
    "\n",
    "-   Imamo manj kot 100K vzorcev\n",
    "\n",
    "-   âœ¨ Lahko izberemo Linear SVC\n",
    "\n",
    "-   ÄŒe to ne deluje, ker imamo numeriÄne podatke\n",
    "\n",
    "    -   Lahko poskusimo âœ¨ KNeighbors Classifier\n",
    "\n",
    "        -   ÄŒe to ne deluje, poskusite âœ¨ SVC in âœ¨ Ensemble Classifiers\n",
    "\n",
    "To je zelo koristna pot, ki ji lahko sledite. Zdaj pa se lotimo dela z uporabo [tidymodels](https://www.tidymodels.org/) okvira za modeliranje: dosledne in prilagodljive zbirke paketov za R, razvitih za spodbujanje dobre statistiÄne prakse ğŸ˜Š.\n",
    "\n",
    "## 2. Razdelite podatke in obravnavajte neuravnoteÅ¾en nabor podatkov.\n",
    "\n",
    "Iz naÅ¡ih prejÅ¡njih lekcij smo se nauÄili, da obstaja niz skupnih sestavin med naÅ¡imi kuhinjami. Prav tako je bila precej neenakomerna porazdelitev Å¡tevila kuhinj.\n",
    "\n",
    "To bomo obravnavali tako, da:\n",
    "\n",
    "-   Odstranimo najpogostejÅ¡e sestavine, ki povzroÄajo zmedo med razliÄnimi kuhinjami, z uporabo `dplyr::select()`.\n",
    "\n",
    "-   Uporabimo `recipe`, ki predhodno obdela podatke, da jih pripravi za modeliranje z uporabo algoritma za `over-sampling`.\n",
    "\n",
    "To smo Å¾e obravnavali v prejÅ¡nji lekciji, zato bo to enostavno ğŸ¥³!\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6tj_rN00hClA"
   },
   "source": [
    "# Load the core Tidyverse and Tidymodels packages\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "\n",
    "# Load the original cuisines data\n",
    "df <- read_csv(file = \"https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/data/cuisines.csv\")\n",
    "\n",
    "# Drop id column, rice, garlic and ginger from our original data set\n",
    "df_select <- df %>% \n",
    "  select(-c(1, rice, garlic, ginger)) %>%\n",
    "  # Encode cuisine column as categorical\n",
    "  mutate(cuisine = factor(cuisine))\n",
    "\n",
    "\n",
    "# Create data split specification\n",
    "set.seed(2056)\n",
    "cuisines_split <- initial_split(data = df_select,\n",
    "                                strata = cuisine,\n",
    "                                prop = 0.7)\n",
    "\n",
    "# Extract the data in each split\n",
    "cuisines_train <- training(cuisines_split)\n",
    "cuisines_test <- testing(cuisines_split)\n",
    "\n",
    "# Display distribution of cuisines in the training set\n",
    "cuisines_train %>% \n",
    "  count(cuisine) %>% \n",
    "  arrange(desc(n))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFin5yw3hHb1"
   },
   "source": [
    "### Obdelava neuravnoteÅ¾enih podatkov\n",
    "\n",
    "NeuravnoteÅ¾eni podatki pogosto negativno vplivajo na delovanje modela. Veliko modelov deluje najbolje, ko je Å¡tevilo opazovanj enako, zato imajo teÅ¾ave z neuravnoteÅ¾enimi podatki.\n",
    "\n",
    "Obstajata predvsem dva naÄina za obravnavo neuravnoteÅ¾enih podatkovnih nizov:\n",
    "\n",
    "-   dodajanje opazovanj v manjÅ¡insko skupino: `PrevzorÄenje` (ang. Over-sampling), npr. z uporabo algoritma SMOTE, ki sintetiÄno ustvari nove primere manjÅ¡inske skupine z uporabo najbliÅ¾jih sosedov teh primerov.\n",
    "\n",
    "-   odstranjevanje opazovanj iz veÄinske skupine: `PodvzorÄenje` (ang. Under-sampling)\n",
    "\n",
    "V prejÅ¡nji lekciji smo prikazali, kako obravnavati neuravnoteÅ¾ene podatkovne nize z uporabo `recepta`. Recept si lahko predstavljamo kot naÄrt, ki opisuje, kateri koraki naj se uporabijo na podatkovnem nizu, da bo pripravljen za analizo podatkov. V naÅ¡em primeru Å¾elimo doseÄi enakomerno porazdelitev Å¡tevila naÅ¡ih kulinarik v `uÄnem naboru`. Pa zaÄnimo!\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cRzTnHolhLWd"
   },
   "source": [
    "# Load themis package for dealing with imbalanced data\n",
    "library(themis)\n",
    "\n",
    "# Create a recipe for preprocessing training data\n",
    "cuisines_recipe <- recipe(cuisine ~ ., data = cuisines_train) %>%\n",
    "  step_smote(cuisine) \n",
    "\n",
    "# Print recipe\n",
    "cuisines_recipe"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxOQ2ORhhO81"
   },
   "source": [
    "Zdaj smo pripravljeni na treniranje modelov ğŸ‘©â€ğŸ’»ğŸ‘¨â€ğŸ’»!\n",
    "\n",
    "## 3. Onkraj multinomnih regresijskih modelov\n",
    "\n",
    "V prejÅ¡nji lekciji smo obravnavali multinomne regresijske modele. Raziskali bomo nekaj bolj prilagodljivih modelov za klasifikacijo.\n",
    "\n",
    "### Podporni vektorski stroji\n",
    "\n",
    "V kontekstu klasifikacije so `Podporni vektorski stroji` tehnika strojnega uÄenja, ki poskuÅ¡a najti *hiperploskev*, ki \"najbolje\" loÄuje razrede. Poglejmo preprost primer:\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/svm.png\"\n",
    "   width=\"300\"/>\n",
    "   <figcaption>https://commons.wikimedia.org/w/index.php?curid=22877598</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4Wsd0vZhXYu"
   },
   "source": [
    "H1~ ne loÄuje razredov. H2~ jih loÄuje, vendar le z majhno razdaljo. H3~ jih loÄuje z najveÄjo razdaljo.\n",
    "\n",
    "#### Linearni klasifikator podpornih vektorjev\n",
    "\n",
    "Podporni vektorski razvrÅ¡Äanje (SVC) je del druÅ¾ine tehnik strojnega uÄenja, imenovanih podporni vektorski stroji. Pri SVC je hiperploskev izbrana tako, da pravilno loÄi `veÄino` opazovanj v uÄnem naboru, vendar `lahko napaÄno razvrsti` nekaj opazovanj. Z dovoljenjem, da so nekateri podatkovni toÄki na napaÄni strani, postane SVM bolj odporen na odstopanja, kar omogoÄa boljÅ¡o posploÅ¡itev na nove podatke. Parameter, ki uravnava to krÅ¡itev, se imenuje `cost` in ima privzeto vrednost 1 (glej `help(\"svm_poly\")`).\n",
    "\n",
    "Ustvarimo linearni SVC tako, da nastavimo `degree = 1` v polinomskem modelu SVM.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vJpp6nuChlBz"
   },
   "source": [
    "# Make a linear SVC specification\n",
    "svc_linear_spec <- svm_poly(degree = 1) %>% \n",
    "  set_engine(\"kernlab\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle specification and recipe into a worklow\n",
    "svc_linear_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(svc_linear_spec)\n",
    "\n",
    "# Print out workflow\n",
    "svc_linear_wf"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDs8cWNkhoqu"
   },
   "source": [
    "Zdaj, ko smo zajeli korake predobdelave in specifikacijo modela v *workflow*, lahko nadaljujemo s treniranjem linearnega SVC in hkrati ocenimo rezultate. Za merjenje uÄinkovitosti ustvarimo nabor metrik, ki bo ocenjeval: `natanÄnost`, `obÄutljivost`, `pozitivno napovedno vrednost` in `F-mero`.\n",
    "\n",
    "> `augment()` bo dodal stolpec(-ce) za napovedi k danim podatkom.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "81wiqcwuhrnq"
   },
   "source": [
    "# Train a linear SVC model\n",
    "svc_linear_fit <- svc_linear_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "# Create a metric set\n",
    "eval_metrics <- metric_set(ppv, sens, accuracy, f_meas)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "svc_linear_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UFQvHf-huo3"
   },
   "source": [
    "#### Podporni vektorski stroj\n",
    "\n",
    "Podporni vektorski stroj (SVM) je razÅ¡iritev podpornega vektorskega klasifikatorja, ki omogoÄa uporabo nelinearne meje med razredi. V bistvu SVM-ji uporabljajo *trik s kernelom*, da razÅ¡irijo prostor znaÄilnosti in se prilagodijo nelinearnim odnosom med razredi. Ena izmed priljubljenih in izjemno prilagodljivih funkcij jedra, ki jih uporabljajo SVM-ji, je *funkcija radialne baze.* Poglejmo, kako se bo obnesla na naÅ¡ih podatkih.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-KX4S8mzhzmp"
   },
   "source": [
    "set.seed(2056)\n",
    "\n",
    "# Make an RBF SVM specification\n",
    "svm_rbf_spec <- svm_rbf() %>% \n",
    "  set_engine(\"kernlab\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle specification and recipe into a worklow\n",
    "svm_rbf_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(svm_rbf_spec)\n",
    "\n",
    "\n",
    "# Train an RBF model\n",
    "svm_rbf_fit <- svm_rbf_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "svm_rbf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBFSa7WSh4HQ"
   },
   "source": [
    "Veliko bolje ğŸ¤©!\n",
    "\n",
    "> âœ… Prosimo, poglejte:\n",
    ">\n",
    "> -   [*Support Vector Machines*](https://bradleyboehmke.github.io/HOML/svm.html), Hands-on Machine Learning with R\n",
    ">\n",
    "> -   [*Support Vector Machines*](https://www.statlearning.com/), An Introduction to Statistical Learning with Applications in R\n",
    ">\n",
    "> za dodatno branje.\n",
    "\n",
    "### RazvrÅ¡Äevalniki najbliÅ¾jih sosedov\n",
    "\n",
    "Algoritem *K*-najbliÅ¾jih sosedov (KNN) je metoda, pri kateri se vsaka opazovana vrednost napove na podlagi njene *podobnosti* z drugimi opazovanji.\n",
    "\n",
    "Poglejmo, kako ga lahko uporabimo na naÅ¡ih podatkih.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k4BxxBcdh9Ka"
   },
   "source": [
    "# Make a KNN specification\n",
    "knn_spec <- nearest_neighbor() %>% \n",
    "  set_engine(\"kknn\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "knn_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(knn_spec)\n",
    "\n",
    "# Train a boosted tree model\n",
    "knn_wf_fit <- knn_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "knn_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaegQseriAcj"
   },
   "source": [
    "Zdi se, da ta model ne deluje najbolje. Verjetno bo izboljÅ¡anje delovanja modela mogoÄe z spremembo argumentov modela (glejte `help(\"nearest_neighbor\")`). Vsekakor poskusite to moÅ¾nost.\n",
    "\n",
    "> âœ… Prosimo, poglejte:\n",
    ">\n",
    "> -   [Hands-on Machine Learning with R](https://bradleyboehmke.github.io/HOML/)\n",
    ">\n",
    "> -   [An Introduction to Statistical Learning with Applications in R](https://www.statlearning.com/)\n",
    ">\n",
    "> za veÄ informacij o klasifikatorjih *K*-NajbliÅ¾jih Sosedov.\n",
    "\n",
    "### Ensemble klasifikatorji\n",
    "\n",
    "Ensemble algoritmi delujejo tako, da kombinirajo veÄ osnovnih ocenjevalnikov za izdelavo optimalnega modela bodisi z:\n",
    "\n",
    "`bagging`: uporabo *povpreÄne funkcije* na zbirki osnovnih modelov\n",
    "\n",
    "`boosting`: gradnjo zaporedja modelov, ki se medsebojno nadgrajujejo za izboljÅ¡anje napovedne zmogljivosti.\n",
    "\n",
    "ZaÄnimo z uporabo modela Random Forest, ki gradi veliko zbirko odloÄitvenih dreves in nato uporabi povpreÄno funkcijo za boljÅ¡i celotni model.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "49DPoVs6iK1M"
   },
   "source": [
    "# Make a random forest specification\n",
    "rf_spec <- rand_forest() %>% \n",
    "  set_engine(\"ranger\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "rf_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(rf_spec)\n",
    "\n",
    "# Train a random forest model\n",
    "rf_wf_fit <- rf_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "rf_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGVYwC_aiUWc"
   },
   "source": [
    "OdliÄno delo ğŸ‘!\n",
    "\n",
    "Poskusimo tudi z modelom Boosted Tree.\n",
    "\n",
    "Boosted Tree opredeljuje metodo ansambla, ki ustvari serijo zaporednih odloÄitvenih dreves, kjer vsako drevo temelji na rezultatih prejÅ¡njih dreves, da postopoma zmanjÅ¡a napako. OsredotoÄa se na uteÅ¾i napaÄno razvrÅ¡Äenih elementov in prilagodi prileganje za naslednji klasifikator, da jih popravi.\n",
    "\n",
    "Obstajajo razliÄni naÄini za prileganje tega modela (glejte `help(\"boost_tree\")`). V tem primeru bomo prilegali Boosted drevesa prek pogona `xgboost`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Py1YWo-micWs"
   },
   "source": [
    "# Make a boosted tree specification\n",
    "boost_spec <- boost_tree(trees = 200) %>% \n",
    "  set_engine(\"xgboost\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "boost_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(boost_spec)\n",
    "\n",
    "# Train a boosted tree model\n",
    "boost_wf_fit <- boost_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "boost_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNQnbuejigZM"
   },
   "source": [
    "âœ… Prosimo, da si ogledate:\n",
    "\n",
    "-   [Strojno uÄenje za druÅ¾boslovce](https://cimentadaj.github.io/ml_socsci/tree-based-methods.html#random-forests)\n",
    "-   [PraktiÄno strojno uÄenje z R](https://bradleyboehmke.github.io/HOML/)\n",
    "-   [Uvod v statistiÄno uÄenje z aplikacijami v R](https://www.statlearning.com/)\n",
    "-   <https://algotech.netlify.app/blog/xgboost/> - Raziskuje model AdaBoost, ki je dobra alternativa xgboost.\n",
    "\n",
    "za veÄ informacij o Ensemble klasifikatorjih.\n",
    "\n",
    "## 4. Dodatno - primerjava veÄ modelov\n",
    "\n",
    "V tem laboratoriju smo prilagodili kar nekaj modelov ğŸ™Œ. Ustvarjanje Å¡tevilnih delovnih tokov iz razliÄnih naborov predprocesorjev in/ali specifikacij modelov ter nato izraÄunavanje metrik zmogljivosti enega za drugim lahko postane zamudno ali naporno.\n",
    "\n",
    "Poglejmo, ali lahko to reÅ¡imo z ustvarjanjem funkcije, ki prilagodi seznam delovnih tokov na uÄnem naboru podatkov in nato vrne metrike zmogljivosti na podlagi testnega nabora. Uporabili bomo `map()` in `map_dfr()` iz paketa [purrr](https://purrr.tidyverse.org/), da funkcije uporabimo na vsakem elementu seznama.\n",
    "\n",
    "> Funkcije [`map()`](https://purrr.tidyverse.org/reference/map.html) vam omogoÄajo, da nadomestite Å¡tevilne for zanke s kodo, ki je bolj jedrnata in laÅ¾ja za branje. NajboljÅ¡e mesto za uÄenje o funkcijah [`map()`](https://purrr.tidyverse.org/reference/map.html) je [poglavje o iteraciji](http://r4ds.had.co.nz/iteration.html) v R za podatkovno znanost.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Qzb7LyZnimd2"
   },
   "source": [
    "set.seed(2056)\n",
    "\n",
    "# Create a metric set\n",
    "eval_metrics <- metric_set(ppv, sens, accuracy, f_meas)\n",
    "\n",
    "# Define a function that returns performance metrics\n",
    "compare_models <- function(workflow_list, train_set, test_set){\n",
    "  \n",
    "  suppressWarnings(\n",
    "    # Fit each model to the train_set\n",
    "    map(workflow_list, fit, data = train_set) %>% \n",
    "    # Make predictions on the test set\n",
    "      map_dfr(augment, new_data = test_set, .id = \"model\") %>%\n",
    "    # Select desired columns\n",
    "      select(model, cuisine, .pred_class) %>% \n",
    "    # Evaluate model performance\n",
    "      group_by(model) %>% \n",
    "      eval_metrics(truth = cuisine, estimate = .pred_class) %>% \n",
    "      ungroup()\n",
    "  )\n",
    "  \n",
    "} # End of function"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fwa712sNisDA"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3i4VJOi2iu-a"
   },
   "source": [
    "# Make a list of workflows\n",
    "workflow_list <- list(\n",
    "  \"svc\" = svc_linear_wf,\n",
    "  \"svm\" = svm_rbf_wf,\n",
    "  \"knn\" = knn_wf,\n",
    "  \"random_forest\" = rf_wf,\n",
    "  \"xgboost\" = boost_wf)\n",
    "\n",
    "# Call the function\n",
    "set.seed(2056)\n",
    "perf_metrics <- compare_models(workflow_list = workflow_list, train_set = cuisines_train, test_set = cuisines_test)\n",
    "\n",
    "# Print out performance metrics\n",
    "perf_metrics %>% \n",
    "  group_by(.metric) %>% \n",
    "  arrange(desc(.estimate)) %>% \n",
    "  slice_head(n=7)\n",
    "\n",
    "# Compare accuracy\n",
    "perf_metrics %>% \n",
    "  filter(.metric == \"accuracy\") %>% \n",
    "  arrange(desc(.estimate))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuWK_lEli4nW"
   },
   "source": [
    "[**workflowset**](https://workflowsets.tidymodels.org/) paket omogoÄa uporabnikom, da ustvarijo in enostavno prilegajo veliko Å¡tevilo modelov, vendar je veÄinoma zasnovan za delo s tehnikami ponovnega vzorÄenja, kot je `kriÅ¾no preverjanje`, pristop, ki ga bomo Å¡e obravnavali.\n",
    "\n",
    "## **ğŸš€Izziv**\n",
    "\n",
    "Vsaka od teh tehnik ima veliko Å¡tevilo parametrov, ki jih lahko prilagodite, na primer `cost` pri SVM, `neighbors` pri KNN, `mtry` (nakljuÄno izbrani prediktorji) pri Random Forest.\n",
    "\n",
    "Raziskujte privzete parametre za vsako od teh tehnik in razmislite, kaj bi prilagajanje teh parametrov pomenilo za kakovost modela.\n",
    "\n",
    "ÄŒe Å¾elite izvedeti veÄ o doloÄenem modelu in njegovih parametrih, uporabite: `help(\"model\")`, npr. `help(\"rand_forest\")`.\n",
    "\n",
    "> V praksi obiÄajno *ocenimo* *najboljÅ¡e vrednosti* teh parametrov tako, da treniramo veliko modelov na `simuliranem naboru podatkov` in merimo, kako dobro se vsi ti modeli obnesejo. Ta proces imenujemo **uglaÅ¡evanje**.\n",
    "\n",
    "### [**Kvizi po predavanju**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/24/)\n",
    "\n",
    "### **Pregled in samostojno uÄenje**\n",
    "\n",
    "V teh lekcijah je veliko strokovnih izrazov, zato si vzemite trenutek za pregled [tega seznama](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) uporabne terminologije!\n",
    "\n",
    "#### HVALA:\n",
    "\n",
    "[`Allison Horst`](https://twitter.com/allison_horst/) za ustvarjanje neverjetnih ilustracij, ki naredijo R bolj prijazen in privlaÄen. VeÄ ilustracij najdete v njeni [galeriji](https://www.google.com/url?q=https://github.com/allisonhorst/stats-illustrations&sa=D&source=editors&ust=1626380772530000&usg=AOvVaw3zcfyCizFQZpkSLzxiiQEM).\n",
    "\n",
    "[Cassie Breviu](https://www.twitter.com/cassieview) in [Jen Looper](https://www.twitter.com/jenlooper) za ustvarjanje izvirne razliÄice tega modula v Pythonu â™¥ï¸\n",
    "\n",
    "Veselo uÄenje,\n",
    "\n",
    "[Eric](https://twitter.com/ericntay), zlati Microsoft Learn Å¡tudentski ambasador.\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/r_learners_sm.jpeg\"\n",
    "   width=\"569\"/>\n",
    "   <figcaption>Ilustracija @allison_horst</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Omejitev odgovornosti**:  \nTa dokument je bil preveden z uporabo storitve za strojno prevajanje [Co-op Translator](https://github.com/Azure/co-op-translator). ÄŒeprav si prizadevamo za natanÄnost, vas prosimo, da upoÅ¡tevate, da lahko avtomatizirani prevodi vsebujejo napake ali netoÄnosti. Izvirni dokument v njegovem izvirnem jeziku je treba obravnavati kot avtoritativni vir. Za kljuÄne informacije priporoÄamo strokovno ÄloveÅ¡ko prevajanje. Ne prevzemamo odgovornosti za morebitna nesporazumevanja ali napaÄne razlage, ki izhajajo iz uporabe tega prevoda.\n"
   ]
  }
 ]
}