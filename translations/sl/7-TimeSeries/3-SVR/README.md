<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "482bccabe1df958496ea71a3667995cd",
  "translation_date": "2025-09-05T12:05:29+00:00",
  "source_file": "7-TimeSeries/3-SVR/README.md",
  "language_code": "sl"
}
-->
# Napovedovanje 캜asovnih vrst z regresorjem podpornih vektorjev

V prej코nji lekciji ste se nau캜ili uporabljati model ARIMA za napovedovanje 캜asovnih vrst. Zdaj si bomo ogledali model Support Vector Regressor, ki je regresijski model za napovedovanje neprekinjenih podatkov.

## [Pre-lecture quiz](https://ff-quizzes.netlify.app/en/ml/) 

## Uvod

V tej lekciji boste spoznali specifi캜en na캜in gradnje modelov z [**SVM**: **S**upport **V**ector **M**achine](https://en.wikipedia.org/wiki/Support-vector_machine) za regresijo, ali **SVR: Support Vector Regressor**. 

### SVR v kontekstu 캜asovnih vrst [^1]

Preden razumemo pomen SVR pri napovedovanju 캜asovnih vrst, je pomembno poznati naslednje koncepte:

- **Regresija:** Tehnika nadzorovanega u캜enja za napovedovanje neprekinjenih vrednosti na podlagi danih vhodnih podatkov. Ideja je prilagoditi krivuljo (ali premico) v prostoru zna캜ilnosti, ki zajame najve캜je 코tevilo podatkovnih to캜k. [Kliknite tukaj](https://en.wikipedia.org/wiki/Regression_analysis) za ve캜 informacij.
- **Support Vector Machine (SVM):** Vrsta modela nadzorovanega strojnega u캜enja, ki se uporablja za klasifikacijo, regresijo in zaznavanje odstopanj. Model je hiperploskev v prostoru zna캜ilnosti, ki v primeru klasifikacije deluje kot meja, v primeru regresije pa kot najbolj코a prilagoditvena premica. Pri SVM se pogosto uporablja funkcija jedra (Kernel function), ki transformira podatkovni niz v prostor z ve캜 dimenzijami, da postane la쬵e lo캜ljiv. [Kliknite tukaj](https://en.wikipedia.org/wiki/Support-vector_machine) za ve캜 informacij o SVM.
- **Support Vector Regressor (SVR):** Vrsta SVM, ki najde najbolj코o prilagoditveno premico (ki je v primeru SVM hiperploskev), ki zajame najve캜je 코tevilo podatkovnih to캜k.

### Zakaj SVR? [^1]

V prej코nji lekciji ste spoznali ARIMA, ki je zelo uspe코na statisti캜na linearna metoda za napovedovanje 캜asovnih vrst. Vendar pa so podatki 캜asovnih vrst pogosto *nelinearni*, kar linearni modeli ne morejo zajeti. V takih primerih sposobnost SVM, da upo코teva nelinearnost podatkov pri regresijskih nalogah, naredi SVR uspe코nega pri napovedovanju 캜asovnih vrst.

## Naloga - izdelava modela SVR

Prvi koraki za pripravo podatkov so enaki kot v prej코nji lekciji o [ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA). 

Odprite mapo [_/working_](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/3-SVR/working) v tej lekciji in poi코캜ite datoteko [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/7-TimeSeries/3-SVR/working/notebook.ipynb). [^2]

1. Za쬰nite bele쬶o in uvozite potrebne knji쬹ice: [^2]

   ```python
   import sys
   sys.path.append('../../')
   ```

   ```python
   import os
   import warnings
   import matplotlib.pyplot as plt
   import numpy as np
   import pandas as pd
   import datetime as dt
   import math
   
   from sklearn.svm import SVR
   from sklearn.preprocessing import MinMaxScaler
   from common.utils import load_data, mape
   ```

2. Nalo쬴te podatke iz datoteke `/data/energy.csv` v Pandas dataframe in si jih oglejte: [^2]

   ```python
   energy = load_data('../../data')[['load']]
   ```

3. Prika쬴te vse razpolo쬷jive podatke o energiji od januarja 2012 do decembra 2014: [^2]

   ```python
   energy.plot(y='load', subplots=True, figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![celotni podatki](../../../../7-TimeSeries/3-SVR/images/full-data.png)

   Zdaj pa izdelajmo na코 model SVR.

### Ustvarjanje u캜nih in testnih podatkovnih nizov

Ko so podatki nalo쬰ni, jih lahko lo캜ite na u캜ni in testni niz. Nato jih boste preoblikovali v podatkovni niz, ki temelji na 캜asovnih korakih, kar bo potrebno za SVR. Model boste trenirali na u캜nem nizu. Ko bo model kon캜al s treniranjem, boste ocenili njegovo natan캜nost na u캜nem nizu, testnem nizu in nato na celotnem podatkovnem nizu, da preverite splo코no zmogljivost. Poskrbeti morate, da testni niz zajema poznej코e obdobje v 캜asu od u캜nega niza, da zagotovite, da model ne pridobi informacij iz prihodnjih 캜asovnih obdobij [^2] (situacija, znana kot *Overfitting*).

1. Dodelite dvomese캜no obdobje od 1. septembra do 31. oktobra 2014 u캜nemu nizu. Testni niz bo vklju캜eval dvomese캜no obdobje od 1. novembra do 31. decembra 2014: [^2]

   ```python
   train_start_dt = '2014-11-01 00:00:00'
   test_start_dt = '2014-12-30 00:00:00'
   ```

2. Vizualizirajte razlike: [^2]

   ```python
   energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)][['load']].rename(columns={'load':'train'}) \
       .join(energy[test_start_dt:][['load']].rename(columns={'load':'test'}), how='outer') \
       .plot(y=['train', 'test'], figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![u캜ni in testni podatki](../../../../7-TimeSeries/3-SVR/images/train-test.png)

### Priprava podatkov za treniranje

Zdaj morate pripraviti podatke za treniranje z izvajanjem filtriranja in skaliranja podatkov. Filtrirajte svoj podatkovni niz, da vklju캜ite samo potrebna 캜asovna obdobja in stolpce, ter skalirajte podatke, da jih projicirate v interval 0,1.

1. Filtrirajte izvirni podatkovni niz, da vklju캜ite samo omenjena 캜asovna obdobja na nizih in samo potrebni stolpec 'load' ter datum: [^2]

   ```python
   train = energy.copy()[(energy.index >= train_start_dt) & (energy.index < test_start_dt)][['load']]
   test = energy.copy()[energy.index >= test_start_dt][['load']]
   
   print('Training data shape: ', train.shape)
   print('Test data shape: ', test.shape)
   ```

   ```output
   Training data shape:  (1416, 1)
   Test data shape:  (48, 1)
   ```
   
2. Skalirajte u캜ne podatke, da bodo v razponu (0, 1): [^2]

   ```python
   scaler = MinMaxScaler()
   train['load'] = scaler.fit_transform(train)
   ```
   
4. Zdaj skalirajte testne podatke: [^2]

   ```python
   test['load'] = scaler.transform(test)
   ```

### Ustvarjanje podatkov s 캜asovnimi koraki [^1]

Za SVR preoblikujete vhodne podatke v obliko `[batch, timesteps]`. Tako obstoje캜e `train_data` in `test_data` preoblikujete tako, da dodate novo dimenzijo, ki se nana코a na 캜asovne korake.

```python
# Converting to numpy arrays
train_data = train.values
test_data = test.values
```

Za ta primer vzamemo `timesteps = 5`. Tako so vhodni podatki za model podatki za prve 4 캜asovne korake, izhod pa bodo podatki za 5. 캜asovni korak.

```python
timesteps=5
```

Pretvorba u캜nih podatkov v 2D tensor z uporabo ugnezdene listne komprehencije:

```python
train_data_timesteps=np.array([[j for j in train_data[i:i+timesteps]] for i in range(0,len(train_data)-timesteps+1)])[:,:,0]
train_data_timesteps.shape
```

```output
(1412, 5)
```

Pretvorba testnih podatkov v 2D tensor:

```python
test_data_timesteps=np.array([[j for j in test_data[i:i+timesteps]] for i in range(0,len(test_data)-timesteps+1)])[:,:,0]
test_data_timesteps.shape
```

```output
(44, 5)
```

Izbor vhodov in izhodov iz u캜nih in testnih podatkov:

```python
x_train, y_train = train_data_timesteps[:,:timesteps-1],train_data_timesteps[:,[timesteps-1]]
x_test, y_test = test_data_timesteps[:,:timesteps-1],test_data_timesteps[:,[timesteps-1]]

print(x_train.shape, y_train.shape)
print(x_test.shape, y_test.shape)
```

```output
(1412, 4) (1412, 1)
(44, 4) (44, 1)
```

### Implementacija SVR [^1]

Zdaj je 캜as za implementacijo SVR. Za ve캜 informacij o tej implementaciji si lahko ogledate [to dokumentacijo](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html). Za na코o implementacijo sledimo tem korakom:

  1. Definirajte model z uporabo `SVR()` in podajte hiperparametre modela: kernel, gamma, c in epsilon
  2. Pripravite model za u캜ne podatke z uporabo funkcije `fit()`
  3. Izvedite napovedi z uporabo funkcije `predict()`

Zdaj ustvarimo model SVR. Tukaj uporabimo [RBF kernel](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel) in nastavimo hiperparametre gamma, C in epsilon na 0.5, 10 in 0.05.

```python
model = SVR(kernel='rbf',gamma=0.5, C=10, epsilon = 0.05)
```

#### Prilagoditev modela na u캜ne podatke [^1]

```python
model.fit(x_train, y_train[:,0])
```

```output
SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.05, gamma=0.5,
    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)
```

#### Izvedba napovedi modela [^1]

```python
y_train_pred = model.predict(x_train).reshape(-1,1)
y_test_pred = model.predict(x_test).reshape(-1,1)

print(y_train_pred.shape, y_test_pred.shape)
```

```output
(1412, 1) (44, 1)
```

Izdelali ste svoj SVR! Zdaj ga moramo oceniti.

### Ocenjevanje modela [^1]

Za ocenjevanje najprej skaliramo podatke nazaj na na코o izvirno lestvico. Nato za preverjanje zmogljivosti prika쬰mo izvirni in napovedani 캜asovni niz ter natisnemo rezultat MAPE.

Skaliranje napovedanih in izvirnih izhodov:

```python
# Scaling the predictions
y_train_pred = scaler.inverse_transform(y_train_pred)
y_test_pred = scaler.inverse_transform(y_test_pred)

print(len(y_train_pred), len(y_test_pred))
```

```python
# Scaling the original values
y_train = scaler.inverse_transform(y_train)
y_test = scaler.inverse_transform(y_test)

print(len(y_train), len(y_test))
```

#### Preverjanje zmogljivosti modela na u캜nih in testnih podatkih [^1]

Iz podatkovnega niza izvle캜emo 캜asovne oznake za prikaz na x-osi na코ega grafa. Upo코tevajte, da uporabljamo prvih ```timesteps-1``` vrednosti kot vhod za prvi izhod, zato se 캜asovne oznake za izhod za캜nejo po tem.

```python
train_timestamps = energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)].index[timesteps-1:]
test_timestamps = energy[test_start_dt:].index[timesteps-1:]

print(len(train_timestamps), len(test_timestamps))
```

```output
1412 44
```

Prikaz napovedi za u캜ne podatke:

```python
plt.figure(figsize=(25,6))
plt.plot(train_timestamps, y_train, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(train_timestamps, y_train_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.title("Training data prediction")
plt.show()
```

![napoved u캜nih podatkov](../../../../7-TimeSeries/3-SVR/images/train-data-predict.png)

Natisnite MAPE za u캜ne podatke

```python
print('MAPE for training data: ', mape(y_train_pred, y_train)*100, '%')
```

```output
MAPE for training data: 1.7195710200875551 %
```

Prikaz napovedi za testne podatke

```python
plt.figure(figsize=(10,3))
plt.plot(test_timestamps, y_test, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(test_timestamps, y_test_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![napoved testnih podatkov](../../../../7-TimeSeries/3-SVR/images/test-data-predict.png)

Natisnite MAPE za testne podatke

```python
print('MAPE for testing data: ', mape(y_test_pred, y_test)*100, '%')
```

```output
MAPE for testing data:  1.2623790187854018 %
```

游끥 Na testnem podatkovnem nizu imate zelo dober rezultat!

### Preverjanje zmogljivosti modela na celotnem podatkovnem nizu [^1]

```python
# Extracting load values as numpy array
data = energy.copy().values

# Scaling
data = scaler.transform(data)

# Transforming to 2D tensor as per model input requirement
data_timesteps=np.array([[j for j in data[i:i+timesteps]] for i in range(0,len(data)-timesteps+1)])[:,:,0]
print("Tensor shape: ", data_timesteps.shape)

# Selecting inputs and outputs from data
X, Y = data_timesteps[:,:timesteps-1],data_timesteps[:,[timesteps-1]]
print("X shape: ", X.shape,"\nY shape: ", Y.shape)
```

```output
Tensor shape:  (26300, 5)
X shape:  (26300, 4) 
Y shape:  (26300, 1)
```

```python
# Make model predictions
Y_pred = model.predict(X).reshape(-1,1)

# Inverse scale and reshape
Y_pred = scaler.inverse_transform(Y_pred)
Y = scaler.inverse_transform(Y)
```

```python
plt.figure(figsize=(30,8))
plt.plot(Y, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(Y_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![napoved celotnih podatkov](../../../../7-TimeSeries/3-SVR/images/full-data-predict.png)

```python
print('MAPE: ', mape(Y_pred, Y)*100, '%')
```

```output
MAPE:  2.0572089029888656 %
```

游끥 Zelo lepi grafi, ki prikazujejo model z dobro natan캜nostjo. Odli캜no opravljeno!

---

## 游Izziv

- Poskusite prilagoditi hiperparametre (gamma, C, epsilon) med ustvarjanjem modela in ocenite podatke, da vidite, kateri nabor hiperparametrov daje najbolj코e rezultate na testnih podatkih. Za ve캜 informacij o teh hiperparametrih si lahko ogledate dokument [tukaj](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel). 
- Poskusite uporabiti razli캜ne funkcije jedra za model in analizirajte njihovo zmogljivost na podatkovnem nizu. Koristen dokument najdete [tukaj](https://scikit-learn.org/stable/modules/svm.html#kernel-functions).
- Poskusite uporabiti razli캜ne vrednosti za `timesteps`, da model pogleda nazaj za napovedovanje.

## [Post-lecture quiz](https://ff-quizzes.netlify.app/en/ml/)

## Pregled in samostojno u캜enje

Ta lekcija je bila namenjena predstavitvi uporabe SVR za napovedovanje 캜asovnih vrst. Za ve캜 informacij o SVR si lahko ogledate [ta blog](https://www.analyticsvidhya.com/blog/2020/03/support-vector-regression-tutorial-for-machine-learning/). Ta [dokumentacija o scikit-learn](https://scikit-learn.org/stable/modules/svm.html) ponuja bolj celovito razlago o SVM na splo코no, [SVR](https://scikit-learn.org/stable/modules/svm.html#regression) in tudi druge podrobnosti implementacije, kot so razli캜ne [funkcije jedra](https://scikit-learn.org/stable/modules/svm.html#kernel-functions), ki jih je mogo캜e uporabiti, ter njihovi parametri.

## Naloga

[Novi model SVR](assignment.md)

## Zasluge

[^1]: Besedilo, koda in izhod v tem razdelku je prispeval [@AnirbanMukherjeeXD](https://github.com/AnirbanMukherjeeXD)
[^2]: Besedilo, koda in izhod v tem razdelku je vzeto iz [ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA)

---

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve za strojno prevajanje [Co-op Translator](https://github.com/Azure/co-op-translator). 캛eprav si prizadevamo za natan캜nost, vas prosimo, da se zavedate, da lahko avtomatizirani prevodi vsebujejo napake ali neto캜nosti. Izvirni dokument v njegovem izvirnem jeziku je treba obravnavati kot avtoritativni vir. Za klju캜ne informacije priporo캜amo strokovno 캜love코ko prevajanje. Ne prevzemamo odgovornosti za morebitna nesporazumevanja ali napa캜ne razlage, ki izhajajo iz uporabe tega prevoda.