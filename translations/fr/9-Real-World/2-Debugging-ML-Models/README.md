<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "ba0f6e1019351351c8ee4c92867b6a0b",
  "translation_date": "2025-09-03T23:20:00+00:00",
  "source_file": "9-Real-World/2-Debugging-ML-Models/README.md",
  "language_code": "fr"
}
-->
# Postscript : D√©bogage de mod√®les en apprentissage automatique avec les composants du tableau de bord IA responsable

## [Quiz avant la le√ßon](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/5/)

## Introduction

L'apprentissage automatique influence notre vie quotidienne. L'IA s'int√®gre dans certains des syst√®mes les plus importants qui nous touchent en tant qu'individus et en tant que soci√©t√©, que ce soit dans les domaines de la sant√©, des finances, de l'√©ducation ou de l'emploi. Par exemple, des syst√®mes et mod√®les sont impliqu√©s dans des t√¢ches de prise de d√©cision quotidienne, comme les diagnostics m√©dicaux ou la d√©tection de fraudes. En cons√©quence, les avanc√©es de l'IA, combin√©es √† son adoption acc√©l√©r√©e, sont confront√©es √† des attentes soci√©tales en √©volution et √† une r√©glementation croissante. Nous observons constamment des domaines o√π les syst√®mes d'IA ne r√©pondent pas aux attentes, exposent de nouveaux d√©fis, et o√π les gouvernements commencent √† r√©glementer les solutions d'IA. Il est donc essentiel d'analyser ces mod√®les pour garantir des r√©sultats √©quitables, fiables, inclusifs, transparents et responsables pour tous.

Dans ce programme, nous examinerons des outils pratiques permettant d'√©valuer si un mod√®le pr√©sente des probl√®mes li√©s √† l'IA responsable. Les techniques traditionnelles de d√©bogage en apprentissage automatique reposent souvent sur des calculs quantitatifs tels que la pr√©cision agr√©g√©e ou la perte moyenne d'erreur. Imaginez ce qui peut se produire lorsque les donn√©es utilis√©es pour construire ces mod√®les manquent de certaines caract√©ristiques d√©mographiques, comme la race, le genre, les opinions politiques, la religion, ou repr√©sentent ces caract√©ristiques de mani√®re disproportionn√©e. Que se passe-t-il lorsque les r√©sultats du mod√®le favorisent certains groupes d√©mographiques ? Cela peut entra√Æner une surrepr√©sentation ou une sous-repr√©sentation de ces groupes sensibles, ce qui pose des probl√®mes d'√©quit√©, d'inclusivit√© ou de fiabilit√©. Un autre facteur est que les mod√®les d'apprentissage automatique sont souvent consid√©r√©s comme des bo√Ætes noires, ce qui rend difficile la compr√©hension et l'explication des raisons derri√®re leurs pr√©dictions. Tous ces d√©fis sont rencontr√©s par les data scientists et les d√©veloppeurs d'IA lorsqu'ils ne disposent pas d'outils ad√©quats pour d√©boguer et √©valuer l'√©quit√© ou la fiabilit√© d'un mod√®le.

Dans cette le√ßon, vous apprendrez √† d√©boguer vos mod√®les en utilisant :

- **Analyse des erreurs** : identifier les zones de votre distribution de donn√©es o√π le mod√®le pr√©sente des taux d'erreur √©lev√©s.
- **Vue d'ensemble du mod√®le** : effectuer une analyse comparative entre diff√©rents groupes de donn√©es pour d√©couvrir des disparit√©s dans les m√©triques de performance de votre mod√®le.
- **Analyse des donn√©es** : examiner les zones o√π il pourrait y avoir une surrepr√©sentation ou une sous-repr√©sentation des donn√©es, ce qui pourrait biaiser votre mod√®le en faveur d'un groupe d√©mographique par rapport √† un autre.
- **Importance des caract√©ristiques** : comprendre quelles caract√©ristiques influencent les pr√©dictions de votre mod√®le √† un niveau global ou local.

## Pr√©requis

En guise de pr√©requis, veuillez consulter [les outils d'IA responsable pour les d√©veloppeurs](https://www.microsoft.com/ai/ai-lab-responsible-ai-dashboard)

> ![Gif sur les outils d'IA responsable](../../../../9-Real-World/2-Debugging-ML-Models/images/rai-overview.gif)

## Analyse des erreurs

Les m√©triques traditionnelles de performance des mod√®les utilis√©es pour mesurer la pr√©cision reposent principalement sur des calculs bas√©s sur les pr√©dictions correctes ou incorrectes. Par exemple, d√©terminer qu'un mod√®le est pr√©cis √† 89 % avec une perte d'erreur de 0,001 peut √™tre consid√©r√© comme une bonne performance. Cependant, les erreurs ne sont souvent pas r√©parties uniform√©ment dans votre ensemble de donn√©es sous-jacent. Vous pourriez obtenir un score de pr√©cision de 89 %, mais d√©couvrir que dans certaines r√©gions de vos donn√©es, le mod√®le √©choue 42 % du temps. Les cons√©quences de ces sch√©mas d'√©chec pour certains groupes de donn√©es peuvent entra√Æner des probl√®mes d'√©quit√© ou de fiabilit√©. Il est essentiel de comprendre les zones o√π le mod√®le fonctionne bien ou non. Les r√©gions de donn√©es o√π votre mod√®le pr√©sente un grand nombre d'inexactitudes peuvent s'av√©rer √™tre des groupes d√©mographiques importants.

![Analyser et d√©boguer les erreurs du mod√®le](../../../../translated_images/ea-error-distribution.117452e1177c1dd84fab2369967a68bcde787c76c6ea7fdb92fcf15d1fce8206.fr.png)

Le composant d'analyse des erreurs du tableau de bord RAI illustre comment les √©checs du mod√®le sont r√©partis entre diff√©rents groupes avec une visualisation en arbre. Cela est utile pour identifier les caract√©ristiques ou les zones o√π le taux d'erreur est √©lev√© dans votre ensemble de donn√©es. En voyant d'o√π proviennent la plupart des inexactitudes du mod√®le, vous pouvez commencer √† enqu√™ter sur la cause profonde. Vous pouvez √©galement cr√©er des groupes de donn√©es pour effectuer une analyse. Ces groupes de donn√©es aident dans le processus de d√©bogage √† d√©terminer pourquoi la performance du mod√®le est bonne dans un groupe, mais erron√©e dans un autre.

![Analyse des erreurs](../../../../translated_images/ea-error-cohort.6886209ea5d438c4daa8bfbf5ce3a7042586364dd3eccda4a4e3d05623ac702a.fr.png)

Les indicateurs visuels sur la carte en arbre permettent de localiser plus rapidement les zones probl√©matiques. Par exemple, plus la couleur rouge d'un n≈ìud d'arbre est fonc√©e, plus le taux d'erreur est √©lev√©.

La carte thermique est une autre fonctionnalit√© de visualisation que les utilisateurs peuvent utiliser pour enqu√™ter sur le taux d'erreur en utilisant une ou deux caract√©ristiques afin de trouver un contributeur aux erreurs du mod√®le dans l'ensemble des donn√©es ou les groupes.

![Carte thermique d'analyse des erreurs](../../../../translated_images/ea-heatmap.8d27185e28cee3830c85e1b2e9df9d2d5e5c8c940f41678efdb68753f2f7e56c.fr.png)

Utilisez l'analyse des erreurs lorsque vous devez :

* Comprendre en profondeur comment les √©checs du mod√®le sont r√©partis dans un ensemble de donn√©es et entre plusieurs dimensions d'entr√©e et de caract√©ristiques.
* D√©composer les m√©triques de performance agr√©g√©es pour d√©couvrir automatiquement des groupes erron√©s afin d'informer vos √©tapes de mitigation cibl√©es.

## Vue d'ensemble du mod√®le

√âvaluer la performance d'un mod√®le d'apprentissage automatique n√©cessite une compr√©hension globale de son comportement. Cela peut √™tre r√©alis√© en examinant plusieurs m√©triques telles que le taux d'erreur, la pr√©cision, le rappel, la pr√©cision ou l'erreur absolue moyenne (MAE) pour identifier des disparit√©s entre les m√©triques de performance. Une m√©trique de performance peut sembler excellente, mais des inexactitudes peuvent √™tre r√©v√©l√©es dans une autre. De plus, comparer les m√©triques pour identifier des disparit√©s dans l'ensemble des donn√©es ou les groupes permet de mettre en lumi√®re les zones o√π le mod√®le fonctionne bien ou non. Cela est particuli√®rement important pour observer la performance du mod√®le parmi des caract√©ristiques sensibles ou non sensibles (par exemple, la race, le genre ou l'√¢ge des patients) afin de d√©couvrir des injustices potentielles dans le mod√®le. Par exemple, d√©couvrir que le mod√®le est plus erron√© dans un groupe contenant des caract√©ristiques sensibles peut r√©v√©ler une injustice potentielle.

Le composant Vue d'ensemble du mod√®le du tableau de bord RAI aide non seulement √† analyser les m√©triques de performance de la repr√©sentation des donn√©es dans un groupe, mais il donne √©galement aux utilisateurs la possibilit√© de comparer le comportement du mod√®le entre diff√©rents groupes.

![Groupes de donn√©es - vue d'ensemble du mod√®le dans le tableau de bord RAI](../../../../translated_images/model-overview-dataset-cohorts.dfa463fb527a35a0afc01b7b012fc87bf2cad756763f3652bbd810cac5d6cf33.fr.png)

La fonctionnalit√© d'analyse bas√©e sur les caract√©ristiques du composant permet aux utilisateurs de r√©duire les sous-groupes de donn√©es au sein d'une caract√©ristique particuli√®re pour identifier des anomalies √† un niveau granulaire. Par exemple, le tableau de bord dispose d'une intelligence int√©gr√©e pour g√©n√©rer automatiquement des groupes pour une caract√©ristique s√©lectionn√©e par l'utilisateur (par exemple, *"time_in_hospital < 3"* ou *"time_in_hospital >= 7"*). Cela permet √† un utilisateur d'isoler une caract√©ristique particuli√®re d'un groupe de donn√©es plus large pour voir si elle est un facteur cl√© des r√©sultats erron√©s du mod√®le.

![Groupes de caract√©ristiques - vue d'ensemble du mod√®le dans le tableau de bord RAI](../../../../translated_images/model-overview-feature-cohorts.c5104d575ffd0c80b7ad8ede7703fab6166bfc6f9125dd395dcc4ace2f522f70.fr.png)

Le composant Vue d'ensemble du mod√®le prend en charge deux classes de m√©triques de disparit√© :

**Disparit√© dans la performance du mod√®le** : Ces ensembles de m√©triques calculent la disparit√© (diff√©rence) dans les valeurs de la m√©trique de performance s√©lectionn√©e entre les sous-groupes de donn√©es. Voici quelques exemples :

* Disparit√© dans le taux de pr√©cision
* Disparit√© dans le taux d'erreur
* Disparit√© dans la pr√©cision
* Disparit√© dans le rappel
* Disparit√© dans l'erreur absolue moyenne (MAE)

**Disparit√© dans le taux de s√©lection** : Cette m√©trique contient la diff√©rence dans le taux de s√©lection (pr√©diction favorable) entre les sous-groupes. Un exemple de cela est la disparit√© dans les taux d'approbation de pr√™t. Le taux de s√©lection signifie la fraction de points de donn√©es dans chaque classe class√©e comme 1 (dans une classification binaire) ou la distribution des valeurs de pr√©diction (dans une r√©gression).

## Analyse des donn√©es

> "Si vous torturez les donn√©es suffisamment longtemps, elles avoueront n'importe quoi" - Ronald Coase

Cette affirmation peut sembler extr√™me, mais il est vrai que les donn√©es peuvent √™tre manipul√©es pour soutenir n'importe quelle conclusion. Une telle manipulation peut parfois se produire involontairement. En tant qu'humains, nous avons tous des biais, et il est souvent difficile de savoir consciemment quand nous introduisons des biais dans les donn√©es. Garantir l'√©quit√© dans l'IA et l'apprentissage automatique reste un d√©fi complexe.

Les donn√©es constituent un point aveugle majeur pour les m√©triques traditionnelles de performance des mod√®les. Vous pouvez avoir des scores de pr√©cision √©lev√©s, mais cela ne refl√®te pas toujours les biais sous-jacents qui pourraient exister dans votre ensemble de donn√©es. Par exemple, si un ensemble de donn√©es sur les employ√©s montre que 27 % des femmes occupent des postes de direction dans une entreprise contre 73 % d'hommes au m√™me niveau, un mod√®le d'IA publicitaire form√© sur ces donn√©es pourrait cibler principalement un public masculin pour des postes de haut niveau. Ce d√©s√©quilibre dans les donn√©es a biais√© la pr√©diction du mod√®le en faveur d'un genre. Cela r√©v√®le un probl√®me d'√©quit√© o√π il existe un biais de genre dans le mod√®le d'IA.

Le composant Analyse des donn√©es du tableau de bord RAI aide √† identifier les zones o√π il y a une surrepr√©sentation ou une sous-repr√©sentation dans l'ensemble de donn√©es. Il aide les utilisateurs √† diagnostiquer la cause profonde des erreurs et des probl√®mes d'√©quit√© introduits par des d√©s√©quilibres ou un manque de repr√©sentation dans les donn√©es. Cela donne aux utilisateurs la possibilit√© de visualiser les ensembles de donn√©es en fonction des r√©sultats pr√©dits et r√©els, des groupes d'erreurs et des caract√©ristiques sp√©cifiques. Parfois, d√©couvrir un groupe de donn√©es sous-repr√©sent√© peut √©galement r√©v√©ler que le mod√®le n'apprend pas bien, d'o√π les nombreuses inexactitudes. Avoir un mod√®le avec des biais dans les donn√©es n'est pas seulement un probl√®me d'√©quit√©, mais montre que le mod√®le n'est ni inclusif ni fiable.

![Composant Analyse des donn√©es sur le tableau de bord RAI](../../../../translated_images/dataanalysis-cover.8d6d0683a70a5c1e274e5a94b27a71137e3d0a3b707761d7170eb340dd07f11d.fr.png)

Utilisez l'analyse des donn√©es lorsque vous devez :

* Explorer les statistiques de votre ensemble de donn√©es en s√©lectionnant diff√©rents filtres pour diviser vos donn√©es en diff√©rentes dimensions (√©galement appel√©es groupes).
* Comprendre la distribution de votre ensemble de donn√©es entre diff√©rents groupes et caract√©ristiques.
* D√©terminer si vos conclusions li√©es √† l'√©quit√©, √† l'analyse des erreurs et √† la causalit√© (d√©riv√©es d'autres composants du tableau de bord) sont le r√©sultat de la distribution de votre ensemble de donn√©es.
* D√©cider dans quels domaines collecter davantage de donn√©es pour att√©nuer les erreurs provenant de probl√®mes de repr√©sentation, de bruit dans les √©tiquettes, de bruit dans les caract√©ristiques, de biais dans les √©tiquettes, et de facteurs similaires.

## Interpr√©tabilit√© du mod√®le

Les mod√®les d'apprentissage automatique ont tendance √† √™tre des bo√Ætes noires. Comprendre quelles caract√©ristiques cl√©s des donn√©es influencent les pr√©dictions d'un mod√®le peut √™tre difficile. Il est important de fournir de la transparence sur les raisons pour lesquelles un mod√®le fait une certaine pr√©diction. Par exemple, si un syst√®me d'IA pr√©dit qu'un patient diab√©tique risque d'√™tre r√©admis √† l'h√¥pital dans moins de 30 jours, il devrait √™tre en mesure de fournir des donn√©es justificatives qui ont conduit √† sa pr√©diction. Avoir des indicateurs de donn√©es justificatifs apporte de la transparence pour aider les cliniciens ou les h√¥pitaux √† prendre des d√©cisions √©clair√©es. De plus, √™tre capable d'expliquer pourquoi un mod√®le a fait une pr√©diction pour un patient individuel permet de respecter les r√©glementations en mati√®re de responsabilit√©. Lorsque vous utilisez des mod√®les d'apprentissage automatique de mani√®re √† affecter la vie des gens, il est crucial de comprendre et d'expliquer ce qui influence le comportement d'un mod√®le. L'explicabilit√© et l'interpr√©tabilit√© des mod√®les permettent de r√©pondre √† des questions dans des sc√©narios tels que :

* D√©bogage du mod√®le : Pourquoi mon mod√®le a-t-il fait cette erreur ? Comment puis-je am√©liorer mon mod√®le ?
* Collaboration humain-IA : Comment puis-je comprendre et faire confiance aux d√©cisions du mod√®le ?
* Conformit√© r√©glementaire : Mon mod√®le satisfait-il aux exigences l√©gales ?

Le composant Importance des caract√©ristiques du tableau de bord RAI vous aide √† d√©boguer et √† obtenir une compr√©hension compl√®te de la mani√®re dont un mod√®le fait ses pr√©dictions. C'est √©galement un outil utile pour les professionnels de l'apprentissage automatique et les d√©cideurs afin d'expliquer et de montrer des preuves des caract√©ristiques influen√ßant le comportement d'un mod√®le pour la conformit√© r√©glementaire. Ensuite, les utilisateurs peuvent explorer √† la fois des explications globales et locales pour valider quelles caract√©ristiques influencent les pr√©dictions d'un mod√®le. Les explications globales listent les principales caract√©ristiques qui ont affect√© la pr√©diction globale d'un mod√®le. Les explications locales affichent les caract√©ristiques qui ont conduit √† la pr√©diction d'un mod√®le pour un cas individuel. La capacit√© d'√©valuer des explications locales est √©galement utile pour d√©boguer ou auditer un cas sp√©cifique afin de mieux comprendre et interpr√©ter pourquoi un mod√®le a fait une pr√©diction correcte ou incorrecte.

![Composant Importance des caract√©ristiques du tableau de bord RAI](../../../../translated_images/9-feature-importance.cd3193b4bba3fd4bccd415f566c2437fb3298c4824a3dabbcab15270d783606e.fr.png)

* Explications globales : Par exemple, quelles caract√©ristiques affectent le comportement global d'un mod√®le de r√©admission √† l'h√¥pital pour diab√©tiques ?
* Explications locales : Par exemple, pourquoi un patient diab√©tique de plus de 60 ans avec des hospitalisations ant√©rieures a-t-il √©t√© pr√©dit comme √©tant r√©admis ou non r√©admis dans les 30 jours √† l'h√¥pital ?

Dans le processus de d√©bogage visant √† examiner la performance d'un mod√®le entre diff√©rents groupes, Importance des caract√©ristiques montre le niveau d'impact qu'une caract√©ristique a entre les groupes. Cela aide √† r√©v√©ler des anomalies en comparant le niveau d'influence qu'une caract√©ristique a dans les pr√©dictions erron√©es d'un mod√®le. Le composant Importance des caract√©ristiques peut montrer quelles valeurs dans une caract√©ristique ont influenc√© positivement ou n√©gativement le r√©sultat du mod√®le. Par exemple, si un mod√®le a fait une pr√©diction incorrecte, le composant vous donne la possibilit√© d'approfondir et de d√©terminer quelles caract√©ristiques ou valeurs de caract√©ristiques ont influenc√© la pr√©diction. Ce niveau de d√©tail aide non seulement dans le d√©bogage, mais fournit √©galement de la transparence et de la responsabilit√© dans des situations d'audit. Enfin, le composant peut vous aider √† identifier des probl√®mes d'√©quit√©. Pour illustrer, si une caract√©ristique sensible comme l'origine ethnique ou le genre est tr√®s influente dans les pr√©dictions d'un mod√®le, cela pourrait √™tre un signe de biais racial ou de genre dans le mod√®le.

![Importance des caract√©ristiques](../../../../translated_images/9-features-influence.3ead3d3f68a84029f1e40d3eba82107445d3d3b6975d4682b23d8acc905da6d0.fr.png)

Utilisez l'interpr√©tabilit√© lorsque vous devez :

* D√©terminer dans quelle mesure les pr√©dictions de votre syst√®me d'IA sont fiables en comprenant quelles caract√©ristiques sont les plus importantes pour les pr√©dictions.
* Approcher le d√©bogage de votre mod√®le en le comprenant d'abord et en identifiant si le mod√®le utilise des caract√©ristiques pertinentes ou simplement des corr√©lations erron√©es.
* D√©couvrir des sources potentielles d'injustice en comprenant si le mod√®le base ses pr√©dictions sur des caract√©ristiques sensibles ou sur des caract√©ristiques fortement corr√©l√©es avec elles.
* Renforcer la confiance des utilisateurs dans les d√©cisions de votre mod√®le en g√©n√©rant des explications locales pour illustrer leurs r√©sultats.
* R√©aliser un audit r√©glementaire d'un syst√®me d'IA pour valider les mod√®les et surveiller l'impact des d√©cisions du mod√®le sur les humains.

## Conclusion

Tous les composants du tableau de bord RAI sont des outils pratiques pour vous aider √† construire des mod√®les d'apprentissage automatique moins nuisibles et plus fiables pour la soci√©t√©. Ils am√©liorent la pr√©vention des menaces aux droits humains, la discrimination ou l'exclusion de certains groupes des opportunit√©s de vie, et le risque de blessures physiques ou psychologiques. Ils aident √©galement √† renforcer la confiance dans les d√©cisions de votre mod√®le en g√©n√©rant des explications locales pour illustrer leurs r√©sultats. Certains des pr√©judices potentiels peuvent √™tre class√©s comme :

- **Allocation**, si un genre ou une origine ethnique, par exemple, est favoris√© par rapport √† un autre.
- **Qualit√© du service**. Si vous entra√Ænez les donn√©es pour un sc√©nario sp√©cifique mais que la r√©alit√© est beaucoup plus complexe, cela conduit √† un service de mauvaise qualit√©.
- **St√©r√©otypage**. Associer un groupe donn√© √† des attributs pr√©assign√©s.
- **D√©nigrement**. Critiquer ou √©tiqueter injustement quelque chose ou quelqu'un.
- **Sur- ou sous-repr√©sentation**. L'id√©e est qu'un certain groupe n'est pas visible dans une certaine profession, et tout service ou fonction qui continue de promouvoir cela contribue √† causer des pr√©judices.

### Tableau de bord Azure RAI

[Tableau de bord Azure RAI](https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai-dashboard?WT.mc_id=aiml-90525-ruyakubu) est bas√© sur des outils open-source d√©velopp√©s par des institutions acad√©miques et organisations de premier plan, y compris Microsoft. Ces outils sont essentiels pour les data scientists et les d√©veloppeurs d'IA afin de mieux comprendre le comportement des mod√®les, identifier et att√©nuer les probl√®mes ind√©sirables des mod√®les d'IA.

- Apprenez √† utiliser les diff√©rents composants en consultant la [documentation du tableau de bord RAI.](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-responsible-ai-dashboard?WT.mc_id=aiml-90525-ruyakubu)

- Consultez quelques [notebooks d'exemples du tableau de bord RAI](https://github.com/Azure/RAI-vNext-Preview/tree/main/examples/notebooks) pour d√©boguer des sc√©narios d'IA plus responsables dans Azure Machine Learning.

---
## üöÄ D√©fi

Pour √©viter que des biais statistiques ou de donn√©es ne soient introduits d√®s le d√©part, nous devrions :

- avoir une diversit√© de parcours et de perspectives parmi les personnes travaillant sur les syst√®mes
- investir dans des ensembles de donn√©es qui refl√®tent la diversit√© de notre soci√©t√©
- d√©velopper de meilleures m√©thodes pour d√©tecter et corriger les biais lorsqu'ils surviennent

R√©fl√©chissez √† des sc√©narios r√©els o√π l'injustice est √©vidente dans la construction et l'utilisation des mod√®les. Que devrions-nous √©galement prendre en compte ?

## [Quiz apr√®s le cours](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/6/)
## R√©vision et √©tude personnelle

Dans cette le√ßon, vous avez appris certains des outils pratiques pour int√©grer une IA responsable dans l'apprentissage automatique.

Regardez cet atelier pour approfondir les sujets :

- Tableau de bord Responsible AI : Une solution compl√®te pour op√©rationnaliser l'IA responsable en pratique par Besmira Nushi et Mehrnoosh Sameki

[![Tableau de bord Responsible AI : Une solution compl√®te pour op√©rationnaliser l'IA responsable en pratique](https://img.youtube.com/vi/f1oaDNl3djg/0.jpg)](https://www.youtube.com/watch?v=f1oaDNl3djg "Tableau de bord Responsible AI : Une solution compl√®te pour op√©rationnaliser l'IA responsable en pratique")

> üé• Cliquez sur l'image ci-dessus pour une vid√©o : Tableau de bord Responsible AI : Une solution compl√®te pour op√©rationnaliser l'IA responsable en pratique par Besmira Nushi et Mehrnoosh Sameki

Consultez les mat√©riaux suivants pour en savoir plus sur l'IA responsable et comment construire des mod√®les plus fiables :

- Outils du tableau de bord RAI de Microsoft pour d√©boguer les mod√®les ML : [Ressources sur les outils d'IA responsable](https://aka.ms/rai-dashboard)

- Explorez la bo√Æte √† outils Responsible AI : [Github](https://github.com/microsoft/responsible-ai-toolbox)

- Centre de ressources RAI de Microsoft : [Ressources sur l'IA responsable ‚Äì Microsoft AI](https://www.microsoft.com/ai/responsible-ai-resources?activetab=pivot1%3aprimaryr4)

- Groupe de recherche FATE de Microsoft : [FATE : √âquit√©, Responsabilit√©, Transparence et √âthique dans l'IA - Microsoft Research](https://www.microsoft.com/research/theme/fate/)

## Devoir

[Explorez le tableau de bord RAI](assignment.md)

---

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction professionnelle r√©alis√©e par un humain. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.