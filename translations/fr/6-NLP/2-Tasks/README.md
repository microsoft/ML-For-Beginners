# T√¢ches et techniques courantes en traitement du langage naturel

Pour la plupart des t√¢ches de *traitement du langage naturel*, le texte √† traiter doit √™tre d√©compos√©, examin√©, et les r√©sultats stock√©s ou crois√©s avec des r√®gles et des ensembles de donn√©es. Ces t√¢ches permettent au programmeur de d√©duire le _sens_ ou l‚Äô_intention_ ou simplement la _fr√©quence_ des termes et des mots dans un texte.

## [Quiz pr√©-conf√©rence](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/33/)

D√©couvrons les techniques courantes utilis√©es dans le traitement de texte. Associ√©es √† l'apprentissage automatique, ces techniques vous aident √† analyser efficacement de grandes quantit√©s de texte. Avant d'appliquer l'apprentissage automatique √† ces t√¢ches, comprenons cependant les probl√®mes rencontr√©s par un sp√©cialiste en traitement du langage naturel.

## T√¢ches courantes en NLP

Il existe diff√©rentes mani√®res d'analyser un texte sur lequel vous travaillez. Il y a des t√¢ches que vous pouvez effectuer et, √† travers ces t√¢ches, vous √™tes en mesure de comprendre le texte et de tirer des conclusions. Vous effectuez g√©n√©ralement ces t√¢ches dans un certain ordre.

### Tokenisation

Probablement la premi√®re chose que la plupart des algorithmes de NLP doivent faire est de diviser le texte en tokens, ou mots. Bien que cela semble simple, tenir compte de la ponctuation et des d√©limiteurs de mots et de phrases dans diff√©rentes langues peut rendre cela d√©licat. Vous devrez peut-√™tre utiliser diverses m√©thodes pour d√©terminer les d√©limitations.

![tokenisation](../../../../translated_images/tokenization.1641a160c66cd2d93d4524e8114e93158a9ce0eba3ecf117bae318e8a6ad3487.fr.png)
> Tokenisation d'une phrase de **Orgueil et Pr√©jug√©s**. Infographie par [Jen Looper](https://twitter.com/jenlooper)

### Embeddings

[Les embeddings de mots](https://wikipedia.org/wiki/Word_embedding) sont une mani√®re de convertir vos donn√©es textuelles num√©riquement. Les embeddings sont r√©alis√©s de mani√®re √† ce que les mots ayant un sens similaire ou les mots utilis√©s ensemble se regroupent.

![embeddings de mots](../../../../translated_images/embedding.2cf8953c4b3101d188c2f61a5de5b6f53caaa5ad4ed99236d42bc3b6bd6a1fe2.fr.png)
> "J'ai le plus grand respect pour vos nerfs, ce sont mes vieux amis." - Embeddings de mots pour une phrase de **Orgueil et Pr√©jug√©s**. Infographie par [Jen Looper](https://twitter.com/jenlooper)

‚úÖ Essayez [cet outil int√©ressant](https://projector.tensorflow.org/) pour exp√©rimenter avec les embeddings de mots. En cliquant sur un mot, vous voyez des groupes de mots similaires : 'jouet' se regroupe avec 'disney', 'lego', 'playstation', et 'console'.

### Analyse syntaxique et √©tiquetage des parties du discours

Chaque mot qui a √©t√© tokenis√© peut √™tre √©tiquet√© comme une partie du discours - un nom, un verbe ou un adjectif. La phrase `the quick red fox jumped over the lazy brown dog` pourrait √™tre √©tiquet√©e comme suit : renard = nom, a saut√© = verbe.

![analyse syntaxique](../../../../translated_images/parse.d0c5bbe1106eae8fe7d60a183cd1736c8b6cec907f38000366535f84f3036101.fr.png)

> Analyse syntaxique d'une phrase de **Orgueil et Pr√©jug√©s**. Infographie par [Jen Looper](https://twitter.com/jenlooper)

L'analyse syntaxique consiste √† reconna√Ætre quels mots sont li√©s les uns aux autres dans une phrase - par exemple, `the quick red fox jumped` est une s√©quence adjectif-nom-verbe qui est distincte de la s√©quence `lazy brown dog`.  

### Fr√©quences de mots et de phrases

Une proc√©dure utile lors de l'analyse d'un grand corpus de texte est de construire un dictionnaire de chaque mot ou phrase d'int√©r√™t et de la fr√©quence √† laquelle il appara√Æt. La phrase `the quick red fox jumped over the lazy brown dog` a une fr√©quence de mot de 2 pour le.

Voyons un exemple de texte o√π nous comptons la fr√©quence des mots. Le po√®me de Rudyard Kipling, The Winners, contient le vers suivant :

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

Les fr√©quences de phrases peuvent √™tre insensibles √† la casse ou sensibles √† la casse selon les besoins, la phrase `un ami` has a frequency of 2 and `le` has a frequency of 6, and `voyages` est 2.

### N-grams

Un texte peut √™tre divis√© en s√©quences de mots d'une longueur d√©finie, un seul mot (unigramme), deux mots (bigrammes), trois mots (trigrammes) ou tout nombre de mots (n-grams).

Par exemple, `the quick red fox jumped over the lazy brown dog` avec un score n-gram de 2 produit les n-grams suivants :

1. le rapide 
2. rapide rouge 
3. rouge renard
4. renard a saut√© 
5. a saut√© par-dessus 
6. par-dessus le 
7. le paresseux 
8. paresseux brun 
9. brun chien

Il peut √™tre plus facile de visualiser cela comme une bo√Æte glissante sur la phrase. Voici pour les n-grams de 3 mots, le n-gram est en gras dans chaque phrase :

1.   <u>**le rapide rouge**</u> renard a saut√© par-dessus le paresseux brun chien
2.   le **<u>rapide rouge renard</u>** a saut√© par-dessus le paresseux brun chien
3.   le rapide **<u>rouge renard a saut√©</u>** par-dessus le paresseux brun chien
4.   le rapide rouge **<u>renard a saut√© par-dessus</u>** le paresseux brun chien
5.   le rapide rouge renard **<u>a saut√© par-dessus le</u>** paresseux brun chien
6.   le rapide rouge renard a saut√© **<u>par-dessus le paresseux</u>** brun chien
7.   le rapide rouge renard a saut√© par-dessus <u>**le paresseux brun**</u> chien
8.   le rapide rouge renard a saut√© par-dessus le **<u>paresseux brun chien</u>**

![fen√™tre glissante des n-grams](../../../../6-NLP/2-Tasks/images/n-grams.gif)

> Valeur n-gram de 3 : Infographie par [Jen Looper](https://twitter.com/jenlooper)

### Extraction de phrases nominales

Dans la plupart des phrases, il y a un nom qui est le sujet ou l'objet de la phrase. En anglais, il est souvent identifiable par la pr√©sence de 'un' ou 'une' ou 'le' qui le pr√©c√®de. Identifier le sujet ou l'objet d'une phrase en 'extraction de la phrase nominale' est une t√¢che courante en NLP lorsqu'il s'agit de comprendre le sens d'une phrase.

‚úÖ Dans la phrase "Je ne peux pas me fixer sur l'heure, ou le lieu, ou le regard ou les mots, qui ont pos√© les fondations. Cela fait trop longtemps. J'√©tais au milieu avant de savoir que j'avais commenc√©.", pouvez-vous identifier les phrases nominales ?

Dans la phrase `the quick red fox jumped over the lazy brown dog`, il y a 2 phrases nominales : **rapide renard rouge** et **paresseux chien brun**.

### Analyse des sentiments

Une phrase ou un texte peut √™tre analys√© pour d√©terminer le sentiment, ou √† quel point il est *positif* ou *n√©gatif*. Le sentiment est mesur√© en *polarit√©* et *objectivit√©/sujetivit√©*. La polarit√© est mesur√©e de -1.0 √† 1.0 (n√©gatif √† positif) et de 0.0 √† 1.0 (le plus objectif au plus subjectif).

‚úÖ Plus tard, vous apprendrez qu'il existe diff√©rentes mani√®res de d√©terminer le sentiment en utilisant l'apprentissage automatique, mais une mani√®re consiste √† avoir une liste de mots et de phrases qui sont cat√©goris√©s comme positifs ou n√©gatifs par un expert humain et √† appliquer ce mod√®le au texte pour calculer un score de polarit√©. Pouvez-vous voir comment cela fonctionnerait dans certaines circonstances et moins bien dans d'autres ?

### Flexion

La flexion vous permet de prendre un mot et d'obtenir le singulier ou le pluriel de ce mot.

### Lemmatisation

Un *lemme* est la racine ou le mot principal pour un ensemble de mots, par exemple *vol√©*, *volent*, *volant* ont un lemme du verbe *voler*.

Il existe √©galement des bases de donn√©es utiles disponibles pour le chercheur en NLP, notamment :

### WordNet

[WordNet](https://wordnet.princeton.edu/) est une base de donn√©es de mots, synonymes, antonymes et de nombreux autres d√©tails pour chaque mot dans de nombreuses langues diff√©rentes. Elle est incroyablement utile lorsqu'il s'agit de construire des traductions, des correcteurs orthographiques ou des outils linguistiques de tout type.

## Biblioth√®ques NLP

Heureusement, vous n'avez pas √† construire toutes ces techniques vous-m√™me, car il existe d'excellentes biblioth√®ques Python qui rendent cela beaucoup plus accessible aux d√©veloppeurs qui ne sont pas sp√©cialis√©s dans le traitement du langage naturel ou l'apprentissage automatique. Les le√ßons suivantes incluent davantage d'exemples de celles-ci, mais ici vous apprendrez quelques exemples utiles pour vous aider dans la prochaine t√¢che.

### Exercice - utiliser `TextBlob` library

Let's use a library called TextBlob as it contains helpful APIs for tackling these types of tasks. TextBlob "stands on the giant shoulders of [NLTK](https://nltk.org) and [pattern](https://github.com/clips/pattern), and plays nicely with both." It has a considerable amount of ML embedded in its API.

> Note: A useful [Quick Start](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart) guide is available for TextBlob that is recommended for experienced Python developers 

When attempting to identify *noun phrases*, TextBlob offers several options of extractors to find noun phrases. 

1. Take a look at `ConllExtractor`.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > Que se passe-t-il ici ? [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) est "Un extracteur de phrases nominales qui utilise l'analyse de chunks entra√Æn√©e avec le corpus d'entra√Ænement ConLL-2000." ConLL-2000 fait r√©f√©rence √† la Conf√©rence de 2000 sur l'apprentissage automatique du langage naturel. Chaque ann√©e, la conf√©rence organisait un atelier pour s'attaquer √† un probl√®me √©pineux en NLP, et en 2000, il s'agissait de l'extraction de chunks nominaux. Un mod√®le a √©t√© entra√Æn√© sur le Wall Street Journal, avec "les sections 15-18 comme donn√©es d'entra√Ænement (211727 tokens) et la section 20 comme donn√©es de test (47377 tokens)". Vous pouvez consulter les proc√©dures utilis√©es [ici](https://www.clips.uantwerpen.be/conll2000/chunking/) et les [r√©sultats](https://ifarm.nl/erikt/research/np-chunking.html).

### D√©fi - am√©liorer votre bot avec le NLP

Dans la le√ßon pr√©c√©dente, vous avez construit un bot de questions-r√©ponses tr√®s simple. Maintenant, vous allez rendre Marvin un peu plus sympathique en analysant votre entr√©e pour le sentiment et en imprimant une r√©ponse correspondant au sentiment. Vous devrez √©galement identifier une `noun_phrase` et poser des questions √† son sujet.

Vos √©tapes pour construire un bot conversationnel meilleur :

1. Imprimer des instructions conseillant √† l'utilisateur comment interagir avec le bot
2. D√©marrer la boucle 
   1. Accepter l'entr√©e de l'utilisateur
   2. Si l'utilisateur a demand√© √† quitter, alors quitter
   3. Traiter l'entr√©e de l'utilisateur et d√©terminer la r√©ponse sentimentale appropri√©e
   4. Si une phrase nominale est d√©tect√©e dans le sentiment, la mettre au pluriel et demander plus d'informations sur ce sujet
   5. Imprimer la r√©ponse
3. revenir √† l'√©tape 2

Voici le code pour d√©terminer le sentiment en utilisant TextBlob. Notez qu'il n'y a que quatre *gradients* de r√©ponse au sentiment (vous pourriez en avoir plus si vous le souhaitez) :

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

Voici un exemple de sortie pour vous guider (l'entr√©e de l'utilisateur est sur les lignes commen√ßant par >) :

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

Une solution possible √† la t√¢che est [ici](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/2-Tasks/solution/bot.py)

‚úÖ V√©rification des connaissances

1. Pensez-vous que les r√©ponses sympathiques pourraient "tromper" quelqu'un en pensant que le bot les comprenait r√©ellement ?
2. L'identification de la phrase nominale rend-elle le bot plus "cr√©dible" ?
3. Pourquoi l'extraction d'une "phrase nominale" d'une phrase serait-elle une chose utile √† faire ?

---

Impl√©mentez le bot dans la v√©rification des connaissances pr√©c√©dente et testez-le sur un ami. Peut-il les tromper ? Pouvez-vous rendre votre bot plus "cr√©dible" ?

## üöÄD√©fi

Prenez une t√¢che dans la v√©rification des connaissances pr√©c√©dente et essayez de l'impl√©menter. Testez le bot sur un ami. Peut-il les tromper ? Pouvez-vous rendre votre bot plus "cr√©dible" ?

## [Quiz post-conf√©rence](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/34/)

## Revue et auto-apprentissage

Dans les prochaines le√ßons, vous en apprendrez davantage sur l'analyse des sentiments. Recherchez cette technique int√©ressante dans des articles comme ceux-ci sur [KDNuggets](https://www.kdnuggets.com/tag/nlp)

## Devoir 

[Faites parler un bot](assignment.md)

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide de services de traduction automatique bas√©s sur l'IA. Bien que nous nous effor√ßons d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue native doit √™tre consid√©r√© comme la source autoritaire. Pour des informations critiques, une traduction professionnelle par un humain est recommand√©e. Nous ne sommes pas responsables des malentendus ou des interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.