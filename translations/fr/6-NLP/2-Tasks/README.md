<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6534e145d52a3890590d27be75386e5d",
  "translation_date": "2025-09-04T00:33:49+00:00",
  "source_file": "6-NLP/2-Tasks/README.md",
  "language_code": "fr"
}
-->
# T√¢ches et techniques courantes en traitement du langage naturel

Pour la plupart des t√¢ches de *traitement du langage naturel*, le texte √† traiter doit √™tre d√©compos√©, analys√©, et les r√©sultats doivent √™tre stock√©s ou crois√©s avec des r√®gles et des ensembles de donn√©es. Ces t√¢ches permettent au programmeur de d√©duire le _sens_, l'_intention_ ou simplement la _fr√©quence_ des termes et des mots dans un texte.

## [Quiz avant la le√ßon](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/33/)

D√©couvrons les techniques courantes utilis√©es pour traiter le texte. Combin√©es avec l'apprentissage automatique, ces techniques vous aident √† analyser efficacement de grandes quantit√©s de texte. Avant d'appliquer l'IA √† ces t√¢ches, comprenons les probl√®mes rencontr√©s par un sp√©cialiste du NLP.

## T√¢ches courantes en NLP

Il existe diff√©rentes fa√ßons d'analyser un texte sur lequel vous travaillez. Il y a des t√¢ches que vous pouvez effectuer et, gr√¢ce √† ces t√¢ches, vous pouvez comprendre le texte et en tirer des conclusions. Ces t√¢ches sont g√©n√©ralement effectu√©es dans un ordre pr√©cis.

### Tokenisation

La premi√®re √©tape que la plupart des algorithmes de NLP doivent effectuer est probablement de diviser le texte en tokens, ou mots. Bien que cela semble simple, tenir compte de la ponctuation et des d√©limiteurs de mots et de phrases propres √† chaque langue peut rendre cette t√¢che complexe. Vous pourriez avoir besoin de diff√©rentes m√©thodes pour d√©terminer les d√©limitations.

![tokenisation](../../../../translated_images/tokenization.1641a160c66cd2d93d4524e8114e93158a9ce0eba3ecf117bae318e8a6ad3487.fr.png)
> Tokenisation d'une phrase tir√©e de **Orgueil et Pr√©jug√©s**. Infographie par [Jen Looper](https://twitter.com/jenlooper)

### Embeddings

[Les embeddings de mots](https://wikipedia.org/wiki/Word_embedding) sont une m√©thode pour convertir vos donn√©es textuelles en valeurs num√©riques. Les embeddings sont r√©alis√©s de mani√®re √† ce que les mots ayant un sens similaire ou utilis√©s ensemble se regroupent.

![embeddings de mots](../../../../translated_images/embedding.2cf8953c4b3101d188c2f61a5de5b6f53caaa5ad4ed99236d42bc3b6bd6a1fe2.fr.png)
> "J'ai le plus grand respect pour vos nerfs, ce sont mes vieux amis." - Embeddings de mots pour une phrase tir√©e de **Orgueil et Pr√©jug√©s**. Infographie par [Jen Looper](https://twitter.com/jenlooper)

‚úÖ Essayez [cet outil int√©ressant](https://projector.tensorflow.org/) pour exp√©rimenter avec les embeddings de mots. En cliquant sur un mot, vous verrez des regroupements de mots similaires : 'jouet' se regroupe avec 'disney', 'lego', 'playstation' et 'console'.

### Analyse syntaxique et √©tiquetage des parties du discours

Chaque mot qui a √©t√© tokenis√© peut √™tre √©tiquet√© comme une partie du discours - un nom, un verbe ou un adjectif. La phrase `le rapide renard rouge a saut√© par-dessus le chien brun paresseux` pourrait √™tre √©tiquet√©e comme renard = nom, saut√© = verbe.

![analyse syntaxique](../../../../translated_images/parse.d0c5bbe1106eae8fe7d60a183cd1736c8b6cec907f38000366535f84f3036101.fr.png)

> Analyse syntaxique d'une phrase tir√©e de **Orgueil et Pr√©jug√©s**. Infographie par [Jen Looper](https://twitter.com/jenlooper)

L'analyse syntaxique consiste √† reconna√Ætre quels mots sont li√©s les uns aux autres dans une phrase - par exemple, `le rapide renard rouge a saut√©` est une s√©quence adjectif-nom-verbe distincte de la s√©quence `chien brun paresseux`.

### Fr√©quences des mots et des phrases

Une proc√©dure utile lors de l'analyse d'un grand corpus de texte est de construire un dictionnaire de chaque mot ou phrase d'int√©r√™t et de la fr√©quence √† laquelle il appara√Æt. La phrase `le rapide renard rouge a saut√© par-dessus le chien brun paresseux` a une fr√©quence de 2 pour le mot "le".

Prenons un exemple de texte o√π nous comptons la fr√©quence des mots. Le po√®me Les Vainqueurs de Rudyard Kipling contient le vers suivant :

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

Comme les fr√©quences des phrases peuvent √™tre sensibles ou non √† la casse selon les besoins, la phrase `un ami` a une fr√©quence de 2, `le` a une fr√©quence de 6, et `voyages` a une fr√©quence de 2.

### N-grams

Un texte peut √™tre divis√© en s√©quences de mots d'une longueur d√©finie : un seul mot (unigramme), deux mots (bigrammes), trois mots (trigrammes) ou tout autre nombre de mots (n-grams).

Par exemple, `le rapide renard rouge a saut√© par-dessus le chien brun paresseux` avec un score de n-gram de 2 produit les n-grams suivants :

1. le rapide  
2. rapide renard  
3. renard rouge  
4. rouge a  
5. a saut√©  
6. saut√© par-dessus  
7. par-dessus le  
8. le chien  
9. chien brun  

Il peut √™tre plus facile de le visualiser comme une fen√™tre glissante sur la phrase. Voici un exemple pour des n-grams de 3 mots, le n-gram est en gras dans chaque phrase :

1.   <u>**le rapide renard**</u> a saut√© par-dessus le chien brun paresseux  
2.   le **<u>rapide renard rouge</u>** a saut√© par-dessus le chien brun paresseux  
3.   le rapide **<u>renard rouge a</u>** saut√© par-dessus le chien brun paresseux  
4.   le rapide renard **<u>rouge a saut√©</u>** par-dessus le chien brun paresseux  
5.   le rapide renard rouge **<u>a saut√© par-dessus</u>** le chien brun paresseux  
6.   le rapide renard rouge a **<u>saut√© par-dessus le</u>** chien brun paresseux  
7.   le rapide renard rouge a saut√© <u>**par-dessus le chien**</u> brun paresseux  
8.   le rapide renard rouge a saut√© par-dessus le **<u>chien brun paresseux</u>**

![fen√™tre glissante des n-grams](../../../../6-NLP/2-Tasks/images/n-grams.gif)

> Valeur de n-gram de 3 : Infographie par [Jen Looper](https://twitter.com/jenlooper)

### Extraction de syntagmes nominaux

Dans la plupart des phrases, il y a un nom qui est le sujet ou l'objet de la phrase. En anglais, il est souvent identifiable par la pr√©sence de 'a', 'an' ou 'the' avant lui. Identifier le sujet ou l'objet d'une phrase en 'extrayant le syntagme nominal' est une t√¢che courante en NLP lorsqu'on tente de comprendre le sens d'une phrase.

‚úÖ Dans la phrase "Je ne peux pas fixer l'heure, ni l'endroit, ni le regard ni les mots, qui ont pos√© les bases. C'est trop ancien. J'√©tais au milieu avant de savoir que j'avais commenc√©.", pouvez-vous identifier les syntagmes nominaux ?

Dans la phrase `le rapide renard rouge a saut√© par-dessus le chien brun paresseux`, il y a 2 syntagmes nominaux : **rapide renard rouge** et **chien brun paresseux**.

### Analyse de sentiment

Une phrase ou un texte peut √™tre analys√© pour son sentiment, ou √† quel point il est *positif* ou *n√©gatif*. Le sentiment est mesur√© en *polarit√©* et *objectivit√©/subjectivit√©*. La polarit√© est mesur√©e de -1.0 √† 1.0 (n√©gatif √† positif) et de 0.0 √† 1.0 (le plus objectif au plus subjectif).

‚úÖ Plus tard, vous apprendrez qu'il existe diff√©rentes fa√ßons de d√©terminer le sentiment en utilisant l'apprentissage automatique, mais une m√©thode consiste √† avoir une liste de mots et de phrases cat√©goris√©s comme positifs ou n√©gatifs par un expert humain et √† appliquer ce mod√®le au texte pour calculer un score de polarit√©. Pouvez-vous voir comment cela fonctionnerait dans certains cas et moins bien dans d'autres ?

### Inflection

L'inflexion vous permet de prendre un mot et d'obtenir le singulier ou le pluriel de ce mot.

### Lemmatisation

Un *lemme* est la racine ou le mot principal d'un ensemble de mots, par exemple *vol√©*, *vole*, *volant* ont pour lemme le verbe *voler*.

Il existe √©galement des bases de donn√©es utiles pour les chercheurs en NLP, notamment :

### WordNet

[WordNet](https://wordnet.princeton.edu/) est une base de donn√©es de mots, synonymes, antonymes et de nombreux autres d√©tails pour chaque mot dans de nombreuses langues diff√©rentes. Elle est incroyablement utile lorsqu'on tente de cr√©er des traductions, des correcteurs orthographiques ou des outils linguistiques de tout type.

## Biblioth√®ques NLP

Heureusement, vous n'avez pas besoin de construire toutes ces techniques vous-m√™me, car il existe d'excellentes biblioth√®ques Python qui les rendent beaucoup plus accessibles aux d√©veloppeurs qui ne sont pas sp√©cialis√©s en traitement du langage naturel ou en apprentissage automatique. Les prochaines le√ßons incluent plus d'exemples de ces biblioth√®ques, mais ici vous apprendrez quelques exemples utiles pour vous aider dans la prochaine t√¢che.

### Exercice - utiliser la biblioth√®que `TextBlob`

Utilisons une biblioth√®que appel√©e TextBlob, car elle contient des API utiles pour aborder ces types de t√¢ches. TextBlob "s'appuie sur les √©paules des g√©ants [NLTK](https://nltk.org) et [pattern](https://github.com/clips/pattern), et fonctionne bien avec les deux." Elle int√®gre une quantit√© consid√©rable d'IA dans son API.

> Note : Un [guide de d√©marrage rapide](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart) est disponible pour TextBlob et est recommand√© pour les d√©veloppeurs Python exp√©riment√©s.

Lorsqu'on tente d'identifier des *syntagmes nominaux*, TextBlob propose plusieurs options d'extracteurs pour trouver les syntagmes nominaux.

1. Regardez `ConllExtractor`.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > Que se passe-t-il ici ? [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) est "un extracteur de syntagmes nominaux qui utilise l'analyse par chunking entra√Æn√©e avec le corpus d'entra√Ænement ConLL-2000." ConLL-2000 fait r√©f√©rence √† la Conf√©rence de 2000 sur l'apprentissage automatique du langage naturel. Chaque ann√©e, la conf√©rence organisait un atelier pour r√©soudre un probl√®me complexe de NLP, et en 2000, il s'agissait du chunking nominal. Un mod√®le a √©t√© entra√Æn√© sur le Wall Street Journal, avec "les sections 15-18 comme donn√©es d'entra√Ænement (211727 tokens) et la section 20 comme donn√©es de test (47377 tokens)". Vous pouvez consulter les proc√©dures utilis√©es [ici](https://www.clips.uantwerpen.be/conll2000/chunking/) et les [r√©sultats](https://ifarm.nl/erikt/research/np-chunking.html).

### D√©fi - am√©liorer votre bot avec le NLP

Dans la le√ßon pr√©c√©dente, vous avez construit un bot de questions-r√©ponses tr√®s simple. Maintenant, vous allez rendre Marvin un peu plus sympathique en analysant votre entr√©e pour le sentiment et en imprimant une r√©ponse adapt√©e au sentiment. Vous devrez √©galement identifier un `syntagme nominal` et poser une question √† ce sujet.

Vos √©tapes pour construire un bot conversationnel am√©lior√© :

1. Imprimez des instructions conseillant √† l'utilisateur comment interagir avec le bot  
2. D√©marrez une boucle  
   1. Acceptez l'entr√©e utilisateur  
   2. Si l'utilisateur demande √† quitter, alors quittez  
   3. Traitez l'entr√©e utilisateur et d√©terminez une r√©ponse sentimentale appropri√©e  
   4. Si un syntagme nominal est d√©tect√© dans le sentiment, mettez-le au pluriel et demandez plus d'informations √† ce sujet  
   5. Imprimez la r√©ponse  
3. Revenez √† l'√©tape 2  

Voici l'extrait de code pour d√©terminer le sentiment en utilisant TextBlob. Notez qu'il n'y a que quatre *gradients* de r√©ponse sentimentale (vous pourriez en avoir plus si vous le souhaitez) :

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

Voici un exemple de sortie pour vous guider (l'entr√©e utilisateur est sur les lignes commen√ßant par >) :

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

Une solution possible √† la t√¢che est [ici](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/2-Tasks/solution/bot.py)

‚úÖ V√©rification des connaissances

1. Pensez-vous que les r√©ponses sympathiques pourraient 'tromper' quelqu'un en lui faisant croire que le bot le comprend r√©ellement ?  
2. Identifier le syntagme nominal rend-il le bot plus 'cr√©dible' ?  
3. Pourquoi l'extraction d'un 'syntagme nominal' d'une phrase serait-elle utile ?  

---

Impl√©mentez le bot dans la v√©rification des connaissances pr√©c√©dente et testez-le sur un ami. Peut-il les tromper ? Pouvez-vous rendre votre bot plus 'cr√©dible' ?

## üöÄD√©fi

Prenez une t√¢che dans la v√©rification des connaissances pr√©c√©dente et essayez de l'impl√©menter. Testez le bot sur un ami. Peut-il les tromper ? Pouvez-vous rendre votre bot plus 'cr√©dible' ?

## [Quiz apr√®s la le√ßon](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/34/)

## R√©vision et √©tude personnelle

Dans les prochaines le√ßons, vous en apprendrez davantage sur l'analyse de sentiment. Recherchez cette technique int√©ressante dans des articles tels que ceux sur [KDNuggets](https://www.kdnuggets.com/tag/nlp)

## Devoir 

[Faire parler un bot](assignment.md)

---

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction professionnelle r√©alis√©e par un humain. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.