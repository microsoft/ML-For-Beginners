<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8d32dadeda93c6fb5c43619854882ab1",
  "translation_date": "2025-09-04T23:06:47+00:00",
  "source_file": "6-NLP/4-Hotel-Reviews-1/README.md",
  "language_code": "fr"
}
-->
# Analyse de sentiment avec les avis d'h√¥tels - traitement des donn√©es

Dans cette section, vous utiliserez les techniques des le√ßons pr√©c√©dentes pour effectuer une analyse exploratoire des donn√©es sur un grand ensemble de donn√©es. Une fois que vous aurez une bonne compr√©hension de l'utilit√© des diff√©rentes colonnes, vous apprendrez :

- comment supprimer les colonnes inutiles
- comment calculer de nouvelles donn√©es √† partir des colonnes existantes
- comment sauvegarder l'ensemble de donn√©es r√©sultant pour l'utiliser dans le d√©fi final

## [Quiz avant la le√ßon](https://ff-quizzes.netlify.app/en/ml/)

### Introduction

Jusqu'√† pr√©sent, vous avez appris que les donn√©es textuelles sont tr√®s diff√©rentes des donn√©es num√©riques. Si le texte a √©t√© √©crit ou prononc√© par un humain, il peut √™tre analys√© pour trouver des motifs, des fr√©quences, des sentiments et des significations. Cette le√ßon vous plonge dans un ensemble de donn√©es r√©el avec un d√©fi r√©el : **[515K Hotel Reviews Data in Europe](https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe)**, qui inclut une [licence CC0 : Domaine Public](https://creativecommons.org/publicdomain/zero/1.0/). Les donn√©es ont √©t√© extraites de Booking.com √† partir de sources publiques. Le cr√©ateur de l'ensemble de donn√©es est Jiashen Liu.

### Pr√©paration

Vous aurez besoin de :

* La capacit√© d'ex√©cuter des notebooks .ipynb avec Python 3
* pandas
* NLTK, [que vous devez installer localement](https://www.nltk.org/install.html)
* L'ensemble de donn√©es disponible sur Kaggle [515K Hotel Reviews Data in Europe](https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe). Il p√®se environ 230 Mo une fois d√©compress√©. T√©l√©chargez-le dans le dossier racine `/data` associ√© √† ces le√ßons sur le NLP.

## Analyse exploratoire des donn√©es

Ce d√©fi suppose que vous construisez un bot de recommandation d'h√¥tels en utilisant l'analyse de sentiment et les scores des avis des clients. L'ensemble de donn√©es que vous utiliserez inclut des avis sur 1493 h√¥tels diff√©rents dans 6 villes.

Avec Python, un ensemble de donn√©es d'avis d'h√¥tels et l'analyse de sentiment de NLTK, vous pourriez d√©couvrir :

* Quels sont les mots et expressions les plus fr√©quemment utilis√©s dans les avis ?
* Les *tags* officiels d√©crivant un h√¥tel sont-ils corr√©l√©s aux scores des avis (par exemple, les avis plus n√©gatifs pour un h√¥tel particulier concernent-ils davantage les *Familles avec jeunes enfants* que les *Voyageurs en solo*, ce qui pourrait indiquer qu'il est mieux adapt√© aux *Voyageurs en solo*) ?
* Les scores de sentiment de NLTK "s'accordent-ils" avec le score num√©rique donn√© par le client ?

#### Ensemble de donn√©es

Explorons l'ensemble de donn√©es que vous avez t√©l√©charg√© et sauvegard√© localement. Ouvrez le fichier dans un √©diteur comme VS Code ou m√™me Excel.

Les en-t√™tes de l'ensemble de donn√©es sont les suivants :

*Hotel_Address, Additional_Number_of_Scoring, Review_Date, Average_Score, Hotel_Name, Reviewer_Nationality, Negative_Review, Review_Total_Negative_Word_Counts, Total_Number_of_Reviews, Positive_Review, Review_Total_Positive_Word_Counts, Total_Number_of_Reviews_Reviewer_Has_Given, Reviewer_Score, Tags, days_since_review, lat, lng*

Voici une pr√©sentation regroup√©e pour faciliter l'examen :  
##### Colonnes des h√¥tels

* `Hotel_Name`, `Hotel_Address`, `lat` (latitude), `lng` (longitude)
  * Avec *lat* et *lng*, vous pourriez tracer une carte avec Python montrant les emplacements des h√¥tels (peut-√™tre cod√©s par couleur pour les avis n√©gatifs et positifs).
  * Hotel_Address n'est pas √©videmment utile pour nous, et nous remplacerons probablement cette colonne par un pays pour faciliter le tri et la recherche.

**Colonnes m√©ta-avis des h√¥tels**

* `Average_Score`
  * Selon le cr√©ateur de l'ensemble de donn√©es, cette colonne repr√©sente le *Score moyen de l'h√¥tel, calcul√© sur la base du dernier commentaire de l'ann√©e √©coul√©e*. Cela semble √™tre une mani√®re inhabituelle de calculer le score, mais ce sont les donn√©es extraites, donc nous pouvons les prendre telles quelles pour l'instant.

  ‚úÖ En vous basant sur les autres colonnes de cet ensemble de donn√©es, pouvez-vous imaginer une autre mani√®re de calculer le score moyen ?

* `Total_Number_of_Reviews`
  * Le nombre total d'avis re√ßus par cet h√¥tel - il n'est pas clair (sans √©crire du code) si cela fait r√©f√©rence aux avis pr√©sents dans l'ensemble de donn√©es.
* `Additional_Number_of_Scoring`
  * Cela signifie qu'un score a √©t√© donn√© mais qu'aucun avis positif ou n√©gatif n'a √©t√© √©crit par le client.

**Colonnes des avis**

- `Reviewer_Score`
  - C'est une valeur num√©rique avec au maximum 1 chiffre apr√®s la virgule, entre les valeurs minimales et maximales de 2.5 et 10.
  - Il n'est pas expliqu√© pourquoi 2.5 est le score le plus bas possible.
- `Negative_Review`
  - Si un client n'a rien √©crit, ce champ contiendra "**No Negative**".
  - Notez qu'un client peut √©crire un avis positif dans la colonne des avis n√©gatifs (par exemple, "il n'y a rien de mauvais dans cet h√¥tel").
- `Review_Total_Negative_Word_Counts`
  - Un nombre √©lev√© de mots n√©gatifs indique un score plus bas (sans v√©rifier la tonalit√©).
- `Positive_Review`
  - Si un client n'a rien √©crit, ce champ contiendra "**No Positive**".
  - Notez qu'un client peut √©crire un avis n√©gatif dans la colonne des avis positifs (par exemple, "il n'y a rien de bien dans cet h√¥tel").
- `Review_Total_Positive_Word_Counts`
  - Un nombre √©lev√© de mots positifs indique un score plus √©lev√© (sans v√©rifier la tonalit√©).
- `Review_Date` et `days_since_review`
  - Une mesure de fra√Æcheur ou de vieillissement pourrait √™tre appliqu√©e √† un avis (les avis plus anciens pourraient ne pas √™tre aussi pr√©cis que les plus r√©cents en raison de changements dans la gestion de l'h√¥tel, de r√©novations, ou de l'ajout d'une piscine, etc.).
- `Tags`
  - Ce sont de courtes descriptions qu'un client peut s√©lectionner pour d√©crire le type de client qu'il √©tait (par exemple, solo ou en famille), le type de chambre qu'il avait, la dur√©e de son s√©jour et la mani√®re dont l'avis a √©t√© soumis.
  - Malheureusement, l'utilisation de ces tags est probl√©matique, consultez la section ci-dessous qui discute de leur utilit√©.

**Colonnes des clients**

- `Total_Number_of_Reviews_Reviewer_Has_Given`
  - Cela pourrait √™tre un facteur dans un mod√®le de recommandation, par exemple, si vous pouviez d√©terminer que les clients plus prolifiques avec des centaines d'avis √©taient plus susceptibles d'√™tre n√©gatifs que positifs. Cependant, le client de tout avis particulier n'est pas identifi√© par un code unique, et ne peut donc pas √™tre li√© √† un ensemble d'avis. Il y a 30 clients avec 100 avis ou plus, mais il est difficile de voir comment cela peut aider le mod√®le de recommandation.
- `Reviewer_Nationality`
  - Certains pourraient penser que certaines nationalit√©s sont plus susceptibles de donner un avis positif ou n√©gatif en raison d'une inclination nationale. Soyez prudent en int√©grant de telles vues anecdotiques dans vos mod√®les. Ce sont des st√©r√©otypes nationaux (et parfois raciaux), et chaque client √©tait un individu qui a √©crit un avis bas√© sur son exp√©rience. Cela peut avoir √©t√© filtr√© √† travers de nombreux prismes tels que ses s√©jours pr√©c√©dents, la distance parcourue, et son temp√©rament personnel. Penser que leur nationalit√© √©tait la raison d'un score d'avis est difficile √† justifier.

##### Exemples

| Score moyen | Nombre total d'avis | Score du client | Avis n√©gatif                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | Avis positif                     | Tags                                                                                      |
| ----------- | ------------------- | --------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------- | ----------------------------------------------------------------------------------------- |
| 7.8         | 1945                | 2.5             | Cet endroit n'est actuellement pas un h√¥tel mais un chantier de construction. J'ai √©t√© terroris√© d√®s le matin et toute la journ√©e par des bruits de travaux inacceptables alors que je me reposais apr√®s un long voyage et travaillais dans la chambre. Les ouvriers travaillaient toute la journ√©e, par exemple avec des marteaux-piqueurs dans les chambres adjacentes. J'ai demand√© √† changer de chambre mais aucune chambre silencieuse n'√©tait disponible. Pour aggraver les choses, j'ai √©t√© surfactur√©. J'ai quitt√© l'h√¥tel le soir car je devais prendre un vol tr√®s t√¥t et j'ai re√ßu une facture appropri√©e. Un jour plus tard, l'h√¥tel a effectu√© un autre pr√©l√®vement sans mon consentement, sup√©rieur au prix r√©serv√©. C'est un endroit terrible. Ne vous punissez pas en r√©servant ici. | Rien. Endroit terrible. Fuyez.   | Voyage d'affaires Couple Chambre double standard S√©jour de 2 nuits |

Comme vous pouvez le voir, ce client n'a pas eu un s√©jour heureux dans cet h√¥tel. L'h√¥tel a un bon score moyen de 7.8 et 1945 avis, mais ce client lui a attribu√© un score de 2.5 et a √©crit 115 mots sur la n√©gativit√© de son s√©jour. S'il n'a rien √©crit dans la colonne Positive_Review, vous pourriez en d√©duire qu'il n'y avait rien de positif, mais il a √©crit 7 mots d'avertissement. Si nous comptions simplement les mots au lieu de leur signification ou de leur sentiment, nous pourrions avoir une vision biais√©e de l'intention du client. √âtrangement, son score de 2.5 est d√©routant, car si ce s√©jour √† l'h√¥tel √©tait si mauvais, pourquoi lui attribuer des points ? En examinant attentivement l'ensemble de donn√©es, vous verrez que le score le plus bas possible est de 2.5, pas 0. Le score le plus √©lev√© possible est de 10.

##### Tags

Comme mentionn√© ci-dessus, √† premi√®re vue, l'id√©e d'utiliser `Tags` pour cat√©goriser les donn√©es semble logique. Malheureusement, ces tags ne sont pas standardis√©s, ce qui signifie que dans un h√¥tel donn√©, les options pourraient √™tre *Chambre simple*, *Chambre double*, et *Chambre twin*, mais dans le prochain h√¥tel, elles sont *Chambre simple deluxe*, *Chambre queen classique*, et *Chambre king ex√©cutive*. Ces options pourraient √™tre les m√™mes, mais il y a tellement de variations que le choix devient :

1. Tenter de convertir tous les termes en une norme unique, ce qui est tr√®s difficile, car il n'est pas clair quel serait le chemin de conversion dans chaque cas (par exemple, *Chambre simple classique* correspond √† *Chambre simple*, mais *Chambre queen sup√©rieure avec vue sur cour ou ville* est beaucoup plus difficile √† mapper).

1. Nous pouvons adopter une approche NLP et mesurer la fr√©quence de certains termes comme *Solo*, *Voyageur d'affaires*, ou *Famille avec jeunes enfants* lorsqu'ils s'appliquent √† chaque h√¥tel, et int√©grer cela dans la recommandation.

Les tags sont g√©n√©ralement (mais pas toujours) un champ unique contenant une liste de 5 √† 6 valeurs s√©par√©es par des virgules correspondant √† *Type de voyage*, *Type de client*, *Type de chambre*, *Nombre de nuits*, et *Type d'appareil utilis√© pour soumettre l'avis*. Cependant, comme certains clients ne remplissent pas chaque champ (ils peuvent en laisser un vide), les valeurs ne sont pas toujours dans le m√™me ordre.

Par exemple, prenez *Type de groupe*. Il y a 1025 possibilit√©s uniques dans ce champ de la colonne `Tags`, et malheureusement, seulement certaines d'entre elles se r√©f√®rent √† un groupe (certaines concernent le type de chambre, etc.). Si vous filtrez uniquement celles qui mentionnent famille, les r√©sultats contiennent de nombreux types *Chambre familiale*. Si vous incluez le terme *avec*, c'est-√†-dire comptez les valeurs *Famille avec*, les r√©sultats sont meilleurs, avec plus de 80 000 des 515 000 r√©sultats contenant la phrase "Famille avec jeunes enfants" ou "Famille avec enfants plus √¢g√©s".

Cela signifie que la colonne tags n'est pas compl√®tement inutile pour nous, mais il faudra du travail pour la rendre utile.

##### Score moyen des h√¥tels

Il y a un certain nombre d'√©tranget√©s ou de divergences dans l'ensemble de donn√©es que je ne peux pas expliquer, mais elles sont illustr√©es ici pour que vous en soyez conscient lorsque vous construisez vos mod√®les. Si vous trouvez une explication, merci de nous en informer dans la section de discussion !

L'ensemble de donn√©es contient les colonnes suivantes relatives au score moyen et au nombre d'avis :

1. Hotel_Name
2. Additional_Number_of_Scoring
3. Average_Score
4. Total_Number_of_Reviews
5. Reviewer_Score  

L'h√¥tel avec le plus grand nombre d'avis dans cet ensemble de donn√©es est *Britannia International Hotel Canary Wharf* avec 4789 avis sur 515 000. Mais si nous regardons la valeur `Total_Number_of_Reviews` pour cet h√¥tel, elle est de 9086. Vous pourriez en d√©duire qu'il y a beaucoup plus de scores sans avis, donc peut-√™tre devrions-nous ajouter la valeur de la colonne `Additional_Number_of_Scoring`. Cette valeur est de 2682, et en l'ajoutant √† 4789, nous obtenons 7471, ce qui est encore 1615 de moins que le `Total_Number_of_Reviews`.

Si vous prenez la colonne `Average_Score`, vous pourriez en d√©duire qu'il s'agit de la moyenne des avis dans l'ensemble de donn√©es, mais la description sur Kaggle est "*Score moyen de l'h√¥tel, calcul√© sur la base du dernier commentaire de l'ann√©e √©coul√©e*". Cela ne semble pas tr√®s utile, mais nous pouvons calculer notre propre moyenne bas√©e sur les scores des avis dans l'ensemble de donn√©es. En prenant le m√™me h√¥tel comme exemple, le score moyen de l'h√¥tel est donn√© comme 7.1, mais le score calcul√© (moyenne des scores des clients *dans* l'ensemble de donn√©es) est de 6.8. Cela est proche, mais pas identique, et nous pouvons seulement supposer que les scores donn√©s dans les avis `Additional_Number_of_Scoring` ont augment√© la moyenne √† 7.1. Malheureusement, sans moyen de tester ou de prouver cette assertion, il est difficile d'utiliser ou de faire confiance √† `Average_Score`, `Additional_Number_of_Scoring` et `Total_Number_of_Reviews` lorsqu'ils sont bas√©s sur, ou se r√©f√®rent √†, des donn√©es que nous n'avons pas.

Pour compliquer les choses davantage, l'h√¥tel avec le deuxi√®me plus grand nombre d'avis a un score moyen calcul√© de 8.12 et le `Average_Score` de l'ensemble de donn√©es est de 8.1. Ce score correct est-il une co√Øncidence ou le premier h√¥tel est-il une anomalie ?

En supposant que ces h√¥tels pourraient √™tre des valeurs aberrantes, et que peut-√™tre la plupart des valeurs correspondent (mais certaines ne le font pas pour une raison quelconque), nous √©crirons un court programme ensuite pour explorer les valeurs dans l'ensemble de donn√©es et d√©terminer l'utilisation correcte (ou non-utilisation) des valeurs.
> üö® Une note de prudence  
>  
> Lorsque vous travaillez avec cet ensemble de donn√©es, vous √©crirez du code qui calcule quelque chose √† partir du texte sans avoir √† lire ou analyser le texte vous-m√™me. C'est l'essence du NLP : interpr√©ter le sens ou le sentiment sans qu'un humain ait √† le faire. Cependant, il est possible que vous lisiez certains des avis n√©gatifs. Je vous encourage vivement √† ne pas le faire, car ce n'est pas n√©cessaire. Certains d'entre eux sont absurdes ou concernent des critiques n√©gatives de l'h√¥tel qui sont hors de propos, comme "Le temps n'√©tait pas g√©nial", quelque chose qui √©chappe au contr√¥le de l'h√¥tel, ou de quiconque d'ailleurs. Mais il y a aussi un c√¥t√© sombre √† certains avis. Parfois, les avis n√©gatifs sont racistes, sexistes ou √¢gistes. C'est regrettable, mais pr√©visible dans un ensemble de donn√©es extrait d'un site web public. Certains auteurs laissent des avis que vous pourriez trouver de mauvais go√ªt, inconfortables ou bouleversants. Il vaut mieux laisser le code mesurer le sentiment plut√¥t que de les lire vous-m√™me et d'en √™tre affect√©. Cela dit, c'est une minorit√© qui √©crit de telles choses, mais ils existent tout de m√™me.
## Exercice - Exploration des donn√©es
### Charger les donn√©es

C'est suffisant pour examiner visuellement les donn√©es, maintenant vous allez √©crire du code et obtenir des r√©ponses ! Cette section utilise la biblioth√®que pandas. Votre toute premi√®re t√¢che est de vous assurer que vous pouvez charger et lire les donn√©es CSV. La biblioth√®que pandas dispose d'un chargeur CSV rapide, et le r√©sultat est plac√© dans un dataframe, comme dans les le√ßons pr√©c√©dentes. Le CSV que nous chargeons contient plus d'un demi-million de lignes, mais seulement 17 colonnes. Pandas vous offre de nombreuses fa√ßons puissantes d'interagir avec un dataframe, y compris la possibilit√© d'effectuer des op√©rations sur chaque ligne.

√Ä partir de maintenant dans cette le√ßon, il y aura des extraits de code, des explications sur le code et des discussions sur ce que signifient les r√©sultats. Utilisez le fichier _notebook.ipynb_ inclus pour votre code.

Commen√ßons par charger le fichier de donn√©es que vous allez utiliser :

```python
# Load the hotel reviews from CSV
import pandas as pd
import time
# importing time so the start and end time can be used to calculate file loading time
print("Loading data file now, this could take a while depending on file size")
start = time.time()
# df is 'DataFrame' - make sure you downloaded the file to the data folder
df = pd.read_csv('../../data/Hotel_Reviews.csv')
end = time.time()
print("Loading took " + str(round(end - start, 2)) + " seconds")
```

Maintenant que les donn√©es sont charg√©es, nous pouvons effectuer certaines op√©rations dessus. Gardez ce code en haut de votre programme pour la prochaine partie.

## Explorer les donn√©es

Dans ce cas, les donn√©es sont d√©j√† *propres*, ce qui signifie qu'elles sont pr√™tes √† √™tre utilis√©es et ne contiennent pas de caract√®res dans d'autres langues qui pourraient perturber les algorithmes qui attendent uniquement des caract√®res anglais.

‚úÖ Vous pourriez avoir √† travailler avec des donn√©es n√©cessitant un traitement initial pour les formater avant d'appliquer des techniques de PNL, mais pas cette fois. Si vous deviez le faire, comment g√©reriez-vous les caract√®res non anglais ?

Prenez un moment pour vous assurer qu'une fois les donn√©es charg√©es, vous pouvez les explorer avec du code. Il est tr√®s tentant de se concentrer sur les colonnes `Negative_Review` et `Positive_Review`. Elles sont remplies de texte naturel pour vos algorithmes de PNL. Mais attendez ! Avant de plonger dans la PNL et l'analyse de sentiment, vous devriez suivre le code ci-dessous pour v√©rifier si les valeurs donn√©es dans le dataset correspondent aux valeurs que vous calculez avec pandas.

## Op√©rations sur le dataframe

La premi√®re t√¢che de cette le√ßon est de v√©rifier si les assertions suivantes sont correctes en √©crivant du code qui examine le dataframe (sans le modifier).

> Comme pour de nombreuses t√¢ches de programmation, il existe plusieurs fa√ßons de les accomplir, mais un bon conseil est de le faire de la mani√®re la plus simple et la plus facile possible, surtout si cela sera plus compr√©hensible lorsque vous reviendrez √† ce code √† l'avenir. Avec les dataframes, il existe une API compl√®te qui aura souvent une m√©thode efficace pour faire ce que vous voulez.

Consid√©rez les questions suivantes comme des t√¢ches de codage et essayez de r√©pondre sans regarder la solution.

1. Affichez la *forme* du dataframe que vous venez de charger (la forme correspond au nombre de lignes et de colonnes).
2. Calculez le nombre de fr√©quences pour les nationalit√©s des √©valuateurs :
   1. Combien de valeurs distinctes y a-t-il pour la colonne `Reviewer_Nationality` et quelles sont-elles ?
   2. Quelle nationalit√© d'√©valuateur est la plus courante dans le dataset (affichez le pays et le nombre d'√©valuations) ?
   3. Quelles sont les 10 nationalit√©s les plus fr√©quentes suivantes et leur nombre de fr√©quences ?
3. Quel h√¥tel a √©t√© le plus √©valu√© pour chacune des 10 nationalit√©s d'√©valuateurs les plus fr√©quentes ?
4. Combien d'√©valuations y a-t-il par h√¥tel (nombre de fr√©quences des h√¥tels) dans le dataset ?
5. Bien qu'il existe une colonne `Average_Score` pour chaque h√¥tel dans le dataset, vous pouvez √©galement calculer un score moyen (en obtenant la moyenne de tous les scores des √©valuateurs dans le dataset pour chaque h√¥tel). Ajoutez une nouvelle colonne √† votre dataframe avec l'en-t√™te `Calc_Average_Score` contenant cette moyenne calcul√©e.
6. Est-ce que certains h√¥tels ont le m√™me `Average_Score` (arrondi √† une d√©cimale) et `Calc_Average_Score` ?
   1. Essayez d'√©crire une fonction Python qui prend une s√©rie (ligne) comme argument et compare les valeurs, en affichant un message lorsque les valeurs ne sont pas √©gales. Ensuite, utilisez la m√©thode `.apply()` pour traiter chaque ligne avec la fonction.
7. Calculez et affichez combien de lignes ont des valeurs "No Negative" dans la colonne `Negative_Review`.
8. Calculez et affichez combien de lignes ont des valeurs "No Positive" dans la colonne `Positive_Review`.
9. Calculez et affichez combien de lignes ont des valeurs "No Positive" dans la colonne `Positive_Review` **et** des valeurs "No Negative" dans la colonne `Negative_Review`.

### R√©ponses en code

1. Affichez la *forme* du dataframe que vous venez de charger (la forme correspond au nombre de lignes et de colonnes).

   ```python
   print("The shape of the data (rows, cols) is " + str(df.shape))
   > The shape of the data (rows, cols) is (515738, 17)
   ```

2. Calculez le nombre de fr√©quences pour les nationalit√©s des √©valuateurs :

   1. Combien de valeurs distinctes y a-t-il pour la colonne `Reviewer_Nationality` et quelles sont-elles ?
   2. Quelle nationalit√© d'√©valuateur est la plus courante dans le dataset (affichez le pays et le nombre d'√©valuations) ?

   ```python
   # value_counts() creates a Series object that has index and values in this case, the country and the frequency they occur in reviewer nationality
   nationality_freq = df["Reviewer_Nationality"].value_counts()
   print("There are " + str(nationality_freq.size) + " different nationalities")
   # print first and last rows of the Series. Change to nationality_freq.to_string() to print all of the data
   print(nationality_freq) 
   
   There are 227 different nationalities
    United Kingdom               245246
    United States of America      35437
    Australia                     21686
    Ireland                       14827
    United Arab Emirates          10235
                                  ...  
    Comoros                           1
    Palau                             1
    Northern Mariana Islands          1
    Cape Verde                        1
    Guinea                            1
   Name: Reviewer_Nationality, Length: 227, dtype: int64
   ```

   3. Quelles sont les 10 nationalit√©s les plus fr√©quentes suivantes et leur nombre de fr√©quences ?

      ```python
      print("The highest frequency reviewer nationality is " + str(nationality_freq.index[0]).strip() + " with " + str(nationality_freq[0]) + " reviews.")
      # Notice there is a leading space on the values, strip() removes that for printing
      # What is the top 10 most common nationalities and their frequencies?
      print("The next 10 highest frequency reviewer nationalities are:")
      print(nationality_freq[1:11].to_string())
      
      The highest frequency reviewer nationality is United Kingdom with 245246 reviews.
      The next 10 highest frequency reviewer nationalities are:
       United States of America     35437
       Australia                    21686
       Ireland                      14827
       United Arab Emirates         10235
       Saudi Arabia                  8951
       Netherlands                   8772
       Switzerland                   8678
       Germany                       7941
       Canada                        7894
       France                        7296
      ```

3. Quel h√¥tel a √©t√© le plus √©valu√© pour chacune des 10 nationalit√©s d'√©valuateurs les plus fr√©quentes ?

   ```python
   # What was the most frequently reviewed hotel for the top 10 nationalities
   # Normally with pandas you will avoid an explicit loop, but wanted to show creating a new dataframe using criteria (don't do this with large amounts of data because it could be very slow)
   for nat in nationality_freq[:10].index:
      # First, extract all the rows that match the criteria into a new dataframe
      nat_df = df[df["Reviewer_Nationality"] == nat]   
      # Now get the hotel freq
      freq = nat_df["Hotel_Name"].value_counts()
      print("The most reviewed hotel for " + str(nat).strip() + " was " + str(freq.index[0]) + " with " + str(freq[0]) + " reviews.") 
      
   The most reviewed hotel for United Kingdom was Britannia International Hotel Canary Wharf with 3833 reviews.
   The most reviewed hotel for United States of America was Hotel Esther a with 423 reviews.
   The most reviewed hotel for Australia was Park Plaza Westminster Bridge London with 167 reviews.
   The most reviewed hotel for Ireland was Copthorne Tara Hotel London Kensington with 239 reviews.
   The most reviewed hotel for United Arab Emirates was Millennium Hotel London Knightsbridge with 129 reviews.
   The most reviewed hotel for Saudi Arabia was The Cumberland A Guoman Hotel with 142 reviews.
   The most reviewed hotel for Netherlands was Jaz Amsterdam with 97 reviews.
   The most reviewed hotel for Switzerland was Hotel Da Vinci with 97 reviews.
   The most reviewed hotel for Germany was Hotel Da Vinci with 86 reviews.
   The most reviewed hotel for Canada was St James Court A Taj Hotel London with 61 reviews.
   ```

4. Combien d'√©valuations y a-t-il par h√¥tel (nombre de fr√©quences des h√¥tels) dans le dataset ?

   ```python
   # First create a new dataframe based on the old one, removing the uneeded columns
   hotel_freq_df = df.drop(["Hotel_Address", "Additional_Number_of_Scoring", "Review_Date", "Average_Score", "Reviewer_Nationality", "Negative_Review", "Review_Total_Negative_Word_Counts", "Positive_Review", "Review_Total_Positive_Word_Counts", "Total_Number_of_Reviews_Reviewer_Has_Given", "Reviewer_Score", "Tags", "days_since_review", "lat", "lng"], axis = 1)
   
   # Group the rows by Hotel_Name, count them and put the result in a new column Total_Reviews_Found
   hotel_freq_df['Total_Reviews_Found'] = hotel_freq_df.groupby('Hotel_Name').transform('count')
   
   # Get rid of all the duplicated rows
   hotel_freq_df = hotel_freq_df.drop_duplicates(subset = ["Hotel_Name"])
   display(hotel_freq_df) 
   ```
   |                 Hotel_Name                 | Total_Number_of_Reviews | Total_Reviews_Found |
   | :----------------------------------------: | :---------------------: | :-----------------: |
   | Britannia International Hotel Canary Wharf |          9086           |        4789         |
   |    Park Plaza Westminster Bridge London    |          12158          |        4169         |
   |   Copthorne Tara Hotel London Kensington   |          7105           |        3578         |
   |                    ...                     |           ...           |         ...         |
   |       Mercure Paris Porte d Orleans        |           110           |         10          |
   |                Hotel Wagner                |           135           |         10          |
   |            Hotel Gallitzinberg             |           173           |          8          |
   
   Vous remarquerez peut-√™tre que les r√©sultats *compt√©s dans le dataset* ne correspondent pas √† la valeur dans `Total_Number_of_Reviews`. Il est difficile de savoir si cette valeur dans le dataset repr√©sente le nombre total d'√©valuations que l'h√¥tel a re√ßues, mais que toutes n'ont pas √©t√© extraites, ou si un autre calcul a √©t√© effectu√©. `Total_Number_of_Reviews` n'est pas utilis√© dans le mod√®le en raison de cette incertitude.

5. Bien qu'il existe une colonne `Average_Score` pour chaque h√¥tel dans le dataset, vous pouvez √©galement calculer un score moyen (en obtenant la moyenne de tous les scores des √©valuateurs dans le dataset pour chaque h√¥tel). Ajoutez une nouvelle colonne √† votre dataframe avec l'en-t√™te `Calc_Average_Score` contenant cette moyenne calcul√©e. Affichez les colonnes `Hotel_Name`, `Average_Score` et `Calc_Average_Score`.

   ```python
   # define a function that takes a row and performs some calculation with it
   def get_difference_review_avg(row):
     return row["Average_Score"] - row["Calc_Average_Score"]
   
   # 'mean' is mathematical word for 'average'
   df['Calc_Average_Score'] = round(df.groupby('Hotel_Name').Reviewer_Score.transform('mean'), 1)
   
   # Add a new column with the difference between the two average scores
   df["Average_Score_Difference"] = df.apply(get_difference_review_avg, axis = 1)
   
   # Create a df without all the duplicates of Hotel_Name (so only 1 row per hotel)
   review_scores_df = df.drop_duplicates(subset = ["Hotel_Name"])
   
   # Sort the dataframe to find the lowest and highest average score difference
   review_scores_df = review_scores_df.sort_values(by=["Average_Score_Difference"])
   
   display(review_scores_df[["Average_Score_Difference", "Average_Score", "Calc_Average_Score", "Hotel_Name"]])
   ```

   Vous pourriez √©galement vous demander pourquoi la valeur `Average_Score` est parfois diff√©rente du score moyen calcul√©. Comme nous ne pouvons pas savoir pourquoi certaines valeurs correspondent, mais d'autres pr√©sentent une diff√©rence, il est plus s√ªr dans ce cas d'utiliser les scores des √©valuations que nous avons pour calculer la moyenne nous-m√™mes. Cela dit, les diff√©rences sont g√©n√©ralement tr√®s petites, voici les h√¥tels avec la plus grande d√©viation entre la moyenne du dataset et la moyenne calcul√©e :

   | Average_Score_Difference | Average_Score | Calc_Average_Score |                                  Hotel_Name |
   | :----------------------: | :-----------: | :----------------: | ------------------------------------------: |
   |           -0.8           |      7.7      |        8.5         |                  Best Western Hotel Astoria |
   |           -0.7           |      8.8      |        9.5         | Hotel Stendhal Place Vend me Paris MGallery |
   |           -0.7           |      7.5      |        8.2         |               Mercure Paris Porte d Orleans |
   |           -0.7           |      7.9      |        8.6         |             Renaissance Paris Vendome Hotel |
   |           -0.5           |      7.0      |        7.5         |                         Hotel Royal Elys es |
   |           ...            |      ...      |        ...         |                                         ... |
   |           0.7            |      7.5      |        6.8         |     Mercure Paris Op ra Faubourg Montmartre |
   |           0.8            |      7.1      |        6.3         |      Holiday Inn Paris Montparnasse Pasteur |
   |           0.9            |      6.8      |        5.9         |                               Villa Eugenie |
   |           0.9            |      8.6      |        7.7         |   MARQUIS Faubourg St Honor Relais Ch teaux |
   |           1.3            |      7.2      |        5.9         |                          Kube Hotel Ice Bar |

   Avec seulement 1 h√¥tel ayant une diff√©rence de score sup√©rieure √† 1, cela signifie que nous pouvons probablement ignorer la diff√©rence et utiliser le score moyen calcul√©.

6. Calculez et affichez combien de lignes ont des valeurs "No Negative" dans la colonne `Negative_Review`.

7. Calculez et affichez combien de lignes ont des valeurs "No Positive" dans la colonne `Positive_Review`.

8. Calculez et affichez combien de lignes ont des valeurs "No Positive" dans la colonne `Positive_Review` **et** des valeurs "No Negative" dans la colonne `Negative_Review`.

   ```python
   # with lambdas:
   start = time.time()
   no_negative_reviews = df.apply(lambda x: True if x['Negative_Review'] == "No Negative" else False , axis=1)
   print("Number of No Negative reviews: " + str(len(no_negative_reviews[no_negative_reviews == True].index)))
   
   no_positive_reviews = df.apply(lambda x: True if x['Positive_Review'] == "No Positive" else False , axis=1)
   print("Number of No Positive reviews: " + str(len(no_positive_reviews[no_positive_reviews == True].index)))
   
   both_no_reviews = df.apply(lambda x: True if x['Negative_Review'] == "No Negative" and x['Positive_Review'] == "No Positive" else False , axis=1)
   print("Number of both No Negative and No Positive reviews: " + str(len(both_no_reviews[both_no_reviews == True].index)))
   end = time.time()
   print("Lambdas took " + str(round(end - start, 2)) + " seconds")
   
   Number of No Negative reviews: 127890
   Number of No Positive reviews: 35946
   Number of both No Negative and No Positive reviews: 127
   Lambdas took 9.64 seconds
   ```

## Une autre m√©thode

Une autre m√©thode pour compter les √©l√©ments sans Lambdas, et utiliser sum pour compter les lignes :

   ```python
   # without lambdas (using a mixture of notations to show you can use both)
   start = time.time()
   no_negative_reviews = sum(df.Negative_Review == "No Negative")
   print("Number of No Negative reviews: " + str(no_negative_reviews))
   
   no_positive_reviews = sum(df["Positive_Review"] == "No Positive")
   print("Number of No Positive reviews: " + str(no_positive_reviews))
   
   both_no_reviews = sum((df.Negative_Review == "No Negative") & (df.Positive_Review == "No Positive"))
   print("Number of both No Negative and No Positive reviews: " + str(both_no_reviews))
   
   end = time.time()
   print("Sum took " + str(round(end - start, 2)) + " seconds")
   
   Number of No Negative reviews: 127890
   Number of No Positive reviews: 35946
   Number of both No Negative and No Positive reviews: 127
   Sum took 0.19 seconds
   ```

   Vous avez peut-√™tre remarqu√© qu'il y a 127 lignes qui ont √† la fois des valeurs "No Negative" et "No Positive" pour les colonnes `Negative_Review` et `Positive_Review` respectivement. Cela signifie que l'√©valuateur a donn√© √† l'h√¥tel un score num√©rique, mais a refus√© d'√©crire une √©valuation positive ou n√©gative. Heureusement, cela repr√©sente une petite quantit√© de lignes (127 sur 515738, soit 0,02 %), donc cela ne devrait pas fausser notre mod√®le ou nos r√©sultats dans une direction particuli√®re, mais vous pourriez ne pas avoir attendu qu'un dataset d'√©valuations contienne des lignes sans √©valuations, donc cela vaut la peine d'explorer les donn√©es pour d√©couvrir des lignes comme celle-ci.

Maintenant que vous avez explor√© le dataset, dans la prochaine le√ßon, vous filtrerez les donn√©es et ajouterez une analyse de sentiment.

---
## üöÄD√©fi

Cette le√ßon d√©montre, comme nous l'avons vu dans les le√ßons pr√©c√©dentes, √† quel point il est crucial de comprendre vos donn√©es et leurs particularit√©s avant d'effectuer des op√©rations dessus. Les donn√©es bas√©es sur du texte, en particulier, n√©cessitent une attention particuli√®re. Explorez divers datasets riches en texte et voyez si vous pouvez d√©couvrir des zones qui pourraient introduire des biais ou des sentiments biais√©s dans un mod√®le.

## [Quiz post-lecture](https://ff-quizzes.netlify.app/en/ml/)

## R√©vision & Auto-apprentissage

Suivez [ce parcours d'apprentissage sur la PNL](https://docs.microsoft.com/learn/paths/explore-natural-language-processing/?WT.mc_id=academic-77952-leestott) pour d√©couvrir des outils √† essayer lors de la cr√©ation de mod√®les bas√©s sur la parole et le texte.

## Devoir 

[NLTK](assignment.md)

---

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction professionnelle effectu√©e par un humain. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.