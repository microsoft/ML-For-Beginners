<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3c4738bb0836dd838c552ab9cab7e09d",
  "translation_date": "2025-09-04T00:37:43+00:00",
  "source_file": "6-NLP/4-Hotel-Reviews-1/README.md",
  "language_code": "fr"
}
-->
# Analyse de sentiment avec des avis d'h√¥tels - traitement des donn√©es

Dans cette section, vous utiliserez les techniques des le√ßons pr√©c√©dentes pour effectuer une analyse exploratoire des donn√©es sur un grand ensemble de donn√©es. Une fois que vous aurez une bonne compr√©hension de l'utilit√© des diff√©rentes colonnes, vous apprendrez :

- comment supprimer les colonnes inutiles
- comment calculer de nouvelles donn√©es √† partir des colonnes existantes
- comment sauvegarder l'ensemble de donn√©es r√©sultant pour l'utiliser dans le d√©fi final

## [Quiz avant la le√ßon](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/37/)

### Introduction

Jusqu'√† pr√©sent, vous avez appris que les donn√©es textuelles sont tr√®s diff√©rentes des donn√©es num√©riques. Si le texte a √©t√© √©crit ou prononc√© par un humain, il peut √™tre analys√© pour trouver des motifs, des fr√©quences, des sentiments et des significations. Cette le√ßon vous plonge dans un v√©ritable ensemble de donn√©es avec un d√©fi r√©el : **[515K Hotel Reviews Data in Europe](https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe)**, qui inclut une [licence CC0 : Domaine Public](https://creativecommons.org/publicdomain/zero/1.0/). Ces donn√©es ont √©t√© extraites de Booking.com √† partir de sources publiques. Le cr√©ateur de l'ensemble de donn√©es est Jiashen Liu.

### Pr√©paration

Vous aurez besoin de :

* La capacit√© d'ex√©cuter des notebooks .ipynb avec Python 3
* pandas
* NLTK, [que vous devez installer localement](https://www.nltk.org/install.html)
* L'ensemble de donn√©es disponible sur Kaggle [515K Hotel Reviews Data in Europe](https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe). Il p√®se environ 230 Mo une fois d√©compress√©. T√©l√©chargez-le dans le dossier racine `/data` associ√© √† ces le√ßons sur le traitement du langage naturel.

## Analyse exploratoire des donn√©es

Ce d√©fi suppose que vous construisez un bot de recommandation d'h√¥tels en utilisant l'analyse de sentiment et les notes des avis des clients. L'ensemble de donn√©es que vous utiliserez comprend des avis sur 1493 h√¥tels diff√©rents dans 6 villes.

En utilisant Python, un ensemble de donn√©es d'avis d'h√¥tels et l'analyse de sentiment de NLTK, vous pourriez d√©couvrir :

* Quels sont les mots et expressions les plus fr√©quemment utilis√©s dans les avis ?
* Les *tags* officiels d√©crivant un h√¥tel sont-ils corr√©l√©s avec les notes des avis (par exemple, y a-t-il plus d'avis n√©gatifs pour un h√¥tel particulier pour *Famille avec jeunes enfants* que pour *Voyageur solo*, ce qui pourrait indiquer qu'il est plus adapt√© aux *Voyageurs solos*) ?
* Les scores de sentiment de NLTK "s'accordent-ils" avec les notes num√©riques des avis des clients ?

#### Ensemble de donn√©es

Explorons l'ensemble de donn√©es que vous avez t√©l√©charg√© et sauvegard√© localement. Ouvrez le fichier dans un √©diteur comme VS Code ou m√™me Excel.

Les en-t√™tes de l'ensemble de donn√©es sont les suivants :

*Hotel_Address, Additional_Number_of_Scoring, Review_Date, Average_Score, Hotel_Name, Reviewer_Nationality, Negative_Review, Review_Total_Negative_Word_Counts, Total_Number_of_Reviews, Positive_Review, Review_Total_Positive_Word_Counts, Total_Number_of_Reviews_Reviewer_Has_Given, Reviewer_Score, Tags, days_since_review, lat, lng*

Voici une pr√©sentation regroup√©e pour faciliter l'examen :  
##### Colonnes des h√¥tels

* `Hotel_Name`, `Hotel_Address`, `lat` (latitude), `lng` (longitude)
  * En utilisant *lat* et *lng*, vous pourriez tracer une carte avec Python montrant les emplacements des h√¥tels (peut-√™tre cod√©s par couleur pour les avis n√©gatifs et positifs).
  * Hotel_Address n'est pas √©videmment utile pour nous, et nous remplacerons probablement cela par un pays pour faciliter le tri et la recherche.

**Colonnes des m√©ta-avis des h√¥tels**

* `Average_Score`
  * Selon le cr√©ateur de l'ensemble de donn√©es, cette colonne repr√©sente la *note moyenne de l'h√¥tel, calcul√©e sur la base du dernier commentaire de l'ann√©e √©coul√©e*. Cela semble √™tre une mani√®re inhabituelle de calculer la note, mais ce sont les donn√©es extraites, donc nous pouvons les prendre telles quelles pour l'instant.

  ‚úÖ En vous basant sur les autres colonnes de cet ensemble de donn√©es, pouvez-vous penser √† une autre mani√®re de calculer la note moyenne ?

* `Total_Number_of_Reviews`
  * Le nombre total d'avis re√ßus par cet h√¥tel - il n'est pas clair (sans √©crire du code) si cela se r√©f√®re aux avis dans l'ensemble de donn√©es.
* `Additional_Number_of_Scoring`
  * Cela signifie qu'une note a √©t√© donn√©e, mais aucun avis positif ou n√©gatif n'a √©t√© √©crit par le client.

**Colonnes des avis**

- `Reviewer_Score`
  - C'est une valeur num√©rique avec au maximum 1 chiffre apr√®s la virgule, comprise entre les valeurs minimales et maximales de 2.5 et 10.
  - Il n'est pas expliqu√© pourquoi 2.5 est la note minimale possible.
- `Negative_Review`
  - Si un client n'a rien √©crit, ce champ contiendra "**No Negative**".
  - Notez qu'un client peut √©crire un avis positif dans la colonne des avis n√©gatifs (par exemple, "il n'y a rien de mauvais dans cet h√¥tel").
- `Review_Total_Negative_Word_Counts`
  - Un nombre plus √©lev√© de mots n√©gatifs indique une note plus basse (sans v√©rifier la tonalit√©).
- `Positive_Review`
  - Si un client n'a rien √©crit, ce champ contiendra "**No Positive**".
  - Notez qu'un client peut √©crire un avis n√©gatif dans la colonne des avis positifs (par exemple, "il n'y a rien de bien dans cet h√¥tel").
- `Review_Total_Positive_Word_Counts`
  - Un nombre plus √©lev√© de mots positifs indique une note plus √©lev√©e (sans v√©rifier la tonalit√©).
- `Review_Date` et `days_since_review`
  - Une mesure de fra√Æcheur ou d'anciennet√© pourrait √™tre appliqu√©e √† un avis (les avis plus anciens pourraient ne pas √™tre aussi pr√©cis que les plus r√©cents en raison de changements dans la gestion de l'h√¥tel, de r√©novations, de l'ajout d'une piscine, etc.).
- `Tags`
  - Ce sont de courtes descriptions qu'un client peut s√©lectionner pour d√©crire le type de client qu'il √©tait (par exemple, solo ou en famille), le type de chambre qu'il avait, la dur√©e du s√©jour et comment l'avis a √©t√© soumis.
  - Malheureusement, l'utilisation de ces tags est probl√©matique, consultez la section ci-dessous qui discute de leur utilit√©.

**Colonnes des clients**

- `Total_Number_of_Reviews_Reviewer_Has_Given`
  - Cela pourrait √™tre un facteur dans un mod√®le de recommandation, par exemple, si vous pouviez d√©terminer que les clients plus prolifiques avec des centaines d'avis √©taient plus susceptibles d'√™tre n√©gatifs que positifs. Cependant, le client de tout avis particulier n'est pas identifi√© par un code unique, et ne peut donc pas √™tre li√© √† un ensemble d'avis. Il y a 30 clients avec 100 avis ou plus, mais il est difficile de voir comment cela peut aider le mod√®le de recommandation.
- `Reviewer_Nationality`
  - Certaines personnes pourraient penser que certaines nationalit√©s sont plus susceptibles de donner un avis positif ou n√©gatif en raison d'une inclination nationale. Soyez prudent en int√©grant de telles vues anecdotiques dans vos mod√®les. Ce sont des st√©r√©otypes nationaux (et parfois raciaux), et chaque client est un individu qui a √©crit un avis bas√© sur son exp√©rience. Cela peut avoir √©t√© filtr√© par de nombreux prismes tels que leurs s√©jours pr√©c√©dents, la distance parcourue et leur temp√©rament personnel. Penser que leur nationalit√© est la raison d'une note d'avis est difficile √† justifier.

##### Exemples

| Average  Score | Total Number   Reviews | Reviewer   Score | Negative <br />Review                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | Positive   Review                 | Tags                                                                                      |
| -------------- | ---------------------- | ---------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------- | ----------------------------------------------------------------------------------------- |
| 7.8            | 1945                   | 2.5              | Cet endroit n'est actuellement pas un h√¥tel mais un chantier de construction. J'ai √©t√© terroris√© d√®s le matin et toute la journ√©e par des bruits de travaux inacceptables alors que je me reposais apr√®s un long voyage et travaillais dans la chambre. Les ouvriers travaillaient toute la journ√©e, par exemple avec des marteaux-piqueurs dans les chambres adjacentes. J'ai demand√© √† changer de chambre, mais aucune chambre silencieuse n'√©tait disponible. Pour aggraver les choses, j'ai √©t√© surfactur√©. J'ai quitt√© l'h√¥tel le soir car je devais partir tr√®s t√¥t pour un vol et j'ai re√ßu une facture appropri√©e. Un jour plus tard, l'h√¥tel a effectu√© un autre pr√©l√®vement sans mon consentement, d√©passant le prix r√©serv√©. C'est un endroit terrible. Ne vous infligez pas cela en r√©servant ici. | Rien. Endroit terrible. Fuyez. | Voyage d'affaires, Couple, Chambre double standard, S√©jour de 2 nuits |

Comme vous pouvez le voir, ce client n'a pas eu un s√©jour heureux dans cet h√¥tel. L'h√¥tel a une bonne note moyenne de 7.8 et 1945 avis, mais ce client lui a donn√© 2.5 et a √©crit 115 mots sur la n√©gativit√© de son s√©jour. S'il n'avait rien √©crit dans la colonne Positive_Review, vous pourriez supposer qu'il n'y avait rien de positif, mais il a √©crit 7 mots d'avertissement. Si nous comptions simplement les mots au lieu de leur signification ou de leur sentiment, nous pourrions avoir une vision biais√©e de l'intention du client. √âtrangement, leur note de 2.5 est d√©routante, car si ce s√©jour √† l'h√¥tel √©tait si mauvais, pourquoi lui donner des points ? En examinant de pr√®s l'ensemble de donn√©es, vous verrez que la note minimale possible est de 2.5, pas 0. La note maximale possible est de 10.

##### Tags

Comme mentionn√© ci-dessus, √† premi√®re vue, l'id√©e d'utiliser `Tags` pour cat√©goriser les donn√©es semble logique. Malheureusement, ces tags ne sont pas standardis√©s, ce qui signifie que dans un h√¥tel donn√©, les options pourraient √™tre *Chambre simple*, *Chambre double*, et *Chambre twin*, mais dans un autre h√¥tel, elles sont *Chambre simple de luxe*, *Chambre classique avec lit queen*, et *Chambre ex√©cutive avec lit king*. Cela pourrait d√©signer les m√™mes choses, mais il y a tellement de variations que le choix devient :

1. Tenter de convertir tous les termes en une norme unique, ce qui est tr√®s difficile, car il n'est pas clair quel serait le chemin de conversion dans chaque cas (par exemple, *Chambre simple classique* correspond √† *Chambre simple*, mais *Chambre sup√©rieure avec lit queen et vue sur cour ou ville* est beaucoup plus difficile √† mapper).

1. Nous pouvons adopter une approche NLP et mesurer la fr√©quence de certains termes comme *Solo*, *Voyageur d'affaires*, ou *Famille avec jeunes enfants* lorsqu'ils s'appliquent √† chaque h√¥tel, et int√©grer cela dans le mod√®le de recommandation.

Les tags sont g√©n√©ralement (mais pas toujours) un champ unique contenant une liste de 5 √† 6 valeurs s√©par√©es par des virgules correspondant √† *Type de voyage*, *Type de clients*, *Type de chambre*, *Nombre de nuits*, et *Type d'appareil utilis√© pour soumettre l'avis*. Cependant, comme certains clients ne remplissent pas chaque champ (ils peuvent en laisser un vide), les valeurs ne sont pas toujours dans le m√™me ordre.

Par exemple, prenez *Type de groupe*. Il y a 1025 possibilit√©s uniques dans ce champ de la colonne `Tags`, et malheureusement, seules certaines d'entre elles se r√©f√®rent √† un groupe (certaines concernent le type de chambre, etc.). Si vous filtrez uniquement celles qui mentionnent famille, les r√©sultats contiennent de nombreux types de chambres *Familiale*. Si vous incluez le terme *avec*, c'est-√†-dire comptez les valeurs *Famille avec*, les r√©sultats sont meilleurs, avec plus de 80 000 des 515 000 r√©sultats contenant la phrase "Famille avec jeunes enfants" ou "Famille avec enfants plus √¢g√©s".

Cela signifie que la colonne tags n'est pas compl√®tement inutile pour nous, mais il faudra du travail pour la rendre utile.

##### Note moyenne des h√¥tels

Il y a un certain nombre d'√©tranget√©s ou de divergences dans l'ensemble de donn√©es que je ne peux pas expliquer, mais elles sont illustr√©es ici pour que vous en soyez conscient lors de la construction de vos mod√®les. Si vous trouvez une explication, merci de nous en faire part dans la section de discussion !

L'ensemble de donn√©es contient les colonnes suivantes relatives √† la note moyenne et au nombre d'avis :

1. Hotel_Name
2. Additional_Number_of_Scoring
3. Average_Score
4. Total_Number_of_Reviews
5. Reviewer_Score  

L'h√¥tel unique avec le plus grand nombre d'avis dans cet ensemble de donn√©es est *Britannia International Hotel Canary Wharf* avec 4789 avis sur 515 000. Mais si nous regardons la valeur `Total_Number_of_Reviews` pour cet h√¥tel, elle est de 9086. Vous pourriez supposer qu'il y a beaucoup plus de notes sans avis, donc peut-√™tre devrions-nous ajouter la valeur de la colonne `Additional_Number_of_Scoring`. Cette valeur est de 2682, et en l'ajoutant √† 4789, nous obtenons 7471, ce qui est encore 1615 de moins que le `Total_Number_of_Reviews`.

Si vous prenez la colonne `Average_Score`, vous pourriez supposer qu'il s'agit de la moyenne des avis dans l'ensemble de donn√©es, mais la description de Kaggle est "*Note moyenne de l'h√¥tel, calcul√©e sur la base du dernier commentaire de l'ann√©e √©coul√©e*". Cela ne semble pas tr√®s utile, mais nous pouvons calculer notre propre moyenne bas√©e sur les notes des avis dans l'ensemble de donn√©es. En utilisant le m√™me h√¥tel comme exemple, la note moyenne de l'h√¥tel est donn√©e comme 7.1, mais la note calcul√©e (moyenne des notes des clients *dans* l'ensemble de donn√©es) est de 6.8. Cela est proche, mais pas identique, et nous pouvons seulement supposer que les notes donn√©es dans les avis `Additional_Number_of_Scoring` ont augment√© la moyenne √† 7.1. Malheureusement, sans moyen de tester ou de prouver cette assertion, il est difficile d'utiliser ou de faire confiance √† `Average_Score`, `Additional_Number_of_Scoring` et `Total_Number_of_Reviews` lorsqu'ils sont bas√©s sur, ou se r√©f√®rent √†, des donn√©es que nous n'avons pas.

Pour compliquer encore les choses, l'h√¥tel avec le deuxi√®me plus grand nombre d'avis a une note moyenne calcul√©e de 8.12 et la `Average_Score` de l'ensemble de donn√©es est de 8.1. Cette note correcte est-elle une co√Øncidence ou le premier h√¥tel est-il une anomalie ?
Sur la possibilit√© que cet h√¥tel soit une anomalie, et que peut-√™tre la plupart des valeurs correspondent (mais que certaines ne le font pas pour une raison quelconque), nous allons √©crire un petit programme pour explorer les valeurs du jeu de donn√©es et d√©terminer l'utilisation correcte (ou non-utilisation) des valeurs.

> üö® Une note de prudence
>
> En travaillant avec ce jeu de donn√©es, vous √©crirez du code qui calcule quelque chose √† partir du texte sans avoir √† lire ou analyser le texte vous-m√™me. C'est l'essence du NLP : interpr√©ter le sens ou le sentiment sans qu'un humain ait √† le faire. Cependant, il est possible que vous lisiez certains des avis n√©gatifs. Je vous encourage √† ne pas le faire, car ce n'est pas n√©cessaire. Certains d'entre eux sont absurdes ou des critiques n√©gatives sans rapport avec l'h√¥tel, comme "Le temps n'√©tait pas g√©nial", quelque chose qui √©chappe au contr√¥le de l'h√¥tel, ou de quiconque d'ailleurs. Mais il y a aussi un c√¥t√© sombre √† certains avis. Parfois, les avis n√©gatifs sont racistes, sexistes ou √¢gistes. C'est regrettable mais attendu dans un jeu de donn√©es extrait d'un site web public. Certains auteurs laissent des avis que vous pourriez trouver de mauvais go√ªt, inconfortables ou bouleversants. Il vaut mieux laisser le code mesurer le sentiment plut√¥t que de les lire vous-m√™me et d'en √™tre affect√©. Cela dit, c'est une minorit√© qui √©crit de telles choses, mais ils existent tout de m√™me.

## Exercice - Exploration des donn√©es
### Charger les donn√©es

C'est suffisant pour examiner les donn√©es visuellement, maintenant vous allez √©crire du code et obtenir des r√©ponses‚ÄØ! Cette section utilise la biblioth√®que pandas. Votre toute premi√®re t√¢che est de vous assurer que vous pouvez charger et lire les donn√©es CSV. La biblioth√®que pandas dispose d'un chargeur CSV rapide, et le r√©sultat est plac√© dans un dataframe, comme dans les le√ßons pr√©c√©dentes. Le fichier CSV que nous chargeons contient plus d'un demi-million de lignes, mais seulement 17 colonnes. Pandas vous offre de nombreuses fa√ßons puissantes d'interagir avec un dataframe, y compris la possibilit√© d'effectuer des op√©rations sur chaque ligne.

√Ä partir de maintenant dans cette le√ßon, il y aura des extraits de code, des explications sur le code et des discussions sur ce que signifient les r√©sultats. Utilisez le fichier _notebook.ipynb_ inclus pour votre code.

Commen√ßons par charger le fichier de donn√©es que vous utiliserez‚ÄØ:

```python
# Load the hotel reviews from CSV
import pandas as pd
import time
# importing time so the start and end time can be used to calculate file loading time
print("Loading data file now, this could take a while depending on file size")
start = time.time()
# df is 'DataFrame' - make sure you downloaded the file to the data folder
df = pd.read_csv('../../data/Hotel_Reviews.csv')
end = time.time()
print("Loading took " + str(round(end - start, 2)) + " seconds")
```

Maintenant que les donn√©es sont charg√©es, nous pouvons effectuer certaines op√©rations dessus. Gardez ce code en haut de votre programme pour la prochaine partie.

## Explorer les donn√©es

Dans ce cas, les donn√©es sont d√©j√† *propres*, ce qui signifie qu'elles sont pr√™tes √† √™tre utilis√©es et ne contiennent pas de caract√®res dans d'autres langues qui pourraient perturber les algorithmes s'attendant uniquement √† des caract√®res anglais.

‚úÖ Vous pourriez avoir √† travailler avec des donn√©es n√©cessitant un traitement initial pour les formater avant d'appliquer des techniques NLP, mais pas cette fois. Si vous deviez le faire, comment g√©reriez-vous les caract√®res non anglais‚ÄØ?

Prenez un moment pour vous assurer qu'une fois les donn√©es charg√©es, vous pouvez les explorer avec du code. Il est tr√®s tentant de se concentrer sur les colonnes `Negative_Review` et `Positive_Review`. Elles sont remplies de texte naturel pour vos algorithmes NLP √† traiter. Mais attendez‚ÄØ! Avant de vous lancer dans le NLP et l'analyse de sentiment, vous devriez suivre le code ci-dessous pour v√©rifier si les valeurs donn√©es dans le jeu de donn√©es correspondent aux valeurs que vous calculez avec pandas.

## Op√©rations sur le dataframe

La premi√®re t√¢che de cette le√ßon est de v√©rifier si les affirmations suivantes sont correctes en √©crivant du code qui examine le dataframe (sans le modifier).

> Comme pour de nombreuses t√¢ches de programmation, il existe plusieurs fa√ßons de les accomplir, mais un bon conseil est de le faire de la mani√®re la plus simple et la plus facile possible, surtout si cela sera plus compr√©hensible lorsque vous reviendrez √† ce code √† l'avenir. Avec les dataframes, il existe une API compl√®te qui aura souvent un moyen efficace de faire ce que vous voulez.

Traitez les questions suivantes comme des t√¢ches de codage et essayez d'y r√©pondre sans regarder la solution.

1. Affichez la *forme* du dataframe que vous venez de charger (la forme correspond au nombre de lignes et de colonnes).
2. Calculez la fr√©quence des nationalit√©s des auteurs d'avis :
   1. Combien de valeurs distinctes y a-t-il pour la colonne `Reviewer_Nationality` et quelles sont-elles‚ÄØ?
   2. Quelle nationalit√© d'auteur d'avis est la plus courante dans le jeu de donn√©es (imprimez le pays et le nombre d'avis)‚ÄØ?
   3. Quelles sont les 10 nationalit√©s les plus fr√©quentes suivantes, et leur fr√©quence‚ÄØ?
3. Quel h√¥tel a √©t√© le plus fr√©quemment √©valu√© pour chacune des 10 nationalit√©s d'auteurs d'avis les plus fr√©quentes‚ÄØ?
4. Combien d'avis y a-t-il par h√¥tel (fr√©quence des h√¥tels) dans le jeu de donn√©es‚ÄØ?
5. Bien qu'il existe une colonne `Average_Score` pour chaque h√¥tel dans le jeu de donn√©es, vous pouvez √©galement calculer un score moyen (en obtenant la moyenne de tous les scores des auteurs d'avis dans le jeu de donn√©es pour chaque h√¥tel). Ajoutez une nouvelle colonne √† votre dataframe avec l'en-t√™te `Calc_Average_Score` contenant cette moyenne calcul√©e.
6. Certains h√¥tels ont-ils le m√™me `Average_Score` (arrondi √† 1 d√©cimale) que le `Calc_Average_Score`‚ÄØ?
   1. Essayez d'√©crire une fonction Python qui prend une Series (ligne) comme argument et compare les valeurs, en imprimant un message lorsque les valeurs ne sont pas √©gales. Ensuite, utilisez la m√©thode `.apply()` pour traiter chaque ligne avec la fonction.
7. Calculez et affichez combien de lignes ont des valeurs "No Negative" dans la colonne `Negative_Review`.
8. Calculez et affichez combien de lignes ont des valeurs "No Positive" dans la colonne `Positive_Review`.
9. Calculez et affichez combien de lignes ont des valeurs "No Positive" dans la colonne `Positive_Review` **et** des valeurs "No Negative" dans la colonne `Negative_Review`.

### R√©ponses en code

1. Affichez la *forme* du dataframe que vous venez de charger (la forme correspond au nombre de lignes et de colonnes).

   ```python
   print("The shape of the data (rows, cols) is " + str(df.shape))
   > The shape of the data (rows, cols) is (515738, 17)
   ```

2. Calculez la fr√©quence des nationalit√©s des auteurs d'avis :

   1. Combien de valeurs distinctes y a-t-il pour la colonne `Reviewer_Nationality` et quelles sont-elles‚ÄØ?
   2. Quelle nationalit√© d'auteur d'avis est la plus courante dans le jeu de donn√©es (imprimez le pays et le nombre d'avis)‚ÄØ?

   ```python
   # value_counts() creates a Series object that has index and values in this case, the country and the frequency they occur in reviewer nationality
   nationality_freq = df["Reviewer_Nationality"].value_counts()
   print("There are " + str(nationality_freq.size) + " different nationalities")
   # print first and last rows of the Series. Change to nationality_freq.to_string() to print all of the data
   print(nationality_freq) 
   
   There are 227 different nationalities
    United Kingdom               245246
    United States of America      35437
    Australia                     21686
    Ireland                       14827
    United Arab Emirates          10235
                                  ...  
    Comoros                           1
    Palau                             1
    Northern Mariana Islands          1
    Cape Verde                        1
    Guinea                            1
   Name: Reviewer_Nationality, Length: 227, dtype: int64
   ```

   3. Quelles sont les 10 nationalit√©s les plus fr√©quentes suivantes, et leur fr√©quence‚ÄØ?

      ```python
      print("The highest frequency reviewer nationality is " + str(nationality_freq.index[0]).strip() + " with " + str(nationality_freq[0]) + " reviews.")
      # Notice there is a leading space on the values, strip() removes that for printing
      # What is the top 10 most common nationalities and their frequencies?
      print("The next 10 highest frequency reviewer nationalities are:")
      print(nationality_freq[1:11].to_string())
      
      The highest frequency reviewer nationality is United Kingdom with 245246 reviews.
      The next 10 highest frequency reviewer nationalities are:
       United States of America     35437
       Australia                    21686
       Ireland                      14827
       United Arab Emirates         10235
       Saudi Arabia                  8951
       Netherlands                   8772
       Switzerland                   8678
       Germany                       7941
       Canada                        7894
       France                        7296
      ```

3. Quel h√¥tel a √©t√© le plus fr√©quemment √©valu√© pour chacune des 10 nationalit√©s d'auteurs d'avis les plus fr√©quentes‚ÄØ?

   ```python
   # What was the most frequently reviewed hotel for the top 10 nationalities
   # Normally with pandas you will avoid an explicit loop, but wanted to show creating a new dataframe using criteria (don't do this with large amounts of data because it could be very slow)
   for nat in nationality_freq[:10].index:
      # First, extract all the rows that match the criteria into a new dataframe
      nat_df = df[df["Reviewer_Nationality"] == nat]   
      # Now get the hotel freq
      freq = nat_df["Hotel_Name"].value_counts()
      print("The most reviewed hotel for " + str(nat).strip() + " was " + str(freq.index[0]) + " with " + str(freq[0]) + " reviews.") 
      
   The most reviewed hotel for United Kingdom was Britannia International Hotel Canary Wharf with 3833 reviews.
   The most reviewed hotel for United States of America was Hotel Esther a with 423 reviews.
   The most reviewed hotel for Australia was Park Plaza Westminster Bridge London with 167 reviews.
   The most reviewed hotel for Ireland was Copthorne Tara Hotel London Kensington with 239 reviews.
   The most reviewed hotel for United Arab Emirates was Millennium Hotel London Knightsbridge with 129 reviews.
   The most reviewed hotel for Saudi Arabia was The Cumberland A Guoman Hotel with 142 reviews.
   The most reviewed hotel for Netherlands was Jaz Amsterdam with 97 reviews.
   The most reviewed hotel for Switzerland was Hotel Da Vinci with 97 reviews.
   The most reviewed hotel for Germany was Hotel Da Vinci with 86 reviews.
   The most reviewed hotel for Canada was St James Court A Taj Hotel London with 61 reviews.
   ```

4. Combien d'avis y a-t-il par h√¥tel (fr√©quence des h√¥tels) dans le jeu de donn√©es‚ÄØ?

   ```python
   # First create a new dataframe based on the old one, removing the uneeded columns
   hotel_freq_df = df.drop(["Hotel_Address", "Additional_Number_of_Scoring", "Review_Date", "Average_Score", "Reviewer_Nationality", "Negative_Review", "Review_Total_Negative_Word_Counts", "Positive_Review", "Review_Total_Positive_Word_Counts", "Total_Number_of_Reviews_Reviewer_Has_Given", "Reviewer_Score", "Tags", "days_since_review", "lat", "lng"], axis = 1)
   
   # Group the rows by Hotel_Name, count them and put the result in a new column Total_Reviews_Found
   hotel_freq_df['Total_Reviews_Found'] = hotel_freq_df.groupby('Hotel_Name').transform('count')
   
   # Get rid of all the duplicated rows
   hotel_freq_df = hotel_freq_df.drop_duplicates(subset = ["Hotel_Name"])
   display(hotel_freq_df) 
   ```
   |                 Nom de l'h√¥tel                 | Nombre total d'avis | Avis trouv√©s |
   | :--------------------------------------------: | :-----------------: | :----------: |
   | Britannia International Hotel Canary Wharf     |        9086         |     4789     |
   | Park Plaza Westminster Bridge London           |       12158         |     4169     |
   | Copthorne Tara Hotel London Kensington         |        7105         |     3578     |
   |                     ...                        |         ...         |      ...     |
   | Mercure Paris Porte d'Orleans                  |         110         |      10      |
   | Hotel Wagner                                   |         135         |      10      |
   | Hotel Gallitzinberg                            |         173         |       8      |

   Vous remarquerez peut-√™tre que les r√©sultats *compt√©s dans le jeu de donn√©es* ne correspondent pas √† la valeur dans `Total_Number_of_Reviews`. Il n'est pas clair si cette valeur dans le jeu de donn√©es repr√©sentait le nombre total d'avis que l'h√¥tel avait, mais que tous n'ont pas √©t√© extraits, ou un autre calcul. `Total_Number_of_Reviews` n'est pas utilis√© dans le mod√®le en raison de ce manque de clart√©.

5. Bien qu'il existe une colonne `Average_Score` pour chaque h√¥tel dans le jeu de donn√©es, vous pouvez √©galement calculer un score moyen (en obtenant la moyenne de tous les scores des auteurs d'avis dans le jeu de donn√©es pour chaque h√¥tel). Ajoutez une nouvelle colonne √† votre dataframe avec l'en-t√™te `Calc_Average_Score` contenant cette moyenne calcul√©e. Affichez les colonnes `Hotel_Name`, `Average_Score` et `Calc_Average_Score`.

   ```python
   # define a function that takes a row and performs some calculation with it
   def get_difference_review_avg(row):
     return row["Average_Score"] - row["Calc_Average_Score"]
   
   # 'mean' is mathematical word for 'average'
   df['Calc_Average_Score'] = round(df.groupby('Hotel_Name').Reviewer_Score.transform('mean'), 1)
   
   # Add a new column with the difference between the two average scores
   df["Average_Score_Difference"] = df.apply(get_difference_review_avg, axis = 1)
   
   # Create a df without all the duplicates of Hotel_Name (so only 1 row per hotel)
   review_scores_df = df.drop_duplicates(subset = ["Hotel_Name"])
   
   # Sort the dataframe to find the lowest and highest average score difference
   review_scores_df = review_scores_df.sort_values(by=["Average_Score_Difference"])
   
   display(review_scores_df[["Average_Score_Difference", "Average_Score", "Calc_Average_Score", "Hotel_Name"]])
   ```

   Vous pourriez √©galement vous demander pourquoi la valeur `Average_Score` est parfois diff√©rente du score moyen calcul√©. Comme nous ne pouvons pas savoir pourquoi certaines valeurs correspondent, mais d'autres pr√©sentent une diff√©rence, il est plus s√ªr dans ce cas d'utiliser les scores des avis que nous avons pour calculer la moyenne nous-m√™mes. Cela dit, les diff√©rences sont g√©n√©ralement tr√®s petites, voici les h√¥tels avec les plus grandes d√©viations entre la moyenne du jeu de donn√©es et la moyenne calcul√©e :

   | Diff√©rence de score moyen | Score moyen | Score moyen calcul√© |                                  Nom de l'h√¥tel |
   | :------------------------: | :---------: | :-----------------: | -----------------------------------------------: |
   |           -0.8            |     7.7     |         8.5         |                  Best Western Hotel Astoria      |
   |           -0.7            |     8.8     |         9.5         | Hotel Stendhal Place Vend√¥me Paris MGallery      |
   |           -0.7            |     7.5     |         8.2         |               Mercure Paris Porte d'Orleans      |
   |           -0.7            |     7.9     |         8.6         |             Renaissance Paris Vend√¥me Hotel      |
   |           -0.5            |     7.0     |         7.5         |                         Hotel Royal Elys√©es      |
   |           ...             |     ...     |         ...         |                                            ...   |
   |           0.7             |     7.5     |         6.8         |     Mercure Paris Op√©ra Faubourg Montmartre      |
   |           0.8             |     7.1     |         6.3         |      Holiday Inn Paris Montparnasse Pasteur      |
   |           0.9             |     6.8     |         5.9         |                               Villa Eug√©nie      |
   |           0.9             |     8.6     |         7.7         |   MARQUIS Faubourg St Honor√© Relais Ch√¢teaux     |
   |           1.3             |     7.2     |         5.9         |                          Kube Hotel Ice Bar      |

   Avec seulement 1 h√¥tel ayant une diff√©rence de score sup√©rieure √† 1, cela signifie que nous pouvons probablement ignorer la diff√©rence et utiliser le score moyen calcul√©.

6. Calculez et affichez combien de lignes ont des valeurs "No Negative" dans la colonne `Negative_Review`.

7. Calculez et affichez combien de lignes ont des valeurs "No Positive" dans la colonne `Positive_Review`.

8. Calculez et affichez combien de lignes ont des valeurs "No Positive" dans la colonne `Positive_Review` **et** des valeurs "No Negative" dans la colonne `Negative_Review`.

   ```python
   # with lambdas:
   start = time.time()
   no_negative_reviews = df.apply(lambda x: True if x['Negative_Review'] == "No Negative" else False , axis=1)
   print("Number of No Negative reviews: " + str(len(no_negative_reviews[no_negative_reviews == True].index)))
   
   no_positive_reviews = df.apply(lambda x: True if x['Positive_Review'] == "No Positive" else False , axis=1)
   print("Number of No Positive reviews: " + str(len(no_positive_reviews[no_positive_reviews == True].index)))
   
   both_no_reviews = df.apply(lambda x: True if x['Negative_Review'] == "No Negative" and x['Positive_Review'] == "No Positive" else False , axis=1)
   print("Number of both No Negative and No Positive reviews: " + str(len(both_no_reviews[both_no_reviews == True].index)))
   end = time.time()
   print("Lambdas took " + str(round(end - start, 2)) + " seconds")
   
   Number of No Negative reviews: 127890
   Number of No Positive reviews: 35946
   Number of both No Negative and No Positive reviews: 127
   Lambdas took 9.64 seconds
   ```

## Une autre m√©thode

Une autre fa√ßon de compter les √©l√©ments sans Lambdas, et d'utiliser sum pour compter les lignes :

   ```python
   # without lambdas (using a mixture of notations to show you can use both)
   start = time.time()
   no_negative_reviews = sum(df.Negative_Review == "No Negative")
   print("Number of No Negative reviews: " + str(no_negative_reviews))
   
   no_positive_reviews = sum(df["Positive_Review"] == "No Positive")
   print("Number of No Positive reviews: " + str(no_positive_reviews))
   
   both_no_reviews = sum((df.Negative_Review == "No Negative") & (df.Positive_Review == "No Positive"))
   print("Number of both No Negative and No Positive reviews: " + str(both_no_reviews))
   
   end = time.time()
   print("Sum took " + str(round(end - start, 2)) + " seconds")
   
   Number of No Negative reviews: 127890
   Number of No Positive reviews: 35946
   Number of both No Negative and No Positive reviews: 127
   Sum took 0.19 seconds
   ```

   Vous avez peut-√™tre remarqu√© qu'il y a 127 lignes qui ont √† la fois "No Negative" et "No Positive" comme valeurs pour les colonnes `Negative_Review` et `Positive_Review` respectivement. Cela signifie que l'auteur de l'avis a donn√© √† l'h√¥tel une note num√©rique, mais a refus√© d'√©crire un avis positif ou n√©gatif. Heureusement, cela repr√©sente une petite quantit√© de lignes (127 sur 515738, soit 0,02 %), donc cela ne devrait probablement pas biaiser notre mod√®le ou nos r√©sultats dans une direction particuli√®re, mais vous ne vous attendriez peut-√™tre pas √† ce qu'un jeu de donn√©es d'avis contienne des lignes sans avis, donc cela vaut la peine d'explorer les donn√©es pour d√©couvrir de telles lignes.

Maintenant que vous avez explor√© le jeu de donn√©es, dans la prochaine le√ßon, vous filtrerez les donn√©es et ajouterez une analyse de sentiment.

---
## üöÄD√©fi

Cette le√ßon d√©montre, comme nous l'avons vu dans les le√ßons pr√©c√©dentes, √† quel point il est crucial de comprendre vos donn√©es et leurs particularit√©s avant d'effectuer des op√©rations dessus. Les donn√©es textuelles, en particulier, n√©cessitent une attention minutieuse. Explorez divers jeux de donn√©es riches en texte et voyez si vous pouvez d√©couvrir des zones susceptibles d'introduire des biais ou des sentiments biais√©s dans un mod√®le.

## [Quiz post-cours](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/38/)

## R√©vision et auto-apprentissage

Suivez [ce parcours d'apprentissage sur le NLP](https://docs.microsoft.com/learn/paths/explore-natural-language-processing/?WT.mc_id=academic-77952-leestott) pour d√©couvrir des outils √† essayer lors de la cr√©ation de mod√®les riches en texte et en discours.

## Devoir

[NLTK](assignment.md)

---

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction professionnelle r√©alis√©e par un humain. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.