# Analyse de sentiment avec les avis d'h√¥tels - traitement des donn√©es

Dans cette section, vous utiliserez les techniques des le√ßons pr√©c√©dentes pour effectuer une analyse exploratoire des donn√©es sur un grand ensemble de donn√©es. Une fois que vous aurez une bonne compr√©hension de l'utilit√© des diff√©rentes colonnes, vous apprendrez :

- comment supprimer les colonnes inutiles
- comment calculer de nouvelles donn√©es bas√©es sur les colonnes existantes
- comment sauvegarder l'ensemble de donn√©es r√©sultant pour l'utiliser dans le d√©fi final

## [Quiz pr√©-conf√©rence](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/37/)

### Introduction

Jusqu'√† pr√©sent, vous avez appris que les donn√©es textuelles sont tr√®s diff√©rentes des types de donn√©es num√©riques. Si le texte a √©t√© √©crit ou prononc√© par un humain, il peut √™tre analys√© pour trouver des motifs et des fr√©quences, des sentiments et des significations. Cette le√ßon vous plonge dans un ensemble de donn√©es r√©el avec un v√©ritable d√©fi : **[515K Avis d'H√¥tels en Europe](https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe)** et comprend une [licence CC0 : Domaine public](https://creativecommons.org/publicdomain/zero/1.0/). Il a √©t√© extrait de Booking.com √† partir de sources publiques. Le cr√©ateur de l'ensemble de donn√©es est Jiashen Liu.

### Pr√©paration

Vous aurez besoin de :

* La capacit√© d'ex√©cuter des notebooks .ipynb en utilisant Python 3
* pandas
* NLTK, [que vous devez installer localement](https://www.nltk.org/install.html)
* L'ensemble de donn√©es qui est disponible sur Kaggle [515K Avis d'H√¥tels en Europe](https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe). Il fait environ 230 Mo une fois d√©compress√©. T√©l√©chargez-le dans le dossier racine `/data` associ√© √† ces le√ßons de NLP.

## Analyse exploratoire des donn√©es

Ce d√©fi suppose que vous construisez un bot de recommandation d'h√¥tels utilisant l'analyse de sentiment et les scores des avis des clients. L'ensemble de donn√©es que vous allez utiliser comprend des avis sur 1493 h√¥tels diff√©rents dans 6 villes.

En utilisant Python, un ensemble de donn√©es d'avis d'h√¥tels et l'analyse de sentiment de NLTK, vous pourriez d√©couvrir :

* Quels sont les mots et phrases les plus fr√©quemment utilis√©s dans les avis ?
* Les *tags* officiels d√©crivant un h√¥tel sont-ils corr√©l√©s avec les scores des avis (par exemple, les avis plus n√©gatifs pour un h√¥tel particulier sont-ils pour *Famille avec de jeunes enfants* plut√¥t que pour *Voyageur solo*, ce qui indiquerait peut-√™tre qu'il est mieux pour les *Voyageurs solo* ?) 
* Les scores de sentiment de NLTK 's'accordent-ils' avec le score num√©rique de l'examinateur de l'h√¥tel ?

#### Ensemble de donn√©es

Explorons l'ensemble de donn√©es que vous avez t√©l√©charg√© et sauvegard√© localement. Ouvrez le fichier dans un √©diteur comme VS Code ou m√™me Excel.

Les en-t√™tes dans l'ensemble de donn√©es sont les suivants :

*Hotel_Address, Additional_Number_of_Scoring, Review_Date, Average_Score, Hotel_Name, Reviewer_Nationality, Negative_Review, Review_Total_Negative_Word_Counts, Total_Number_of_Reviews, Positive_Review, Review_Total_Positive_Word_Counts, Total_Number_of_Reviews_Reviewer_Has_Given, Reviewer_Score, Tags, days_since_review, lat, lng*

Voici comment ils sont regroup√©s d'une mani√®re qui pourrait √™tre plus facile √† examiner :
##### Colonnes de l'h√¥tel

* `Hotel_Name`, `Hotel_Address`, `lat` (latitude), `lng` (longitude)
  * En utilisant *lat* et *lng*, vous pourriez tracer une carte avec Python montrant les emplacements des h√¥tels (peut-√™tre cod√©e par couleur pour les avis n√©gatifs et positifs)
  * Hotel_Address n'est pas √©videmment utile pour nous, et nous allons probablement le remplacer par un pays pour un tri et une recherche plus faciles

**Colonnes de m√©ta-avis sur l'h√¥tel**

* `Average_Score`
  * Selon le cr√©ateur de l'ensemble de donn√©es, cette colonne est le *Score moyen de l'h√¥tel, calcul√© sur la base du dernier commentaire dans l'ann√©e √©coul√©e*. Cela semble √™tre une mani√®re inhabituelle de calculer le score, mais c'est les donn√©es extraites donc nous pouvons le prendre pour ce qu'il est pour l'instant.
  
  ‚úÖ En vous basant sur les autres colonnes de ces donn√©es, pouvez-vous penser √† une autre fa√ßon de calculer le score moyen ?

* `Total_Number_of_Reviews`
  * Le nombre total d'avis que cet h√¥tel a re√ßus - il n'est pas clair (sans √©crire un peu de code) si cela fait r√©f√©rence aux avis dans l'ensemble de donn√©es.
* `Additional_Number_of_Scoring`
  * Cela signifie qu'un score d'avis a √©t√© donn√© mais qu'aucun avis positif ou n√©gatif n'a √©t√© √©crit par l'examinateur

**Colonnes d'avis**

- `Reviewer_Score`
  - Il s'agit d'une valeur num√©rique avec au maximum 1 d√©cimale entre les valeurs minimales et maximales 2.5 et 10
  - Il n'est pas expliqu√© pourquoi 2.5 est le score le plus bas possible
- `Negative_Review`
  - Si un examinateur n'a rien √©crit, ce champ aura "**No Negative**"
  - Notez qu'un examinateur peut √©crire un avis positif dans la colonne Negative review (par exemple, "il n'y a rien de mauvais dans cet h√¥tel")
- `Review_Total_Negative_Word_Counts`
  - Un nombre de mots n√©gatifs plus √©lev√© indique un score plus bas (sans v√©rifier la sentimentalit√©)
- `Positive_Review`
  - Si un examinateur n'a rien √©crit, ce champ aura "**No Positive**"
  - Notez qu'un examinateur peut √©crire un avis n√©gatif dans la colonne Positive review (par exemple, "il n'y a rien de bon dans cet h√¥tel")
- `Review_Total_Positive_Word_Counts`
  - Un nombre de mots positifs plus √©lev√© indique un score plus √©lev√© (sans v√©rifier la sentimentalit√©)
- `Review_Date` et `days_since_review`
  - Une mesure de fra√Æcheur ou de stagnation pourrait √™tre appliqu√©e √† un avis (les avis plus anciens pourraient ne pas √™tre aussi pr√©cis que les plus r√©cents en raison de changements de gestion d'h√¥tel, de r√©novations effectu√©es, ou d'une piscine ajout√©e, etc.)
- `Tags`
  - Ce sont de courts descripteurs qu'un examinateur peut s√©lectionner pour d√©crire le type de client qu'il √©tait (par exemple, solo ou famille), le type de chambre qu'il avait, la dur√©e du s√©jour et comment l'avis a √©t√© soumis.
  - Malheureusement, l'utilisation de ces tags pose probl√®me, consultez la section ci-dessous qui discute de leur utilit√©

**Colonnes d'examinateur**

- `Total_Number_of_Reviews_Reviewer_Has_Given`
  - Cela pourrait √™tre un facteur dans un mod√®le de recommandation, par exemple, si vous pouviez d√©terminer que les examinateurs plus prolifiques avec des centaines d'avis √©taient plus susceptibles d'√™tre n√©gatifs plut√¥t que positifs. Cependant, l'examinateur d'un avis particulier n'est pas identifi√© par un code unique, et ne peut donc pas √™tre li√© √† un ensemble d'avis. Il y a 30 examinateurs avec 100 avis ou plus, mais il est difficile de voir comment cela peut aider le mod√®le de recommandation.
- `Reviewer_Nationality`
  - Certaines personnes pourraient penser que certaines nationalit√©s sont plus susceptibles de donner un avis positif ou n√©gatif en raison d'une inclination nationale. Faites attention √† ne pas int√©grer de telles vues anecdotiques dans vos mod√®les. Ce sont des st√©r√©otypes nationaux (et parfois raciaux), et chaque examinateur √©tait un individu qui a √©crit un avis bas√© sur son exp√©rience. Cela peut avoir √©t√© filtr√© √† travers de nombreuses lentilles telles que ses pr√©c√©dents s√©jours √† l'h√¥tel, la distance parcourue, et son temp√©rament personnel. Penser que leur nationalit√© √©tait la raison d'un score d'avis est difficile √† justifier.

##### Exemples

| Score Moyen | Nombre Total d'Avis | Score de l'Examinateur | Avis N√©gatif <br />                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | Avis Positif                 | Tags                                                                                      |
| ------------ | --------------------- | ---------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------- | ----------------------------------------------------------------------------------------- |
| 7.8          | 1945                  | 2.5                    | Actuellement, ce n'est pas un h√¥tel mais un chantier de construction. J'ai √©t√© terroris√© d√®s le matin et toute la journ√©e par un bruit de construction inacceptable tout en essayant de me reposer apr√®s un long voyage et de travailler dans la chambre. Des personnes travaillaient toute la journ√©e avec des perceuses dans les chambres adjacentes. J'ai demand√© un changement de chambre, mais aucune chambre silencieuse n'√©tait disponible. Pour aggraver les choses, j'ai √©t√© surfactur√©. J'ai quitt√© l'h√¥tel le soir puisque je devais partir tr√®s t√¥t pour un vol et j'ai re√ßu une facture appropri√©e. Un jour plus tard, l'h√¥tel a effectu√© un autre pr√©l√®vement sans mon consentement, sup√©rieur au prix r√©serv√©. C'est un endroit terrible. Ne vous punissez pas en r√©servant ici. | Rien. Endroit terrible. Restez √† l'√©cart. | Voyage d'affaires                                Couple, Chambre Double Standard, S√©jour de 2 nuits |

Comme vous pouvez le voir, ce client n'a pas eu un s√©jour heureux dans cet h√¥tel. L'h√¥tel a un bon score moyen de 7.8 et 1945 avis, mais cet examinateur lui a donn√© 2.5 et a √©crit 115 mots sur la n√©gativit√© de son s√©jour. S'il n'avait rien √©crit du tout dans la colonne Positive_Review, vous pourriez supposer qu'il n'y avait rien de positif, mais h√©las, il a √©crit 7 mots d'avertissement. Si nous ne comptions que les mots au lieu de la signification ou du sentiment des mots, nous pourrions avoir une vision biais√©e de l'intention de l'examinateur. √âtrangement, leur score de 2.5 est d√©routant, car si ce s√©jour √† l'h√¥tel √©tait si mauvais, pourquoi lui donner des points du tout ? En examinant de pr√®s l'ensemble de donn√©es, vous verrez que le score le plus bas possible est 2.5, pas 0. Le score le plus √©lev√© possible est 10.

##### Tags

Comme mentionn√© ci-dessus, √† premi√®re vue, l'id√©e d'utiliser `Tags` pour cat√©goriser les donn√©es a du sens. Malheureusement, ces tags ne sont pas standardis√©s, ce qui signifie que dans un h√¥tel donn√©, les options pourraient √™tre *Chambre simple*, *Chambre twin*, et *Chambre double*, mais dans l'h√¥tel suivant, elles sont *Chambre Simple Deluxe*, *Chambre Reine Classique*, et *Chambre Roi Ex√©cutive*. Ces options pourraient √™tre les m√™mes, mais il y a tellement de variations que le choix devient :

1. Essayer de changer tous les termes en une seule norme, ce qui est tr√®s difficile, car il n'est pas clair quel serait le chemin de conversion dans chaque cas (par exemple, *Chambre simple classique* correspond √† *Chambre simple* mais *Chambre Reine Sup√©rieure avec Jardin Cour ou Vue sur la Ville* est beaucoup plus difficile √† mapper)

2. Nous pouvons adopter une approche NLP et mesurer la fr√©quence de certains termes comme *Solo*, *Voyageur d'affaires*, ou *Famille avec de jeunes enfants* tels qu'ils s'appliquent √† chaque h√¥tel, et en tenir compte dans la recommandation  

Les tags sont g√©n√©ralement (mais pas toujours) un champ unique contenant une liste de 5 √† 6 valeurs s√©par√©es par des virgules correspondant √† *Type de voyage*, *Type de clients*, *Type de chambre*, *Nombre de nuits*, et *Type de dispositif sur lequel l'avis a √©t√© soumis*. Cependant, comme certains examinateurs ne remplissent pas chaque champ (ils peuvent en laisser un vide), les valeurs ne sont pas toujours dans le m√™me ordre.

Prenons un exemple, le champ *Type de groupe*. Il y a 1025 possibilit√©s uniques dans ce champ de la colonne `Tags`, et malheureusement, seules certaines d'entre elles font r√©f√©rence √† un groupe (certaines sont le type de chambre, etc.). Si vous filtrez uniquement celles qui mentionnent la famille, les r√©sultats contiennent de nombreux types de r√©sultats *Chambre familiale*. Si vous incluez le terme *avec*, c'est-√†-dire compter les valeurs *Famille avec*, les r√©sultats sont meilleurs, avec plus de 80 000 des 515 000 r√©sultats contenant la phrase "Famille avec de jeunes enfants" ou "Famille avec des enfants plus √¢g√©s".

Cela signifie que la colonne des tags n'est pas compl√®tement inutile pour nous, mais il faudra du travail pour la rendre utile.

##### Score moyen de l'h√¥tel

Il y a un certain nombre d'√©tranget√©s ou de divergences avec l'ensemble de donn√©es que je ne peux pas comprendre, mais qui sont illustr√©es ici afin que vous en soyez conscient lors de la construction de vos mod√®les. Si vous le comprenez, merci de nous le faire savoir dans la section discussion !

L'ensemble de donn√©es a les colonnes suivantes concernant le score moyen et le nombre d'avis :

1. Hotel_Name
2. Additional_Number_of_Scoring
3. Average_Score
4. Total_Number_of_Reviews
5. Reviewer_Score  

L'h√¥tel avec le plus d'avis dans cet ensemble de donn√©es est *Britannia International Hotel Canary Wharf* avec 4789 avis sur 515 000. Mais si nous regardons la valeur `Total_Number_of_Reviews` pour cet h√¥tel, elle est de 9086. Vous pourriez supposer qu'il y a beaucoup plus de scores sans avis, donc peut-√™tre devrions-nous ajouter la valeur de la colonne `Additional_Number_of_Scoring`. Cette valeur est de 2682, et l'ajouter √† 4789 nous donne 7471, ce qui est encore 1615 de moins que le `Total_Number_of_Reviews`. 

Si vous prenez les colonnes `Average_Score`, vous pourriez supposer qu'il s'agit de la moyenne des avis dans l'ensemble de donn√©es, mais la description de Kaggle est "*Score moyen de l'h√¥tel, calcul√© sur la base du dernier commentaire dans l'ann√©e √©coul√©e*". Cela ne semble pas tr√®s utile, mais nous pouvons calculer notre propre moyenne bas√©e sur les scores des avis dans l'ensemble de donn√©es. En utilisant le m√™me h√¥tel comme exemple, le score moyen de l'h√¥tel est donn√© comme 7.1 mais le score calcul√© (score moyen des examinateurs *dans* l'ensemble de donn√©es) est de 6.8. C'est proche, mais pas la m√™me valeur, et nous ne pouvons que deviner que les scores donn√©s dans les avis `Additional_Number_of_Scoring` ont augment√© la moyenne √† 7.1. Malheureusement, sans moyen de tester ou de prouver cette assertion, il est difficile d'utiliser ou de faire confiance √† `Average_Score`, `Additional_Number_of_Scoring` et `Total_Number_of_Reviews` lorsqu'ils sont bas√©s sur, ou se r√©f√®rent √†, des donn√©es que nous n'avons pas.

Pour compliquer encore les choses, l'h√¥tel avec le deuxi√®me plus grand nombre d'avis a un score moyen calcul√© de 8.12 et l'ensemble de donn√©es `Average_Score` est de 8.1. Ce score correct est-il une co√Øncidence ou le premier h√¥tel est-il une anomalie ? 

Dans l'√©ventualit√© o√π ces h√¥tels pourraient √™tre des cas extr√™mes, et que peut-√™tre la plupart des valeurs s'additionnent (mais certaines ne le font pas pour une raison quelconque), nous allons √©crire un court programme ensuite pour explorer les valeurs dans l'ensemble de donn√©es et d√©terminer l'utilisation correcte (ou non-utilisation) des valeurs.

> üö® Une note de prudence
>
> Lorsque vous travaillez avec cet ensemble de donn√©es, vous √©crirez du code qui calcule quelque chose √† partir du texte sans avoir √† lire ou analyser le texte vous-m√™me. C'est l'essence du NLP, interpr√©ter la signification ou le sentiment sans qu'un humain le fasse. Cependant, il est possible que vous lisiez certains des avis n√©gatifs. Je vous conseillerais de ne pas le faire, car vous n'avez pas besoin de. Certains d'entre eux sont ridicules ou des avis n√©gatifs sans pertinence, comme "Le temps n'√©tait pas super", quelque chose qui √©chappe au contr√¥le de l'h√¥tel, ou en effet, de quiconque. Mais il y a aussi un c√¥t√© sombre √† certains avis. Parfois, les avis n√©gatifs sont racistes, sexistes ou √¢gistes. C'est malheureux mais √† pr√©voir dans un ensemble de donn√©es extrait d'un site web public. Certains examinateurs laissent des avis que vous trouveriez de mauvais go√ªt, inconfortables ou troublants. Il vaut mieux laisser le code mesurer le sentiment plut√¥t que de les lire vous-m√™me et d'√™tre contrari√©. Cela dit, c'est une minorit√© qui √©crit de telles choses, mais elles existent n√©anmoins. 

## Exercice - Exploration des donn√©es
### Charger les donn√©es

C'est assez d'examiner les donn√©es visuellement, maintenant vous allez √©crire un peu de code et obtenir des r√©ponses ! Cette section utilise la biblioth√®que pandas. Votre toute premi√®re t√¢che est de vous assurer que vous pouvez charger et lire les donn√©es CSV. La biblioth√®que pandas a un chargeur CSV rapide, et le r√©sultat est plac√© dans un dataframe, comme dans les le√ßons pr√©c√©dentes. Le CSV que nous chargeons a plus d'un demi-million de lignes, mais seulement 17 colonnes. Pandas vous offre de nombreuses fa√ßons puissantes d'interagir avec un dataframe, y compris la capacit√© d'effectuer des op√©rations sur chaque ligne. 

√Ä partir de maintenant dans cette le√ßon, il y aura des extraits de code et quelques explications du code ainsi que des discussions sur ce que les r√©sultats signifient. Utilisez le _notebook.ipynb_ inclus pour votre code.

Commen√ßons par charger le fichier de donn√©es que vous allez utiliser :

```python
# Load the hotel reviews from CSV
import pandas as pd
import time
# importing time so the start and end time can be used to calculate file loading time
print("Loading data file now, this could take a while depending on file size")
start = time.time()
# df is 'DataFrame' - make sure you downloaded the file to the data folder
df = pd.read_csv('../../data/Hotel_Reviews.csv')
end = time.time()
print("Loading took " + str(round(end - start, 2)) + " seconds")
```

Maintenant que les donn√©es sont charg√©es, nous pouvons effectuer certaines op√©rations dessus. Gardez ce code en haut de votre programme pour la prochaine partie.

## Explorer les donn√©es

Dans ce cas, les donn√©es sont d√©j√† *propres*, cela signifie qu'elles sont pr√™tes √† √™tre utilis√©es, et n'ont pas de caract√®res dans d'autres langues qui pourraient perturber les algorithmes s'attendant uniquement √† des caract√®res anglais. 

‚úÖ Vous pourriez avoir √† travailler avec des donn√©es qui n√©cessitaient un traitement initial pour les formater avant d'appliquer des techniques NLP, mais pas cette fois. Si vous deviez le faire, comment g√©reriez-vous les caract√®res non anglais ?

Prenez un moment pour vous assurer qu'une fois les donn√©es charg√©es, vous pouvez les
les lignes ont des valeurs de colonne `Positive_Review` de "Aucun Positif" 9. Calculez et imprimez combien de lignes ont des valeurs de colonne `Positive_Review` de "Aucun Positif" **et** des valeurs `Negative_Review` de "Aucun N√©gatif" ### R√©ponses au code 1. Imprimez la *forme* du cadre de donn√©es que vous venez de charger (la forme est le nombre de lignes et de colonnes) ```python
   print("The shape of the data (rows, cols) is " + str(df.shape))
   > The shape of the data (rows, cols) is (515738, 17)
   ``` 2. Calculez le nombre de fr√©quences pour les nationalit√©s des examinateurs : 1. Combien de valeurs distinctes y a-t-il pour la colonne `Reviewer_Nationality` et quelles sont-elles ? 2. Quelle nationalit√© d'examinateur est la plus courante dans l'ensemble de donn√©es (imprimez le pays et le nombre de critiques) ? ```python
   # value_counts() creates a Series object that has index and values in this case, the country and the frequency they occur in reviewer nationality
   nationality_freq = df["Reviewer_Nationality"].value_counts()
   print("There are " + str(nationality_freq.size) + " different nationalities")
   # print first and last rows of the Series. Change to nationality_freq.to_string() to print all of the data
   print(nationality_freq) 
   
   There are 227 different nationalities
    United Kingdom               245246
    United States of America      35437
    Australia                     21686
    Ireland                       14827
    United Arab Emirates          10235
                                  ...  
    Comoros                           1
    Palau                             1
    Northern Mariana Islands          1
    Cape Verde                        1
    Guinea                            1
   Name: Reviewer_Nationality, Length: 227, dtype: int64
   ``` 3. Quelles sont les 10 nationalit√©s les plus fr√©quemment trouv√©es, et leur nombre de fr√©quences ? ```python
      print("The highest frequency reviewer nationality is " + str(nationality_freq.index[0]).strip() + " with " + str(nationality_freq[0]) + " reviews.")
      # Notice there is a leading space on the values, strip() removes that for printing
      # What is the top 10 most common nationalities and their frequencies?
      print("The next 10 highest frequency reviewer nationalities are:")
      print(nationality_freq[1:11].to_string())
      
      The highest frequency reviewer nationality is United Kingdom with 245246 reviews.
      The next 10 highest frequency reviewer nationalities are:
       United States of America     35437
       Australia                    21686
       Ireland                      14827
       United Arab Emirates         10235
       Saudi Arabia                  8951
       Netherlands                   8772
       Switzerland                   8678
       Germany                       7941
       Canada                        7894
       France                        7296
      ``` 3. Quel √©tait l'h√¥tel le plus fr√©quemment √©valu√© pour chacune des 10 nationalit√©s d'examinateurs les plus repr√©sent√©es ? ```python
   # What was the most frequently reviewed hotel for the top 10 nationalities
   # Normally with pandas you will avoid an explicit loop, but wanted to show creating a new dataframe using criteria (don't do this with large amounts of data because it could be very slow)
   for nat in nationality_freq[:10].index:
      # First, extract all the rows that match the criteria into a new dataframe
      nat_df = df[df["Reviewer_Nationality"] == nat]   
      # Now get the hotel freq
      freq = nat_df["Hotel_Name"].value_counts()
      print("The most reviewed hotel for " + str(nat).strip() + " was " + str(freq.index[0]) + " with " + str(freq[0]) + " reviews.") 
      
   The most reviewed hotel for United Kingdom was Britannia International Hotel Canary Wharf with 3833 reviews.
   The most reviewed hotel for United States of America was Hotel Esther a with 423 reviews.
   The most reviewed hotel for Australia was Park Plaza Westminster Bridge London with 167 reviews.
   The most reviewed hotel for Ireland was Copthorne Tara Hotel London Kensington with 239 reviews.
   The most reviewed hotel for United Arab Emirates was Millennium Hotel London Knightsbridge with 129 reviews.
   The most reviewed hotel for Saudi Arabia was The Cumberland A Guoman Hotel with 142 reviews.
   The most reviewed hotel for Netherlands was Jaz Amsterdam with 97 reviews.
   The most reviewed hotel for Switzerland was Hotel Da Vinci with 97 reviews.
   The most reviewed hotel for Germany was Hotel Da Vinci with 86 reviews.
   The most reviewed hotel for Canada was St James Court A Taj Hotel London with 61 reviews.
   ``` 4. Combien de critiques y a-t-il par h√¥tel (nombre de fr√©quences de l'h√¥tel) dans l'ensemble de donn√©es ? ```python
   # First create a new dataframe based on the old one, removing the uneeded columns
   hotel_freq_df = df.drop(["Hotel_Address", "Additional_Number_of_Scoring", "Review_Date", "Average_Score", "Reviewer_Nationality", "Negative_Review", "Review_Total_Negative_Word_Counts", "Positive_Review", "Review_Total_Positive_Word_Counts", "Total_Number_of_Reviews_Reviewer_Has_Given", "Reviewer_Score", "Tags", "days_since_review", "lat", "lng"], axis = 1)
   
   # Group the rows by Hotel_Name, count them and put the result in a new column Total_Reviews_Found
   hotel_freq_df['Total_Reviews_Found'] = hotel_freq_df.groupby('Hotel_Name').transform('count')
   
   # Get rid of all the duplicated rows
   hotel_freq_df = hotel_freq_df.drop_duplicates(subset = ["Hotel_Name"])
   display(hotel_freq_df) 
   ``` | Nom_H√¥tel | Nombre_Total_de_Critiques | Total_Critiques_Trouv√©es | | :----------------------------------------: | :---------------------: | :-----------------: | | Britannia International Hotel Canary Wharf | 9086 | 4789 | | Park Plaza Westminster Bridge London | 12158 | 4169 | | Copthorne Tara Hotel London Kensington | 7105 | 3578 | | ... | ... | ... | | Mercure Paris Porte d Orleans | 110 | 10 | | H√¥tel Wagner | 135 | 10 | | H√¥tel Gallitzinberg | 173 | 8 | Vous remarquerez peut-√™tre que les r√©sultats *compt√©s dans l'ensemble de donn√©es* ne correspondent pas √† la valeur dans `Total_Number_of_Reviews`. Il n'est pas clair si cette valeur dans l'ensemble de donn√©es repr√©sentait le nombre total de critiques que l'h√¥tel avait, mais que toutes n'ont pas √©t√© extraites, ou un autre calcul. `Total_Number_of_Reviews` n'est pas utilis√© dans le mod√®le en raison de cette incertitude. 5. Bien qu'il y ait une colonne `Average_Score` pour chaque h√¥tel dans l'ensemble de donn√©es, vous pouvez √©galement calculer un score moyen (obtenant la moyenne de tous les scores des examinateurs dans l'ensemble de donn√©es pour chaque h√¥tel). Ajoutez une nouvelle colonne √† votre cadre de donn√©es avec l'en-t√™te de colonne `Calc_Average_Score` qui contient cette moyenne calcul√©e. Imprimez les colonnes `Hotel_Name`, `Average_Score`, et `Calc_Average_Score`. ```python
   # define a function that takes a row and performs some calculation with it
   def get_difference_review_avg(row):
     return row["Average_Score"] - row["Calc_Average_Score"]
   
   # 'mean' is mathematical word for 'average'
   df['Calc_Average_Score'] = round(df.groupby('Hotel_Name').Reviewer_Score.transform('mean'), 1)
   
   # Add a new column with the difference between the two average scores
   df["Average_Score_Difference"] = df.apply(get_difference_review_avg, axis = 1)
   
   # Create a df without all the duplicates of Hotel_Name (so only 1 row per hotel)
   review_scores_df = df.drop_duplicates(subset = ["Hotel_Name"])
   
   # Sort the dataframe to find the lowest and highest average score difference
   review_scores_df = review_scores_df.sort_values(by=["Average_Score_Difference"])
   
   display(review_scores_df[["Average_Score_Difference", "Average_Score", "Calc_Average_Score", "Hotel_Name"]])
   ``` Vous vous demandez peut-√™tre √©galement pourquoi la valeur `Average_Score` est parfois diff√©rente du score moyen calcul√©. Comme nous ne pouvons pas savoir pourquoi certaines des valeurs correspondent, mais d'autres ont une diff√©rence, il est plus s√ªr dans ce cas d'utiliser les scores de critique que nous avons pour calculer la moyenne nous-m√™mes. Cela dit, les diff√©rences sont g√©n√©ralement tr√®s petites, voici les h√¥tels avec la plus grande d√©viation par rapport √† la moyenne de l'ensemble de donn√©es et √† la moyenne calcul√©e : | Diff√©rence_Score_Moyen | Score_Moyen | Calc_Average_Score | Nom_H√¥tel | | :----------------------: | :-----------: | :----------------: | ------------------------------------------: | | -0.8 | 7.7 | 8.5 | Best Western Hotel Astoria | | -0.7 | 8.8 | 9.5 | H√¥tel Stendhal Place Vend√¥me Paris MGallery | | -0.7 | 7.5 | 8.2 | Mercure Paris Porte d Orleans | | -0.7 | 7.9 | 8.6 | Renaissance Paris Vend√¥me H√¥tel | | -0.5 | 7.0 | 7.5 | H√¥tel Royal √âlys√©es | | ... | ... | ... | ... | | 0.7 | 7.5 | 6.8 | Mercure Paris Op√©ra Faubourg Montmartre | | 0.8 | 7.1 | 6.3 | Holiday Inn Paris Montparnasse Pasteur | | 0.9 | 6.8 | 5.9 | Villa Eugenie | | 0.9 | 8.6 | 7.7 | MARQUIS Faubourg St Honor Relais Ch√¢teaux | | 1.3 | 7.2 | 5.9 | Kube Hotel Ice Bar | Avec seulement 1 h√¥tel ayant une diff√©rence de score sup√©rieure √† 1, cela signifie que nous pouvons probablement ignorer la diff√©rence et utiliser le score moyen calcul√©. 6. Calculez et imprimez combien de lignes ont des valeurs de colonne `Negative_Review` de "Aucun N√©gatif" 7. Calculez et imprimez combien de lignes ont des valeurs de colonne `Positive_Review` de "Aucun Positif" 8. Calculez et imprimez combien de lignes ont des valeurs de colonne `Positive_Review` de "Aucun Positif" **et** des valeurs `Negative_Review` de "Aucun N√©gatif" ```python
   # with lambdas:
   start = time.time()
   no_negative_reviews = df.apply(lambda x: True if x['Negative_Review'] == "No Negative" else False , axis=1)
   print("Number of No Negative reviews: " + str(len(no_negative_reviews[no_negative_reviews == True].index)))
   
   no_positive_reviews = df.apply(lambda x: True if x['Positive_Review'] == "No Positive" else False , axis=1)
   print("Number of No Positive reviews: " + str(len(no_positive_reviews[no_positive_reviews == True].index)))
   
   both_no_reviews = df.apply(lambda x: True if x['Negative_Review'] == "No Negative" and x['Positive_Review'] == "No Positive" else False , axis=1)
   print("Number of both No Negative and No Positive reviews: " + str(len(both_no_reviews[both_no_reviews == True].index)))
   end = time.time()
   print("Lambdas took " + str(round(end - start, 2)) + " seconds")
   
   Number of No Negative reviews: 127890
   Number of No Positive reviews: 35946
   Number of both No Negative and No Positive reviews: 127
   Lambdas took 9.64 seconds
   ``` ## Une autre fa√ßon Une autre fa√ßon de compter les √©l√©ments sans Lambdas, et d'utiliser sum pour compter les lignes : ```python
   # without lambdas (using a mixture of notations to show you can use both)
   start = time.time()
   no_negative_reviews = sum(df.Negative_Review == "No Negative")
   print("Number of No Negative reviews: " + str(no_negative_reviews))
   
   no_positive_reviews = sum(df["Positive_Review"] == "No Positive")
   print("Number of No Positive reviews: " + str(no_positive_reviews))
   
   both_no_reviews = sum((df.Negative_Review == "No Negative") & (df.Positive_Review == "No Positive"))
   print("Number of both No Negative and No Positive reviews: " + str(both_no_reviews))
   
   end = time.time()
   print("Sum took " + str(round(end - start, 2)) + " seconds")
   
   Number of No Negative reviews: 127890
   Number of No Positive reviews: 35946
   Number of both No Negative and No Positive reviews: 127
   Sum took 0.19 seconds
   ``` Vous avez peut-√™tre remarqu√© qu'il y a 127 lignes qui ont √† la fois des valeurs "Aucun N√©gatif" et "Aucun Positif" pour les colonnes `Negative_Review` et `Positive_Review` respectivement. Cela signifie que l'examinateur a donn√© √† l'h√¥tel un score num√©rique, mais a refus√© d'√©crire soit une critique positive, soit une critique n√©gative. Heureusement, c'est un petit nombre de lignes (127 sur 515738, ou 0,02 %), donc cela ne faussera probablement pas notre mod√®le ou nos r√©sultats dans une direction particuli√®re, mais vous ne vous attendiez peut-√™tre pas √† ce qu'un ensemble de donn√©es de critiques ait des lignes sans critiques, donc il vaut la peine d'explorer les donn√©es pour d√©couvrir des lignes comme celle-ci. Maintenant que vous avez explor√© l'ensemble de donn√©es, dans la prochaine le√ßon, vous filtrerez les donn√©es et ajouterez une analyse de sentiment. --- ## üöÄD√©fi Cette le√ßon d√©montre, comme nous l'avons vu dans les le√ßons pr√©c√©dentes, √† quel point il est crucial de comprendre vos donn√©es et ses caprices avant d'effectuer des op√©rations dessus. Les donn√©es textuelles, en particulier, n√©cessitent un examen attentif. Fouillez √† travers divers ensembles de donn√©es riches en texte et voyez si vous pouvez d√©couvrir des domaines qui pourraient introduire des biais ou des sentiments fauss√©s dans un mod√®le. ## [Quiz post-lecture](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/38/) ## R√©vision & Auto-apprentissage Suivez [ce parcours d'apprentissage sur le NLP](https://docs.microsoft.com/learn/paths/explore-natural-language-processing/?WT.mc_id=academic-77952-leestott) pour d√©couvrir des outils √† essayer lors de la construction de mod√®les lourds en discours et en texte. ## Devoir [NLTK](assignment.md) Veuillez √©crire la sortie de gauche √† droite.

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide de services de traduction automatis√©s bas√©s sur l'IA. Bien que nous nous effor√ßons d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue native doit √™tre consid√©r√© comme la source autoritaire. Pour des informations critiques, une traduction humaine professionnelle est recommand√©e. Nous ne sommes pas responsables des malentendus ou des erreurs d'interpr√©tation r√©sultant de l'utilisation de cette traduction.