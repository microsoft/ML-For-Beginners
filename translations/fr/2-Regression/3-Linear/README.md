<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2f88fbc741d792890ff2f1430fe0dae0",
  "translation_date": "2025-09-03T22:16:07+00:00",
  "source_file": "2-Regression/3-Linear/README.md",
  "language_code": "fr"
}
-->
# Construire un mod√®le de r√©gression avec Scikit-learn : quatre approches de r√©gression

![Infographie sur la r√©gression lin√©aire vs polynomiale](../../../../translated_images/linear-polynomial.5523c7cb6576ccab0fecbd0e3505986eb2d191d9378e785f82befcf3a578a6e7.fr.png)
> Infographie par [Dasani Madipalli](https://twitter.com/dasani_decoded)
## [Quiz pr√©-lecture](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/13/)

> ### [Cette le√ßon est disponible en R !](../../../../2-Regression/3-Linear/solution/R/lesson_3.html)
### Introduction 

Jusqu'√† pr√©sent, vous avez explor√© ce qu'est la r√©gression √† l'aide d'un exemple de donn√©es issues du jeu de donn√©es sur les prix des citrouilles que nous utiliserons tout au long de cette le√ßon. Vous l'avez √©galement visualis√©e √† l'aide de Matplotlib.

Vous √™tes maintenant pr√™t √† plonger plus profond√©ment dans la r√©gression pour l'apprentissage automatique. Bien que la visualisation permette de comprendre les donn√©es, la v√©ritable puissance de l'apprentissage automatique r√©side dans l‚Äô_entra√Ænement des mod√®les_. Les mod√®les sont entra√Æn√©s sur des donn√©es historiques pour capturer automatiquement les d√©pendances entre les donn√©es, et ils permettent de pr√©dire des r√©sultats pour de nouvelles donn√©es que le mod√®le n'a jamais vues auparavant.

Dans cette le√ßon, vous en apprendrez davantage sur deux types de r√©gression : la _r√©gression lin√©aire de base_ et la _r√©gression polynomiale_, ainsi que sur certaines notions math√©matiques sous-jacentes √† ces techniques. Ces mod√®les nous permettront de pr√©dire les prix des citrouilles en fonction de diff√©rentes donn√©es d'entr√©e.

[![ML pour d√©butants - Comprendre la r√©gression lin√©aire](https://img.youtube.com/vi/CRxFT8oTDMg/0.jpg)](https://youtu.be/CRxFT8oTDMg "ML pour d√©butants - Comprendre la r√©gression lin√©aire")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o d'introduction √† la r√©gression lin√©aire.

> Tout au long de ce programme, nous supposons une connaissance minimale des math√©matiques et cherchons √† les rendre accessibles aux √©tudiants venant d'autres domaines. Soyez attentif aux notes, üßÆ encadr√©s, diagrammes et autres outils d'apprentissage pour faciliter la compr√©hension.

### Pr√©requis

Vous devriez maintenant √™tre familier avec la structure des donn√©es sur les citrouilles que nous examinons. Vous pouvez les trouver pr√©charg√©es et pr√©-nettoy√©es dans le fichier _notebook.ipynb_ de cette le√ßon. Dans ce fichier, le prix des citrouilles est affich√© par boisseau dans un nouveau DataFrame. Assurez-vous de pouvoir ex√©cuter ces notebooks dans des kernels dans Visual Studio Code.

### Pr√©paration

Pour rappel, vous chargez ces donn√©es afin de poser des questions √† leur sujet.

- Quel est le meilleur moment pour acheter des citrouilles ?
- Quel prix puis-je attendre pour une caisse de citrouilles miniatures ?
- Devrais-je les acheter en paniers d'un demi-boisseau ou en cartons de 1 1/9 boisseau ?
Continuons √† explorer ces donn√©es.

Dans la le√ßon pr√©c√©dente, vous avez cr√©√© un DataFrame Pandas et l'avez rempli avec une partie du jeu de donn√©es original, en standardisant les prix par boisseau. Cependant, en faisant cela, vous n'avez pu rassembler qu'environ 400 points de donn√©es, uniquement pour les mois d'automne.

Examinez les donn√©es pr√©charg√©es dans le notebook accompagnant cette le√ßon. Les donn√©es sont pr√©charg√©es et un nuage de points initial est trac√© pour montrer les donn√©es mensuelles. Peut-√™tre pouvons-nous obtenir un peu plus de d√©tails sur la nature des donn√©es en les nettoyant davantage.

## Une ligne de r√©gression lin√©aire

Comme vous l'avez appris dans la le√ßon 1, l'objectif d'un exercice de r√©gression lin√©aire est de tracer une ligne pour :

- **Montrer les relations entre les variables**. Montrer la relation entre les variables.
- **Faire des pr√©dictions**. Faire des pr√©dictions pr√©cises sur la position d'un nouveau point de donn√©es par rapport √† cette ligne.

Il est typique d'utiliser la **r√©gression des moindres carr√©s** pour tracer ce type de ligne. Le terme "moindres carr√©s" signifie que tous les points de donn√©es entourant la ligne de r√©gression sont √©lev√©s au carr√©, puis additionn√©s. Id√©alement, cette somme finale est aussi petite que possible, car nous voulons un faible nombre d'erreurs, ou "moindres carr√©s".

Nous faisons cela car nous voulons mod√©liser une ligne ayant la plus faible distance cumulative par rapport √† tous nos points de donn√©es. Nous √©levons √©galement les termes au carr√© avant de les additionner, car nous nous int√©ressons √† leur magnitude plut√¥t qu'√† leur direction.

> **üßÆ Montrez-moi les maths** 
> 
> Cette ligne, appel√©e _ligne de meilleure ad√©quation_, peut √™tre exprim√©e par [une √©quation](https://fr.wikipedia.org/wiki/R%C3%A9gression_lin%C3%A9aire_simple) : 
> 
> ```
> Y = a + bX
> ```
>
> `X` est la "variable explicative". `Y` est la "variable d√©pendante". La pente de la ligne est `b` et `a` est l'ordonn√©e √† l'origine, qui fait r√©f√©rence √† la valeur de `Y` lorsque `X = 0`. 
>
>![calculer la pente](../../../../translated_images/slope.f3c9d5910ddbfcf9096eb5564254ba22c9a32d7acd7694cab905d29ad8261db3.fr.png)
>
> Tout d'abord, calculez la pente `b`. Infographie par [Jen Looper](https://twitter.com/jenlooper)
>
> En d'autres termes, et en se r√©f√©rant √† la question initiale sur les donn√©es des citrouilles : "pr√©dire le prix d'une citrouille par boisseau selon le mois", `X` ferait r√©f√©rence au prix et `Y` au mois de vente. 
>
>![compl√©ter l'√©quation](../../../../translated_images/calculation.a209813050a1ddb141cdc4bc56f3af31e67157ed499e16a2ecf9837542704c94.fr.png)
>
> Calculez la valeur de Y. Si vous payez environ 4 $, cela doit √™tre en avril ! Infographie par [Jen Looper](https://twitter.com/jenlooper)
>
> Les calculs de cette ligne doivent d√©montrer la pente de la ligne, qui d√©pend √©galement de l'ordonn√©e √† l'origine, ou de la position de `Y` lorsque `X = 0`.
>
> Vous pouvez observer la m√©thode de calcul de ces valeurs sur le site [Math is Fun](https://www.mathsisfun.com/data/least-squares-regression.html). Consultez √©galement [ce calculateur des moindres carr√©s](https://www.mathsisfun.com/data/least-squares-calculator.html) pour voir comment les valeurs influencent la ligne.

## Corr√©lation

Un autre terme √† comprendre est le **coefficient de corr√©lation** entre les variables X et Y donn√©es. √Ä l'aide d'un nuage de points, vous pouvez rapidement visualiser ce coefficient. Un graphique avec des points de donn√©es align√©s de mani√®re nette pr√©sente une forte corr√©lation, tandis qu'un graphique avec des points dispers√©s partout entre X et Y pr√©sente une faible corr√©lation.

Un bon mod√®le de r√©gression lin√©aire sera celui qui a un coefficient de corr√©lation √©lev√© (proche de 1 plut√¥t que de 0) en utilisant la m√©thode des moindres carr√©s avec une ligne de r√©gression.

‚úÖ Ex√©cutez le notebook accompagnant cette le√ßon et examinez le nuage de points associant le mois au prix. Les donn√©es associant le mois au prix des ventes de citrouilles semblent-elles avoir une corr√©lation √©lev√©e ou faible, selon votre interpr√©tation visuelle du nuage de points ? Cela change-t-il si vous utilisez une mesure plus fine comme le *jour de l'ann√©e* (c'est-√†-dire le nombre de jours depuis le d√©but de l'ann√©e) ?

Dans le code ci-dessous, nous supposerons que nous avons nettoy√© les donn√©es et obtenu un DataFrame appel√© `new_pumpkins`, similaire √† ce qui suit :

ID | Mois | JourDeLAnnee | Vari√©t√© | Ville | Emballage | Prix Bas | Prix Haut | Prix
---|------|--------------|---------|-------|-----------|----------|-----------|------
70 | 9 | 267 | TYPE TARTE | BALTIMORE | cartons de 1 1/9 boisseau | 15.0 | 15.0 | 13.636364
71 | 9 | 267 | TYPE TARTE | BALTIMORE | cartons de 1 1/9 boisseau | 18.0 | 18.0 | 16.363636
72 | 10 | 274 | TYPE TARTE | BALTIMORE | cartons de 1 1/9 boisseau | 18.0 | 18.0 | 16.363636
73 | 10 | 274 | TYPE TARTE | BALTIMORE | cartons de 1 1/9 boisseau | 17.0 | 17.0 | 15.454545
74 | 10 | 281 | TYPE TARTE | BALTIMORE | cartons de 1 1/9 boisseau | 15.0 | 15.0 | 13.636364

> Le code pour nettoyer les donn√©es est disponible dans [`notebook.ipynb`](notebook.ipynb). Nous avons effectu√© les m√™mes √©tapes de nettoyage que dans la le√ßon pr√©c√©dente et avons calcul√© la colonne `JourDeLAnnee` √† l'aide de l'expression suivante : 

```python
day_of_year = pd.to_datetime(pumpkins['Date']).apply(lambda dt: (dt-datetime(dt.year,1,1)).days)
```

Maintenant que vous comprenez les math√©matiques derri√®re la r√©gression lin√©aire, cr√©ons un mod√®le de r√©gression pour voir si nous pouvons pr√©dire quel emballage de citrouilles aura les meilleurs prix. Une personne achetant des citrouilles pour un champ de citrouilles pour les f√™tes pourrait vouloir cette information pour optimiser ses achats.

## Recherche de corr√©lation

[![ML pour d√©butants - Recherche de corr√©lation : la cl√© de la r√©gression lin√©aire](https://img.youtube.com/vi/uoRq-lW2eQo/0.jpg)](https://youtu.be/uoRq-lW2eQo "ML pour d√©butants - Recherche de corr√©lation : la cl√© de la r√©gression lin√©aire")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o sur la corr√©lation.

Dans la le√ßon pr√©c√©dente, vous avez probablement vu que le prix moyen pour diff√©rents mois ressemble √† ceci :

<img alt="Prix moyen par mois" src="../2-Data/images/barchart.png" width="50%"/>

Cela sugg√®re qu'il devrait y avoir une certaine corr√©lation, et nous pouvons essayer d'entra√Æner un mod√®le de r√©gression lin√©aire pour pr√©dire la relation entre `Mois` et `Prix`, ou entre `JourDeLAnnee` et `Prix`. Voici le nuage de points montrant cette derni√®re relation :

<img alt="Nuage de points du prix vs jour de l'ann√©e" src="images/scatter-dayofyear.png" width="50%" /> 

Voyons s'il existe une corr√©lation √† l'aide de la fonction `corr` :

```python
print(new_pumpkins['Month'].corr(new_pumpkins['Price']))
print(new_pumpkins['DayOfYear'].corr(new_pumpkins['Price']))
```

Il semble que la corr√©lation soit assez faible, -0,15 pour `Mois` et -0,17 pour `JourDeLAnnee`, mais il pourrait y avoir une autre relation importante. Il semble qu'il existe diff√©rents groupes de prix correspondant √† diff√©rentes vari√©t√©s de citrouilles. Pour confirmer cette hypoth√®se, tra√ßons chaque cat√©gorie de citrouilles avec une couleur diff√©rente. En passant un param√®tre `ax` √† la fonction de trac√© `scatter`, nous pouvons tracer tous les points sur le m√™me graphique :

```python
ax=None
colors = ['red','blue','green','yellow']
for i,var in enumerate(new_pumpkins['Variety'].unique()):
    df = new_pumpkins[new_pumpkins['Variety']==var]
    ax = df.plot.scatter('DayOfYear','Price',ax=ax,c=colors[i],label=var)
```

<img alt="Nuage de points du prix vs jour de l'ann√©e" src="images/scatter-dayofyear-color.png" width="50%" /> 

Notre enqu√™te sugg√®re que la vari√©t√© a plus d'effet sur le prix global que la date de vente r√©elle. Nous pouvons le voir avec un graphique en barres :

```python
new_pumpkins.groupby('Variety')['Price'].mean().plot(kind='bar')
```

<img alt="Graphique en barres du prix vs vari√©t√©" src="images/price-by-variety.png" width="50%" /> 

Concentrons-nous pour le moment uniquement sur une vari√©t√© de citrouilles, le "type tarte", et voyons quel effet la date a sur le prix :

```python
pie_pumpkins = new_pumpkins[new_pumpkins['Variety']=='PIE TYPE']
pie_pumpkins.plot.scatter('DayOfYear','Price') 
```
<img alt="Nuage de points du prix vs jour de l'ann√©e" src="images/pie-pumpkins-scatter.png" width="50%" /> 

Si nous calculons maintenant la corr√©lation entre `Prix` et `JourDeLAnnee` √† l'aide de la fonction `corr`, nous obtiendrons quelque chose comme `-0,27` - ce qui signifie qu'entra√Æner un mod√®le pr√©dictif a du sens.

> Avant d'entra√Æner un mod√®le de r√©gression lin√©aire, il est important de s'assurer que nos donn√©es sont propres. La r√©gression lin√©aire ne fonctionne pas bien avec des valeurs manquantes, il est donc logique de se d√©barrasser de toutes les cellules vides :

```python
pie_pumpkins.dropna(inplace=True)
pie_pumpkins.info()
```

Une autre approche consisterait √† remplir ces valeurs vides avec les valeurs moyennes de la colonne correspondante.

## R√©gression lin√©aire simple

[![ML pour d√©butants - R√©gression lin√©aire et polynomiale avec Scikit-learn](https://img.youtube.com/vi/e4c_UP2fSjg/0.jpg)](https://youtu.be/e4c_UP2fSjg "ML pour d√©butants - R√©gression lin√©aire et polynomiale avec Scikit-learn")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o sur la r√©gression lin√©aire et polynomiale.

Pour entra√Æner notre mod√®le de r√©gression lin√©aire, nous utiliserons la biblioth√®que **Scikit-learn**.

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
```

Nous commen√ßons par s√©parer les valeurs d'entr√©e (caract√©ristiques) et la sortie attendue (√©tiquette) en tableaux numpy distincts :

```python
X = pie_pumpkins['DayOfYear'].to_numpy().reshape(-1,1)
y = pie_pumpkins['Price']
```

> Notez que nous avons d√ª effectuer un `reshape` sur les donn√©es d'entr√©e pour que le package de r√©gression lin√©aire les comprenne correctement. La r√©gression lin√©aire attend un tableau 2D en entr√©e, o√π chaque ligne du tableau correspond √† un vecteur de caract√©ristiques d'entr√©e. Dans notre cas, comme nous n'avons qu'une seule entr√©e, nous avons besoin d'un tableau de forme N√ó1, o√π N est la taille du jeu de donn√©es.

Ensuite, nous devons diviser les donn√©es en ensembles d'entra√Ænement et de test, afin de pouvoir valider notre mod√®le apr√®s l'entra√Ænement :

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
```

Enfin, entra√Æner le mod√®le de r√©gression lin√©aire r√©el ne prend que deux lignes de code. Nous d√©finissons l'objet `LinearRegression` et l'ajustons √† nos donn√©es √† l'aide de la m√©thode `fit` :

```python
lin_reg = LinearRegression()
lin_reg.fit(X_train,y_train)
```

L'objet `LinearRegression` apr√®s l'ajustement contient tous les coefficients de la r√©gression, accessibles via la propri√©t√© `.coef_`. Dans notre cas, il n'y a qu'un seul coefficient, qui devrait √™tre d'environ `-0,017`. Cela signifie que les prix semblent l√©g√®rement baisser avec le temps, mais pas beaucoup, environ 2 centimes par jour. Nous pouvons √©galement acc√©der au point d'intersection de la r√©gression avec l'axe Y √† l'aide de `lin_reg.intercept_` - il sera d'environ `21` dans notre cas, indiquant le prix au d√©but de l'ann√©e.

Pour voir √† quel point notre mod√®le est pr√©cis, nous pouvons pr√©dire les prix sur un ensemble de test, puis mesurer √† quel point nos pr√©dictions sont proches des valeurs attendues. Cela peut √™tre fait √† l'aide de la m√©trique de l'erreur quadratique moyenne (MSE), qui est la moyenne de toutes les diff√©rences au carr√© entre les valeurs attendues et pr√©dites.

```python
pred = lin_reg.predict(X_test)

mse = np.sqrt(mean_squared_error(y_test,pred))
print(f'Mean error: {mse:3.3} ({mse/np.mean(pred)*100:3.3}%)')
```
Notre erreur semble se situer autour de 2 points, soit environ 17 %. Pas tr√®s bon. Un autre indicateur de la qualit√© du mod√®le est le **coefficient de d√©termination**, que l'on peut obtenir comme suit :

```python
score = lin_reg.score(X_train,y_train)
print('Model determination: ', score)
```
Si la valeur est 0, cela signifie que le mod√®le ne prend pas en compte les donn√©es d'entr√©e et agit comme le *pire pr√©dicteur lin√©aire*, qui est simplement une moyenne des r√©sultats. Une valeur de 1 signifie que nous pouvons pr√©dire parfaitement tous les r√©sultats attendus. Dans notre cas, le coefficient est d'environ 0,06, ce qui est assez faible.

Nous pouvons √©galement tracer les donn√©es de test avec la ligne de r√©gression pour mieux comprendre comment la r√©gression fonctionne dans notre cas :

```python
plt.scatter(X_test,y_test)
plt.plot(X_test,pred)
```

<img alt="R√©gression lin√©aire" src="images/linear-results.png" width="50%" />

## R√©gression polynomiale

Un autre type de r√©gression lin√©aire est la r√©gression polynomiale. Bien qu'il existe parfois une relation lin√©aire entre les variables - plus le volume de la citrouille est grand, plus le prix est √©lev√© - ces relations ne peuvent parfois pas √™tre repr√©sent√©es par un plan ou une ligne droite.

‚úÖ Voici [quelques exemples suppl√©mentaires](https://online.stat.psu.edu/stat501/lesson/9/9.8) de donn√©es qui pourraient utiliser la r√©gression polynomiale.

Regardez √† nouveau la relation entre la date et le prix. Ce nuage de points semble-t-il devoir n√©cessairement √™tre analys√© par une ligne droite ? Les prix ne peuvent-ils pas fluctuer ? Dans ce cas, vous pouvez essayer la r√©gression polynomiale.

‚úÖ Les polyn√¥mes sont des expressions math√©matiques qui peuvent contenir une ou plusieurs variables et coefficients.

La r√©gression polynomiale cr√©e une courbe pour mieux ajuster les donn√©es non lin√©aires. Dans notre cas, si nous incluons une variable `DayOfYear` au carr√© dans les donn√©es d'entr√©e, nous devrions pouvoir ajuster nos donn√©es avec une courbe parabolique, qui aura un minimum √† un certain moment de l'ann√©e.

Scikit-learn inclut une API [pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html?highlight=pipeline#sklearn.pipeline.make_pipeline) utile pour combiner diff√©rentes √©tapes de traitement des donn√©es. Un **pipeline** est une cha√Æne d'**estimateurs**. Dans notre cas, nous allons cr√©er un pipeline qui ajoute d'abord des caract√©ristiques polynomiales √† notre mod√®le, puis entra√Æne la r√©gression :

```python
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

pipeline = make_pipeline(PolynomialFeatures(2), LinearRegression())

pipeline.fit(X_train,y_train)
```

Utiliser `PolynomialFeatures(2)` signifie que nous inclurons tous les polyn√¥mes de degr√© 2 des donn√©es d'entr√©e. Dans notre cas, cela signifie simplement `DayOfYear`<sup>2</sup>, mais avec deux variables d'entr√©e X et Y, cela ajoutera X<sup>2</sup>, XY et Y<sup>2</sup>. Nous pouvons √©galement utiliser des polyn√¥mes de degr√© sup√©rieur si nous le souhaitons.

Les pipelines peuvent √™tre utilis√©s de la m√™me mani√®re que l'objet `LinearRegression` original, c'est-√†-dire que nous pouvons `fit` le pipeline, puis utiliser `predict` pour obtenir les r√©sultats de pr√©diction. Voici le graphique montrant les donn√©es de test et la courbe d'approximation :

<img alt="R√©gression polynomiale" src="images/poly-results.png" width="50%" />

Avec la r√©gression polynomiale, nous pouvons obtenir un MSE l√©g√®rement inf√©rieur et un coefficient de d√©termination plus √©lev√©, mais pas de mani√®re significative. Nous devons prendre en compte d'autres caract√©ristiques !

> Vous pouvez voir que les prix minimaux des citrouilles sont observ√©s autour d'Halloween. Comment expliquez-vous cela ?

üéÉ F√©licitations, vous venez de cr√©er un mod√®le qui peut aider √† pr√©dire le prix des citrouilles pour tartes. Vous pouvez probablement r√©p√©ter la m√™me proc√©dure pour tous les types de citrouilles, mais cela serait fastidieux. Apprenons maintenant √† prendre en compte la vari√©t√© des citrouilles dans notre mod√®le !

## Caract√©ristiques cat√©gorielles

Dans un monde id√©al, nous voulons pouvoir pr√©dire les prix pour diff√©rentes vari√©t√©s de citrouilles en utilisant le m√™me mod√®le. Cependant, la colonne `Variety` est quelque peu diff√©rente des colonnes comme `Month`, car elle contient des valeurs non num√©riques. Ces colonnes sont appel√©es **cat√©gorielles**.

[![ML pour d√©butants - Pr√©dictions avec caract√©ristiques cat√©gorielles et r√©gression lin√©aire](https://img.youtube.com/vi/DYGliioIAE0/0.jpg)](https://youtu.be/DYGliioIAE0 "ML pour d√©butants - Pr√©dictions avec caract√©ristiques cat√©gorielles et r√©gression lin√©aire")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o sur l'utilisation des caract√©ristiques cat√©gorielles.

Voici comment le prix moyen d√©pend de la vari√©t√© :

<img alt="Prix moyen par vari√©t√©" src="images/price-by-variety.png" width="50%" />

Pour prendre en compte la vari√©t√©, nous devons d'abord la convertir en forme num√©rique, ou **encoder**. Il existe plusieurs fa√ßons de le faire :

* Un simple **encodage num√©rique** construira un tableau des diff√©rentes vari√©t√©s, puis remplacera le nom de la vari√©t√© par un indice dans ce tableau. Ce n'est pas la meilleure id√©e pour la r√©gression lin√©aire, car la r√©gression lin√©aire prend la valeur num√©rique r√©elle de l'indice et l'ajoute au r√©sultat, en la multipliant par un coefficient. Dans notre cas, la relation entre le num√©ro d'indice et le prix est clairement non lin√©aire, m√™me si nous nous assurons que les indices sont ordonn√©s d'une mani√®re sp√©cifique.
* **L'encodage one-hot** remplacera la colonne `Variety` par 4 colonnes diff√©rentes, une pour chaque vari√©t√©. Chaque colonne contiendra `1` si la ligne correspondante est d'une vari√©t√© donn√©e, et `0` sinon. Cela signifie qu'il y aura quatre coefficients dans la r√©gression lin√©aire, un pour chaque vari√©t√© de citrouille, responsable du "prix de d√©part" (ou plut√¥t "prix suppl√©mentaire") pour cette vari√©t√© particuli√®re.

Le code ci-dessous montre comment nous pouvons encoder une vari√©t√© en one-hot :

```python
pd.get_dummies(new_pumpkins['Variety'])
```

 ID | FAIRYTALE | MINIATURE | MIXED HEIRLOOM VARIETIES | PIE TYPE
----|-----------|-----------|--------------------------|----------
70 | 0 | 0 | 0 | 1
71 | 0 | 0 | 0 | 1
... | ... | ... | ... | ...
1738 | 0 | 1 | 0 | 0
1739 | 0 | 1 | 0 | 0
1740 | 0 | 1 | 0 | 0
1741 | 0 | 1 | 0 | 0
1742 | 0 | 1 | 0 | 0

Pour entra√Æner une r√©gression lin√©aire en utilisant la vari√©t√© encod√©e en one-hot comme entr√©e, nous devons simplement initialiser correctement les donn√©es `X` et `y` :

```python
X = pd.get_dummies(new_pumpkins['Variety'])
y = new_pumpkins['Price']
```

Le reste du code est identique √† celui que nous avons utilis√© ci-dessus pour entra√Æner la r√©gression lin√©aire. Si vous essayez, vous verrez que l'erreur quadratique moyenne est √† peu pr√®s la m√™me, mais nous obtenons un coefficient de d√©termination beaucoup plus √©lev√© (~77 %). Pour obtenir des pr√©dictions encore plus pr√©cises, nous pouvons prendre en compte davantage de caract√©ristiques cat√©gorielles, ainsi que des caract√©ristiques num√©riques, comme `Month` ou `DayOfYear`. Pour obtenir un grand tableau de caract√©ristiques, nous pouvons utiliser `join` :

```python
X = pd.get_dummies(new_pumpkins['Variety']) \
        .join(new_pumpkins['Month']) \
        .join(pd.get_dummies(new_pumpkins['City'])) \
        .join(pd.get_dummies(new_pumpkins['Package']))
y = new_pumpkins['Price']
```

Ici, nous prenons √©galement en compte `City` et le type de `Package`, ce qui nous donne un MSE de 2,84 (10 %) et un coefficient de d√©termination de 0,94 !

## Tout rassembler

Pour cr√©er le meilleur mod√®le, nous pouvons utiliser les donn√©es combin√©es (cat√©gorielles encod√©es en one-hot + num√©riques) de l'exemple ci-dessus avec la r√©gression polynomiale. Voici le code complet pour votre commodit√© :

```python
# set up training data
X = pd.get_dummies(new_pumpkins['Variety']) \
        .join(new_pumpkins['Month']) \
        .join(pd.get_dummies(new_pumpkins['City'])) \
        .join(pd.get_dummies(new_pumpkins['Package']))
y = new_pumpkins['Price']

# make train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# setup and train the pipeline
pipeline = make_pipeline(PolynomialFeatures(2), LinearRegression())
pipeline.fit(X_train,y_train)

# predict results for test data
pred = pipeline.predict(X_test)

# calculate MSE and determination
mse = np.sqrt(mean_squared_error(y_test,pred))
print(f'Mean error: {mse:3.3} ({mse/np.mean(pred)*100:3.3}%)')

score = pipeline.score(X_train,y_train)
print('Model determination: ', score)
```

Cela devrait nous donner le meilleur coefficient de d√©termination, presque 97 %, et un MSE=2,23 (~8 % d'erreur de pr√©diction).

| Mod√®le | MSE | D√©termination |
|--------|-----|---------------|
| `DayOfYear` Lin√©aire | 2,77 (17,2 %) | 0,07 |
| `DayOfYear` Polynomial | 2,73 (17,0 %) | 0,08 |
| `Variety` Lin√©aire | 5,24 (19,7 %) | 0,77 |
| Toutes les caract√©ristiques Lin√©aire | 2,84 (10,5 %) | 0,94 |
| Toutes les caract√©ristiques Polynomial | 2,23 (8,25 %) | 0,97 |

üèÜ Bien jou√© ! Vous avez cr√©√© quatre mod√®les de r√©gression en une seule le√ßon et am√©lior√© la qualit√© du mod√®le √† 97 %. Dans la section finale sur la r√©gression, vous apprendrez la r√©gression logistique pour d√©terminer des cat√©gories.

---
## üöÄD√©fi

Testez plusieurs variables diff√©rentes dans ce notebook pour voir comment la corr√©lation correspond √† la pr√©cision du mod√®le.

## [Quiz post-lecture](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/14/)

## R√©vision et auto-apprentissage

Dans cette le√ßon, nous avons appris la r√©gression lin√©aire. Il existe d'autres types importants de r√©gression. Lisez sur les techniques Stepwise, Ridge, Lasso et Elasticnet. Un bon cours pour approfondir est le [cours de Stanford sur l'apprentissage statistique](https://online.stanford.edu/courses/sohs-ystatslearning-statistical-learning).

## Devoir 

[Construisez un mod√®le](assignment.md)

---

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction professionnelle r√©alis√©e par un humain. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.