<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "40e64f004f3cb50aa1d8661672d3cd92",
  "translation_date": "2025-09-04T22:51:19+00:00",
  "source_file": "2-Regression/3-Linear/README.md",
  "language_code": "fr"
}
-->
# Construire un mod√®le de r√©gression avec Scikit-learn : quatre approches de r√©gression

![Infographie sur la r√©gression lin√©aire vs polynomiale](../../../../2-Regression/3-Linear/images/linear-polynomial.png)
> Infographie par [Dasani Madipalli](https://twitter.com/dasani_decoded)
## [Quiz avant le cours](https://ff-quizzes.netlify.app/en/ml/)

> ### [Cette le√ßon est disponible en R !](../../../../2-Regression/3-Linear/solution/R/lesson_3.html)
### Introduction 

Jusqu'√† pr√©sent, vous avez explor√© ce qu'est la r√©gression avec des donn√©es d'exemple issues du jeu de donn√©es sur les prix des citrouilles que nous utiliserons tout au long de cette le√ßon. Vous l'avez √©galement visualis√©e √† l'aide de Matplotlib.

Vous √™tes maintenant pr√™t √† approfondir la r√©gression pour l'apprentissage automatique. Bien que la visualisation permette de donner du sens aux donn√©es, la v√©ritable puissance de l'apprentissage automatique r√©side dans l'_entra√Ænement des mod√®les_. Les mod√®les sont entra√Æn√©s sur des donn√©es historiques pour capturer automatiquement les d√©pendances des donn√©es, et ils permettent de pr√©dire les r√©sultats pour de nouvelles donn√©es que le mod√®le n'a jamais vues auparavant.

Dans cette le√ßon, vous en apprendrez davantage sur deux types de r√©gression : _la r√©gression lin√©aire de base_ et _la r√©gression polynomiale_, ainsi que sur certaines notions math√©matiques sous-jacentes √† ces techniques. Ces mod√®les nous permettront de pr√©dire les prix des citrouilles en fonction de diff√©rentes donn√©es d'entr√©e.

[![ML pour d√©butants - Comprendre la r√©gression lin√©aire](https://img.youtube.com/vi/CRxFT8oTDMg/0.jpg)](https://youtu.be/CRxFT8oTDMg "ML pour d√©butants - Comprendre la r√©gression lin√©aire")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o d'introduction √† la r√©gression lin√©aire.

> Tout au long de ce programme, nous supposons une connaissance minimale des math√©matiques et cherchons √† les rendre accessibles aux √©tudiants venant d'autres domaines. Soyez attentif aux notes, üßÆ aux encadr√©s, aux diagrammes et √† d'autres outils d'apprentissage pour faciliter la compr√©hension.

### Pr√©requis

Vous devriez maintenant √™tre familier avec la structure des donn√©es sur les citrouilles que nous examinons. Vous pouvez les trouver pr√©charg√©es et pr√©-nettoy√©es dans le fichier _notebook.ipynb_ de cette le√ßon. Dans ce fichier, le prix des citrouilles est affich√© par boisseau dans un nouveau cadre de donn√©es. Assurez-vous de pouvoir ex√©cuter ces notebooks dans des kernels dans Visual Studio Code.

### Pr√©paration

Pour rappel, vous chargez ces donn√©es afin de poser des questions √† leur sujet.

- Quel est le meilleur moment pour acheter des citrouilles ? 
- Quel prix puis-je attendre pour une caisse de citrouilles miniatures ?
- Dois-je les acheter en paniers d'un demi-boisseau ou en cartons de 1 1/9 boisseau ?
Continuons √† explorer ces donn√©es.

Dans la le√ßon pr√©c√©dente, vous avez cr√©√© un cadre de donn√©es Pandas et l'avez rempli avec une partie du jeu de donn√©es original, en standardisant les prix par boisseau. Cependant, en faisant cela, vous n'avez pu recueillir qu'environ 400 points de donn√©es et uniquement pour les mois d'automne.

Examinez les donn√©es que nous avons pr√©charg√©es dans le notebook accompagnant cette le√ßon. Les donn√©es sont pr√©charg√©es et un premier nuage de points est trac√© pour montrer les donn√©es mensuelles. Peut-√™tre pouvons-nous obtenir un peu plus de d√©tails sur la nature des donn√©es en les nettoyant davantage.

## Une ligne de r√©gression lin√©aire

Comme vous l'avez appris dans la le√ßon 1, l'objectif d'un exercice de r√©gression lin√©aire est de pouvoir tracer une ligne pour :

- **Montrer les relations entre les variables**. Montrer la relation entre les variables
- **Faire des pr√©dictions**. Faire des pr√©dictions pr√©cises sur l'endroit o√π un nouveau point de donn√©es se situerait par rapport √† cette ligne. 
 
Il est typique de la **r√©gression des moindres carr√©s** de tracer ce type de ligne. Le terme "moindres carr√©s" signifie que tous les points de donn√©es entourant la ligne de r√©gression sont √©lev√©s au carr√© puis additionn√©s. Id√©alement, cette somme finale est aussi petite que possible, car nous voulons un faible nombre d'erreurs, ou `moindres carr√©s`. 

Nous proc√©dons ainsi car nous voulons mod√©liser une ligne ayant la plus faible distance cumul√©e par rapport √† tous nos points de donn√©es. Nous √©levons √©galement les termes au carr√© avant de les additionner, car nous nous int√©ressons √† leur magnitude plut√¥t qu'√† leur direction.

> **üßÆ Montrez-moi les maths** 
> 
> Cette ligne, appel√©e _ligne de meilleure ajustement_, peut √™tre exprim√©e par [une √©quation](https://en.wikipedia.org/wiki/Simple_linear_regression) : 
> 
> ```
> Y = a + bX
> ```
>
> `X` est la 'variable explicative'. `Y` est la 'variable d√©pendante'. La pente de la ligne est `b` et `a` est l'ordonn√©e √† l'origine, qui fait r√©f√©rence √† la valeur de `Y` lorsque `X = 0`. 
>
>![calculer la pente](../../../../2-Regression/3-Linear/images/slope.png)
>
> Tout d'abord, calculez la pente `b`. Infographie par [Jen Looper](https://twitter.com/jenlooper)
>
> En d'autres termes, et en se r√©f√©rant √† la question originale sur les donn√©es des citrouilles : "pr√©dire le prix d'une citrouille par boisseau selon le mois", `X` ferait r√©f√©rence au prix et `Y` au mois de vente. 
>
>![compl√©ter l'√©quation](../../../../2-Regression/3-Linear/images/calculation.png)
>
> Calculez la valeur de Y. Si vous payez environ 4 $, cela doit √™tre en avril ! Infographie par [Jen Looper](https://twitter.com/jenlooper)
>
> Les calculs math√©matiques de la ligne doivent d√©montrer la pente de la ligne, qui d√©pend √©galement de l'ordonn√©e √† l'origine, ou de la position de `Y` lorsque `X = 0`.
>
> Vous pouvez observer la m√©thode de calcul de ces valeurs sur le site [Math is Fun](https://www.mathsisfun.com/data/least-squares-regression.html). Consultez √©galement [ce calculateur de moindres carr√©s](https://www.mathsisfun.com/data/least-squares-calculator.html) pour voir comment les valeurs des nombres influencent la ligne.

## Corr√©lation

Un autre terme √† comprendre est le **coefficient de corr√©lation** entre les variables X et Y donn√©es. √Ä l'aide d'un nuage de points, vous pouvez rapidement visualiser ce coefficient. Un graphique avec des points de donn√©es align√©s de mani√®re ordonn√©e pr√©sente une forte corr√©lation, mais un graphique avec des points de donn√©es dispers√©s partout entre X et Y pr√©sente une faible corr√©lation.

Un bon mod√®le de r√©gression lin√©aire sera celui qui pr√©sente un coefficient de corr√©lation √©lev√© (plus proche de 1 que de 0) en utilisant la m√©thode de r√©gression des moindres carr√©s avec une ligne de r√©gression.

‚úÖ Ex√©cutez le notebook accompagnant cette le√ßon et examinez le nuage de points associant le mois au prix. Selon votre interpr√©tation visuelle du nuage de points, les donn√©es associant le mois au prix des ventes de citrouilles semblent-elles pr√©senter une corr√©lation √©lev√©e ou faible ? Cela change-t-il si vous utilisez une mesure plus fine, comme *le jour de l'ann√©e* (c'est-√†-dire le nombre de jours depuis le d√©but de l'ann√©e) ?

Dans le code ci-dessous, nous supposerons que nous avons nettoy√© les donn√©es et obtenu un cadre de donn√©es appel√© `new_pumpkins`, similaire √† ce qui suit :

ID | Mois | JourDeLAn | Vari√©t√© | Ville | Emballage | Prix bas | Prix haut | Prix
---|------|-----------|---------|-------|-----------|----------|-----------|------
70 | 9 | 267 | TYPE TARTE | BALTIMORE | cartons de 1 1/9 boisseau | 15.0 | 15.0 | 13.636364
71 | 9 | 267 | TYPE TARTE | BALTIMORE | cartons de 1 1/9 boisseau | 18.0 | 18.0 | 16.363636
72 | 10 | 274 | TYPE TARTE | BALTIMORE | cartons de 1 1/9 boisseau | 18.0 | 18.0 | 16.363636
73 | 10 | 274 | TYPE TARTE | BALTIMORE | cartons de 1 1/9 boisseau | 17.0 | 17.0 | 15.454545
74 | 10 | 281 | TYPE TARTE | BALTIMORE | cartons de 1 1/9 boisseau | 15.0 | 15.0 | 13.636364

> Le code pour nettoyer les donn√©es est disponible dans [`notebook.ipynb`](../../../../2-Regression/3-Linear/notebook.ipynb). Nous avons effectu√© les m√™mes √©tapes de nettoyage que dans la le√ßon pr√©c√©dente et avons calcul√© la colonne `JourDeLAn` en utilisant l'expression suivante : 

```python
day_of_year = pd.to_datetime(pumpkins['Date']).apply(lambda dt: (dt-datetime(dt.year,1,1)).days)
```

Maintenant que vous comprenez les math√©matiques derri√®re la r√©gression lin√©aire, cr√©ons un mod√®le de r√©gression pour voir si nous pouvons pr√©dire quel emballage de citrouilles aura les meilleurs prix. Quelqu'un achetant des citrouilles pour un champ de citrouilles de vacances pourrait vouloir cette information pour optimiser ses achats d'emballages de citrouilles pour le champ.

## Recherche de corr√©lation

[![ML pour d√©butants - Recherche de corr√©lation : la cl√© de la r√©gression lin√©aire](https://img.youtube.com/vi/uoRq-lW2eQo/0.jpg)](https://youtu.be/uoRq-lW2eQo "ML pour d√©butants - Recherche de corr√©lation : la cl√© de la r√©gression lin√©aire")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o sur la corr√©lation.

Dans la le√ßon pr√©c√©dente, vous avez probablement vu que le prix moyen pour diff√©rents mois ressemble √† ceci :

<img alt="Prix moyen par mois" src="../2-Data/images/barchart.png" width="50%"/>

Cela sugg√®re qu'il pourrait y avoir une certaine corr√©lation, et nous pouvons essayer d'entra√Æner un mod√®le de r√©gression lin√©aire pour pr√©dire la relation entre `Mois` et `Prix`, ou entre `JourDeLAn` et `Prix`. Voici le nuage de points qui montre cette derni√®re relation :

<img alt="Nuage de points du prix vs jour de l'ann√©e" src="images/scatter-dayofyear.png" width="50%" /> 

Voyons s'il existe une corr√©lation en utilisant la fonction `corr` :

```python
print(new_pumpkins['Month'].corr(new_pumpkins['Price']))
print(new_pumpkins['DayOfYear'].corr(new_pumpkins['Price']))
```

Il semble que la corr√©lation soit assez faible, -0.15 par `Mois` et -0.17 par `JourDeLAn`, mais il pourrait y avoir une autre relation importante. Il semble qu'il existe diff√©rents groupes de prix correspondant √† diff√©rentes vari√©t√©s de citrouilles. Pour confirmer cette hypoth√®se, tra√ßons chaque cat√©gorie de citrouilles en utilisant une couleur diff√©rente. En passant un param√®tre `ax` √† la fonction de trac√© de nuage de points, nous pouvons tracer tous les points sur le m√™me graphique :

```python
ax=None
colors = ['red','blue','green','yellow']
for i,var in enumerate(new_pumpkins['Variety'].unique()):
    df = new_pumpkins[new_pumpkins['Variety']==var]
    ax = df.plot.scatter('DayOfYear','Price',ax=ax,c=colors[i],label=var)
```

<img alt="Nuage de points du prix vs jour de l'ann√©e" src="images/scatter-dayofyear-color.png" width="50%" /> 

Notre enqu√™te sugg√®re que la vari√©t√© a plus d'effet sur le prix global que la date de vente r√©elle. Nous pouvons le voir avec un graphique en barres :

```python
new_pumpkins.groupby('Variety')['Price'].mean().plot(kind='bar')
```

<img alt="Graphique en barres du prix vs vari√©t√©" src="images/price-by-variety.png" width="50%" /> 

Concentrons-nous pour le moment uniquement sur une vari√©t√© de citrouilles, le 'type tarte', et voyons quel effet la date a sur le prix :

```python
pie_pumpkins = new_pumpkins[new_pumpkins['Variety']=='PIE TYPE']
pie_pumpkins.plot.scatter('DayOfYear','Price') 
```
<img alt="Nuage de points du prix vs jour de l'ann√©e" src="images/pie-pumpkins-scatter.png" width="50%" /> 

Si nous calculons maintenant la corr√©lation entre `Prix` et `JourDeLAn` en utilisant la fonction `corr`, nous obtiendrons quelque chose comme `-0.27` - ce qui signifie qu'entra√Æner un mod√®le pr√©dictif a du sens.

> Avant d'entra√Æner un mod√®le de r√©gression lin√©aire, il est important de s'assurer que nos donn√©es sont propres. La r√©gression lin√©aire ne fonctionne pas bien avec des valeurs manquantes, il est donc logique de se d√©barrasser de toutes les cellules vides :

```python
pie_pumpkins.dropna(inplace=True)
pie_pumpkins.info()
```

Une autre approche consisterait √† remplir ces valeurs manquantes avec les valeurs moyennes de la colonne correspondante.

## R√©gression lin√©aire simple

[![ML pour d√©butants - R√©gression lin√©aire et polynomiale avec Scikit-learn](https://img.youtube.com/vi/e4c_UP2fSjg/0.jpg)](https://youtu.be/e4c_UP2fSjg "ML pour d√©butants - R√©gression lin√©aire et polynomiale avec Scikit-learn")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o sur la r√©gression lin√©aire et polynomiale.

Pour entra√Æner notre mod√®le de r√©gression lin√©aire, nous utiliserons la biblioth√®que **Scikit-learn**.

```python
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import train_test_split
```

Nous commen√ßons par s√©parer les valeurs d'entr√©e (caract√©ristiques) et la sortie attendue (√©tiquette) en tableaux numpy distincts :

```python
X = pie_pumpkins['DayOfYear'].to_numpy().reshape(-1,1)
y = pie_pumpkins['Price']
```

> Notez que nous avons d√ª effectuer un `reshape` sur les donn√©es d'entr√©e afin que le package de r√©gression lin√©aire les comprenne correctement. La r√©gression lin√©aire attend un tableau 2D en entr√©e, o√π chaque ligne du tableau correspond √† un vecteur de caract√©ristiques d'entr√©e. Dans notre cas, comme nous n'avons qu'une seule entr√©e, nous avons besoin d'un tableau de forme N√ó1, o√π N est la taille du jeu de donn√©es.

Ensuite, nous devons diviser les donn√©es en ensembles d'entra√Ænement et de test, afin de pouvoir valider notre mod√®le apr√®s l'entra√Ænement :

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
```

Enfin, entra√Æner le mod√®le de r√©gression lin√©aire r√©el ne prend que deux lignes de code. Nous d√©finissons l'objet `LinearRegression` et l'ajustons √† nos donn√©es en utilisant la m√©thode `fit` :

```python
lin_reg = LinearRegression()
lin_reg.fit(X_train,y_train)
```

L'objet `LinearRegression` apr√®s l'ajustement contient tous les coefficients de la r√©gression, qui peuvent √™tre accessibles via la propri√©t√© `.coef_`. Dans notre cas, il n'y a qu'un seul coefficient, qui devrait √™tre autour de `-0.017`. Cela signifie que les prix semblent baisser l√©g√®rement avec le temps, mais pas beaucoup, environ 2 centimes par jour. Nous pouvons √©galement acc√©der au point d'intersection de la r√©gression avec l'axe Y en utilisant `lin_reg.intercept_` - il sera autour de `21` dans notre cas, indiquant le prix au d√©but de l'ann√©e.

Pour voir √† quel point notre mod√®le est pr√©cis, nous pouvons pr√©dire les prix sur un ensemble de test, puis mesurer √† quel point nos pr√©dictions sont proches des valeurs attendues. Cela peut √™tre fait en utilisant la m√©trique de l'erreur quadratique moyenne (MSE), qui est la moyenne de toutes les diff√©rences au carr√© entre la valeur attendue et la valeur pr√©dite.

```python
pred = lin_reg.predict(X_test)

mse = np.sqrt(mean_squared_error(y_test,pred))
print(f'Mean error: {mse:3.3} ({mse/np.mean(pred)*100:3.3}%)')
```
Notre erreur semble se situer autour de 2 points, soit environ 17 %. Pas tr√®s bon. Un autre indicateur de la qualit√© du mod√®le est le **coefficient de d√©termination**, que l'on peut obtenir comme suit :

```python
score = lin_reg.score(X_train,y_train)
print('Model determination: ', score)
```  
Si la valeur est 0, cela signifie que le mod√®le ne prend pas en compte les donn√©es d'entr√©e et agit comme le *pire pr√©dicteur lin√©aire*, qui est simplement une moyenne des r√©sultats. Une valeur de 1 signifie que nous pouvons pr√©dire parfaitement tous les r√©sultats attendus. Dans notre cas, le coefficient est d'environ 0,06, ce qui est assez faible.

Nous pouvons √©galement tracer les donn√©es de test avec la ligne de r√©gression pour mieux comprendre comment la r√©gression fonctionne dans notre cas :

```python
plt.scatter(X_test,y_test)
plt.plot(X_test,pred)
```  

<img alt="R√©gression lin√©aire" src="images/linear-results.png" width="50%" />

## R√©gression polynomiale

Un autre type de r√©gression lin√©aire est la r√©gression polynomiale. Bien qu'il existe parfois une relation lin√©aire entre les variables - plus le volume de la citrouille est grand, plus le prix est √©lev√© - ces relations ne peuvent parfois pas √™tre repr√©sent√©es par un plan ou une ligne droite.

‚úÖ Voici [quelques exemples suppl√©mentaires](https://online.stat.psu.edu/stat501/lesson/9/9.8) de donn√©es qui pourraient utiliser la r√©gression polynomiale.

Regardez √† nouveau la relation entre la date et le prix. Ce nuage de points semble-t-il devoir n√©cessairement √™tre analys√© par une ligne droite ? Les prix ne peuvent-ils pas fluctuer ? Dans ce cas, vous pouvez essayer la r√©gression polynomiale.

‚úÖ Les polyn√¥mes sont des expressions math√©matiques qui peuvent inclure une ou plusieurs variables et coefficients.

La r√©gression polynomiale cr√©e une courbe pour mieux ajuster les donn√©es non lin√©aires. Dans notre cas, si nous incluons une variable `DayOfYear` au carr√© dans les donn√©es d'entr√©e, nous devrions pouvoir ajuster nos donn√©es avec une courbe parabolique, qui aura un minimum √† un certain moment de l'ann√©e.

Scikit-learn inclut une API [pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.make_pipeline.html?highlight=pipeline#sklearn.pipeline.make_pipeline) utile pour combiner diff√©rentes √©tapes de traitement des donn√©es. Un **pipeline** est une cha√Æne d'**estimateurs**. Dans notre cas, nous allons cr√©er un pipeline qui ajoute d'abord des caract√©ristiques polynomiales √† notre mod√®le, puis entra√Æne la r√©gression :

```python
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import make_pipeline

pipeline = make_pipeline(PolynomialFeatures(2), LinearRegression())

pipeline.fit(X_train,y_train)
```  

Utiliser `PolynomialFeatures(2)` signifie que nous inclurons tous les polyn√¥mes de degr√© 2 des donn√©es d'entr√©e. Dans notre cas, cela signifie simplement `DayOfYear`<sup>2</sup>, mais avec deux variables d'entr√©e X et Y, cela ajoutera X<sup>2</sup>, XY et Y<sup>2</sup>. Nous pouvons √©galement utiliser des polyn√¥mes de degr√© sup√©rieur si nous le souhaitons.

Les pipelines peuvent √™tre utilis√©s de la m√™me mani√®re que l'objet `LinearRegression` original, c'est-√†-dire que nous pouvons `fit` le pipeline, puis utiliser `predict` pour obtenir les r√©sultats de pr√©diction. Voici le graphique montrant les donn√©es de test et la courbe d'approximation :

<img alt="R√©gression polynomiale" src="images/poly-results.png" width="50%" />

Avec la r√©gression polynomiale, nous pouvons obtenir un MSE l√©g√®rement inf√©rieur et un coefficient de d√©termination plus √©lev√©, mais pas de mani√®re significative. Nous devons prendre en compte d'autres caract√©ristiques !

> Vous pouvez voir que les prix minimaux des citrouilles sont observ√©s autour d'Halloween. Comment expliquez-vous cela ?

üéÉ F√©licitations, vous venez de cr√©er un mod√®le qui peut aider √† pr√©dire le prix des citrouilles pour tartes. Vous pouvez probablement r√©p√©ter la m√™me proc√©dure pour tous les types de citrouilles, mais cela serait fastidieux. Apprenons maintenant √† prendre en compte la vari√©t√© des citrouilles dans notre mod√®le !

## Caract√©ristiques cat√©gorielles

Dans un monde id√©al, nous voulons pouvoir pr√©dire les prix pour diff√©rentes vari√©t√©s de citrouilles en utilisant le m√™me mod√®le. Cependant, la colonne `Variety` est quelque peu diff√©rente des colonnes comme `Month`, car elle contient des valeurs non num√©riques. Ces colonnes sont appel√©es **cat√©gorielles**.

[![ML pour d√©butants - Pr√©dictions avec caract√©ristiques cat√©gorielles et r√©gression lin√©aire](https://img.youtube.com/vi/DYGliioIAE0/0.jpg)](https://youtu.be/DYGliioIAE0 "ML pour d√©butants - Pr√©dictions avec caract√©ristiques cat√©gorielles et r√©gression lin√©aire")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o sur l'utilisation des caract√©ristiques cat√©gorielles.

Voici comment le prix moyen d√©pend de la vari√©t√© :

<img alt="Prix moyen par vari√©t√©" src="images/price-by-variety.png" width="50%" />

Pour prendre en compte la vari√©t√©, nous devons d'abord la convertir en forme num√©rique, ou **l'encoder**. Il existe plusieurs fa√ßons de le faire :

* Un simple **encodage num√©rique** construira une table des diff√©rentes vari√©t√©s, puis remplacera le nom de la vari√©t√© par un indice dans cette table. Ce n'est pas la meilleure id√©e pour la r√©gression lin√©aire, car la r√©gression lin√©aire prend la valeur num√©rique r√©elle de l'indice et l'ajoute au r√©sultat, en la multipliant par un coefficient. Dans notre cas, la relation entre le num√©ro d'indice et le prix est clairement non lin√©aire, m√™me si nous nous assurons que les indices sont ordonn√©s d'une mani√®re sp√©cifique.
* **L'encodage one-hot** remplacera la colonne `Variety` par 4 colonnes diff√©rentes, une pour chaque vari√©t√©. Chaque colonne contiendra `1` si la ligne correspondante est d'une vari√©t√© donn√©e, et `0` sinon. Cela signifie qu'il y aura quatre coefficients dans la r√©gression lin√©aire, un pour chaque vari√©t√© de citrouille, responsable du "prix de d√©part" (ou plut√¥t "prix suppl√©mentaire") pour cette vari√©t√© particuli√®re.

Le code ci-dessous montre comment nous pouvons encoder une vari√©t√© en one-hot :

```python
pd.get_dummies(new_pumpkins['Variety'])
```  

 ID | FAIRYTALE | MINIATURE | MIXED HEIRLOOM VARIETIES | PIE TYPE  
----|-----------|-----------|--------------------------|----------  
70 | 0 | 0 | 0 | 1  
71 | 0 | 0 | 0 | 1  
... | ... | ... | ... | ...  
1738 | 0 | 1 | 0 | 0  
1739 | 0 | 1 | 0 | 0  
1740 | 0 | 1 | 0 | 0  
1741 | 0 | 1 | 0 | 0  
1742 | 0 | 1 | 0 | 0  

Pour entra√Æner une r√©gression lin√©aire en utilisant la vari√©t√© encod√©e en one-hot comme entr√©e, nous devons simplement initialiser correctement les donn√©es `X` et `y` :

```python
X = pd.get_dummies(new_pumpkins['Variety'])
y = new_pumpkins['Price']
```  

Le reste du code est le m√™me que celui que nous avons utilis√© ci-dessus pour entra√Æner la r√©gression lin√©aire. Si vous essayez, vous verrez que l'erreur quadratique moyenne est √† peu pr√®s la m√™me, mais nous obtenons un coefficient de d√©termination beaucoup plus √©lev√© (~77 %). Pour obtenir des pr√©dictions encore plus pr√©cises, nous pouvons prendre en compte davantage de caract√©ristiques cat√©gorielles, ainsi que des caract√©ristiques num√©riques, comme `Month` ou `DayOfYear`. Pour obtenir un grand tableau de caract√©ristiques, nous pouvons utiliser `join` :

```python
X = pd.get_dummies(new_pumpkins['Variety']) \
        .join(new_pumpkins['Month']) \
        .join(pd.get_dummies(new_pumpkins['City'])) \
        .join(pd.get_dummies(new_pumpkins['Package']))
y = new_pumpkins['Price']
```  

Ici, nous prenons √©galement en compte `City` et le type de `Package`, ce qui nous donne un MSE de 2,84 (10 %) et un coefficient de d√©termination de 0,94 !

## Tout rassembler

Pour cr√©er le meilleur mod√®le, nous pouvons utiliser des donn√©es combin√©es (cat√©gorielles encod√©es en one-hot + num√©riques) de l'exemple ci-dessus avec la r√©gression polynomiale. Voici le code complet pour votre commodit√© :

```python
# set up training data
X = pd.get_dummies(new_pumpkins['Variety']) \
        .join(new_pumpkins['Month']) \
        .join(pd.get_dummies(new_pumpkins['City'])) \
        .join(pd.get_dummies(new_pumpkins['Package']))
y = new_pumpkins['Price']

# make train-test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)

# setup and train the pipeline
pipeline = make_pipeline(PolynomialFeatures(2), LinearRegression())
pipeline.fit(X_train,y_train)

# predict results for test data
pred = pipeline.predict(X_test)

# calculate MSE and determination
mse = np.sqrt(mean_squared_error(y_test,pred))
print(f'Mean error: {mse:3.3} ({mse/np.mean(pred)*100:3.3}%)')

score = pipeline.score(X_train,y_train)
print('Model determination: ', score)
```  

Cela devrait nous donner le meilleur coefficient de d√©termination, presque 97 %, et un MSE=2,23 (~8 % d'erreur de pr√©diction).

| Mod√®le | MSE | D√©termination |  
|--------|-----|---------------|  
| `DayOfYear` Lin√©aire | 2,77 (17,2 %) | 0,07 |  
| `DayOfYear` Polynomial | 2,73 (17,0 %) | 0,08 |  
| `Variety` Lin√©aire | 5,24 (19,7 %) | 0,77 |  
| Toutes les caract√©ristiques Lin√©aire | 2,84 (10,5 %) | 0,94 |  
| Toutes les caract√©ristiques Polynomial | 2,23 (8,25 %) | 0,97 |  

üèÜ Bien jou√© ! Vous avez cr√©√© quatre mod√®les de r√©gression en une seule le√ßon et am√©lior√© la qualit√© du mod√®le √† 97 %. Dans la section finale sur la r√©gression, vous apprendrez la r√©gression logistique pour d√©terminer des cat√©gories.

---

## üöÄD√©fi

Testez plusieurs variables diff√©rentes dans ce notebook pour voir comment la corr√©lation correspond √† la pr√©cision du mod√®le.

## [Quiz post-lecture](https://ff-quizzes.netlify.app/en/ml/)

## R√©vision et auto-apprentissage

Dans cette le√ßon, nous avons appris la r√©gression lin√©aire. Il existe d'autres types importants de r√©gression. Lisez sur les techniques Stepwise, Ridge, Lasso et Elasticnet. Un bon cours pour approfondir est le [cours de Stanford sur l'apprentissage statistique](https://online.stanford.edu/courses/sohs-ystatslearning-statistical-learning).

## Devoir

[Construisez un mod√®le](assignment.md)

---

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction professionnelle r√©alis√©e par un humain. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.