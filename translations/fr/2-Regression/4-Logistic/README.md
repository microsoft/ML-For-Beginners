<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "72b5bae0879baddf6aafc82bb07b8776",
  "translation_date": "2025-09-03T22:23:34+00:00",
  "source_file": "2-Regression/4-Logistic/README.md",
  "language_code": "fr"
}
-->
# R√©gression logistique pour pr√©dire des cat√©gories

![Infographie sur la r√©gression logistique vs lin√©aire](../../../../translated_images/linear-vs-logistic.ba180bf95e7ee66721ba10ebf2dac2666acbd64a88b003c83928712433a13c7d.fr.png)

## [Quiz avant le cours](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/15/)

> ### [Cette le√ßon est disponible en R !](../../../../2-Regression/4-Logistic/solution/R/lesson_4.html)

## Introduction

Dans cette derni√®re le√ßon sur la r√©gression, l'une des techniques classiques de base en apprentissage automatique, nous allons examiner la r√©gression logistique. Vous utiliseriez cette technique pour d√©couvrir des mod√®les permettant de pr√©dire des cat√©gories binaires. Ce bonbon est-il au chocolat ou non ? Cette maladie est-elle contagieuse ou non ? Ce client choisira-t-il ce produit ou non ?

Dans cette le√ßon, vous apprendrez :

- Une nouvelle biblioth√®que pour la visualisation des donn√©es
- Des techniques pour la r√©gression logistique

‚úÖ Approfondissez votre compr√©hension de ce type de r√©gression dans ce [module d'apprentissage](https://docs.microsoft.com/learn/modules/train-evaluate-classification-models?WT.mc_id=academic-77952-leestott)

## Pr√©requis

Apr√®s avoir travaill√© avec les donn√©es sur les citrouilles, nous sommes maintenant suffisamment familiers avec elles pour r√©aliser qu'il existe une cat√©gorie binaire sur laquelle nous pouvons travailler : `Color`.

Construisons un mod√®le de r√©gression logistique pour pr√©dire, √† partir de certaines variables, _quelle couleur une citrouille donn√©e est susceptible d'avoir_ (orange üéÉ ou blanche üëª).

> Pourquoi parlons-nous de classification binaire dans une le√ßon sur la r√©gression ? C'est uniquement pour des raisons linguistiques, car la r√©gression logistique est [en r√©alit√© une m√©thode de classification](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression), bien qu'elle soit bas√©e sur des principes lin√©aires. D√©couvrez d'autres fa√ßons de classifier les donn√©es dans le prochain groupe de le√ßons.

## D√©finir la question

Pour nos besoins, nous exprimerons cela comme une binaire : 'Blanche' ou 'Non blanche'. Il existe √©galement une cat√©gorie 'ray√©e' dans notre ensemble de donn√©es, mais elle contient peu d'exemples, donc nous ne l'utiliserons pas. Elle dispara√Æt de toute fa√ßon une fois que nous supprimons les valeurs nulles de l'ensemble de donn√©es.

> üéÉ Fait amusant : nous appelons parfois les citrouilles blanches des citrouilles 'fant√¥mes'. Elles ne sont pas tr√®s faciles √† sculpter, donc elles ne sont pas aussi populaires que les citrouilles oranges, mais elles ont un look sympa ! Nous pourrions donc reformuler notre question ainsi : 'Fant√¥me' ou 'Non fant√¥me'. üëª

## √Ä propos de la r√©gression logistique

La r√©gression logistique diff√®re de la r√©gression lin√©aire, que vous avez apprise pr√©c√©demment, de plusieurs mani√®res importantes.

[![ML pour d√©butants - Comprendre la r√©gression logistique pour la classification en apprentissage automatique](https://img.youtube.com/vi/KpeCT6nEpBY/0.jpg)](https://youtu.be/KpeCT6nEpBY "ML pour d√©butants - Comprendre la r√©gression logistique pour la classification en apprentissage automatique")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o sur la r√©gression logistique.

### Classification binaire

La r√©gression logistique n'offre pas les m√™mes fonctionnalit√©s que la r√©gression lin√©aire. La premi√®re propose une pr√©diction sur une cat√©gorie binaire ("blanche ou non blanche"), tandis que la seconde est capable de pr√©dire des valeurs continues, par exemple, en fonction de l'origine d'une citrouille et du moment de la r√©colte, _de combien son prix augmentera_.

![Mod√®le de classification des citrouilles](../../../../translated_images/pumpkin-classifier.562771f104ad5436b87d1c67bca02a42a17841133556559325c0a0e348e5b774.fr.png)
> Infographie par [Dasani Madipalli](https://twitter.com/dasani_decoded)

### Autres classifications

Il existe d'autres types de r√©gression logistique, notamment multinomiale et ordinale :

- **Multinomiale**, qui implique d'avoir plus d'une cat√©gorie - "Orange, Blanche et Ray√©e".
- **Ordinale**, qui implique des cat√©gories ordonn√©es, utile si nous voulons ordonner nos r√©sultats logiquement, comme nos citrouilles class√©es par un nombre fini de tailles (mini, petite, moyenne, grande, XL, XXL).

![R√©gression multinomiale vs ordinale](../../../../translated_images/multinomial-vs-ordinal.36701b4850e37d86c9dd49f7bef93a2f94dbdb8fe03443eb68f0542f97f28f29.fr.png)

### Les variables n'ont PAS besoin d'√™tre corr√©l√©es

Vous vous souvenez que la r√©gression lin√©aire fonctionnait mieux avec des variables plus corr√©l√©es ? La r√©gression logistique est l'oppos√© - les variables n'ont pas besoin d'√™tre align√©es. Cela fonctionne pour ces donn√©es qui ont des corr√©lations relativement faibles.

### Vous avez besoin de beaucoup de donn√©es propres

La r√©gression logistique donnera des r√©sultats plus pr√©cis si vous utilisez davantage de donn√©es ; notre petit ensemble de donn√©es n'est pas optimal pour cette t√¢che, donc gardez cela √† l'esprit.

[![ML pour d√©butants - Analyse et pr√©paration des donn√©es pour la r√©gression logistique](https://img.youtube.com/vi/B2X4H9vcXTs/0.jpg)](https://youtu.be/B2X4H9vcXTs "ML pour d√©butants - Analyse et pr√©paration des donn√©es pour la r√©gression logistique")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o sur la pr√©paration des donn√©es pour la r√©gression lin√©aire.

‚úÖ R√©fl√©chissez aux types de donn√©es qui se pr√™tent bien √† la r√©gression logistique.

## Exercice - nettoyer les donn√©es

Tout d'abord, nettoyez un peu les donn√©es en supprimant les valeurs nulles et en s√©lectionnant uniquement certaines colonnes :

1. Ajoutez le code suivant :

    ```python
  
    columns_to_select = ['City Name','Package','Variety', 'Origin','Item Size', 'Color']
    pumpkins = full_pumpkins.loc[:, columns_to_select]

    pumpkins.dropna(inplace=True)
    ```

    Vous pouvez toujours jeter un coup d'≈ìil √† votre nouveau dataframe :

    ```python
    pumpkins.info
    ```

### Visualisation - graphique cat√©goriel

√Ä ce stade, vous avez charg√© le [notebook de d√©part](./notebook.ipynb) avec les donn√©es sur les citrouilles et les avez nettoy√©es pour conserver un ensemble de donn√©es contenant quelques variables, y compris `Color`. Visualisons le dataframe dans le notebook en utilisant une biblioth√®que diff√©rente : [Seaborn](https://seaborn.pydata.org/index.html), qui est construite sur Matplotlib que nous avons utilis√© pr√©c√©demment.

Seaborn offre des moyens int√©ressants de visualiser vos donn√©es. Par exemple, vous pouvez comparer les distributions des donn√©es pour chaque `Variety` et `Color` dans un graphique cat√©goriel.

1. Cr√©ez un tel graphique en utilisant la fonction `catplot`, avec nos donn√©es sur les citrouilles `pumpkins`, et en sp√©cifiant une correspondance de couleurs pour chaque cat√©gorie de citrouilles (orange ou blanche) :

    ```python
    import seaborn as sns
    
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }

    sns.catplot(
    data=pumpkins, y="Variety", hue="Color", kind="count",
    palette=palette, 
    )
    ```

    ![Une grille de donn√©es visualis√©es](../../../../translated_images/pumpkins_catplot_1.c55c409b71fea2ecc01921e64b91970542101f90bcccfa4aa3a205db8936f48b.fr.png)

    En observant les donn√©es, vous pouvez voir comment les donn√©es de couleur se rapportent √† la vari√©t√©.

    ‚úÖ √Ä partir de ce graphique cat√©goriel, quelles explorations int√©ressantes pouvez-vous envisager ?

### Pr√©traitement des donn√©es : encodage des caract√©ristiques et des √©tiquettes

Notre ensemble de donn√©es sur les citrouilles contient des valeurs de type cha√Æne pour toutes ses colonnes. Travailler avec des donn√©es cat√©goriques est intuitif pour les humains mais pas pour les machines. Les algorithmes d'apprentissage automatique fonctionnent bien avec des nombres. C'est pourquoi l'encodage est une √©tape tr√®s importante dans la phase de pr√©traitement des donn√©es, car il nous permet de transformer des donn√©es cat√©goriques en donn√©es num√©riques, sans perdre aucune information. Un bon encodage permet de construire un bon mod√®le.

Pour l'encodage des caract√©ristiques, il existe deux principaux types d'encodeurs :

1. Encodeur ordinal : il convient bien aux variables ordinales, qui sont des variables cat√©goriques dont les donn√©es suivent un ordre logique, comme la colonne `Item Size` dans notre ensemble de donn√©es. Il cr√©e une correspondance de sorte que chaque cat√©gorie soit repr√©sent√©e par un nombre, qui est l'ordre de la cat√©gorie dans la colonne.

    ```python
    from sklearn.preprocessing import OrdinalEncoder

    item_size_categories = [['sml', 'med', 'med-lge', 'lge', 'xlge', 'jbo', 'exjbo']]
    ordinal_features = ['Item Size']
    ordinal_encoder = OrdinalEncoder(categories=item_size_categories)
    ```

2. Encodeur cat√©goriel : il convient bien aux variables nominales, qui sont des variables cat√©goriques dont les donn√©es ne suivent pas un ordre logique, comme toutes les caract√©ristiques diff√©rentes de `Item Size` dans notre ensemble de donn√©es. Il s'agit d'un encodage one-hot, ce qui signifie que chaque cat√©gorie est repr√©sent√©e par une colonne binaire : la variable encod√©e est √©gale √† 1 si la citrouille appartient √† cette vari√©t√© et √† 0 sinon.

    ```python
    from sklearn.preprocessing import OneHotEncoder

    categorical_features = ['City Name', 'Package', 'Variety', 'Origin']
    categorical_encoder = OneHotEncoder(sparse_output=False)
    ```

Ensuite, `ColumnTransformer` est utilis√© pour combiner plusieurs encodeurs en une seule √©tape et les appliquer aux colonnes appropri√©es.

```python
    from sklearn.compose import ColumnTransformer
    
    ct = ColumnTransformer(transformers=[
        ('ord', ordinal_encoder, ordinal_features),
        ('cat', categorical_encoder, categorical_features)
        ])
    
    ct.set_output(transform='pandas')
    encoded_features = ct.fit_transform(pumpkins)
```

D'autre part, pour encoder l'√©tiquette, nous utilisons la classe `LabelEncoder` de scikit-learn, qui est une classe utilitaire pour normaliser les √©tiquettes de sorte qu'elles contiennent uniquement des valeurs entre 0 et n_classes-1 (ici, 0 et 1).

```python
    from sklearn.preprocessing import LabelEncoder

    label_encoder = LabelEncoder()
    encoded_label = label_encoder.fit_transform(pumpkins['Color'])
```

Une fois que nous avons encod√© les caract√©ristiques et l'√©tiquette, nous pouvons les fusionner dans un nouveau dataframe `encoded_pumpkins`.

```python
    encoded_pumpkins = encoded_features.assign(Color=encoded_label)
```

‚úÖ Quels sont les avantages d'utiliser un encodeur ordinal pour la colonne `Item Size` ?

### Analyser les relations entre les variables

Maintenant que nous avons pr√©trait√© nos donn√©es, nous pouvons analyser les relations entre les caract√©ristiques et l'√©tiquette pour avoir une id√©e de la capacit√© du mod√®le √† pr√©dire l'√©tiquette √† partir des caract√©ristiques. La meilleure fa√ßon de r√©aliser ce type d'analyse est de tracer les donn√©es. Nous utiliserons √† nouveau la fonction `catplot` de Seaborn pour visualiser les relations entre `Item Size`, `Variety` et `Color` dans un graphique cat√©goriel. Pour mieux tracer les donn√©es, nous utiliserons la colonne encod√©e `Item Size` et la colonne non encod√©e `Variety`.

```python
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }
    pumpkins['Item Size'] = encoded_pumpkins['ord__Item Size']

    g = sns.catplot(
        data=pumpkins,
        x="Item Size", y="Color", row='Variety',
        kind="box", orient="h",
        sharex=False, margin_titles=True,
        height=1.8, aspect=4, palette=palette,
    )
    g.set(xlabel="Item Size", ylabel="").set(xlim=(0,6))
    g.set_titles(row_template="{row_name}")
```

![Un catplot de donn√©es visualis√©es](../../../../translated_images/pumpkins_catplot_2.87a354447880b3889278155957f8f60dd63db4598de5a6d0fda91c334d31f9f1.fr.png)

### Utiliser un graphique en essaim

√âtant donn√© que `Color` est une cat√©gorie binaire (Blanche ou Non), elle n√©cessite 'une [approche sp√©cialis√©e](https://seaborn.pydata.org/tutorial/categorical.html?highlight=bar) pour la visualisation'. Il existe d'autres fa√ßons de visualiser la relation de cette cat√©gorie avec d'autres variables.

Vous pouvez visualiser les variables c√¥te √† c√¥te avec des graphiques Seaborn.

1. Essayez un graphique en essaim pour montrer la distribution des valeurs :

    ```python
    palette = {
    0: 'orange',
    1: 'wheat'
    }
    sns.swarmplot(x="Color", y="ord__Item Size", data=encoded_pumpkins, palette=palette)
    ```

    ![Un essaim de donn√©es visualis√©es](../../../../translated_images/swarm_2.efeacfca536c2b577dc7b5f8891f28926663fbf62d893ab5e1278ae734ca104e.fr.png)

**Attention** : le code ci-dessus pourrait g√©n√©rer un avertissement, car Seaborn √©choue √† repr√©senter une telle quantit√© de points de donn√©es dans un graphique en essaim. Une solution possible est de r√©duire la taille du marqueur, en utilisant le param√®tre 'size'. Cependant, soyez conscient que cela affecte la lisibilit√© du graphique.

> **üßÆ Montrez-moi les math√©matiques**
>
> La r√©gression logistique repose sur le concept de 'maximum de vraisemblance' en utilisant des [fonctions sigmo√Ødes](https://wikipedia.org/wiki/Sigmoid_function). Une 'fonction sigmo√Øde' sur un graphique ressemble √† une forme en 'S'. Elle prend une valeur et la mappe entre 0 et 1. Sa courbe est √©galement appel√©e 'courbe logistique'. Sa formule ressemble √† ceci :
>
> ![fonction logistique](../../../../translated_images/sigmoid.8b7ba9d095c789cf72780675d0d1d44980c3736617329abfc392dfc859799704.fr.png)
>
> o√π le point m√©dian de la sigmo√Øde se trouve au point 0 de x, L est la valeur maximale de la courbe, et k est la pente de la courbe. Si le r√©sultat de la fonction est sup√©rieur √† 0,5, l'√©tiquette en question sera attribu√©e √† la classe '1' du choix binaire. Sinon, elle sera class√©e comme '0'.

## Construisez votre mod√®le

Construire un mod√®le pour trouver ces classifications binaires est √©tonnamment simple avec Scikit-learn.

[![ML pour d√©butants - R√©gression logistique pour la classification des donn√©es](https://img.youtube.com/vi/MmZS2otPrQ8/0.jpg)](https://youtu.be/MmZS2otPrQ8 "ML pour d√©butants - R√©gression logistique pour la classification des donn√©es")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o sur la construction d'un mod√®le de r√©gression lin√©aire.

1. S√©lectionnez les variables que vous souhaitez utiliser dans votre mod√®le de classification et divisez les ensembles d'entra√Ænement et de test en appelant `train_test_split()` :

    ```python
    from sklearn.model_selection import train_test_split
    
    X = encoded_pumpkins[encoded_pumpkins.columns.difference(['Color'])]
    y = encoded_pumpkins['Color']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
    
    ```

2. Maintenant, vous pouvez entra√Æner votre mod√®le en appelant `fit()` avec vos donn√©es d'entra√Ænement, et afficher son r√©sultat :

    ```python
    from sklearn.metrics import f1_score, classification_report 
    from sklearn.linear_model import LogisticRegression

    model = LogisticRegression()
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)

    print(classification_report(y_test, predictions))
    print('Predicted labels: ', predictions)
    print('F1-score: ', f1_score(y_test, predictions))
    ```

    Regardez le tableau de bord de votre mod√®le. Ce n'est pas mal, compte tenu du fait que vous avez seulement environ 1000 lignes de donn√©es :

    ```output
                       precision    recall  f1-score   support
    
                    0       0.94      0.98      0.96       166
                    1       0.85      0.67      0.75        33
    
        accuracy                                0.92       199
        macro avg           0.89      0.82      0.85       199
        weighted avg        0.92      0.92      0.92       199
    
        Predicted labels:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0
        0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
        1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0
        0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0
        0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
        0 0 0 1 0 0 0 0 0 0 0 0 1 1]
        F1-score:  0.7457627118644068
    ```

## Meilleure compr√©hension via une matrice de confusion

Bien que vous puissiez obtenir un rapport de tableau de bord [termes](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html?highlight=classification_report#sklearn.metrics.classification_report) en imprimant les √©l√©ments ci-dessus, vous pourriez comprendre votre mod√®le plus facilement en utilisant une [matrice de confusion](https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix) pour nous aider √† comprendre comment le mod√®le fonctionne.

> üéì Une '[matrice de confusion](https://wikipedia.org/wiki/Confusion_matrix)' (ou 'matrice d'erreur') est un tableau qui exprime les vrais vs faux positifs et n√©gatifs de votre mod√®le, √©valuant ainsi la pr√©cision des pr√©dictions.

1. Pour utiliser une matrice de confusion, appelez `confusion_matrix()` :

    ```python
    from sklearn.metrics import confusion_matrix
    confusion_matrix(y_test, predictions)
    ```

    Regardez la matrice de confusion de votre mod√®le :

    ```output
    array([[162,   4],
           [ 11,  22]])
    ```

Dans Scikit-learn, les lignes (axe 0) sont les √©tiquettes r√©elles et les colonnes (axe 1) sont les √©tiquettes pr√©dites.

|       |   0   |   1   |
| :---: | :---: | :---: |
|   0   |  TN   |  FP   |
|   1   |  FN   |  TP   |

Que se passe-t-il ici ? Disons que notre mod√®le est charg√© de classifier les citrouilles entre deux cat√©gories binaires, cat√©gorie 'blanche' et cat√©gorie 'non blanche'.

- Si votre mod√®le pr√©dit qu'une citrouille n'est pas blanche et qu'elle appartient √† la cat√©gorie 'non blanche' en r√©alit√©, nous appelons cela un vrai n√©gatif, indiqu√© par le nombre en haut √† gauche.
- Si votre mod√®le pr√©dit qu'une citrouille est blanche et qu'elle appartient √† la cat√©gorie 'non blanche' en r√©alit√©, nous appelons cela un faux n√©gatif, indiqu√© par le nombre en bas √† gauche.
- Si votre mod√®le pr√©dit qu'une citrouille n'est pas blanche et qu'elle appartient √† la cat√©gorie 'blanche' en r√©alit√©, nous appelons cela un faux positif, indiqu√© par le nombre en haut √† droite.
- Si votre mod√®le pr√©dit qu'une citrouille est blanche et qu'elle appartient √† la cat√©gorie 'blanche' en r√©alit√©, nous appelons cela un vrai positif, indiqu√© par le nombre en bas √† droite.

Comme vous l'avez probablement devin√©, il est pr√©f√©rable d'avoir un plus grand nombre de vrais positifs et de vrais n√©gatifs et un plus petit nombre de faux positifs et de faux n√©gatifs, ce qui implique que le mod√®le fonctionne mieux.
Comment la matrice de confusion est-elle li√©e √† la pr√©cision et au rappel ? Rappelez-vous, le rapport de classification imprim√© ci-dessus montrait une pr√©cision (0,85) et un rappel (0,67).

Pr√©cision = tp / (tp + fp) = 22 / (22 + 4) = 0,8461538461538461

Rappel = tp / (tp + fn) = 22 / (22 + 11) = 0,6666666666666666

‚úÖ Q : Selon la matrice de confusion, comment le mod√®le s'en est-il sorti ?  
R : Pas mal ; il y a un bon nombre de vrais n√©gatifs mais aussi quelques faux n√©gatifs.

Revisitons les termes que nous avons vus pr√©c√©demment √† l'aide de la cartographie TP/TN et FP/FN de la matrice de confusion :

üéì Pr√©cision : TP/(TP + FP) La fraction des instances pertinentes parmi les instances r√©cup√©r√©es (par exemple, quels labels ont √©t√© bien √©tiquet√©s).

üéì Rappel : TP/(TP + FN) La fraction des instances pertinentes qui ont √©t√© r√©cup√©r√©es, qu'elles soient bien √©tiquet√©es ou non.

üéì f1-score : (2 * pr√©cision * rappel)/(pr√©cision + rappel) Une moyenne pond√©r√©e de la pr√©cision et du rappel, avec le meilleur score √©tant 1 et le pire √©tant 0.

üéì Support : Le nombre d'occurrences de chaque label r√©cup√©r√©.

üéì Exactitude : (TP + TN)/(TP + TN + FP + FN) Le pourcentage de labels pr√©dits correctement pour un √©chantillon.

üéì Macro Moyenne : Le calcul de la moyenne non pond√©r√©e des m√©triques pour chaque label, sans tenir compte du d√©s√©quilibre des labels.

üéì Moyenne Pond√©r√©e : Le calcul de la moyenne des m√©triques pour chaque label, en tenant compte du d√©s√©quilibre des labels en les pond√©rant par leur support (le nombre d'instances r√©elles pour chaque label).

‚úÖ Pouvez-vous r√©fl√©chir √† quelle m√©trique surveiller si vous voulez que votre mod√®le r√©duise le nombre de faux n√©gatifs ?

## Visualiser la courbe ROC de ce mod√®le

[![ML pour d√©butants - Analyse de la performance de la r√©gression logistique avec les courbes ROC](https://img.youtube.com/vi/GApO575jTA0/0.jpg)](https://youtu.be/GApO575jTA0 "ML pour d√©butants - Analyse de la performance de la r√©gression logistique avec les courbes ROC")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o sur les courbes ROC.

Faisons une autre visualisation pour voir la fameuse courbe 'ROC' :

```python
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline

y_scores = model.predict_proba(X_test)
fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])

fig = plt.figure(figsize=(6, 6))
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.show()
```

En utilisant Matplotlib, tracez la [caract√©ristique de fonctionnement du r√©cepteur](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html?highlight=roc) ou ROC du mod√®le. Les courbes ROC sont souvent utilis√©es pour obtenir une vue d'ensemble des r√©sultats d'un classificateur en termes de vrais positifs contre faux positifs. "Les courbes ROC pr√©sentent g√©n√©ralement le taux de vrais positifs sur l'axe Y et le taux de faux positifs sur l'axe X." Ainsi, la pente de la courbe et l'espace entre la ligne m√©diane et la courbe sont importants : vous voulez une courbe qui monte rapidement et d√©passe la ligne. Dans notre cas, il y a des faux positifs au d√©part, puis la ligne monte correctement :

![ROC](../../../../translated_images/ROC_2.777f20cdfc4988ca683ade6850ac832cb70c96c12f1b910d294f270ef36e1a1c.fr.png)

Enfin, utilisez l'API [`roc_auc_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html?highlight=roc_auc#sklearn.metrics.roc_auc_score) de Scikit-learn pour calculer la v√©ritable 'Surface sous la courbe' (AUC) :

```python
auc = roc_auc_score(y_test,y_scores[:,1])
print(auc)
```  
Le r√©sultat est `0.9749908725812341`. √âtant donn√© que l'AUC varie de 0 √† 1, vous voulez un score √©lev√©, car un mod√®le qui est 100 % correct dans ses pr√©dictions aura une AUC de 1 ; dans ce cas, le mod√®le est _plut√¥t bon_.

Dans les prochaines le√ßons sur les classifications, vous apprendrez comment it√©rer pour am√©liorer les scores de votre mod√®le. Mais pour l'instant, f√©licitations ! Vous avez termin√© ces le√ßons sur la r√©gression !

---
## üöÄD√©fi

Il y a beaucoup plus √† d√©couvrir sur la r√©gression logistique ! Mais la meilleure fa√ßon d'apprendre est d'exp√©rimenter. Trouvez un ensemble de donn√©es qui se pr√™te √† ce type d'analyse et construisez un mod√®le avec celui-ci. Qu'apprenez-vous ? Astuce : essayez [Kaggle](https://www.kaggle.com/search?q=logistic+regression+datasets) pour des ensembles de donn√©es int√©ressants.

## [Quiz post-lecture](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/16/)

## R√©vision & Auto-√©tude

Lisez les premi√®res pages de [cet article de Stanford](https://web.stanford.edu/~jurafsky/slp3/5.pdf) sur quelques utilisations pratiques de la r√©gression logistique. R√©fl√©chissez aux t√¢ches qui conviennent mieux √† l'un ou l'autre type de t√¢ches de r√©gression que nous avons √©tudi√©es jusqu'√† pr√©sent. Qu'est-ce qui fonctionnerait le mieux ?

## Devoir

[Reprendre cette r√©gression](assignment.md)

---

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction professionnelle r√©alis√©e par un humain. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.