<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "abf86d845c84330bce205a46b382ec88",
  "translation_date": "2025-09-04T22:53:01+00:00",
  "source_file": "2-Regression/4-Logistic/README.md",
  "language_code": "fr"
}
-->
# R√©gression logistique pour pr√©dire des cat√©gories

![Infographie sur la r√©gression logistique vs lin√©aire](../../../../2-Regression/4-Logistic/images/linear-vs-logistic.png)

## [Quiz avant le cours](https://ff-quizzes.netlify.app/en/ml/)

> ### [Cette le√ßon est disponible en R !](../../../../2-Regression/4-Logistic/solution/R/lesson_4.html)

## Introduction

Dans cette derni√®re le√ßon sur la r√©gression, l'une des techniques de base _classiques_ en apprentissage automatique, nous allons examiner la r√©gression logistique. Vous utiliseriez cette technique pour d√©couvrir des mod√®les permettant de pr√©dire des cat√©gories binaires. Ce bonbon est-il au chocolat ou non ? Cette maladie est-elle contagieuse ou non ? Ce client choisira-t-il ce produit ou non ?

Dans cette le√ßon, vous apprendrez :

- Une nouvelle biblioth√®que pour la visualisation des donn√©es
- Des techniques pour la r√©gression logistique

‚úÖ Approfondissez votre compr√©hension de ce type de r√©gression dans ce [module d'apprentissage](https://docs.microsoft.com/learn/modules/train-evaluate-classification-models?WT.mc_id=academic-77952-leestott)

## Pr√©requis

Apr√®s avoir travaill√© avec les donn√©es sur les citrouilles, nous sommes maintenant suffisamment familiers avec elles pour r√©aliser qu'il existe une cat√©gorie binaire sur laquelle nous pouvons travailler : `Color`.

Construisons un mod√®le de r√©gression logistique pour pr√©dire, en fonction de certaines variables, _quelle couleur une citrouille donn√©e est susceptible d'avoir_ (orange üéÉ ou blanche üëª).

> Pourquoi parlons-nous de classification binaire dans une le√ßon sur la r√©gression ? C'est uniquement pour des raisons linguistiques, car la r√©gression logistique est [en r√©alit√© une m√©thode de classification](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression), bien qu'elle soit bas√©e sur des mod√®les lin√©aires. D√©couvrez d'autres fa√ßons de classifier les donn√©es dans le prochain groupe de le√ßons.

## D√©finir la question

Pour nos besoins, nous exprimerons cela comme une binaire : 'Blanche' ou 'Non blanche'. Il existe √©galement une cat√©gorie 'ray√©e' dans notre ensemble de donn√©es, mais elle contient peu d'exemples, donc nous ne l'utiliserons pas. Elle dispara√Æt de toute fa√ßon une fois que nous supprimons les valeurs nulles de l'ensemble de donn√©es.

> üéÉ Fait amusant : nous appelons parfois les citrouilles blanches des citrouilles 'fant√¥mes'. Elles ne sont pas tr√®s faciles √† sculpter, donc elles ne sont pas aussi populaires que les citrouilles oranges, mais elles ont un look cool ! Nous pourrions donc reformuler notre question ainsi : 'Fant√¥me' ou 'Non fant√¥me'. üëª

## √Ä propos de la r√©gression logistique

La r√©gression logistique diff√®re de la r√©gression lin√©aire, que vous avez apprise pr√©c√©demment, de plusieurs fa√ßons importantes.

[![ML pour d√©butants - Comprendre la r√©gression logistique pour la classification en apprentissage automatique](https://img.youtube.com/vi/KpeCT6nEpBY/0.jpg)](https://youtu.be/KpeCT6nEpBY "ML pour d√©butants - Comprendre la r√©gression logistique pour la classification en apprentissage automatique")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o sur la r√©gression logistique.

### Classification binaire

La r√©gression logistique n'offre pas les m√™mes fonctionnalit√©s que la r√©gression lin√©aire. La premi√®re propose une pr√©diction sur une cat√©gorie binaire ("blanche ou non blanche"), tandis que la seconde est capable de pr√©dire des valeurs continues, par exemple, en fonction de l'origine d'une citrouille et du moment de la r√©colte, _de combien son prix augmentera_.

![Mod√®le de classification des citrouilles](../../../../2-Regression/4-Logistic/images/pumpkin-classifier.png)
> Infographie par [Dasani Madipalli](https://twitter.com/dasani_decoded)

### Autres classifications

Il existe d'autres types de r√©gression logistique, notamment multinomiale et ordinale :

- **Multinomiale**, qui implique d'avoir plus d'une cat√©gorie - "Orange, Blanche et Ray√©e".
- **Ordinale**, qui implique des cat√©gories ordonn√©es, utile si nous voulons ordonner nos r√©sultats de mani√®re logique, comme nos citrouilles class√©es par un nombre fini de tailles (mini, sm, med, lg, xl, xxl).

![R√©gression multinomiale vs ordinale](../../../../2-Regression/4-Logistic/images/multinomial-vs-ordinal.png)

### Les variables n'ont PAS besoin d'√™tre corr√©l√©es

Vous vous souvenez de la fa√ßon dont la r√©gression lin√©aire fonctionnait mieux avec des variables plus corr√©l√©es ? La r√©gression logistique est l'oppos√© - les variables n'ont pas besoin d'√™tre align√©es. Cela fonctionne pour ces donn√©es qui ont des corr√©lations relativement faibles.

### Vous avez besoin de beaucoup de donn√©es propres

La r√©gression logistique donnera des r√©sultats plus pr√©cis si vous utilisez davantage de donn√©es ; notre petit ensemble de donn√©es n'est pas optimal pour cette t√¢che, donc gardez cela √† l'esprit.

[![ML pour d√©butants - Analyse et pr√©paration des donn√©es pour la r√©gression logistique](https://img.youtube.com/vi/B2X4H9vcXTs/0.jpg)](https://youtu.be/B2X4H9vcXTs "ML pour d√©butants - Analyse et pr√©paration des donn√©es pour la r√©gression logistique")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o sur la pr√©paration des donn√©es pour la r√©gression lin√©aire.

‚úÖ R√©fl√©chissez aux types de donn√©es qui se pr√™tent bien √† la r√©gression logistique.

## Exercice - nettoyer les donn√©es

Tout d'abord, nettoyez un peu les donn√©es en supprimant les valeurs nulles et en s√©lectionnant uniquement certaines colonnes :

1. Ajoutez le code suivant :

    ```python
  
    columns_to_select = ['City Name','Package','Variety', 'Origin','Item Size', 'Color']
    pumpkins = full_pumpkins.loc[:, columns_to_select]

    pumpkins.dropna(inplace=True)
    ```

    Vous pouvez toujours jeter un coup d'≈ìil √† votre nouveau dataframe :

    ```python
    pumpkins.info
    ```

### Visualisation - graphique cat√©goriel

√Ä ce stade, vous avez charg√© le [notebook de d√©part](../../../../2-Regression/4-Logistic/notebook.ipynb) avec les donn√©es sur les citrouilles et les avez nettoy√©es pour conserver un ensemble de donn√©es contenant quelques variables, y compris `Color`. Visualisons le dataframe dans le notebook en utilisant une biblioth√®que diff√©rente : [Seaborn](https://seaborn.pydata.org/index.html), qui est construite sur Matplotlib que nous avons utilis√© pr√©c√©demment.

Seaborn offre des moyens int√©ressants de visualiser vos donn√©es. Par exemple, vous pouvez comparer les distributions des donn√©es pour chaque `Variety` et `Color` dans un graphique cat√©goriel.

1. Cr√©ez un tel graphique en utilisant la fonction `catplot`, avec nos donn√©es sur les citrouilles `pumpkins`, et en sp√©cifiant une correspondance de couleurs pour chaque cat√©gorie de citrouilles (orange ou blanche) :

    ```python
    import seaborn as sns
    
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }

    sns.catplot(
    data=pumpkins, y="Variety", hue="Color", kind="count",
    palette=palette, 
    )
    ```

    ![Une grille de donn√©es visualis√©es](../../../../2-Regression/4-Logistic/images/pumpkins_catplot_1.png)

    En observant les donn√©es, vous pouvez voir comment les donn√©es de couleur se rapportent √† la vari√©t√©.

    ‚úÖ √Ä partir de ce graphique cat√©goriel, quelles explorations int√©ressantes pouvez-vous envisager ?

### Pr√©traitement des donn√©es : encodage des caract√©ristiques et des √©tiquettes

Notre ensemble de donn√©es sur les citrouilles contient des valeurs de cha√Æne pour toutes ses colonnes. Travailler avec des donn√©es cat√©gorielles est intuitif pour les humains mais pas pour les machines. Les algorithmes d'apprentissage automatique fonctionnent bien avec des nombres. C'est pourquoi l'encodage est une √©tape tr√®s importante dans la phase de pr√©traitement des donn√©es, car il nous permet de transformer les donn√©es cat√©gorielles en donn√©es num√©riques, sans perdre aucune information. Un bon encodage permet de construire un bon mod√®le.

Pour l'encodage des caract√©ristiques, il existe deux principaux types d'encodeurs :

1. Encodeur ordinal : il convient bien aux variables ordinales, qui sont des variables cat√©gorielles dont les donn√©es suivent un ordre logique, comme la colonne `Item Size` dans notre ensemble de donn√©es. Il cr√©e une correspondance de sorte que chaque cat√©gorie soit repr√©sent√©e par un nombre, qui est l'ordre de la cat√©gorie dans la colonne.

    ```python
    from sklearn.preprocessing import OrdinalEncoder

    item_size_categories = [['sml', 'med', 'med-lge', 'lge', 'xlge', 'jbo', 'exjbo']]
    ordinal_features = ['Item Size']
    ordinal_encoder = OrdinalEncoder(categories=item_size_categories)
    ```

2. Encodeur cat√©goriel : il convient bien aux variables nominales, qui sont des variables cat√©gorielles dont les donn√©es ne suivent pas un ordre logique, comme toutes les caract√©ristiques diff√©rentes de `Item Size` dans notre ensemble de donn√©es. Il s'agit d'un encodage one-hot, ce qui signifie que chaque cat√©gorie est repr√©sent√©e par une colonne binaire : la variable encod√©e est √©gale √† 1 si la citrouille appartient √† cette vari√©t√© et √† 0 sinon.

    ```python
    from sklearn.preprocessing import OneHotEncoder

    categorical_features = ['City Name', 'Package', 'Variety', 'Origin']
    categorical_encoder = OneHotEncoder(sparse_output=False)
    ```
Ensuite, `ColumnTransformer` est utilis√© pour combiner plusieurs encodeurs en une seule √©tape et les appliquer aux colonnes appropri√©es.

```python
    from sklearn.compose import ColumnTransformer
    
    ct = ColumnTransformer(transformers=[
        ('ord', ordinal_encoder, ordinal_features),
        ('cat', categorical_encoder, categorical_features)
        ])
    
    ct.set_output(transform='pandas')
    encoded_features = ct.fit_transform(pumpkins)
```
D'autre part, pour encoder l'√©tiquette, nous utilisons la classe `LabelEncoder` de scikit-learn, qui est une classe utilitaire pour normaliser les √©tiquettes de sorte qu'elles contiennent uniquement des valeurs entre 0 et n_classes-1 (ici, 0 et 1).

```python
    from sklearn.preprocessing import LabelEncoder

    label_encoder = LabelEncoder()
    encoded_label = label_encoder.fit_transform(pumpkins['Color'])
```
Une fois que nous avons encod√© les caract√©ristiques et l'√©tiquette, nous pouvons les fusionner dans un nouveau dataframe `encoded_pumpkins`.

```python
    encoded_pumpkins = encoded_features.assign(Color=encoded_label)
```
‚úÖ Quels sont les avantages d'utiliser un encodeur ordinal pour la colonne `Item Size` ?

### Analyser les relations entre les variables

Maintenant que nous avons pr√©trait√© nos donn√©es, nous pouvons analyser les relations entre les caract√©ristiques et l'√©tiquette pour avoir une id√©e de la capacit√© du mod√®le √† pr√©dire l'√©tiquette en fonction des caract√©ristiques.
La meilleure fa√ßon de r√©aliser ce type d'analyse est de tracer les donn√©es. Nous utiliserons √† nouveau la fonction `catplot` de Seaborn pour visualiser les relations entre `Item Size`, `Variety` et `Color` dans un graphique cat√©goriel. Pour mieux tracer les donn√©es, nous utiliserons la colonne encod√©e `Item Size` et la colonne non encod√©e `Variety`.

```python
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }
    pumpkins['Item Size'] = encoded_pumpkins['ord__Item Size']

    g = sns.catplot(
        data=pumpkins,
        x="Item Size", y="Color", row='Variety',
        kind="box", orient="h",
        sharex=False, margin_titles=True,
        height=1.8, aspect=4, palette=palette,
    )
    g.set(xlabel="Item Size", ylabel="").set(xlim=(0,6))
    g.set_titles(row_template="{row_name}")
```
![Un catplot de donn√©es visualis√©es](../../../../2-Regression/4-Logistic/images/pumpkins_catplot_2.png)

### Utiliser un graphique en essaim

√âtant donn√© que Color est une cat√©gorie binaire (Blanche ou Non), elle n√©cessite 'une [approche sp√©cialis√©e](https://seaborn.pydata.org/tutorial/categorical.html?highlight=bar) pour la visualisation'. Il existe d'autres fa√ßons de visualiser la relation de cette cat√©gorie avec d'autres variables.

Vous pouvez visualiser les variables c√¥te √† c√¥te avec des graphiques Seaborn.

1. Essayez un graphique en 'essaim' pour montrer la distribution des valeurs :

    ```python
    palette = {
    0: 'orange',
    1: 'wheat'
    }
    sns.swarmplot(x="Color", y="ord__Item Size", data=encoded_pumpkins, palette=palette)
    ```

    ![Un essaim de donn√©es visualis√©es](../../../../2-Regression/4-Logistic/images/swarm_2.png)

**Attention** : le code ci-dessus pourrait g√©n√©rer un avertissement, car Seaborn √©choue √† repr√©senter une telle quantit√© de points de donn√©es dans un graphique en essaim. Une solution possible est de r√©duire la taille du marqueur, en utilisant le param√®tre 'size'. Cependant, soyez conscient que cela affecte la lisibilit√© du graphique.

> **üßÆ Montrez-moi les maths**
>
> La r√©gression logistique repose sur le concept de 'maximum de vraisemblance' en utilisant des [fonctions sigmo√Ødes](https://wikipedia.org/wiki/Sigmoid_function). Une 'fonction sigmo√Øde' sur un graphique ressemble √† une forme en 'S'. Elle prend une valeur et la mappe entre 0 et 1. Sa courbe est √©galement appel√©e 'courbe logistique'. Sa formule ressemble √† ceci :
>
> ![fonction logistique](../../../../2-Regression/4-Logistic/images/sigmoid.png)
>
> o√π le point m√©dian de la sigmo√Øde se trouve au point 0 de x, L est la valeur maximale de la courbe, et k est la pente de la courbe. Si le r√©sultat de la fonction est sup√©rieur √† 0,5, l'√©tiquette en question sera attribu√©e √† la classe '1' du choix binaire. Sinon, elle sera class√©e comme '0'.

## Construisez votre mod√®le

Construire un mod√®le pour trouver ces classifications binaires est √©tonnamment simple avec Scikit-learn.

[![ML pour d√©butants - R√©gression logistique pour la classification des donn√©es](https://img.youtube.com/vi/MmZS2otPrQ8/0.jpg)](https://youtu.be/MmZS2otPrQ8 "ML pour d√©butants - R√©gression logistique pour la classification des donn√©es")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o sur la construction d'un mod√®le de r√©gression lin√©aire.

1. S√©lectionnez les variables que vous souhaitez utiliser dans votre mod√®le de classification et divisez les ensembles d'entra√Ænement et de test en appelant `train_test_split()` :

    ```python
    from sklearn.model_selection import train_test_split
    
    X = encoded_pumpkins[encoded_pumpkins.columns.difference(['Color'])]
    y = encoded_pumpkins['Color']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
    
    ```

2. Maintenant, vous pouvez entra√Æner votre mod√®le, en appelant `fit()` avec vos donn√©es d'entra√Ænement, et afficher son r√©sultat :

    ```python
    from sklearn.metrics import f1_score, classification_report 
    from sklearn.linear_model import LogisticRegression

    model = LogisticRegression()
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)

    print(classification_report(y_test, predictions))
    print('Predicted labels: ', predictions)
    print('F1-score: ', f1_score(y_test, predictions))
    ```

    Regardez le tableau de bord de votre mod√®le. Ce n'est pas mal, compte tenu du fait que vous avez seulement environ 1000 lignes de donn√©es :

    ```output
                       precision    recall  f1-score   support
    
                    0       0.94      0.98      0.96       166
                    1       0.85      0.67      0.75        33
    
        accuracy                                0.92       199
        macro avg           0.89      0.82      0.85       199
        weighted avg        0.92      0.92      0.92       199
    
        Predicted labels:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0
        0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
        1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0
        0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0
        0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
        0 0 0 1 0 0 0 0 0 0 0 0 1 1]
        F1-score:  0.7457627118644068
    ```

## Meilleure compr√©hension via une matrice de confusion

Bien que vous puissiez obtenir un rapport de tableau de bord [termes](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html?highlight=classification_report#sklearn.metrics.classification_report) en imprimant les √©l√©ments ci-dessus, vous pourriez mieux comprendre votre mod√®le en utilisant une [matrice de confusion](https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix) pour nous aider √† comprendre comment le mod√®le fonctionne.

> üéì Une '[matrice de confusion](https://wikipedia.org/wiki/Confusion_matrix)' (ou 'matrice d'erreur') est un tableau qui exprime les vrais positifs et n√©gatifs de votre mod√®le par rapport aux faux positifs et n√©gatifs, √©valuant ainsi la pr√©cision des pr√©dictions.

1. Pour utiliser une matrice de confusion, appelez `confusion_matrix()` :

    ```python
    from sklearn.metrics import confusion_matrix
    confusion_matrix(y_test, predictions)
    ```

    Regardez la matrice de confusion de votre mod√®le :

    ```output
    array([[162,   4],
           [ 11,  22]])
    ```

Dans Scikit-learn, les lignes (axe 0) sont les √©tiquettes r√©elles et les colonnes (axe 1) sont les √©tiquettes pr√©dites.

|       |   0   |   1   |
| :---: | :---: | :---: |
|   0   |  TN   |  FP   |
|   1   |  FN   |  TP   |

Que se passe-t-il ici ? Disons que notre mod√®le est charg√© de classer les citrouilles entre deux cat√©gories binaires, cat√©gorie 'blanche' et cat√©gorie 'non blanche'.

- Si votre mod√®le pr√©dit qu'une citrouille n'est pas blanche et qu'elle appartient √† la cat√©gorie 'non blanche' en r√©alit√©, nous appelons cela un vrai n√©gatif, indiqu√© par le nombre en haut √† gauche.
- Si votre mod√®le pr√©dit qu'une citrouille est blanche et qu'elle appartient √† la cat√©gorie 'non blanche' en r√©alit√©, nous appelons cela un faux n√©gatif, indiqu√© par le nombre en bas √† gauche.
- Si votre mod√®le pr√©dit qu'une citrouille n'est pas blanche et qu'elle appartient √† la cat√©gorie 'blanche' en r√©alit√©, nous appelons cela un faux positif, indiqu√© par le nombre en haut √† droite.
- Si votre mod√®le pr√©dit qu'une citrouille est blanche et qu'elle appartient √† la cat√©gorie 'blanche' en r√©alit√©, nous appelons cela un vrai positif, indiqu√© par le nombre en bas √† droite.

Comme vous l'avez probablement devin√©, il est pr√©f√©rable d'avoir un plus grand nombre de vrais positifs et de vrais n√©gatifs et un plus petit nombre de faux positifs et de faux n√©gatifs, ce qui implique que le mod√®le fonctionne mieux.
Comment la matrice de confusion est-elle li√©e √† la pr√©cision et au rappel ? Rappelez-vous, le rapport de classification imprim√© ci-dessus montrait une pr√©cision (0,85) et un rappel (0,67).

Pr√©cision = tp / (tp + fp) = 22 / (22 + 4) = 0,8461538461538461

Rappel = tp / (tp + fn) = 22 / (22 + 11) = 0,6666666666666666

‚úÖ Q : Selon la matrice de confusion, comment le mod√®le s'en est-il sorti ?  
A : Pas mal ; il y a un bon nombre de vrais n√©gatifs mais aussi quelques faux n√©gatifs.

Revisitons les termes que nous avons vus pr√©c√©demment √† l'aide de la cartographie TP/TN et FP/FN de la matrice de confusion :

üéì Pr√©cision : TP/(TP + FP)  
La fraction des instances pertinentes parmi les instances r√©cup√©r√©es (par exemple, quelles √©tiquettes ont √©t√© bien class√©es).

üéì Rappel : TP/(TP + FN)  
La fraction des instances pertinentes qui ont √©t√© r√©cup√©r√©es, qu'elles soient bien class√©es ou non.

üéì f1-score : (2 * pr√©cision * rappel)/(pr√©cision + rappel)  
Une moyenne pond√©r√©e de la pr√©cision et du rappel, avec un score maximal de 1 et minimal de 0.

üéì Support :  
Le nombre d'occurrences de chaque √©tiquette r√©cup√©r√©e.

üéì Exactitude : (TP + TN)/(TP + TN + FP + FN)  
Le pourcentage d'√©tiquettes pr√©dites correctement pour un √©chantillon.

üéì Macro Moyenne :  
Le calcul de la moyenne non pond√©r√©e des m√©triques pour chaque √©tiquette, sans tenir compte du d√©s√©quilibre des √©tiquettes.

üéì Moyenne Pond√©r√©e :  
Le calcul de la moyenne des m√©triques pour chaque √©tiquette, en tenant compte du d√©s√©quilibre des √©tiquettes en les pond√©rant par leur support (le nombre d'instances r√©elles pour chaque √©tiquette).

‚úÖ Pouvez-vous r√©fl√©chir √† quel m√©trique surveiller si vous voulez que votre mod√®le r√©duise le nombre de faux n√©gatifs ?

## Visualiser la courbe ROC de ce mod√®le

[![ML pour d√©butants - Analyse de la performance de la r√©gression logistique avec les courbes ROC](https://img.youtube.com/vi/GApO575jTA0/0.jpg)](https://youtu.be/GApO575jTA0 "ML pour d√©butants - Analyse de la performance de la r√©gression logistique avec les courbes ROC")

> üé• Cliquez sur l'image ci-dessus pour une courte vid√©o sur les courbes ROC.

Faisons une derni√®re visualisation pour voir la fameuse courbe 'ROC' :

```python
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline

y_scores = model.predict_proba(X_test)
fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])

fig = plt.figure(figsize=(6, 6))
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.show()
```

En utilisant Matplotlib, tracez la [caract√©ristique de fonctionnement du r√©cepteur](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html?highlight=roc) ou ROC du mod√®le. Les courbes ROC sont souvent utilis√©es pour obtenir une vue d'ensemble des r√©sultats d'un classificateur en termes de vrais positifs vs faux positifs. "Les courbes ROC pr√©sentent g√©n√©ralement le taux de vrais positifs sur l'axe Y et le taux de faux positifs sur l'axe X." Ainsi, la pente de la courbe et l'espace entre la ligne m√©diane et la courbe sont importants : vous voulez une courbe qui monte rapidement et d√©passe la ligne. Dans notre cas, il y a des faux positifs au d√©part, puis la ligne monte correctement :

![ROC](../../../../2-Regression/4-Logistic/images/ROC_2.png)

Enfin, utilisez l'API [`roc_auc_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html?highlight=roc_auc#sklearn.metrics.roc_auc_score) de Scikit-learn pour calculer la v√©ritable 'Surface sous la courbe' (AUC) :

```python
auc = roc_auc_score(y_test,y_scores[:,1])
print(auc)
```  
Le r√©sultat est `0,9749908725812341`. √âtant donn√© que l'AUC varie de 0 √† 1, vous voulez un score √©lev√©, car un mod√®le qui est correct √† 100 % dans ses pr√©dictions aura une AUC de 1 ; dans ce cas, le mod√®le est _plut√¥t bon_.

Dans les prochaines le√ßons sur les classifications, vous apprendrez comment it√©rer pour am√©liorer les scores de votre mod√®le. Mais pour l'instant, f√©licitations ! Vous avez termin√© ces le√ßons sur la r√©gression !

---
## üöÄD√©fi

Il y a beaucoup plus √† d√©couvrir sur la r√©gression logistique ! Mais la meilleure fa√ßon d'apprendre est d'exp√©rimenter. Trouvez un jeu de donn√©es qui se pr√™te √† ce type d'analyse et construisez un mod√®le avec celui-ci. Qu'apprenez-vous ? Astuce : essayez [Kaggle](https://www.kaggle.com/search?q=logistic+regression+datasets) pour des jeux de donn√©es int√©ressants.

## [Quiz post-lecture](https://ff-quizzes.netlify.app/en/ml/)

## R√©vision & √âtude personnelle

Lisez les premi√®res pages de [cet article de Stanford](https://web.stanford.edu/~jurafsky/slp3/5.pdf) sur quelques utilisations pratiques de la r√©gression logistique. R√©fl√©chissez aux t√¢ches qui conviennent mieux √† l'un ou l'autre type de t√¢ches de r√©gression que nous avons √©tudi√©es jusqu'√† pr√©sent. Qu'est-ce qui fonctionnerait le mieux ?

## Devoir

[Reprendre cette r√©gression](assignment.md)

---

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction professionnelle r√©alis√©e par un humain. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.