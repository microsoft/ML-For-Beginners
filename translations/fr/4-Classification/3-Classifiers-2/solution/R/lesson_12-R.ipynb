{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "lesson_12-R.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "ir",
   "display_name": "R"
  },
  "language_info": {
   "name": "R"
  },
  "coopTranslator": {
   "original_hash": "fab50046ca413a38939d579f8432274f",
   "translation_date": "2025-09-04T02:33:50+00:00",
   "source_file": "4-Classification/3-Classifiers-2/solution/R/lesson_12-R.ipynb",
   "language_code": "fr"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsFutf_ygqSx"
   },
   "source": [
    "# Construire un mod√®le de classification : D√©licieuses cuisines asiatiques et indiennes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HD54bEefgtNO"
   },
   "source": [
    "## Classificateurs de cuisine 2\n",
    "\n",
    "Dans cette deuxi√®me le√ßon sur la classification, nous allons explorer `davantage de m√©thodes` pour classifier les donn√©es cat√©gorielles. Nous examinerons √©galement les implications du choix d'un classificateur plut√¥t qu'un autre.\n",
    "\n",
    "### [**Quiz avant la le√ßon**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/23/)\n",
    "\n",
    "### **Pr√©requis**\n",
    "\n",
    "Nous supposons que vous avez termin√© les le√ßons pr√©c√©dentes, car nous allons reprendre certains concepts abord√©s auparavant.\n",
    "\n",
    "Pour cette le√ßon, nous aurons besoin des packages suivants :\n",
    "\n",
    "-   `tidyverse` : Le [tidyverse](https://www.tidyverse.org/) est une [collection de packages R](https://www.tidyverse.org/packages) con√ßue pour rendre la science des donn√©es plus rapide, plus facile et plus agr√©able !\n",
    "\n",
    "-   `tidymodels` : Le framework [tidymodels](https://www.tidymodels.org/) est une [collection de packages](https://www.tidymodels.org/packages/) d√©di√©e √† la mod√©lisation et √† l'apprentissage automatique.\n",
    "\n",
    "-   `themis` : Le package [themis](https://themis.tidymodels.org/) fournit des √©tapes suppl√©mentaires pour traiter les donn√©es d√©s√©quilibr√©es.\n",
    "\n",
    "Vous pouvez les installer avec la commande suivante :\n",
    "\n",
    "`install.packages(c(\"tidyverse\", \"tidymodels\", \"kernlab\", \"themis\", \"ranger\", \"xgboost\", \"kknn\"))`\n",
    "\n",
    "Sinon, le script ci-dessous v√©rifie si vous avez les packages n√©cessaires pour compl√©ter ce module et les installe pour vous s'ils sont manquants.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vZ57IuUxgyQt"
   },
   "source": [
    "suppressWarnings(if (!require(\"pacman\"))install.packages(\"pacman\"))\n",
    "\n",
    "pacman::p_load(tidyverse, tidymodels, themis, kernlab, ranger, xgboost, kknn)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z22M-pj4g07x"
   },
   "source": [
    "## **1. Une carte de classification**\n",
    "\n",
    "Dans notre [le√ßon pr√©c√©dente](https://github.com/microsoft/ML-For-Beginners/tree/main/4-Classification/2-Classifiers-1), nous avons tent√© de r√©pondre √† la question : comment choisir entre plusieurs mod√®les ? En grande partie, cela d√©pend des caract√©ristiques des donn√©es et du type de probl√®me que nous voulons r√©soudre (par exemple, classification ou r√©gression ?)\n",
    "\n",
    "Auparavant, nous avons appris les diff√©rentes options disponibles pour classifier des donn√©es en utilisant l'aide-m√©moire de Microsoft. Le framework de Machine Learning en Python, Scikit-learn, propose un aide-m√©moire similaire mais plus d√©taill√©, qui peut vous aider √† affiner davantage vos estimateurs (un autre terme pour d√©signer les classificateurs) :\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/map.png\"\n",
    "   width=\"700\"/>\n",
    "   <figcaption></figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1i3xRIVg7vG"
   },
   "source": [
    "> Conseil : [consultez cette carte en ligne](https://scikit-learn.org/stable/tutorial/machine_learning_map/) et cliquez sur les chemins pour lire la documentation.  \n",
    ">  \n",
    "> Le [site de r√©f√©rence Tidymodels](https://www.tidymodels.org/find/parsnip/#models) propose √©galement une excellente documentation sur les diff√©rents types de mod√®les.\n",
    "\n",
    "### **Le plan** üó∫Ô∏è\n",
    "\n",
    "Cette carte est tr√®s utile une fois que vous comprenez bien vos donn√©es, car vous pouvez \"suivre\" ses chemins pour arriver √† une d√©cision :\n",
    "\n",
    "-   Nous avons \\>50 √©chantillons\n",
    "\n",
    "-   Nous voulons pr√©dire une cat√©gorie\n",
    "\n",
    "-   Nous avons des donn√©es √©tiquet√©es\n",
    "\n",
    "-   Nous avons moins de 100K √©chantillons\n",
    "\n",
    "-   ‚ú® Nous pouvons choisir un Linear SVC\n",
    "\n",
    "-   Si cela ne fonctionne pas, √©tant donn√© que nous avons des donn√©es num√©riques :\n",
    "\n",
    "    -   Nous pouvons essayer un ‚ú® KNeighbors Classifier\n",
    "\n",
    "        -   Si cela ne fonctionne pas, essayez ‚ú® SVC et ‚ú® Ensemble Classifiers\n",
    "\n",
    "C'est un chemin tr√®s utile √† suivre. Maintenant, passons directement √† l'action en utilisant le framework de mod√©lisation [tidymodels](https://www.tidymodels.org/) : une collection coh√©rente et flexible de packages R d√©velopp√©e pour encourager de bonnes pratiques statistiques üòä.\n",
    "\n",
    "## 2. Diviser les donn√©es et g√©rer un ensemble de donn√©es d√©s√©quilibr√©.\n",
    "\n",
    "Dans nos le√ßons pr√©c√©dentes, nous avons appris qu'il existait un ensemble d'ingr√©dients communs √† travers nos cuisines. De plus, il y avait une r√©partition assez in√©gale du nombre de cuisines.\n",
    "\n",
    "Nous allons g√©rer cela en :\n",
    "\n",
    "-   Supprimant les ingr√©dients les plus courants qui cr√©ent de la confusion entre des cuisines distinctes, en utilisant `dplyr::select()`.\n",
    "\n",
    "-   Utilisant une `recipe` qui pr√©traite les donn√©es pour les pr√©parer √† la mod√©lisation en appliquant un algorithme de `sur-√©chantillonnage`.\n",
    "\n",
    "Nous avons d√©j√† vu cela dans la le√ßon pr√©c√©dente, donc cela devrait √™tre un jeu d'enfant ü•≥ !\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6tj_rN00hClA"
   },
   "source": [
    "# Load the core Tidyverse and Tidymodels packages\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "\n",
    "# Load the original cuisines data\n",
    "df <- read_csv(file = \"https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/data/cuisines.csv\")\n",
    "\n",
    "# Drop id column, rice, garlic and ginger from our original data set\n",
    "df_select <- df %>% \n",
    "  select(-c(1, rice, garlic, ginger)) %>%\n",
    "  # Encode cuisine column as categorical\n",
    "  mutate(cuisine = factor(cuisine))\n",
    "\n",
    "\n",
    "# Create data split specification\n",
    "set.seed(2056)\n",
    "cuisines_split <- initial_split(data = df_select,\n",
    "                                strata = cuisine,\n",
    "                                prop = 0.7)\n",
    "\n",
    "# Extract the data in each split\n",
    "cuisines_train <- training(cuisines_split)\n",
    "cuisines_test <- testing(cuisines_split)\n",
    "\n",
    "# Display distribution of cuisines in the training set\n",
    "cuisines_train %>% \n",
    "  count(cuisine) %>% \n",
    "  arrange(desc(n))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFin5yw3hHb1"
   },
   "source": [
    "### G√©rer les donn√©es d√©s√©quilibr√©es\n",
    "\n",
    "Les donn√©es d√©s√©quilibr√©es ont souvent des effets n√©gatifs sur les performances du mod√®le. De nombreux mod√®les fonctionnent mieux lorsque le nombre d'observations est √©quilibr√© et, par cons√©quent, ont tendance √† rencontrer des difficult√©s avec des donn√©es non √©quilibr√©es.\n",
    "\n",
    "Il existe principalement deux fa√ßons de traiter les ensembles de donn√©es d√©s√©quilibr√©s :\n",
    "\n",
    "-   ajouter des observations √† la classe minoritaire : `Sur-√©chantillonnage`, par exemple en utilisant un algorithme SMOTE qui g√©n√®re de mani√®re synth√©tique de nouveaux exemples de la classe minoritaire en utilisant les plus proches voisins de ces cas.\n",
    "\n",
    "-   supprimer des observations de la classe majoritaire : `Sous-√©chantillonnage`\n",
    "\n",
    "Dans notre le√ßon pr√©c√©dente, nous avons d√©montr√© comment traiter les ensembles de donn√©es d√©s√©quilibr√©s en utilisant une `recette`. Une recette peut √™tre consid√©r√©e comme un plan d√©crivant les √©tapes √† appliquer √† un ensemble de donn√©es pour le pr√©parer √† l'analyse. Dans notre cas, nous souhaitons obtenir une distribution √©gale du nombre de nos cuisines pour notre `ensemble d'entra√Ænement`. Allons-y directement.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cRzTnHolhLWd"
   },
   "source": [
    "# Load themis package for dealing with imbalanced data\n",
    "library(themis)\n",
    "\n",
    "# Create a recipe for preprocessing training data\n",
    "cuisines_recipe <- recipe(cuisine ~ ., data = cuisines_train) %>%\n",
    "  step_smote(cuisine) \n",
    "\n",
    "# Print recipe\n",
    "cuisines_recipe"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxOQ2ORhhO81"
   },
   "source": [
    "Nous sommes pr√™ts √† entra√Æner des mod√®les üë©‚Äçüíªüë®‚Äçüíª !\n",
    "\n",
    "## 3. Au-del√† des mod√®les de r√©gression multinomiale\n",
    "\n",
    "Dans notre le√ßon pr√©c√©dente, nous avons √©tudi√© les mod√®les de r√©gression multinomiale. Explorons maintenant des mod√®les plus flexibles pour la classification.\n",
    "\n",
    "### Machines √† vecteurs de support\n",
    "\n",
    "Dans le contexte de la classification, les `Machines √† vecteurs de support` sont une technique d'apprentissage automatique qui cherche √† trouver un *hyperplan* qui s√©pare \"au mieux\" les classes. Prenons un exemple simple :\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/svm.png\"\n",
    "   width=\"300\"/>\n",
    "   <figcaption>https://commons.wikimedia.org/w/index.php?curid=22877598</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4Wsd0vZhXYu"
   },
   "source": [
    "H1~ ne s√©pare pas les classes. H2~ les s√©pare, mais seulement avec une petite marge. H3~ les s√©pare avec la marge maximale.\n",
    "\n",
    "#### Classificateur Lin√©aire √† Vecteurs de Support\n",
    "\n",
    "Le clustering par vecteurs de support (SVC) est une branche de la famille des machines √† vecteurs de support, une technique d'apprentissage automatique. Dans le SVC, l'hyperplan est choisi pour s√©parer correctement `la plupart` des observations d'entra√Ænement, mais `peut mal classer` quelques observations. En permettant √† certains points d'√™tre du mauvais c√¥t√©, le SVM devient plus robuste face aux valeurs aberrantes, ce qui am√©liore la g√©n√©ralisation aux nouvelles donn√©es. Le param√®tre qui r√©gule cette violation est appel√© `cost`, avec une valeur par d√©faut de 1 (voir `help(\"svm_poly\")`).\n",
    "\n",
    "Cr√©ons un SVC lin√©aire en d√©finissant `degree = 1` dans un mod√®le SVM polynomial.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vJpp6nuChlBz"
   },
   "source": [
    "# Make a linear SVC specification\n",
    "svc_linear_spec <- svm_poly(degree = 1) %>% \n",
    "  set_engine(\"kernlab\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle specification and recipe into a worklow\n",
    "svc_linear_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(svc_linear_spec)\n",
    "\n",
    "# Print out workflow\n",
    "svc_linear_wf"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDs8cWNkhoqu"
   },
   "source": [
    "Maintenant que nous avons int√©gr√© les √©tapes de pr√©traitement et la sp√©cification du mod√®le dans un *workflow*, nous pouvons passer √† l'entra√Ænement du SVC lin√©aire et √©valuer les r√©sultats en m√™me temps. Pour les m√©triques de performance, cr√©ons un ensemble de m√©triques qui √©valuera : `accuracy`, `sensitivity`, `Positive Predicted Value` et `F Measure`.\n",
    "\n",
    "> `augment()` ajoutera une ou plusieurs colonnes pour les pr√©dictions aux donn√©es fournies.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "81wiqcwuhrnq"
   },
   "source": [
    "# Train a linear SVC model\n",
    "svc_linear_fit <- svc_linear_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "# Create a metric set\n",
    "eval_metrics <- metric_set(ppv, sens, accuracy, f_meas)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "svc_linear_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UFQvHf-huo3"
   },
   "source": [
    "#### Machine √† Vecteurs de Support\n",
    "\n",
    "La machine √† vecteurs de support (SVM) est une extension du classificateur √† vecteurs de support afin de g√©rer une fronti√®re non lin√©aire entre les classes. En substance, les SVM utilisent l‚Äô*astuce du noyau* pour agrandir l‚Äôespace des caract√©ristiques et s‚Äôadapter aux relations non lin√©aires entre les classes. Une fonction noyau populaire et extr√™mement flexible utilis√©e par les SVM est la *fonction de base radiale.* Voyons comment elle se comporte avec nos donn√©es.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-KX4S8mzhzmp"
   },
   "source": [
    "set.seed(2056)\n",
    "\n",
    "# Make an RBF SVM specification\n",
    "svm_rbf_spec <- svm_rbf() %>% \n",
    "  set_engine(\"kernlab\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle specification and recipe into a worklow\n",
    "svm_rbf_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(svm_rbf_spec)\n",
    "\n",
    "\n",
    "# Train an RBF model\n",
    "svm_rbf_fit <- svm_rbf_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "svm_rbf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBFSa7WSh4HQ"
   },
   "source": [
    "Beaucoup mieux ü§© !\n",
    "\n",
    "> ‚úÖ Veuillez consulter :\n",
    ">\n",
    "> -   [*Support Vector Machines*](https://bradleyboehmke.github.io/HOML/svm.html), Hands-on Machine Learning avec R\n",
    ">\n",
    "> -   [*Support Vector Machines*](https://www.statlearning.com/), An Introduction to Statistical Learning with Applications in R\n",
    ">\n",
    "> pour en savoir plus.\n",
    "\n",
    "### Classificateurs des plus proches voisins\n",
    "\n",
    "Le *K*-nearest neighbor (KNN) est un algorithme dans lequel chaque observation est pr√©dite en fonction de sa *similarit√©* avec d'autres observations.\n",
    "\n",
    "Essayons d'en ajuster un √† nos donn√©es.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k4BxxBcdh9Ka"
   },
   "source": [
    "# Make a KNN specification\n",
    "knn_spec <- nearest_neighbor() %>% \n",
    "  set_engine(\"kknn\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "knn_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(knn_spec)\n",
    "\n",
    "# Train a boosted tree model\n",
    "knn_wf_fit <- knn_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "knn_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaegQseriAcj"
   },
   "source": [
    "Il semble que ce mod√®le ne donne pas de tr√®s bons r√©sultats. Modifier les arguments du mod√®le (voir `help(\"nearest_neighbor\")`) pourrait probablement am√©liorer ses performances. Assurez-vous d'essayer.\n",
    "\n",
    "> ‚úÖ Veuillez consulter :\n",
    ">\n",
    "> -   [Hands-on Machine Learning with R](https://bradleyboehmke.github.io/HOML/)\n",
    ">\n",
    "> -   [An Introduction to Statistical Learning with Applications in R](https://www.statlearning.com/)\n",
    ">\n",
    "> pour en savoir plus sur les classificateurs *K*-Nearest Neighbors.\n",
    "\n",
    "### Classificateurs par ensemble\n",
    "\n",
    "Les algorithmes d'ensemble fonctionnent en combinant plusieurs estimateurs de base pour produire un mod√®le optimal, soit en :\n",
    "\n",
    "`bagging` : appliquant une *fonction de moyenne* √† une collection de mod√®les de base\n",
    "\n",
    "`boosting` : construisant une s√©quence de mod√®les qui s'appuient les uns sur les autres pour am√©liorer les performances pr√©dictives.\n",
    "\n",
    "Commen√ßons par essayer un mod√®le de For√™t Al√©atoire, qui construit une grande collection d'arbres de d√©cision, puis applique une fonction de moyenne pour obtenir un meilleur mod√®le global.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "49DPoVs6iK1M"
   },
   "source": [
    "# Make a random forest specification\n",
    "rf_spec <- rand_forest() %>% \n",
    "  set_engine(\"ranger\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "rf_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(rf_spec)\n",
    "\n",
    "# Train a random forest model\n",
    "rf_wf_fit <- rf_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "rf_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGVYwC_aiUWc"
   },
   "source": [
    "Bon travail üëè !\n",
    "\n",
    "Essayons √©galement un mod√®le Boosted Tree.\n",
    "\n",
    "Boosted Tree d√©finit une m√©thode d'ensemble qui cr√©e une s√©rie d'arbres de d√©cision s√©quentiels o√π chaque arbre d√©pend des r√©sultats des arbres pr√©c√©dents dans le but de r√©duire progressivement l'erreur. Il se concentre sur les poids des √©l√©ments mal class√©s et ajuste l'ajustement pour le prochain classificateur afin de corriger.\n",
    "\n",
    "Il existe diff√©rentes fa√ßons d'ajuster ce mod√®le (voir `help(\"boost_tree\")`). Dans cet exemple, nous ajusterons les Boosted Trees via le moteur `xgboost`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Py1YWo-micWs"
   },
   "source": [
    "# Make a boosted tree specification\n",
    "boost_spec <- boost_tree(trees = 200) %>% \n",
    "  set_engine(\"xgboost\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "boost_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(boost_spec)\n",
    "\n",
    "# Train a boosted tree model\n",
    "boost_wf_fit <- boost_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "boost_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNQnbuejigZM"
   },
   "source": [
    "> ‚úÖ Veuillez consulter :\n",
    ">\n",
    "> -   [Machine Learning for Social Scientists](https://cimentadaj.github.io/ml_socsci/tree-based-methods.html#random-forests)\n",
    ">\n",
    "> -   [Hands-on Machine Learning with R](https://bradleyboehmke.github.io/HOML/)\n",
    ">\n",
    "> -   [An Introduction to Statistical Learning with Applications in R](https://www.statlearning.com/)\n",
    ">\n",
    "> -   <https://algotech.netlify.app/blog/xgboost/> - Explore le mod√®le AdaBoost, une bonne alternative √† xgboost.\n",
    ">\n",
    "> pour en savoir plus sur les classificateurs ensemblistes.\n",
    "\n",
    "## 4. Extra - comparer plusieurs mod√®les\n",
    "\n",
    "Nous avons ajust√© un bon nombre de mod√®les dans ce laboratoire üôå. Cela peut devenir fastidieux ou compliqu√© de cr√©er de nombreux workflows √† partir de diff√©rents ensembles de pr√©processeurs et/ou sp√©cifications de mod√®les, puis de calculer les m√©triques de performance une par une.\n",
    "\n",
    "Voyons si nous pouvons r√©soudre ce probl√®me en cr√©ant une fonction qui ajuste une liste de workflows sur l'ensemble d'entra√Ænement, puis retourne les m√©triques de performance bas√©es sur l'ensemble de test. Nous allons utiliser `map()` et `map_dfr()` du package [purrr](https://purrr.tidyverse.org/) pour appliquer des fonctions √† chaque √©l√©ment d'une liste.\n",
    "\n",
    "> Les fonctions [`map()`](https://purrr.tidyverse.org/reference/map.html) vous permettent de remplacer de nombreuses boucles for par un code √† la fois plus concis et plus facile √† lire. Le meilleur endroit pour apprendre les fonctions [`map()`](https://purrr.tidyverse.org/reference/map.html) est le [chapitre sur l'it√©ration](http://r4ds.had.co.nz/iteration.html) dans R for data science.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Qzb7LyZnimd2"
   },
   "source": [
    "set.seed(2056)\n",
    "\n",
    "# Create a metric set\n",
    "eval_metrics <- metric_set(ppv, sens, accuracy, f_meas)\n",
    "\n",
    "# Define a function that returns performance metrics\n",
    "compare_models <- function(workflow_list, train_set, test_set){\n",
    "  \n",
    "  suppressWarnings(\n",
    "    # Fit each model to the train_set\n",
    "    map(workflow_list, fit, data = train_set) %>% \n",
    "    # Make predictions on the test set\n",
    "      map_dfr(augment, new_data = test_set, .id = \"model\") %>%\n",
    "    # Select desired columns\n",
    "      select(model, cuisine, .pred_class) %>% \n",
    "    # Evaluate model performance\n",
    "      group_by(model) %>% \n",
    "      eval_metrics(truth = cuisine, estimate = .pred_class) %>% \n",
    "      ungroup()\n",
    "  )\n",
    "  \n",
    "} # End of function"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fwa712sNisDA"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3i4VJOi2iu-a"
   },
   "source": [
    "# Make a list of workflows\n",
    "workflow_list <- list(\n",
    "  \"svc\" = svc_linear_wf,\n",
    "  \"svm\" = svm_rbf_wf,\n",
    "  \"knn\" = knn_wf,\n",
    "  \"random_forest\" = rf_wf,\n",
    "  \"xgboost\" = boost_wf)\n",
    "\n",
    "# Call the function\n",
    "set.seed(2056)\n",
    "perf_metrics <- compare_models(workflow_list = workflow_list, train_set = cuisines_train, test_set = cuisines_test)\n",
    "\n",
    "# Print out performance metrics\n",
    "perf_metrics %>% \n",
    "  group_by(.metric) %>% \n",
    "  arrange(desc(.estimate)) %>% \n",
    "  slice_head(n=7)\n",
    "\n",
    "# Compare accuracy\n",
    "perf_metrics %>% \n",
    "  filter(.metric == \"accuracy\") %>% \n",
    "  arrange(desc(.estimate))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuWK_lEli4nW"
   },
   "source": [
    "[**workflowset**](https://workflowsets.tidymodels.org/) permet aux utilisateurs de cr√©er et d'ajuster facilement un grand nombre de mod√®les, mais il est principalement con√ßu pour fonctionner avec des techniques de r√©√©chantillonnage telles que la `validation crois√©e`, une approche que nous n'avons pas encore abord√©e.\n",
    "\n",
    "## **üöÄD√©fi**\n",
    "\n",
    "Chacune de ces techniques poss√®de un grand nombre de param√®tres que vous pouvez ajuster, comme par exemple `cost` pour les SVM, `neighbors` pour les KNN, ou `mtry` (Pr√©dicteurs S√©lectionn√©s Al√©atoirement) pour les For√™ts Al√©atoires.\n",
    "\n",
    "Faites des recherches sur les param√®tres par d√©faut de chacun et r√©fl√©chissez √† ce que modifier ces param√®tres pourrait signifier pour la qualit√© du mod√®le.\n",
    "\n",
    "Pour en savoir plus sur un mod√®le particulier et ses param√®tres, utilisez : `help(\"model\")`, par exemple `help(\"rand_forest\")`.\n",
    "\n",
    "> En pratique, nous *estimons* g√©n√©ralement les *meilleures valeurs* pour ces param√®tres en entra√Ænant de nombreux mod√®les sur un `jeu de donn√©es simul√©` et en mesurant les performances de tous ces mod√®les. Ce processus s'appelle **l'optimisation**.\n",
    "\n",
    "### [**Quiz apr√®s le cours**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/24/)\n",
    "\n",
    "### **R√©vision & √âtude Personnelle**\n",
    "\n",
    "Il y a beaucoup de jargon dans ces le√ßons, alors prenez un moment pour consulter [cette liste](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) de terminologie utile !\n",
    "\n",
    "#### MERCI √Ä :\n",
    "\n",
    "[`Allison Horst`](https://twitter.com/allison_horst/) pour avoir cr√©√© les illustrations incroyables qui rendent R plus accueillant et engageant. Retrouvez plus d'illustrations dans sa [galerie](https://www.google.com/url?q=https://github.com/allisonhorst/stats-illustrations&sa=D&source=editors&ust=1626380772530000&usg=AOvVaw3zcfyCizFQZpkSLzxiiQEM).\n",
    "\n",
    "[Cassie Breviu](https://www.twitter.com/cassieview) et [Jen Looper](https://www.twitter.com/jenlooper) pour avoir cr√©√© la version originale en Python de ce module ‚ô•Ô∏è\n",
    "\n",
    "Bon apprentissage,\n",
    "\n",
    "[Eric](https://twitter.com/ericntay), Gold Microsoft Learn Student Ambassador.\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/r_learners_sm.jpeg\"\n",
    "   width=\"569\"/>\n",
    "   <figcaption>Illustration par @allison_horst</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Avertissement** :  \nCe document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction professionnelle r√©alis√©e par un humain. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.\n"
   ]
  }
 ]
}