# Classificateurs de cuisine 2

Dans cette deuxi√®me le√ßon de classification, vous explorerez d'autres fa√ßons de classifier des donn√©es num√©riques. Vous apprendrez √©galement les implications du choix d'un classificateur plut√¥t qu'un autre.

## [Quiz pr√©-cours](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/23/)

### Pr√©requis

Nous supposons que vous avez termin√© les le√ßons pr√©c√©dentes et que vous disposez d'un ensemble de donn√©es nettoy√© dans votre dossier `data` appel√© _cleaned_cuisines.csv_ √† la racine de ce dossier de 4 le√ßons.

### Pr√©paration

Nous avons charg√© votre fichier _notebook.ipynb_ avec l'ensemble de donn√©es nettoy√© et l'avons divis√© en dataframes X et y, pr√™ts pour le processus de construction du mod√®le.

## Une carte de classification

Auparavant, vous avez appris les diff√©rentes options qui s'offrent √† vous lors de la classification des donn√©es en utilisant la feuille de triche de Microsoft. Scikit-learn propose une feuille de triche similaire, mais plus d√©taill√©e, qui peut encore vous aider √† affiner vos estimateurs (un autre terme pour classificateurs) :

![Carte ML de Scikit-learn](../../../../translated_images/map.e963a6a51349425ab107b38f6c7307eb4c0d0c7ccdd2e81a5e1919292bab9ac7.fr.png)
> Conseil : [visitez cette carte en ligne](https://scikit-learn.org/stable/tutorial/machine_learning_map/) et cliquez le long du chemin pour lire la documentation.

### Le plan

Cette carte est tr√®s utile une fois que vous avez une bonne compr√©hension de vos donn√©es, car vous pouvez 'marcher' le long de ses chemins vers une d√©cision :

- Nous avons >50 √©chantillons
- Nous voulons pr√©dire une cat√©gorie
- Nous avons des donn√©es √©tiquet√©es
- Nous avons moins de 100K √©chantillons
- ‚ú® Nous pouvons choisir un SVC lin√©aire
- Si cela ne fonctionne pas, puisque nous avons des donn√©es num√©riques
    - Nous pouvons essayer un ‚ú® classificateur KNeighbors 
      - Si cela ne fonctionne pas, essayez un ‚ú® SVC et des ‚ú® classificateurs d'ensemble

C'est un chemin tr√®s utile √† suivre.

## Exercice - diviser les donn√©es

En suivant ce chemin, nous devrions commencer par importer certaines biblioth√®ques √† utiliser.

1. Importez les biblioth√®ques n√©cessaires :

    ```python
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    import numpy as np
    ```

1. Divisez vos donn√©es d'entra√Ænement et de test :

    ```python
    X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)
    ```

## Classificateur SVC lin√©aire

Le clustering par Support-Vector (SVC) est un membre de la famille des techniques ML des machines √† vecteurs de support (apprenez-en plus sur celles-ci ci-dessous). Dans cette m√©thode, vous pouvez choisir un 'noyau' pour d√©cider comment regrouper les √©tiquettes. Le param√®tre 'C' fait r√©f√©rence √† la 'r√©gularisation' qui r√©gule l'influence des param√®tres. Le noyau peut √™tre l'un des [plusieurs](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC) ; ici, nous le d√©finissons sur 'lin√©aire' pour nous assurer que nous tirons parti du SVC lin√©aire. La probabilit√© par d√©faut est 'fausse' ; ici, nous la d√©finissons sur 'vrai' pour recueillir des estimations de probabilit√©. Nous d√©finissons l'√©tat al√©atoire sur '0' pour m√©langer les donn√©es afin d'obtenir des probabilit√©s.

### Exercice - appliquer un SVC lin√©aire

Commencez par cr√©er un tableau de classificateurs. Vous ajouterez progressivement √† ce tableau au fur et √† mesure de nos tests. 

1. Commencez avec un SVC lin√©aire :

    ```python
    C = 10
    # Create different classifiers.
    classifiers = {
        'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0)
    }
    ```

2. Entra√Ænez votre mod√®le en utilisant le SVC lin√©aire et imprimez un rapport :

    ```python
    n_classifiers = len(classifiers)
    
    for index, (name, classifier) in enumerate(classifiers.items()):
        classifier.fit(X_train, np.ravel(y_train))
    
        y_pred = classifier.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print("Accuracy (train) for %s: %0.1f%% " % (name, accuracy * 100))
        print(classification_report(y_test,y_pred))
    ```

    Le r√©sultat est plut√¥t bon :

    ```output
    Accuracy (train) for Linear SVC: 78.6% 
                  precision    recall  f1-score   support
    
         chinese       0.71      0.67      0.69       242
          indian       0.88      0.86      0.87       234
        japanese       0.79      0.74      0.76       254
          korean       0.85      0.81      0.83       242
            thai       0.71      0.86      0.78       227
    
        accuracy                           0.79      1199
       macro avg       0.79      0.79      0.79      1199
    weighted avg       0.79      0.79      0.79      1199
    ```

## Classificateur K-Neighbors

K-Neighbors fait partie de la famille des m√©thodes ML "voisins", qui peuvent √™tre utilis√©es pour l'apprentissage supervis√© et non supervis√©. Dans cette m√©thode, un nombre pr√©d√©fini de points est cr√©√© et des donn√©es sont rassembl√©es autour de ces points de mani√®re √† ce que des √©tiquettes g√©n√©ralis√©es puissent √™tre pr√©dites pour les donn√©es.

### Exercice - appliquer le classificateur K-Neighbors

Le classificateur pr√©c√©dent √©tait bon et a bien fonctionn√© avec les donn√©es, mais peut-√™tre que nous pouvons obtenir une meilleure pr√©cision. Essayez un classificateur K-Neighbors.

1. Ajoutez une ligne √† votre tableau de classificateurs (ajoutez une virgule apr√®s l'√©l√©ment SVC lin√©aire) :

    ```python
    'KNN classifier': KNeighborsClassifier(C),
    ```

    Le r√©sultat est un peu moins bon :

    ```output
    Accuracy (train) for KNN classifier: 73.8% 
                  precision    recall  f1-score   support
    
         chinese       0.64      0.67      0.66       242
          indian       0.86      0.78      0.82       234
        japanese       0.66      0.83      0.74       254
          korean       0.94      0.58      0.72       242
            thai       0.71      0.82      0.76       227
    
        accuracy                           0.74      1199
       macro avg       0.76      0.74      0.74      1199
    weighted avg       0.76      0.74      0.74      1199
    ```

    ‚úÖ Apprenez-en plus sur [K-Neighbors](https://scikit-learn.org/stable/modules/neighbors.html#neighbors)

## Classificateur √† vecteurs de support

Les classificateurs √† vecteurs de support font partie de la famille des [machines √† vecteurs de support](https://wikipedia.org/wiki/Support-vector_machine) des m√©thodes ML utilis√©es pour les t√¢ches de classification et de r√©gression. Les SVM "cartographient les exemples d'entra√Ænement en points dans l'espace" pour maximiser la distance entre deux cat√©gories. Les donn√©es suivantes sont cartographi√©es dans cet espace afin que leur cat√©gorie puisse √™tre pr√©dite.

### Exercice - appliquer un classificateur √† vecteurs de support

Essayons d'obtenir une pr√©cision un peu meilleure avec un classificateur √† vecteurs de support.

1. Ajoutez une virgule apr√®s l'√©l√©ment K-Neighbors, puis ajoutez cette ligne :

    ```python
    'SVC': SVC(),
    ```

    Le r√©sultat est assez bon !

    ```output
    Accuracy (train) for SVC: 83.2% 
                  precision    recall  f1-score   support
    
         chinese       0.79      0.74      0.76       242
          indian       0.88      0.90      0.89       234
        japanese       0.87      0.81      0.84       254
          korean       0.91      0.82      0.86       242
            thai       0.74      0.90      0.81       227
    
        accuracy                           0.83      1199
       macro avg       0.84      0.83      0.83      1199
    weighted avg       0.84      0.83      0.83      1199
    ```

    ‚úÖ Apprenez-en plus sur [Support-Vectors](https://scikit-learn.org/stable/modules/svm.html#svm)

## Classificateurs d'ensemble

Suivons le chemin jusqu'√† la fin, m√™me si le test pr√©c√©dent √©tait assez bon. Essayons quelques 'classificateurs d'ensemble', en particulier Random Forest et AdaBoost :

```python
  'RFST': RandomForestClassifier(n_estimators=100),
  'ADA': AdaBoostClassifier(n_estimators=100)
```

Le r√©sultat est tr√®s bon, surtout pour Random Forest :

```output
Accuracy (train) for RFST: 84.5% 
              precision    recall  f1-score   support

     chinese       0.80      0.77      0.78       242
      indian       0.89      0.92      0.90       234
    japanese       0.86      0.84      0.85       254
      korean       0.88      0.83      0.85       242
        thai       0.80      0.87      0.83       227

    accuracy                           0.84      1199
   macro avg       0.85      0.85      0.84      1199
weighted avg       0.85      0.84      0.84      1199

Accuracy (train) for ADA: 72.4% 
              precision    recall  f1-score   support

     chinese       0.64      0.49      0.56       242
      indian       0.91      0.83      0.87       234
    japanese       0.68      0.69      0.69       254
      korean       0.73      0.79      0.76       242
        thai       0.67      0.83      0.74       227

    accuracy                           0.72      1199
   macro avg       0.73      0.73      0.72      1199
weighted avg       0.73      0.72      0.72      1199
```

‚úÖ Apprenez-en plus sur [classificateurs d'ensemble](https://scikit-learn.org/stable/modules/ensemble.html)

Cette m√©thode d'apprentissage automatique "combine les pr√©dictions de plusieurs estimateurs de base" pour am√©liorer la qualit√© du mod√®le. Dans notre exemple, nous avons utilis√© des arbres al√©atoires et AdaBoost.

- [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest), une m√©thode de moyennage, construit une 'for√™t' d'arbres de d√©cision infus√©s de hasard pour √©viter le surajustement. Le param√®tre n_estimators est d√©fini sur le nombre d'arbres.

- [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) ajuste un classificateur √† un ensemble de donn√©es, puis ajuste des copies de ce classificateur au m√™me ensemble de donn√©es. Il se concentre sur les poids des √©l√©ments mal class√©s et ajuste l'ajustement pour le prochain classificateur afin de corriger.

---

## üöÄD√©fi

Chacune de ces techniques a un grand nombre de param√®tres que vous pouvez ajuster. Renseignez-vous sur les param√®tres par d√©faut de chacun et r√©fl√©chissez √† ce que l'ajustement de ces param√®tres signifierait pour la qualit√© du mod√®le.

## [Quiz post-cours](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/24/)

## R√©vision & Auto-√©tude

Il y a beaucoup de jargon dans ces le√ßons, alors prenez une minute pour revoir [cette liste](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) de terminologie utile !

## Devoir 

[Jeu de param√®tres](assignment.md)

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide de services de traduction automatique bas√©s sur l'IA. Bien que nous nous effor√ßons d'assurer l'exactitude, veuillez noter que les traductions automatiques peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue native doit √™tre consid√©r√© comme la source autoris√©e. Pour des informations critiques, une traduction humaine professionnelle est recommand√©e. Nous ne sommes pas responsables des malentendus ou des interpr√©tations erron√©es d√©coulant de l'utilisation de cette traduction.