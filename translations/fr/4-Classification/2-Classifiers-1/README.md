<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "9579f42e3ff5114c58379cc9e186a828",
  "translation_date": "2025-09-03T23:49:36+00:00",
  "source_file": "4-Classification/2-Classifiers-1/README.md",
  "language_code": "fr"
}
-->
# Classificateurs de cuisine 1

Dans cette le√ßon, vous utiliserez le jeu de donn√©es que vous avez sauvegard√© lors de la derni√®re le√ßon, rempli de donn√©es √©quilibr√©es et propres sur les cuisines.

Vous utiliserez ce jeu de donn√©es avec une vari√©t√© de classificateurs pour _pr√©dire une cuisine nationale donn√©e en fonction d'un groupe d'ingr√©dients_. En le faisant, vous en apprendrez davantage sur certaines des fa√ßons dont les algorithmes peuvent √™tre utilis√©s pour des t√¢ches de classification.

## [Quiz avant la le√ßon](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/21/)
# Pr√©paration

En supposant que vous avez termin√© [Le√ßon 1](../1-Introduction/README.md), assurez-vous qu'un fichier _cleaned_cuisines.csv_ existe dans le dossier racine `/data` pour ces quatre le√ßons.

## Exercice - pr√©dire une cuisine nationale

1. En travaillant dans le dossier _notebook.ipynb_ de cette le√ßon, importez ce fichier ainsi que la biblioth√®que Pandas :

    ```python
    import pandas as pd
    cuisines_df = pd.read_csv("../data/cleaned_cuisines.csv")
    cuisines_df.head()
    ```

    Les donn√©es ressemblent √† ceci :

|     | Unnamed: 0 | cuisine | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood | yam | yeast | yogurt | zucchini |
| --- | ---------- | ------- | ------ | -------- | ----- | ---------- | ----- | ------------ | ------- | -------- | --- | ------- | ----------- | ---------- | ----------------------- | ---- | ---- | --- | ----- | ------ | -------- |
| 0   | 0          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 1   | 1          | indian  | 1      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 2   | 2          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 3   | 3          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 4   | 4          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 1      | 0        |
  

1. Maintenant, importez plusieurs autres biblioth√®ques :

    ```python
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    from sklearn.svm import SVC
    import numpy as np
    ```

1. Divisez les coordonn√©es X et y en deux dataframes pour l'entra√Ænement. `cuisine` peut √™tre le dataframe des √©tiquettes :

    ```python
    cuisines_label_df = cuisines_df['cuisine']
    cuisines_label_df.head()
    ```

    Cela ressemblera √† ceci :

    ```output
    0    indian
    1    indian
    2    indian
    3    indian
    4    indian
    Name: cuisine, dtype: object
    ```

1. Supprimez la colonne `Unnamed: 0` et la colonne `cuisine` en appelant `drop()`. Sauvegardez le reste des donn√©es comme caract√©ristiques entra√Ænables :

    ```python
    cuisines_feature_df = cuisines_df.drop(['Unnamed: 0', 'cuisine'], axis=1)
    cuisines_feature_df.head()
    ```

    Vos caract√©ristiques ressemblent √† ceci :

|      | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | artemisia | artichoke |  ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood |  yam | yeast | yogurt | zucchini |
| ---: | -----: | -------: | ----: | ---------: | ----: | -----------: | ------: | -------: | --------: | --------: | ---: | ------: | ----------: | ---------: | ----------------------: | ---: | ---: | ---: | ----: | -----: | -------: |
|    0 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    1 |      1 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    2 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    3 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    4 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      1 |        0 | 0 |

Vous √™tes maintenant pr√™t √† entra√Æner votre mod√®le !

## Choisir votre classificateur

Maintenant que vos donn√©es sont propres et pr√™tes pour l'entra√Ænement, vous devez d√©cider quel algorithme utiliser pour la t√¢che. 

Scikit-learn regroupe la classification sous l'apprentissage supervis√©, et dans cette cat√©gorie, vous trouverez de nombreuses fa√ßons de classifier. [La vari√©t√©](https://scikit-learn.org/stable/supervised_learning.html) peut sembler d√©routante au premier abord. Les m√©thodes suivantes incluent toutes des techniques de classification :

- Mod√®les lin√©aires
- Machines √† vecteurs de support
- Descente de gradient stochastique
- Plus proches voisins
- Processus gaussiens
- Arbres de d√©cision
- M√©thodes d'ensemble (classificateur par vote)
- Algorithmes multiclasses et multi-sorties (classification multiclasses et multi-√©tiquettes, classification multiclasses-multi-sorties)

> Vous pouvez √©galement utiliser [les r√©seaux neuronaux pour classifier des donn√©es](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#classification), mais cela d√©passe le cadre de cette le√ßon.

### Quel classificateur choisir ?

Alors, quel classificateur devriez-vous choisir ? Souvent, tester plusieurs et chercher un bon r√©sultat est une fa√ßon de proc√©der. Scikit-learn propose une [comparaison c√¥te √† c√¥te](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) sur un jeu de donn√©es cr√©√©, comparant KNeighbors, SVC de deux fa√ßons, GaussianProcessClassifier, DecisionTreeClassifier, RandomForestClassifier, MLPClassifier, AdaBoostClassifier, GaussianNB et QuadraticDiscriminationAnalysis, montrant les r√©sultats visualis√©s : 

![comparaison des classificateurs](../../../../translated_images/comparison.edfab56193a85e7fdecbeaa1b1f8c99e94adbf7178bed0de902090cf93d6734f.fr.png)
> Graphiques g√©n√©r√©s √† partir de la documentation de Scikit-learn

> AutoML r√©sout ce probl√®me de mani√®re √©l√©gante en ex√©cutant ces comparaisons dans le cloud, vous permettant de choisir le meilleur algorithme pour vos donn√©es. Essayez-le [ici](https://docs.microsoft.com/learn/modules/automate-model-selection-with-azure-automl/?WT.mc_id=academic-77952-leestott)

### Une meilleure approche

Une meilleure fa√ßon que de deviner au hasard est de suivre les id√©es de cette [fiche pratique ML t√©l√©chargeable](https://docs.microsoft.com/azure/machine-learning/algorithm-cheat-sheet?WT.mc_id=academic-77952-leestott). Ici, nous d√©couvrons que, pour notre probl√®me multiclasses, nous avons quelques choix :

![fiche pratique pour les probl√®mes multiclasses](../../../../translated_images/cheatsheet.07a475ea444d22234cb8907a3826df5bdd1953efec94bd18e4496f36ff60624a.fr.png)
> Une section de la fiche pratique des algorithmes de Microsoft, d√©taillant les options de classification multiclasses

‚úÖ T√©l√©chargez cette fiche pratique, imprimez-la et accrochez-la sur votre mur !

### Raisonnement

Voyons si nous pouvons raisonner sur diff√©rentes approches donn√©es les contraintes que nous avons :

- **Les r√©seaux neuronaux sont trop lourds**. √âtant donn√© notre jeu de donn√©es propre mais minimal, et le fait que nous ex√©cutons l'entra√Ænement localement via des notebooks, les r√©seaux neuronaux sont trop lourds pour cette t√¢che.
- **Pas de classificateur √† deux classes**. Nous n'utilisons pas de classificateur √† deux classes, ce qui exclut le one-vs-all. 
- **Un arbre de d√©cision ou une r√©gression logistique pourrait fonctionner**. Un arbre de d√©cision pourrait fonctionner, ou une r√©gression logistique pour des donn√©es multiclasses. 
- **Les arbres de d√©cision boost√©s multiclasses r√©solvent un probl√®me diff√©rent**. L'arbre de d√©cision boost√© multiclasses est le plus adapt√© aux t√¢ches non param√©triques, par exemple les t√¢ches con√ßues pour √©tablir des classements, donc il n'est pas utile pour nous.

### Utiliser Scikit-learn 

Nous utiliserons Scikit-learn pour analyser nos donn√©es. Cependant, il existe de nombreuses fa√ßons d'utiliser la r√©gression logistique dans Scikit-learn. Consultez les [param√®tres √† passer](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regressio#sklearn.linear_model.LogisticRegression).  

Essentiellement, il y a deux param√®tres importants - `multi_class` et `solver` - que nous devons sp√©cifier lorsque nous demandons √† Scikit-learn d'effectuer une r√©gression logistique. La valeur de `multi_class` applique un certain comportement. La valeur du solver correspond √† l'algorithme √† utiliser. Tous les solveurs ne peuvent pas √™tre associ√©s √† toutes les valeurs de `multi_class`.

Selon la documentation, dans le cas multiclasses, l'algorithme d'entra√Ænement :

- **Utilise le sch√©ma one-vs-rest (OvR)**, si l'option `multi_class` est d√©finie sur `ovr`
- **Utilise la perte d'entropie crois√©e**, si l'option `multi_class` est d√©finie sur `multinomial`. (Actuellement, l'option `multinomial` est prise en charge uniquement par les solveurs ‚Äòlbfgs‚Äô, ‚Äòsag‚Äô, ‚Äòsaga‚Äô et ‚Äònewton-cg‚Äô.)"

> üéì Le 'sch√©ma' ici peut √™tre 'ovr' (one-vs-rest) ou 'multinomial'. √âtant donn√© que la r√©gression logistique est vraiment con√ßue pour prendre en charge la classification binaire, ces sch√©mas lui permettent de mieux g√©rer les t√¢ches de classification multiclasses. [source](https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/)

> üéì Le 'solver' est d√©fini comme "l'algorithme √† utiliser dans le probl√®me d'optimisation". [source](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regressio#sklearn.linear_model.LogisticRegression).

Scikit-learn propose ce tableau pour expliquer comment les solveurs g√®rent les diff√©rents d√©fis pr√©sent√©s par les diff√©rentes structures de donn√©es :

![solveurs](../../../../translated_images/solvers.5fc648618529e627dfac29b917b3ccabda4b45ee8ed41b0acb1ce1441e8d1ef1.fr.png)

## Exercice - diviser les donn√©es

Nous pouvons nous concentrer sur la r√©gression logistique pour notre premier essai d'entra√Ænement, puisque vous avez r√©cemment appris √† ce sujet dans une le√ßon pr√©c√©dente.
Divisez vos donn√©es en groupes d'entra√Ænement et de test en appelant `train_test_split()` :

```python
X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)
```

## Exercice - appliquer la r√©gression logistique

√âtant donn√© que vous utilisez le cas multiclasses, vous devez choisir quel _sch√©ma_ utiliser et quel _solver_ d√©finir. Utilisez LogisticRegression avec un param√®tre multiclasses et le solveur **liblinear** pour entra√Æner.

1. Cr√©ez une r√©gression logistique avec multi_class d√©fini sur `ovr` et le solveur d√©fini sur `liblinear` :

    ```python
    lr = LogisticRegression(multi_class='ovr',solver='liblinear')
    model = lr.fit(X_train, np.ravel(y_train))
    
    accuracy = model.score(X_test, y_test)
    print ("Accuracy is {}".format(accuracy))
    ```

    ‚úÖ Essayez un solveur diff√©rent comme `lbfgs`, qui est souvent d√©fini par d√©faut
> Remarque, utilisez la fonction Pandas [`ravel`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.ravel.html) pour aplatir vos donn√©es si n√©cessaire.
La pr√©cision est bonne √† plus de **80 %** !

1. Vous pouvez voir ce mod√®le en action en testant une ligne de donn√©es (#50) :

    ```python
    print(f'ingredients: {X_test.iloc[50][X_test.iloc[50]!=0].keys()}')
    print(f'cuisine: {y_test.iloc[50]}')
    ```

    Le r√©sultat est affich√© :

   ```output
   ingredients: Index(['cilantro', 'onion', 'pea', 'potato', 'tomato', 'vegetable_oil'], dtype='object')
   cuisine: indian
   ```

   ‚úÖ Essayez un autre num√©ro de ligne et v√©rifiez les r√©sultats.

1. En approfondissant, vous pouvez v√©rifier la pr√©cision de cette pr√©diction :

    ```python
    test= X_test.iloc[50].values.reshape(-1, 1).T
    proba = model.predict_proba(test)
    classes = model.classes_
    resultdf = pd.DataFrame(data=proba, columns=classes)
    
    topPrediction = resultdf.T.sort_values(by=[0], ascending = [False])
    topPrediction.head()
    ```

    Le r√©sultat est affich√© - la cuisine indienne est sa meilleure supposition, avec une bonne probabilit√© :

    |          |        0 |
    | -------: | -------: |
    |   indian | 0.715851 |
    |  chinese | 0.229475 |
    | japanese | 0.029763 |
    |   korean | 0.017277 |
    |     thai | 0.007634 |

    ‚úÖ Pouvez-vous expliquer pourquoi le mod√®le est assez s√ªr qu'il s'agit d'une cuisine indienne ?

1. Obtenez plus de d√©tails en affichant un rapport de classification, comme vous l'avez fait dans les le√ßons sur la r√©gression :

    ```python
    y_pred = model.predict(X_test)
    print(classification_report(y_test,y_pred))
    ```

    |              | pr√©cision | rappel | f1-score | support |
    | ------------ | --------- | ------ | -------- | ------- |
    | chinese      | 0.73      | 0.71   | 0.72     | 229     |
    | indian       | 0.91      | 0.93   | 0.92     | 254     |
    | japanese     | 0.70      | 0.75   | 0.72     | 220     |
    | korean       | 0.86      | 0.76   | 0.81     | 242     |
    | thai         | 0.79      | 0.85   | 0.82     | 254     |
    | pr√©cision    | 0.80      | 1199   |          |         |
    | moyenne macro| 0.80      | 0.80   | 0.80     | 1199    |
    | moyenne pond√©r√©e | 0.80  | 0.80   | 0.80     | 1199    |

## üöÄD√©fi

Dans cette le√ßon, vous avez utilis√© vos donn√©es nettoy√©es pour construire un mod√®le d'apprentissage automatique capable de pr√©dire une cuisine nationale en fonction d'une s√©rie d'ingr√©dients. Prenez le temps de parcourir les nombreuses options que Scikit-learn propose pour classifier les donn√©es. Approfondissez le concept de 'solver' pour comprendre ce qui se passe en coulisses.

## [Quiz apr√®s la le√ßon](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/22/)

## R√©vision & √âtude personnelle

Approfondissez un peu plus les math√©matiques derri√®re la r√©gression logistique dans [cette le√ßon](https://people.eecs.berkeley.edu/~russell/classes/cs194/f11/lectures/CS194%20Fall%202011%20Lecture%2006.pdf)
## Devoir 

[√âtudiez les solvers](assignment.md)

---

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de faire appel √† une traduction humaine professionnelle. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.