<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "76438ce4e5d48982d48f1b55c981caac",
  "translation_date": "2025-09-04T00:01:04+00:00",
  "source_file": "4-Classification/1-Introduction/README.md",
  "language_code": "fr"
}
-->
# Introduction √† la classification

Dans ces quatre le√ßons, vous allez explorer un aspect fondamental de l'apprentissage automatique classique : _la classification_. Nous allons utiliser divers algorithmes de classification avec un ensemble de donn√©es sur les cuisines brillantes d'Asie et d'Inde. Pr√©parez-vous √† avoir faim !

![juste une pinc√©e !](../../../../translated_images/pinch.1b035ec9ba7e0d408313b551b60c721c9c290b2dd2094115bc87e6ddacd114c9.fr.png)

> C√©l√©brez les cuisines pan-asiatiques dans ces le√ßons ! Image par [Jen Looper](https://twitter.com/jenlooper)

La classification est une forme d'[apprentissage supervis√©](https://wikipedia.org/wiki/Supervised_learning) qui partage de nombreux points communs avec les techniques de r√©gression. Si l'apprentissage automatique consiste √† pr√©dire des valeurs ou des noms en utilisant des ensembles de donn√©es, alors la classification se divise g√©n√©ralement en deux groupes : _classification binaire_ et _classification multicat√©gorie_.

[![Introduction √† la classification](https://img.youtube.com/vi/eg8DJYwdMyg/0.jpg)](https://youtu.be/eg8DJYwdMyg "Introduction √† la classification")

> üé• Cliquez sur l'image ci-dessus pour une vid√©o : John Guttag du MIT introduit la classification

Rappel :

- **La r√©gression lin√©aire** vous a aid√© √† pr√©dire les relations entre les variables et √† faire des pr√©dictions pr√©cises sur la position d'un nouveau point de donn√©es par rapport √† cette ligne. Par exemple, vous pourriez pr√©dire _quel serait le prix d'une citrouille en septembre par rapport √† d√©cembre_.
- **La r√©gression logistique** vous a permis de d√©couvrir des "cat√©gories binaires" : √† ce prix, _cette citrouille est-elle orange ou non-orange_ ?

La classification utilise divers algorithmes pour d√©terminer d'autres fa√ßons d'attribuer une √©tiquette ou une classe √† un point de donn√©es. Travaillons avec ces donn√©es sur les cuisines pour voir si, en observant un groupe d'ingr√©dients, nous pouvons d√©terminer leur origine culinaire.

## [Quiz avant la le√ßon](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/19/)

> ### [Cette le√ßon est disponible en R !](../../../../4-Classification/1-Introduction/solution/R/lesson_10.html)

### Introduction

La classification est l'une des activit√©s fondamentales du chercheur en apprentissage automatique et du data scientist. De la classification basique d'une valeur binaire ("cet email est-il un spam ou non ?") √† la classification et segmentation complexe d'images utilisant la vision par ordinateur, il est toujours utile de pouvoir trier les donn√©es en classes et leur poser des questions.

Pour exprimer le processus de mani√®re plus scientifique, votre m√©thode de classification cr√©e un mod√®le pr√©dictif qui vous permet de cartographier la relation entre les variables d'entr√©e et les variables de sortie.

![classification binaire vs multicat√©gorie](../../../../translated_images/binary-multiclass.b56d0c86c81105a697dddd82242c1d11e4d78b7afefea07a44627a0f1111c1a9.fr.png)

> Probl√®mes binaires vs multicat√©gorie pour les algorithmes de classification. Infographie par [Jen Looper](https://twitter.com/jenlooper)

Avant de commencer le processus de nettoyage de nos donn√©es, de leur visualisation et de leur pr√©paration pour nos t√¢ches d'apprentissage automatique, apprenons un peu plus sur les diff√©rentes fa√ßons dont l'apprentissage automatique peut √™tre utilis√© pour classer des donn√©es.

D√©riv√©e des [statistiques](https://wikipedia.org/wiki/Statistical_classification), la classification utilisant l'apprentissage automatique classique utilise des caract√©ristiques telles que `smoker`, `weight` et `age` pour d√©terminer _la probabilit√© de d√©velopper une maladie X_. En tant que technique d'apprentissage supervis√© similaire aux exercices de r√©gression que vous avez effectu√©s pr√©c√©demment, vos donn√©es sont √©tiquet√©es et les algorithmes d'apprentissage automatique utilisent ces √©tiquettes pour classer et pr√©dire les classes (ou "caract√©ristiques") d'un ensemble de donn√©es et les attribuer √† un groupe ou un r√©sultat.

‚úÖ Prenez un moment pour imaginer un ensemble de donn√©es sur les cuisines. Qu'est-ce qu'un mod√®le multicat√©gorie pourrait r√©pondre ? Qu'est-ce qu'un mod√®le binaire pourrait r√©pondre ? Et si vous vouliez d√©terminer si une cuisine donn√©e √©tait susceptible d'utiliser du fenugrec ? Et si vous vouliez voir si, avec un sac de courses contenant de l'anis √©toil√©, des artichauts, du chou-fleur et du raifort, vous pourriez cr√©er un plat typique indien ?

[![Paniers myst√®res fous](https://img.youtube.com/vi/GuTeDbaNoEU/0.jpg)](https://youtu.be/GuTeDbaNoEU "Paniers myst√®res fous")

> üé• Cliquez sur l'image ci-dessus pour une vid√©o. Tout le concept de l'√©mission 'Chopped' repose sur le 'panier myst√®re' o√π les chefs doivent pr√©parer un plat √† partir d'un choix al√©atoire d'ingr√©dients. Un mod√®le d'apprentissage automatique aurait s√ªrement aid√© !

## Bonjour 'classificateur'

La question que nous voulons poser √† cet ensemble de donn√©es sur les cuisines est en fait une **question multicat√©gorie**, car nous avons plusieurs cuisines nationales potentielles avec lesquelles travailler. √âtant donn√© un lot d'ingr√©dients, √† laquelle de ces nombreuses classes les donn√©es correspondent-elles ?

Scikit-learn propose plusieurs algorithmes diff√©rents pour classer les donn√©es, selon le type de probl√®me que vous souhaitez r√©soudre. Dans les deux prochaines le√ßons, vous apprendrez √† utiliser plusieurs de ces algorithmes.

## Exercice - nettoyer et √©quilibrer vos donn√©es

La premi√®re t√¢che √† accomplir, avant de commencer ce projet, est de nettoyer et **√©quilibrer** vos donn√©es pour obtenir de meilleurs r√©sultats. Commencez avec le fichier _notebook.ipynb_ vierge dans le dossier racine.

La premi√®re chose √† installer est [imblearn](https://imbalanced-learn.org/stable/). Il s'agit d'un package Scikit-learn qui vous permettra d'√©quilibrer les donn√©es plus efficacement (vous en apprendrez davantage sur cette t√¢che dans un instant).

1. Pour installer `imblearn`, ex√©cutez `pip install`, comme suit :

    ```python
    pip install imblearn
    ```

1. Importez les packages n√©cessaires pour importer vos donn√©es et les visualiser, et importez √©galement `SMOTE` depuis `imblearn`.

    ```python
    import pandas as pd
    import matplotlib.pyplot as plt
    import matplotlib as mpl
    import numpy as np
    from imblearn.over_sampling import SMOTE
    ```

    Vous √™tes maintenant pr√™t √† importer les donn√©es.

1. La t√¢che suivante consiste √† importer les donn√©es :

    ```python
    df  = pd.read_csv('../data/cuisines.csv')
    ```

   Utiliser `read_csv()` permettra de lire le contenu du fichier csv _cusines.csv_ et de le placer dans la variable `df`.

1. V√©rifiez la forme des donn√©es :

    ```python
    df.head()
    ```

   Les cinq premi√®res lignes ressemblent √† ceci :

    ```output
    |     | Unnamed: 0 | cuisine | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood | yam | yeast | yogurt | zucchini |
    | --- | ---------- | ------- | ------ | -------- | ----- | ---------- | ----- | ------------ | ------- | -------- | --- | ------- | ----------- | ---------- | ----------------------- | ---- | ---- | --- | ----- | ------ | -------- |
    | 0   | 65         | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
    | 1   | 66         | indian  | 1      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
    | 2   | 67         | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
    | 3   | 68         | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
    | 4   | 69         | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 1      | 0        |
    ```

1. Obtenez des informations sur ces donn√©es en appelant `info()` :

    ```python
    df.info()
    ```

    Votre sortie ressemble √† :

    ```output
    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 2448 entries, 0 to 2447
    Columns: 385 entries, Unnamed: 0 to zucchini
    dtypes: int64(384), object(1)
    memory usage: 7.2+ MB
    ```

## Exercice - d√©couvrir les cuisines

Maintenant, le travail commence √† devenir plus int√©ressant. D√©couvrons la distribution des donn√©es par cuisine.

1. Tracez les donn√©es sous forme de barres en appelant `barh()` :

    ```python
    df.cuisine.value_counts().plot.barh()
    ```

    ![distribution des donn√©es sur les cuisines](../../../../translated_images/cuisine-dist.d0cc2d551abe5c25f83d73a5f560927e4a061e9a4560bac1e97d35682ef3ca6d.fr.png)

    Il existe un nombre fini de cuisines, mais la distribution des donn√©es est in√©gale. Vous pouvez corriger cela ! Avant de le faire, explorez un peu plus.

1. D√©couvrez combien de donn√©es sont disponibles par cuisine et imprimez-les :

    ```python
    thai_df = df[(df.cuisine == "thai")]
    japanese_df = df[(df.cuisine == "japanese")]
    chinese_df = df[(df.cuisine == "chinese")]
    indian_df = df[(df.cuisine == "indian")]
    korean_df = df[(df.cuisine == "korean")]
    
    print(f'thai df: {thai_df.shape}')
    print(f'japanese df: {japanese_df.shape}')
    print(f'chinese df: {chinese_df.shape}')
    print(f'indian df: {indian_df.shape}')
    print(f'korean df: {korean_df.shape}')
    ```

    La sortie ressemble √† ceci :

    ```output
    thai df: (289, 385)
    japanese df: (320, 385)
    chinese df: (442, 385)
    indian df: (598, 385)
    korean df: (799, 385)
    ```

## D√©couvrir les ingr√©dients

Vous pouvez maintenant approfondir les donn√©es et d√©couvrir quels sont les ingr√©dients typiques par cuisine. Vous devriez nettoyer les donn√©es r√©currentes qui cr√©ent de la confusion entre les cuisines, alors apprenons-en davantage sur ce probl√®me.

1. Cr√©ez une fonction `create_ingredient()` en Python pour cr√©er un dataframe d'ingr√©dients. Cette fonction commencera par supprimer une colonne inutile et triera les ingr√©dients par leur nombre :

    ```python
    def create_ingredient_df(df):
        ingredient_df = df.T.drop(['cuisine','Unnamed: 0']).sum(axis=1).to_frame('value')
        ingredient_df = ingredient_df[(ingredient_df.T != 0).any()]
        ingredient_df = ingredient_df.sort_values(by='value', ascending=False,
        inplace=False)
        return ingredient_df
    ```

   Vous pouvez maintenant utiliser cette fonction pour avoir une id√©e des dix ingr√©dients les plus populaires par cuisine.

1. Appelez `create_ingredient()` et tracez les donn√©es en appelant `barh()` :

    ```python
    thai_ingredient_df = create_ingredient_df(thai_df)
    thai_ingredient_df.head(10).plot.barh()
    ```

    ![tha√Ø](../../../../translated_images/thai.0269dbab2e78bd38a132067759fe980008bdb80b6d778e5313448dbe12bed846.fr.png)

1. Faites de m√™me pour les donn√©es japonaises :

    ```python
    japanese_ingredient_df = create_ingredient_df(japanese_df)
    japanese_ingredient_df.head(10).plot.barh()
    ```

    ![japonais](../../../../translated_images/japanese.30260486f2a05c463c8faa62ebe7b38f0961ed293bd9a6db8eef5d3f0cf17155.fr.png)

1. Maintenant pour les ingr√©dients chinois :

    ```python
    chinese_ingredient_df = create_ingredient_df(chinese_df)
    chinese_ingredient_df.head(10).plot.barh()
    ```

    ![chinois](../../../../translated_images/chinese.e62cafa5309f111afd1b54490336daf4e927ce32bed837069a0b7ce481dfae8d.fr.png)

1. Tracez les ingr√©dients indiens :

    ```python
    indian_ingredient_df = create_ingredient_df(indian_df)
    indian_ingredient_df.head(10).plot.barh()
    ```

    ![indien](../../../../translated_images/indian.2c4292002af1a1f97a4a24fec6b1459ee8ff616c3822ae56bb62b9903e192af6.fr.png)

1. Enfin, tracez les ingr√©dients cor√©ens :

    ```python
    korean_ingredient_df = create_ingredient_df(korean_df)
    korean_ingredient_df.head(10).plot.barh()
    ```

    ![cor√©en](../../../../translated_images/korean.4a4f0274f3d9805a65e61f05597eeaad8620b03be23a2c0a705c023f65fad2c0.fr.png)

1. Maintenant, supprimez les ingr√©dients les plus courants qui cr√©ent de la confusion entre les cuisines distinctes, en appelant `drop()` :

   Tout le monde aime le riz, l'ail et le gingembre !

    ```python
    feature_df= df.drop(['cuisine','Unnamed: 0','rice','garlic','ginger'], axis=1)
    labels_df = df.cuisine #.unique()
    feature_df.head()
    ```

## √âquilibrer l'ensemble de donn√©es

Maintenant que vous avez nettoy√© les donn√©es, utilisez [SMOTE](https://imbalanced-learn.org/dev/references/generated/imblearn.over_sampling.SMOTE.html) - "Synthetic Minority Over-sampling Technique" - pour les √©quilibrer.

1. Appelez `fit_resample()`, cette strat√©gie g√©n√®re de nouveaux √©chantillons par interpolation.

    ```python
    oversample = SMOTE()
    transformed_feature_df, transformed_label_df = oversample.fit_resample(feature_df, labels_df)
    ```

    En √©quilibrant vos donn√©es, vous obtiendrez de meilleurs r√©sultats lors de leur classification. Pensez √† une classification binaire. Si la majorit√© de vos donn√©es appartient √† une classe, un mod√®le d'apprentissage automatique va pr√©dire cette classe plus fr√©quemment, simplement parce qu'il y a plus de donn√©es pour elle. L'√©quilibrage des donn√©es permet de corriger ce d√©s√©quilibre.

1. Vous pouvez maintenant v√©rifier le nombre d'√©tiquettes par ingr√©dient :

    ```python
    print(f'new label count: {transformed_label_df.value_counts()}')
    print(f'old label count: {df.cuisine.value_counts()}')
    ```

    Votre sortie ressemble √† ceci :

    ```output
    new label count: korean      799
    chinese     799
    indian      799
    japanese    799
    thai        799
    Name: cuisine, dtype: int64
    old label count: korean      799
    indian      598
    chinese     442
    japanese    320
    thai        289
    Name: cuisine, dtype: int64
    ```

    Les donn√©es sont propres, √©quilibr√©es et tr√®s app√©tissantes !

1. La derni√®re √©tape consiste √† sauvegarder vos donn√©es √©quilibr√©es, y compris les √©tiquettes et les caract√©ristiques, dans un nouveau dataframe qui peut √™tre export√© dans un fichier :

    ```python
    transformed_df = pd.concat([transformed_label_df,transformed_feature_df],axis=1, join='outer')
    ```

1. Vous pouvez jeter un dernier coup d'≈ìil aux donn√©es en utilisant `transformed_df.head()` et `transformed_df.info()`. Sauvegardez une copie de ces donn√©es pour les utiliser dans les le√ßons futures :

    ```python
    transformed_df.head()
    transformed_df.info()
    transformed_df.to_csv("../data/cleaned_cuisines.csv")
    ```

    Ce nouveau fichier CSV se trouve maintenant dans le dossier racine des donn√©es.

---

## üöÄD√©fi

Ce programme contient plusieurs ensembles de donn√©es int√©ressants. Explorez les dossiers `data` et voyez si certains contiennent des ensembles de donn√©es qui seraient appropri√©s pour une classification binaire ou multicat√©gorie. Quelles questions poseriez-vous √† cet ensemble de donn√©es ?

## [Quiz apr√®s la le√ßon](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/20/)

## R√©vision et auto-apprentissage

Explorez l'API de SMOTE. Pour quels cas d'utilisation est-elle la mieux adapt√©e ? Quels probl√®mes r√©sout-elle ?

## Devoir 

[Explorez les m√©thodes de classification](assignment.md)

---

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de faire appel √† une traduction humaine professionnelle. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.