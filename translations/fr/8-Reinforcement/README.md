<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "20ca019012b1725de956681d036d8b18",
  "translation_date": "2025-09-04T00:13:30+00:00",
  "source_file": "8-Reinforcement/README.md",
  "language_code": "fr"
}
-->
# Introduction √† l'apprentissage par renforcement

L'apprentissage par renforcement, ou RL, est consid√©r√© comme l'un des paradigmes fondamentaux de l'apprentissage automatique, aux c√¥t√©s de l'apprentissage supervis√© et non supervis√©. Le RL concerne les d√©cisions : prendre les bonnes d√©cisions ou, √† d√©faut, apprendre de celles-ci.

Imaginez que vous avez un environnement simul√©, comme le march√© boursier. Que se passe-t-il si vous imposez une r√©glementation donn√©e ? A-t-elle un effet positif ou n√©gatif ? Si quelque chose de n√©gatif se produit, vous devez tirer parti de ce _renforcement n√©gatif_, en apprendre et changer de cap. Si le r√©sultat est positif, vous devez vous appuyer sur ce _renforcement positif_.

![peter et le loup](../../../translated_images/peter.779730f9ba3a8a8d9290600dcf55f2e491c0640c785af7ac0d64f583c49b8864.fr.png)

> Peter et ses amis doivent √©chapper au loup affam√© ! Image par [Jen Looper](https://twitter.com/jenlooper)

## Sujet r√©gional : Pierre et le Loup (Russie)

[Pierre et le Loup](https://fr.wikipedia.org/wiki/Pierre_et_le_Loup) est un conte musical √©crit par le compositeur russe [Sergei Prokofiev](https://fr.wikipedia.org/wiki/Serge_Prokofiev). C'est l'histoire du jeune pionnier Pierre, qui sort courageusement de sa maison pour aller dans la clairi√®re de la for√™t et chasser le loup. Dans cette section, nous allons entra√Æner des algorithmes d'apprentissage automatique qui aideront Pierre √† :

- **Explorer** les environs et construire une carte de navigation optimale.
- **Apprendre** √† utiliser un skateboard et √† garder l'√©quilibre dessus, afin de se d√©placer plus rapidement.

[![Pierre et le Loup](https://img.youtube.com/vi/Fmi5zHg4QSM/0.jpg)](https://www.youtube.com/watch?v=Fmi5zHg4QSM)

> üé• Cliquez sur l'image ci-dessus pour √©couter Pierre et le Loup de Prokofiev

## Apprentissage par renforcement

Dans les sections pr√©c√©dentes, vous avez vu deux exemples de probl√®mes d'apprentissage automatique :

- **Supervis√©**, o√π nous avons des ensembles de donn√©es qui sugg√®rent des solutions possibles au probl√®me que nous voulons r√©soudre. [La classification](../4-Classification/README.md) et [la r√©gression](../2-Regression/README.md) sont des t√¢ches d'apprentissage supervis√©.
- **Non supervis√©**, o√π nous n'avons pas de donn√©es d'entra√Ænement √©tiquet√©es. L'exemple principal d'apprentissage non supervis√© est [le clustering](../5-Clustering/README.md).

Dans cette section, nous allons vous pr√©senter un nouveau type de probl√®me d'apprentissage qui ne n√©cessite pas de donn√©es d'entra√Ænement √©tiquet√©es. Il existe plusieurs types de tels probl√®mes :

- **[Apprentissage semi-supervis√©](https://fr.wikipedia.org/wiki/Apprentissage_semi-supervis%C3%A9)**, o√π nous avons beaucoup de donn√©es non √©tiquet√©es qui peuvent √™tre utilis√©es pour pr√©-entra√Æner le mod√®le.
- **[Apprentissage par renforcement](https://fr.wikipedia.org/wiki/Apprentissage_par_renforcement)**, dans lequel un agent apprend √† se comporter en r√©alisant des exp√©riences dans un environnement simul√©.

### Exemple - jeu vid√©o

Supposons que vous voulez apprendre √† un ordinateur √† jouer √† un jeu, comme les √©checs ou [Super Mario](https://fr.wikipedia.org/wiki/Super_Mario). Pour que l'ordinateur joue √† un jeu, nous devons lui apprendre √† pr√©dire quel mouvement effectuer dans chacun des √©tats du jeu. Bien que cela puisse sembler √™tre un probl√®me de classification, ce n'est pas le cas - car nous n'avons pas d'ensemble de donn√©es avec des √©tats et des actions correspondantes. Bien que nous puissions avoir des donn√©es comme des parties d'√©checs existantes ou des enregistrements de joueurs jouant √† Super Mario, il est probable que ces donn√©es ne couvrent pas suffisamment un grand nombre d'√©tats possibles.

Au lieu de chercher des donn√©es de jeu existantes, **l'apprentissage par renforcement** (RL) repose sur l'id√©e de *faire jouer l'ordinateur* plusieurs fois et d'observer le r√©sultat. Ainsi, pour appliquer l'apprentissage par renforcement, nous avons besoin de deux √©l√©ments :

- **Un environnement** et **un simulateur** qui nous permettent de jouer au jeu plusieurs fois. Ce simulateur d√©finirait toutes les r√®gles du jeu ainsi que les √©tats et actions possibles.

- **Une fonction de r√©compense**, qui nous indiquerait √† quel point nous avons bien jou√© √† chaque mouvement ou partie.

La principale diff√©rence entre les autres types d'apprentissage automatique et le RL est que dans le RL, nous ne savons g√©n√©ralement pas si nous gagnons ou perdons avant de terminer la partie. Ainsi, nous ne pouvons pas dire si un certain mouvement seul est bon ou non - nous ne recevons une r√©compense qu'√† la fin de la partie. Et notre objectif est de concevoir des algorithmes qui nous permettront d'entra√Æner un mod√®le dans des conditions incertaines. Nous allons apprendre un algorithme de RL appel√© **Q-learning**.

## Le√ßons

1. [Introduction √† l'apprentissage par renforcement et au Q-Learning](1-QLearning/README.md)
2. [Utilisation d'un environnement de simulation gym](2-Gym/README.md)

## Cr√©dits

"Introduction √† l'apprentissage par renforcement" a √©t√© √©crit avec ‚ô•Ô∏è par [Dmitry Soshnikov](http://soshnikov.com)

---

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de faire appel √† une traduction humaine professionnelle. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d'interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.