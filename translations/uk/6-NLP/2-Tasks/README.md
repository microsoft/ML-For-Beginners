<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "5f3cb462e3122e1afe7ab0050ccf2bd3",
  "translation_date": "2025-09-05T13:55:40+00:00",
  "source_file": "6-NLP/2-Tasks/README.md",
  "language_code": "uk"
}
-->
# Загальні завдання та техніки обробки природної мови

Для більшості завдань з *обробки природної мови* текст, який потрібно обробити, необхідно розбити, проаналізувати, а результати зберегти або звірити з правилами та наборами даних. Ці завдання дозволяють програмісту визначити _значення_, _намір_ або лише _частоту_ термінів і слів у тексті.

## [Тест перед лекцією](https://ff-quizzes.netlify.app/en/ml/)

Давайте розглянемо загальні техніки, які використовуються для обробки тексту. У поєднанні з машинним навчанням ці техніки допомагають ефективно аналізувати великі обсяги тексту. Однак перед тим, як застосовувати ML до цих завдань, давайте зрозуміємо проблеми, з якими стикається спеціаліст з NLP.

## Загальні завдання NLP

Існують різні способи аналізу тексту, з яким ви працюєте. Є завдання, які ви можете виконувати, і через ці завдання ви зможете краще зрозуміти текст і зробити висновки. Зазвичай ці завдання виконуються послідовно.

### Токенізація

Мабуть, перше, що повинні зробити більшість алгоритмів NLP, — це розбити текст на токени або слова. Хоча це звучить просто, врахування пунктуації та розділових знаків у різних мовах може ускладнити процес. Можливо, вам доведеться використовувати різні методи для визначення меж.

![токенізація](../../../../6-NLP/2-Tasks/images/tokenization.png)
> Токенізація речення з **Гордості і упередження**. Інфографіка від [Jen Looper](https://twitter.com/jenlooper)

### Вбудовування слів

[Вбудовування слів](https://wikipedia.org/wiki/Word_embedding) — це спосіб числового представлення текстових даних. Вбудовування виконується так, щоб слова зі схожим значенням або ті, що часто використовуються разом, групувалися поруч.

![вбудовування слів](../../../../6-NLP/2-Tasks/images/embedding.png)
> "Я маю найвищу повагу до ваших нервів, вони мої старі друзі." - Вбудовування слів для речення з **Гордості і упередження**. Інфографіка від [Jen Looper](https://twitter.com/jenlooper)

✅ Спробуйте [цей цікавий інструмент](https://projector.tensorflow.org/) для експериментів із вбудовуванням слів. Натискання на одне слово показує групи схожих слів: 'іграшка' групується з 'дисней', 'лего', 'плейстейшн' і 'консоль'.

### Розбір і визначення частин мови

Кожне слово, яке було токенізоване, може бути позначене як частина мови — іменник, дієслово або прикметник. Наприклад, речення `швидка червона лисиця перестрибнула через ледачого коричневого собаку` може бути позначене як лисиця = іменник, перестрибнула = дієслово.

![розбір](../../../../6-NLP/2-Tasks/images/parse.png)

> Розбір речення з **Гордості і упередження**. Інфографіка від [Jen Looper](https://twitter.com/jenlooper)

Розбір — це визначення, які слова пов'язані між собою в реченні. Наприклад, `швидка червона лисиця перестрибнула` — це послідовність прикметник-іменник-дієслово, яка відокремлена від послідовності `ледачий коричневий собака`.

### Частота слів і фраз

Корисною процедурою при аналізі великого тексту є створення словника всіх слів або фраз, що вас цікавлять, і підрахунок, як часто вони зустрічаються. Наприклад, у фразі `швидка червона лисиця перестрибнула через ледачого коричневого собаку` слово "the" зустрічається 2 рази.

Розглянемо приклад тексту, де ми рахуємо частоту слів. У вірші Редьярда Кіплінга "Переможці" є такий уривок:

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

Оскільки частота фраз може бути чутливою або нечутливою до регістру, фраза `a friend` має частоту 2, `the` — 6, а `travels` — 2.

### N-грами

Текст можна розбити на послідовності слів заданої довжини: одне слово (уніграм), два слова (біграми), три слова (триграми) або будь-яку кількість слів (n-грам).

Наприклад, `швидка червона лисиця перестрибнула через ледачого коричневого собаку` з n-грамами довжини 2 дає такі n-грами:

1. швидка червона  
2. червона лисиця  
3. лисиця перестрибнула  
4. перестрибнула через  
5. через ледачого  
6. ледачого коричневого  
7. коричневого собаку  

Це можна уявити як ковзне вікно по реченню. Ось приклад для n-грамів із 3 слів, де n-грам виділено жирним у кожному реченні:

1.   <u>**швидка червона лисиця**</u> перестрибнула через ледачого коричневого собаку  
2.   швидка **<u>червона лисиця перестрибнула</u>** через ледачого коричневого собаку  
3.   швидка червона **<u>лисиця перестрибнула через</u>** ледачого коричневого собаку  
4.   швидка червона лисиця **<u>перестрибнула через ледачого</u>** коричневого собаку  
5.   швидка червона лисиця перестрибнула **<u>через ледачого коричневого</u>** собаку  
6.   швидка червона лисиця перестрибнула через <u>**ледачого коричневого собаку**</u>  

![ковзне вікно n-грамів](../../../../6-NLP/2-Tasks/images/n-grams.gif)

> Значення n-граму = 3: Інфографіка від [Jen Looper](https://twitter.com/jenlooper)

### Витяг іменних фраз

У більшості речень є іменник, який є підметом або додатком речення. В англійській мові його часто можна визначити за словами 'a', 'an' або 'the', які передують йому. Визначення підмета або додатка речення шляхом "витягу іменної фрази" є поширеним завданням NLP для розуміння значення речення.

✅ У реченні "Я не можу визначити годину, місце, погляд чи слова, які заклали основу. Це було занадто давно. Я був у середині, перш ніж зрозумів, що почав." чи можете ви визначити іменні фрази?

У реченні `швидка червона лисиця перестрибнула через ледачого коричневого собаку` є 2 іменні фрази: **швидка червона лисиця** і **ледачий коричневий собака**.

### Аналіз настроїв

Речення або текст можна проаналізувати на настрій, тобто наскільки він *позитивний* чи *негативний*. Настрій вимірюється за *полярністю* та *об'єктивністю/суб'єктивністю*. Полярність вимірюється від -1.0 до 1.0 (негативний до позитивного), а об'єктивність — від 0.0 до 1.0 (найбільш об'єктивний до найбільш суб'єктивного).

✅ Пізніше ви дізнаєтеся, що існують різні способи визначення настрою за допомогою машинного навчання, але один із способів — це мати список слів і фраз, які класифіковані як позитивні чи негативні експертом, і застосовувати цю модель до тексту для розрахунку полярності. Чи можете ви уявити, як це працює в одних випадках і менш ефективно в інших?

### Інфлексія

Інфлексія дозволяє взяти слово та отримати його однину або множину.

### Лематизація

*Лема* — це корінь або основне слово для набору слів, наприклад, *летів*, *літає*, *літаючий* мають лему дієслова *літати*.

Також існують корисні бази даних для дослідників NLP, зокрема:

### WordNet

[WordNet](https://wordnet.princeton.edu/) — це база даних слів, синонімів, антонімів та багатьох інших деталей для кожного слова багатьма мовами. Вона надзвичайно корисна для створення перекладів, перевірки орфографії або будь-яких мовних інструментів.

## Бібліотеки NLP

На щастя, вам не потрібно створювати всі ці техніки самостійно, оскільки існують чудові бібліотеки Python, які роблять їх набагато доступнішими для розробників, які не спеціалізуються на обробці природної мови чи машинному навчанні. У наступних уроках буде більше прикладів, але тут ви дізнаєтеся кілька корисних прикладів, які допоможуть вам із наступним завданням.

### Вправа - використання бібліотеки `TextBlob`

Давайте використаємо бібліотеку TextBlob, оскільки вона містить корисні API для вирішення таких завдань. TextBlob "побудована на основі [NLTK](https://nltk.org) та [pattern](https://github.com/clips/pattern) і добре працює з обома." Вона має значну кількість ML, вбудованого в її API.

> Примітка: Корисний [швидкий старт](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart) доступний для TextBlob і рекомендується для досвідчених розробників Python.

Коли ви намагаєтеся визначити *іменні фрази*, TextBlob пропонує кілька варіантів екстракторів для їх пошуку.

1. Ознайомтеся з `ConllExtractor`.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > Що тут відбувається? [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) — це "екстрактор іменних фраз, який використовує розбір на основі моделі, навченої на корпусі ConLL-2000." ConLL-2000 стосується Конференції з обчислювального навчання природної мови 2000 року. Кожного року конференція проводила семінар для вирішення складної проблеми NLP, і в 2000 році це було виділення іменних фраз. Модель була навчена на текстах Wall Street Journal, використовуючи "розділи 15-18 як навчальні дані (211727 токенів) і розділ 20 як тестові дані (47377 токенів)". Ви можете ознайомитися з процедурами [тут](https://www.clips.uantwerpen.be/conll2000/chunking/) і [результатами](https://ifarm.nl/erikt/research/np-chunking.html).

### Завдання - покращення вашого бота за допомогою NLP

У попередньому уроці ви створили дуже простого бота для запитань і відповідей. Тепер ви зробите Марвіна трохи більш співчутливим, аналізуючи ваш ввід на настрій і друкуючи відповідь, яка відповідає настрою. Вам також потрібно буде визначити `noun_phrase` і запитати про неї.

Ваші кроки для створення кращого розмовного бота:

1. Надрукуйте інструкції, які пояснюють користувачеві, як взаємодіяти з ботом.  
2. Почніть цикл:  
   1. Прийміть ввід користувача.  
   2. Якщо користувач попросив вийти, завершіть роботу.  
   3. Обробіть ввід користувача та визначте відповідь, яка відповідає настрою.  
   4. Якщо в настрої виявлено іменну фразу, зробіть її множиною та запитайте більше про цю тему.  
   5. Надрукуйте відповідь.  
3. Поверніться до кроку 2.  

Ось фрагмент коду для визначення настрою за допомогою TextBlob. Зверніть увагу, що є лише чотири *градації* відповіді на настрій (ви можете додати більше, якщо хочете):

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

Ось приклад виводу, який може вас спрямувати (ввід користувача позначено рядками, що починаються з >):

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

Можливе рішення завдання доступне [тут](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/2-Tasks/solution/bot.py).

✅ Перевірка знань

1. Чи вважаєте ви, що співчутливі відповіді можуть "обдурити" когось, змусивши думати, що бот дійсно їх розуміє?  
2. Чи робить визначення іменної фрази бота більш "переконливим"?  
3. Чому витяг іменної фрази з речення є корисним завданням?  

---

Реалізуйте бота з попередньої перевірки знань і протестуйте його на другові. Чи може він їх обдурити? Чи можете ви зробити вашого бота більш "переконливим"?

## 🚀Виклик

Візьміть завдання з попередньої перевірки знань і спробуйте його реалізувати. Протестуйте бота на другові. Чи може він їх обдурити? Чи можете ви зробити вашого бота більш "переконливим"?

## [Тест після лекції](https://ff-quizzes.netlify.app/en/ml/)

## Огляд і самостійне навчання

У наступних уроках ви дізнаєтеся більше про аналіз настроїв. Досліджуйте цю цікаву техніку в таких статтях, як ці на [KDNuggets](https://www.kdnuggets.com/tag/nlp).

## Завдання

[Зробіть бота, який відповідає](assignment.md)

---

**Відмова від відповідальності**:  
Цей документ було перекладено за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, зверніть увагу, що автоматичні переклади можуть містити помилки або неточності. Оригінальний документ мовою оригіналу слід вважати авторитетним джерелом. Для критично важливої інформації рекомендується професійний людський переклад. Ми не несемо відповідальності за будь-які непорозуміння або неправильні тлумачення, що виникли внаслідок використання цього перекладу.