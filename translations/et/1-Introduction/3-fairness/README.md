<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "9a6b702d1437c0467e3c5c28d763dac2",
  "translation_date": "2025-10-11T11:26:33+00:00",
  "source_file": "1-Introduction/3-fairness/README.md",
  "language_code": "et"
}
-->
# Masin√µppe lahenduste loomine vastutustundliku tehisintellektiga

![Vastutustundliku tehisintellekti kokkuv√µte masin√µppes sket≈°im√§rkmetes](../../../../translated_images/et/ml-fairness.ef296ebec6afc98a.webp)
> Sket≈°im√§rkmed: [Tomomi Imura](https://www.twitter.com/girlie_mac)

## [Loengu-eelne viktoriin](https://ff-quizzes.netlify.app/en/ml/)

## Sissejuhatus

Selles √µppekavas hakkate avastama, kuidas masin√µpe m√µjutab meie igap√§evaelu. Juba praegu on s√ºsteemid ja mudelid seotud igap√§evaste otsustusprotsessidega, nagu tervishoiudiagnoosid, laenu heakskiitmine v√µi pettuste tuvastamine. Seet√µttu on oluline, et need mudelid t√∂√∂taksid h√§sti ja pakuksid usaldusv√§√§rseid tulemusi. Nagu iga tarkvararakendus, v√µivad ka tehisintellekti s√ºsteemid eksida ootustes v√µi anda soovimatuid tulemusi. Seet√µttu on h√§davajalik m√µista ja selgitada tehisintellekti mudeli k√§itumist.

Kujutage ette, mis juhtub, kui andmed, mida kasutate mudelite loomiseks, ei sisalda teatud demograafilisi r√ºhmi, nagu rass, sugu, poliitilised vaated, religioon, v√µi esindavad neid ebaproportsionaalselt. Mis saab siis, kui mudeli v√§ljund eelistab teatud demograafilist r√ºhma? Millised on tagaj√§rjed rakendusele? Lisaks, mis juhtub siis, kui mudelil on kahjulik tulemus? Kes vastutab tehisintellekti s√ºsteemi k√§itumise eest? Need on m√µned k√ºsimused, mida selles √µppekavas uurime.

Selles √µppet√ºkis:

- T√µstate teadlikkust masin√µppe √µiglusest ja sellega seotud kahjudest.
- Tutvute praktika ja ebatavaliste stsenaariumide uurimisega, et tagada usaldusv√§√§rsus ja ohutus.
- Saate aru, miks on oluline luua kaasavaid s√ºsteeme, mis v√µimestavad k√µiki.
- Uurite, kui t√§htis on kaitsta inimeste ja andmete privaatsust ja turvalisust.
- N√§ete, kui oluline on "klaaskasti" l√§henemine tehisintellekti mudelite k√§itumise selgitamiseks.
- M√µistate, kuidas vastutus on h√§davajalik tehisintellekti s√ºsteemide usalduse loomiseks.

## Eeltingimus

Eeltingimusena palun l√§bige "Vastutustundliku tehisintellekti p√µhim√µtted" √µppeprogramm ja vaadake allolevat videot:

Lisateavet vastutustundliku tehisintellekti kohta leiate siit: [√ïppeprogramm](https://docs.microsoft.com/learn/modules/responsible-ai-principles/?WT.mc_id=academic-77952-leestott)

[![Microsofti l√§henemine vastutustundlikule tehisintellektile](https://img.youtube.com/vi/dnC8-uUZXSc/0.jpg)](https://youtu.be/dnC8-uUZXSc "Microsofti l√§henemine vastutustundlikule tehisintellektile")

> üé• Kl√µpsake √ºlaloleval pildil, et vaadata videot: Microsofti l√§henemine vastutustundlikule tehisintellektile

## √ïiglus

Tehisintellekti s√ºsteemid peaksid kohtlema k√µiki √µiglaselt ja v√§ltima sarnaste inimr√ºhmade erinevat kohtlemist. N√§iteks kui tehisintellekti s√ºsteemid annavad juhiseid meditsiinilise ravi, laenutaotluste v√µi t√∂√∂lev√µtmise kohta, peaksid nad tegema samad soovitused k√µigile, kellel on sarnased s√ºmptomid, finantsolukord v√µi professionaalsed kvalifikatsioonid. Iga√ºks meist kannab endaga kaasas p√§rilikke eelarvamusi, mis m√µjutavad meie otsuseid ja tegevusi. Need eelarvamused v√µivad ilmneda andmetes, mida kasutame tehisintellekti s√ºsteemide treenimiseks. Selline manipuleerimine v√µib m√µnikord juhtuda tahtmatult. Sageli on raske teadlikult m√§rgata, millal andmetesse eelarvamusi lisate.

**"Eba√µiglus"** h√µlmab negatiivseid m√µjusid v√µi "kahjusid" inimr√ºhmale, n√§iteks rassi, soo, vanuse v√µi puude alusel. Peamised √µigusega seotud kahjud v√µib jagada j√§rgmiselt:

- **Jaotamine**, kui n√§iteks sugu v√µi etnilist kuuluvust eelistatakse teisele.
- **Teenuse kvaliteet**. Kui treenite andmeid √ºhe konkreetse stsenaariumi jaoks, kuid tegelikkus on palju keerulisem, viib see halvasti toimiva teenuseni. N√§iteks k√§te seebidosaator, mis ei suutnud tuvastada tumedanahalisi inimesi. [Viide](https://gizmodo.com/why-cant-this-soap-dispenser-identify-dark-skin-1797931773)
- **Halvustamine**. Eba√µiglane kriitika ja kellegi v√µi millegi sildistamine. N√§iteks pildisildistamise tehnoloogia, mis kurikuulsalt ekslikult sildistas tumedanahaliste inimeste pilte gorilladena.
- **√úle- v√µi alaesindatus**. Idee, et teatud r√ºhma ei n√§hta teatud ametis, ja iga teenus v√µi funktsioon, mis seda j√§tkuvalt edendab, aitab kaasa kahjule.
- **Stereot√ºpiseerimine**. Teatud r√ºhma seostamine eelnevalt m√§√§ratud omadustega. N√§iteks inglise ja t√ºrgi keele vahel t√µlkiv s√ºsteem v√µib eksida s√µnadega, millel on sooga seotud stereot√º√ºpsed seosed.

![T√µlge t√ºrgi keelde](../../../../translated_images/et/gender-bias-translate-en-tr.f185fd8822c2d437.webp)
> T√µlge t√ºrgi keelde

![T√µlge tagasi inglise keelde](../../../../translated_images/et/gender-bias-translate-tr-en.4eee7e3cecb8c70e.webp)
> T√µlge tagasi inglise keelde

Tehisintellekti s√ºsteemide kavandamisel ja testimisel peame tagama, et tehisintellekt oleks √µiglane ega oleks programmeeritud tegema eelarvamuslikke v√µi diskrimineerivaid otsuseid, mida ka inimestel on keelatud teha. √ïigluse tagamine tehisintellektis ja masin√µppes j√§√§b keeruliseks sotsiaal-tehniliseks v√§ljakutseks.

### Usaldusv√§√§rsus ja ohutus

Usalduse loomiseks peavad tehisintellekti s√ºsteemid olema usaldusv√§√§rsed, ohutud ja j√§rjepidevad nii tavap√§rastes kui ka ootamatutes tingimustes. Oluline on teada, kuidas tehisintellekti s√ºsteemid k√§ituvad erinevates olukordades, eriti kui tegemist on eranditega. Tehisintellekti lahenduste loomisel tuleb keskenduda sellele, kuidas lahendused suudavad toime tulla mitmesuguste olukordadega, millega nad kokku puutuvad. N√§iteks peab ises√µitev auto seadma inimeste ohutuse esikohale. Seet√µttu peab autot juhtiv tehisintellekt arvestama k√µiki v√µimalikke stsenaariume, millega auto v√µib kokku puutuda, nagu √∂√∂, √§ikesetormid v√µi lumetormid, t√§naval jooksvad lapsed, lemmikloomad, teet√∂√∂d jne. Kui h√§sti tehisintellekti s√ºsteem suudab usaldusv√§√§rselt ja ohutult toime tulla laia valiku tingimustega, peegeldab see andmeteadlase v√µi tehisintellekti arendaja disaini- v√µi testimisprotsessi taset.

> [üé• Kl√µpsake siia, et vaadata videot: ](https://www.microsoft.com/videoplayer/embed/RE4vvIl)

### Kaasavus

Tehisintellekti s√ºsteemid peaksid olema loodud kaasama ja v√µimestama k√µiki. Tehisintellekti s√ºsteemide kavandamisel ja rakendamisel tuvastavad andmeteadlased ja tehisintellekti arendajad s√ºsteemis potentsiaalsed takistused, mis v√µivad tahtmatult inimesi v√§listada. N√§iteks on maailmas 1 miljard puudega inimest. Tehisintellekti arenguga saavad nad igap√§evaelus h√µlpsamini juurde p√§√§seda laiale hulgale teabele ja v√µimalustele. Takistuste k√µrvaldamine loob v√µimalusi innovatsiooniks ja tehisintellekti toodete arendamiseks paremate kogemustega, mis toovad kasu k√µigile.

> [üé• Kl√µpsake siia, et vaadata videot: kaasavus tehisintellektis](https://www.microsoft.com/videoplayer/embed/RE4vl9v)

### Turvalisus ja privaatsus

Tehisintellekti s√ºsteemid peaksid olema ohutud ja austama inimeste privaatsust. Inimesed usaldavad v√§hem s√ºsteeme, mis seavad ohtu nende privaatsuse, teabe v√µi elu. Masin√µppe mudelite treenimisel toetume andmetele, et saavutada parimaid tulemusi. Selle k√§igus tuleb arvestada andmete p√§ritolu ja terviklikkusega. N√§iteks, kas andmed on kasutaja esitatud v√µi avalikult k√§ttesaadavad? J√§rgmisena, andmetega t√∂√∂tades on oluline arendada tehisintellekti s√ºsteeme, mis suudavad kaitsta konfidentsiaalset teavet ja taluda r√ºnnakuid. Kuna tehisintellekt muutub √ºha levinumaks, muutub privaatsuse kaitsmine ja olulise isikliku ning √§rilise teabe turvalisuse tagamine √ºha kriitilisemaks ja keerulisemaks. Privaatsuse ja andmete turvalisuse k√ºsimused vajavad tehisintellekti puhul erilist t√§helepanu, kuna andmetele juurdep√§√§s on h√§davajalik, et tehisintellekti s√ºsteemid saaksid teha t√§pseid ja informeeritud ennustusi ning otsuseid inimeste kohta.

> [üé• Kl√µpsake siia, et vaadata videot: turvalisus tehisintellektis](https://www.microsoft.com/videoplayer/embed/RE4voJF)

- T√∂√∂stus on teinud privaatsuse ja turvalisuse valdkonnas m√§rkimisv√§√§rseid edusamme, mida on oluliselt edendanud sellised regulatsioonid nagu GDPR (√ºldine andmekaitse m√§√§rus).
- Kuid tehisintellekti s√ºsteemide puhul peame tunnistama pinget, mis tekib vajadusest koguda rohkem isikuandmeid, et muuta s√ºsteemid isiklikumaks ja t√µhusamaks ‚Äì ja privaatsuse s√§ilitamise vahel.
- Nagu internetiga √ºhendatud arvutite s√ºnni puhul, n√§eme ka tehisintellektiga seotud turvalisusk√ºsimuste suurt kasvu.
- Samal ajal on tehisintellekti kasutatud turvalisuse parandamiseks. N√§iteks enamik kaasaegseid viiruset√µrje skannereid p√µhineb tehisintellekti heuristikal.
- Peame tagama, et meie andmeteaduse protsessid sobituksid harmooniliselt uusimate privaatsuse ja turvalisuse praktikatega.

### L√§bipaistvus

Tehisintellekti s√ºsteemid peaksid olema arusaadavad. L√§bipaistvuse oluline osa on tehisintellekti s√ºsteemide ja nende komponentide k√§itumise selgitamine. Tehisintellekti s√ºsteemide m√µistmise parandamine n√µuab, et sidusr√ºhmad m√µistaksid, kuidas ja miks need toimivad, et nad saaksid tuvastada v√µimalikke j√µudlusprobleeme, ohutus- ja privaatsusprobleeme, eelarvamusi, v√§listavaid tavasid v√µi soovimatuid tulemusi. Usume ka, et need, kes kasutavad tehisintellekti s√ºsteeme, peaksid olema ausad ja avameelsed, kui, miks ja kuidas nad otsustavad neid rakendada. Samuti peaksid nad selgitama kasutatavate s√ºsteemide piiranguid. N√§iteks kui pank kasutab tehisintellekti s√ºsteemi, et toetada tarbijate laenuotsuseid, on oluline uurida tulemusi ja m√µista, millised andmed m√µjutavad s√ºsteemi soovitusi. Valitsused hakkavad tehisintellekti t√∂√∂stusharudes reguleerima, seega peavad andmeteadlased ja organisatsioonid selgitama, kas tehisintellekti s√ºsteem vastab regulatiivsetele n√µuetele, eriti kui esineb soovimatu tulemus.

> [üé• Kl√µpsake siia, et vaadata videot: l√§bipaistvus tehisintellektis](https://www.microsoft.com/videoplayer/embed/RE4voJF)

- Kuna tehisintellekti s√ºsteemid on nii keerulised, on raske m√µista, kuidas need t√∂√∂tavad ja tulemusi t√µlgendada.
- See arusaamise puudumine m√µjutab nende s√ºsteemide haldamist, rakendamist ja dokumenteerimist.
- Veelgi olulisem on see, et see arusaamise puudumine m√µjutab otsuseid, mis tehakse nende s√ºsteemide toodetud tulemuste p√µhjal.

### Vastutus

Inimesed, kes kavandavad ja rakendavad tehisintellekti s√ºsteeme, peavad vastutama selle eest, kuidas nende s√ºsteemid toimivad. Vastutuse vajadus on eriti oluline tundlike tehnoloogiate, nagu n√§otuvastus, puhul. Viimasel ajal on n√§otuvastustehnoloogia j√§rele olnud kasvav n√µudlus, eriti √µiguskaitseorganisatsioonide poolt, kes n√§evad tehnoloogia potentsiaali n√§iteks kadunud laste leidmisel. Kuid need tehnoloogiad v√µivad valitsuse poolt potentsiaalselt ohustada kodanike p√µhi√µigusi, v√µimaldades n√§iteks konkreetsete isikute pidevat j√§lgimist. Seet√µttu peavad andmeteadlased ja organisatsioonid vastutama selle eest, kuidas nende tehisintellekti s√ºsteem m√µjutab √ºksikisikuid v√µi √ºhiskonda.

[![Juhtiv tehisintellekti teadlane hoiatab massilise j√§lgimise eest n√§otuvastuse kaudu](../../../../translated_images/et/accountability.41d8c0f4b85b6231.webp)](https://www.youtube.com/watch?v=Wldt8P5V6D0 "Microsofti l√§henemine vastutustundlikule tehisintellektile")

> üé• Kl√µpsake √ºlaloleval pildil, et vaadata videot: Hoiatused massilise j√§lgimise eest n√§otuvastuse kaudu

L√µppkokkuv√µttes on √ºks suurimaid k√ºsimusi meie p√µlvkonnale, kui esimesele p√µlvkonnale, kes toob tehisintellekti √ºhiskonda, kuidas tagada, et arvutid j√§√§ksid inimestele vastutavaks ja kuidas tagada, et arvutite disainerid j√§√§ksid vastutavaks k√µigi teiste ees.

## M√µju hindamine

Enne masin√µppe mudeli treenimist on oluline l√§bi viia m√µju hindamine, et m√µista tehisintellekti s√ºsteemi eesm√§rki; milline on kavandatud kasutus; kus seda rakendatakse; ja kes s√ºsteemiga suhtleb. Need on kasulikud hindajatele v√µi testijatele, et teada saada, milliseid tegureid arvestada v√µimalike riskide ja oodatavate tagaj√§rgede tuvastamisel.

M√µju hindamise fookusvaldkonnad:

* **Kahjulik m√µju √ºksikisikutele**. Oluline on olla teadlik piirangutest v√µi n√µuetest, mittetoetatud kasutusest v√µi teadaolevatest piirangutest, mis takistavad s√ºsteemi toimimist, et tagada, et s√ºsteemi ei kasutata viisil, mis v√µiks √ºksikisikutele kahju tekitada.
* **Andmete n√µuded**. S√ºsteemi andmekasutuse m√µistmine v√µimaldab hindajatel uurida andmen√µudeid, mida tuleb arvesse v√µtta (nt GDPR v√µi HIPAA andmereeglid). Lisaks tuleb uurida, kas andmete allikas v√µi kogus on treenimiseks piisav.
* **M√µju kokkuv√µte**. Koostage nimekiri v√µimalikest kahjudest, mis v√µivad s√ºsteemi kasutamisest tuleneda. Masin√µppe eluts√ºkli jooksul vaadake √ºle, kas tuvastatud probleemid on leevendatud v√µi lahendatud.
* **Rakendatavad eesm√§rgid** kuue p√µhiv√§√§rtuse jaoks. Hinnake, kas iga p√µhim√µtte eesm√§rgid on t√§idetud ja kas on mingeid puuduj√§√§ke.

## Vastutustundliku tehisintellektiga silumine

Sarnaselt tarkvararakenduse silumisele on tehisintellekti s√ºsteemi silumine vajalik protsess s√ºsteemi probleemide tuvastamiseks ja lahendamiseks. On palju tegureid, mis v√µivad p√µhjustada mudeli ootustele mittevastavat v√µi vastutustundetut toimimist. Enamik traditsioonilisi mudeli j√µudluse m√µ√µdikuid on kvantitatiivsed koondandmed mudeli j√µudluse kohta, mis ei ole piisavad, et anal√º√ºsida, kuidas mudel rikub vastutustundliku tehisintellekti p√µhim√µtteid. Lisaks on masin√µppe mudel must kast, mis teeb selle tulemuste p√µhjuseid raskesti m√µistetavaks v√µi selgitab eksimusi. Hiljem selles kursuses √µpime kasutama vastutustundliku tehisintellekti juhtpaneeli, et aidata tehisintellekti s√ºsteeme siluda. Juhtpaneel pakub terviklikku t√∂√∂riista andmeteadlastele ja tehisintellekti arendajatele, et teha:

* **Vigade anal√º√ºs**. Tuvastada mudeli veajaotust, mis v√µib m√µjutada s√ºsteemi √µiglust v√µi usaldusv√§√§rsust.
* **Mudeli √ºlevaade**. Avastada, kus mudeli j√µudluses esineb erinevusi andmekoortide vahel.
* **Andmete anal√º√ºs
## √úlevaade ja iseseisev √µppimine

Selles tunnis √µppisite masin√µppe √µiglus- ja eba√µigluskontseptsioonide p√µhit√µdesid.

Vaadake seda t√∂√∂tuba, et teemadesse s√ºveneda:

- Vastutustundliku tehisintellekti poole p√º√ºdlemine: P√µhim√µtete rakendamine praktikas, autorid Besmira Nushi, Mehrnoosh Sameki ja Amit Sharma

[![Vastutustundliku tehisintellekti t√∂√∂riistakast: avatud l√§htekoodiga raamistik vastutustundliku tehisintellekti loomiseks](https://img.youtube.com/vi/tGgJCrA-MZU/0.jpg)](https://www.youtube.com/watch?v=tGgJCrA-MZU "RAI Toolbox: Avatud l√§htekoodiga raamistik vastutustundliku tehisintellekti loomiseks")

> üé• Kl√µpsake √ºlaloleval pildil, et vaadata videot: RAI Toolbox: Avatud l√§htekoodiga raamistik vastutustundliku tehisintellekti loomiseks, autorid Besmira Nushi, Mehrnoosh Sameki ja Amit Sharma

Lugege ka:

- Microsofti RAI ressursikeskus: [Vastutustundliku tehisintellekti ressursid ‚Äì Microsoft AI](https://www.microsoft.com/ai/responsible-ai-resources?activetab=pivot1%3aprimaryr4)

- Microsofti FATE uurimisr√ºhm: [FATE: √ïiglus, vastutus, l√§bipaistvus ja eetika tehisintellektis - Microsoft Research](https://www.microsoft.com/research/theme/fate/)

RAI t√∂√∂riistakast:

- [Vastutustundliku tehisintellekti t√∂√∂riistakasti GitHubi hoidla](https://github.com/microsoft/responsible-ai-toolbox)

Lugege Azure Machine Learningu t√∂√∂riistade kohta, mis aitavad tagada √µiglust:

- [Azure Machine Learning](https://docs.microsoft.com/azure/machine-learning/concept-fairness-ml?WT.mc_id=academic-77952-leestott)

## √úlesanne

[Uurige RAI t√∂√∂riistakasti](assignment.md)

---

**Vastutusest loobumine**:  
See dokument on t√µlgitud AI t√µlketeenuse [Co-op Translator](https://github.com/Azure/co-op-translator) abil. Kuigi p√º√ºame tagada t√§psust, palume arvestada, et automaatsed t√µlked v√µivad sisaldada vigu v√µi ebat√§psusi. Algne dokument selle algses keeles tuleks pidada autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimt√µlget. Me ei vastuta arusaamatuste v√µi valesti t√µlgenduste eest, mis v√µivad tuleneda selle t√µlke kasutamisest.