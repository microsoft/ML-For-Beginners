<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1a6e9e46b34a2e559fbbfc1f95397c7b",
  "translation_date": "2025-10-11T11:54:05+00:00",
  "source_file": "4-Classification/2-Classifiers-1/README.md",
  "language_code": "et"
}
-->
# K√∂√∂gi klassifikaatorid 1

Selles tunnis kasutad eelmises tunnis salvestatud andmestikku, mis sisaldab tasakaalustatud ja puhastatud andmeid erinevate k√∂√∂kide kohta.

Seda andmestikku kasutatakse mitmesuguste klassifikaatoritega, et _ennustada rahvuslikku k√∂√∂ki, l√§htudes koostisosade grupist_. Samal ajal √µpid rohkem algoritmide kasutamise kohta klassifitseerimis√ºlesannetes.

## [Eelloengu viktoriin](https://ff-quizzes.netlify.app/en/ml/)
# Ettevalmistus

Eeldades, et oled l√µpetanud [1. tunni](../1-Introduction/README.md), veendu, et _cleaned_cuisines.csv_ fail asub juurkataloogi `/data` kaustas, mis on m√µeldud nende nelja tunni jaoks.

## Harjutus - rahvusliku k√∂√∂gi ennustamine

1. T√∂√∂tades selle tunni _notebook.ipynb_ kaustas, impordi fail koos Pandas teegiga:

    ```python
    import pandas as pd
    cuisines_df = pd.read_csv("../data/cleaned_cuisines.csv")
    cuisines_df.head()
    ```

    Andmed n√§evad v√§lja sellised:

|     | Unnamed: 0 | cuisine | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood | yam | yeast | yogurt | zucchini |
| --- | ---------- | ------- | ------ | -------- | ----- | ---------- | ----- | ------------ | ------- | -------- | --- | ------- | ----------- | ---------- | ----------------------- | ---- | ---- | --- | ----- | ------ | -------- |
| 0   | 0          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 1   | 1          | indian  | 1      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 2   | 2          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 3   | 3          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 4   | 4          | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 1      | 0        |
  

1. N√º√ºd impordi veel m√µned teegid:

    ```python
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    from sklearn.svm import SVC
    import numpy as np
    ```

1. Jaga X ja y koordinaadid kaheks andmeraamiks treenimiseks. `cuisine` v√µib olla siltide andmeraam:

    ```python
    cuisines_label_df = cuisines_df['cuisine']
    cuisines_label_df.head()
    ```

    See n√§eb v√§lja selline:

    ```output
    0    indian
    1    indian
    2    indian
    3    indian
    4    indian
    Name: cuisine, dtype: object
    ```

1. Eemalda `Unnamed: 0` ja `cuisine` veerud, kasutades `drop()` funktsiooni. Salvesta √ºlej√§√§nud andmed treenitavate omadustena:

    ```python
    cuisines_feature_df = cuisines_df.drop(['Unnamed: 0', 'cuisine'], axis=1)
    cuisines_feature_df.head()
    ```

    Sinu omadused n√§evad v√§lja sellised:

|      | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | artemisia | artichoke |  ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood |  yam | yeast | yogurt | zucchini |
| ---: | -----: | -------: | ----: | ---------: | ----: | -----------: | ------: | -------: | --------: | --------: | ---: | ------: | ----------: | ---------: | ----------------------: | ---: | ---: | ---: | ----: | -----: | -------: |
|    0 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    1 |      1 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    2 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    3 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    4 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      1 |        0 | 0 |

N√º√ºd oled valmis oma mudelit treenima!

## Klassifikaatori valimine

N√º√ºd, kui andmed on puhastatud ja treenimiseks valmis, pead otsustama, millist algoritmi kasutada.

Scikit-learn liigitab klassifitseerimise juhendatud √µppimise alla, ja selles kategoorias on palju erinevaid viise klassifitseerimiseks. [Valik](https://scikit-learn.org/stable/supervised_learning.html) v√µib esmapilgul tunduda √ºsna segadusttekitav. J√§rgnevad meetodid sisaldavad k√µik klassifitseerimistehnikaid:

- Lineaarsed mudelid
- Toetavate vektorite masinad
- Stohhastiline gradientide langus
- L√§himate naabrite meetod
- Gaussi protsessid
- Otsustuspuud
- Ansamblimeetodid (h√§√§letav klassifikaator)
- Mitmeklassi ja mitme v√§ljundi algoritmid (mitmeklassi ja mitmesildi klassifikatsioon, mitmeklassi-mitmev√§ljundi klassifikatsioon)

> V√µid kasutada ka [n√§rviv√µrke andmete klassifitseerimiseks](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#classification), kuid see j√§√§b selle tunni teemast v√§lja.

### Millist klassifikaatorit valida?

Millist klassifikaatorit valida? Sageli on hea katsetada mitmeid ja otsida parimat tulemust. Scikit-learn pakub [k√µrvutavat v√µrdlust](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) loodud andmestikul, v√µrreldes KNeighbors, SVC kahte viisi, GaussianProcessClassifier, DecisionTreeClassifier, RandomForestClassifier, MLPClassifier, AdaBoostClassifier, GaussianNB ja QuadraticDiscriminationAnalysis, n√§idates tulemusi visualiseeritult:

![klassifikaatorite v√µrdlus](../../../../translated_images/et/comparison.edfab56193a85e7f.png)
> Graafikud on genereeritud Scikit-learn'i dokumentatsioonis

> AutoML lahendab selle probleemi elegantselt, tehes need v√µrdlused pilves ja v√µimaldades valida parima algoritmi sinu andmete jaoks. Proovi seda [siin](https://docs.microsoft.com/learn/modules/automate-model-selection-with-azure-automl/?WT.mc_id=academic-77952-leestott)

### Parem l√§henemine

Parem viis kui lihtsalt juhuslikult arvata, on j√§rgida ideid selle allalaaditava [ML Cheat Sheet](https://docs.microsoft.com/azure/machine-learning/algorithm-cheat-sheet?WT.mc_id=academic-77952-leestott) abil. Siin avastame, et meie mitmeklassi probleemi jaoks on m√µned valikud:

![spikker mitmeklassi probleemide jaoks](../../../../translated_images/et/cheatsheet.07a475ea444d2223.png)
> Microsofti algoritmi spikri osa, mis kirjeldab mitmeklassi klassifikatsiooni valikuid

‚úÖ Laadi see spikker alla, prindi see v√§lja ja riputa seinale!

### P√µhjendamine

Vaatame, kas suudame erinevaid l√§henemisi p√µhjendada, arvestades meie piiranguid:

- **N√§rviv√µrgud on liiga rasked**. Arvestades meie puhast, kuid minimaalset andmestikku ja asjaolu, et treenime kohapeal m√§rkmike kaudu, on n√§rviv√µrgud selle √ºlesande jaoks liiga rasked.
- **Kaheklassi klassifikaator ei sobi**. Me ei kasuta kaheklassi klassifikaatorit, seega v√§listame one-vs-all meetodi.
- **Otsustuspuu v√µi logistiline regressioon v√µiks sobida**. Otsustuspuu v√µiks sobida, v√µi logistiline regressioon mitmeklassi andmete jaoks.
- **Mitmeklassi t√µhustatud otsustuspuud lahendavad teistsuguse probleemi**. Mitmeklassi t√µhustatud otsustuspuu sobib k√µige paremini mitteparametriliste √ºlesannete jaoks, n√§iteks √ºlesannete jaoks, mis on m√µeldud j√§rjestuste loomiseks, seega ei ole see meile kasulik.

### Scikit-learn'i kasutamine

Kasutame Scikit-learn'i, et anal√º√ºsida oma andmeid. Siiski on palju viise, kuidas kasutada logistilist regressiooni Scikit-learn'is. Vaata [parameetreid, mida saab m√§√§rata](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regressio#sklearn.linear_model.LogisticRegression).  

Sisuliselt on kaks olulist parameetrit - `multi_class` ja `solver` -, mida peame m√§√§rama, kui palume Scikit-learn'il teha logistilist regressiooni. `multi_class` v√§√§rtus rakendab teatud k√§itumist. Solveri v√§√§rtus m√§√§rab, millist algoritmi kasutada. Mitte k√µik solverid ei sobi k√µigi `multi_class` v√§√§rtustega.

Dokumentatsiooni j√§rgi mitmeklassi puhul treeningalgoritm:

- **Kasutab one-vs-rest (OvR) skeemi**, kui `multi_class` valik on m√§√§ratud `ovr`
- **Kasutab ristentropia kaotust**, kui `multi_class` valik on m√§√§ratud `multinomial`. (Praegu toetavad `multinomial` valikut ainult solverid ‚Äòlbfgs‚Äô, ‚Äòsag‚Äô, ‚Äòsaga‚Äô ja ‚Äònewton-cg‚Äô.)

> üéì 'Skeem' v√µib olla kas 'ovr' (one-vs-rest) v√µi 'multinomial'. Kuna logistiline regressioon on tegelikult m√µeldud binaarse klassifikatsiooni toetamiseks, v√µimaldavad need skeemid paremini k√§sitleda mitmeklassi klassifikatsiooni √ºlesandeid. [allikas](https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/)

> üéì 'Solver' on defineeritud kui "algoritm, mida kasutatakse optimeerimisprobleemi lahendamiseks". [allikas](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regressio#sklearn.linear_model.LogisticRegression).

Scikit-learn pakub seda tabelit, et selgitada, kuidas solverid k√§sitlevad erinevaid v√§ljakutseid, mida esitavad erinevat t√º√ºpi andmestruktuurid:

![solverid](../../../../translated_images/et/solvers.5fc648618529e627.png)

## Harjutus - andmete jagamine

Keskendume logistilisele regressioonile meie esimese treeningkatse jaoks, kuna sa √µppisid seda hiljuti eelmises tunnis.
Jaga oma andmed treening- ja testimisgruppideks, kutsudes `train_test_split()`:

```python
X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)
```

## Harjutus - logistilise regressiooni rakendamine

Kuna kasutad mitmeklassi juhtumit, pead valima, millist _skeemi_ kasutada ja millist _solverit_ m√§√§rata. Kasuta LogisticRegression'i mitmeklassi seadistusega ja **liblinear** solverit treenimiseks.

1. Loo logistiline regressioon, kus multi_class on m√§√§ratud `ovr` ja solver m√§√§ratud `liblinear`:

    ```python
    lr = LogisticRegression(multi_class='ovr',solver='liblinear')
    model = lr.fit(X_train, np.ravel(y_train))
    
    accuracy = model.score(X_test, y_test)
    print ("Accuracy is {}".format(accuracy))
    ```

    ‚úÖ Proovi teist solverit, n√§iteks `lbfgs`, mis on sageli m√§√§ratud vaikimisi.

    > M√§rkus: kasuta Pandas [`ravel`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.ravel.html) funktsiooni, et vajadusel oma andmeid tasandada.

    T√§psus on hea, √ºle **80%**!

1. N√§ed seda mudelit tegevuses, testides √ºhte andmerida (#50):

    ```python
    print(f'ingredients: {X_test.iloc[50][X_test.iloc[50]!=0].keys()}')
    print(f'cuisine: {y_test.iloc[50]}')
    ```

    Tulemus tr√ºkitakse:

   ```output
   ingredients: Index(['cilantro', 'onion', 'pea', 'potato', 'tomato', 'vegetable_oil'], dtype='object')
   cuisine: indian
   ```

‚úÖ Proovi teist rea numbrit ja kontrolli tulemusi

1. S√ºvenedes, saad kontrollida selle ennustuse t√§psust:

    ```python
    test= X_test.iloc[50].values.reshape(-1, 1).T
    proba = model.predict_proba(test)
    classes = model.classes_
    resultdf = pd.DataFrame(data=proba, columns=classes)
    
    topPrediction = resultdf.T.sort_values(by=[0], ascending = [False])
    topPrediction.head()
    ```

    Tulemus tr√ºkitakse v√§lja - India k√∂√∂k on parim oletus, √ºsna suure t√µen√§osusega:

    |          |        0 |
    | -------: | -------: |
    |   indian | 0.715851 |
    |  chinese | 0.229475 |
    | japanese | 0.029763 |
    |   korean | 0.017277 |
    |     thai | 0.007634 |

    ‚úÖ Kas oskad selgitada, miks mudel on √ºsna kindel, et tegemist on India k√∂√∂giga?

1. Saad rohkem detaile, tr√ºkkides v√§lja klassifikatsiooni aruande, nagu tegid regressiooni tundides:

    ```python
    y_pred = model.predict(X_test)
    print(classification_report(y_test,y_pred))
    ```

    |              | t√§psus   | tagasikutsumine | f1-skoor | tugi     |
    | ------------ | -------- | --------------- | -------- | -------- |
    | chinese      | 0.73     | 0.71            | 0.72     | 229      |
    | indian       | 0.91     | 0.93            | 0.92     | 254      |
    | japanese     | 0.70     | 0.75            | 0.72     | 220      |
    | korean       | 0.86     | 0.76            | 0.81     | 242      |
    | thai         | 0.79     | 0.85            | 0.82     | 254      |
    | t√§psus       | 0.80     | 1199            |          |          |
    | makro keskm. | 0.80     | 0.80            | 0.80     | 1199     |
    | kaalutud keskm.| 0.80   | 0.80            | 0.80     | 1199     |

## üöÄV√§ljakutse

Selles tunnis kasutasid puhastatud andmeid, et luua masin√µppe mudel, mis suudab ennustada rahvusk√∂√∂ki koostisosade p√µhjal. V√µta aega, et tutvuda Scikit-learn'i paljude v√µimalustega andmete klassifitseerimiseks. S√ºvene 'lahendaja' (solver) kontseptsiooni, et m√µista, mis toimub kulisside taga.

## [Loengu j√§rgne viktoriin](https://ff-quizzes.netlify.app/en/ml/)

## √úlevaade ja iseseisev √µppimine

S√ºvene veidi rohkem logistilise regressiooni matemaatikasse [selles tunnis](https://people.eecs.berkeley.edu/~russell/classes/cs194/f11/lectures/CS194%20Fall%202011%20Lecture%2006.pdf)
## √úlesanne 

[Uuri lahendajaid](assignment.md)

---

**Lahti√ºtlus**:  
See dokument on t√µlgitud AI t√µlketeenuse [Co-op Translator](https://github.com/Azure/co-op-translator) abil. Kuigi p√º√ºame tagada t√§psust, palume arvestada, et automaatsed t√µlked v√µivad sisaldada vigu v√µi ebat√§psusi. Algne dokument selle algses keeles tuleks pidada autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimt√µlget. Me ei vastuta selle t√µlke kasutamisest tulenevate arusaamatuste v√µi valesti t√µlgenduste eest.