{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## **An√°lisis de m√∫sica nigeriana extra√≠da de Spotify**\n",
    "\n",
    "El clustering es un tipo de [aprendizaje no supervisado](https://wikipedia.org/wiki/Aprendizaje_no_supervisado) que asume que un conjunto de datos no est√° etiquetado o que sus entradas no est√°n asociadas a salidas predefinidas. Utiliza varios algoritmos para clasificar datos no etiquetados y proporcionar agrupaciones seg√∫n los patrones que detecta en los datos.\n",
    "\n",
    "[**Cuestionario previo a la lecci√≥n**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/27/)\n",
    "\n",
    "### **Introducci√≥n**\n",
    "\n",
    "El [clustering](https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-30164-8_124) es muy √∫til para la exploraci√≥n de datos. Veamos si puede ayudar a descubrir tendencias y patrones en la forma en que las audiencias nigerianas consumen m√∫sica.\n",
    "\n",
    "> ‚úÖ T√≥mate un minuto para pensar en los usos del clustering. En la vida cotidiana, el clustering ocurre cuando tienes un mont√≥n de ropa sucia y necesitas clasificar la ropa de los miembros de tu familia üß¶üëïüëñü©≤. En ciencia de datos, el clustering ocurre al intentar analizar las preferencias de un usuario o determinar las caracter√≠sticas de un conjunto de datos no etiquetado. El clustering, de alguna manera, ayuda a dar sentido al caos, como un caj√≥n de calcetines.\n",
    "\n",
    "En un entorno profesional, el clustering puede usarse para determinar cosas como la segmentaci√≥n de mercado, identificando qu√© grupos de edad compran qu√© productos, por ejemplo. Otro uso ser√≠a la detecci√≥n de anomal√≠as, tal vez para identificar fraudes en un conjunto de datos de transacciones con tarjetas de cr√©dito. O podr√≠as usar el clustering para identificar tumores en un lote de escaneos m√©dicos.\n",
    "\n",
    "‚úÖ Piensa un momento en c√≥mo podr√≠as haber encontrado clustering \"en la vida real\", en un entorno bancario, de comercio electr√≥nico o empresarial.\n",
    "\n",
    "> üéì Curiosamente, el an√°lisis de cl√∫steres se origin√≥ en los campos de la Antropolog√≠a y la Psicolog√≠a en la d√©cada de 1930. ¬øPuedes imaginar c√≥mo podr√≠a haberse utilizado?\n",
    "\n",
    "Alternativamente, podr√≠as usarlo para agrupar resultados de b√∫squeda, como enlaces de compras, im√°genes o rese√±as, por ejemplo. El clustering es √∫til cuando tienes un conjunto de datos grande que deseas reducir y sobre el cual deseas realizar un an√°lisis m√°s detallado, por lo que la t√©cnica puede usarse para aprender sobre los datos antes de construir otros modelos.\n",
    "\n",
    "‚úÖ Una vez que tus datos est√°n organizados en cl√∫steres, les asignas un Id de cl√∫ster, y esta t√©cnica puede ser √∫til para preservar la privacidad de un conjunto de datos; en lugar de referirte a un punto de datos por informaci√≥n m√°s reveladora, puedes referirte a √©l por su Id de cl√∫ster. ¬øPuedes pensar en otras razones por las que preferir√≠as referirte a un Id de cl√∫ster en lugar de otros elementos del cl√∫ster para identificarlo?\n",
    "\n",
    "### Comenzando con el clustering\n",
    "\n",
    "> üéì La forma en que creamos cl√∫steres tiene mucho que ver con c√≥mo agrupamos los puntos de datos. Vamos a desglosar algo de vocabulario:\n",
    ">\n",
    "> üéì ['Transductivo' vs. 'inductivo'](https://wikipedia.org/wiki/Transduction_(machine_learning))\n",
    ">\n",
    "> La inferencia transductiva se deriva de casos de entrenamiento observados que se mapean a casos de prueba espec√≠ficos. La inferencia inductiva se deriva de casos de entrenamiento que se mapean a reglas generales que luego se aplican a los casos de prueba.\n",
    ">\n",
    "> Un ejemplo: Imagina que tienes un conjunto de datos que est√° parcialmente etiquetado. Algunas cosas son 'discos', otras 'CDs', y otras est√°n en blanco. Tu tarea es proporcionar etiquetas para los elementos en blanco. Si eliges un enfoque inductivo, entrenar√≠as un modelo buscando 'discos' y 'CDs', y aplicar√≠as esas etiquetas a tus datos no etiquetados. Este enfoque tendr√° problemas para clasificar cosas que en realidad son 'cassettes'. Un enfoque transductivo, por otro lado, maneja estos datos desconocidos de manera m√°s efectiva al agrupar elementos similares y luego aplicar una etiqueta a un grupo. En este caso, los cl√∫steres podr√≠an reflejar 'cosas musicales redondas' y 'cosas musicales cuadradas'.\n",
    ">\n",
    "> üéì ['Geometr√≠a no plana' vs. 'plana'](https://datascience.stackexchange.com/questions/52260/terminology-flat-geometry-in-the-context-of-clustering)\n",
    ">\n",
    "> Derivado de la terminolog√≠a matem√°tica, la geometr√≠a no plana vs. plana se refiere a la medida de distancias entre puntos mediante m√©todos geom√©tricos 'planos' ([Euclidianos](https://wikipedia.org/wiki/Geometr%C3%ADa_euclidiana)) o 'no planos' (no Euclidianos).\n",
    ">\n",
    "> 'Plana' en este contexto se refiere a la geometr√≠a Euclidiana (partes de la cual se ense√±an como geometr√≠a 'plana'), y no plana se refiere a la geometr√≠a no Euclidiana. ¬øQu√© tiene que ver la geometr√≠a con el aprendizaje autom√°tico? Bueno, como dos campos que tienen ra√≠ces en las matem√°ticas, debe haber una forma com√∫n de medir distancias entre puntos en cl√∫steres, y eso puede hacerse de manera 'plana' o 'no plana', dependiendo de la naturaleza de los datos. Las [distancias Euclidianas](https://wikipedia.org/wiki/Distancia_euclidiana) se miden como la longitud de un segmento de l√≠nea entre dos puntos. Las [distancias no Euclidianas](https://wikipedia.org/wiki/Geometr%C3%ADa_no_euclidiana) se miden a lo largo de una curva. Si tus datos, al visualizarlos, parecen no existir en un plano, podr√≠as necesitar usar un algoritmo especializado para manejarlos.\n",
    "\n",
    "<p>\n",
    "   <img src=\"../../images/flat-nonflat.png\"\n",
    "   width=\"600\"/>\n",
    "   <figcaption>Infograf√≠a por Dasani Madipalli</figcaption>\n",
    "\n",
    "> üéì ['Distancias'](https://web.stanford.edu/class/cs345a/slides/12-clustering.pdf)\n",
    ">\n",
    "> Los cl√∫steres se definen por su matriz de distancias, es decir, las distancias entre puntos. Esta distancia puede medirse de varias maneras. Los cl√∫steres Euclidianos se definen por el promedio de los valores de los puntos y contienen un 'centroide' o punto central. Las distancias se miden por la distancia a ese centroide. Las distancias no Euclidianas se refieren a 'clustroides', el punto m√°s cercano a otros puntos. Los clustroides, a su vez, pueden definirse de varias maneras.\n",
    ">\n",
    "> üéì ['Restringido'](https://wikipedia.org/wiki/Constrained_clustering)\n",
    ">\n",
    "> El [clustering restringido](https://web.cs.ucdavis.edu/~davidson/Publications/ICDMTutorial.pdf) introduce el aprendizaje 'semi-supervisado' en este m√©todo no supervisado. Las relaciones entre puntos se marcan como 'no puede enlazar' o 'debe enlazar', de modo que se imponen algunas reglas al conjunto de datos.\n",
    ">\n",
    "> Un ejemplo: Si un algoritmo se deja libre en un lote de datos no etiquetados o semi-etiquetados, los cl√∫steres que produce pueden ser de baja calidad. En el ejemplo anterior, los cl√∫steres podr√≠an agrupar 'cosas musicales redondas', 'cosas musicales cuadradas', 'cosas triangulares' y 'galletas'. Si se le dan algunas restricciones o reglas a seguir (\"el objeto debe estar hecho de pl√°stico\", \"el objeto debe ser capaz de producir m√∫sica\"), esto puede ayudar a 'restringir' el algoritmo para tomar mejores decisiones.\n",
    ">\n",
    "> üéì 'Densidad'\n",
    ">\n",
    "> Los datos que son 'ruidosos' se consideran 'densos'. Las distancias entre puntos en cada uno de sus cl√∫steres pueden resultar, al examinarlas, m√°s o menos densas, o 'congestionadas', y por lo tanto estos datos necesitan ser analizados con el m√©todo de clustering apropiado. [Este art√≠culo](https://www.kdnuggets.com/2020/02/understanding-density-based-clustering.html) demuestra la diferencia entre usar el clustering K-Means y los algoritmos HDBSCAN para explorar un conjunto de datos ruidoso con densidad de cl√∫ster desigual.\n",
    "\n",
    "Profundiza tu comprensi√≥n de las t√©cnicas de clustering en este [m√≥dulo de aprendizaje](https://docs.microsoft.com/learn/modules/train-evaluate-cluster-models?WT.mc_id=academic-77952-leestott)\n",
    "\n",
    "### **Algoritmos de clustering**\n",
    "\n",
    "Existen m√°s de 100 algoritmos de clustering, y su uso depende de la naturaleza de los datos en cuesti√≥n. Hablemos de algunos de los principales:\n",
    "\n",
    "-   **Clustering jer√°rquico**. Si un objeto se clasifica por su proximidad a un objeto cercano, en lugar de uno m√°s lejano, los cl√∫steres se forman en funci√≥n de la distancia entre sus miembros. El clustering jer√°rquico se caracteriza por combinar repetidamente dos cl√∫steres.\n",
    "\n",
    "<p>\n",
    "   <img src=\"../../images/hierarchical.png\"\n",
    "   width=\"600\"/>\n",
    "   <figcaption>Infograf√≠a por Dasani Madipalli</figcaption>\n",
    "\n",
    "-   **Clustering por centroides**. Este algoritmo popular requiere elegir 'k', o el n√∫mero de cl√∫steres a formar, despu√©s de lo cual el algoritmo determina el punto central de un cl√∫ster y agrupa los datos alrededor de ese punto. El [clustering K-means](https://wikipedia.org/wiki/K-means_clustering) es una versi√≥n popular de clustering por centroides que separa un conjunto de datos en K grupos predefinidos. El centro se determina por la media m√°s cercana, de ah√≠ el nombre. La distancia cuadrada desde el cl√∫ster se minimiza.\n",
    "\n",
    "<p>\n",
    "   <img src=\"../../images/centroid.png\"\n",
    "   width=\"600\"/>\n",
    "   <figcaption>Infograf√≠a por Dasani Madipalli</figcaption>\n",
    "\n",
    "-   **Clustering basado en distribuci√≥n**. Basado en modelos estad√≠sticos, el clustering basado en distribuci√≥n se centra en determinar la probabilidad de que un punto de datos pertenezca a un cl√∫ster y asignarlo en consecuencia. Los m√©todos de mezcla gaussiana pertenecen a este tipo.\n",
    "\n",
    "-   **Clustering basado en densidad**. Los puntos de datos se asignan a cl√∫steres en funci√≥n de su densidad, o su agrupaci√≥n entre s√≠. Los puntos de datos alejados del grupo se consideran valores at√≠picos o ruido. DBSCAN, Mean-shift y OPTICS pertenecen a este tipo de clustering.\n",
    "\n",
    "-   **Clustering basado en cuadr√≠cula**. Para conjuntos de datos multidimensionales, se crea una cuadr√≠cula y los datos se dividen entre las celdas de la cuadr√≠cula, creando as√≠ cl√∫steres.\n",
    "\n",
    "La mejor manera de aprender sobre clustering es probarlo t√∫ mismo, as√≠ que eso es lo que har√°s en este ejercicio.\n",
    "\n",
    "Necesitaremos algunos paquetes para completar este m√≥dulo. Puedes instalarlos con: `install.packages(c('tidyverse', 'tidymodels', 'DataExplorer', 'summarytools', 'plotly', 'paletteer', 'corrplot', 'patchwork'))`\n",
    "\n",
    "Alternativamente, el siguiente script verifica si tienes los paquetes necesarios para completar este m√≥dulo e instala los que falten.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "suppressWarnings(if(!require(\"pacman\")) install.packages(\"pacman\"))\r\n",
    "\r\n",
    "pacman::p_load('tidyverse', 'tidymodels', 'DataExplorer', 'summarytools', 'plotly', 'paletteer', 'corrplot', 'patchwork')\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Ejercicio - agrupa tus datos\n",
    "\n",
    "El clustering como t√©cnica se beneficia enormemente de una visualizaci√≥n adecuada, as√≠ que comencemos visualizando nuestros datos musicales. Este ejercicio nos ayudar√° a decidir cu√°l de los m√©todos de clustering deber√≠amos usar de manera m√°s efectiva seg√∫n la naturaleza de estos datos.\n",
    "\n",
    "Comencemos importando los datos.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Load the core tidyverse and make it available in your current R session\r\n",
    "library(tidyverse)\r\n",
    "\r\n",
    "# Import the data into a tibble\r\n",
    "df <- read_csv(file = \"https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/5-Clustering/data/nigerian-songs.csv\")\r\n",
    "\r\n",
    "# View the first 5 rows of the data set\r\n",
    "df %>% \r\n",
    "  slice_head(n = 5)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A veces, podemos querer un poco m√°s de informaci√≥n sobre nuestros datos. Podemos echar un vistazo a los `datos` y a `su estructura` utilizando la funci√≥n [*glimpse()*](https://pillar.r-lib.org/reference/glimpse.html):\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Glimpse into the data set\r\n",
    "df %>% \r\n",
    "  glimpse()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "¬°Buen trabajo!üí™\n",
    "\n",
    "Podemos observar que `glimpse()` te mostrar√° el n√∫mero total de filas (observaciones) y columnas (variables), seguido de las primeras entradas de cada variable en una fila despu√©s del nombre de la variable. Adem√°s, el *tipo de dato* de la variable se muestra inmediatamente despu√©s del nombre de cada variable dentro de `< >`.\n",
    "\n",
    "`DataExplorer::introduce()` puede resumir esta informaci√≥n de manera ordenada:\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Describe basic information for our data\r\n",
    "df %>% \r\n",
    "  introduce()\r\n",
    "\r\n",
    "# A visual display of the same\r\n",
    "df %>% \r\n",
    "  plot_intro()\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "¬°Genial! Acabamos de aprender que nuestros datos no tienen valores faltantes.\n",
    "\n",
    "Mientras estamos en ello, podemos explorar estad√≠sticas comunes de tendencia central (por ejemplo, [media](https://en.wikipedia.org/wiki/Arithmetic_mean) y [mediana](https://en.wikipedia.org/wiki/Median)) y medidas de dispersi√≥n (por ejemplo, [desviaci√≥n est√°ndar](https://en.wikipedia.org/wiki/Standard_deviation)) utilizando `summarytools::descr()`\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Describe common statistics\r\n",
    "df %>% \r\n",
    "  descr(stats = \"common\")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos los valores generales de los datos. Ten en cuenta que la popularidad puede ser `0`, lo que indica canciones que no tienen clasificaci√≥n. Eliminaremos esos datos en breve.\n",
    "\n",
    "> ü§î Si estamos trabajando con clustering, un m√©todo no supervisado que no requiere datos etiquetados, ¬øpor qu√© estamos mostrando estos datos con etiquetas? En la fase de exploraci√≥n de datos, son √∫tiles, pero no son necesarios para que los algoritmos de clustering funcionen.\n",
    "\n",
    "### 1. Explorar g√©neros populares\n",
    "\n",
    "Vamos a descubrir cu√°les son los g√©neros m√°s populares üé∂ haciendo un conteo de las veces que aparecen.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Popular genres\r\n",
    "top_genres <- df %>% \r\n",
    "  count(artist_top_genre, sort = TRUE) %>% \r\n",
    "# Encode to categorical and reorder the according to count\r\n",
    "  mutate(artist_top_genre = factor(artist_top_genre) %>% fct_inorder())\r\n",
    "\r\n",
    "# Print the top genres\r\n",
    "top_genres\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "¬°Eso sali√≥ bien! Dicen que una imagen vale m√°s que mil filas de un marco de datos (en realidad, nadie dice eso üòÖ). Pero entiendes la idea, ¬øverdad?\n",
    "\n",
    "Una forma de visualizar datos categ√≥ricos (variables de tipo car√°cter o factor) es utilizando gr√°ficos de barras. Hagamos un gr√°fico de barras con los 10 g√©neros principales:\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Change the default gray theme\r\n",
    "theme_set(theme_light())\r\n",
    "\r\n",
    "# Visualize popular genres\r\n",
    "top_genres %>%\r\n",
    "  slice(1:10) %>% \r\n",
    "  ggplot(mapping = aes(x = artist_top_genre, y = n,\r\n",
    "                       fill = artist_top_genre)) +\r\n",
    "  geom_col(alpha = 0.8) +\r\n",
    "  paletteer::scale_fill_paletteer_d(\"rcartocolor::Vivid\") +\r\n",
    "  ggtitle(\"Top genres\") +\r\n",
    "  theme(plot.title = element_text(hjust = 0.5),\r\n",
    "        # Rotates the X markers (so we can read them)\r\n",
    "    axis.text.x = element_text(angle = 90))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "¬°Ahora es mucho m√°s f√°cil identificar que tenemos g√©neros `missing` üßê!\n",
    "\n",
    "> Una buena visualizaci√≥n te mostrar√° cosas que no esperabas, o plantear√° nuevas preguntas sobre los datos - Hadley Wickham y Garrett Grolemund, [R For Data Science](https://r4ds.had.co.nz/introduction.html)\n",
    "\n",
    "Nota: cuando el g√©nero principal se describe como `Missing`, significa que Spotify no lo clasific√≥, as√≠ que elimin√©moslo.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Visualize popular genres\r\n",
    "top_genres %>%\r\n",
    "  filter(artist_top_genre != \"Missing\") %>% \r\n",
    "  slice(1:10) %>% \r\n",
    "  ggplot(mapping = aes(x = artist_top_genre, y = n,\r\n",
    "                       fill = artist_top_genre)) +\r\n",
    "  geom_col(alpha = 0.8) +\r\n",
    "  paletteer::scale_fill_paletteer_d(\"rcartocolor::Vivid\") +\r\n",
    "  ggtitle(\"Top genres\") +\r\n",
    "  theme(plot.title = element_text(hjust = 0.5),\r\n",
    "        # Rotates the X markers (so we can read them)\r\n",
    "    axis.text.x = element_text(angle = 90))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "A partir de la peque√±a exploraci√≥n de datos, aprendemos que los tres g√©neros principales dominan este conjunto de datos. Vamos a concentrarnos en `afro dancehall`, `afropop` y `nigerian pop`, adem√°s de filtrar el conjunto de datos para eliminar cualquier elemento con un valor de popularidad de 0 (lo que significa que no fue clasificado con una popularidad en el conjunto de datos y puede considerarse ruido para nuestros prop√≥sitos):\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "nigerian_songs <- df %>% \r\n",
    "  # Concentrate on top 3 genres\r\n",
    "  filter(artist_top_genre %in% c(\"afro dancehall\", \"afropop\",\"nigerian pop\")) %>% \r\n",
    "  # Remove unclassified observations\r\n",
    "  filter(popularity != 0)\r\n",
    "\r\n",
    "\r\n",
    "\r\n",
    "# Visualize popular genres\r\n",
    "nigerian_songs %>%\r\n",
    "  count(artist_top_genre) %>%\r\n",
    "  ggplot(mapping = aes(x = artist_top_genre, y = n,\r\n",
    "                       fill = artist_top_genre)) +\r\n",
    "  geom_col(alpha = 0.8) +\r\n",
    "  paletteer::scale_fill_paletteer_d(\"ggsci::category10_d3\") +\r\n",
    "  ggtitle(\"Top genres\") +\r\n",
    "  theme(plot.title = element_text(hjust = 0.5))\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Veamos si existe alguna relaci√≥n lineal aparente entre las variables num√©ricas de nuestro conjunto de datos. Esta relaci√≥n se cuantifica matem√°ticamente mediante la [estad√≠stica de correlaci√≥n](https://en.wikipedia.org/wiki/Correlation).\n",
    "\n",
    "La estad√≠stica de correlaci√≥n es un valor entre -1 y 1 que indica la fuerza de una relaci√≥n. Los valores por encima de 0 indican una correlaci√≥n *positiva* (valores altos de una variable tienden a coincidir con valores altos de la otra), mientras que los valores por debajo de 0 indican una correlaci√≥n *negativa* (valores altos de una variable tienden a coincidir con valores bajos de la otra).\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Narrow down to numeric variables and fid correlation\r\n",
    "corr_mat <- nigerian_songs %>% \r\n",
    "  select(where(is.numeric)) %>% \r\n",
    "  cor()\r\n",
    "\r\n",
    "# Visualize correlation matrix\r\n",
    "corrplot(corr_mat, order = 'AOE', col = c('white', 'black'), bg = 'gold2')  \r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Los datos no est√°n fuertemente correlacionados, excepto entre `energy` y `loudness`, lo cual tiene sentido, dado que la m√∫sica fuerte suele ser bastante en√©rgica. `Popularity` tiene una correspondencia con `release date`, lo que tambi√©n tiene sentido, ya que las canciones m√°s recientes probablemente sean m√°s populares. La duraci√≥n y la energ√≠a parecen tener una correlaci√≥n tambi√©n.\n",
    "\n",
    "¬°Ser√° interesante ver qu√© puede hacer un algoritmo de agrupamiento con estos datos!\n",
    "\n",
    "> üéì Ten en cuenta que la correlaci√≥n no implica causalidad. Tenemos prueba de correlaci√≥n, pero no prueba de causalidad. Un [sitio web divertido](https://tylervigen.com/spurious-correlations) tiene algunos gr√°ficos que enfatizan este punto.\n",
    "\n",
    "### 2. Explorar la distribuci√≥n de los datos\n",
    "\n",
    "Hagamos preguntas m√°s sutiles. ¬øSon los g√©neros significativamente diferentes en la percepci√≥n de su capacidad para bailar, seg√∫n su popularidad? Examinemos la distribuci√≥n de datos de nuestros tres g√©neros principales en t√©rminos de popularidad y capacidad para bailar a lo largo de un eje x y y utilizando [gr√°ficos de densidad](https://www.khanacademy.org/math/ap-statistics/density-curves-normal-distribution-ap/density-curves/v/density-curves).\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Perform 2D kernel density estimation\r\n",
    "density_estimate_2d <- nigerian_songs %>% \r\n",
    "  ggplot(mapping = aes(x = popularity, y = danceability, color = artist_top_genre)) +\r\n",
    "  geom_density_2d(bins = 5, size = 1) +\r\n",
    "  paletteer::scale_color_paletteer_d(\"RSkittleBrewer::wildberry\") +\r\n",
    "  xlim(-20, 80) +\r\n",
    "  ylim(0, 1.2)\r\n",
    "\r\n",
    "# Density plot based on the popularity\r\n",
    "density_estimate_pop <- nigerian_songs %>% \r\n",
    "  ggplot(mapping = aes(x = popularity, fill = artist_top_genre, color = artist_top_genre)) +\r\n",
    "  geom_density(size = 1, alpha = 0.5) +\r\n",
    "  paletteer::scale_fill_paletteer_d(\"RSkittleBrewer::wildberry\") +\r\n",
    "  paletteer::scale_color_paletteer_d(\"RSkittleBrewer::wildberry\") +\r\n",
    "  theme(legend.position = \"none\")\r\n",
    "\r\n",
    "# Density plot based on the danceability\r\n",
    "density_estimate_dance <- nigerian_songs %>% \r\n",
    "  ggplot(mapping = aes(x = danceability, fill = artist_top_genre, color = artist_top_genre)) +\r\n",
    "  geom_density(size = 1, alpha = 0.5) +\r\n",
    "  paletteer::scale_fill_paletteer_d(\"RSkittleBrewer::wildberry\") +\r\n",
    "  paletteer::scale_color_paletteer_d(\"RSkittleBrewer::wildberry\")\r\n",
    "\r\n",
    "\r\n",
    "# Patch everything together\r\n",
    "library(patchwork)\r\n",
    "density_estimate_2d / (density_estimate_pop + density_estimate_dance)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vemos que hay c√≠rculos conc√©ntricos que se alinean, independientemente del g√©nero. ¬øPodr√≠a ser que los gustos nigerianos convergen en cierto nivel de bailabilidad para este g√©nero?\n",
    "\n",
    "En general, los tres g√©neros se alinean en t√©rminos de su popularidad y bailabilidad. Determinar agrupaciones en estos datos ligeramente alineados ser√° un desaf√≠o. Veamos si un gr√°fico de dispersi√≥n puede respaldar esto.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# A scatter plot of popularity and danceability\r\n",
    "scatter_plot <- nigerian_songs %>% \r\n",
    "  ggplot(mapping = aes(x = popularity, y = danceability, color = artist_top_genre, shape = artist_top_genre)) +\r\n",
    "  geom_point(size = 2, alpha = 0.8) +\r\n",
    "  paletteer::scale_color_paletteer_d(\"futurevisions::mars\")\r\n",
    "\r\n",
    "# Add a touch of interactivity\r\n",
    "ggplotly(scatter_plot)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Un diagrama de dispersi√≥n de los mismos ejes muestra un patr√≥n similar de convergencia.\n",
    "\n",
    "En general, para la agrupaci√≥n, puedes usar diagramas de dispersi√≥n para mostrar grupos de datos, por lo que dominar este tipo de visualizaci√≥n es muy √∫til. En la pr√≥xima lecci√≥n, tomaremos estos datos filtrados y utilizaremos el agrupamiento k-means para descubrir grupos en estos datos que parecen superponerse de maneras interesantes.\n",
    "\n",
    "## **üöÄ Desaf√≠o**\n",
    "\n",
    "En preparaci√≥n para la pr√≥xima lecci√≥n, crea un gr√°fico sobre los diversos algoritmos de agrupamiento que podr√≠as descubrir y usar en un entorno de producci√≥n. ¬øQu√© tipos de problemas est√° tratando de resolver el agrupamiento?\n",
    "\n",
    "## [**Cuestionario posterior a la lecci√≥n**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/28/)\n",
    "\n",
    "## **Revisi√≥n y autoestudio**\n",
    "\n",
    "Antes de aplicar algoritmos de agrupamiento, como hemos aprendido, es una buena idea entender la naturaleza de tu conjunto de datos. Lee m√°s sobre este tema [aqu√≠](https://www.kdnuggets.com/2019/10/right-clustering-algorithm.html)\n",
    "\n",
    "Profundiza tu comprensi√≥n de las t√©cnicas de agrupamiento:\n",
    "\n",
    "-   [Entrena y eval√∫a modelos de agrupamiento usando Tidymodels y amigos](https://rpubs.com/eR_ic/clustering)\n",
    "\n",
    "-   Bradley Boehmke & Brandon Greenwell, [*Hands-On Machine Learning with R*](https://bradleyboehmke.github.io/HOML/)*.*\n",
    "\n",
    "## **Tarea**\n",
    "\n",
    "[Investiga otras visualizaciones para agrupamiento](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/1-Visualize/assignment.md)\n",
    "\n",
    "## AGRADECIMIENTOS A:\n",
    "\n",
    "[Jen Looper](https://www.twitter.com/jenlooper) por crear la versi√≥n original en Python de este m√≥dulo ‚ô•Ô∏è\n",
    "\n",
    "[`Dasani Madipalli`](https://twitter.com/dasani_decoded) por crear las incre√≠bles ilustraciones que hacen que los conceptos de aprendizaje autom√°tico sean m√°s interpretables y f√°ciles de entender.\n",
    "\n",
    "Feliz aprendizaje,\n",
    "\n",
    "[Eric](https://twitter.com/ericntay), Embajador Estudiantil Gold de Microsoft Learn.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Descargo de responsabilidad**:  \nEste documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": "",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  },
  "coopTranslator": {
   "original_hash": "99c36449cad3708a435f6798cfa39972",
   "translation_date": "2025-09-04T02:05:14+00:00",
   "source_file": "5-Clustering/1-Visualize/solution/R/lesson_14-R.ipynb",
   "language_code": "es"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}