{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "anaconda-cloud": "",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  },
  "colab": {
   "name": "lesson_14.ipynb",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "coopTranslator": {
   "original_hash": "ad65fb4aad0a156b42216e4929f490fc",
   "translation_date": "2025-09-04T02:17:58+00:00",
   "source_file": "5-Clustering/2-K-Means/solution/R/lesson_15-R.ipynb",
   "language_code": "es"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GULATlQXLXyR"
   },
   "source": [
    "## Explora la agrupaci√≥n K-Means usando R y los principios de datos ordenados.\n",
    "\n",
    "### [**Cuestionario previo a la lecci√≥n**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/29/)\n",
    "\n",
    "En esta lecci√≥n, aprender√°s c√≥mo crear grupos utilizando el paquete Tidymodels y otros paquetes del ecosistema de R (los llamaremos amigos üßë‚Äçü§ù‚Äçüßë), y el conjunto de datos de m√∫sica nigeriana que importaste anteriormente. Cubriremos los conceptos b√°sicos de K-Means para la agrupaci√≥n. Ten en cuenta que, como aprendiste en la lecci√≥n anterior, hay muchas formas de trabajar con agrupaciones y el m√©todo que utilices depende de tus datos. Intentaremos K-Means ya que es la t√©cnica de agrupaci√≥n m√°s com√∫n. ¬°Comencemos!\n",
    "\n",
    "T√©rminos que aprender√°s:\n",
    "\n",
    "-   Puntuaci√≥n de silueta\n",
    "\n",
    "-   M√©todo del codo\n",
    "\n",
    "-   Inercia\n",
    "\n",
    "-   Varianza\n",
    "\n",
    "### **Introducci√≥n**\n",
    "\n",
    "[La agrupaci√≥n K-Means](https://wikipedia.org/wiki/K-means_clustering) es un m√©todo derivado del dominio del procesamiento de se√±ales. Se utiliza para dividir y particionar grupos de datos en `k grupos` basados en similitudes en sus caracter√≠sticas.\n",
    "\n",
    "Los grupos pueden visualizarse como [diagramas de Voronoi](https://wikipedia.org/wiki/Voronoi_diagram), que incluyen un punto (o 'semilla') y su regi√≥n correspondiente.\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/voronoi.png\"\n",
    "   width=\"500\"/>\n",
    "   <figcaption>Infograf√≠a por Jen Looper</figcaption>\n",
    "\n",
    "\n",
    "La agrupaci√≥n K-Means tiene los siguientes pasos:\n",
    "\n",
    "1.  El cient√≠fico de datos comienza especificando el n√∫mero deseado de grupos a crear.\n",
    "\n",
    "2.  Luego, el algoritmo selecciona aleatoriamente K observaciones del conjunto de datos para servir como los centros iniciales de los grupos (es decir, los centroides).\n",
    "\n",
    "3.  A continuaci√≥n, cada una de las observaciones restantes se asigna a su centroide m√°s cercano.\n",
    "\n",
    "4.  Despu√©s, se calcula el nuevo promedio de cada grupo y el centroide se mueve al promedio.\n",
    "\n",
    "5.  Ahora que los centros han sido recalculados, cada observaci√≥n se verifica nuevamente para ver si podr√≠a estar m√°s cerca de un grupo diferente. Todos los objetos se reasignan nuevamente utilizando los promedios actualizados de los grupos. Los pasos de asignaci√≥n de grupos y actualizaci√≥n de centroides se repiten iterativamente hasta que las asignaciones de grupos dejan de cambiar (es decir, cuando se logra la convergencia). Por lo general, el algoritmo termina cuando cada nueva iteraci√≥n resulta en un movimiento insignificante de los centroides y los grupos se vuelven est√°ticos.\n",
    "\n",
    "<div>\n",
    "\n",
    "> Ten en cuenta que debido a la aleatoriedad de las observaciones iniciales k utilizadas como centroides iniciales, podemos obtener resultados ligeramente diferentes cada vez que aplicamos el procedimiento. Por esta raz√≥n, la mayor√≠a de los algoritmos utilizan varios *inicios aleatorios* y eligen la iteraci√≥n con el menor WCSS. Por lo tanto, se recomienda encarecidamente ejecutar K-Means con varios valores de *nstart* para evitar un *√≥ptimo local no deseado.*\n",
    "\n",
    "</div>\n",
    "\n",
    "Esta breve animaci√≥n utilizando la [obra](https://github.com/allisonhorst/stats-illustrations) de Allison Horst explica el proceso de agrupaci√≥n:\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/kmeans.gif\"\n",
    "   width=\"550\"/>\n",
    "   <figcaption>Obra de @allison_horst</figcaption>\n",
    "\n",
    "\n",
    "\n",
    "Una pregunta fundamental que surge en la agrupaci√≥n es esta: ¬øc√≥mo sabes cu√°ntos grupos separar en tus datos? Una desventaja de usar K-Means incluye el hecho de que necesitar√°s establecer `k`, es decir, el n√∫mero de `centroides`. Afortunadamente, el `m√©todo del codo` ayuda a estimar un buen valor inicial para `k`. Lo probar√°s en un momento.\n",
    "\n",
    "### \n",
    "\n",
    "**Requisito previo**\n",
    "\n",
    "Continuaremos justo desde donde lo dejamos en la [lecci√≥n anterior](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/1-Visualize/solution/R/lesson_14-R.ipynb), donde analizamos el conjunto de datos, hicimos muchas visualizaciones y filtramos el conjunto de datos a observaciones de inter√©s. ¬°Aseg√∫rate de revisarlo!\n",
    "\n",
    "Necesitaremos algunos paquetes para completar este m√≥dulo. Puedes instalarlos como: `install.packages(c('tidyverse', 'tidymodels', 'cluster', 'summarytools', 'plotly', 'paletteer', 'factoextra', 'patchwork'))`\n",
    "\n",
    "Alternativamente, el script a continuaci√≥n verifica si tienes los paquetes necesarios para completar este m√≥dulo y los instala por ti en caso de que falten algunos.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ah_tBi58LXyi"
   },
   "source": [
    "suppressWarnings(if(!require(\"pacman\")) install.packages(\"pacman\"))\n",
    "\n",
    "pacman::p_load('tidyverse', 'tidymodels', 'cluster', 'summarytools', 'plotly', 'paletteer', 'factoextra', 'patchwork')\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7e--UCUTLXym"
   },
   "source": [
    "¬°Vamos a ponernos en marcha!\n",
    "\n",
    "## 1. Un baile con los datos: Reduce a los 3 g√©neros musicales m√°s populares\n",
    "\n",
    "Este es un repaso de lo que hicimos en la lecci√≥n anterior. ¬°Vamos a analizar y desglosar algunos datos!\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ycamx7GGLXyn"
   },
   "source": [
    "# Load the core tidyverse and make it available in your current R session\n",
    "library(tidyverse)\n",
    "\n",
    "# Import the data into a tibble\n",
    "df <- read_csv(file = \"https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/5-Clustering/data/nigerian-songs.csv\", show_col_types = FALSE)\n",
    "\n",
    "# Narrow down to top 3 popular genres\n",
    "nigerian_songs <- df %>% \n",
    "  # Concentrate on top 3 genres\n",
    "  filter(artist_top_genre %in% c(\"afro dancehall\", \"afropop\",\"nigerian pop\")) %>% \n",
    "  # Remove unclassified observations\n",
    "  filter(popularity != 0)\n",
    "\n",
    "\n",
    "\n",
    "# Visualize popular genres using bar plots\n",
    "theme_set(theme_light())\n",
    "nigerian_songs %>%\n",
    "  count(artist_top_genre) %>%\n",
    "  ggplot(mapping = aes(x = artist_top_genre, y = n,\n",
    "                       fill = artist_top_genre)) +\n",
    "  geom_col(alpha = 0.8) +\n",
    "  paletteer::scale_fill_paletteer_d(\"ggsci::category10_d3\") +\n",
    "  ggtitle(\"Top genres\") +\n",
    "  theme(plot.title = element_text(hjust = 0.5))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5h5zmkPLXyp"
   },
   "source": [
    "ü§© ¬°Eso sali√≥ bien!\n",
    "\n",
    "## 2. M√°s exploraci√≥n de datos.\n",
    "\n",
    "¬øQu√© tan limpios est√°n estos datos? Vamos a verificar la presencia de valores at√≠picos utilizando diagramas de caja. Nos concentraremos en las columnas num√©ricas con menos valores at√≠picos (aunque podr√≠as limpiar los valores at√≠picos). Los diagramas de caja pueden mostrar el rango de los datos y ayudar a elegir qu√© columnas usar. Nota: los diagramas de caja no muestran la varianza, un elemento importante para datos que se puedan agrupar bien. Por favor, consulta [esta discusi√≥n](https://stats.stackexchange.com/questions/91536/deduce-variance-from-boxplot) para m√°s informaci√≥n.\n",
    "\n",
    "Los [diagramas de caja](https://es.wikipedia.org/wiki/Diagrama_de_caja) se utilizan para representar gr√°ficamente la distribuci√≥n de datos `num√©ricos`, as√≠ que comencemos *seleccionando* todas las columnas num√©ricas junto con los g√©neros musicales populares.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HhNreJKLLXyq"
   },
   "source": [
    "# Select top genre column and all other numeric columns\n",
    "df_numeric <- nigerian_songs %>% \n",
    "  select(artist_top_genre, where(is.numeric)) \n",
    "\n",
    "# Display the data\n",
    "df_numeric %>% \n",
    "  slice_head(n = 5)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYXrwJRaLXyq"
   },
   "source": [
    "¬øVes c√≥mo el selector `where` facilita esto üíÅ? Explora otras funciones similares [aqu√≠](https://tidyselect.r-lib.org/).\n",
    "\n",
    "Como vamos a crear un diagrama de caja para cada caracter√≠stica num√©rica y queremos evitar usar bucles, reformateemos nuestros datos a un formato *m√°s largo* que nos permita aprovechar los `facets`, es decir, subgr√°ficos que muestran un subconjunto de los datos cada uno.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gd5bR3f8LXys"
   },
   "source": [
    "# Pivot data from wide to long\n",
    "df_numeric_long <- df_numeric %>% \n",
    "  pivot_longer(!artist_top_genre, names_to = \"feature_names\", values_to = \"values\") \n",
    "\n",
    "# Print out data\n",
    "df_numeric_long %>% \n",
    "  slice_head(n = 15)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-7tE1swnLXyv"
   },
   "source": [
    "¬°Mucho m√°s largo! ¬°Ahora es momento de algunos `ggplots`! Entonces, ¬øqu√© `geom` usaremos?\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "r88bIsyuLXyy"
   },
   "source": [
    "# Make a box plot\n",
    "df_numeric_long %>% \n",
    "  ggplot(mapping = aes(x = feature_names, y = values, fill = feature_names)) +\n",
    "  geom_boxplot() +\n",
    "  facet_wrap(~ feature_names, ncol = 4, scales = \"free\") +\n",
    "  theme(legend.position = \"none\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EYVyKIUELXyz"
   },
   "source": [
    "¬°F√°cil-gg!\n",
    "\n",
    "Ahora podemos ver que estos datos est√°n un poco desordenados: al observar cada columna como un diagrama de caja, puedes notar valores at√≠picos. Podr√≠as revisar el conjunto de datos y eliminar estos valores at√≠picos, pero eso har√≠a que los datos fueran bastante m√≠nimos.\n",
    "\n",
    "Por ahora, elijamos qu√© columnas utilizaremos para nuestro ejercicio de agrupamiento. Seleccionemos las columnas num√©ricas con rangos similares. Podr√≠amos codificar `artist_top_genre` como num√©rico, pero por ahora lo descartaremos.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-wkpINyZLXy0"
   },
   "source": [
    "# Select variables with similar ranges\n",
    "df_numeric_select <- df_numeric %>% \n",
    "  select(popularity, danceability, acousticness, loudness, energy) \n",
    "\n",
    "# Normalize data\n",
    "# df_numeric_select <- scale(df_numeric_select)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D7dLzgpqLXy1"
   },
   "source": [
    "## 3. C√°lculo de agrupamiento k-means en R\n",
    "\n",
    "Podemos calcular k-means en R utilizando la funci√≥n incorporada `kmeans`. Consulta `help(\"kmeans()\")`. La funci√≥n `kmeans()` acepta un marco de datos con todas las columnas num√©ricas como su argumento principal.\n",
    "\n",
    "El primer paso al usar el agrupamiento k-means es especificar el n√∫mero de cl√∫steres (k) que se generar√°n en la soluci√≥n final. Sabemos que hay 3 g√©neros musicales que extrajimos del conjunto de datos, as√≠ que probemos con 3:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "uC4EQ5w7LXy5"
   },
   "source": [
    "set.seed(2056)\n",
    "# Kmeans clustering for 3 clusters\n",
    "kclust <- kmeans(\n",
    "  df_numeric_select,\n",
    "  # Specify the number of clusters\n",
    "  centers = 3,\n",
    "  # How many random initial configurations\n",
    "  nstart = 25\n",
    ")\n",
    "\n",
    "# Display clustering object\n",
    "kclust\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hzfhscWrLXy-"
   },
   "source": [
    "El objeto kmeans contiene varios elementos de informaci√≥n que est√°n bien explicados en `help(\"kmeans()\")`. Por ahora, enfoqu√©monos en algunos. Vemos que los datos se han agrupado en 3 clusters de tama√±os 65, 110, 111. El resultado tambi√©n incluye los centros de los clusters (medias) para los 3 grupos a trav√©s de las 5 variables.\n",
    "\n",
    "El vector de agrupamiento es la asignaci√≥n de cluster para cada observaci√≥n. Usemos la funci√≥n `augment` para agregar la asignaci√≥n de cluster al conjunto de datos original.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0XwwpFGQLXy_"
   },
   "source": [
    "# Add predicted cluster assignment to data set\n",
    "augment(kclust, df_numeric_select) %>% \n",
    "  relocate(.cluster) %>% \n",
    "  slice_head(n = 10)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NXIVXXACLXzA"
   },
   "source": [
    "Perfecto, hemos dividido nuestro conjunto de datos en un conjunto de 3 grupos. Entonces, ¬øqu√© tan bueno es nuestro agrupamiento ü§∑? Echemos un vistazo al `Silhouette score`.\n",
    "\n",
    "### **Silhouette score**\n",
    "\n",
    "El [an√°lisis de Silhouette](https://en.wikipedia.org/wiki/Silhouette_(clustering)) se puede utilizar para estudiar la distancia de separaci√≥n entre los cl√∫steres resultantes. Este puntaje var√≠a de -1 a 1, y si el puntaje est√° cerca de 1, el cl√∫ster es denso y est√° bien separado de otros cl√∫steres. Un valor cercano a 0 representa cl√∫steres superpuestos con muestras muy cercanas al l√≠mite de decisi√≥n de los cl√∫steres vecinos. [fuente](https://dzone.com/articles/kmeans-silhouette-score-explained-with-python-exam).\n",
    "\n",
    "El m√©todo de Silhouette promedio calcula el promedio de Silhouette de las observaciones para diferentes valores de *k*. Un puntaje promedio de Silhouette alto indica un buen agrupamiento.\n",
    "\n",
    "La funci√≥n `silhouette` en el paquete de cl√∫ster se utiliza para calcular el ancho promedio de Silhouette.\n",
    "\n",
    "> El Silhouette se puede calcular con cualquier [m√©trica de distancia](https://en.wikipedia.org/wiki/Distance \"Distance\"), como la [distancia euclidiana](https://en.wikipedia.org/wiki/Euclidean_distance \"Euclidean distance\") o la [distancia Manhattan](https://en.wikipedia.org/wiki/Manhattan_distance \"Manhattan distance\") que discutimos en la [lecci√≥n anterior](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/1-Visualize/solution/R/lesson_14-R.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Jn0McL28LXzB"
   },
   "source": [
    "# Load cluster package\n",
    "library(cluster)\n",
    "\n",
    "# Compute average silhouette score\n",
    "ss <- silhouette(kclust$cluster,\n",
    "                 # Compute euclidean distance\n",
    "                 dist = dist(df_numeric_select))\n",
    "mean(ss[, 3])\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyQRn97nLXzC"
   },
   "source": [
    "Nuestro puntaje es **.549**, lo que nos coloca justo en el medio. Esto indica que nuestros datos no est√°n particularmente bien adaptados a este tipo de agrupamiento. Veamos si podemos confirmar esta sospecha de manera visual. El [paquete factoextra](https://rpkgs.datanovia.com/factoextra/index.html) proporciona funciones (`fviz_cluster()`) para visualizar agrupamientos.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7a6Km1_FLXzD"
   },
   "source": [
    "library(factoextra)\n",
    "\n",
    "# Visualize clustering results\n",
    "fviz_cluster(kclust, df_numeric_select)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBwCWt-0LXzD"
   },
   "source": [
    "El solapamiento en los cl√∫steres indica que nuestros datos no son particularmente adecuados para este tipo de agrupamiento, pero sigamos adelante.\n",
    "\n",
    "## 4. Determinando el n√∫mero √≥ptimo de cl√∫steres\n",
    "\n",
    "Una pregunta fundamental que surge a menudo en el agrupamiento K-Means es esta: sin etiquetas de clase conocidas, ¬øc√≥mo sabes en cu√°ntos cl√∫steres separar tus datos?\n",
    "\n",
    "Una forma de intentar averiguarlo es usar una muestra de datos para `crear una serie de modelos de agrupamiento` con un n√∫mero creciente de cl√∫steres (por ejemplo, de 1 a 10) y evaluar m√©tricas de agrupamiento como el **√≠ndice de Silhouette.**\n",
    "\n",
    "Determinemos el n√∫mero √≥ptimo de cl√∫steres calculando el algoritmo de agrupamiento para diferentes valores de *k* y evaluando el **Suma de Cuadrados Dentro del Cl√∫ster** (WCSS, por sus siglas en ingl√©s). La suma total de cuadrados dentro del cl√∫ster (WCSS) mide la compacidad del agrupamiento, y queremos que sea lo m√°s peque√±a posible, ya que valores m√°s bajos significan que los puntos de datos est√°n m√°s cerca entre s√≠.\n",
    "\n",
    "Exploremos el efecto de diferentes elecciones de `k`, desde 1 hasta 10, en este agrupamiento.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hSeIiylDLXzE"
   },
   "source": [
    "# Create a series of clustering models\n",
    "kclusts <- tibble(k = 1:10) %>% \n",
    "  # Perform kmeans clustering for 1,2,3 ... ,10 clusters\n",
    "  mutate(model = map(k, ~ kmeans(df_numeric_select, centers = .x, nstart = 25)),\n",
    "  # Farm out clustering metrics eg WCSS\n",
    "         glanced = map(model, ~ glance(.x))) %>% \n",
    "  unnest(cols = glanced)\n",
    "  \n",
    "\n",
    "# View clustering rsulsts\n",
    "kclusts\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m7rS2U1eLXzE"
   },
   "source": [
    "Ahora que tenemos la suma total de cuadrados dentro del grupo (tot.withinss) para cada algoritmo de agrupamiento con centro *k*, utilizamos el [m√©todo del codo](https://en.wikipedia.org/wiki/Elbow_method_(clustering)) para encontrar el n√∫mero √≥ptimo de grupos. El m√©todo consiste en graficar la WCSS como una funci√≥n del n√∫mero de grupos y elegir el [codo de la curva](https://en.wikipedia.org/wiki/Elbow_of_the_curve \"Elbow of the curve\") como el n√∫mero de grupos a utilizar.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "o_DjHGItLXzF"
   },
   "source": [
    "set.seed(2056)\n",
    "# Use elbow method to determine optimum number of clusters\n",
    "kclusts %>% \n",
    "  ggplot(mapping = aes(x = k, y = tot.withinss)) +\n",
    "  geom_line(size = 1.2, alpha = 0.8, color = \"#FF7F0EFF\") +\n",
    "  geom_point(size = 2, color = \"#FF7F0EFF\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pLYyt5XSLXzG"
   },
   "source": [
    "El gr√°fico muestra una gran reducci√≥n en WCSS (lo que indica una mayor *cohesi√≥n*) a medida que el n√∫mero de cl√∫steres aumenta de uno a dos, y una reducci√≥n adicional notable de dos a tres cl√∫steres. Despu√©s de eso, la reducci√≥n es menos pronunciada, lo que da lugar a un `codo` üí™ en el gr√°fico alrededor de tres cl√∫steres. Esto es una buena indicaci√≥n de que hay dos o tres cl√∫steres de puntos de datos razonablemente bien separados.\n",
    "\n",
    "Ahora podemos proceder a extraer el modelo de clustering donde `k = 3`:\n",
    "\n",
    "> `pull()`: se utiliza para extraer una sola columna  \n",
    ">  \n",
    "> `pluck()`: se utiliza para indexar estructuras de datos como listas  \n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "JP_JPKBILXzG"
   },
   "source": [
    "# Extract k = 3 clustering\n",
    "final_kmeans <- kclusts %>% \n",
    "  filter(k == 3) %>% \n",
    "  pull(model) %>% \n",
    "  pluck(1)\n",
    "\n",
    "\n",
    "final_kmeans\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_PDTu8tLXzI"
   },
   "source": [
    "¬°Genial! Vamos a visualizar los cl√∫steres obtenidos. ¬øTe interesa algo de interactividad usando `plotly`?\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dNcleFe-LXzJ"
   },
   "source": [
    "# Add predicted cluster assignment to data set\n",
    "results <-  augment(final_kmeans, df_numeric_select) %>% \n",
    "  bind_cols(df_numeric %>% select(artist_top_genre)) \n",
    "\n",
    "# Plot cluster assignments\n",
    "clust_plt <- results %>% \n",
    "  ggplot(mapping = aes(x = popularity, y = danceability, color = .cluster, shape = artist_top_genre)) +\n",
    "  geom_point(size = 2, alpha = 0.8) +\n",
    "  paletteer::scale_color_paletteer_d(\"ggthemes::Tableau_10\")\n",
    "\n",
    "ggplotly(clust_plt)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6JUM_51VLXzK"
   },
   "source": [
    "Quiz√°s hubi√©ramos esperado que cada cl√∫ster (representado por diferentes colores) tuviera g√©neros distintos (representados por diferentes formas).\n",
    "\n",
    "Echemos un vistazo a la precisi√≥n del modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HdIMUGq7LXzL"
   },
   "source": [
    "# Assign genres to predefined integers\n",
    "label_count <- results %>% \n",
    "  group_by(artist_top_genre) %>% \n",
    "  mutate(id = cur_group_id()) %>% \n",
    "  ungroup() %>% \n",
    "  summarise(correct_labels = sum(.cluster == id))\n",
    "\n",
    "\n",
    "# Print results  \n",
    "cat(\"Result:\", label_count$correct_labels, \"out of\", nrow(results), \"samples were correctly labeled.\")\n",
    "\n",
    "cat(\"\\nAccuracy score:\", label_count$correct_labels/nrow(results))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C50wvaAOLXzM"
   },
   "source": [
    "La precisi√≥n de este modelo no est√° mal, pero tampoco es excelente. Puede ser que los datos no se presten bien para el uso de K-Means Clustering. Estos datos est√°n demasiado desequilibrados, tienen poca correlaci√≥n y existe demasiada variabilidad entre los valores de las columnas como para agruparlos de manera efectiva. De hecho, los cl√∫steres que se forman probablemente est√°n muy influenciados o sesgados por las tres categor√≠as de g√©neros que definimos anteriormente.\n",
    "\n",
    "¬°Aun as√≠, fue un proceso de aprendizaje interesante!\n",
    "\n",
    "En la documentaci√≥n de Scikit-learn, puedes ver que un modelo como este, con cl√∫steres no muy bien definidos, tiene un problema de 'varianza':\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/problems.png\"\n",
    "   width=\"500\"/>\n",
    "   <figcaption>Infograf√≠a de Scikit-learn</figcaption>\n",
    "\n",
    "\n",
    "\n",
    "## **Varianza**\n",
    "\n",
    "La varianza se define como \"el promedio de las diferencias al cuadrado respecto a la media\" [fuente](https://www.mathsisfun.com/data/standard-deviation.html). En el contexto de este problema de clustering, se refiere a que los n√∫meros de nuestro conjunto de datos tienden a divergir demasiado de la media.\n",
    "\n",
    "‚úÖ Este es un gran momento para pensar en todas las formas en que podr√≠as corregir este problema. ¬øAjustar un poco m√°s los datos? ¬øUsar diferentes columnas? ¬øProbar con un algoritmo distinto? Pista: Intenta [escalar tus datos](https://www.mygreatlearning.com/blog/learning-data-science-with-k-means-clustering/) para normalizarlos y prueba con otras columnas.\n",
    "\n",
    "> Prueba este '[calculador de varianza](https://www.calculatorsoup.com/calculators/statistics/variance-calculator.php)' para entender un poco m√°s el concepto.\n",
    "\n",
    "------------------------------------------------------------------------\n",
    "\n",
    "## **üöÄDesaf√≠o**\n",
    "\n",
    "Dedica algo de tiempo a este notebook ajustando par√°metros. ¬øPuedes mejorar la precisi√≥n del modelo limpiando m√°s los datos (eliminando valores at√≠picos, por ejemplo)? Puedes usar pesos para dar m√°s importancia a ciertas muestras de datos. ¬øQu√© m√°s podr√≠as hacer para crear mejores cl√∫steres?\n",
    "\n",
    "Pista: Intenta escalar tus datos. Hay c√≥digo comentado en el notebook que agrega escalado est√°ndar para hacer que las columnas de datos se parezcan m√°s entre s√≠ en t√©rminos de rango. Descubrir√°s que, aunque el puntaje de silueta disminuye, el 'codo' en el gr√°fico de codo se suaviza. Esto se debe a que dejar los datos sin escalar permite que los datos con menos varianza tengan m√°s peso. Lee un poco m√°s sobre este problema [aqu√≠](https://stats.stackexchange.com/questions/21222/are-mean-normalization-and-feature-scaling-needed-for-k-means-clustering/21226#21226).\n",
    "\n",
    "## [**Cuestionario posterior a la lecci√≥n**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/30/)\n",
    "\n",
    "## **Revisi√≥n y Autoestudio**\n",
    "\n",
    "-   Echa un vistazo a un simulador de K-Means [como este](https://user.ceng.metu.edu.tr/~akifakkus/courses/ceng574/k-means/). Puedes usar esta herramienta para visualizar puntos de datos de muestra y determinar sus centroides. Puedes editar la aleatoriedad de los datos, el n√∫mero de cl√∫steres y el n√∫mero de centroides. ¬øTe ayuda esto a tener una idea de c√≥mo se pueden agrupar los datos?\n",
    "\n",
    "-   Tambi√©n, revisa [este documento sobre K-Means](https://stanford.edu/~cpiech/cs221/handouts/kmeans.html) de Stanford.\n",
    "\n",
    "¬øQuieres probar tus reci√©n adquiridas habilidades de clustering en conjuntos de datos que se presten bien para K-Means clustering? Consulta:\n",
    "\n",
    "-   [Entrenar y Evaluar Modelos de Clustering](https://rpubs.com/eR_ic/clustering) usando Tidymodels y amigos\n",
    "\n",
    "-   [An√°lisis de Cl√∫steres K-Means](https://uc-r.github.io/kmeans_clustering), Gu√≠a de Programaci√≥n en R para An√°lisis de Negocios de UC\n",
    "\n",
    "- [Clustering K-Means con principios de datos ordenados](https://www.tidymodels.org/learn/statistics/k-means/)\n",
    "\n",
    "## **Tarea**\n",
    "\n",
    "[Prueba diferentes m√©todos de clustering](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/2-K-Means/assignment.md)\n",
    "\n",
    "## AGRADECIMIENTOS A:\n",
    "\n",
    "[Jen Looper](https://www.twitter.com/jenlooper) por crear la versi√≥n original en Python de este m√≥dulo ‚ô•Ô∏è\n",
    "\n",
    "[`Allison Horst`](https://twitter.com/allison_horst/) por crear las incre√≠bles ilustraciones que hacen que R sea m√°s accesible y atractivo. Encuentra m√°s ilustraciones en su [galer√≠a](https://www.google.com/url?q=https://github.com/allisonhorst/stats-illustrations&sa=D&source=editors&ust=1626380772530000&usg=AOvVaw3zcfyCizFQZpkSLzxiiQEM).\n",
    "\n",
    "Feliz aprendizaje,\n",
    "\n",
    "[Eric](https://twitter.com/ericntay), Embajador Estudiantil Gold de Microsoft Learn.\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/r_learners_sm.jpeg\"\n",
    "   width=\"500\"/>\n",
    "   <figcaption>Arte de @allison_horst</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Descargo de responsabilidad**:  \nEste documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.\n"
   ]
  }
 ]
}