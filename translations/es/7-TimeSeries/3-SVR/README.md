<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f80e513b3279869e7661e3190cc83076",
  "translation_date": "2025-09-03T22:53:22+00:00",
  "source_file": "7-TimeSeries/3-SVR/README.md",
  "language_code": "es"
}
-->
# Pron칩stico de Series Temporales con Support Vector Regressor

En la lecci칩n anterior, aprendiste a usar el modelo ARIMA para realizar predicciones de series temporales. Ahora exploraremos el modelo Support Vector Regressor, que es un modelo de regresi칩n utilizado para predecir datos continuos.

## [Cuestionario previo a la lecci칩n](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/51/) 

## Introducci칩n

En esta lecci칩n, descubrir치s una forma espec칤fica de construir modelos con [**SVM**: **S**upport **V**ector **M**achine](https://en.wikipedia.org/wiki/Support-vector_machine) para regresi칩n, o **SVR: Support Vector Regressor**. 

### SVR en el contexto de series temporales [^1]

Antes de entender la importancia de SVR en la predicci칩n de series temporales, aqu칤 tienes algunos conceptos importantes que necesitas conocer:

- **Regresi칩n:** T칠cnica de aprendizaje supervisado para predecir valores continuos a partir de un conjunto de entradas. La idea es ajustar una curva (o l칤nea) en el espacio de caracter칤sticas que tenga el mayor n칰mero de puntos de datos. [Haz clic aqu칤](https://en.wikipedia.org/wiki/Regression_analysis) para m치s informaci칩n.
- **Support Vector Machine (SVM):** Un tipo de modelo de aprendizaje supervisado utilizado para clasificaci칩n, regresi칩n y detecci칩n de valores at칤picos. El modelo es un hiperplano en el espacio de caracter칤sticas, que en el caso de la clasificaci칩n act칰a como un l칤mite, y en el caso de la regresi칩n act칰a como la l칤nea de mejor ajuste. En SVM, generalmente se utiliza una funci칩n Kernel para transformar el conjunto de datos a un espacio de mayor n칰mero de dimensiones, de modo que puedan ser f치cilmente separables. [Haz clic aqu칤](https://en.wikipedia.org/wiki/Support-vector_machine) para m치s informaci칩n sobre SVMs.
- **Support Vector Regressor (SVR):** Un tipo de SVM, que encuentra la l칤nea de mejor ajuste (que en el caso de SVM es un hiperplano) que tiene el mayor n칰mero de puntos de datos.

### 쯇or qu칠 SVR? [^1]

En la 칰ltima lecci칩n aprendiste sobre ARIMA, que es un m칠todo estad칤stico lineal muy exitoso para pronosticar datos de series temporales. Sin embargo, en muchos casos, los datos de series temporales tienen *no linealidad*, que no puede ser modelada por modelos lineales. En tales casos, la capacidad de SVM para considerar la no linealidad en los datos para tareas de regresi칩n hace que SVR sea exitoso en el pron칩stico de series temporales.

## Ejercicio - construir un modelo SVR

Los primeros pasos para la preparaci칩n de datos son los mismos que en la lecci칩n anterior sobre [ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA). 

Abre la carpeta [_/working_](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/3-SVR/working) en esta lecci칩n y encuentra el archivo [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/7-TimeSeries/3-SVR/working/notebook.ipynb). [^2]

1. Ejecuta el notebook e importa las bibliotecas necesarias: [^2]

   ```python
   import sys
   sys.path.append('../../')
   ```

   ```python
   import os
   import warnings
   import matplotlib.pyplot as plt
   import numpy as np
   import pandas as pd
   import datetime as dt
   import math
   
   from sklearn.svm import SVR
   from sklearn.preprocessing import MinMaxScaler
   from common.utils import load_data, mape
   ```

2. Carga los datos del archivo `/data/energy.csv` en un dataframe de Pandas y 칠chales un vistazo: [^2]

   ```python
   energy = load_data('../../data')[['load']]
   ```

3. Grafica todos los datos de energ칤a disponibles desde enero de 2012 hasta diciembre de 2014: [^2]

   ```python
   energy.plot(y='load', subplots=True, figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![datos completos](../../../../translated_images/full-data.a82ec9957e580e976f651a4fc38f280b9229c6efdbe3cfe7c60abaa9486d2cbe.es.png)

   Ahora, construyamos nuestro modelo SVR.

### Crear conjuntos de entrenamiento y prueba

Ahora que tus datos est치n cargados, puedes separarlos en conjuntos de entrenamiento y prueba. Luego, reformatear치s los datos para crear un conjunto de datos basado en pasos de tiempo que ser치 necesario para el SVR. Entrenar치s tu modelo en el conjunto de entrenamiento. Una vez que el modelo haya terminado de entrenarse, evaluar치s su precisi칩n en el conjunto de entrenamiento, el conjunto de prueba y luego en el conjunto de datos completo para ver el rendimiento general. Debes asegurarte de que el conjunto de prueba cubra un per칤odo posterior en el tiempo al conjunto de entrenamiento para garantizar que el modelo no obtenga informaci칩n de per칤odos futuros [^2] (una situaci칩n conocida como *sobreajuste*).

1. Asigna un per칤odo de dos meses del 1 de septiembre al 31 de octubre de 2014 al conjunto de entrenamiento. El conjunto de prueba incluir치 el per칤odo de dos meses del 1 de noviembre al 31 de diciembre de 2014: [^2]

   ```python
   train_start_dt = '2014-11-01 00:00:00'
   test_start_dt = '2014-12-30 00:00:00'
   ```

2. Visualiza las diferencias: [^2]

   ```python
   energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)][['load']].rename(columns={'load':'train'}) \
       .join(energy[test_start_dt:][['load']].rename(columns={'load':'test'}), how='outer') \
       .plot(y=['train', 'test'], figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![datos de entrenamiento y prueba](../../../../translated_images/train-test.ead0cecbfc341921d4875eccf25fed5eefbb860cdbb69cabcc2276c49e4b33e5.es.png)

### Preparar los datos para el entrenamiento

Ahora necesitas preparar los datos para el entrenamiento realizando un filtrado y escalado de tus datos. Filtra tu conjunto de datos para incluir solo los per칤odos de tiempo y columnas necesarios, y escala los datos para asegurarte de que est칠n proyectados en el intervalo 0,1.

1. Filtra el conjunto de datos original para incluir solo los per칤odos de tiempo mencionados por conjunto e incluyendo 칰nicamente la columna 'load' m치s la fecha: [^2]

   ```python
   train = energy.copy()[(energy.index >= train_start_dt) & (energy.index < test_start_dt)][['load']]
   test = energy.copy()[energy.index >= test_start_dt][['load']]
   
   print('Training data shape: ', train.shape)
   print('Test data shape: ', test.shape)
   ```

   ```output
   Training data shape:  (1416, 1)
   Test data shape:  (48, 1)
   ```
   
2. Escala los datos de entrenamiento para que est칠n en el rango (0, 1): [^2]

   ```python
   scaler = MinMaxScaler()
   train['load'] = scaler.fit_transform(train)
   ```
   
4. Ahora, escala los datos de prueba: [^2]

   ```python
   test['load'] = scaler.transform(test)
   ```

### Crear datos con pasos de tiempo [^1]

Para el SVR, transformas los datos de entrada para que tengan la forma `[batch, timesteps]`. Por lo tanto, reformateas los `train_data` y `test_data` existentes de manera que haya una nueva dimensi칩n que se refiera a los pasos de tiempo.

```python
# Converting to numpy arrays
train_data = train.values
test_data = test.values
```

En este ejemplo, tomamos `timesteps = 5`. Por lo tanto, las entradas al modelo son los datos de los primeros 4 pasos de tiempo, y la salida ser치n los datos del quinto paso de tiempo.

```python
timesteps=5
```

Convirtiendo los datos de entrenamiento a un tensor 2D usando comprensi칩n de listas anidadas:

```python
train_data_timesteps=np.array([[j for j in train_data[i:i+timesteps]] for i in range(0,len(train_data)-timesteps+1)])[:,:,0]
train_data_timesteps.shape
```

```output
(1412, 5)
```

Convirtiendo los datos de prueba a un tensor 2D:

```python
test_data_timesteps=np.array([[j for j in test_data[i:i+timesteps]] for i in range(0,len(test_data)-timesteps+1)])[:,:,0]
test_data_timesteps.shape
```

```output
(44, 5)
```

Seleccionando entradas y salidas de los datos de entrenamiento y prueba:

```python
x_train, y_train = train_data_timesteps[:,:timesteps-1],train_data_timesteps[:,[timesteps-1]]
x_test, y_test = test_data_timesteps[:,:timesteps-1],test_data_timesteps[:,[timesteps-1]]

print(x_train.shape, y_train.shape)
print(x_test.shape, y_test.shape)
```

```output
(1412, 4) (1412, 1)
(44, 4) (44, 1)
```

### Implementar SVR [^1]

Ahora es momento de implementar SVR. Para leer m치s sobre esta implementaci칩n, puedes consultar [esta documentaci칩n](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html). Para nuestra implementaci칩n, seguimos estos pasos:

  1. Define el modelo llamando a `SVR()` y pasando los hiperpar치metros del modelo: kernel, gamma, c y epsilon.
  2. Prepara el modelo para los datos de entrenamiento llamando a la funci칩n `fit()`.
  3. Realiza predicciones llamando a la funci칩n `predict()`.

Ahora creamos un modelo SVR. Aqu칤 usamos el [kernel RBF](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel), y configuramos los hiperpar치metros gamma, C y epsilon como 0.5, 10 y 0.05 respectivamente.

```python
model = SVR(kernel='rbf',gamma=0.5, C=10, epsilon = 0.05)
```

#### Ajustar el modelo a los datos de entrenamiento [^1]

```python
model.fit(x_train, y_train[:,0])
```

```output
SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.05, gamma=0.5,
    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)
```

#### Realizar predicciones con el modelo [^1]

```python
y_train_pred = model.predict(x_train).reshape(-1,1)
y_test_pred = model.predict(x_test).reshape(-1,1)

print(y_train_pred.shape, y_test_pred.shape)
```

```output
(1412, 1) (44, 1)
```

춰Has construido tu SVR! Ahora necesitamos evaluarlo.

### Evaluar tu modelo [^1]

Para la evaluaci칩n, primero escalaremos los datos de vuelta a su escala original. Luego, para verificar el rendimiento, graficaremos la serie temporal original y la predicha, y tambi칠n imprimiremos el resultado de MAPE.

Escala la salida predicha y la original:

```python
# Scaling the predictions
y_train_pred = scaler.inverse_transform(y_train_pred)
y_test_pred = scaler.inverse_transform(y_test_pred)

print(len(y_train_pred), len(y_test_pred))
```

```python
# Scaling the original values
y_train = scaler.inverse_transform(y_train)
y_test = scaler.inverse_transform(y_test)

print(len(y_train), len(y_test))
```

#### Verificar el rendimiento del modelo en los datos de entrenamiento y prueba [^1]

Extraemos las marcas de tiempo del conjunto de datos para mostrarlas en el eje x de nuestro gr치fico. Ten en cuenta que estamos usando los primeros ```timesteps-1``` valores como entrada para la primera salida, por lo que las marcas de tiempo para la salida comenzar치n despu칠s de eso.

```python
train_timestamps = energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)].index[timesteps-1:]
test_timestamps = energy[test_start_dt:].index[timesteps-1:]

print(len(train_timestamps), len(test_timestamps))
```

```output
1412 44
```

Grafica las predicciones para los datos de entrenamiento:

```python
plt.figure(figsize=(25,6))
plt.plot(train_timestamps, y_train, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(train_timestamps, y_train_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.title("Training data prediction")
plt.show()
```

![predicci칩n de datos de entrenamiento](../../../../translated_images/train-data-predict.3c4ef4e78553104ffdd53d47a4c06414007947ea328e9261ddf48d3eafdefbbf.es.png)

Imprime MAPE para los datos de entrenamiento:

```python
print('MAPE for training data: ', mape(y_train_pred, y_train)*100, '%')
```

```output
MAPE for training data: 1.7195710200875551 %
```

Grafica las predicciones para los datos de prueba:

```python
plt.figure(figsize=(10,3))
plt.plot(test_timestamps, y_test, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(test_timestamps, y_test_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![predicci칩n de datos de prueba](../../../../translated_images/test-data-predict.8afc47ee7e52874f514ebdda4a798647e9ecf44a97cc927c535246fcf7a28aa9.es.png)

Imprime MAPE para los datos de prueba:

```python
print('MAPE for testing data: ', mape(y_test_pred, y_test)*100, '%')
```

```output
MAPE for testing data:  1.2623790187854018 %
```

游끥 춰Tienes un muy buen resultado en el conjunto de datos de prueba!

### Verificar el rendimiento del modelo en el conjunto de datos completo [^1]

```python
# Extracting load values as numpy array
data = energy.copy().values

# Scaling
data = scaler.transform(data)

# Transforming to 2D tensor as per model input requirement
data_timesteps=np.array([[j for j in data[i:i+timesteps]] for i in range(0,len(data)-timesteps+1)])[:,:,0]
print("Tensor shape: ", data_timesteps.shape)

# Selecting inputs and outputs from data
X, Y = data_timesteps[:,:timesteps-1],data_timesteps[:,[timesteps-1]]
print("X shape: ", X.shape,"\nY shape: ", Y.shape)
```

```output
Tensor shape:  (26300, 5)
X shape:  (26300, 4) 
Y shape:  (26300, 1)
```

```python
# Make model predictions
Y_pred = model.predict(X).reshape(-1,1)

# Inverse scale and reshape
Y_pred = scaler.inverse_transform(Y_pred)
Y = scaler.inverse_transform(Y)
```

```python
plt.figure(figsize=(30,8))
plt.plot(Y, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(Y_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![predicci칩n de datos completos](../../../../translated_images/full-data-predict.4f0fed16a131c8f3bcc57a3060039dc7f2f714a05b07b68c513e0fe7fb3d8964.es.png)

```python
print('MAPE: ', mape(Y_pred, Y)*100, '%')
```

```output
MAPE:  2.0572089029888656 %
```

游끥 Muy buenos gr치ficos, mostrando un modelo con buena precisi칩n. 춰Bien hecho!

---

## 游Desaf칤o

- Intenta ajustar los hiperpar치metros (gamma, C, epsilon) al crear el modelo y eval칰alo en los datos para ver qu칠 conjunto de hiperpar치metros da los mejores resultados en los datos de prueba. Para saber m치s sobre estos hiperpar치metros, puedes consultar el documento [aqu칤](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel). 
- Intenta usar diferentes funciones kernel para el modelo y analiza su rendimiento en el conjunto de datos. Un documento 칰til se encuentra [aqu칤](https://scikit-learn.org/stable/modules/svm.html#kernel-functions).
- Intenta usar diferentes valores para `timesteps` para que el modelo mire hacia atr치s y haga predicciones.

## [Cuestionario posterior a la lecci칩n](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/52/)

## Revisi칩n y Autoestudio

Esta lecci칩n fue una introducci칩n a la aplicaci칩n de SVR para el pron칩stico de series temporales. Para leer m치s sobre SVR, puedes consultar [este blog](https://www.analyticsvidhya.com/blog/2020/03/support-vector-regression-tutorial-for-machine-learning/). Esta [documentaci칩n en scikit-learn](https://scikit-learn.org/stable/modules/svm.html) proporciona una explicaci칩n m치s completa sobre SVMs en general, [SVRs](https://scikit-learn.org/stable/modules/svm.html#regression) y tambi칠n otros detalles de implementaci칩n como las diferentes [funciones kernel](https://scikit-learn.org/stable/modules/svm.html#kernel-functions) que se pueden usar y sus par치metros.

## Tarea

[Un nuevo modelo SVR](assignment.md)

## Cr칠ditos

[^1]: El texto, c칩digo y resultados en esta secci칩n fueron contribuidos por [@AnirbanMukherjeeXD](https://github.com/AnirbanMukherjeeXD)  
[^2]: El texto, c칩digo y resultados en esta secci칩n fueron tomados de [ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci칩n autom치tica [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por lograr precisi칩n, tenga en cuenta que las traducciones autom치ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci칩n cr칤tica, se recomienda una traducci칩n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err칩neas que puedan surgir del uso de esta traducci칩n.