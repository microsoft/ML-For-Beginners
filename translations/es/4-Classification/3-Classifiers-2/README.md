<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "49047911108adc49d605cddfb455749c",
  "translation_date": "2025-09-04T22:24:07+00:00",
  "source_file": "4-Classification/3-Classifiers-2/README.md",
  "language_code": "es"
}
-->
# Clasificadores de cocina 2

En esta segunda lecci√≥n de clasificaci√≥n, explorar√°s m√°s formas de clasificar datos num√©ricos. Tambi√©n aprender√°s sobre las implicaciones de elegir un clasificador sobre otro.

## [Cuestionario previo a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

### Prerrequisitos

Asumimos que has completado las lecciones anteriores y tienes un conjunto de datos limpio en tu carpeta `data` llamado _cleaned_cuisines.csv_ en la ra√≠z de esta carpeta de 4 lecciones.

### Preparaci√≥n

Hemos cargado tu archivo _notebook.ipynb_ con el conjunto de datos limpio y lo hemos dividido en los dataframes X e y, listos para el proceso de construcci√≥n del modelo.

## Un mapa de clasificaci√≥n

Anteriormente, aprendiste sobre las diversas opciones que tienes al clasificar datos utilizando la hoja de referencia de Microsoft. Scikit-learn ofrece una hoja de referencia similar, pero m√°s detallada, que puede ayudarte a√∫n m√°s a reducir tus estimadores (otro t√©rmino para clasificadores):

![Mapa de ML de Scikit-learn](../../../../4-Classification/3-Classifiers-2/images/map.png)
> Consejo: [visita este mapa en l√≠nea](https://scikit-learn.org/stable/tutorial/machine_learning_map/) y haz clic en el camino para leer la documentaci√≥n.

### El plan

Este mapa es muy √∫til una vez que tienes una comprensi√≥n clara de tus datos, ya que puedes "caminar" por sus caminos hacia una decisi√≥n:

- Tenemos >50 muestras
- Queremos predecir una categor√≠a
- Tenemos datos etiquetados
- Tenemos menos de 100K muestras
- ‚ú® Podemos elegir un Linear SVC
- Si eso no funciona, dado que tenemos datos num√©ricos
    - Podemos intentar un ‚ú® KNeighbors Classifier 
      - Si eso no funciona, probar ‚ú® SVC y ‚ú® Ensemble Classifiers

Este es un camino muy √∫til a seguir.

## Ejercicio - dividir los datos

Siguiendo este camino, deber√≠amos comenzar importando algunas bibliotecas para usar.

1. Importa las bibliotecas necesarias:

    ```python
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    import numpy as np
    ```

1. Divide tus datos de entrenamiento y prueba:

    ```python
    X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)
    ```

## Clasificador Linear SVC

El clustering de vectores de soporte (SVC) es un miembro de la familia de t√©cnicas de ML de m√°quinas de vectores de soporte (aprende m√°s sobre estas abajo). En este m√©todo, puedes elegir un 'kernel' para decidir c√≥mo agrupar las etiquetas. El par√°metro 'C' se refiere a la 'regularizaci√≥n', que regula la influencia de los par√°metros. El kernel puede ser uno de [varios](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC); aqu√≠ lo configuramos como 'linear' para asegurarnos de aprovechar el Linear SVC. La probabilidad por defecto es 'false'; aqu√≠ la configuramos como 'true' para obtener estimaciones de probabilidad. Configuramos el estado aleatorio en '0' para mezclar los datos y obtener probabilidades.

### Ejercicio - aplicar un Linear SVC

Comienza creando un array de clasificadores. Ir√°s a√±adiendo progresivamente a este array mientras probamos.

1. Comienza con un Linear SVC:

    ```python
    C = 10
    # Create different classifiers.
    classifiers = {
        'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0)
    }
    ```

2. Entrena tu modelo usando el Linear SVC e imprime un informe:

    ```python
    n_classifiers = len(classifiers)
    
    for index, (name, classifier) in enumerate(classifiers.items()):
        classifier.fit(X_train, np.ravel(y_train))
    
        y_pred = classifier.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print("Accuracy (train) for %s: %0.1f%% " % (name, accuracy * 100))
        print(classification_report(y_test,y_pred))
    ```

    El resultado es bastante bueno:

    ```output
    Accuracy (train) for Linear SVC: 78.6% 
                  precision    recall  f1-score   support
    
         chinese       0.71      0.67      0.69       242
          indian       0.88      0.86      0.87       234
        japanese       0.79      0.74      0.76       254
          korean       0.85      0.81      0.83       242
            thai       0.71      0.86      0.78       227
    
        accuracy                           0.79      1199
       macro avg       0.79      0.79      0.79      1199
    weighted avg       0.79      0.79      0.79      1199
    ```

## Clasificador K-Neighbors

K-Neighbors es parte de la familia de m√©todos de ML "neighbors", que pueden ser utilizados tanto para aprendizaje supervisado como no supervisado. En este m√©todo, se crea un n√∫mero predefinido de puntos y se recopilan datos alrededor de estos puntos para que se puedan predecir etiquetas generalizadas para los datos.

### Ejercicio - aplicar el clasificador K-Neighbors

El clasificador anterior fue bueno y funcion√≥ bien con los datos, pero tal vez podamos obtener mejor precisi√≥n. Prueba un clasificador K-Neighbors.

1. A√±ade una l√≠nea a tu array de clasificadores (a√±ade una coma despu√©s del elemento Linear SVC):

    ```python
    'KNN classifier': KNeighborsClassifier(C),
    ```

    El resultado es un poco peor:

    ```output
    Accuracy (train) for KNN classifier: 73.8% 
                  precision    recall  f1-score   support
    
         chinese       0.64      0.67      0.66       242
          indian       0.86      0.78      0.82       234
        japanese       0.66      0.83      0.74       254
          korean       0.94      0.58      0.72       242
            thai       0.71      0.82      0.76       227
    
        accuracy                           0.74      1199
       macro avg       0.76      0.74      0.74      1199
    weighted avg       0.76      0.74      0.74      1199
    ```

    ‚úÖ Aprende sobre [K-Neighbors](https://scikit-learn.org/stable/modules/neighbors.html#neighbors)

## Clasificador de vectores de soporte

Los clasificadores de vectores de soporte son parte de la familia de [m√°quinas de vectores de soporte](https://wikipedia.org/wiki/Support-vector_machine) de m√©todos de ML que se utilizan para tareas de clasificaci√≥n y regresi√≥n. Las SVM "mapean ejemplos de entrenamiento a puntos en el espacio" para maximizar la distancia entre dos categor√≠as. Los datos posteriores se mapean en este espacio para que se pueda predecir su categor√≠a.

### Ejercicio - aplicar un clasificador de vectores de soporte

Intentemos obtener una mejor precisi√≥n con un clasificador de vectores de soporte.

1. A√±ade una coma despu√©s del elemento K-Neighbors y luego a√±ade esta l√≠nea:

    ```python
    'SVC': SVC(),
    ```

    ¬°El resultado es bastante bueno!

    ```output
    Accuracy (train) for SVC: 83.2% 
                  precision    recall  f1-score   support
    
         chinese       0.79      0.74      0.76       242
          indian       0.88      0.90      0.89       234
        japanese       0.87      0.81      0.84       254
          korean       0.91      0.82      0.86       242
            thai       0.74      0.90      0.81       227
    
        accuracy                           0.83      1199
       macro avg       0.84      0.83      0.83      1199
    weighted avg       0.84      0.83      0.83      1199
    ```

    ‚úÖ Aprende sobre [vectores de soporte](https://scikit-learn.org/stable/modules/svm.html#svm)

## Clasificadores Ensemble

Sigamos el camino hasta el final, aunque la prueba anterior fue bastante buena. Probemos algunos clasificadores Ensemble, espec√≠ficamente Random Forest y AdaBoost:

```python
  'RFST': RandomForestClassifier(n_estimators=100),
  'ADA': AdaBoostClassifier(n_estimators=100)
```

El resultado es muy bueno, especialmente para Random Forest:

```output
Accuracy (train) for RFST: 84.5% 
              precision    recall  f1-score   support

     chinese       0.80      0.77      0.78       242
      indian       0.89      0.92      0.90       234
    japanese       0.86      0.84      0.85       254
      korean       0.88      0.83      0.85       242
        thai       0.80      0.87      0.83       227

    accuracy                           0.84      1199
   macro avg       0.85      0.85      0.84      1199
weighted avg       0.85      0.84      0.84      1199

Accuracy (train) for ADA: 72.4% 
              precision    recall  f1-score   support

     chinese       0.64      0.49      0.56       242
      indian       0.91      0.83      0.87       234
    japanese       0.68      0.69      0.69       254
      korean       0.73      0.79      0.76       242
        thai       0.67      0.83      0.74       227

    accuracy                           0.72      1199
   macro avg       0.73      0.73      0.72      1199
weighted avg       0.73      0.72      0.72      1199
```

‚úÖ Aprende sobre [clasificadores Ensemble](https://scikit-learn.org/stable/modules/ensemble.html)

Este m√©todo de aprendizaje autom√°tico "combina las predicciones de varios estimadores base" para mejorar la calidad del modelo. En nuestro ejemplo, utilizamos Random Trees y AdaBoost. 

- [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest), un m√©todo de promediaci√≥n, construye un 'bosque' de '√°rboles de decisi√≥n' infundidos con aleatoriedad para evitar el sobreajuste. El par√°metro n_estimators se establece en el n√∫mero de √°rboles.

- [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) ajusta un clasificador a un conjunto de datos y luego ajusta copias de ese clasificador al mismo conjunto de datos. Se enfoca en los pesos de los elementos clasificados incorrectamente y ajusta el ajuste para el siguiente clasificador para corregir.

---

## üöÄDesaf√≠o

Cada una de estas t√©cnicas tiene un gran n√∫mero de par√°metros que puedes ajustar. Investiga los par√°metros predeterminados de cada una y piensa en lo que significar√≠a ajustar estos par√°metros para la calidad del modelo.

## [Cuestionario posterior a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

## Revisi√≥n y autoestudio

Hay mucho vocabulario t√©cnico en estas lecciones, as√≠ que t√≥mate un momento para revisar [esta lista](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) de terminolog√≠a √∫til.

## Tarea 

[Prueba de par√°metros](assignment.md)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por garantizar la precisi√≥n, tenga en cuenta que las traducciones automatizadas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.