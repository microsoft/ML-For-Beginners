{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "lesson_12-R.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "ir",
   "display_name": "R"
  },
  "language_info": {
   "name": "R"
  },
  "coopTranslator": {
   "original_hash": "fab50046ca413a38939d579f8432274f",
   "translation_date": "2025-09-04T02:36:44+00:00",
   "source_file": "4-Classification/3-Classifiers-2/solution/R/lesson_12-R.ipynb",
   "language_code": "es"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsFutf_ygqSx"
   },
   "source": [
    "# Construir un modelo de clasificaci√≥n: Deliciosas cocinas asi√°ticas e indias\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HD54bEefgtNO"
   },
   "source": [
    "## Clasificadores de cocina 2\n",
    "\n",
    "En esta segunda lecci√≥n sobre clasificaci√≥n, exploraremos `m√°s formas` de clasificar datos categ√≥ricos. Tambi√©n aprenderemos sobre las implicaciones de elegir un clasificador sobre otro.\n",
    "\n",
    "### [**Cuestionario previo a la lecci√≥n**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/23/)\n",
    "\n",
    "### **Requisito previo**\n",
    "\n",
    "Asumimos que has completado las lecciones anteriores, ya que retomaremos algunos conceptos que aprendimos antes.\n",
    "\n",
    "Para esta lecci√≥n, necesitaremos los siguientes paquetes:\n",
    "\n",
    "-   `tidyverse`: El [tidyverse](https://www.tidyverse.org/) es una [colecci√≥n de paquetes de R](https://www.tidyverse.org/packages) dise√±ada para hacer la ciencia de datos m√°s r√°pida, f√°cil y divertida.\n",
    "\n",
    "-   `tidymodels`: El marco de trabajo [tidymodels](https://www.tidymodels.org/) es una [colecci√≥n de paquetes](https://www.tidymodels.org/packages/) para modelado y aprendizaje autom√°tico.\n",
    "\n",
    "-   `themis`: El paquete [themis](https://themis.tidymodels.org/) proporciona pasos adicionales de recetas para tratar con datos desbalanceados.\n",
    "\n",
    "Puedes instalarlos con el siguiente comando:\n",
    "\n",
    "`install.packages(c(\"tidyverse\", \"tidymodels\", \"kernlab\", \"themis\", \"ranger\", \"xgboost\", \"kknn\"))`\n",
    "\n",
    "Alternativamente, el siguiente script verifica si tienes los paquetes necesarios para completar este m√≥dulo y los instala por ti en caso de que falten.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vZ57IuUxgyQt"
   },
   "source": [
    "suppressWarnings(if (!require(\"pacman\"))install.packages(\"pacman\"))\n",
    "\n",
    "pacman::p_load(tidyverse, tidymodels, themis, kernlab, ranger, xgboost, kknn)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z22M-pj4g07x"
   },
   "source": [
    "## **1. Un mapa de clasificaci√≥n**\n",
    "\n",
    "En nuestra [lecci√≥n anterior](https://github.com/microsoft/ML-For-Beginners/tree/main/4-Classification/2-Classifiers-1), intentamos abordar la pregunta: ¬øc√≥mo elegimos entre m√∫ltiples modelos? En gran medida, depende de las caracter√≠sticas de los datos y del tipo de problema que queremos resolver (por ejemplo, ¬øclasificaci√≥n o regresi√≥n?).\n",
    "\n",
    "Anteriormente, aprendimos sobre las diversas opciones que tienes al clasificar datos utilizando la hoja de referencia de Microsoft. El marco de aprendizaje autom√°tico de Python, Scikit-learn, ofrece una hoja de referencia similar pero m√°s detallada que puede ayudarte a√∫n m√°s a reducir tus estimadores (otro t√©rmino para clasificadores):\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/map.png\"\n",
    "   width=\"700\"/>\n",
    "   <figcaption></figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1i3xRIVg7vG"
   },
   "source": [
    "> Consejo: [visita este mapa en l√≠nea](https://scikit-learn.org/stable/tutorial/machine_learning_map/) y haz clic a lo largo del camino para leer la documentaci√≥n.  \n",
    ">  \n",
    "> El [sitio de referencia de Tidymodels](https://www.tidymodels.org/find/parsnip/#models) tambi√©n ofrece una excelente documentaci√≥n sobre los diferentes tipos de modelos.\n",
    "\n",
    "### **El plan** üó∫Ô∏è\n",
    "\n",
    "Este mapa es muy √∫til una vez que tienes un entendimiento claro de tus datos, ya que puedes 'caminar' por sus caminos hacia una decisi√≥n:\n",
    "\n",
    "-   Tenemos \\>50 muestras\n",
    "\n",
    "-   Queremos predecir una categor√≠a\n",
    "\n",
    "-   Tenemos datos etiquetados\n",
    "\n",
    "-   Tenemos menos de 100K muestras\n",
    "\n",
    "-   ‚ú® Podemos elegir un Linear SVC\n",
    "\n",
    "-   Si eso no funciona, dado que tenemos datos num√©ricos\n",
    "\n",
    "    -   Podemos intentar un ‚ú® KNeighbors Classifier\n",
    "\n",
    "        -   Si eso tampoco funciona, probar ‚ú® SVC y ‚ú® Ensemble Classifiers\n",
    "\n",
    "Este es un camino muy √∫til a seguir. Ahora, vamos a sumergirnos directamente utilizando el marco de modelado [tidymodels](https://www.tidymodels.org/): una colecci√≥n consistente y flexible de paquetes de R desarrollada para fomentar buenas pr√°cticas estad√≠sticas üòä.\n",
    "\n",
    "## 2. Dividir los datos y manejar un conjunto de datos desequilibrado.\n",
    "\n",
    "En nuestras lecciones anteriores, aprendimos que hab√≠a un conjunto de ingredientes comunes entre nuestras cocinas. Adem√°s, hab√≠a una distribuci√≥n bastante desigual en el n√∫mero de cocinas.\n",
    "\n",
    "Abordaremos esto de la siguiente manera:\n",
    "\n",
    "-   Eliminando los ingredientes m√°s comunes que generan confusi√≥n entre cocinas distintas, usando `dplyr::select()`.\n",
    "\n",
    "-   Usando una `recipe` que preprocesa los datos para prepararlos para el modelado aplicando un algoritmo de `over-sampling`.\n",
    "\n",
    "Ya vimos lo anterior en la lecci√≥n pasada, ¬°as√≠ que esto ser√° pan comido ü•≥!\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6tj_rN00hClA"
   },
   "source": [
    "# Load the core Tidyverse and Tidymodels packages\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "\n",
    "# Load the original cuisines data\n",
    "df <- read_csv(file = \"https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/data/cuisines.csv\")\n",
    "\n",
    "# Drop id column, rice, garlic and ginger from our original data set\n",
    "df_select <- df %>% \n",
    "  select(-c(1, rice, garlic, ginger)) %>%\n",
    "  # Encode cuisine column as categorical\n",
    "  mutate(cuisine = factor(cuisine))\n",
    "\n",
    "\n",
    "# Create data split specification\n",
    "set.seed(2056)\n",
    "cuisines_split <- initial_split(data = df_select,\n",
    "                                strata = cuisine,\n",
    "                                prop = 0.7)\n",
    "\n",
    "# Extract the data in each split\n",
    "cuisines_train <- training(cuisines_split)\n",
    "cuisines_test <- testing(cuisines_split)\n",
    "\n",
    "# Display distribution of cuisines in the training set\n",
    "cuisines_train %>% \n",
    "  count(cuisine) %>% \n",
    "  arrange(desc(n))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFin5yw3hHb1"
   },
   "source": [
    "### C√≥mo manejar datos desbalanceados\n",
    "\n",
    "Los datos desbalanceados a menudo tienen efectos negativos en el rendimiento del modelo. Muchos modelos funcionan mejor cuando el n√∫mero de observaciones es igual y, por lo tanto, tienden a tener dificultades con datos desbalanceados.\n",
    "\n",
    "Existen principalmente dos formas de abordar conjuntos de datos desbalanceados:\n",
    "\n",
    "-   agregar observaciones a la clase minoritaria: `Sobre-muestreo`, por ejemplo, utilizando un algoritmo SMOTE que genera de manera sint√©tica nuevos ejemplos de la clase minoritaria utilizando los vecinos m√°s cercanos de estos casos.\n",
    "\n",
    "-   eliminar observaciones de la clase mayoritaria: `Sub-muestreo`\n",
    "\n",
    "En nuestra lecci√≥n anterior, demostramos c√≥mo manejar conjuntos de datos desbalanceados utilizando una `receta`. Una receta puede considerarse como un plan que describe qu√© pasos deben aplicarse a un conjunto de datos para prepararlo para el an√°lisis. En nuestro caso, queremos tener una distribuci√≥n equitativa en el n√∫mero de nuestras categor√≠as de cocina para nuestro `conjunto de entrenamiento`. Vamos a ello.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cRzTnHolhLWd"
   },
   "source": [
    "# Load themis package for dealing with imbalanced data\n",
    "library(themis)\n",
    "\n",
    "# Create a recipe for preprocessing training data\n",
    "cuisines_recipe <- recipe(cuisine ~ ., data = cuisines_train) %>%\n",
    "  step_smote(cuisine) \n",
    "\n",
    "# Print recipe\n",
    "cuisines_recipe"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxOQ2ORhhO81"
   },
   "source": [
    "¬°Ahora estamos listos para entrenar modelos üë©‚Äçüíªüë®‚Äçüíª!\n",
    "\n",
    "## 3. M√°s all√° de los modelos de regresi√≥n multinomial\n",
    "\n",
    "En nuestra lecci√≥n anterior, vimos los modelos de regresi√≥n multinomial. Ahora exploremos algunos modelos m√°s flexibles para clasificaci√≥n.\n",
    "\n",
    "### M√°quinas de Vectores de Soporte\n",
    "\n",
    "En el contexto de la clasificaci√≥n, las `M√°quinas de Vectores de Soporte` son una t√©cnica de aprendizaje autom√°tico que intenta encontrar un *hiperplano* que \"mejor\" separe las clases. Veamos un ejemplo sencillo:\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/svm.png\"\n",
    "   width=\"300\"/>\n",
    "   <figcaption>https://commons.wikimedia.org/w/index.php?curid=22877598</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4Wsd0vZhXYu"
   },
   "source": [
    "H1~ no separa las clases. H2~ s√≠ lo hace, pero solo con un peque√±o margen. H3~ las separa con el margen m√°ximo.\n",
    "\n",
    "#### Clasificador Lineal de Vectores de Soporte\n",
    "\n",
    "El clustering de vectores de soporte (SVC) es una t√©cnica derivada de la familia de m√°quinas de vectores de soporte (SVM) en el aprendizaje autom√°tico. En SVC, el hiperplano se elige para separar correctamente a `la mayor√≠a` de las observaciones de entrenamiento, pero `puede clasificar err√≥neamente` algunas observaciones. Al permitir que algunos puntos est√©n en el lado incorrecto, el SVM se vuelve m√°s robusto frente a valores at√≠picos, lo que mejora su capacidad de generalizaci√≥n a nuevos datos. El par√°metro que regula esta violaci√≥n se denomina `coste`, y tiene un valor predeterminado de 1 (consulta `help(\"svm_poly\")`).\n",
    "\n",
    "Vamos a crear un SVC lineal configurando `degree = 1` en un modelo SVM polin√≥mico.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vJpp6nuChlBz"
   },
   "source": [
    "# Make a linear SVC specification\n",
    "svc_linear_spec <- svm_poly(degree = 1) %>% \n",
    "  set_engine(\"kernlab\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle specification and recipe into a worklow\n",
    "svc_linear_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(svc_linear_spec)\n",
    "\n",
    "# Print out workflow\n",
    "svc_linear_wf"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDs8cWNkhoqu"
   },
   "source": [
    "Ahora que hemos capturado los pasos de preprocesamiento y la especificaci√≥n del modelo en un *workflow*, podemos proceder a entrenar el SVC lineal y evaluar los resultados al mismo tiempo. Para las m√©tricas de rendimiento, vamos a crear un conjunto de m√©tricas que eval√∫e: `accuracy`, `sensitivity`, `Positive Predicted Value` y `F Measure`.\n",
    "\n",
    "> `augment()` a√±adir√° columna(s) con las predicciones a los datos proporcionados.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "81wiqcwuhrnq"
   },
   "source": [
    "# Train a linear SVC model\n",
    "svc_linear_fit <- svc_linear_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "# Create a metric set\n",
    "eval_metrics <- metric_set(ppv, sens, accuracy, f_meas)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "svc_linear_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UFQvHf-huo3"
   },
   "source": [
    "#### M√°quina de Vectores de Soporte\n",
    "\n",
    "La m√°quina de vectores de soporte (SVM, por sus siglas en ingl√©s) es una extensi√≥n del clasificador de vectores de soporte dise√±ada para manejar l√≠mites no lineales entre las clases. En esencia, las SVM utilizan el *truco del kernel* para ampliar el espacio de caracter√≠sticas y adaptarse a relaciones no lineales entre las clases. Una funci√≥n kernel popular y extremadamente flexible que utilizan las SVM es la *funci√≥n de base radial.* Veamos c√≥mo se desempe√±a con nuestros datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-KX4S8mzhzmp"
   },
   "source": [
    "set.seed(2056)\n",
    "\n",
    "# Make an RBF SVM specification\n",
    "svm_rbf_spec <- svm_rbf() %>% \n",
    "  set_engine(\"kernlab\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle specification and recipe into a worklow\n",
    "svm_rbf_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(svm_rbf_spec)\n",
    "\n",
    "\n",
    "# Train an RBF model\n",
    "svm_rbf_fit <- svm_rbf_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "svm_rbf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBFSa7WSh4HQ"
   },
   "source": [
    "¬°Mucho mejor ü§©!\n",
    "\n",
    "> ‚úÖ Por favor consulta:\n",
    ">\n",
    "> -   [*Support Vector Machines*](https://bradleyboehmke.github.io/HOML/svm.html), Hands-on Machine Learning with R\n",
    ">\n",
    "> -   [*Support Vector Machines*](https://www.statlearning.com/), An Introduction to Statistical Learning with Applications in R\n",
    ">\n",
    "> para m√°s informaci√≥n.\n",
    "\n",
    "### Clasificadores de Vecinos M√°s Cercanos\n",
    "\n",
    "El algoritmo de *K*-vecinos m√°s cercanos (KNN) predice cada observaci√≥n bas√°ndose en su *similitud* con otras observaciones.\n",
    "\n",
    "Vamos a ajustarlo a nuestros datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k4BxxBcdh9Ka"
   },
   "source": [
    "# Make a KNN specification\n",
    "knn_spec <- nearest_neighbor() %>% \n",
    "  set_engine(\"kknn\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "knn_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(knn_spec)\n",
    "\n",
    "# Train a boosted tree model\n",
    "knn_wf_fit <- knn_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "knn_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaegQseriAcj"
   },
   "source": [
    "Parece que este modelo no est√° funcionando tan bien. Probablemente cambiar los argumentos del modelo (consulta `help(\"nearest_neighbor\")`) mejorar√° el rendimiento del modelo. Aseg√∫rate de probarlo.\n",
    "\n",
    "> ‚úÖ Por favor consulta:\n",
    ">\n",
    "> -   [Hands-on Machine Learning with R](https://bradleyboehmke.github.io/HOML/)\n",
    ">\n",
    "> -   [An Introduction to Statistical Learning with Applications in R](https://www.statlearning.com/)\n",
    ">\n",
    "> para aprender m√°s sobre los clasificadores *K*-Nearest Neighbors.\n",
    "\n",
    "### Clasificadores en conjunto\n",
    "\n",
    "Los algoritmos en conjunto funcionan combinando m√∫ltiples estimadores base para producir un modelo √≥ptimo, ya sea mediante:\n",
    "\n",
    "`bagging`: aplicando una *funci√≥n de promediado* a una colecci√≥n de modelos base\n",
    "\n",
    "`boosting`: construyendo una secuencia de modelos que se basan unos en otros para mejorar el rendimiento predictivo.\n",
    "\n",
    "Comencemos probando un modelo de Random Forest, que construye una gran colecci√≥n de √°rboles de decisi√≥n y luego aplica una funci√≥n de promediado para obtener un modelo general mejorado.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "49DPoVs6iK1M"
   },
   "source": [
    "# Make a random forest specification\n",
    "rf_spec <- rand_forest() %>% \n",
    "  set_engine(\"ranger\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "rf_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(rf_spec)\n",
    "\n",
    "# Train a random forest model\n",
    "rf_wf_fit <- rf_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "rf_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGVYwC_aiUWc"
   },
   "source": [
    "¬°Buen trabajo üëè!\n",
    "\n",
    "Vamos a experimentar tambi√©n con un modelo de √Årbol Potenciado.\n",
    "\n",
    "El √Årbol Potenciado define un m√©todo de conjunto que crea una serie de √°rboles de decisi√≥n secuenciales, donde cada √°rbol depende de los resultados de los √°rboles anteriores en un intento de reducir el error de manera incremental. Se enfoca en los pesos de los elementos clasificados incorrectamente y ajusta el modelo del siguiente clasificador para corregirlos.\n",
    "\n",
    "Existen diferentes formas de ajustar este modelo (consulta `help(\"boost_tree\")`). En este ejemplo, ajustaremos √Årboles Potenciados utilizando el motor `xgboost`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Py1YWo-micWs"
   },
   "source": [
    "# Make a boosted tree specification\n",
    "boost_spec <- boost_tree(trees = 200) %>% \n",
    "  set_engine(\"xgboost\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "boost_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(boost_spec)\n",
    "\n",
    "# Train a boosted tree model\n",
    "boost_wf_fit <- boost_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "boost_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNQnbuejigZM"
   },
   "source": [
    "> ‚úÖ Por favor consulta:\n",
    ">\n",
    "> -   [Machine Learning for Social Scientists](https://cimentadaj.github.io/ml_socsci/tree-based-methods.html#random-forests)\n",
    ">\n",
    "> -   [Hands-on Machine Learning with R](https://bradleyboehmke.github.io/HOML/)\n",
    ">\n",
    "> -   [An Introduction to Statistical Learning with Applications in R](https://www.statlearning.com/)\n",
    ">\n",
    "> -   <https://algotech.netlify.app/blog/xgboost/> - Explora el modelo AdaBoost, que es una buena alternativa a xgboost.\n",
    ">\n",
    "> para aprender m√°s sobre clasificadores Ensemble.\n",
    "\n",
    "## 4. Extra - comparando m√∫ltiples modelos\n",
    "\n",
    "Hemos ajustado bastantes modelos en este laboratorio üôå. Puede volverse tedioso o complicado crear muchos flujos de trabajo a partir de diferentes conjuntos de preprocesadores y/o especificaciones de modelos y luego calcular las m√©tricas de rendimiento una por una.\n",
    "\n",
    "Veamos si podemos abordar esto creando una funci√≥n que ajuste una lista de flujos de trabajo en el conjunto de entrenamiento y luego devuelva las m√©tricas de rendimiento basadas en el conjunto de prueba. Usaremos `map()` y `map_dfr()` del paquete [purrr](https://purrr.tidyverse.org/) para aplicar funciones a cada elemento de una lista.\n",
    "\n",
    "> Las funciones [`map()`](https://purrr.tidyverse.org/reference/map.html) te permiten reemplazar muchos bucles for con un c√≥digo que es m√°s conciso y f√°cil de leer. El mejor lugar para aprender sobre las funciones [`map()`](https://purrr.tidyverse.org/reference/map.html) es el [cap√≠tulo de iteraci√≥n](http://r4ds.had.co.nz/iteration.html) en R for Data Science.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Qzb7LyZnimd2"
   },
   "source": [
    "set.seed(2056)\n",
    "\n",
    "# Create a metric set\n",
    "eval_metrics <- metric_set(ppv, sens, accuracy, f_meas)\n",
    "\n",
    "# Define a function that returns performance metrics\n",
    "compare_models <- function(workflow_list, train_set, test_set){\n",
    "  \n",
    "  suppressWarnings(\n",
    "    # Fit each model to the train_set\n",
    "    map(workflow_list, fit, data = train_set) %>% \n",
    "    # Make predictions on the test set\n",
    "      map_dfr(augment, new_data = test_set, .id = \"model\") %>%\n",
    "    # Select desired columns\n",
    "      select(model, cuisine, .pred_class) %>% \n",
    "    # Evaluate model performance\n",
    "      group_by(model) %>% \n",
    "      eval_metrics(truth = cuisine, estimate = .pred_class) %>% \n",
    "      ungroup()\n",
    "  )\n",
    "  \n",
    "} # End of function"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fwa712sNisDA"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3i4VJOi2iu-a"
   },
   "source": [
    "# Make a list of workflows\n",
    "workflow_list <- list(\n",
    "  \"svc\" = svc_linear_wf,\n",
    "  \"svm\" = svm_rbf_wf,\n",
    "  \"knn\" = knn_wf,\n",
    "  \"random_forest\" = rf_wf,\n",
    "  \"xgboost\" = boost_wf)\n",
    "\n",
    "# Call the function\n",
    "set.seed(2056)\n",
    "perf_metrics <- compare_models(workflow_list = workflow_list, train_set = cuisines_train, test_set = cuisines_test)\n",
    "\n",
    "# Print out performance metrics\n",
    "perf_metrics %>% \n",
    "  group_by(.metric) %>% \n",
    "  arrange(desc(.estimate)) %>% \n",
    "  slice_head(n=7)\n",
    "\n",
    "# Compare accuracy\n",
    "perf_metrics %>% \n",
    "  filter(.metric == \"accuracy\") %>% \n",
    "  arrange(desc(.estimate))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuWK_lEli4nW"
   },
   "source": [
    "El paquete [**workflowset**](https://workflowsets.tidymodels.org/) permite a los usuarios crear y ajustar f√°cilmente una gran cantidad de modelos, pero est√° dise√±ado principalmente para trabajar con t√©cnicas de remuestreo como `cross-validation`, un enfoque que a√∫n no hemos cubierto.\n",
    "\n",
    "## **üöÄDesaf√≠o**\n",
    "\n",
    "Cada una de estas t√©cnicas tiene una gran cantidad de par√°metros que puedes ajustar, por ejemplo, `cost` en SVMs, `neighbors` en KNN, `mtry` (Predictores Seleccionados Aleatoriamente) en Random Forest.\n",
    "\n",
    "Investiga los par√°metros predeterminados de cada uno y piensa en lo que significar√≠a ajustar estos par√°metros para la calidad del modelo.\n",
    "\n",
    "Para obtener m√°s informaci√≥n sobre un modelo en particular y sus par√°metros, utiliza: `help(\"model\")`, por ejemplo, `help(\"rand_forest\")`.\n",
    "\n",
    "> En la pr√°ctica, usualmente *estimamos* los *mejores valores* para estos entrenando muchos modelos en un `conjunto de datos simulado` y midiendo qu√© tan bien funcionan todos estos modelos. Este proceso se llama **ajuste**.\n",
    "\n",
    "### [**Cuestionario post-clase**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/24/)\n",
    "\n",
    "### **Revisi√≥n y Estudio Personal**\n",
    "\n",
    "Hay mucho vocabulario t√©cnico en estas lecciones, as√≠ que t√≥mate un momento para revisar [esta lista](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) de terminolog√≠a √∫til.\n",
    "\n",
    "#### GRACIAS A:\n",
    "\n",
    "[`Allison Horst`](https://twitter.com/allison_horst/) por crear las incre√≠bles ilustraciones que hacen que R sea m√°s acogedor y atractivo. Encuentra m√°s ilustraciones en su [galer√≠a](https://www.google.com/url?q=https://github.com/allisonhorst/stats-illustrations&sa=D&source=editors&ust=1626380772530000&usg=AOvVaw3zcfyCizFQZpkSLzxiiQEM).\n",
    "\n",
    "[Cassie Breviu](https://www.twitter.com/cassieview) y [Jen Looper](https://www.twitter.com/jenlooper) por crear la versi√≥n original en Python de este m√≥dulo ‚ô•Ô∏è\n",
    "\n",
    "Feliz aprendizaje,\n",
    "\n",
    "[Eric](https://twitter.com/ericntay), Embajador Estudiantil de Microsoft Learn Gold.\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/r_learners_sm.jpeg\"\n",
    "   width=\"569\"/>\n",
    "   <figcaption>Arte por @allison_horst</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Descargo de responsabilidad**:  \nEste documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.\n"
   ]
  }
 ]
}