{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construir un modelo de regresi√≥n log√≠stica - Lecci√≥n 4\n",
    "\n",
    "![Infograf√≠a de regresi√≥n log√≠stica vs. regresi√≥n lineal](../../../../../../translated_images/linear-vs-logistic.ba180bf95e7ee66721ba10ebf2dac2666acbd64a88b003c83928712433a13c7d.es.png)\n",
    "\n",
    "#### **[Cuestionario previo a la lecci√≥n](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/15/)**\n",
    "\n",
    "#### Introducci√≥n\n",
    "\n",
    "En esta √∫ltima lecci√≥n sobre Regresi√≥n, una de las t√©cnicas b√°sicas *cl√°sicas* de Machine Learning, echaremos un vistazo a la Regresi√≥n Log√≠stica. Utilizar√≠as esta t√©cnica para descubrir patrones y predecir categor√≠as binarias. ¬øEs este dulce de chocolate o no? ¬øEs esta enfermedad contagiosa o no? ¬øElegir√° este cliente este producto o no?\n",
    "\n",
    "En esta lecci√≥n, aprender√°s:\n",
    "\n",
    "-   T√©cnicas para la regresi√≥n log√≠stica\n",
    "\n",
    "‚úÖ Profundiza tu comprensi√≥n sobre c√≥mo trabajar con este tipo de regresi√≥n en este [m√≥dulo de aprendizaje](https://learn.microsoft.com/training/modules/introduction-classification-models/?WT.mc_id=academic-77952-leestott)\n",
    "\n",
    "## Prerrequisito\n",
    "\n",
    "Habiendo trabajado con los datos de calabazas, ahora estamos lo suficientemente familiarizados con ellos como para darnos cuenta de que hay una categor√≠a binaria con la que podemos trabajar: `Color`.\n",
    "\n",
    "Construyamos un modelo de regresi√≥n log√≠stica para predecir, dado algunas variables, *de qu√© color es probable que sea una calabaza* (naranja üéÉ o blanca üëª).\n",
    "\n",
    "> ¬øPor qu√© estamos hablando de clasificaci√≥n binaria en una lecci√≥n sobre regresi√≥n? Solo por conveniencia ling√º√≠stica, ya que la regresi√≥n log√≠stica es [en realidad un m√©todo de clasificaci√≥n](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression), aunque basado en un modelo lineal. Aprende sobre otras formas de clasificar datos en el pr√≥ximo grupo de lecciones.\n",
    "\n",
    "Para esta lecci√≥n, necesitaremos los siguientes paquetes:\n",
    "\n",
    "-   `tidyverse`: El [tidyverse](https://www.tidyverse.org/) es una [colecci√≥n de paquetes de R](https://www.tidyverse.org/packages) dise√±ada para hacer la ciencia de datos m√°s r√°pida, f√°cil y divertida.\n",
    "\n",
    "-   `tidymodels`: El marco de trabajo [tidymodels](https://www.tidymodels.org/) es una [colecci√≥n de paquetes](https://www.tidymodels.org/packages/) para modelado y aprendizaje autom√°tico.\n",
    "\n",
    "-   `janitor`: El paquete [janitor](https://github.com/sfirke/janitor) proporciona herramientas simples para examinar y limpiar datos desordenados.\n",
    "\n",
    "-   `ggbeeswarm`: El paquete [ggbeeswarm](https://github.com/eclarke/ggbeeswarm) ofrece m√©todos para crear gr√°ficos estilo \"beeswarm\" utilizando ggplot2.\n",
    "\n",
    "Puedes instalarlos con:\n",
    "\n",
    "`install.packages(c(\"tidyverse\", \"tidymodels\", \"janitor\", \"ggbeeswarm\"))`\n",
    "\n",
    "Alternativamente, el siguiente script verifica si tienes los paquetes necesarios para completar este m√≥dulo y los instala por ti en caso de que falten.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "suppressWarnings(if (!require(\"pacman\"))install.packages(\"pacman\"))\n",
    "\n",
    "pacman::p_load(tidyverse, tidymodels, janitor, ggbeeswarm)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Definir la pregunta**\n",
    "\n",
    "Para nuestros prop√≥sitos, expresaremos esto como un binario: 'Blanco' o 'No Blanco'. Tambi√©n hay una categor√≠a 'rayado' en nuestro conjunto de datos, pero hay pocos casos de ella, as√≠ que no la usaremos. De todos modos, desaparece una vez que eliminamos los valores nulos del conjunto de datos.\n",
    "\n",
    "> üéÉ Dato curioso: a veces llamamos a las calabazas blancas 'calabazas fantasma'. No son muy f√°ciles de tallar, por lo que no son tan populares como las naranjas, ¬°pero tienen un aspecto genial! As√≠ que tambi√©n podr√≠amos reformular nuestra pregunta como: 'Fantasma' o 'No Fantasma'. üëª\n",
    "\n",
    "## **Sobre la regresi√≥n log√≠stica**\n",
    "\n",
    "La regresi√≥n log√≠stica difiere de la regresi√≥n lineal, que aprendiste anteriormente, en algunos aspectos importantes.\n",
    "\n",
    "#### **Clasificaci√≥n binaria**\n",
    "\n",
    "La regresi√≥n log√≠stica no ofrece las mismas caracter√≠sticas que la regresi√≥n lineal. La primera ofrece una predicci√≥n sobre una `categor√≠a binaria` (\"naranja o no naranja\"), mientras que la segunda es capaz de predecir `valores continuos`, por ejemplo, dado el origen de una calabaza y el momento de la cosecha, *cu√°nto aumentar√° su precio*.\n",
    "\n",
    "![Infograf√≠a por Dasani Madipalli](../../../../../../translated_images/pumpkin-classifier.562771f104ad5436b87d1c67bca02a42a17841133556559325c0a0e348e5b774.es.png)\n",
    "\n",
    "### Otras clasificaciones\n",
    "\n",
    "Existen otros tipos de regresi√≥n log√≠stica, incluyendo multinomial y ordinal:\n",
    "\n",
    "- **Multinomial**, que implica tener m√°s de una categor√≠a - \"Naranja, Blanco y Rayado\".\n",
    "\n",
    "- **Ordinal**, que implica categor√≠as ordenadas, √∫til si quisi√©ramos ordenar nuestros resultados l√≥gicamente, como nuestras calabazas que est√°n ordenadas por un n√∫mero finito de tama√±os (mini,peque√±o,mediano,grande,xl,xxl).\n",
    "\n",
    "![Regresi√≥n multinomial vs ordinal](../../../../../../translated_images/multinomial-vs-ordinal.36701b4850e37d86c9dd49f7bef93a2f94dbdb8fe03443eb68f0542f97f28f29.es.png)\n",
    "\n",
    "#### **Las variables NO tienen que correlacionarse**\n",
    "\n",
    "¬øRecuerdas c√≥mo la regresi√≥n lineal funcionaba mejor con variables m√°s correlacionadas? La regresi√≥n log√≠stica es lo opuesto: las variables no tienen que alinearse. Esto funciona para estos datos que tienen correlaciones algo d√©biles.\n",
    "\n",
    "#### **Necesitas muchos datos limpios**\n",
    "\n",
    "La regresi√≥n log√≠stica dar√° resultados m√°s precisos si utilizas m√°s datos; nuestro conjunto de datos peque√±o no es √≥ptimo para esta tarea, as√≠ que tenlo en cuenta.\n",
    "\n",
    "‚úÖ Piensa en los tipos de datos que se prestar√≠an bien para la regresi√≥n log√≠stica.\n",
    "\n",
    "## Ejercicio - ordenar los datos\n",
    "\n",
    "Primero, limpia un poco los datos, eliminando valores nulos y seleccionando solo algunas de las columnas:\n",
    "\n",
    "1. Agrega el siguiente c√≥digo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Load the core tidyverse packages\n",
    "library(tidyverse)\n",
    "\n",
    "# Import the data and clean column names\n",
    "pumpkins <- read_csv(file = \"https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/2-Regression/data/US-pumpkins.csv\") %>% \n",
    "  clean_names()\n",
    "\n",
    "# Select desired columns\n",
    "pumpkins_select <- pumpkins %>% \n",
    "  select(c(city_name, package, variety, origin, item_size, color)) \n",
    "\n",
    "# Drop rows containing missing values and encode color as factor (category)\n",
    "pumpkins_select <- pumpkins_select %>% \n",
    "  drop_na() %>% \n",
    "  mutate(color = factor(color))\n",
    "\n",
    "# View the first few rows\n",
    "pumpkins_select %>% \n",
    "  slice_head(n = 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siempre puedes echar un vistazo a tu nuevo dataframe utilizando la funci√≥n [*glimpse()*](https://pillar.r-lib.org/reference/glimpse.html) como se muestra a continuaci√≥n:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "pumpkins_select %>% \n",
    "  glimpse()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirmemos que, de hecho, vamos a trabajar en un problema de clasificaci√≥n binaria:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Subset distinct observations in outcome column\n",
    "pumpkins_select %>% \n",
    "  distinct(color)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaci√≥n - gr√°fico categ√≥rico\n",
    "A estas alturas, ya has cargado nuevamente los datos de las calabazas y los has limpiado para conservar un conjunto de datos que incluye algunas variables, como el Color. Vamos a visualizar el dataframe en el notebook utilizando la biblioteca ggplot.\n",
    "\n",
    "La biblioteca ggplot ofrece formas interesantes de visualizar tus datos. Por ejemplo, puedes comparar las distribuciones de los datos para cada Variedad y Color en un gr√°fico categ√≥rico.\n",
    "\n",
    "1. Crea un gr√°fico de este tipo utilizando la funci√≥n geombar, con los datos de las calabazas, y especificando un mapeo de color para cada categor√≠a de calabaza (naranja o blanca):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Specify colors for each value of the hue variable\n",
    "palette <- c(ORANGE = \"orange\", WHITE = \"wheat\")\n",
    "\n",
    "# Create the bar plot\n",
    "ggplot(pumpkins_select, aes(y = variety, fill = color)) +\n",
    "  geom_bar(position = \"dodge\") +\n",
    "  scale_fill_manual(values = palette) +\n",
    "  labs(y = \"Variety\", fill = \"Color\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al observar los datos, puedes ver c√≥mo los datos de Color se relacionan con la Variedad.\n",
    "\n",
    "‚úÖ Dado este gr√°fico categ√≥rico, ¬øqu√© exploraciones interesantes puedes imaginar?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento de datos: codificaci√≥n de caracter√≠sticas\n",
    "\n",
    "Nuestro conjunto de datos de calabazas contiene valores de tipo cadena en todas sus columnas. Trabajar con datos categ√≥ricos es intuitivo para los humanos, pero no para las m√°quinas. Los algoritmos de aprendizaje autom√°tico funcionan mejor con n√∫meros. Por eso, la codificaci√≥n es un paso muy importante en la fase de preprocesamiento de datos, ya que nos permite convertir datos categ√≥ricos en datos num√©ricos sin perder informaci√≥n. Una buena codificaci√≥n conduce a la construcci√≥n de un buen modelo.\n",
    "\n",
    "Para la codificaci√≥n de caracter√≠sticas, existen dos tipos principales de codificadores:\n",
    "\n",
    "1. Codificador ordinal: es adecuado para variables ordinales, que son variables categ√≥ricas donde sus datos siguen un orden l√≥gico, como la columna `item_size` en nuestro conjunto de datos. Crea un mapeo de manera que cada categor√≠a se representa con un n√∫mero, que corresponde al orden de la categor√≠a en la columna.\n",
    "\n",
    "2. Codificador categ√≥rico: es adecuado para variables nominales, que son variables categ√≥ricas donde sus datos no siguen un orden l√≥gico, como todas las caracter√≠sticas diferentes de `item_size` en nuestro conjunto de datos. Es una codificaci√≥n de tipo one-hot, lo que significa que cada categor√≠a se representa con una columna binaria: la variable codificada es igual a 1 si la calabaza pertenece a esa variedad y 0 en caso contrario.\n",
    "\n",
    "Tidymodels ofrece otro paquete interesante: [recipes](https://recipes.tidymodels.org/), un paquete para el preprocesamiento de datos. Definiremos una `recipe` que especifica que todas las columnas predictoras deben codificarse en un conjunto de enteros, la `prep` para estimar las cantidades y estad√≠sticas necesarias para cualquier operaci√≥n, y finalmente la `bake` para aplicar los c√°lculos a nuevos datos.\n",
    "\n",
    "> Normalmente, recipes se utiliza como un preprocesador para modelado, donde define qu√© pasos deben aplicarse a un conjunto de datos para que est√© listo para el modelado. En ese caso, es **altamente recomendable** que utilices un `workflow()` en lugar de estimar manualmente una receta usando prep y bake. Veremos todo esto en un momento.\n",
    ">\n",
    "> Sin embargo, por ahora, estamos utilizando recipes + prep + bake para especificar qu√© pasos deben aplicarse a un conjunto de datos para que est√© listo para el an√°lisis de datos y luego extraer los datos preprocesados con los pasos aplicados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Preprocess and extract data to allow some data analysis\n",
    "baked_pumpkins <- recipe(color ~ ., data = pumpkins_select) %>%\n",
    "  # Define ordering for item_size column\n",
    "  step_mutate(item_size = ordered(item_size, levels = c('sml', 'med', 'med-lge', 'lge', 'xlge', 'jbo', 'exjbo'))) %>%\n",
    "  # Convert factors to numbers using the order defined above (Ordinal encoding)\n",
    "  step_integer(item_size, zero_based = F) %>%\n",
    "  # Encode all other predictors using one hot encoding\n",
    "  step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE) %>%\n",
    "  prep(data = pumpkin_select) %>%\n",
    "  bake(new_data = NULL)\n",
    "\n",
    "# Display the first few rows of preprocessed data\n",
    "baked_pumpkins %>% \n",
    "  slice_head(n = 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ ¬øCu√°les son las ventajas de usar un codificador ordinal para la columna Item Size?\n",
    "\n",
    "### Analizar las relaciones entre variables\n",
    "\n",
    "Ahora que hemos preprocesado nuestros datos, podemos analizar las relaciones entre las caracter√≠sticas y la etiqueta para hacernos una idea de qu√© tan bien el modelo podr√° predecir la etiqueta a partir de las caracter√≠sticas. La mejor manera de realizar este tipo de an√°lisis es graficando los datos.  \n",
    "Usaremos nuevamente la funci√≥n ggplot geom_boxplot_ para visualizar las relaciones entre Item Size, Variety y Color en un gr√°fico categ√≥rico. Para representar mejor los datos, utilizaremos la columna codificada de Item Size y la columna no codificada de Variety.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Define the color palette\n",
    "palette <- c(ORANGE = \"orange\", WHITE = \"wheat\")\n",
    "\n",
    "# We need the encoded Item Size column to use it as the x-axis values in the plot\n",
    "pumpkins_select_plot<-pumpkins_select\n",
    "pumpkins_select_plot$item_size <- baked_pumpkins$item_size\n",
    "\n",
    "# Create the grouped box plot\n",
    "ggplot(pumpkins_select_plot, aes(x = `item_size`, y = color, fill = color)) +\n",
    "  geom_boxplot() +\n",
    "  facet_grid(variety ~ ., scales = \"free_x\") +\n",
    "  scale_fill_manual(values = palette) +\n",
    "  labs(x = \"Item Size\", y = \"\") +\n",
    "  theme_minimal() +\n",
    "  theme(strip.text = element_text(size = 12)) +\n",
    "  theme(axis.text.x = element_text(size = 10)) +\n",
    "  theme(axis.title.x = element_text(size = 12)) +\n",
    "  theme(axis.title.y = element_blank()) +\n",
    "  theme(legend.position = \"bottom\") +\n",
    "  guides(fill = guide_legend(title = \"Color\")) +\n",
    "  theme(panel.spacing = unit(0.5, \"lines\"))+\n",
    "  theme(strip.text.y = element_text(size = 4, hjust = 0)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usar un gr√°fico de enjambre\n",
    "\n",
    "Dado que Color es una categor√≠a binaria (Blanco o No), requiere 'un [enfoque especializado](https://github.com/rstudio/cheatsheets/blob/main/data-visualization.pdf) para su visualizaci√≥n'.\n",
    "\n",
    "Prueba un `gr√°fico de enjambre` para mostrar la distribuci√≥n del color con respecto al tama√±o del art√≠culo.\n",
    "\n",
    "Usaremos el [paquete ggbeeswarm](https://github.com/eclarke/ggbeeswarm), que proporciona m√©todos para crear gr√°ficos estilo enjambre utilizando ggplot2. Los gr√°ficos de enjambre son una forma de representar puntos que normalmente se superpondr√≠an, de manera que se posicionen uno al lado del otro.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create beeswarm plots of color and item_size\n",
    "baked_pumpkins %>% \n",
    "  mutate(color = factor(color)) %>% \n",
    "  ggplot(mapping = aes(x = color, y = item_size, color = color)) +\n",
    "  geom_quasirandom() +\n",
    "  scale_color_brewer(palette = \"Dark2\", direction = -1) +\n",
    "  theme(legend.position = \"none\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos una idea de la relaci√≥n entre las categor√≠as binarias de color y el grupo m√°s amplio de tama√±os, exploremos la regresi√≥n log√≠stica para determinar el color probable de una calabaza.\n",
    "\n",
    "## Construye tu modelo\n",
    "\n",
    "Selecciona las variables que deseas usar en tu modelo de clasificaci√≥n y divide los datos en conjuntos de entrenamiento y prueba. [rsample](https://rsample.tidymodels.org/), un paquete de Tidymodels, proporciona infraestructura para una divisi√≥n y remuestreo de datos eficiente:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Split data into 80% for training and 20% for testing\n",
    "set.seed(2056)\n",
    "pumpkins_split <- pumpkins_select %>% \n",
    "  initial_split(prop = 0.8)\n",
    "\n",
    "# Extract the data in each split\n",
    "pumpkins_train <- training(pumpkins_split)\n",
    "pumpkins_test <- testing(pumpkins_split)\n",
    "\n",
    "# Print out the first 5 rows of the training set\n",
    "pumpkins_train %>% \n",
    "  slice_head(n = 5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üôå Ahora estamos listos para entrenar un modelo ajustando las caracter√≠sticas de entrenamiento a la etiqueta de entrenamiento (color).\n",
    "\n",
    "Comenzaremos creando una receta que especifique los pasos de preprocesamiento que deben realizarse en nuestros datos para prepararlos para el modelado, es decir: codificar variables categ√≥ricas en un conjunto de enteros. Al igual que `baked_pumpkins`, creamos una `pumpkins_recipe` pero no usamos `prep` ni `bake`, ya que esto se integrar√° en un flujo de trabajo, como ver√°s en unos pocos pasos.\n",
    "\n",
    "Existen varias formas de especificar un modelo de regresi√≥n log√≠stica en Tidymodels. Consulta `?logistic_reg()`. Por ahora, especificaremos un modelo de regresi√≥n log√≠stica mediante el motor predeterminado `stats::glm()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create a recipe that specifies preprocessing steps for modelling\n",
    "pumpkins_recipe <- recipe(color ~ ., data = pumpkins_train) %>% \n",
    "  step_mutate(item_size = ordered(item_size, levels = c('sml', 'med', 'med-lge', 'lge', 'xlge', 'jbo', 'exjbo'))) %>%\n",
    "  step_integer(item_size, zero_based = F) %>%  \n",
    "  step_dummy(all_nominal(), -all_outcomes(), one_hot = TRUE)\n",
    "\n",
    "# Create a logistic model specification\n",
    "log_reg <- logistic_reg() %>% \n",
    "  set_engine(\"glm\") %>% \n",
    "  set_mode(\"classification\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que tenemos una receta y una especificaci√≥n del modelo, necesitamos encontrar una forma de combinarlas en un objeto que primero preprocese los datos (prep+bake detr√°s de escena), ajuste el modelo con los datos preprocesados y tambi√©n permita posibles actividades de postprocesamiento.\n",
    "\n",
    "En Tidymodels, este pr√°ctico objeto se llama [`workflow`](https://workflows.tidymodels.org/) y organiza convenientemente los componentes de tu modelo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Bundle modelling components in a workflow\n",
    "log_reg_wf <- workflow() %>% \n",
    "  add_recipe(pumpkins_recipe) %>% \n",
    "  add_model(log_reg)\n",
    "\n",
    "# Print out the workflow\n",
    "log_reg_wf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despu√©s de que se haya *especificado* un flujo de trabajo, se puede `entrenar` un modelo utilizando la funci√≥n [`fit()`](https://tidymodels.github.io/parsnip/reference/fit.html). El flujo de trabajo estimar√° una receta y preprocesar√° los datos antes del entrenamiento, por lo que no ser√° necesario hacerlo manualmente utilizando prep y bake.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "wf_fit <- log_reg_wf %>% \n",
    "  fit(data = pumpkins_train)\n",
    "\n",
    "# Print the trained workflow\n",
    "wf_fit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El modelo muestra los coeficientes aprendidos durante el entrenamiento.\n",
    "\n",
    "Ahora que hemos entrenado el modelo utilizando los datos de entrenamiento, podemos hacer predicciones sobre los datos de prueba usando [parsnip::predict()](https://parsnip.tidymodels.org/reference/predict.model_fit.html). Comencemos utilizando el modelo para predecir etiquetas para nuestro conjunto de prueba y las probabilidades de cada etiqueta. Cuando la probabilidad es mayor a 0.5, la clase predicha es `WHITE`, de lo contrario, es `ORANGE`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Make predictions for color and corresponding probabilities\n",
    "results <- pumpkins_test %>% select(color) %>% \n",
    "  bind_cols(wf_fit %>% \n",
    "              predict(new_data = pumpkins_test)) %>%\n",
    "  bind_cols(wf_fit %>%\n",
    "              predict(new_data = pumpkins_test, type = \"prob\"))\n",
    "\n",
    "# Compare predictions\n",
    "results %>% \n",
    "  slice_head(n = 10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¬°Muy bien! Esto proporciona m√°s informaci√≥n sobre c√≥mo funciona la regresi√≥n log√≠stica.\n",
    "\n",
    "### Mejor comprensi√≥n mediante una matriz de confusi√≥n\n",
    "\n",
    "Comparar cada predicci√≥n con su valor \"real\" correspondiente no es una forma muy eficiente de determinar qu√© tan bien est√° prediciendo el modelo. Afortunadamente, Tidymodels tiene algunos trucos m√°s bajo la manga: [`yardstick`](https://yardstick.tidymodels.org/) - un paquete utilizado para medir la efectividad de los modelos mediante m√©tricas de rendimiento.\n",
    "\n",
    "Una m√©trica de rendimiento asociada con problemas de clasificaci√≥n es la [`matriz de confusi√≥n`](https://wikipedia.org/wiki/Confusion_matrix). Una matriz de confusi√≥n describe qu√© tan bien funciona un modelo de clasificaci√≥n. Una matriz de confusi√≥n tabula cu√°ntos ejemplos de cada clase fueron clasificados correctamente por un modelo. En nuestro caso, te mostrar√° cu√°ntas calabazas naranjas fueron clasificadas como naranjas y cu√°ntas calabazas blancas fueron clasificadas como blancas; la matriz de confusi√≥n tambi√©n te mostrar√° cu√°ntas fueron clasificadas en las categor√≠as **incorrectas**.\n",
    "\n",
    "La funci√≥n [**`conf_mat()`**](https://tidymodels.github.io/yardstick/reference/conf_mat.html) de yardstick calcula esta tabulaci√≥n cruzada de clases observadas y predichas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Confusion matrix for prediction results\n",
    "conf_mat(data = results, truth = color, estimate = .pred_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a interpretar la matriz de confusi√≥n. Nuestro modelo debe clasificar calabazas entre dos categor√≠as binarias, la categor√≠a `blanca` y la categor√≠a `no blanca`.\n",
    "\n",
    "-   Si tu modelo predice que una calabaza es blanca y en realidad pertenece a la categor√≠a 'blanca', lo llamamos un `verdadero positivo`, representado por el n√∫mero en la esquina superior izquierda.\n",
    "\n",
    "-   Si tu modelo predice que una calabaza no es blanca y en realidad pertenece a la categor√≠a 'blanca', lo llamamos un `falso negativo`, representado por el n√∫mero en la esquina inferior izquierda.\n",
    "\n",
    "-   Si tu modelo predice que una calabaza es blanca y en realidad pertenece a la categor√≠a 'no blanca', lo llamamos un `falso positivo`, representado por el n√∫mero en la esquina superior derecha.\n",
    "\n",
    "-   Si tu modelo predice que una calabaza no es blanca y en realidad pertenece a la categor√≠a 'no blanca', lo llamamos un `verdadero negativo`, representado por el n√∫mero en la esquina inferior derecha.\n",
    "\n",
    "| Verdad |\n",
    "|:-----:|\n",
    "\n",
    "\n",
    "|               |        |       |\n",
    "|---------------|--------|-------|\n",
    "| **Predicci√≥n** | BLANCA | NARANJA |\n",
    "| BLANCA        | VP     | FP    |\n",
    "| NARANJA       | FN     | VN    |\n",
    "\n",
    "Como habr√°s adivinado, es preferible tener un mayor n√∫mero de verdaderos positivos y verdaderos negativos, y un menor n√∫mero de falsos positivos y falsos negativos, lo que implica que el modelo tiene un mejor desempe√±o.\n",
    "\n",
    "La matriz de confusi√≥n es √∫til porque da lugar a otras m√©tricas que nos ayudan a evaluar mejor el rendimiento de un modelo de clasificaci√≥n. Vamos a repasarlas:\n",
    "\n",
    "üéì Precisi√≥n: `VP/(VP + FP)` definida como la proporci√≥n de positivos predichos que realmente son positivos. Tambi√©n conocida como [valor predictivo positivo](https://es.wikipedia.org/wiki/Valor_predictivo_positivo \"Valor predictivo positivo\").\n",
    "\n",
    "üéì Recall: `VP/(VP + FN)` definida como la proporci√≥n de resultados positivos sobre el n√∫mero de muestras que realmente eran positivas. Tambi√©n conocida como `sensibilidad`.\n",
    "\n",
    "üéì Especificidad: `VN/(VN + FP)` definida como la proporci√≥n de resultados negativos sobre el n√∫mero de muestras que realmente eran negativas.\n",
    "\n",
    "üéì Exactitud: `VP + VN/(VP + VN + FP + FN)` El porcentaje de etiquetas predichas correctamente para una muestra.\n",
    "\n",
    "üéì Medida F: Un promedio ponderado entre la precisi√≥n y el recall, donde el mejor valor es 1 y el peor es 0.\n",
    "\n",
    "¬°Vamos a calcular estas m√©tricas!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Combine metric functions and calculate them all at once\n",
    "eval_metrics <- metric_set(ppv, recall, spec, f_meas, accuracy)\n",
    "eval_metrics(data = results, truth = color, estimate = .pred_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizar la curva ROC de este modelo\n",
    "\n",
    "Hagamos una visualizaci√≥n m√°s para observar la llamada [`curva ROC`](https://en.wikipedia.org/wiki/Receiver_operating_characteristic):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Make a roc_curve\n",
    "results %>% \n",
    "  roc_curve(color, .pred_ORANGE) %>% \n",
    "  autoplot()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las curvas ROC se utilizan frecuentemente para obtener una visi√≥n del rendimiento de un clasificador en t√©rminos de sus verdaderos positivos frente a los falsos positivos. Las curvas ROC suelen mostrar la `Tasa de Verdaderos Positivos`/Sensibilidad en el eje Y, y la `Tasa de Falsos Positivos`/1-Especificidad en el eje X. Por lo tanto, la inclinaci√≥n de la curva y el espacio entre la l√≠nea del punto medio y la curva son importantes: se busca una curva que suba r√°pidamente y se aleje de la l√≠nea. En nuestro caso, hay falsos positivos al principio, y luego la l√≠nea sube y se aleja correctamente.\n",
    "\n",
    "Finalmente, usemos `yardstick::roc_auc()` para calcular el √Årea Bajo la Curva. Una forma de interpretar el AUC es como la probabilidad de que el modelo clasifique un ejemplo positivo aleatorio m√°s alto que un ejemplo negativo aleatorio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate area under curve\n",
    "results %>% \n",
    "  roc_auc(color, .pred_ORANGE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado es alrededor de `0.975`. Dado que el AUC var√≠a de 0 a 1, quieres un puntaje alto, ya que un modelo que sea 100% correcto en sus predicciones tendr√° un AUC de 1; en este caso, el modelo es *bastante bueno*.\n",
    "\n",
    "En futuras lecciones sobre clasificaciones, aprender√°s c√≥mo mejorar los puntajes de tu modelo (como manejar datos desbalanceados en este caso).\n",
    "\n",
    "## üöÄDesaf√≠o\n",
    "\n",
    "¬°Hay mucho m√°s que explorar sobre la regresi√≥n log√≠stica! Pero la mejor manera de aprender es experimentar. Encuentra un conjunto de datos que se preste a este tipo de an√°lisis y construye un modelo con √©l. ¬øQu√© aprendes? consejo: prueba [Kaggle](https://www.kaggle.com/search?q=logistic+regression+datasets) para conjuntos de datos interesantes.\n",
    "\n",
    "## Revisi√≥n y Autoestudio\n",
    "\n",
    "Lee las primeras p√°ginas de [este art√≠culo de Stanford](https://web.stanford.edu/~jurafsky/slp3/5.pdf) sobre algunos usos pr√°cticos de la regresi√≥n log√≠stica. Piensa en tareas que sean m√°s adecuadas para uno u otro tipo de tareas de regresi√≥n que hemos estudiado hasta ahora. ¬øQu√© funcionar√≠a mejor?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Descargo de responsabilidad**:  \nEste documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": "",
  "kernelspec": {
   "display_name": "R",
   "langauge": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.1"
  },
  "coopTranslator": {
   "original_hash": "feaf125f481a89c468fa115bf2aed580",
   "translation_date": "2025-09-04T01:24:55+00:00",
   "source_file": "2-Regression/4-Logistic/solution/R/lesson_4-R.ipynb",
   "language_code": "es"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}