<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "abf86d845c84330bce205a46b382ec88",
  "translation_date": "2025-09-04T22:12:57+00:00",
  "source_file": "2-Regression/4-Logistic/README.md",
  "language_code": "es"
}
-->
# Regresi√≥n log√≠stica para predecir categor√≠as

![Infograf√≠a de regresi√≥n log√≠stica vs. regresi√≥n lineal](../../../../2-Regression/4-Logistic/images/linear-vs-logistic.png)

## [Cuestionario previo a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

> ### [¬°Esta lecci√≥n est√° disponible en R!](../../../../2-Regression/4-Logistic/solution/R/lesson_4.html)

## Introducci√≥n

En esta √∫ltima lecci√≥n sobre Regresi√≥n, una de las t√©cnicas b√°sicas _cl√°sicas_ de ML, exploraremos la Regresi√≥n Log√≠stica. Utilizar√≠as esta t√©cnica para descubrir patrones y predecir categor√≠as binarias. ¬øEs este dulce de chocolate o no? ¬øEs esta enfermedad contagiosa o no? ¬øElegir√° este cliente este producto o no?

En esta lecci√≥n, aprender√°s:

- Una nueva biblioteca para la visualizaci√≥n de datos
- T√©cnicas para la regresi√≥n log√≠stica

‚úÖ Profundiza tu comprensi√≥n sobre c√≥mo trabajar con este tipo de regresi√≥n en este [m√≥dulo de aprendizaje](https://docs.microsoft.com/learn/modules/train-evaluate-classification-models?WT.mc_id=academic-77952-leestott)

## Prerrequisitos

Despu√©s de trabajar con los datos de calabazas, ya estamos lo suficientemente familiarizados con ellos como para darnos cuenta de que hay una categor√≠a binaria con la que podemos trabajar: `Color`.

Construyamos un modelo de regresi√≥n log√≠stica para predecir, dado algunas variables, _de qu√© color es probable que sea una calabaza_ (naranja üéÉ o blanca üëª).

> ¬øPor qu√© estamos hablando de clasificaci√≥n binaria en una lecci√≥n sobre regresi√≥n? Solo por conveniencia ling√º√≠stica, ya que la regresi√≥n log√≠stica es [realmente un m√©todo de clasificaci√≥n](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression), aunque basado en un enfoque lineal. Aprende sobre otras formas de clasificar datos en el pr√≥ximo grupo de lecciones.

## Define la pregunta

Para nuestros prop√≥sitos, expresaremos esto como un binario: 'Blanca' o 'No Blanca'. Tambi√©n hay una categor√≠a 'rayada' en nuestro conjunto de datos, pero hay pocos casos de ella, por lo que no la usaremos. De todos modos, desaparece una vez que eliminamos los valores nulos del conjunto de datos.

> üéÉ Dato curioso: a veces llamamos a las calabazas blancas 'calabazas fantasma'. No son muy f√°ciles de tallar, por lo que no son tan populares como las naranjas, ¬°pero tienen un aspecto genial! As√≠ que tambi√©n podr√≠amos reformular nuestra pregunta como: 'Fantasma' o 'No Fantasma'. üëª

## Sobre la regresi√≥n log√≠stica

La regresi√≥n log√≠stica difiere de la regresi√≥n lineal, que aprendiste anteriormente, en algunos aspectos importantes.

[![ML para principiantes - Comprendiendo la Regresi√≥n Log√≠stica para la Clasificaci√≥n en Machine Learning](https://img.youtube.com/vi/KpeCT6nEpBY/0.jpg)](https://youtu.be/KpeCT6nEpBY "ML para principiantes - Comprendiendo la Regresi√≥n Log√≠stica para la Clasificaci√≥n en Machine Learning")

> üé• Haz clic en la imagen de arriba para un breve video sobre la regresi√≥n log√≠stica.

### Clasificaci√≥n binaria

La regresi√≥n log√≠stica no ofrece las mismas caracter√≠sticas que la regresi√≥n lineal. La primera ofrece una predicci√≥n sobre una categor√≠a binaria ("blanca o no blanca"), mientras que la segunda es capaz de predecir valores continuos, por ejemplo, dado el origen de una calabaza y el momento de la cosecha, _cu√°nto subir√° su precio_.

![Modelo de clasificaci√≥n de calabazas](../../../../2-Regression/4-Logistic/images/pumpkin-classifier.png)
> Infograf√≠a por [Dasani Madipalli](https://twitter.com/dasani_decoded)

### Otras clasificaciones

Existen otros tipos de regresi√≥n log√≠stica, incluyendo multinomial y ordinal:

- **Multinomial**, que implica tener m√°s de una categor√≠a - "Naranja, Blanca y Rayada".
- **Ordinal**, que implica categor√≠as ordenadas, √∫til si quisi√©ramos ordenar nuestros resultados l√≥gicamente, como nuestras calabazas que est√°n ordenadas por un n√∫mero finito de tama√±os (mini, peque√±a, mediana, grande, XL, XXL).

![Regresi√≥n multinomial vs ordinal](../../../../2-Regression/4-Logistic/images/multinomial-vs-ordinal.png)

### Las variables NO tienen que correlacionarse

¬øRecuerdas c√≥mo la regresi√≥n lineal funcionaba mejor con variables m√°s correlacionadas? La regresi√≥n log√≠stica es lo opuesto: las variables no tienen que estar alineadas. Esto funciona para estos datos, que tienen correlaciones algo d√©biles.

### Necesitas muchos datos limpios

La regresi√≥n log√≠stica dar√° resultados m√°s precisos si utilizas m√°s datos; nuestro peque√±o conjunto de datos no es √≥ptimo para esta tarea, as√≠ que tenlo en cuenta.

[![ML para principiantes - An√°lisis y Preparaci√≥n de Datos para la Regresi√≥n Log√≠stica](https://img.youtube.com/vi/B2X4H9vcXTs/0.jpg)](https://youtu.be/B2X4H9vcXTs "ML para principiantes - An√°lisis y Preparaci√≥n de Datos para la Regresi√≥n Log√≠stica")

> üé• Haz clic en la imagen de arriba para un breve video sobre la preparaci√≥n de datos para la regresi√≥n lineal.

‚úÖ Piensa en los tipos de datos que se prestar√≠an bien a la regresi√≥n log√≠stica.

## Ejercicio - organiza los datos

Primero, limpia un poco los datos, eliminando valores nulos y seleccionando solo algunas de las columnas:

1. Agrega el siguiente c√≥digo:

    ```python
  
    columns_to_select = ['City Name','Package','Variety', 'Origin','Item Size', 'Color']
    pumpkins = full_pumpkins.loc[:, columns_to_select]

    pumpkins.dropna(inplace=True)
    ```

    Siempre puedes echar un vistazo a tu nuevo dataframe:

    ```python
    pumpkins.info
    ```

### Visualizaci√≥n - gr√°fico categ√≥rico

Hasta ahora has cargado el [notebook inicial](../../../../2-Regression/4-Logistic/notebook.ipynb) con datos de calabazas una vez m√°s y lo has limpiado para preservar un conjunto de datos que contiene algunas variables, incluyendo `Color`. Visualicemos el dataframe en el notebook usando una biblioteca diferente: [Seaborn](https://seaborn.pydata.org/index.html), que est√° construida sobre Matplotlib, que usamos anteriormente.

Seaborn ofrece formas interesantes de visualizar tus datos. Por ejemplo, puedes comparar distribuciones de los datos para cada `Variety` y `Color` en un gr√°fico categ√≥rico.

1. Crea dicho gr√°fico usando la funci√≥n `catplot`, con nuestros datos de calabazas `pumpkins`, y especificando un mapeo de colores para cada categor√≠a de calabaza (naranja o blanca):

    ```python
    import seaborn as sns
    
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }

    sns.catplot(
    data=pumpkins, y="Variety", hue="Color", kind="count",
    palette=palette, 
    )
    ```

    ![Una cuadr√≠cula de datos visualizados](../../../../2-Regression/4-Logistic/images/pumpkins_catplot_1.png)

    Al observar los datos, puedes ver c√≥mo los datos de Color se relacionan con Variety.

    ‚úÖ Dado este gr√°fico categ√≥rico, ¬øqu√© exploraciones interesantes puedes imaginar?

### Preprocesamiento de datos: codificaci√≥n de caracter√≠sticas y etiquetas

Nuestro conjunto de datos de calabazas contiene valores de cadena para todas sus columnas. Trabajar con datos categ√≥ricos es intuitivo para los humanos, pero no para las m√°quinas. Los algoritmos de aprendizaje autom√°tico funcionan bien con n√∫meros. Por eso, la codificaci√≥n es un paso muy importante en la fase de preprocesamiento de datos, ya que nos permite convertir datos categ√≥ricos en datos num√©ricos, sin perder informaci√≥n. Una buena codificaci√≥n conduce a la construcci√≥n de un buen modelo.

Para la codificaci√≥n de caracter√≠sticas, hay dos tipos principales de codificadores:

1. Codificador ordinal: es adecuado para variables ordinales, que son variables categ√≥ricas donde sus datos siguen un orden l√≥gico, como la columna `Item Size` en nuestro conjunto de datos. Crea un mapeo de modo que cada categor√≠a est√© representada por un n√∫mero, que es el orden de la categor√≠a en la columna.

    ```python
    from sklearn.preprocessing import OrdinalEncoder

    item_size_categories = [['sml', 'med', 'med-lge', 'lge', 'xlge', 'jbo', 'exjbo']]
    ordinal_features = ['Item Size']
    ordinal_encoder = OrdinalEncoder(categories=item_size_categories)
    ```

2. Codificador categ√≥rico: es adecuado para variables nominales, que son variables categ√≥ricas donde sus datos no siguen un orden l√≥gico, como todas las caracter√≠sticas diferentes de `Item Size` en nuestro conjunto de datos. Es una codificaci√≥n one-hot, lo que significa que cada categor√≠a est√° representada por una columna binaria: la variable codificada es igual a 1 si la calabaza pertenece a esa Variety y 0 en caso contrario.

    ```python
    from sklearn.preprocessing import OneHotEncoder

    categorical_features = ['City Name', 'Package', 'Variety', 'Origin']
    categorical_encoder = OneHotEncoder(sparse_output=False)
    ```

Luego, `ColumnTransformer` se utiliza para combinar m√∫ltiples codificadores en un solo paso y aplicarlos a las columnas apropiadas.

```python
    from sklearn.compose import ColumnTransformer
    
    ct = ColumnTransformer(transformers=[
        ('ord', ordinal_encoder, ordinal_features),
        ('cat', categorical_encoder, categorical_features)
        ])
    
    ct.set_output(transform='pandas')
    encoded_features = ct.fit_transform(pumpkins)
```

Por otro lado, para codificar la etiqueta, usamos la clase `LabelEncoder` de scikit-learn, que es una clase de utilidad para ayudar a normalizar etiquetas de modo que contengan solo valores entre 0 y n_classes-1 (aqu√≠, 0 y 1).

```python
    from sklearn.preprocessing import LabelEncoder

    label_encoder = LabelEncoder()
    encoded_label = label_encoder.fit_transform(pumpkins['Color'])
```

Una vez que hemos codificado las caracter√≠sticas y la etiqueta, podemos fusionarlas en un nuevo dataframe `encoded_pumpkins`.

```python
    encoded_pumpkins = encoded_features.assign(Color=encoded_label)
```

‚úÖ ¬øCu√°les son las ventajas de usar un codificador ordinal para la columna `Item Size`?

### Analiza las relaciones entre variables

Ahora que hemos preprocesado nuestros datos, podemos analizar las relaciones entre las caracter√≠sticas y la etiqueta para hacernos una idea de qu√© tan bien el modelo podr√° predecir la etiqueta dadas las caracter√≠sticas. La mejor manera de realizar este tipo de an√°lisis es graficando los datos. Usaremos nuevamente la funci√≥n `catplot` de Seaborn para visualizar las relaciones entre `Item Size`, `Variety` y `Color` en un gr√°fico categ√≥rico. Para graficar mejor los datos, usaremos la columna codificada `Item Size` y la columna sin codificar `Variety`.

```python
    palette = {
    'ORANGE': 'orange',
    'WHITE': 'wheat',
    }
    pumpkins['Item Size'] = encoded_pumpkins['ord__Item Size']

    g = sns.catplot(
        data=pumpkins,
        x="Item Size", y="Color", row='Variety',
        kind="box", orient="h",
        sharex=False, margin_titles=True,
        height=1.8, aspect=4, palette=palette,
    )
    g.set(xlabel="Item Size", ylabel="").set(xlim=(0,6))
    g.set_titles(row_template="{row_name}")
```

![Un gr√°fico categ√≥rico de datos visualizados](../../../../2-Regression/4-Logistic/images/pumpkins_catplot_2.png)

### Usa un gr√°fico de enjambre

Dado que Color es una categor√≠a binaria (Blanca o No), necesita '[un enfoque especializado](https://seaborn.pydata.org/tutorial/categorical.html?highlight=bar) para la visualizaci√≥n'. Hay otras formas de visualizar la relaci√≥n de esta categor√≠a con otras variables.

Puedes visualizar variables lado a lado con gr√°ficos de Seaborn.

1. Prueba un gr√°fico de 'enjambre' para mostrar la distribuci√≥n de valores:

    ```python
    palette = {
    0: 'orange',
    1: 'wheat'
    }
    sns.swarmplot(x="Color", y="ord__Item Size", data=encoded_pumpkins, palette=palette)
    ```

    ![Un enjambre de datos visualizados](../../../../2-Regression/4-Logistic/images/swarm_2.png)

**Cuidado**: el c√≥digo anterior podr√≠a generar una advertencia, ya que Seaborn falla al representar tal cantidad de puntos de datos en un gr√°fico de enjambre. Una posible soluci√≥n es disminuir el tama√±o del marcador, utilizando el par√°metro 'size'. Sin embargo, ten en cuenta que esto afecta la legibilidad del gr√°fico.

> **üßÆ Mu√©strame las matem√°ticas**
>
> La regresi√≥n log√≠stica se basa en el concepto de 'm√°xima verosimilitud' utilizando [funciones sigmoides](https://wikipedia.org/wiki/Sigmoid_function). Una 'Funci√≥n Sigmoide' en un gr√°fico tiene forma de 'S'. Toma un valor y lo mapea a un rango entre 0 y 1. Su curva tambi√©n se llama 'curva log√≠stica'. Su f√≥rmula es la siguiente:
>
> ![funci√≥n log√≠stica](../../../../2-Regression/4-Logistic/images/sigmoid.png)
>
> donde el punto medio de la sigmoide se encuentra en el punto 0 de x, L es el valor m√°ximo de la curva, y k es la pendiente de la curva. Si el resultado de la funci√≥n es mayor a 0.5, la etiqueta en cuesti√≥n se clasificar√° como '1' de la elecci√≥n binaria. Si no, se clasificar√° como '0'.

## Construye tu modelo

Construir un modelo para encontrar estas clasificaciones binarias es sorprendentemente sencillo en Scikit-learn.

[![ML para principiantes - Regresi√≥n Log√≠stica para la clasificaci√≥n de datos](https://img.youtube.com/vi/MmZS2otPrQ8/0.jpg)](https://youtu.be/MmZS2otPrQ8 "ML para principiantes - Regresi√≥n Log√≠stica para la clasificaci√≥n de datos")

> üé• Haz clic en la imagen de arriba para un breve video sobre c√≥mo construir un modelo de regresi√≥n lineal.

1. Selecciona las variables que deseas usar en tu modelo de clasificaci√≥n y divide los conjuntos de entrenamiento y prueba llamando a `train_test_split()`:

    ```python
    from sklearn.model_selection import train_test_split
    
    X = encoded_pumpkins[encoded_pumpkins.columns.difference(['Color'])]
    y = encoded_pumpkins['Color']

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
    
    ```

2. Ahora puedes entrenar tu modelo llamando a `fit()` con tus datos de entrenamiento y mostrar su resultado:

    ```python
    from sklearn.metrics import f1_score, classification_report 
    from sklearn.linear_model import LogisticRegression

    model = LogisticRegression()
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)

    print(classification_report(y_test, predictions))
    print('Predicted labels: ', predictions)
    print('F1-score: ', f1_score(y_test, predictions))
    ```

    Observa el puntaje de tu modelo. No est√° mal, considerando que solo tienes alrededor de 1000 filas de datos:

    ```output
                       precision    recall  f1-score   support
    
                    0       0.94      0.98      0.96       166
                    1       0.85      0.67      0.75        33
    
        accuracy                                0.92       199
        macro avg           0.89      0.82      0.85       199
        weighted avg        0.92      0.92      0.92       199
    
        Predicted labels:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0
        0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 0 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0
        1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 1 0
        0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0
        0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1
        0 0 0 1 0 0 0 0 0 0 0 0 1 1]
        F1-score:  0.7457627118644068
    ```

## Mejor comprensi√≥n mediante una matriz de confusi√≥n

Aunque puedes obtener un informe de puntaje [t√©rminos](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html?highlight=classification_report#sklearn.metrics.classification_report) imprimiendo los elementos anteriores, podr√≠as entender mejor tu modelo utilizando una [matriz de confusi√≥n](https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix) para ayudarnos a comprender c√≥mo est√° funcionando el modelo.

> üéì Una '[matriz de confusi√≥n](https://wikipedia.org/wiki/Confusion_matrix)' (o 'matriz de error') es una tabla que expresa los verdaderos vs. falsos positivos y negativos de tu modelo, evaluando as√≠ la precisi√≥n de las predicciones.

1. Para usar una matriz de confusi√≥n, llama a `confusion_matrix()`:

    ```python
    from sklearn.metrics import confusion_matrix
    confusion_matrix(y_test, predictions)
    ```

    Observa la matriz de confusi√≥n de tu modelo:

    ```output
    array([[162,   4],
           [ 11,  22]])
    ```

En Scikit-learn, las filas (eje 0) son etiquetas reales y las columnas (eje 1) son etiquetas predichas.

|       |   0   |   1   |
| :---: | :---: | :---: |
|   0   |  TN   |  FP   |
|   1   |  FN   |  TP   |

¬øQu√© est√° pasando aqu√≠? Supongamos que nuestro modelo debe clasificar calabazas entre dos categor√≠as binarias, categor√≠a 'blanca' y categor√≠a 'no blanca'.

- Si tu modelo predice una calabaza como no blanca y en realidad pertenece a la categor√≠a 'no blanca', lo llamamos un verdadero negativo, mostrado por el n√∫mero en la esquina superior izquierda.
- Si tu modelo predice una calabaza como blanca y en realidad pertenece a la categor√≠a 'no blanca', lo llamamos un falso negativo, mostrado por el n√∫mero en la esquina inferior izquierda.
- Si tu modelo predice una calabaza como no blanca y en realidad pertenece a la categor√≠a 'blanca', lo llamamos un falso positivo, mostrado por el n√∫mero en la esquina superior derecha.
- Si tu modelo predice una calabaza como blanca y en realidad pertenece a la categor√≠a 'blanca', lo llamamos un verdadero positivo, mostrado por el n√∫mero en la esquina inferior derecha.

Como habr√°s adivinado, es preferible tener un mayor n√∫mero de verdaderos positivos y verdaderos negativos y un menor n√∫mero de falsos positivos y falsos negativos, lo que implica que el modelo funciona mejor.
¬øC√≥mo se relaciona la matriz de confusi√≥n con la precisi√≥n y el recall? Recuerda, el informe de clasificaci√≥n mostrado anteriormente indic√≥ una precisi√≥n (0.85) y un recall (0.67).

Precisi√≥n = tp / (tp + fp) = 22 / (22 + 4) = 0.8461538461538461

Recall = tp / (tp + fn) = 22 / (22 + 11) = 0.6666666666666666

‚úÖ P: Seg√∫n la matriz de confusi√≥n, ¬øc√≥mo le fue al modelo? R: No est√° mal; hay un buen n√∫mero de verdaderos negativos, pero tambi√©n algunos falsos negativos.

Volvamos a revisar los t√©rminos que vimos antes con la ayuda del mapeo de TP/TN y FP/FN en la matriz de confusi√≥n:

üéì Precisi√≥n: TP/(TP + FP) La fracci√≥n de instancias relevantes entre las instancias recuperadas (por ejemplo, qu√© etiquetas fueron bien etiquetadas).

üéì Recall: TP/(TP + FN) La fracci√≥n de instancias relevantes que fueron recuperadas, ya sea bien etiquetadas o no.

üéì f1-score: (2 * precisi√≥n * recall)/(precisi√≥n + recall) Un promedio ponderado de la precisi√≥n y el recall, donde el mejor valor es 1 y el peor es 0.

üéì Soporte: El n√∫mero de ocurrencias de cada etiqueta recuperada.

üéì Exactitud: (TP + TN)/(TP + TN + FP + FN) El porcentaje de etiquetas predichas correctamente para una muestra.

üéì Promedio Macro: El c√°lculo de las m√©tricas medias no ponderadas para cada etiqueta, sin tener en cuenta el desequilibrio de etiquetas.

üéì Promedio Ponderado: El c√°lculo de las m√©tricas medias para cada etiqueta, teniendo en cuenta el desequilibrio de etiquetas al ponderarlas seg√∫n su soporte (el n√∫mero de instancias verdaderas para cada etiqueta).

‚úÖ ¬øPuedes pensar en qu√© m√©trica deber√≠as enfocarte si quieres que tu modelo reduzca el n√∫mero de falsos negativos?

## Visualizar la curva ROC de este modelo

[![ML para principiantes - Analizando el rendimiento de la regresi√≥n log√≠stica con curvas ROC](https://img.youtube.com/vi/GApO575jTA0/0.jpg)](https://youtu.be/GApO575jTA0 "ML para principiantes - Analizando el rendimiento de la regresi√≥n log√≠stica con curvas ROC")

> üé• Haz clic en la imagen de arriba para un breve video sobre las curvas ROC.

Hagamos una visualizaci√≥n m√°s para observar la llamada curva 'ROC':

```python
from sklearn.metrics import roc_curve, roc_auc_score
import matplotlib
import matplotlib.pyplot as plt
%matplotlib inline

y_scores = model.predict_proba(X_test)
fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])

fig = plt.figure(figsize=(6, 6))
plt.plot([0, 1], [0, 1], 'k--')
plt.plot(fpr, tpr)
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.show()
```

Usando Matplotlib, grafica la [Curva Caracter√≠stica Operativa del Receptor](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html?highlight=roc) o ROC del modelo. Las curvas ROC se usan a menudo para obtener una vista del rendimiento de un clasificador en t√©rminos de sus verdaderos positivos frente a los falsos positivos. "Las curvas ROC t√≠picamente muestran la tasa de verdaderos positivos en el eje Y y la tasa de falsos positivos en el eje X." Por lo tanto, la inclinaci√≥n de la curva y el espacio entre la l√≠nea del punto medio y la curva son importantes: quieres una curva que suba r√°pidamente y se aleje de la l√≠nea. En nuestro caso, hay falsos positivos al principio, y luego la l√≠nea sube y se aleja correctamente:

![ROC](../../../../2-Regression/4-Logistic/images/ROC_2.png)

Finalmente, usa la API [`roc_auc_score` de Scikit-learn](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html?highlight=roc_auc#sklearn.metrics.roc_auc_score) para calcular el '√Årea Bajo la Curva' (AUC):

```python
auc = roc_auc_score(y_test,y_scores[:,1])
print(auc)
```
El resultado es `0.9749908725812341`. Dado que el AUC var√≠a de 0 a 1, quieres un puntaje alto, ya que un modelo que sea 100% correcto en sus predicciones tendr√° un AUC de 1; en este caso, el modelo es _bastante bueno_.

En futuras lecciones sobre clasificaciones, aprender√°s c√≥mo iterar para mejorar los puntajes de tu modelo. Pero por ahora, ¬°felicitaciones! ¬°Has completado estas lecciones sobre regresi√≥n!

---
## üöÄDesaf√≠o

¬°Hay mucho m√°s que explorar sobre la regresi√≥n log√≠stica! Pero la mejor manera de aprender es experimentando. Encuentra un conjunto de datos que se preste a este tipo de an√°lisis y construye un modelo con √©l. ¬øQu√© aprendes? Consejo: prueba [Kaggle](https://www.kaggle.com/search?q=logistic+regression+datasets) para encontrar conjuntos de datos interesantes.

## [Cuestionario posterior a la lecci√≥n](https://ff-quizzes.netlify.app/en/ml/)

## Revisi√≥n y Autoestudio

Lee las primeras p√°ginas de [este art√≠culo de Stanford](https://web.stanford.edu/~jurafsky/slp3/5.pdf) sobre algunos usos pr√°cticos de la regresi√≥n log√≠stica. Piensa en tareas que se adapten mejor a uno u otro tipo de tareas de regresi√≥n que hemos estudiado hasta ahora. ¬øQu√© funcionar√≠a mejor?

## Tarea

[Reintentando esta regresi√≥n](assignment.md)

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.