# An√°lisis de sentimiento con rese√±as de hoteles - procesando los datos

En esta secci√≥n, usar√°s las t√©cnicas de las lecciones anteriores para realizar un an√°lisis exploratorio de datos de un conjunto de datos grande. Una vez que tengas una buena comprensi√≥n de la utilidad de las diversas columnas, aprender√°s:

- c√≥mo eliminar las columnas innecesarias
- c√≥mo calcular algunos datos nuevos basados en las columnas existentes
- c√≥mo guardar el conjunto de datos resultante para usarlo en el desaf√≠o final

## [Cuestionario previo a la lecci√≥n](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/37/)

### Introducci√≥n

Hasta ahora has aprendido que los datos de texto son bastante diferentes a los datos num√©ricos. Si es un texto escrito o hablado por un humano, puede analizarse para encontrar patrones y frecuencias, sentimiento y significado. Esta lecci√≥n te lleva a un conjunto de datos real con un desaf√≠o real: **[515K Hotel Reviews Data in Europe](https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe)** e incluye una [licencia CC0: Public Domain](https://creativecommons.org/publicdomain/zero/1.0/). Fue recopilado de Booking.com de fuentes p√∫blicas. El creador del conjunto de datos fue Jiashen Liu.

### Preparaci√≥n

Necesitar√°s:

* La capacidad de ejecutar notebooks .ipynb usando Python 3
* pandas
* NLTK, [que deber√≠as instalar localmente](https://www.nltk.org/install.html)
* El conjunto de datos que est√° disponible en Kaggle [515K Hotel Reviews Data in Europe](https://www.kaggle.com/jiashenliu/515k-hotel-reviews-data-in-europe). Pesa alrededor de 230 MB descomprimido. Desc√°rgalo en la carpeta ra√≠z `/data` asociada con estas lecciones de PLN.

## An√°lisis exploratorio de datos

Este desaf√≠o asume que est√°s construyendo un bot de recomendaciones de hoteles utilizando an√°lisis de sentimiento y puntuaciones de rese√±as de hu√©spedes. El conjunto de datos que utilizar√°s incluye rese√±as de 1493 hoteles diferentes en 6 ciudades.

Usando Python, un conjunto de datos de rese√±as de hoteles, y el an√°lisis de sentimiento de NLTK podr√≠as descubrir:

* ¬øCu√°les son las palabras y frases m√°s frecuentemente utilizadas en las rese√±as?
* ¬øLos *tags* oficiales que describen un hotel se correlacionan con las puntuaciones de las rese√±as (por ejemplo, hay m√°s rese√±as negativas para un hotel particular por *Familia con ni√±os peque√±os* que por *Viajero solo*, tal vez indicando que es mejor para *Viajeros solos*)?
* ¬øLas puntuaciones de sentimiento de NLTK 'coinciden' con la puntuaci√≥n num√©rica del revisor del hotel?

#### Conjunto de datos

Vamos a explorar el conjunto de datos que has descargado y guardado localmente. Abre el archivo en un editor como VS Code o incluso Excel.

Los encabezados en el conjunto de datos son los siguientes:

*Hotel_Address, Additional_Number_of_Scoring, Review_Date, Average_Score, Hotel_Name, Reviewer_Nationality, Negative_Review, Review_Total_Negative_Word_Counts, Total_Number_of_Reviews, Positive_Review, Review_Total_Positive_Word_Counts, Total_Number_of_Reviews_Reviewer_Has_Given, Reviewer_Score, Tags, days_since_review, lat, lng*

Aqu√≠ est√°n agrupados de una manera que podr√≠a ser m√°s f√°cil de examinar:
##### Columnas del hotel

* `Hotel_Name`, `Hotel_Address`, `lat` (latitud), `lng` (longitud)
  * Usando *lat* y *lng* podr√≠as trazar un mapa con Python mostrando las ubicaciones de los hoteles (quiz√°s codificado por colores para rese√±as negativas y positivas)
  * Hotel_Address no es obviamente √∫til para nosotros, y probablemente lo reemplazaremos con un pa√≠s para facilitar la clasificaci√≥n y b√∫squeda

**Columnas de meta-rese√±a del hotel**

* `Average_Score`
  * Seg√∫n el creador del conjunto de datos, esta columna es el *Puntaje promedio del hotel, calculado en base al √∫ltimo comentario en el √∫ltimo a√±o*. Esto parece una forma inusual de calcular el puntaje, pero es el dato recopilado, as√≠ que lo tomaremos como v√°lido por ahora.
  
  ‚úÖ Basado en las otras columnas en estos datos, ¬øpuedes pensar en otra manera de calcular el puntaje promedio?

* `Total_Number_of_Reviews`
  * El n√∫mero total de rese√±as que ha recibido este hotel - no est√° claro (sin escribir algo de c√≥digo) si esto se refiere a las rese√±as en el conjunto de datos.
* `Additional_Number_of_Scoring`
  * Esto significa que se dio un puntaje de rese√±a pero el revisor no escribi√≥ una rese√±a positiva o negativa

**Columnas de rese√±as**

- `Reviewer_Score`
  - Este es un valor num√©rico con hasta 1 decimal entre los valores m√≠nimos y m√°ximos 2.5 y 10
  - No se explica por qu√© 2.5 es el puntaje m√°s bajo posible
- `Negative_Review`
  - Si un revisor no escribi√≥ nada, este campo tendr√° "**No Negative**"
  - Ten en cuenta que un revisor puede escribir una rese√±a positiva en la columna de rese√±a negativa (por ejemplo, "no hay nada malo en este hotel")
- `Review_Total_Negative_Word_Counts`
  - Un mayor conteo de palabras negativas indica un puntaje m√°s bajo (sin verificar la sentimentalidad)
- `Positive_Review`
  - Si un revisor no escribi√≥ nada, este campo tendr√° "**No Positive**"
  - Ten en cuenta que un revisor puede escribir una rese√±a negativa en la columna de rese√±a positiva (por ejemplo, "no hay nada bueno en este hotel en absoluto")
- `Review_Total_Positive_Word_Counts`
  - Un mayor conteo de palabras positivas indica un puntaje m√°s alto (sin verificar la sentimentalidad)
- `Review_Date` y `days_since_review`
  - Se podr√≠a aplicar una medida de frescura o antig√ºedad a una rese√±a (las rese√±as m√°s antiguas podr√≠an no ser tan precisas como las m√°s nuevas porque la administraci√≥n del hotel cambi√≥, o se realizaron renovaciones, o se agreg√≥ una piscina, etc.)
- `Tags`
  - Son descriptores cortos que un revisor puede seleccionar para describir el tipo de hu√©sped que eran (por ejemplo, solo o familia), el tipo de habitaci√≥n que ten√≠an, la duraci√≥n de la estancia y c√≥mo se envi√≥ la rese√±a.
  - Desafortunadamente, usar estos tags es problem√°tico, revisa la secci√≥n a continuaci√≥n que discute su utilidad

**Columnas del revisor**

- `Total_Number_of_Reviews_Reviewer_Has_Given`
  - Esto podr√≠a ser un factor en un modelo de recomendaci√≥n, por ejemplo, si pudieras determinar que los revisores m√°s prol√≠ficos con cientos de rese√±as eran m√°s propensos a ser negativos en lugar de positivos. Sin embargo, el revisor de cualquier rese√±a en particular no est√° identificado con un c√≥digo √∫nico, y por lo tanto no puede vincularse a un conjunto de rese√±as. Hay 30 revisores con 100 o m√°s rese√±as, pero es dif√≠cil ver c√≥mo esto puede ayudar al modelo de recomendaci√≥n.
- `Reviewer_Nationality`
  - Algunas personas podr√≠an pensar que ciertas nacionalidades son m√°s propensas a dar una rese√±a positiva o negativa debido a una inclinaci√≥n nacional. Ten cuidado al construir tales opiniones anecd√≥ticas en tus modelos. Estos son estereotipos nacionales (y a veces raciales), y cada revisor fue un individuo que escribi√≥ una rese√±a basada en su experiencia. Puede haber sido filtrado a trav√©s de muchas lentes como sus estancias anteriores en hoteles, la distancia viajada, y su temperamento personal. Pensar que su nacionalidad fue la raz√≥n de una puntuaci√≥n de rese√±a es dif√≠cil de justificar.

##### Ejemplos

| Puntaje Promedio | N√∫mero Total de Rese√±as | Puntaje del Revisor | Rese√±a Negativa                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  | Rese√±a Positiva                 | Tags                                                                                      |
| ---------------- | ----------------------- | ------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------- | ----------------------------------------------------------------------------------------- |
| 7.8              | 1945                    | 2.5                 | Este no es actualmente un hotel sino un sitio de construcci√≥n. Fui aterrorizado desde temprano en la ma√±ana y todo el d√≠a con ruidos de construcci√≥n inaceptables mientras descansaba despu√©s de un largo viaje y trabajaba en la habitaci√≥n. La gente trabajaba todo el d√≠a, es decir, con martillos neum√°ticos en las habitaciones contiguas. Ped√≠ un cambio de habitaci√≥n pero no hab√≠a una habitaci√≥n silenciosa disponible. Para empeorar las cosas, me cobraron de m√°s. Me fui en la noche ya que ten√≠a que salir muy temprano en vuelo y recib√≠ una factura apropiada. Un d√≠a despu√©s, el hotel hizo otro cargo sin mi consentimiento en exceso del precio reservado. Es un lugar terrible. No te castigues reservando aqu√≠. | Nada. Lugar terrible. Al√©jate. | Viaje de negocios. Pareja. Habitaci√≥n Doble Est√°ndar. Se hosped√≥ 2 noches. |

Como puedes ver, este hu√©sped no tuvo una estancia feliz en este hotel. El hotel tiene un buen puntaje promedio de 7.8 y 1945 rese√±as, pero este revisor le dio 2.5 y escribi√≥ 115 palabras sobre lo negativa que fue su estancia. Si no escribi√≥ nada en la columna de Rese√±a Positiva, podr√≠as suponer que no hab√≠a nada positivo, pero escribi√≥ 7 palabras de advertencia. Si solo cont√°ramos palabras en lugar del significado o sentimiento de las palabras, podr√≠amos tener una visi√≥n sesgada de la intenci√≥n del revisor. Curiosamente, su puntaje de 2.5 es confuso, porque si esa estancia en el hotel fue tan mala, ¬øpor qu√© darle alg√∫n punto? Investigando el conjunto de datos de cerca, ver√°s que el puntaje m√°s bajo posible es 2.5, no 0. El puntaje m√°s alto posible es 10.

##### Tags

Como se mencion√≥ anteriormente, a primera vista, la idea de usar `Tags` para categorizar los datos tiene sentido. Desafortunadamente, estos tags no est√°n estandarizados, lo que significa que en un hotel dado, las opciones podr√≠an ser *Single room*, *Twin room*, y *Double room*, pero en el siguiente hotel, son *Deluxe Single Room*, *Classic Queen Room*, y *Executive King Room*. Estos podr√≠an ser las mismas cosas, pero hay tantas variaciones que la elecci√≥n se convierte en:

1. Intentar cambiar todos los t√©rminos a un est√°ndar √∫nico, lo cual es muy dif√≠cil, porque no est√° claro cu√°l ser√≠a el camino de conversi√≥n en cada caso (por ejemplo, *Classic single room* se mapea a *Single room* pero *Superior Queen Room with Courtyard Garden or City View* es mucho m√°s dif√≠cil de mapear)

1. Podemos tomar un enfoque de PLN y medir la frecuencia de ciertos t√©rminos como *Solo*, *Business Traveller*, o *Family with young kids* a medida que se aplican a cada hotel, y factorizar eso en la recomendaci√≥n  

Los tags son usualmente (pero no siempre) un solo campo que contiene una lista de 5 a 6 valores separados por comas alineados a *Tipo de viaje*, *Tipo de hu√©spedes*, *Tipo de habitaci√≥n*, *N√∫mero de noches*, y *Tipo de dispositivo en el que se envi√≥ la rese√±a*. Sin embargo, debido a que algunos revisores no completan cada campo (pueden dejar uno en blanco), los valores no siempre est√°n en el mismo orden.

Como ejemplo, toma *Tipo de grupo*. Hay 1025 posibilidades √∫nicas en este campo en la columna `Tags`, y desafortunadamente solo algunos de ellos se refieren a un grupo (algunos son el tipo de habitaci√≥n, etc.). Si filtras solo los que mencionan familia, los resultados contienen muchos resultados del tipo *Family room*. Si incluyes el t√©rmino *with*, es decir, cuentas los valores de *Family with*, los resultados son mejores, con m√°s de 80,000 de los 515,000 resultados que contienen la frase "Family with young children" o "Family with older children".

Esto significa que la columna de tags no es completamente in√∫til para nosotros, pero tomar√° algo de trabajo hacerla √∫til.

##### Puntaje promedio del hotel

Hay una serie de rarezas o discrepancias con el conjunto de datos que no puedo descifrar, pero est√°n ilustradas aqu√≠ para que est√©s al tanto de ellas al construir tus modelos. Si las descifras, por favor h√°znoslo saber en la secci√≥n de discusi√≥n.

El conjunto de datos tiene las siguientes columnas relacionadas con el puntaje promedio y el n√∫mero de rese√±as:

1. Hotel_Name
2. Additional_Number_of_Scoring
3. Average_Score
4. Total_Number_of_Reviews
5. Reviewer_Score  

El √∫nico hotel con m√°s rese√±as en este conjunto de datos es *Britannia International Hotel Canary Wharf* con 4789 rese√±as de 515,000. Pero si miramos el valor de `Total_Number_of_Reviews` para este hotel, es 9086. Podr√≠as suponer que hay muchas m√°s puntuaciones sin rese√±as, as√≠ que tal vez deber√≠amos agregar el valor de la columna `Additional_Number_of_Scoring`. Ese valor es 2682, y sum√°ndolo a 4789 nos da 7,471, lo cual sigue estando 1615 por debajo de `Total_Number_of_Reviews`.

Si tomas las columnas `Average_Score`, podr√≠as suponer que es el promedio de las rese√±as en el conjunto de datos, pero la descripci√≥n de Kaggle es "*Puntaje Promedio del hotel, calculado en base al √∫ltimo comentario en el √∫ltimo a√±o*". Eso no parece tan √∫til, pero podemos calcular nuestro propio promedio basado en las puntuaciones de las rese√±as en el conjunto de datos. Usando el mismo hotel como ejemplo, el puntaje promedio del hotel se da como 7.1 pero el puntaje calculado (promedio de las puntuaciones de los revisores *en* el conjunto de datos) es 6.8. Esto es cercano, pero no el mismo valor, y solo podemos suponer que las puntuaciones dadas en las rese√±as `Additional_Number_of_Scoring` aumentaron el promedio a 7.1. Desafortunadamente, sin una forma de probar o demostrar esa afirmaci√≥n, es dif√≠cil usar o confiar en `Average_Score`, `Additional_Number_of_Scoring` y `Total_Number_of_Reviews` cuando se basan en, o se refieren a, datos que no tenemos.

Para complicar las cosas a√∫n m√°s, el hotel con el segundo mayor n√∫mero de rese√±as tiene un puntaje promedio calculado de 8.12 y el `Average_Score` del conjunto de datos es 8.1. ¬øEs esta coincidencia del puntaje correcto o es el primer hotel una discrepancia?

En la posibilidad de que estos hoteles puedan ser un caso at√≠pico, y que tal vez la mayor√≠a de los valores coincidan (pero algunos no por alguna raz√≥n), escribiremos un programa corto a continuaci√≥n para explorar los valores en el conjunto de datos y determinar el uso correcto (o no uso) de los valores.

> üö® Una nota de precauci√≥n
>
> Al trabajar con este conjunto de datos, escribir√°s c√≥digo que calcule algo a partir del texto sin tener que leer o analizar el texto t√∫ mismo. Esta es la esencia del PLN, interpretar el significado o sentimiento sin que un humano tenga que hacerlo. Sin embargo, es posible que leas algunas de las rese√±as negativas. Te insto a no hacerlo, porque no tienes que hacerlo. Algunas de ellas son tontas o irrelevantes, como "El clima no fue bueno", algo fuera del control del hotel, o de hecho, de cualquiera. Pero hay un lado oscuro en algunas rese√±as tambi√©n. A veces las rese√±as negativas son racistas, sexistas, o discriminatorias por edad. Esto es desafortunado pero de esperarse en un conjunto de datos recopilado de un sitio web p√∫blico. Algunos revisores dejan rese√±as que encontrar√≠as de mal gusto, inc√≥modas, o molestas. Es mejor dejar que el c√≥digo mida el sentimiento que leerlas t√∫ mismo y molestarte. Dicho esto, es una minor√≠a la que escribe tales cosas, pero existen de todas formas.

## Ejercicio - Exploraci√≥n de datos
### Cargar los datos

Eso es suficiente examinando los datos visualmente, ¬°ahora escribir√°s algo de c√≥digo y obtendr√°s algunas respuestas! Esta secci√≥n usa la biblioteca pandas. Tu primera tarea es asegurarte de que puedes cargar y leer los datos CSV. La biblioteca pandas tiene un cargador de CSV r√°pido, y el resultado se coloca en un dataframe, como en lecciones anteriores. El CSV que estamos cargando tiene m√°s de medio mill√≥n de filas, pero solo 17 columnas. Pandas te da muchas formas poderosas de interactuar con un dataframe, incluyendo la capacidad de realizar operaciones en cada fila.

De aqu√≠ en adelante en esta lecci√≥n, habr√° fragmentos de c√≥digo y algunas explicaciones del c√≥digo y algunas discusiones sobre lo que significan los resultados. Usa el _notebook.ipynb_ incluido para tu c√≥digo.

Comencemos cargando el archivo de datos que estar√°s usando:

```python
# Load the hotel reviews from CSV
import pandas as pd
import time
# importing time so the start and end time can be used to calculate file loading time
print("Loading data file now, this could take a while depending on file size")
start = time.time()
# df is 'DataFrame' - make sure you downloaded the file to the data folder
df = pd.read_csv('../../data/Hotel_Reviews.csv')
end = time.time()
print("Loading took " + str(round(end - start, 2)) + " seconds")
```

Ahora que los datos est√°n cargados, podemos realizar algunas operaciones sobre ellos. Mant√©n este c√≥digo en la parte superior de tu programa para la siguiente parte.

## Explorar los datos

En este caso, los datos ya est√°n *limpios*, eso significa que est√°n listos para trabajar, y no tienen caracteres en otros idiomas que puedan hacer tropezar a los algoritmos que esperan solo caracteres en ingl√©s.

‚úÖ Puede que tengas que trabajar con datos que requieran alg√∫n procesamiento inicial para formatearlos antes de aplicar t√©cnicas de PLN, pero no esta vez. Si tuvieras que hacerlo, ¬øc√≥mo manejar√≠as los caracteres no ingleses?

T√≥mate un momento para asegurarte de que una vez que los datos est√©n cargados, puedas explorarlos con c√≥digo. Es muy f√°cil querer enfocarse en las columnas `Negative_Review` y `Positive_Review`. Est√°n llenas de texto natural para que tus algoritmos de PLN los procesen. ¬°Pero espera! Antes de saltar al PLN y el sentimiento, deber√≠as seguir el c√≥digo a continuaci√≥n para verificar si los valores dados en el conjunto de datos coinciden con los valores que calculas con pandas.

## Operaciones con dataframes

La primera tarea en esta lecci√≥n es verificar si las siguientes afirmaciones son correctas escribiendo algo de c√≥digo que examine el dataframe (sin cambiarlo).

> Como muchas tareas de programaci√≥n, hay varias formas de completarlo, pero un buen consejo es hacerlo de la manera m√°s simple y f√°cil posible, especialmente si ser√° m√°s f√°cil de entender cuando vuelvas a este c√≥digo en el futuro. Con dataframes, hay una API completa que a menudo tendr√° una manera de hacer lo que deseas de manera eficiente.
Trata las siguientes preguntas como tareas de codificaci√≥n e intenta responderlas sin mirar la soluci√≥n. 1. Imprime la *forma* del dataframe que acabas de cargar (
rows have column `Positive_Review` values of "No Positive" 9. Calculate and print out how many rows have column `Positive_Review` values of "No Positive" **and** `Negative_Review` values of "No Negative" ### Respuestas de c√≥digo 1. Imprime la *forma* del marco de datos que acabas de cargar (la forma es el n√∫mero de filas y columnas) ```python
   print("The shape of the data (rows, cols) is " + str(df.shape))
   > The shape of the data (rows, cols) is (515738, 17)
   ``` 2. Calcula el conteo de frecuencia para las nacionalidades de los revisores: 1. ¬øCu√°ntos valores distintos hay para la columna `Reviewer_Nationality` y cu√°les son? 2. ¬øQu√© nacionalidad de revisor es la m√°s com√∫n en el conjunto de datos (imprime el pa√≠s y el n√∫mero de rese√±as)? ```python
   # value_counts() creates a Series object that has index and values in this case, the country and the frequency they occur in reviewer nationality
   nationality_freq = df["Reviewer_Nationality"].value_counts()
   print("There are " + str(nationality_freq.size) + " different nationalities")
   # print first and last rows of the Series. Change to nationality_freq.to_string() to print all of the data
   print(nationality_freq) 
   
   There are 227 different nationalities
    United Kingdom               245246
    United States of America      35437
    Australia                     21686
    Ireland                       14827
    United Arab Emirates          10235
                                  ...  
    Comoros                           1
    Palau                             1
    Northern Mariana Islands          1
    Cape Verde                        1
    Guinea                            1
   Name: Reviewer_Nationality, Length: 227, dtype: int64
   ``` 3. ¬øCu√°les son las siguientes 10 nacionalidades m√°s frecuentemente encontradas, y su conteo de frecuencia? ```python
      print("The highest frequency reviewer nationality is " + str(nationality_freq.index[0]).strip() + " with " + str(nationality_freq[0]) + " reviews.")
      # Notice there is a leading space on the values, strip() removes that for printing
      # What is the top 10 most common nationalities and their frequencies?
      print("The next 10 highest frequency reviewer nationalities are:")
      print(nationality_freq[1:11].to_string())
      
      The highest frequency reviewer nationality is United Kingdom with 245246 reviews.
      The next 10 highest frequency reviewer nationalities are:
       United States of America     35437
       Australia                    21686
       Ireland                      14827
       United Arab Emirates         10235
       Saudi Arabia                  8951
       Netherlands                   8772
       Switzerland                   8678
       Germany                       7941
       Canada                        7894
       France                        7296
      ``` 3. ¬øCu√°l fue el hotel m√°s frecuentemente revisado para cada una de las 10 nacionalidades de revisores m√°s comunes? ```python
   # What was the most frequently reviewed hotel for the top 10 nationalities
   # Normally with pandas you will avoid an explicit loop, but wanted to show creating a new dataframe using criteria (don't do this with large amounts of data because it could be very slow)
   for nat in nationality_freq[:10].index:
      # First, extract all the rows that match the criteria into a new dataframe
      nat_df = df[df["Reviewer_Nationality"] == nat]   
      # Now get the hotel freq
      freq = nat_df["Hotel_Name"].value_counts()
      print("The most reviewed hotel for " + str(nat).strip() + " was " + str(freq.index[0]) + " with " + str(freq[0]) + " reviews.") 
      
   The most reviewed hotel for United Kingdom was Britannia International Hotel Canary Wharf with 3833 reviews.
   The most reviewed hotel for United States of America was Hotel Esther a with 423 reviews.
   The most reviewed hotel for Australia was Park Plaza Westminster Bridge London with 167 reviews.
   The most reviewed hotel for Ireland was Copthorne Tara Hotel London Kensington with 239 reviews.
   The most reviewed hotel for United Arab Emirates was Millennium Hotel London Knightsbridge with 129 reviews.
   The most reviewed hotel for Saudi Arabia was The Cumberland A Guoman Hotel with 142 reviews.
   The most reviewed hotel for Netherlands was Jaz Amsterdam with 97 reviews.
   The most reviewed hotel for Switzerland was Hotel Da Vinci with 97 reviews.
   The most reviewed hotel for Germany was Hotel Da Vinci with 86 reviews.
   The most reviewed hotel for Canada was St James Court A Taj Hotel London with 61 reviews.
   ``` 4. ¬øCu√°ntas rese√±as hay por hotel (conteo de frecuencia de hotel) en el conjunto de datos? ```python
   # First create a new dataframe based on the old one, removing the uneeded columns
   hotel_freq_df = df.drop(["Hotel_Address", "Additional_Number_of_Scoring", "Review_Date", "Average_Score", "Reviewer_Nationality", "Negative_Review", "Review_Total_Negative_Word_Counts", "Positive_Review", "Review_Total_Positive_Word_Counts", "Total_Number_of_Reviews_Reviewer_Has_Given", "Reviewer_Score", "Tags", "days_since_review", "lat", "lng"], axis = 1)
   
   # Group the rows by Hotel_Name, count them and put the result in a new column Total_Reviews_Found
   hotel_freq_df['Total_Reviews_Found'] = hotel_freq_df.groupby('Hotel_Name').transform('count')
   
   # Get rid of all the duplicated rows
   hotel_freq_df = hotel_freq_df.drop_duplicates(subset = ["Hotel_Name"])
   display(hotel_freq_df) 
   ``` | Nombre_Hotel | N√∫mero_Total_de_Rese√±as | Rese√±as_Encontradas | | :----------------------------------------: | :---------------------: | :-----------------: | | Britannia International Hotel Canary Wharf | 9086 | 4789 | | Park Plaza Westminster Bridge London | 12158 | 4169 | | Copthorne Tara Hotel London Kensington | 7105 | 3578 | | ... | ... | ... | | Mercure Paris Porte d Orleans | 110 | 10 | | Hotel Wagner | 135 | 10 | | Hotel Gallitzinberg | 173 | 8 | Puedes notar que los *contados en el conjunto de datos* resultados no coinciden con el valor en `Total_Number_of_Reviews`. No est√° claro si este valor en el conjunto de datos representaba el n√∫mero total de rese√±as que ten√≠a el hotel, pero no todas fueron extra√≠das, o alg√∫n otro c√°lculo. `Total_Number_of_Reviews` no se usa en el modelo debido a esta falta de claridad. 5. Aunque hay una columna `Average_Score` para cada hotel en el conjunto de datos, tambi√©n puedes calcular un puntaje promedio (obteniendo el promedio de todas las puntuaciones de los revisores en el conjunto de datos para cada hotel). Agrega una nueva columna a tu marco de datos con el encabezado de columna `Calc_Average_Score` que contenga ese promedio calculado. Imprime las columnas `Hotel_Name`, `Average_Score`, y `Calc_Average_Score`. ```python
   # define a function that takes a row and performs some calculation with it
   def get_difference_review_avg(row):
     return row["Average_Score"] - row["Calc_Average_Score"]
   
   # 'mean' is mathematical word for 'average'
   df['Calc_Average_Score'] = round(df.groupby('Hotel_Name').Reviewer_Score.transform('mean'), 1)
   
   # Add a new column with the difference between the two average scores
   df["Average_Score_Difference"] = df.apply(get_difference_review_avg, axis = 1)
   
   # Create a df without all the duplicates of Hotel_Name (so only 1 row per hotel)
   review_scores_df = df.drop_duplicates(subset = ["Hotel_Name"])
   
   # Sort the dataframe to find the lowest and highest average score difference
   review_scores_df = review_scores_df.sort_values(by=["Average_Score_Difference"])
   
   display(review_scores_df[["Average_Score_Difference", "Average_Score", "Calc_Average_Score", "Hotel_Name"]])
   ``` Tambi√©n puedes preguntarte sobre el valor de `Average_Score` y por qu√© a veces es diferente del puntaje promedio calculado. Como no podemos saber por qu√© algunos de los valores coinciden, pero otros tienen una diferencia, es m√°s seguro en este caso usar las puntuaciones de las rese√±as que tenemos para calcular el promedio nosotros mismos. Dicho esto, las diferencias son generalmente muy peque√±as, aqu√≠ est√°n los hoteles con la mayor desviaci√≥n del promedio del conjunto de datos y el promedio calculado: | Diferencia_Promedio_Puntaje | Promedio_Puntaje | Calc_Average_Score | Nombre_Hotel | | :----------------------: | :-----------: | :----------------: | ------------------------------------------: | | -0.8 | 7.7 | 8.5 | Best Western Hotel Astoria | | -0.7 | 8.8 | 9.5 | Hotel Stendhal Place Vend me Paris MGallery | | -0.7 | 7.5 | 8.2 | Mercure Paris Porte d Orleans | | -0.7 | 7.9 | 8.6 | Renaissance Paris Vendome Hotel | | -0.5 | 7.0 | 7.5 | Hotel Royal Elys es | | ... | ... | ... | ... | | 0.7 | 7.5 | 6.8 | Mercure Paris Op ra Faubourg Montmartre | | 0.8 | 7.1 | 6.3 | Holiday Inn Paris Montparnasse Pasteur | | 0.9 | 6.8 | 5.9 | Villa Eugenie | | 0.9 | 8.6 | 7.7 | MARQUIS Faubourg St Honor Relais Ch teaux | | 1.3 | 7.2 | 5.9 | Kube Hotel Ice Bar | Con solo 1 hotel teniendo una diferencia de puntaje mayor a 1, significa que probablemente podemos ignorar la diferencia y usar el puntaje promedio calculado. 6. Calcula e imprime cu√°ntas filas tienen valores de columna `Negative_Review` de "No Negative" 7. Calcula e imprime cu√°ntas filas tienen valores de columna `Positive_Review` de "No Positive" 8. Calcula e imprime cu√°ntas filas tienen valores de columna `Positive_Review` de "No Positive" **y** valores de columna `Negative_Review` de "No Negative" ```python
   # with lambdas:
   start = time.time()
   no_negative_reviews = df.apply(lambda x: True if x['Negative_Review'] == "No Negative" else False , axis=1)
   print("Number of No Negative reviews: " + str(len(no_negative_reviews[no_negative_reviews == True].index)))
   
   no_positive_reviews = df.apply(lambda x: True if x['Positive_Review'] == "No Positive" else False , axis=1)
   print("Number of No Positive reviews: " + str(len(no_positive_reviews[no_positive_reviews == True].index)))
   
   both_no_reviews = df.apply(lambda x: True if x['Negative_Review'] == "No Negative" and x['Positive_Review'] == "No Positive" else False , axis=1)
   print("Number of both No Negative and No Positive reviews: " + str(len(both_no_reviews[both_no_reviews == True].index)))
   end = time.time()
   print("Lambdas took " + str(round(end - start, 2)) + " seconds")
   
   Number of No Negative reviews: 127890
   Number of No Positive reviews: 35946
   Number of both No Negative and No Positive reviews: 127
   Lambdas took 9.64 seconds
   ``` ## Otra manera Otra manera de contar √≠tems sin Lambdas, y usar sum para contar las filas: ```python
   # without lambdas (using a mixture of notations to show you can use both)
   start = time.time()
   no_negative_reviews = sum(df.Negative_Review == "No Negative")
   print("Number of No Negative reviews: " + str(no_negative_reviews))
   
   no_positive_reviews = sum(df["Positive_Review"] == "No Positive")
   print("Number of No Positive reviews: " + str(no_positive_reviews))
   
   both_no_reviews = sum((df.Negative_Review == "No Negative") & (df.Positive_Review == "No Positive"))
   print("Number of both No Negative and No Positive reviews: " + str(both_no_reviews))
   
   end = time.time()
   print("Sum took " + str(round(end - start, 2)) + " seconds")
   
   Number of No Negative reviews: 127890
   Number of No Positive reviews: 35946
   Number of both No Negative and No Positive reviews: 127
   Sum took 0.19 seconds
   ``` Puedes haber notado que hay 127 filas que tienen tanto "No Negative" como "No Positive" valores para las columnas `Negative_Review` y `Positive_Review` respectivamente. Eso significa que el revisor dio al hotel un puntaje num√©rico, pero se neg√≥ a escribir una rese√±a positiva o negativa. Afortunadamente, esta es una peque√±a cantidad de filas (127 de 515738, o 0.02%), por lo que probablemente no sesgar√° nuestro modelo o resultados en ninguna direcci√≥n particular, pero podr√≠as no haber esperado que un conjunto de datos de rese√±as tuviera filas sin rese√±as, por lo que vale la pena explorar los datos para descubrir filas como esta. Ahora que has explorado el conjunto de datos, en la pr√≥xima lecci√≥n filtrar√°s los datos y agregar√°s alg√∫n an√°lisis de sentimiento. --- ## üöÄDesaf√≠o Esta lecci√≥n demuestra, como vimos en lecciones anteriores, lo cr√≠ticamente importante que es entender tus datos y sus peculiaridades antes de realizar operaciones sobre ellos. Los datos basados en texto, en particular, requieren un escrutinio cuidadoso. Profundiza en varios conjuntos de datos pesados en texto y ve si puedes descubrir √°reas que podr√≠an introducir sesgo o sentimiento sesgado en un modelo. ## [Cuestionario post-lectura](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/38/) ## Revisi√≥n y autoestudio Toma [este Camino de Aprendizaje sobre NLP](https://docs.microsoft.com/learn/paths/explore-natural-language-processing/?WT.mc_id=academic-77952-leestott) para descubrir herramientas que probar al construir modelos de habla y texto pesados. ## Asignaci√≥n [NLTK](assignment.md)

        **Descargo de responsabilidad**:
        Este documento ha sido traducido utilizando servicios de traducci√≥n autom√°tica basados en IA. Si bien nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda la traducci√≥n humana profesional. No somos responsables de ning√∫n malentendido o interpretaci√≥n err√≥nea que surja del uso de esta traducci√≥n.