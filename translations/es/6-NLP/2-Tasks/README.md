# Tareas y t√©cnicas comunes de procesamiento de lenguaje natural

Para la mayor√≠a de las tareas de *procesamiento de lenguaje natural*, el texto a procesar debe descomponerse, examinarse y los resultados deben almacenarse o cruzarse con reglas y conjuntos de datos. Estas tareas permiten al programador derivar el _significado_ o _intenci√≥n_ o solo la _frecuencia_ de t√©rminos y palabras en un texto.

## [Cuestionario previo a la lecci√≥n](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/33/)

Vamos a descubrir t√©cnicas comunes utilizadas en el procesamiento de texto. Combinadas con el aprendizaje autom√°tico, estas t√©cnicas te ayudan a analizar grandes cantidades de texto de manera eficiente. Sin embargo, antes de aplicar ML a estas tareas, entendamos los problemas que enfrenta un especialista en PLN.

## Tareas comunes en PLN

Existen diferentes formas de analizar un texto en el que est√°s trabajando. Hay tareas que puedes realizar y a trav√©s de estas tareas puedes comprender el texto y sacar conclusiones. Normalmente, llevas a cabo estas tareas en una secuencia.

### Tokenizaci√≥n

Probablemente, lo primero que la mayor√≠a de los algoritmos de PLN deben hacer es dividir el texto en tokens o palabras. Aunque esto suena simple, tener en cuenta la puntuaci√≥n y los delimitadores de palabras y oraciones en diferentes idiomas puede complicarlo. Es posible que debas usar varios m√©todos para determinar las demarcaciones.

![tokenization](../../../../translated_images/tokenization.1641a160c66cd2d93d4524e8114e93158a9ce0eba3ecf117bae318e8a6ad3487.es.png)
> Tokenizando una oraci√≥n de **Orgullo y Prejuicio**. Infograf√≠a por [Jen Looper](https://twitter.com/jenlooper)

### Embeddings

[Embeddings de palabras](https://wikipedia.org/wiki/Word_embedding) son una forma de convertir tus datos de texto num√©ricamente. Los embeddings se realizan de manera que las palabras con un significado similar o palabras usadas juntas se agrupan.

![word embeddings](../../../../translated_images/embedding.2cf8953c4b3101d188c2f61a5de5b6f53caaa5ad4ed99236d42bc3b6bd6a1fe2.es.png)
> "Tengo el mayor respeto por tus nervios, son mis viejos amigos." - Embeddings de palabras para una oraci√≥n en **Orgullo y Prejuicio**. Infograf√≠a por [Jen Looper](https://twitter.com/jenlooper)

‚úÖ Prueba [esta herramienta interesante](https://projector.tensorflow.org/) para experimentar con embeddings de palabras. Hacer clic en una palabra muestra grupos de palabras similares: 'juguete' se agrupa con 'disney', 'lego', 'playstation' y 'consola'.

### An√°lisis gramatical y etiquetado de partes del discurso

Cada palabra que ha sido tokenizada puede etiquetarse como una parte del discurso: un sustantivo, verbo o adjetivo. La oraci√≥n `the quick red fox jumped over the lazy brown dog` podr√≠a etiquetarse como POS: zorro = sustantivo, salt√≥ = verbo.

![parsing](../../../../translated_images/parse.d0c5bbe1106eae8fe7d60a183cd1736c8b6cec907f38000366535f84f3036101.es.png)

> Analizando una oraci√≥n de **Orgullo y Prejuicio**. Infograf√≠a por [Jen Looper](https://twitter.com/jenlooper)

El an√°lisis gramatical es reconocer qu√© palabras est√°n relacionadas entre s√≠ en una oraci√≥n. Por ejemplo, `the quick red fox jumped` es una secuencia adjetivo-sustantivo-verbo que est√° separada de la secuencia `lazy brown dog`.

### Frecuencia de palabras y frases

Un procedimiento √∫til al analizar un gran cuerpo de texto es construir un diccionario de cada palabra o frase de inter√©s y cu√°ntas veces aparece. La frase `the quick red fox jumped over the lazy brown dog` tiene una frecuencia de palabras de 2 para "the".

Veamos un ejemplo de texto donde contamos la frecuencia de palabras. El poema de Rudyard Kipling "Los Ganadores" contiene el siguiente verso:

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

Como las frecuencias de frases pueden ser insensibles a may√∫sculas o sensibles a may√∫sculas seg√∫n sea necesario, la frase `a friend` has a frequency of 2 and `the` has a frequency of 6, and `travels` es 2.

### N-gramas

Un texto puede dividirse en secuencias de palabras de una longitud establecida, una sola palabra (unigrama), dos palabras (bigramas), tres palabras (trigramas) o cualquier n√∫mero de palabras (n-gramas).

Por ejemplo, `the quick red fox jumped over the lazy brown dog` con una puntuaci√≥n de n-grama de 2 produce los siguientes n-gramas:

1. the quick 
2. quick red 
3. red fox
4. fox jumped 
5. jumped over 
6. over the 
7. the lazy 
8. lazy brown 
9. brown dog

Podr√≠a ser m√°s f√°cil visualizarlo como una caja deslizante sobre la oraci√≥n. Aqu√≠ est√° para n-gramas de 3 palabras, el n-grama est√° en negrita en cada oraci√≥n:

1.   <u>**the quick red**</u> fox jumped over the lazy brown dog
2.   the **<u>quick red fox</u>** jumped over the lazy brown dog
3.   the quick **<u>red fox jumped</u>** over the lazy brown dog
4.   the quick red **<u>fox jumped over</u>** the lazy brown dog
5.   the quick red fox **<u>jumped over the</u>** lazy brown dog
6.   the quick red fox jumped **<u>over the lazy</u>** brown dog
7.   the quick red fox jumped over <u>**the lazy brown**</u> dog
8.   the quick red fox jumped over the **<u>lazy brown dog</u>**

![n-grams sliding window](../../../../6-NLP/2-Tasks/images/n-grams.gif)

> Valor de n-grama de 3: Infograf√≠a por [Jen Looper](https://twitter.com/jenlooper)

### Extracci√≥n de frases nominales

En la mayor√≠a de las oraciones, hay un sustantivo que es el sujeto u objeto de la oraci√≥n. En ingl√©s, a menudo se identifica por tener 'a', 'an' o 'the' antes de √©l. Identificar el sujeto u objeto de una oraci√≥n extrayendo la frase nominal es una tarea com√∫n en PLN cuando se intenta entender el significado de una oraci√≥n.

‚úÖ En la oraci√≥n "No puedo fijar la hora, ni el lugar, ni la mirada ni las palabras, que sentaron las bases. Hace demasiado tiempo. Estaba en medio antes de saber que hab√≠a comenzado.", ¬øpuedes identificar las frases nominales?

En la oraci√≥n `the quick red fox jumped over the lazy brown dog` hay 2 frases nominales: **quick red fox** y **lazy brown dog**.

### An√°lisis de sentimiento

Una oraci√≥n o texto puede analizarse para determinar su sentimiento, o cu√°n *positivo* o *negativo* es. El sentimiento se mide en *polaridad* y *objetividad/subjetividad*. La polaridad se mide de -1.0 a 1.0 (negativo a positivo) y de 0.0 a 1.0 (m√°s objetivo a m√°s subjetivo).

‚úÖ M√°s adelante aprender√°s que hay diferentes formas de determinar el sentimiento utilizando el aprendizaje autom√°tico, pero una forma es tener una lista de palabras y frases categorizadas como positivas o negativas por un experto humano y aplicar ese modelo al texto para calcular una puntuaci√≥n de polaridad. ¬øPuedes ver c√≥mo esto funcionar√≠a en algunas circunstancias y menos en otras?

### Inflecci√≥n

La inflecci√≥n te permite tomar una palabra y obtener el singular o plural de la palabra.

### Lematizaci√≥n

Un *lema* es la ra√≠z o palabra principal de un conjunto de palabras, por ejemplo, *flew*, *flies*, *flying* tienen como lema el verbo *fly*.

Tambi√©n hay bases de datos √∫tiles disponibles para el investigador de PLN, notablemente:

### WordNet

[WordNet](https://wordnet.princeton.edu/) es una base de datos de palabras, sin√≥nimos, ant√≥nimos y muchos otros detalles para cada palabra en muchos idiomas diferentes. Es incre√≠blemente √∫til al intentar construir traducciones, correctores ortogr√°ficos o herramientas de lenguaje de cualquier tipo.

## Bibliotecas de PLN

Afortunadamente, no tienes que construir todas estas t√©cnicas t√∫ mismo, ya que hay excelentes bibliotecas de Python disponibles que lo hacen mucho m√°s accesible para los desarrolladores que no est√°n especializados en procesamiento de lenguaje natural o aprendizaje autom√°tico. Las pr√≥ximas lecciones incluyen m√°s ejemplos de estas, pero aqu√≠ aprender√°s algunos ejemplos √∫tiles para ayudarte con la siguiente tarea.

### Ejercicio - usando `TextBlob` library

Let's use a library called TextBlob as it contains helpful APIs for tackling these types of tasks. TextBlob "stands on the giant shoulders of [NLTK](https://nltk.org) and [pattern](https://github.com/clips/pattern), and plays nicely with both." It has a considerable amount of ML embedded in its API.

> Note: A useful [Quick Start](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart) guide is available for TextBlob that is recommended for experienced Python developers 

When attempting to identify *noun phrases*, TextBlob offers several options of extractors to find noun phrases. 

1. Take a look at `ConllExtractor`.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > ¬øQu√© est√° pasando aqu√≠? [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) es "Un extractor de frases nominales que utiliza an√°lisis por fragmentos entrenados con el corpus de entrenamiento ConLL-2000." ConLL-2000 se refiere a la Conferencia de 2000 sobre Aprendizaje Computacional del Lenguaje Natural. Cada a√±o la conferencia organizaba un taller para abordar un problema espinoso de PLN, y en 2000 fue la fragmentaci√≥n de sustantivos. Se entren√≥ un modelo en el Wall Street Journal, con "las secciones 15-18 como datos de entrenamiento (211727 tokens) y la secci√≥n 20 como datos de prueba (47377 tokens)". Puedes ver los procedimientos utilizados [aqu√≠](https://www.clips.uantwerpen.be/conll2000/chunking/) y los [resultados](https://ifarm.nl/erikt/research/np-chunking.html).

### Desaf√≠o - mejorando tu bot con PLN

En la lecci√≥n anterior construiste un bot de preguntas y respuestas muy simple. Ahora, har√°s que Marvin sea un poco m√°s simp√°tico analizando tu entrada para detectar el sentimiento y mostrando una respuesta que coincida con el sentimiento. Tambi√©n necesitar√°s identificar una `noun_phrase` y preguntar sobre ella.

Tus pasos al construir un mejor bot conversacional:

1. Imprime instrucciones aconsejando al usuario c√≥mo interactuar con el bot
2. Inicia el bucle 
   1. Acepta la entrada del usuario
   2. Si el usuario ha pedido salir, entonces salir
   3. Procesa la entrada del usuario y determina la respuesta de sentimiento adecuada
   4. Si se detecta una frase nominal en el sentimiento, plural√≠zala y pide m√°s informaci√≥n sobre ese tema
   5. Imprime la respuesta
3. vuelve al paso 2

Aqu√≠ est√° el fragmento de c√≥digo para determinar el sentimiento usando TextBlob. Nota que solo hay cuatro *gradientes* de respuesta de sentimiento (podr√≠as tener m√°s si lo deseas):

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

Aqu√≠ hay un ejemplo de salida para guiarte (la entrada del usuario est√° en las l√≠neas que comienzan con >):

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

Una posible soluci√≥n a la tarea est√° [aqu√≠](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/2-Tasks/solution/bot.py)

‚úÖ Verificaci√≥n de conocimiento

1. ¬øCrees que las respuestas simp√°ticas podr√≠an 'enga√±ar' a alguien haci√©ndole pensar que el bot realmente los entend√≠a?
2. ¬øHace que el bot sea m√°s 'cre√≠ble' identificar la frase nominal?
3. ¬øPor qu√© ser√≠a √∫til extraer una 'frase nominal' de una oraci√≥n?

---

Implementa el bot en la verificaci√≥n de conocimiento previa y pru√©balo con un amigo. ¬øPuede enga√±arlo? ¬øPuedes hacer que tu bot sea m√°s 'cre√≠ble'?

## üöÄDesaf√≠o

Toma una tarea en la verificaci√≥n de conocimiento previa e intenta implementarla. Prueba el bot con un amigo. ¬øPuede enga√±arlo? ¬øPuedes hacer que tu bot sea m√°s 'cre√≠ble'?

## [Cuestionario posterior a la lecci√≥n](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/34/)

## Revisi√≥n y autoestudio

En las pr√≥ximas lecciones aprender√°s m√°s sobre el an√°lisis de sentimiento. Investiga esta interesante t√©cnica en art√≠culos como estos en [KDNuggets](https://www.kdnuggets.com/tag/nlp)

## Tarea 

[Haz que un bot responda](assignment.md)

**Descargo de responsabilidad**:
Este documento ha sido traducido utilizando servicios de traducci√≥n automatizados por IA. Si bien nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional humana. No somos responsables de ning√∫n malentendido o interpretaci√≥n err√≥nea que surja del uso de esta traducci√≥n.