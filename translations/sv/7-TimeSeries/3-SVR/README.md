<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "482bccabe1df958496ea71a3667995cd",
  "translation_date": "2025-09-05T21:23:41+00:00",
  "source_file": "7-TimeSeries/3-SVR/README.md",
  "language_code": "sv"
}
-->
# Tidsserieprognoser med Support Vector Regressor

I den f칬reg친ende lektionen l칛rde du dig hur man anv칛nder ARIMA-modellen f칬r att g칬ra tidsserieprognoser. Nu ska vi titta p친 Support Vector Regressor-modellen, som 칛r en regressionsmodell som anv칛nds f칬r att f칬ruts칛ga kontinuerliga data.

## [Quiz f칬re lektionen](https://ff-quizzes.netlify.app/en/ml/) 

## Introduktion

I denna lektion kommer du att uppt칛cka ett specifikt s칛tt att bygga modeller med [**SVM**: **S**upport **V**ector **M**achine](https://en.wikipedia.org/wiki/Support-vector_machine) f칬r regression, eller **SVR: Support Vector Regressor**. 

### SVR i kontexten av tidsserier [^1]

Innan vi f칬rst친r vikten av SVR f칬r tidsserieprognoser, 칛r h칛r n친gra viktiga begrepp du beh칬ver k칛nna till:

- **Regression:** En teknik f칬r 칬vervakad inl칛rning som anv칛nds f칬r att f칬ruts칛ga kontinuerliga v칛rden fr친n en given upps칛ttning indata. Id칠n 칛r att passa en kurva (eller linje) i funktionsutrymmet som har maximalt antal datapunkter. [Klicka h칛r](https://en.wikipedia.org/wiki/Regression_analysis) f칬r mer information.
- **Support Vector Machine (SVM):** En typ av 칬vervakad maskininl칛rningsmodell som anv칛nds f칬r klassificering, regression och detektering av avvikelser. Modellen 칛r ett hyperplan i funktionsutrymmet, som i fallet med klassificering fungerar som en gr칛ns, och i fallet med regression fungerar som den b칛sta anpassade linjen. I SVM anv칛nds vanligtvis en k칛rnfunktion f칬r att transformera datasetet till ett utrymme med h칬gre dimensioner, s친 att de kan separeras enklare. [Klicka h칛r](https://en.wikipedia.org/wiki/Support-vector_machine) f칬r mer information om SVM.
- **Support Vector Regressor (SVR):** En typ av SVM som anv칛nds f칬r att hitta den b칛sta anpassade linjen (som i fallet med SVM 칛r ett hyperplan) som har maximalt antal datapunkter.

### Varf칬r SVR? [^1]

I den senaste lektionen l칛rde du dig om ARIMA, som 칛r en mycket framg친ngsrik statistisk linj칛r metod f칬r att f칬ruts칛ga tidsseriedata. Men i m친nga fall har tidsseriedata *icke-linj칛ritet*, vilket inte kan modelleras av linj칛ra metoder. I s친dana fall g칬r SVM:s f칬rm친ga att hantera icke-linj칛ritet i data f칬r regressionsuppgifter SVR framg친ngsrik f칬r tidsserieprognoser.

## 칐vning - bygg en SVR-modell

De f칬rsta stegen f칬r databeredning 칛r desamma som i den f칬reg친ende lektionen om [ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA). 

칐ppna mappen [_/working_](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/3-SVR/working) i denna lektion och hitta filen [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/7-TimeSeries/3-SVR/working/notebook.ipynb). [^2]

1. K칬r notebooken och importera de n칬dv칛ndiga biblioteken: [^2]

   ```python
   import sys
   sys.path.append('../../')
   ```

   ```python
   import os
   import warnings
   import matplotlib.pyplot as plt
   import numpy as np
   import pandas as pd
   import datetime as dt
   import math
   
   from sklearn.svm import SVR
   from sklearn.preprocessing import MinMaxScaler
   from common.utils import load_data, mape
   ```

2. Ladda data fr친n filen `/data/energy.csv` till en Pandas-dataram och granska den: [^2]

   ```python
   energy = load_data('../../data')[['load']]
   ```

3. Plotta all tillg칛nglig energidata fr친n januari 2012 till december 2014: [^2]

   ```python
   energy.plot(y='load', subplots=True, figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![full data](../../../../7-TimeSeries/3-SVR/images/full-data.png)

   Nu ska vi bygga v친r SVR-modell.

### Skapa tr칛nings- och testdataset

Nu 칛r din data laddad, s친 du kan dela upp den i tr칛nings- och testdataset. D칛refter omformar du datan f칬r att skapa ett dataset baserat p친 tidssteg, vilket kommer att beh칬vas f칬r SVR. Du tr칛nar din modell p친 tr칛ningsdatasetet. N칛r modellen har tr칛nats klart utv칛rderar du dess noggrannhet p친 tr칛ningsdatasetet, testdatasetet och sedan hela datasetet f칬r att se den 칬vergripande prestandan. Du m친ste s칛kerst칛lla att testdatasetet t칛cker en senare tidsperiod 칛n tr칛ningsdatasetet f칬r att s칛kerst칛lla att modellen inte f친r information fr친n framtida tidsperioder [^2] (en situation som kallas *칬veranpassning*).

1. Tilldela en tv친m친nadersperiod fr친n 1 september till 31 oktober 2014 till tr칛ningsdatasetet. Testdatasetet kommer att inkludera tv친m친nadersperioden fr친n 1 november till 31 december 2014: [^2]

   ```python
   train_start_dt = '2014-11-01 00:00:00'
   test_start_dt = '2014-12-30 00:00:00'
   ```

2. Visualisera skillnaderna: [^2]

   ```python
   energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)][['load']].rename(columns={'load':'train'}) \
       .join(energy[test_start_dt:][['load']].rename(columns={'load':'test'}), how='outer') \
       .plot(y=['train', 'test'], figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![training and testing data](../../../../7-TimeSeries/3-SVR/images/train-test.png)

### F칬rbered data f칬r tr칛ning

Nu beh칬ver du f칬rbereda data f칬r tr칛ning genom att filtrera och skala din data. Filtrera ditt dataset f칬r att endast inkludera de tidsperioder och kolumner du beh칬ver, och skala f칬r att s칛kerst칛lla att datan projiceras inom intervallet 0,1.

1. Filtrera det ursprungliga datasetet f칬r att endast inkludera de n칛mnda tidsperioderna per set och endast inkludera den n칬dv칛ndiga kolumnen 'load' plus datum: [^2]

   ```python
   train = energy.copy()[(energy.index >= train_start_dt) & (energy.index < test_start_dt)][['load']]
   test = energy.copy()[energy.index >= test_start_dt][['load']]
   
   print('Training data shape: ', train.shape)
   print('Test data shape: ', test.shape)
   ```

   ```output
   Training data shape:  (1416, 1)
   Test data shape:  (48, 1)
   ```
   
2. Skala tr칛ningsdatan till intervallet (0, 1): [^2]

   ```python
   scaler = MinMaxScaler()
   train['load'] = scaler.fit_transform(train)
   ```
   
4. Skala nu testdatan: [^2]

   ```python
   test['load'] = scaler.transform(test)
   ```

### Skapa data med tidssteg [^1]

F칬r SVR omvandlar du indata till formen `[batch, timesteps]`. S친 du omformar den befintliga `train_data` och `test_data` s친 att det finns en ny dimension som h칛nvisar till tidsstegen. 

```python
# Converting to numpy arrays
train_data = train.values
test_data = test.values
```

F칬r detta exempel tar vi `timesteps = 5`. S친 indata till modellen 칛r datan f칬r de f칬rsta 4 tidsstegen, och utdata kommer att vara datan f칬r det 5:e tidssteget.

```python
timesteps=5
```

Omvandla tr칛ningsdata till en 2D-tensor med hj칛lp av n칛stlad listkomprimering:

```python
train_data_timesteps=np.array([[j for j in train_data[i:i+timesteps]] for i in range(0,len(train_data)-timesteps+1)])[:,:,0]
train_data_timesteps.shape
```

```output
(1412, 5)
```

Omvandla testdata till en 2D-tensor:

```python
test_data_timesteps=np.array([[j for j in test_data[i:i+timesteps]] for i in range(0,len(test_data)-timesteps+1)])[:,:,0]
test_data_timesteps.shape
```

```output
(44, 5)
```

V칛lja indata och utdata fr친n tr칛nings- och testdata:

```python
x_train, y_train = train_data_timesteps[:,:timesteps-1],train_data_timesteps[:,[timesteps-1]]
x_test, y_test = test_data_timesteps[:,:timesteps-1],test_data_timesteps[:,[timesteps-1]]

print(x_train.shape, y_train.shape)
print(x_test.shape, y_test.shape)
```

```output
(1412, 4) (1412, 1)
(44, 4) (44, 1)
```

### Implementera SVR [^1]

Nu 칛r det dags att implementera SVR. F칬r att l칛sa mer om denna implementering kan du referera till [denna dokumentation](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html). F칬r v친r implementering f칬ljer vi dessa steg:

  1. Definiera modellen genom att kalla p친 `SVR()` och skicka in modellens hyperparametrar: kernel, gamma, c och epsilon
  2. F칬rbered modellen f칬r tr칛ningsdata genom att kalla p친 funktionen `fit()`
  3. G칬r f칬ruts칛gelser genom att kalla p친 funktionen `predict()`

Nu skapar vi en SVR-modell. H칛r anv칛nder vi [RBF-k칛rnan](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel), och st칛ller in hyperparametrarna gamma, C och epsilon till 0.5, 10 och 0.05 respektive.

```python
model = SVR(kernel='rbf',gamma=0.5, C=10, epsilon = 0.05)
```

#### Tr칛na modellen p친 tr칛ningsdata [^1]

```python
model.fit(x_train, y_train[:,0])
```

```output
SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.05, gamma=0.5,
    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)
```

#### G칬r modellf칬ruts칛gelser [^1]

```python
y_train_pred = model.predict(x_train).reshape(-1,1)
y_test_pred = model.predict(x_test).reshape(-1,1)

print(y_train_pred.shape, y_test_pred.shape)
```

```output
(1412, 1) (44, 1)
```

Du har byggt din SVR! Nu beh칬ver vi utv칛rdera den.

### Utv칛rdera din modell [^1]

F칬r utv칛rdering kommer vi f칬rst att skala tillbaka datan till v친r ursprungliga skala. Sedan, f칬r att kontrollera prestandan, kommer vi att plotta den ursprungliga och f칬rutsagda tidsserieplotten, och 칛ven skriva ut MAPE-resultatet.

Skala tillbaka den f칬rutsagda och ursprungliga utdata:

```python
# Scaling the predictions
y_train_pred = scaler.inverse_transform(y_train_pred)
y_test_pred = scaler.inverse_transform(y_test_pred)

print(len(y_train_pred), len(y_test_pred))
```

```python
# Scaling the original values
y_train = scaler.inverse_transform(y_train)
y_test = scaler.inverse_transform(y_test)

print(len(y_train), len(y_test))
```

#### Kontrollera modellens prestanda p친 tr칛nings- och testdata [^1]

Vi extraherar tidsst칛mplarna fr친n datasetet f칬r att visa p친 x-axeln i v친r plot. Observera att vi anv칛nder de f칬rsta ```timesteps-1``` v칛rdena som indata f칬r den f칬rsta utdata, s친 tidsst칛mplarna f칬r utdata b칬rjar efter det.

```python
train_timestamps = energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)].index[timesteps-1:]
test_timestamps = energy[test_start_dt:].index[timesteps-1:]

print(len(train_timestamps), len(test_timestamps))
```

```output
1412 44
```

Plotta f칬ruts칛gelser f칬r tr칛ningsdata:

```python
plt.figure(figsize=(25,6))
plt.plot(train_timestamps, y_train, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(train_timestamps, y_train_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.title("Training data prediction")
plt.show()
```

![training data prediction](../../../../7-TimeSeries/3-SVR/images/train-data-predict.png)

Skriv ut MAPE f칬r tr칛ningsdata

```python
print('MAPE for training data: ', mape(y_train_pred, y_train)*100, '%')
```

```output
MAPE for training data: 1.7195710200875551 %
```

Plotta f칬ruts칛gelser f칬r testdata

```python
plt.figure(figsize=(10,3))
plt.plot(test_timestamps, y_test, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(test_timestamps, y_test_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![testing data prediction](../../../../7-TimeSeries/3-SVR/images/test-data-predict.png)

Skriv ut MAPE f칬r testdata

```python
print('MAPE for testing data: ', mape(y_test_pred, y_test)*100, '%')
```

```output
MAPE for testing data:  1.2623790187854018 %
```

游끥 Du har ett mycket bra resultat p친 testdatasetet!

### Kontrollera modellens prestanda p친 hela datasetet [^1]

```python
# Extracting load values as numpy array
data = energy.copy().values

# Scaling
data = scaler.transform(data)

# Transforming to 2D tensor as per model input requirement
data_timesteps=np.array([[j for j in data[i:i+timesteps]] for i in range(0,len(data)-timesteps+1)])[:,:,0]
print("Tensor shape: ", data_timesteps.shape)

# Selecting inputs and outputs from data
X, Y = data_timesteps[:,:timesteps-1],data_timesteps[:,[timesteps-1]]
print("X shape: ", X.shape,"\nY shape: ", Y.shape)
```

```output
Tensor shape:  (26300, 5)
X shape:  (26300, 4) 
Y shape:  (26300, 1)
```

```python
# Make model predictions
Y_pred = model.predict(X).reshape(-1,1)

# Inverse scale and reshape
Y_pred = scaler.inverse_transform(Y_pred)
Y = scaler.inverse_transform(Y)
```

```python
plt.figure(figsize=(30,8))
plt.plot(Y, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(Y_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![full data prediction](../../../../7-TimeSeries/3-SVR/images/full-data-predict.png)

```python
print('MAPE: ', mape(Y_pred, Y)*100, '%')
```

```output
MAPE:  2.0572089029888656 %
```

游끥 Mycket fina plottar som visar en modell med god noggrannhet. Bra jobbat!

---

## 游Utmaning

- F칬rs칬k att justera hyperparametrarna (gamma, C, epsilon) n칛r du skapar modellen och utv칛rdera p친 datan f칬r att se vilka upps칛ttningar av hyperparametrar som ger de b칛sta resultaten p친 testdatan. F칬r att veta mer om dessa hyperparametrar kan du referera till dokumentet [h칛r](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel). 
- F칬rs칬k att anv칛nda olika k칛rnfunktioner f칬r modellen och analysera deras prestanda p친 datasetet. Ett hj칛lpsamt dokument kan hittas [h칛r](https://scikit-learn.org/stable/modules/svm.html#kernel-functions).
- F칬rs칬k att anv칛nda olika v칛rden f칬r `timesteps` f칬r modellen att titta tillbaka f칬r att g칬ra f칬ruts칛gelser.

## [Quiz efter lektionen](https://ff-quizzes.netlify.app/en/ml/)

## Granskning & Sj칛lvstudier

Denna lektion introducerade till칛mpningen av SVR f칬r tidsserieprognoser. F칬r att l칛sa mer om SVR kan du referera till [denna blogg](https://www.analyticsvidhya.com/blog/2020/03/support-vector-regression-tutorial-for-machine-learning/). Denna [dokumentation om scikit-learn](https://scikit-learn.org/stable/modules/svm.html) ger en mer omfattande f칬rklaring om SVM i allm칛nhet, [SVR](https://scikit-learn.org/stable/modules/svm.html#regression) och 칛ven andra implementeringsdetaljer s친som de olika [k칛rnfunktionerna](https://scikit-learn.org/stable/modules/svm.html#kernel-functions) som kan anv칛ndas, och deras parametrar.

## Uppgift

[En ny SVR-modell](assignment.md)

## Krediter

[^1]: Text, kod och resultat i denna sektion bidrog av [@AnirbanMukherjeeXD](https://github.com/AnirbanMukherjeeXD)
[^2]: Text, kod och resultat i denna sektion togs fr친n [ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA)

---

**Ansvarsfriskrivning**:  
Detta dokument har 칬versatts med hj칛lp av AI-칬vers칛ttningstj칛nsten [Co-op Translator](https://github.com/Azure/co-op-translator). 츿ven om vi str칛var efter noggrannhet, v칛nligen notera att automatiska 칬vers칛ttningar kan inneh친lla fel eller felaktigheter. Det ursprungliga dokumentet p친 dess originalspr친k b칬r betraktas som den auktoritativa k칛llan. F칬r kritisk information rekommenderas professionell m칛nsklig 칬vers칛ttning. Vi ansvarar inte f칬r eventuella missf칬rst친nd eller feltolkningar som uppst친r vid anv칛ndning av denna 칬vers칛ttning.