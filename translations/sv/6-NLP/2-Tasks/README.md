<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "5f3cb462e3122e1afe7ab0050ccf2bd3",
  "translation_date": "2025-09-05T22:13:18+00:00",
  "source_file": "6-NLP/2-Tasks/README.md",
  "language_code": "sv"
}
-->
# Vanliga uppgifter och tekniker inom naturlig spr√•kbehandling

F√∂r de flesta *uppgifter inom naturlig spr√•kbehandling* m√•ste texten som ska bearbetas brytas ner, analyseras och resultaten lagras eller j√§mf√∂ras med regler och dataset. Dessa uppgifter g√∂r det m√∂jligt f√∂r programmeraren att h√§rleda _meningen_ eller _avsikten_ eller bara _frekvensen_ av termer och ord i en text.

## [Quiz f√∂re f√∂rel√§sningen](https://ff-quizzes.netlify.app/en/ml/)

L√•t oss utforska vanliga tekniker som anv√§nds f√∂r att bearbeta text. Kombinerat med maskininl√§rning hj√§lper dessa tekniker dig att analysera stora m√§ngder text effektivt. Innan du till√§mpar ML p√• dessa uppgifter, l√•t oss f√∂rst√• de problem som en NLP-specialist st√∂ter p√•.

## Vanliga uppgifter inom NLP

Det finns olika s√§tt att analysera en text du arbetar med. Det finns uppgifter du kan utf√∂ra, och genom dessa uppgifter kan du f√• en f√∂rst√•else f√∂r texten och dra slutsatser. Du utf√∂r vanligtvis dessa uppgifter i en sekvens.

### Tokenisering

F√∂rmodligen det f√∂rsta de flesta NLP-algoritmer m√•ste g√∂ra √§r att dela upp texten i tokens, eller ord. √Ñven om detta l√•ter enkelt kan det bli knepigt att ta h√§nsyn till skiljetecken och olika spr√•ks ord- och meningsavgr√§nsare. Du kan beh√∂va anv√§nda olika metoder f√∂r att best√§mma avgr√§nsningar.

![tokenisering](../../../../6-NLP/2-Tasks/images/tokenization.png)
> Tokenisering av en mening fr√•n **Stolthet och f√∂rdom**. Infografik av [Jen Looper](https://twitter.com/jenlooper)

### Embeddingar

[Word embeddings](https://wikipedia.org/wiki/Word_embedding) √§r ett s√§tt att konvertera din textdata till numeriska v√§rden. Embeddingar g√∂rs p√• ett s√§tt s√• att ord med liknande betydelse eller ord som anv√§nds tillsammans grupperas.

![word embeddings](../../../../6-NLP/2-Tasks/images/embedding.png)
> "Jag har den st√∂rsta respekt f√∂r dina nerver, de √§r mina gamla v√§nner." - Word embeddings f√∂r en mening i **Stolthet och f√∂rdom**. Infografik av [Jen Looper](https://twitter.com/jenlooper)

‚úÖ Prova [detta intressanta verktyg](https://projector.tensorflow.org/) f√∂r att experimentera med word embeddings. Genom att klicka p√• ett ord visas kluster av liknande ord: 'leksak' grupperas med 'disney', 'lego', 'playstation' och 'konsol'.

### Parsing & Part-of-speech Tagging

Varje ord som har tokeniserats kan taggas som en del av talet - ett substantiv, verb eller adjektiv. Meningen `den snabba r√∂da r√§ven hoppade √∂ver den lata bruna hunden` kan POS-taggas som r√§v = substantiv, hoppade = verb.

![parsing](../../../../6-NLP/2-Tasks/images/parse.png)

> Parsing av en mening fr√•n **Stolthet och f√∂rdom**. Infografik av [Jen Looper](https://twitter.com/jenlooper)

Parsing inneb√§r att k√§nna igen vilka ord som √§r relaterade till varandra i en mening - till exempel `den snabba r√∂da r√§ven hoppade` √§r en adjektiv-substantiv-verb-sekvens som √§r separat fr√•n sekvensen `den lata bruna hunden`.

### Ord- och frasfrekvenser

En anv√§ndbar procedur vid analys av en stor textmassa √§r att bygga en ordlista √∂ver varje ord eller fras av intresse och hur ofta det f√∂rekommer. Frasen `den snabba r√∂da r√§ven hoppade √∂ver den lata bruna hunden` har en ordfrekvens p√• 2 f√∂r ordet "den".

L√•t oss titta p√• ett exempel d√§r vi r√§knar frekvensen av ord. Rudyard Kiplings dikt "The Winners" inneh√•ller f√∂ljande vers:

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

Eftersom frasfrekvenser kan vara skiftl√§gesk√§nsliga eller skiftl√§gesok√§nsliga efter behov, har frasen `en v√§n` en frekvens p√• 2 och `den` har en frekvens p√• 6, och `reser` √§r 2.

### N-grams

En text kan delas upp i sekvenser av ord med en viss l√§ngd, ett enda ord (unigram), tv√• ord (bigram), tre ord (trigram) eller valfritt antal ord (n-grams).

Till exempel `den snabba r√∂da r√§ven hoppade √∂ver den lata bruna hunden` med ett n-gram-v√§rde p√• 2 producerar f√∂ljande n-grams:

1. den snabba  
2. snabba r√∂da  
3. r√∂da r√§ven  
4. r√§ven hoppade  
5. hoppade √∂ver  
6. √∂ver den  
7. den lata  
8. lata bruna  
9. bruna hunden  

Det kan vara l√§ttare att visualisera det som en glidande ruta √∂ver meningen. H√§r √§r det f√∂r n-grams med 3 ord, n-grammet √§r fetstil i varje mening:

1.   <u>**den snabba r√∂da**</u> r√§ven hoppade √∂ver den lata bruna hunden  
2.   den **<u>snabba r√∂da r√§ven</u>** hoppade √∂ver den lata bruna hunden  
3.   den snabba **<u>r√∂da r√§ven hoppade</u>** √∂ver den lata bruna hunden  
4.   den snabba r√∂da **<u>r√§ven hoppade √∂ver</u>** den lata bruna hunden  
5.   den snabba r√∂da r√§ven **<u>hoppade √∂ver den</u>** lata bruna hunden  
6.   den snabba r√∂da r√§ven hoppade **<u>√∂ver den lata</u>** bruna hunden  
7.   den snabba r√∂da r√§ven hoppade √∂ver <u>**den lata bruna**</u> hunden  
8.   den snabba r√∂da r√§ven hoppade √∂ver den **<u>lata bruna hunden</u>**

![n-grams glidande ruta](../../../../6-NLP/2-Tasks/images/n-grams.gif)

> N-gram-v√§rde p√• 3: Infografik av [Jen Looper](https://twitter.com/jenlooper)

### Substantivfrasextraktion

I de flesta meningar finns det ett substantiv som √§r subjekt eller objekt i meningen. P√• engelska kan det ofta identifieras genom att det f√∂reg√•s av 'a', 'an' eller 'the'. Att identifiera subjektet eller objektet i en mening genom att 'extrahera substantivfrasen' √§r en vanlig uppgift inom NLP n√§r man f√∂rs√∂ker f√∂rst√• meningen i en mening.

‚úÖ I meningen "Jag kan inte best√§mma mig f√∂r timmen, eller platsen, eller utseendet eller orden, som lade grunden. Det √§r f√∂r l√§nge sedan. Jag var mitt i det innan jag visste att jag hade b√∂rjat.", kan du identifiera substantivfraserna?

I meningen `den snabba r√∂da r√§ven hoppade √∂ver den lata bruna hunden` finns det 2 substantivfraser: **snabba r√∂da r√§ven** och **lata bruna hunden**.

### Sentimentanalys

En mening eller text kan analyseras f√∂r sentiment, eller hur *positiv* eller *negativ* den √§r. Sentiment m√§ts i *polaritet* och *objektivitet/subjektivitet*. Polaritet m√§ts fr√•n -1,0 till 1,0 (negativ till positiv) och 0,0 till 1,0 (mest objektiv till mest subjektiv).

‚úÖ Senare kommer du att l√§ra dig att det finns olika s√§tt att best√§mma sentiment med hj√§lp av maskininl√§rning, men ett s√§tt √§r att ha en lista med ord och fraser som kategoriseras som positiva eller negativa av en m√§nsklig expert och till√§mpa den modellen p√• text f√∂r att ber√§kna ett polaritetsv√§rde. Kan du se hur detta skulle fungera i vissa fall och mindre bra i andra?

### B√∂jning

B√∂jning g√∂r det m√∂jligt att ta ett ord och f√• dess singular eller plural.

### Lemmatization

En *lemma* √§r grundformen eller huvudordet f√∂r en upps√§ttning ord, till exempel *fl√∂g*, *flyger*, *flygande* har en lemma av verbet *flyga*.

Det finns ocks√• anv√§ndbara databaser tillg√§ngliga f√∂r NLP-forskare, s√§rskilt:

### WordNet

[WordNet](https://wordnet.princeton.edu/) √§r en databas med ord, synonymer, antonymer och m√•nga andra detaljer f√∂r varje ord p√• m√•nga olika spr√•k. Det √§r otroligt anv√§ndbart n√§r man f√∂rs√∂ker bygga √∂vers√§ttningar, stavningskontroller eller spr√•kliga verktyg av alla slag.

## NLP-bibliotek

Som tur √§r beh√∂ver du inte bygga alla dessa tekniker sj√§lv, eftersom det finns utm√§rkta Python-bibliotek som g√∂r det mycket mer tillg√§ngligt f√∂r utvecklare som inte √§r specialiserade p√• naturlig spr√•kbehandling eller maskininl√§rning. De kommande lektionerna inneh√•ller fler exempel p√• dessa, men h√§r kommer du att l√§ra dig n√•gra anv√§ndbara exempel f√∂r att hj√§lpa dig med n√§sta uppgift.

### √ñvning - anv√§nda biblioteket `TextBlob`

L√•t oss anv√§nda ett bibliotek som heter TextBlob eftersom det inneh√•ller anv√§ndbara API:er f√∂r att hantera dessa typer av uppgifter. TextBlob "st√•r p√• de gigantiska axlarna av [NLTK](https://nltk.org) och [pattern](https://github.com/clips/pattern), och fungerar bra med b√•da." Det har en betydande m√§ngd ML inb√§ddad i sitt API.

> Obs: En anv√§ndbar [Quick Start](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart) guide √§r tillg√§nglig f√∂r TextBlob som rekommenderas f√∂r erfarna Python-utvecklare.

N√§r du f√∂rs√∂ker identifiera *substantivfraser* erbjuder TextBlob flera alternativ f√∂r att hitta substantivfraser.

1. Ta en titt p√• `ConllExtractor`.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > Vad h√§nder h√§r? [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) √§r "En substantivfrasextraktor som anv√§nder chunk parsing tr√§nad med ConLL-2000 tr√§ningskorpus." ConLL-2000 h√§nvisar till 2000 √•rs konferens om Computational Natural Language Learning. Varje √•r h√∂ll konferensen en workshop f√∂r att hantera ett sv√•rt NLP-problem, och 2000 var det substantivchunking. En modell tr√§nades p√• Wall Street Journal, med "sektionerna 15-18 som tr√§ningsdata (211727 tokens) och sektion 20 som testdata (47377 tokens)". Du kan titta p√• de procedurer som anv√§ndes [h√§r](https://www.clips.uantwerpen.be/conll2000/chunking/) och [resultaten](https://ifarm.nl/erikt/research/np-chunking.html).

### Utmaning - f√∂rb√§ttra din bot med NLP

I den f√∂reg√•ende lektionen byggde du en mycket enkel Q&A-bot. Nu ska du g√∂ra Marvin lite mer sympatisk genom att analysera din input f√∂r sentiment och skriva ut ett svar som matchar sentimentet. Du m√•ste ocks√• identifiera en `substantivfras` och fr√•ga om den.

Dina steg n√§r du bygger en b√§ttre konversationsbot:

1. Skriv instruktioner som informerar anv√§ndaren om hur man interagerar med boten  
2. Starta loop  
   1. Acceptera anv√§ndarens input  
   2. Om anv√§ndaren har bett om att avsluta, avsluta  
   3. Bearbeta anv√§ndarens input och best√§m l√§mpligt sentiment-svar  
   4. Om en substantivfras uppt√§cks i sentimentet, pluralisera den och fr√•ga om mer input om det √§mnet  
   5. Skriv ut svar  
3. G√• tillbaka till steg 2  

H√§r √§r kodsnutten f√∂r att best√§mma sentiment med TextBlob. Observera att det bara finns fyra *graderingar* av sentiment-svar (du kan ha fler om du vill):

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

H√§r √§r ett exempel p√• output f√∂r att guida dig (anv√§ndarens input √§r p√• rader som b√∂rjar med >):

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

En m√∂jlig l√∂sning p√• uppgiften finns [h√§r](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/2-Tasks/solution/bot.py)

‚úÖ Kunskapskontroll

1. Tror du att de sympatiska svaren skulle 'lura' n√•gon att tro att boten faktiskt f√∂rstod dem?  
2. G√∂r identifieringen av substantivfrasen boten mer 'trov√§rdig'?  
3. Varf√∂r skulle det vara anv√§ndbart att extrahera en 'substantivfras' fr√•n en mening?  

---

Implementera boten i den tidigare kunskapskontrollen och testa den p√• en v√§n. Kan den lura dem? Kan du g√∂ra din bot mer 'trov√§rdig'?

## üöÄUtmaning

Ta en uppgift fr√•n den tidigare kunskapskontrollen och f√∂rs√∂k implementera den. Testa boten p√• en v√§n. Kan den lura dem? Kan du g√∂ra din bot mer 'trov√§rdig'?

## [Quiz efter f√∂rel√§sningen](https://ff-quizzes.netlify.app/en/ml/)

## Granskning & Sj√§lvstudier

I de kommande lektionerna kommer du att l√§ra dig mer om sentimentanalys. Unders√∂k denna intressanta teknik i artiklar som dessa p√• [KDNuggets](https://www.kdnuggets.com/tag/nlp)

## Uppgift 

[F√• en bot att svara](assignment.md)

---

**Ansvarsfriskrivning**:  
Detta dokument har √∂versatts med hj√§lp av AI-√∂vers√§ttningstj√§nsten [Co-op Translator](https://github.com/Azure/co-op-translator). √Ñven om vi str√§var efter noggrannhet, b√∂r du vara medveten om att automatiska √∂vers√§ttningar kan inneh√•lla fel eller felaktigheter. Det ursprungliga dokumentet p√• dess ursprungliga spr√•k b√∂r betraktas som den auktoritativa k√§llan. F√∂r kritisk information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r eventuella missf√∂rst√•nd eller feltolkningar som uppst√•r vid anv√§ndning av denna √∂vers√§ttning.