<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "aaf391d922bd6de5efba871d514c6d47",
  "translation_date": "2025-09-05T21:55:18+00:00",
  "source_file": "4-Classification/1-Introduction/README.md",
  "language_code": "sv"
}
-->
# Introduktion till klassificering

I dessa fyra lektioner kommer du att utforska ett grundl√§ggande fokus inom klassisk maskininl√§rning - _klassificering_. Vi kommer att g√• igenom anv√§ndningen av olika klassificeringsalgoritmer med en dataset om alla fantastiska k√∂k fr√•n Asien och Indien. Hoppas du √§r hungrig!

![bara en nypa!](../../../../4-Classification/1-Introduction/images/pinch.png)

> Fira pan-asiatiska k√∂k i dessa lektioner! Bild av [Jen Looper](https://twitter.com/jenlooper)

Klassificering √§r en form av [√∂vervakad inl√§rning](https://wikipedia.org/wiki/Supervised_learning) som har mycket gemensamt med regressionstekniker. Om maskininl√§rning handlar om att f√∂ruts√§ga v√§rden eller namn p√• saker med hj√§lp av dataset, s√• faller klassificering generellt sett in i tv√• grupper: _bin√§r klassificering_ och _multiklassklassificering_.

[![Introduktion till klassificering](https://img.youtube.com/vi/eg8DJYwdMyg/0.jpg)](https://youtu.be/eg8DJYwdMyg "Introduktion till klassificering")

> üé• Klicka p√• bilden ovan f√∂r en video: MIT:s John Guttag introducerar klassificering

Kom ih√•g:

- **Linj√§r regression** hj√§lpte dig att f√∂ruts√§ga relationer mellan variabler och g√∂ra exakta f√∂ruts√§gelser om var en ny datapunkt skulle hamna i f√∂rh√•llande till den linjen. S√•, du kunde f√∂ruts√§ga _vad priset p√• en pumpa skulle vara i september j√§mf√∂rt med december_, till exempel.
- **Logistisk regression** hj√§lpte dig att uppt√§cka "bin√§ra kategorier": vid denna prisniv√•, _√§r denna pumpa orange eller inte-orange_?

Klassificering anv√§nder olika algoritmer f√∂r att best√§mma andra s√§tt att avg√∂ra en datapunkts etikett eller klass. L√•t oss arbeta med denna dataset om k√∂k f√∂r att se om vi, genom att observera en grupp ingredienser, kan avg√∂ra dess ursprungsk√∂k.

## [Quiz f√∂re lektionen](https://ff-quizzes.netlify.app/en/ml/)

> ### [Denna lektion finns tillg√§nglig i R!](../../../../4-Classification/1-Introduction/solution/R/lesson_10.html)

### Introduktion

Klassificering √§r en av de grundl√§ggande aktiviteterna f√∂r forskare inom maskininl√§rning och dataanalytiker. Fr√•n grundl√§ggande klassificering av ett bin√§rt v√§rde ("√§r detta e-postmeddelande skr√§ppost eller inte?") till komplex bildklassificering och segmentering med hj√§lp av datorseende, √§r det alltid anv√§ndbart att kunna sortera data i klasser och st√§lla fr√•gor om den.

F√∂r att uttrycka processen p√• ett mer vetenskapligt s√§tt skapar din klassificeringsmetod en prediktiv modell som g√∂r det m√∂jligt att kartl√§gga relationen mellan indata och utdata.

![bin√§r vs. multiklassklassificering](../../../../4-Classification/1-Introduction/images/binary-multiclass.png)

> Bin√§ra vs. multiklassproblem f√∂r klassificeringsalgoritmer att hantera. Infografik av [Jen Looper](https://twitter.com/jenlooper)

Innan vi b√∂rjar processen med att rensa v√•r data, visualisera den och f√∂rbereda den f√∂r v√•ra ML-uppgifter, l√•t oss l√§ra oss lite om de olika s√§tten maskininl√§rning kan anv√§ndas f√∂r att klassificera data.

H√§rledd fr√•n [statistik](https://wikipedia.org/wiki/Statistical_classification), klassificering med klassisk maskininl√§rning anv√§nder egenskaper, s√•som `smoker`, `weight` och `age` f√∂r att avg√∂ra _sannolikheten att utveckla X sjukdom_. Som en √∂vervakad inl√§rningsteknik liknande de regression√∂vningar du utf√∂rde tidigare, √§r din data m√§rkt och ML-algoritmerna anv√§nder dessa etiketter f√∂r att klassificera och f√∂ruts√§ga klasser (eller 'egenskaper') i en dataset och tilldela dem till en grupp eller ett resultat.

‚úÖ Ta en stund och f√∂rest√§ll dig en dataset om k√∂k. Vad skulle en multiklassmodell kunna svara p√•? Vad skulle en bin√§r modell kunna svara p√•? Vad h√§nder om du ville avg√∂ra om ett visst k√∂k sannolikt anv√§nder bockhornskl√∂ver? Vad h√§nder om du ville se om du, med en present av en matkasse full av stj√§rnanis, kron√§rtskockor, blomk√•l och pepparrot, kunde skapa en typisk indisk r√§tt?

[![Galna mysteriekorgar](https://img.youtube.com/vi/GuTeDbaNoEU/0.jpg)](https://youtu.be/GuTeDbaNoEU "Galna mysteriekorgar")

> üé• Klicka p√• bilden ovan f√∂r en video. Hela premissen f√∂r programmet 'Chopped' √§r 'mysteriekorgen' d√§r kockar m√•ste g√∂ra en r√§tt av ett slumpm√§ssigt val av ingredienser. Visst skulle en ML-modell ha hj√§lpt!

## Hej 'klassificerare'

Fr√•gan vi vill st√§lla om denna dataset om k√∂k √§r faktiskt en **multiklassfr√•ga**, eftersom vi har flera potentiella nationella k√∂k att arbeta med. Givet en m√§ngd ingredienser, vilken av dessa m√•nga klasser passar datan in i?

Scikit-learn erbjuder flera olika algoritmer att anv√§nda f√∂r att klassificera data, beroende p√• vilken typ av problem du vill l√∂sa. I de kommande tv√• lektionerna kommer du att l√§ra dig om flera av dessa algoritmer.

## √ñvning - rensa och balansera din data

Den f√∂rsta uppgiften, innan vi b√∂rjar detta projekt, √§r att rensa och **balansera** din data f√∂r att f√• b√§ttre resultat. B√∂rja med den tomma filen _notebook.ipynb_ i roten av denna mapp.

Det f√∂rsta du beh√∂ver installera √§r [imblearn](https://imbalanced-learn.org/stable/). Detta √§r ett Scikit-learn-paket som g√∂r det m√∂jligt att b√§ttre balansera datan (du kommer att l√§ra dig mer om denna uppgift om en stund).

1. F√∂r att installera `imblearn`, k√∂r `pip install`, s√• h√§r:

    ```python
    pip install imblearn
    ```

1. Importera de paket du beh√∂ver f√∂r att importera din data och visualisera den, importera ocks√• `SMOTE` fr√•n `imblearn`.

    ```python
    import pandas as pd
    import matplotlib.pyplot as plt
    import matplotlib as mpl
    import numpy as np
    from imblearn.over_sampling import SMOTE
    ```

    Nu √§r du redo att importera datan n√§sta g√•ng.

1. N√§sta uppgift √§r att importera datan:

    ```python
    df  = pd.read_csv('../data/cuisines.csv')
    ```

   Genom att anv√§nda `read_csv()` kommer inneh√•llet i csv-filen _cusines.csv_ att l√§sas och placeras i variabeln `df`.

1. Kontrollera datans form:

    ```python
    df.head()
    ```

   De f√∂rsta fem raderna ser ut s√• h√§r:

    ```output
    |     | Unnamed: 0 | cuisine | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood | yam | yeast | yogurt | zucchini |
    | --- | ---------- | ------- | ------ | -------- | ----- | ---------- | ----- | ------------ | ------- | -------- | --- | ------- | ----------- | ---------- | ----------------------- | ---- | ---- | --- | ----- | ------ | -------- |
    | 0   | 65         | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
    | 1   | 66         | indian  | 1      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
    | 2   | 67         | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
    | 3   | 68         | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
    | 4   | 69         | indian  | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 1      | 0        |
    ```

1. F√• information om denna data genom att kalla p√• `info()`:

    ```python
    df.info()
    ```

    Din utdata liknar:

    ```output
    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 2448 entries, 0 to 2447
    Columns: 385 entries, Unnamed: 0 to zucchini
    dtypes: int64(384), object(1)
    memory usage: 7.2+ MB
    ```

## √ñvning - l√§ra sig om k√∂k

Nu b√∂rjar arbetet bli mer intressant. L√•t oss uppt√§cka f√∂rdelningen av data, per k√∂k.

1. Plotta datan som staplar genom att kalla p√• `barh()`:

    ```python
    df.cuisine.value_counts().plot.barh()
    ```

    ![f√∂rdelning av k√∂ksdata](../../../../4-Classification/1-Introduction/images/cuisine-dist.png)

    Det finns ett begr√§nsat antal k√∂k, men f√∂rdelningen av data √§r oj√§mn. Du kan fixa det! Innan du g√∂r det, utforska lite mer.

1. Ta reda p√• hur mycket data som finns tillg√§ngligt per k√∂k och skriv ut det:

    ```python
    thai_df = df[(df.cuisine == "thai")]
    japanese_df = df[(df.cuisine == "japanese")]
    chinese_df = df[(df.cuisine == "chinese")]
    indian_df = df[(df.cuisine == "indian")]
    korean_df = df[(df.cuisine == "korean")]
    
    print(f'thai df: {thai_df.shape}')
    print(f'japanese df: {japanese_df.shape}')
    print(f'chinese df: {chinese_df.shape}')
    print(f'indian df: {indian_df.shape}')
    print(f'korean df: {korean_df.shape}')
    ```

    Utdata ser ut s√• h√§r:

    ```output
    thai df: (289, 385)
    japanese df: (320, 385)
    chinese df: (442, 385)
    indian df: (598, 385)
    korean df: (799, 385)
    ```

## Uppt√§cka ingredienser

Nu kan du gr√§va djupare i datan och l√§ra dig vilka som √§r de typiska ingredienserna per k√∂k. Du b√∂r rensa bort √•terkommande data som skapar f√∂rvirring mellan k√∂k, s√• l√•t oss l√§ra oss om detta problem.

1. Skapa en funktion `create_ingredient()` i Python f√∂r att skapa en ingrediens-dataset. Denna funktion b√∂rjar med att ta bort en oanv√§ndbar kolumn och sortera ingredienser efter deras antal:

    ```python
    def create_ingredient_df(df):
        ingredient_df = df.T.drop(['cuisine','Unnamed: 0']).sum(axis=1).to_frame('value')
        ingredient_df = ingredient_df[(ingredient_df.T != 0).any()]
        ingredient_df = ingredient_df.sort_values(by='value', ascending=False,
        inplace=False)
        return ingredient_df
    ```

   Nu kan du anv√§nda den funktionen f√∂r att f√• en id√© om de tio mest popul√§ra ingredienserna per k√∂k.

1. Kalla p√• `create_ingredient()` och plotta det genom att kalla p√• `barh()`:

    ```python
    thai_ingredient_df = create_ingredient_df(thai_df)
    thai_ingredient_df.head(10).plot.barh()
    ```

    ![thai](../../../../4-Classification/1-Introduction/images/thai.png)

1. G√∂r samma sak f√∂r den japanska datan:

    ```python
    japanese_ingredient_df = create_ingredient_df(japanese_df)
    japanese_ingredient_df.head(10).plot.barh()
    ```

    ![japanska](../../../../4-Classification/1-Introduction/images/japanese.png)

1. Nu f√∂r de kinesiska ingredienserna:

    ```python
    chinese_ingredient_df = create_ingredient_df(chinese_df)
    chinese_ingredient_df.head(10).plot.barh()
    ```

    ![kinesiska](../../../../4-Classification/1-Introduction/images/chinese.png)

1. Plotta de indiska ingredienserna:

    ```python
    indian_ingredient_df = create_ingredient_df(indian_df)
    indian_ingredient_df.head(10).plot.barh()
    ```

    ![indiska](../../../../4-Classification/1-Introduction/images/indian.png)

1. Slutligen, plotta de koreanska ingredienserna:

    ```python
    korean_ingredient_df = create_ingredient_df(korean_df)
    korean_ingredient_df.head(10).plot.barh()
    ```

    ![koreanska](../../../../4-Classification/1-Introduction/images/korean.png)

1. Nu, ta bort de vanligaste ingredienserna som skapar f√∂rvirring mellan olika k√∂k, genom att kalla p√• `drop()`:

   Alla √§lskar ris, vitl√∂k och ingef√§ra!

    ```python
    feature_df= df.drop(['cuisine','Unnamed: 0','rice','garlic','ginger'], axis=1)
    labels_df = df.cuisine #.unique()
    feature_df.head()
    ```

## Balansera datasetet

Nu n√§r du har rensat datan, anv√§nd [SMOTE](https://imbalanced-learn.org/dev/references/generated/imblearn.over_sampling.SMOTE.html) - "Synthetic Minority Over-sampling Technique" - f√∂r att balansera den.

1. Kalla p√• `fit_resample()`, denna strategi genererar nya prover genom interpolation.

    ```python
    oversample = SMOTE()
    transformed_feature_df, transformed_label_df = oversample.fit_resample(feature_df, labels_df)
    ```

    Genom att balansera din data f√•r du b√§ttre resultat n√§r du klassificerar den. T√§nk p√• en bin√§r klassificering. Om det mesta av din data √§r en klass, kommer en ML-modell att f√∂ruts√§ga den klassen oftare, bara f√∂r att det finns mer data f√∂r den. Att balansera datan tar bort eventuella snedvridningar och hj√§lper till att eliminera denna obalans.

1. Nu kan du kontrollera antalet etiketter per ingrediens:

    ```python
    print(f'new label count: {transformed_label_df.value_counts()}')
    print(f'old label count: {df.cuisine.value_counts()}')
    ```

    Din utdata ser ut s√• h√§r:

    ```output
    new label count: korean      799
    chinese     799
    indian      799
    japanese    799
    thai        799
    Name: cuisine, dtype: int64
    old label count: korean      799
    indian      598
    chinese     442
    japanese    320
    thai        289
    Name: cuisine, dtype: int64
    ```

    Datan √§r fin och ren, balanserad och mycket l√§cker!

1. Det sista steget √§r att spara din balanserade data, inklusive etiketter och egenskaper, i en ny dataset som kan exporteras till en fil:

    ```python
    transformed_df = pd.concat([transformed_label_df,transformed_feature_df],axis=1, join='outer')
    ```

1. Du kan ta en sista titt p√• datan med `transformed_df.head()` och `transformed_df.info()`. Spara en kopia av denna data f√∂r anv√§ndning i framtida lektioner:

    ```python
    transformed_df.head()
    transformed_df.info()
    transformed_df.to_csv("../data/cleaned_cuisines.csv")
    ```

    Denna nya CSV-fil kan nu hittas i rotens datamapp.

---

## üöÄUtmaning

Detta l√§roplan inneh√•ller flera intressanta dataset. Gr√§v igenom `data`-mapparna och se om n√•gon inneh√•ller dataset som skulle vara l√§mpliga f√∂r bin√§r eller multiklassklassificering? Vilka fr√•gor skulle du st√§lla till denna dataset?

## [Quiz efter lektionen](https://ff-quizzes.netlify.app/en/ml/)

## Granskning & Sj√§lvstudier

Utforska SMOTEs API. Vilka anv√§ndningsomr√•den √§r det b√§st l√§mpat f√∂r? Vilka problem l√∂ser det?

## Uppgift 

[Utforska klassificeringsmetoder](assignment.md)

---

**Ansvarsfriskrivning**:  
Detta dokument har √∂versatts med hj√§lp av AI-√∂vers√§ttningstj√§nsten [Co-op Translator](https://github.com/Azure/co-op-translator). √Ñven om vi str√§var efter noggrannhet, b√∂r du vara medveten om att automatiserade √∂vers√§ttningar kan inneh√•lla fel eller felaktigheter. Det ursprungliga dokumentet p√• dess originalspr√•k b√∂r betraktas som den auktoritativa k√§llan. F√∂r kritisk information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r eventuella missf√∂rst√•nd eller feltolkningar som uppst√•r vid anv√§ndning av denna √∂vers√§ttning.