<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "482bccabe1df958496ea71a3667995cd",
  "translation_date": "2025-09-05T08:40:23+00:00",
  "source_file": "7-TimeSeries/3-SVR/README.md",
  "language_code": "pt"
}
-->
# Previs√£o de S√©ries Temporais com Support Vector Regressor

Na li√ß√£o anterior, aprendeste a usar o modelo ARIMA para fazer previs√µes de s√©ries temporais. Agora vais explorar o modelo Support Vector Regressor, que √© um modelo de regress√£o utilizado para prever dados cont√≠nuos.

## [Question√°rio pr√©-aula](https://ff-quizzes.netlify.app/en/ml/) 

## Introdu√ß√£o

Nesta li√ß√£o, vais descobrir uma forma espec√≠fica de construir modelos com [**SVM**: **S**upport **V**ector **M**achine](https://en.wikipedia.org/wiki/Support-vector_machine) para regress√£o, ou **SVR: Support Vector Regressor**. 

### SVR no contexto de s√©ries temporais [^1]

Antes de compreender a import√¢ncia do SVR na previs√£o de s√©ries temporais, aqui est√£o alguns conceitos importantes que precisas de saber:

- **Regress√£o:** T√©cnica de aprendizagem supervisionada para prever valores cont√≠nuos a partir de um conjunto de entradas. A ideia √© ajustar uma curva (ou linha) no espa√ßo de caracter√≠sticas que tenha o maior n√∫mero de pontos de dados. [Clica aqui](https://en.wikipedia.org/wiki/Regression_analysis) para mais informa√ß√µes.
- **Support Vector Machine (SVM):** Um tipo de modelo de aprendizagem supervisionada usado para classifica√ß√£o, regress√£o e dete√ß√£o de outliers. O modelo √© um hiperplano no espa√ßo de caracter√≠sticas, que no caso de classifica√ß√£o atua como uma fronteira, e no caso de regress√£o atua como a linha de melhor ajuste. No SVM, uma fun√ß√£o Kernel √© geralmente usada para transformar o conjunto de dados para um espa√ßo com maior n√∫mero de dimens√µes, de forma a torn√°-los mais facilmente separ√°veis. [Clica aqui](https://en.wikipedia.org/wiki/Support-vector_machine) para mais informa√ß√µes sobre SVMs.
- **Support Vector Regressor (SVR):** Um tipo de SVM, que encontra a linha de melhor ajuste (que no caso de SVM √© um hiperplano) com o maior n√∫mero de pontos de dados.

### Porqu√™ SVR? [^1]

Na √∫ltima li√ß√£o aprendeste sobre o ARIMA, que √© um m√©todo estat√≠stico linear muito bem-sucedido para prever dados de s√©ries temporais. No entanto, em muitos casos, os dados de s√©ries temporais apresentam *n√£o-linearidade*, que n√£o pode ser mapeada por modelos lineares. Nestes casos, a capacidade do SVM de considerar a n√£o-linearidade nos dados para tarefas de regress√£o torna o SVR bem-sucedido na previs√£o de s√©ries temporais.

## Exerc√≠cio - construir um modelo SVR

Os primeiros passos para a prepara√ß√£o dos dados s√£o os mesmos da li√ß√£o anterior sobre [ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA). 

Abre a pasta [_/working_](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/3-SVR/working) nesta li√ß√£o e encontra o ficheiro [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/7-TimeSeries/3-SVR/working/notebook.ipynb). [^2]

1. Executa o notebook e importa as bibliotecas necess√°rias: [^2]

   ```python
   import sys
   sys.path.append('../../')
   ```

   ```python
   import os
   import warnings
   import matplotlib.pyplot as plt
   import numpy as np
   import pandas as pd
   import datetime as dt
   import math
   
   from sklearn.svm import SVR
   from sklearn.preprocessing import MinMaxScaler
   from common.utils import load_data, mape
   ```

2. Carrega os dados do ficheiro `/data/energy.csv` para um dataframe do Pandas e analisa-os: [^2]

   ```python
   energy = load_data('../../data')[['load']]
   ```

3. Faz o gr√°fico de todos os dados de energia dispon√≠veis de janeiro de 2012 a dezembro de 2014: [^2]

   ```python
   energy.plot(y='load', subplots=True, figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![dados completos](../../../../7-TimeSeries/3-SVR/images/full-data.png)

   Agora, vamos construir o nosso modelo SVR.

### Criar conjuntos de treino e teste

Agora que os dados est√£o carregados, podes separ√°-los em conjuntos de treino e teste. Depois vais remodelar os dados para criar um conjunto de dados baseado em passos temporais, que ser√° necess√°rio para o SVR. Vais treinar o teu modelo no conjunto de treino. Ap√≥s o modelo terminar o treino, vais avaliar a sua precis√£o no conjunto de treino, no conjunto de teste e depois no conjunto de dados completo para ver o desempenho geral. √â importante garantir que o conjunto de teste cobre um per√≠odo posterior ao conjunto de treino para assegurar que o modelo n√£o obt√©m informa√ß√µes de per√≠odos futuros [^2] (uma situa√ß√£o conhecida como *Overfitting*).

1. Aloca um per√≠odo de dois meses de 1 de setembro a 31 de outubro de 2014 para o conjunto de treino. O conjunto de teste incluir√° o per√≠odo de dois meses de 1 de novembro a 31 de dezembro de 2014: [^2]

   ```python
   train_start_dt = '2014-11-01 00:00:00'
   test_start_dt = '2014-12-30 00:00:00'
   ```

2. Visualiza as diferen√ßas: [^2]

   ```python
   energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)][['load']].rename(columns={'load':'train'}) \
       .join(energy[test_start_dt:][['load']].rename(columns={'load':'test'}), how='outer') \
       .plot(y=['train', 'test'], figsize=(15, 8), fontsize=12)
   plt.xlabel('timestamp', fontsize=12)
   plt.ylabel('load', fontsize=12)
   plt.show()
   ```

   ![dados de treino e teste](../../../../7-TimeSeries/3-SVR/images/train-test.png)

### Preparar os dados para treino

Agora, precisas de preparar os dados para treino, realizando filtragem e escalonamento dos dados. Filtra o conjunto de dados para incluir apenas os per√≠odos de tempo e colunas necess√°rios, e faz o escalonamento para garantir que os dados s√£o projetados no intervalo 0,1.

1. Filtra o conjunto de dados original para incluir apenas os per√≠odos de tempo mencionados por conjunto e apenas a coluna necess√°ria 'load' mais a data: [^2]

   ```python
   train = energy.copy()[(energy.index >= train_start_dt) & (energy.index < test_start_dt)][['load']]
   test = energy.copy()[energy.index >= test_start_dt][['load']]
   
   print('Training data shape: ', train.shape)
   print('Test data shape: ', test.shape)
   ```

   ```output
   Training data shape:  (1416, 1)
   Test data shape:  (48, 1)
   ```
   
2. Escalona os dados de treino para estarem no intervalo (0, 1): [^2]

   ```python
   scaler = MinMaxScaler()
   train['load'] = scaler.fit_transform(train)
   ```
   
4. Agora, escalona os dados de teste: [^2]

   ```python
   test['load'] = scaler.transform(test)
   ```

### Criar dados com passos temporais [^1]

Para o SVR, transformas os dados de entrada para a forma `[batch, timesteps]`. Assim, remodelas os `train_data` e `test_data` existentes de forma a que haja uma nova dimens√£o que se refere aos passos temporais. 

```python
# Converting to numpy arrays
train_data = train.values
test_data = test.values
```

Para este exemplo, usamos `timesteps = 5`. Assim, as entradas para o modelo s√£o os dados dos primeiros 4 passos temporais, e a sa√≠da ser√° os dados do 5¬∫ passo temporal.

```python
timesteps=5
```

Converter os dados de treino para tensor 2D usando list comprehension aninhada:

```python
train_data_timesteps=np.array([[j for j in train_data[i:i+timesteps]] for i in range(0,len(train_data)-timesteps+1)])[:,:,0]
train_data_timesteps.shape
```

```output
(1412, 5)
```

Converter os dados de teste para tensor 2D:

```python
test_data_timesteps=np.array([[j for j in test_data[i:i+timesteps]] for i in range(0,len(test_data)-timesteps+1)])[:,:,0]
test_data_timesteps.shape
```

```output
(44, 5)
```

Selecionar entradas e sa√≠das dos dados de treino e teste:

```python
x_train, y_train = train_data_timesteps[:,:timesteps-1],train_data_timesteps[:,[timesteps-1]]
x_test, y_test = test_data_timesteps[:,:timesteps-1],test_data_timesteps[:,[timesteps-1]]

print(x_train.shape, y_train.shape)
print(x_test.shape, y_test.shape)
```

```output
(1412, 4) (1412, 1)
(44, 4) (44, 1)
```

### Implementar SVR [^1]

Agora, √© hora de implementar o SVR. Para saber mais sobre esta implementa√ß√£o, podes consultar [esta documenta√ß√£o](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html). Para a nossa implementa√ß√£o, seguimos estes passos:

  1. Define o modelo chamando `SVR()` e passando os hiperpar√¢metros do modelo: kernel, gamma, c e epsilon
  2. Prepara o modelo para os dados de treino chamando a fun√ß√£o `fit()`
  3. Faz previs√µes chamando a fun√ß√£o `predict()`

Agora criamos um modelo SVR. Aqui usamos o [kernel RBF](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel), e definimos os hiperpar√¢metros gamma, C e epsilon como 0.5, 10 e 0.05 respetivamente.

```python
model = SVR(kernel='rbf',gamma=0.5, C=10, epsilon = 0.05)
```

#### Ajustar o modelo aos dados de treino [^1]

```python
model.fit(x_train, y_train[:,0])
```

```output
SVR(C=10, cache_size=200, coef0=0.0, degree=3, epsilon=0.05, gamma=0.5,
    kernel='rbf', max_iter=-1, shrinking=True, tol=0.001, verbose=False)
```

#### Fazer previs√µes com o modelo [^1]

```python
y_train_pred = model.predict(x_train).reshape(-1,1)
y_test_pred = model.predict(x_test).reshape(-1,1)

print(y_train_pred.shape, y_test_pred.shape)
```

```output
(1412, 1) (44, 1)
```

Constru√≠ste o teu SVR! Agora precisamos de avali√°-lo.

### Avaliar o modelo [^1]

Para avalia√ß√£o, primeiro vamos escalonar os dados de volta para a escala original. Depois, para verificar o desempenho, vamos fazer o gr√°fico da s√©rie temporal original e prevista, e tamb√©m imprimir o resultado do MAPE.

Escalona os dados previstos e originais:

```python
# Scaling the predictions
y_train_pred = scaler.inverse_transform(y_train_pred)
y_test_pred = scaler.inverse_transform(y_test_pred)

print(len(y_train_pred), len(y_test_pred))
```

```python
# Scaling the original values
y_train = scaler.inverse_transform(y_train)
y_test = scaler.inverse_transform(y_test)

print(len(y_train), len(y_test))
```

#### Verificar o desempenho do modelo nos dados de treino e teste [^1]

Extra√≠mos os timestamps do conjunto de dados para mostrar no eixo x do nosso gr√°fico. Nota que estamos a usar os primeiros ```timesteps-1``` valores como entrada para a primeira sa√≠da, ent√£o os timestamps para a sa√≠da come√ßar√£o depois disso.

```python
train_timestamps = energy[(energy.index < test_start_dt) & (energy.index >= train_start_dt)].index[timesteps-1:]
test_timestamps = energy[test_start_dt:].index[timesteps-1:]

print(len(train_timestamps), len(test_timestamps))
```

```output
1412 44
```

Faz o gr√°fico das previs√µes para os dados de treino:

```python
plt.figure(figsize=(25,6))
plt.plot(train_timestamps, y_train, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(train_timestamps, y_train_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.title("Training data prediction")
plt.show()
```

![previs√£o dos dados de treino](../../../../7-TimeSeries/3-SVR/images/train-data-predict.png)

Imprime o MAPE para os dados de treino

```python
print('MAPE for training data: ', mape(y_train_pred, y_train)*100, '%')
```

```output
MAPE for training data: 1.7195710200875551 %
```

Faz o gr√°fico das previs√µes para os dados de teste

```python
plt.figure(figsize=(10,3))
plt.plot(test_timestamps, y_test, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(test_timestamps, y_test_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![previs√£o dos dados de teste](../../../../7-TimeSeries/3-SVR/images/test-data-predict.png)

Imprime o MAPE para os dados de teste

```python
print('MAPE for testing data: ', mape(y_test_pred, y_test)*100, '%')
```

```output
MAPE for testing data:  1.2623790187854018 %
```

üèÜ Obtiveste um resultado muito bom no conjunto de dados de teste!

### Verificar o desempenho do modelo no conjunto de dados completo [^1]

```python
# Extracting load values as numpy array
data = energy.copy().values

# Scaling
data = scaler.transform(data)

# Transforming to 2D tensor as per model input requirement
data_timesteps=np.array([[j for j in data[i:i+timesteps]] for i in range(0,len(data)-timesteps+1)])[:,:,0]
print("Tensor shape: ", data_timesteps.shape)

# Selecting inputs and outputs from data
X, Y = data_timesteps[:,:timesteps-1],data_timesteps[:,[timesteps-1]]
print("X shape: ", X.shape,"\nY shape: ", Y.shape)
```

```output
Tensor shape:  (26300, 5)
X shape:  (26300, 4) 
Y shape:  (26300, 1)
```

```python
# Make model predictions
Y_pred = model.predict(X).reshape(-1,1)

# Inverse scale and reshape
Y_pred = scaler.inverse_transform(Y_pred)
Y = scaler.inverse_transform(Y)
```

```python
plt.figure(figsize=(30,8))
plt.plot(Y, color = 'red', linewidth=2.0, alpha = 0.6)
plt.plot(Y_pred, color = 'blue', linewidth=0.8)
plt.legend(['Actual','Predicted'])
plt.xlabel('Timestamp')
plt.show()
```

![previs√£o dos dados completos](../../../../7-TimeSeries/3-SVR/images/full-data-predict.png)

```python
print('MAPE: ', mape(Y_pred, Y)*100, '%')
```

```output
MAPE:  2.0572089029888656 %
```

üèÜ Gr√°ficos muito bons, mostrando um modelo com boa precis√£o. Excelente trabalho!

---

## üöÄDesafio

- Tenta ajustar os hiperpar√¢metros (gamma, C, epsilon) ao criar o modelo e avalia os dados para ver qual conjunto de hiperpar√¢metros d√° os melhores resultados nos dados de teste. Para saber mais sobre estes hiperpar√¢metros, podes consultar o documento [aqui](https://scikit-learn.org/stable/modules/svm.html#parameters-of-the-rbf-kernel). 
- Experimenta usar diferentes fun√ß√µes kernel para o modelo e analisa os seus desempenhos no conjunto de dados. Um documento √∫til pode ser encontrado [aqui](https://scikit-learn.org/stable/modules/svm.html#kernel-functions).
- Tenta usar diferentes valores para `timesteps` para o modelo olhar para tr√°s e fazer previs√µes.

## [Question√°rio p√≥s-aula](https://ff-quizzes.netlify.app/en/ml/)

## Revis√£o & Estudo Individual

Esta li√ß√£o foi para introduzir a aplica√ß√£o de SVR na previs√£o de s√©ries temporais. Para saber mais sobre SVR, podes consultar [este blog](https://www.analyticsvidhya.com/blog/2020/03/support-vector-regression-tutorial-for-machine-learning/). Esta [documenta√ß√£o sobre scikit-learn](https://scikit-learn.org/stable/modules/svm.html) fornece uma explica√ß√£o mais abrangente sobre SVMs em geral, [SVRs](https://scikit-learn.org/stable/modules/svm.html#regression) e tamb√©m outros detalhes de implementa√ß√£o, como as diferentes [fun√ß√µes kernel](https://scikit-learn.org/stable/modules/svm.html#kernel-functions) que podem ser usadas e os seus par√¢metros.

## Tarefa

[Um novo modelo SVR](assignment.md)

## Cr√©ditos

[^1]: O texto, c√≥digo e sa√≠da nesta se√ß√£o foram contribu√≠dos por [@AnirbanMukherjeeXD](https://github.com/AnirbanMukherjeeXD)
[^2]: O texto, c√≥digo e sa√≠da nesta se√ß√£o foram retirados de [ARIMA](https://github.com/microsoft/ML-For-Beginners/tree/main/7-TimeSeries/2-ARIMA)

---

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original no seu idioma nativo deve ser considerado a fonte oficial. Para informa√ß√µes cr√≠ticas, recomenda-se uma tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas resultantes do uso desta tradu√ß√£o.