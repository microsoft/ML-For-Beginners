<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "730225ea274c9174fe688b21d421539d",
  "translation_date": "2025-09-05T08:40:50+00:00",
  "source_file": "5-Clustering/1-Visualize/README.md",
  "language_code": "pt"
}
-->
# Introdu√ß√£o √† Clustering

Clustering √© um tipo de [Aprendizagem N√£o Supervisionada](https://wikipedia.org/wiki/Unsupervised_learning) que parte do pressuposto de que um conjunto de dados n√£o est√° rotulado ou que suas entradas n√£o est√£o associadas a sa√≠das predefinidas. Ele utiliza v√°rios algoritmos para organizar dados n√£o rotulados e fornecer agrupamentos com base nos padr√µes identificados nos dados.

[![No One Like You by PSquare](https://img.youtube.com/vi/ty2advRiWJM/0.jpg)](https://youtu.be/ty2advRiWJM "No One Like You by PSquare")

> üé• Clique na imagem acima para assistir a um v√≠deo. Enquanto estuda machine learning com clustering, aproveite algumas faixas de Dance Hall nigeriano - esta √© uma m√∫sica muito bem avaliada de 2014 por PSquare.

## [Question√°rio pr√©-aula](https://ff-quizzes.netlify.app/en/ml/)

### Introdu√ß√£o

[Clustering](https://link.springer.com/referenceworkentry/10.1007%2F978-0-387-30164-8_124) √© muito √∫til para explora√ß√£o de dados. Vamos ver se ele pode ajudar a descobrir tend√™ncias e padr√µes na forma como o p√∫blico nigeriano consome m√∫sica.

‚úÖ Reserve um momento para pensar sobre os usos do clustering. Na vida real, clustering acontece sempre que voc√™ tem uma pilha de roupa suja e precisa separar as roupas dos membros da sua fam√≠lia üß¶üëïüëñü©≤. Em ci√™ncia de dados, clustering ocorre ao tentar analisar as prefer√™ncias de um usu√°rio ou determinar as caracter√≠sticas de qualquer conjunto de dados n√£o rotulado. Clustering, de certa forma, ajuda a dar sentido ao caos, como uma gaveta de meias.

[![Introdu√ß√£o ao ML](https://img.youtube.com/vi/esmzYhuFnds/0.jpg)](https://youtu.be/esmzYhuFnds "Introdu√ß√£o ao Clustering")

> üé• Clique na imagem acima para assistir a um v√≠deo: John Guttag do MIT apresenta clustering.

No ambiente profissional, clustering pode ser usado para determinar coisas como segmenta√ß√£o de mercado, identificando quais faixas et√°rias compram quais itens, por exemplo. Outro uso seria a detec√ß√£o de anomalias, talvez para identificar fraudes em um conjunto de dados de transa√ß√µes com cart√£o de cr√©dito. Ou voc√™ pode usar clustering para identificar tumores em um lote de exames m√©dicos.

‚úÖ Pense por um momento sobre como voc√™ pode ter encontrado clustering 'na pr√°tica', em um ambiente banc√°rio, de e-commerce ou empresarial.

> üéì Curiosamente, a an√°lise de clusters teve origem nos campos de Antropologia e Psicologia na d√©cada de 1930. Consegue imaginar como ela pode ter sido usada?

Alternativamente, voc√™ poderia us√°-lo para agrupar resultados de pesquisa - por links de compras, imagens ou avalia√ß√µes, por exemplo. Clustering √© √∫til quando voc√™ tem um grande conjunto de dados que deseja reduzir e sobre o qual deseja realizar uma an√°lise mais detalhada, ent√£o a t√©cnica pode ser usada para aprender sobre os dados antes de construir outros modelos.

‚úÖ Uma vez que seus dados est√£o organizados em clusters, voc√™ atribui a eles um Id de cluster, e essa t√©cnica pode ser √∫til para preservar a privacidade de um conjunto de dados; voc√™ pode, em vez disso, referir-se a um ponto de dados pelo seu Id de cluster, em vez de por dados identific√°veis mais reveladores. Consegue pensar em outros motivos pelos quais voc√™ preferiria usar um Id de cluster em vez de outros elementos do cluster para identific√°-lo?

Aprofunde seu entendimento sobre t√©cnicas de clustering neste [m√≥dulo de aprendizado](https://docs.microsoft.com/learn/modules/train-evaluate-cluster-models?WT.mc_id=academic-77952-leestott).

## Come√ßando com clustering

[Scikit-learn oferece uma ampla gama](https://scikit-learn.org/stable/modules/clustering.html) de m√©todos para realizar clustering. O tipo que voc√™ escolhe depender√° do seu caso de uso. De acordo com a documenta√ß√£o, cada m√©todo tem v√°rios benef√≠cios. Aqui est√° uma tabela simplificada dos m√©todos suportados pelo Scikit-learn e seus casos de uso apropriados:

| Nome do m√©todo                | Caso de uso                                                           |
| :---------------------------- | :-------------------------------------------------------------------- |
| K-Means                       | prop√≥sito geral, indutivo                                             |
| Propaga√ß√£o de afinidade       | muitos clusters desiguais, indutivo                                  |
| Mean-shift                    | muitos clusters desiguais, indutivo                                  |
| Clustering espectral          | poucos clusters iguais, transdutivo                                  |
| Clustering hier√°rquico Ward   | muitos clusters restritos, transdutivo                               |
| Clustering aglomerativo       | muitos clusters restritos, dist√¢ncias n√£o euclidianas, transdutivo   |
| DBSCAN                        | geometria n√£o plana, clusters desiguais, transdutivo                 |
| OPTICS                        | geometria n√£o plana, clusters desiguais com densidade vari√°vel, transdutivo |
| Misturas Gaussianas           | geometria plana, indutivo                                            |
| BIRCH                         | grande conjunto de dados com outliers, indutivo                      |

> üéì Como criamos clusters tem muito a ver com como agrupamos os pontos de dados. Vamos explorar alguns vocabul√°rios:
>
> üéì ['Transdutivo' vs. 'indutivo'](https://wikipedia.org/wiki/Transduction_(machine_learning))
> 
> Infer√™ncia transdutiva √© derivada de casos de treinamento observados que mapeiam para casos de teste espec√≠ficos. Infer√™ncia indutiva √© derivada de casos de treinamento que mapeiam para regras gerais que s√≥ ent√£o s√£o aplicadas aos casos de teste. 
> 
> Um exemplo: Imagine que voc√™ tem um conjunto de dados parcialmente rotulado. Algumas coisas s√£o 'discos', outras 'CDs', e algumas est√£o em branco. Sua tarefa √© fornecer r√≥tulos para os itens em branco. Se voc√™ escolher uma abordagem indutiva, treinaria um modelo procurando por 'discos' e 'CDs', e aplicaria esses r√≥tulos aos dados n√£o rotulados. Essa abordagem ter√° dificuldade em classificar coisas que s√£o, na verdade, 'cassetes'. Uma abordagem transdutiva, por outro lado, lida com esses dados desconhecidos de forma mais eficaz, agrupando itens semelhantes e aplicando um r√≥tulo ao grupo. Nesse caso, os clusters podem refletir 'coisas musicais redondas' e 'coisas musicais quadradas'.
> 
> üéì ['Geometria n√£o plana' vs. 'plana'](https://datascience.stackexchange.com/questions/52260/terminology-flat-geometry-in-the-context-of-clustering)
> 
> Derivado da terminologia matem√°tica, geometria n√£o plana vs. plana refere-se √† medida de dist√¢ncias entre pontos por m√©todos geom√©tricos 'planos' ([Euclidianos](https://wikipedia.org/wiki/Euclidean_geometry)) ou 'n√£o planos' (n√£o Euclidianos). 
>
>'Plana' neste contexto refere-se √† geometria Euclidiana (partes da qual s√£o ensinadas como 'geometria plana'), e n√£o plana refere-se √† geometria n√£o Euclidiana. O que a geometria tem a ver com machine learning? Bem, como dois campos que t√™m ra√≠zes na matem√°tica, deve haver uma maneira comum de medir dist√¢ncias entre pontos em clusters, e isso pode ser feito de forma 'plana' ou 'n√£o plana', dependendo da natureza dos dados. [Dist√¢ncias Euclidianas](https://wikipedia.org/wiki/Euclidean_distance) s√£o medidas como o comprimento de um segmento de linha entre dois pontos. [Dist√¢ncias n√£o Euclidianas](https://wikipedia.org/wiki/Non-Euclidean_geometry) s√£o medidas ao longo de uma curva. Se seus dados, visualizados, parecem n√£o existir em um plano, voc√™ pode precisar usar um algoritmo especializado para lidar com isso.
>
![Infogr√°fico Geometria Plana vs N√£o Plana](../../../../5-Clustering/1-Visualize/images/flat-nonflat.png)
> Infogr√°fico por [Dasani Madipalli](https://twitter.com/dasani_decoded)
> 
> üéì ['Dist√¢ncias'](https://web.stanford.edu/class/cs345a/slides/12-clustering.pdf)
> 
> Clusters s√£o definidos por sua matriz de dist√¢ncias, ou seja, as dist√¢ncias entre pontos. Essa dist√¢ncia pode ser medida de algumas maneiras. Clusters Euclidianos s√£o definidos pela m√©dia dos valores dos pontos e cont√™m um 'centroide' ou ponto central. As dist√¢ncias s√£o, portanto, medidas pela dist√¢ncia at√© esse centroide. Dist√¢ncias n√£o Euclidianas referem-se a 'clustroids', o ponto mais pr√≥ximo de outros pontos. Clustroids, por sua vez, podem ser definidos de v√°rias maneiras.
> 
> üéì ['Restrito'](https://wikipedia.org/wiki/Constrained_clustering)
> 
> [Clustering Restrito](https://web.cs.ucdavis.edu/~davidson/Publications/ICDMTutorial.pdf) introduz aprendizado 'semi-supervisionado' neste m√©todo n√£o supervisionado. As rela√ß√µes entre pontos s√£o marcadas como 'n√£o pode vincular' ou 'deve vincular', ent√£o algumas regras s√£o impostas ao conjunto de dados.
>
> Um exemplo: Se um algoritmo √© liberado em um lote de dados n√£o rotulados ou semi-rotulados, os clusters que ele produz podem ser de baixa qualidade. No exemplo acima, os clusters podem agrupar 'coisas musicais redondas', 'coisas musicais quadradas', 'coisas triangulares' e 'biscoitos'. Se forem dadas algumas restri√ß√µes ou regras para seguir ("o item deve ser feito de pl√°stico", "o item precisa ser capaz de produzir m√∫sica"), isso pode ajudar a 'restringir' o algoritmo para fazer escolhas melhores.
> 
> üéì 'Densidade'
> 
> Dados que s√£o 'ruidosos' s√£o considerados 'densos'. As dist√¢ncias entre pontos em cada um de seus clusters podem, ao serem examinadas, provar ser mais ou menos densas, ou 'aglomeradas', e assim esses dados precisam ser analisados com o m√©todo de clustering apropriado. [Este artigo](https://www.kdnuggets.com/2020/02/understanding-density-based-clustering.html) demonstra a diferen√ßa entre usar clustering K-Means vs. algoritmos HDBSCAN para explorar um conjunto de dados ruidoso com densidade de cluster desigual.

## Algoritmos de clustering

Existem mais de 100 algoritmos de clustering, e seu uso depende da natureza dos dados em quest√£o. Vamos discutir alguns dos principais:

- **Clustering hier√°rquico**. Se um objeto √© classificado por sua proximidade a um objeto pr√≥ximo, em vez de a um mais distante, os clusters s√£o formados com base na dist√¢ncia de seus membros para outros objetos. O clustering aglomerativo do Scikit-learn √© hier√°rquico.

   ![Infogr√°fico Clustering Hier√°rquico](../../../../5-Clustering/1-Visualize/images/hierarchical.png)
   > Infogr√°fico por [Dasani Madipalli](https://twitter.com/dasani_decoded)

- **Clustering por centroide**. Este algoritmo popular exige a escolha de 'k', ou o n√∫mero de clusters a serem formados, ap√≥s o qual o algoritmo determina o ponto central de um cluster e re√∫ne dados ao redor desse ponto. [Clustering K-means](https://wikipedia.org/wiki/K-means_clustering) √© uma vers√£o popular de clustering por centroide. O centro √© determinado pela m√©dia mais pr√≥xima, da√≠ o nome. A dist√¢ncia quadrada do cluster √© minimizada.

   ![Infogr√°fico Clustering por Centroide](../../../../5-Clustering/1-Visualize/images/centroid.png)
   > Infogr√°fico por [Dasani Madipalli](https://twitter.com/dasani_decoded)

- **Clustering baseado em distribui√ß√£o**. Baseado em modelagem estat√≠stica, clustering baseado em distribui√ß√£o centra-se em determinar a probabilidade de um ponto de dados pertencer a um cluster e atribu√≠-lo de acordo. M√©todos de mistura Gaussianas pertencem a este tipo.

- **Clustering baseado em densidade**. Pontos de dados s√£o atribu√≠dos a clusters com base em sua densidade, ou seu agrupamento ao redor uns dos outros. Pontos de dados distantes do grupo s√£o considerados outliers ou ru√≠dos. DBSCAN, Mean-shift e OPTICS pertencem a este tipo de clustering.

- **Clustering baseado em grade**. Para conjuntos de dados multidimensionais, uma grade √© criada e os dados s√£o divididos entre as c√©lulas da grade, criando assim clusters.

## Exerc√≠cio - agrupe seus dados

Clustering como t√©cnica √© muito auxiliado por uma boa visualiza√ß√£o, ent√£o vamos come√ßar visualizando nossos dados musicais. Este exerc√≠cio nos ajudar√° a decidir qual dos m√©todos de clustering devemos usar de forma mais eficaz para a natureza desses dados.

1. Abra o arquivo [_notebook.ipynb_](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/1-Visualize/notebook.ipynb) nesta pasta.

1. Importe o pacote `Seaborn` para uma boa visualiza√ß√£o de dados.

    ```python
    !pip install seaborn
    ```

1. Adicione os dados das m√∫sicas do arquivo [_nigerian-songs.csv_](https://github.com/microsoft/ML-For-Beginners/blob/main/5-Clustering/data/nigerian-songs.csv). Carregue um dataframe com alguns dados sobre as m√∫sicas. Prepare-se para explorar esses dados importando as bibliotecas e exibindo os dados:

    ```python
    import matplotlib.pyplot as plt
    import pandas as pd
    
    df = pd.read_csv("../data/nigerian-songs.csv")
    df.head()
    ```

    Verifique as primeiras linhas de dados:

    |     | nome                     | √°lbum                        | artista             | g√©nero_principal_artista | data_lan√ßamento | dura√ß√£o | popularidade | dan√ßabilidade | ac√∫stica | energia | instrumentalidade | vivacidade | volume   | discurso   | tempo   | assinatura_tempo |
    | --- | ------------------------ | ---------------------------- | ------------------- | ------------------------- | ---------------- | ------- | ------------ | ------------- | -------- | ------- | ------------------ | ---------- | -------- | ---------- | ------- | ---------------- |
    | 0   | Sparky                   | Mandy & The Jungle           | Cruel Santino       | r&b alternativo          | 2019             | 144000  | 48           | 0.666         | 0.851    | 0.42    | 0.534              | 0.11       | -6.699   | 0.0829     | 133.015 | 5                |
    | 1   | shuga rush               | EVERYTHING YOU HEARD IS TRUE | Odunsi (The Engine) | afropop                  | 2020             | 89488   | 30           | 0.71          | 0.0822   | 0.683   | 0.000169           | 0.101      | -5.64    | 0.36       | 129.993 | 3                |
| 2   | LITT!                    | LITT!                        | AYL√ò                | indie r&b        | 2018         | 207758 | 40         | 0.836        | 0.272        | 0.564  | 0.000537         | 0.11     | -7.127   | 0.0424      | 130.005 | 4              |
| 3   | Confident / Feeling Cool | Enjoy Your Life              | Lady Donli          | nigerian pop     | 2019         | 175135 | 14         | 0.894        | 0.798        | 0.611  | 0.000187         | 0.0964   | -4.961   | 0.113       | 111.087 | 4              |
| 4   | wanted you               | rare.                        | Odunsi (The Engine) | afropop          | 2018         | 152049 | 25         | 0.702        | 0.116        | 0.833  | 0.91             | 0.348    | -6.044   | 0.0447      | 105.115 | 4              |

1. Obtenha algumas informa√ß√µes sobre o dataframe, chamando `info()`:

    ```python
    df.info()
    ```

   O resultado ser√° semelhante a:

    ```output
    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 530 entries, 0 to 529
    Data columns (total 16 columns):
     #   Column            Non-Null Count  Dtype  
    ---  ------            --------------  -----  
     0   name              530 non-null    object 
     1   album             530 non-null    object 
     2   artist            530 non-null    object 
     3   artist_top_genre  530 non-null    object 
     4   release_date      530 non-null    int64  
     5   length            530 non-null    int64  
     6   popularity        530 non-null    int64  
     7   danceability      530 non-null    float64
     8   acousticness      530 non-null    float64
     9   energy            530 non-null    float64
     10  instrumentalness  530 non-null    float64
     11  liveness          530 non-null    float64
     12  loudness          530 non-null    float64
     13  speechiness       530 non-null    float64
     14  tempo             530 non-null    float64
     15  time_signature    530 non-null    int64  
    dtypes: float64(8), int64(4), object(4)
    memory usage: 66.4+ KB
    ```

1. Verifique novamente se h√° valores nulos, chamando `isnull()` e verificando se a soma √© 0:

    ```python
    df.isnull().sum()
    ```

    Tudo certo:

    ```output
    name                0
    album               0
    artist              0
    artist_top_genre    0
    release_date        0
    length              0
    popularity          0
    danceability        0
    acousticness        0
    energy              0
    instrumentalness    0
    liveness            0
    loudness            0
    speechiness         0
    tempo               0
    time_signature      0
    dtype: int64
    ```

1. Descreva os dados:

    ```python
    df.describe()
    ```

    |       | release_date | length      | popularity | danceability | acousticness | energy   | instrumentalness | liveness | loudness  | speechiness | tempo      | time_signature |
    | ----- | ------------ | ----------- | ---------- | ------------ | ------------ | -------- | ---------------- | -------- | --------- | ----------- | ---------- | -------------- |
    | count | 530          | 530         | 530        | 530          | 530          | 530      | 530              | 530      | 530       | 530         | 530        | 530            |
    | mean  | 2015.390566  | 222298.1698 | 17.507547  | 0.741619     | 0.265412     | 0.760623 | 0.016305         | 0.147308 | -4.953011 | 0.130748    | 116.487864 | 3.986792       |
    | std   | 3.131688     | 39696.82226 | 18.992212  | 0.117522     | 0.208342     | 0.148533 | 0.090321         | 0.123588 | 2.464186  | 0.092939    | 23.518601  | 0.333701       |
    | min   | 1998         | 89488       | 0          | 0.255        | 0.000665     | 0.111    | 0                | 0.0283   | -19.362   | 0.0278      | 61.695     | 3              |
    | 25%   | 2014         | 199305      | 0          | 0.681        | 0.089525     | 0.669    | 0                | 0.07565  | -6.29875  | 0.0591      | 102.96125  | 4              |
    | 50%   | 2016         | 218509      | 13         | 0.761        | 0.2205       | 0.7845   | 0.000004         | 0.1035   | -4.5585   | 0.09795     | 112.7145   | 4              |
    | 75%   | 2017         | 242098.5    | 31         | 0.8295       | 0.403        | 0.87575  | 0.000234         | 0.164    | -3.331    | 0.177       | 125.03925  | 4              |
    | max   | 2020         | 511738      | 73         | 0.966        | 0.954        | 0.995    | 0.91             | 0.811    | 0.582     | 0.514       | 206.007    | 5              |

> ü§î Se estamos a trabalhar com clustering, um m√©todo n√£o supervisionado que n√£o requer dados rotulados, por que estamos a mostrar estes dados com r√≥tulos? Na fase de explora√ß√£o de dados, eles s√£o √∫teis, mas n√£o s√£o necess√°rios para os algoritmos de clustering funcionarem. Poder√≠amos simplesmente remover os cabe√ßalhos das colunas e referir-nos aos dados pelo n√∫mero da coluna.

Observe os valores gerais dos dados. Note que a popularidade pode ser '0', o que indica m√∫sicas que n√£o t√™m classifica√ß√£o. Vamos remover esses valores em breve.

1. Use um gr√°fico de barras para descobrir os g√©neros mais populares:

    ```python
    import seaborn as sns
    
    top = df['artist_top_genre'].value_counts()
    plt.figure(figsize=(10,7))
    sns.barplot(x=top[:5].index,y=top[:5].values)
    plt.xticks(rotation=45)
    plt.title('Top genres',color = 'blue')
    ```

    ![most popular](../../../../5-Clustering/1-Visualize/images/popular.png)

‚úÖ Se quiser ver mais valores principais, altere o top `[:5]` para um valor maior ou remova-o para ver todos.

Note que, quando o g√©nero principal √© descrito como 'Missing', isso significa que o Spotify n√£o o classificou, ent√£o vamos elimin√°-lo.

1. Elimine os dados ausentes filtrando-os:

    ```python
    df = df[df['artist_top_genre'] != 'Missing']
    top = df['artist_top_genre'].value_counts()
    plt.figure(figsize=(10,7))
    sns.barplot(x=top.index,y=top.values)
    plt.xticks(rotation=45)
    plt.title('Top genres',color = 'blue')
    ```

    Agora verifique novamente os g√©neros:

    ![most popular](../../../../5-Clustering/1-Visualize/images/all-genres.png)

1. De longe, os tr√™s g√©neros principais dominam este conjunto de dados. Vamos concentrar-nos em `afro dancehall`, `afropop` e `nigerian pop`, e adicionalmente filtrar o conjunto de dados para remover qualquer valor de popularidade igual a 0 (o que significa que n√£o foi classificado com uma popularidade no conjunto de dados e pode ser considerado ru√≠do para os nossos prop√≥sitos):

    ```python
    df = df[(df['artist_top_genre'] == 'afro dancehall') | (df['artist_top_genre'] == 'afropop') | (df['artist_top_genre'] == 'nigerian pop')]
    df = df[(df['popularity'] > 0)]
    top = df['artist_top_genre'].value_counts()
    plt.figure(figsize=(10,7))
    sns.barplot(x=top.index,y=top.values)
    plt.xticks(rotation=45)
    plt.title('Top genres',color = 'blue')
    ```

1. Fa√ßa um teste r√°pido para ver se os dados t√™m alguma correla√ß√£o particularmente forte:

    ```python
    corrmat = df.corr(numeric_only=True)
    f, ax = plt.subplots(figsize=(12, 9))
    sns.heatmap(corrmat, vmax=.8, square=True)
    ```

    ![correlations](../../../../5-Clustering/1-Visualize/images/correlation.png)

    A √∫nica correla√ß√£o forte √© entre `energy` e `loudness`, o que n√£o √© muito surpreendente, dado que m√∫sica alta geralmente √© bastante energ√©tica. Fora isso, as correla√ß√µes s√£o relativamente fracas. Ser√° interessante ver o que um algoritmo de clustering pode fazer com estes dados.

    > üéì Note que correla√ß√£o n√£o implica causalidade! Temos prova de correla√ß√£o, mas n√£o prova de causalidade. Um [site divertido](https://tylervigen.com/spurious-correlations) tem alguns visuais que enfatizam este ponto.

H√° alguma converg√™ncia neste conjunto de dados em torno da popularidade percebida de uma m√∫sica e sua capacidade de dan√ßa? Um FacetGrid mostra que h√° c√≠rculos conc√™ntricos que se alinham, independentemente do g√©nero. Poderia ser que os gostos nigerianos convergem a um certo n√≠vel de capacidade de dan√ßa para este g√©nero?  

‚úÖ Experimente diferentes pontos de dados (energia, loudness, speechiness) e mais ou diferentes g√©neros musicais. O que consegue descobrir? Veja a tabela `df.describe()` para observar a distribui√ß√£o geral dos pontos de dados.

### Exerc√≠cio - distribui√ß√£o de dados

Estes tr√™s g√©neros s√£o significativamente diferentes na perce√ß√£o da sua capacidade de dan√ßa, com base na sua popularidade?

1. Examine a distribui√ß√£o de dados dos nossos tr√™s g√©neros principais para popularidade e capacidade de dan√ßa ao longo de um eixo x e y dado.

    ```python
    sns.set_theme(style="ticks")
    
    g = sns.jointplot(
        data=df,
        x="popularity", y="danceability", hue="artist_top_genre",
        kind="kde",
    )
    ```

    Pode descobrir c√≠rculos conc√™ntricos em torno de um ponto geral de converg√™ncia, mostrando a distribui√ß√£o dos pontos.

    > üéì Note que este exemplo usa um gr√°fico KDE (Kernel Density Estimate) que representa os dados usando uma curva de densidade de probabilidade cont√≠nua. Isso permite interpretar os dados ao trabalhar com m√∫ltiplas distribui√ß√µes.

    Em geral, os tr√™s g√©neros alinham-se vagamente em termos de sua popularidade e capacidade de dan√ßa. Determinar clusters nestes dados vagamente alinhados ser√° um desafio:

    ![distribution](../../../../5-Clustering/1-Visualize/images/distribution.png)

1. Crie um gr√°fico de dispers√£o:

    ```python
    sns.FacetGrid(df, hue="artist_top_genre", height=5) \
       .map(plt.scatter, "popularity", "danceability") \
       .add_legend()
    ```

    Um gr√°fico de dispers√£o dos mesmos eixos mostra um padr√£o semelhante de converg√™ncia.

    ![Facetgrid](../../../../5-Clustering/1-Visualize/images/facetgrid.png)

Em geral, para clustering, pode usar gr√°ficos de dispers√£o para mostrar clusters de dados, por isso dominar este tipo de visualiza√ß√£o √© muito √∫til. Na pr√≥xima li√ß√£o, vamos pegar neste conjunto de dados filtrado e usar clustering k-means para descobrir grupos nestes dados que parecem sobrepor-se de formas interessantes.

---

## üöÄDesafio

Em prepara√ß√£o para a pr√≥xima li√ß√£o, crie um gr√°fico sobre os v√°rios algoritmos de clustering que pode descobrir e usar num ambiente de produ√ß√£o. Que tipos de problemas o clustering est√° a tentar resolver?

## [Question√°rio p√≥s-aula](https://ff-quizzes.netlify.app/en/ml/)

## Revis√£o e Autoestudo

Antes de aplicar algoritmos de clustering, como aprendemos, √© uma boa ideia entender a natureza do seu conjunto de dados. Leia mais sobre este t√≥pico [aqui](https://www.kdnuggets.com/2019/10/right-clustering-algorithm.html)

[Este artigo √∫til](https://www.freecodecamp.org/news/8-clustering-algorithms-in-machine-learning-that-all-data-scientists-should-know/) explica os diferentes comportamentos de v√°rios algoritmos de clustering, dados diferentes formatos de dados.

## Tarefa

[Pesquise outras visualiza√ß√µes para clustering](assignment.md)

---

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original no seu idioma nativo deve ser considerado a fonte oficial. Para informa√ß√µes cr√≠ticas, recomenda-se uma tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas resultantes do uso desta tradu√ß√£o.