# Classificadores de culin√°ria 1

Nesta li√ß√£o, voc√™ usar√° o conjunto de dados que salvou na √∫ltima li√ß√£o, repleto de dados equilibrados e limpos sobre culin√°rias.

Voc√™ utilizar√° esse conjunto de dados com uma variedade de classificadores para _prever uma determinada culin√°ria nacional com base em um grupo de ingredientes_. Enquanto faz isso, voc√™ aprender√° mais sobre algumas das maneiras que os algoritmos podem ser aproveitados para tarefas de classifica√ß√£o.

## [Quiz pr√©-aula](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/21/)
# Prepara√ß√£o

Assumindo que voc√™ completou a [Li√ß√£o 1](../1-Introduction/README.md), certifique-se de que um arquivo _cleaned_cuisines.csv_ exista na pasta raiz `/data` para essas quatro li√ß√µes.

## Exerc√≠cio - prever uma culin√°ria nacional

1. Trabalhando na pasta _notebook.ipynb_ desta li√ß√£o, importe esse arquivo juntamente com a biblioteca Pandas:

    ```python
    import pandas as pd
    cuisines_df = pd.read_csv("../data/cleaned_cuisines.csv")
    cuisines_df.head()
    ```

    Os dados se parecem com isto:

|     | Unnamed: 0 | cuisine | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood | yam | yeast | yogurt | zucchini |
| --- | ---------- | ------- | ------ | -------- | ----- | ---------- | ----- | ------------ | ------- | -------- | --- | ------- | ----------- | ---------- | ----------------------- | ---- | ---- | --- | ----- | ------ | -------- |
| 0   | 0          | indiana | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 1   | 1          | indiana | 1      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 2   | 2          | indiana | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 3   | 3          | indiana | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 0      | 0        |
| 4   | 4          | indiana | 0      | 0        | 0     | 0          | 0     | 0            | 0       | 0        | ... | 0       | 0           | 0          | 0                       | 0    | 0    | 0   | 0     | 1      | 0        |
  

1. Agora, importe v√°rias outras bibliotecas:

    ```python
    from sklearn.linear_model import LogisticRegression
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    from sklearn.svm import SVC
    import numpy as np
    ```

1. Divida as coordenadas X e y em dois dataframes para treinamento. `cuisine` pode ser o dataframe de r√≥tulos:

    ```python
    cuisines_label_df = cuisines_df['cuisine']
    cuisines_label_df.head()
    ```

    Ele se parecer√° com isto:

    ```output
    0    indian
    1    indian
    2    indian
    3    indian
    4    indian
    Name: cuisine, dtype: object
    ```

1. Remova `Unnamed: 0` column and the `cuisine` column, calling `drop()`. Salve o restante dos dados como caracter√≠sticas trein√°veis:

    ```python
    cuisines_feature_df = cuisines_df.drop(['Unnamed: 0', 'cuisine'], axis=1)
    cuisines_feature_df.head()
    ```

    Suas caracter√≠sticas se parecem com isto:

|      | almond | angelica | anise | anise_seed | apple | apple_brandy | apricot | armagnac | artemisia | artichoke |  ... | whiskey | white_bread | white_wine | whole_grain_wheat_flour | wine | wood |  yam | yeast | yogurt | zucchini |
| ---: | -----: | -------: | ----: | ---------: | ----: | -----------: | ------: | -------: | --------: | --------: | ---: | ------: | ----------: | ---------: | ----------------------: | ---: | ---: | ---: | ----: | -----: | -------: |
|    0 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    1 |      1 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    2 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    3 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      0 |        0 | 0 |
|    4 |      0 |        0 |     0 |          0 |     0 |            0 |       0 |        0 |         0 |         0 |  ... |       0 |           0 |          0 |                       0 |    0 |    0 |    0 |     0 |      1 |        0 | 0 |

Agora voc√™ est√° pronto para treinar seu modelo!

## Escolhendo seu classificador

Agora que seus dados est√£o limpos e prontos para treinamento, voc√™ precisa decidir qual algoritmo usar para o trabalho. 

O Scikit-learn agrupa a classifica√ß√£o sob Aprendizado Supervisionado, e nessa categoria voc√™ encontrar√° muitas maneiras de classificar. [A variedade](https://scikit-learn.org/stable/supervised_learning.html) √© bastante impressionante √† primeira vista. Os seguintes m√©todos incluem t√©cnicas de classifica√ß√£o:

- Modelos Lineares
- M√°quinas de Vetores de Suporte
- Gradiente Estoc√°stico
- Vizinhos Mais Pr√≥ximos
- Processos Gaussianos
- √Årvores de Decis√£o
- M√©todos de Conjunto (Classificador de Vota√ß√£o)
- Algoritmos Multiclasse e Multi-sa√≠da (classifica√ß√£o multiclasse e multilabel, classifica√ß√£o multiclasse-multi-sa√≠da)

> Voc√™ tamb√©m pode usar [redes neurais para classificar dados](https://scikit-learn.org/stable/modules/neural_networks_supervised.html#classification), mas isso est√° fora do escopo desta li√ß√£o.

### Qual classificador escolher?

Ent√£o, qual classificador voc√™ deve escolher? Muitas vezes, passar por v√°rios e buscar um bom resultado √© uma maneira de testar. O Scikit-learn oferece uma [compara√ß√£o lado a lado](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) em um conjunto de dados criado, comparando KNeighbors, SVC de duas maneiras, GaussianProcessClassifier, DecisionTreeClassifier, RandomForestClassifier, MLPClassifier, AdaBoostClassifier, GaussianNB e QuadraticDiscriminantAnalysis, mostrando os resultados visualizados: 

![compara√ß√£o de classificadores](../../../../translated_images/comparison.edfab56193a85e7fdecbeaa1b1f8c99e94adbf7178bed0de902090cf93d6734f.pt.png)
> Gr√°ficos gerados na documenta√ß√£o do Scikit-learn

> O AutoML resolve esse problema de forma elegante executando essas compara√ß√µes na nuvem, permitindo que voc√™ escolha o melhor algoritmo para seus dados. Experimente [aqui](https://docs.microsoft.com/learn/modules/automate-model-selection-with-azure-automl/?WT.mc_id=academic-77952-leestott)

### Uma abordagem melhor

Uma maneira melhor do que adivinhar aleatoriamente, no entanto, √© seguir as ideias neste [ML Cheat sheet](https://docs.microsoft.com/azure/machine-learning/algorithm-cheat-sheet?WT.mc_id=academic-77952-leestott) que pode ser baixada. Aqui, descobrimos que, para o nosso problema multiclasse, temos algumas op√ß√µes:

![cheatsheet para problemas multiclasse](../../../../translated_images/cheatsheet.07a475ea444d22234cb8907a3826df5bdd1953efec94bd18e4496f36ff60624a.pt.png)
> Uma se√ß√£o da Folha de Dicas de Algoritmos da Microsoft, detalhando op√ß√µes de classifica√ß√£o multiclasse

‚úÖ Baixe esta folha de dicas, imprima e coloque na sua parede!

### Racioc√≠nio

Vamos ver se conseguimos raciocinar sobre diferentes abordagens dadas as restri√ß√µes que temos:

- **Redes neurais s√£o muito pesadas**. Dado nosso conjunto de dados limpo, mas m√≠nimo, e o fato de que estamos realizando o treinamento localmente via notebooks, redes neurais s√£o muito pesadas para esta tarefa.
- **Nenhum classificador de duas classes**. N√£o usamos um classificador de duas classes, ent√£o isso elimina um contra todos. 
- **√Årvore de decis√£o ou regress√£o log√≠stica podem funcionar**. Uma √°rvore de decis√£o pode funcionar, ou regress√£o log√≠stica para dados multiclasse. 
- **√Årvores de Decis√£o Aumentadas Multiclasse resolvem um problema diferente**. A √°rvore de decis√£o aumentada multiclasse √© mais adequada para tarefas n√£o param√©tricas, por exemplo, tarefas projetadas para construir classifica√ß√µes, ent√£o n√£o √© √∫til para n√≥s.

### Usando Scikit-learn 

Usaremos o Scikit-learn para analisar nossos dados. No entanto, existem muitas maneiras de usar a regress√£o log√≠stica no Scikit-learn. D√™ uma olhada nos [par√¢metros a serem passados](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regressio#sklearn.linear_model.LogisticRegression).  

Essencialmente, h√° dois par√¢metros importantes - `multi_class` and `solver` - that we need to specify, when we ask Scikit-learn to perform a logistic regression. The `multi_class` value applies a certain behavior. The value of the solver is what algorithm to use. Not all solvers can be paired with all `multi_class` values.

According to the docs, in the multiclass case, the training algorithm:

- **Uses the one-vs-rest (OvR) scheme**, if the `multi_class` option is set to `ovr`
- **Uses the cross-entropy loss**, if the `multi_class` option is set to `multinomial`. (Currently the `multinomial` option is supported only by the ‚Äòlbfgs‚Äô, ‚Äòsag‚Äô, ‚Äòsaga‚Äô and ‚Äònewton-cg‚Äô solvers.)"

> üéì The 'scheme' here can either be 'ovr' (one-vs-rest) or 'multinomial'. Since logistic regression is really designed to support binary classification, these schemes allow it to better handle multiclass classification tasks. [source](https://machinelearningmastery.com/one-vs-rest-and-one-vs-one-for-multi-class-classification/)

> üéì The 'solver' is defined as "the algorithm to use in the optimization problem". [source](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html?highlight=logistic%20regressio#sklearn.linear_model.LogisticRegression).

Scikit-learn offers this table to explain how solvers handle different challenges presented by different kinds of data structures:

![solvers](../../../../translated_images/solvers.5fc648618529e627dfac29b917b3ccabda4b45ee8ed41b0acb1ce1441e8d1ef1.pt.png)

## Exercise - split the data

We can focus on logistic regression for our first training trial since you recently learned about the latter in a previous lesson.
Split your data into training and testing groups by calling `train_test_split()`:

```python
X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)
```

## Exerc√≠cio - aplicar regress√£o log√≠stica

Como voc√™ est√° usando o caso multiclasse, precisa escolher qual _esquema_ usar e qual _solver_ definir. Use LogisticRegression com uma configura√ß√£o multiclasse e o **liblinear** solver para treinar.

1. Crie uma regress√£o log√≠stica com multi_class definido como `ovr` and the solver set to `liblinear`:

    ```python
    lr = LogisticRegression(multi_class='ovr',solver='liblinear')
    model = lr.fit(X_train, np.ravel(y_train))
    
    accuracy = model.score(X_test, y_test)
    print ("Accuracy is {}".format(accuracy))
    ```

    ‚úÖ Tente um solver diferente como `lbfgs`, which is often set as default

    > Note, use Pandas [`ravel`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.ravel.html) para achatar seus dados quando necess√°rio.

    A precis√£o √© boa, acima de **80%**!

1. Voc√™ pode ver este modelo em a√ß√£o testando uma linha de dados (#50):

    ```python
    print(f'ingredients: {X_test.iloc[50][X_test.iloc[50]!=0].keys()}')
    print(f'cuisine: {y_test.iloc[50]}')
    ```

    O resultado √© impresso:

   ```output
   ingredients: Index(['cilantro', 'onion', 'pea', 'potato', 'tomato', 'vegetable_oil'], dtype='object')
   cuisine: indian
   ```

   ‚úÖ Tente um n√∫mero de linha diferente e verifique os resultados

1. Aprofundando, voc√™ pode verificar a precis√£o desta previs√£o:

    ```python
    test= X_test.iloc[50].values.reshape(-1, 1).T
    proba = model.predict_proba(test)
    classes = model.classes_
    resultdf = pd.DataFrame(data=proba, columns=classes)
    
    topPrediction = resultdf.T.sort_values(by=[0], ascending = [False])
    topPrediction.head()
    ```

    O resultado √© impresso - a culin√°ria indiana √© a melhor aposta, com boa probabilidade:

    |          |        0 |
    | -------: | -------: |
    |   indiana | 0.715851 |
    |  chinesa | 0.229475 |
    | japonesa | 0.029763 |
    |   coreana | 0.017277 |
    |     tailandesa | 0.007634 |

    ‚úÖ Voc√™ consegue explicar por que o modelo est√° bastante certo de que esta √© uma culin√°ria indiana?

1. Obtenha mais detalhes imprimindo um relat√≥rio de classifica√ß√£o, como voc√™ fez nas li√ß√µes de regress√£o:

    ```python
    y_pred = model.predict(X_test)
    print(classification_report(y_test,y_pred))
    ```

    |              | precis√£o | recall | f1-score | suporte |
    | ------------ | --------- | ------ | -------- | ------- |
    | chinesa      | 0.73      | 0.71   | 0.72     | 229     |
    | indiana       | 0.91      | 0.93   | 0.92     | 254     |
    | japonesa     | 0.70      | 0.75   | 0.72     | 220     |
    | coreana       | 0.86      | 0.76   | 0.81     | 242     |
    | tailandesa         | 0.79      | 0.85   | 0.82     | 254     |
    | precis√£o     | 0.80      | 1199   |          |         |
    | m√©dia macro    | 0.80      | 0.80   | 0.80     | 1199    |
    | m√©dia ponderada | 0.80      | 0.80   | 0.80     | 1199    |

## üöÄDesafio

Nesta li√ß√£o, voc√™ usou seus dados limpos para construir um modelo de aprendizado de m√°quina que pode prever uma culin√°ria nacional com base em uma s√©rie de ingredientes. Reserve um tempo para ler sobre as muitas op√ß√µes que o Scikit-learn oferece para classificar dados. Aprofunde-se no conceito de 'solver' para entender o que acontece nos bastidores.

## [Quiz p√≥s-aula](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/22/)

## Revis√£o e Autoestudo

Aprofunde-se um pouco mais na matem√°tica por tr√°s da regress√£o log√≠stica nesta [li√ß√£o](https://people.eecs.berkeley.edu/~russell/classes/cs194/f11/lectures/CS194%20Fall%202011%20Lecture%2006.pdf)
## Tarefa 

[Estude os solvers](assignment.md)

**Isen√ß√£o de responsabilidade**:  
Este documento foi traduzido usando servi√ßos de tradu√ß√£o autom√°tica baseados em IA. Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autorit√°ria. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional feita por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes err√¥neas decorrentes do uso desta tradu√ß√£o.