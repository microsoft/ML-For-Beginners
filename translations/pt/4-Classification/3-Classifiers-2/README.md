# Classificadores de culin√°ria 2

Nesta segunda li√ß√£o de classifica√ß√£o, voc√™ explorar√° mais maneiras de classificar dados num√©ricos. Voc√™ tamb√©m aprender√° sobre as implica√ß√µes de escolher um classificador em vez de outro.

## [Quiz pr√©-aula](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/23/)

### Pr√©-requisito

Assumimos que voc√™ completou as li√ß√µes anteriores e tem um conjunto de dados limpo na sua pasta `data` chamada _cleaned_cuisines.csv_ na raiz desta pasta de 4 li√ß√µes.

### Prepara√ß√£o

Carregamos seu arquivo _notebook.ipynb_ com o conjunto de dados limpo e o dividimos em dataframes X e y, prontos para o processo de constru√ß√£o do modelo.

## Um mapa de classifica√ß√£o

Anteriormente, voc√™ aprendeu sobre as v√°rias op√ß√µes que tem ao classificar dados usando a folha de dicas da Microsoft. O Scikit-learn oferece uma folha de dicas semelhante, mas mais detalhada, que pode ajudar ainda mais a restringir seus estimadores (outro termo para classificadores):

![Mapa ML do Scikit-learn](../../../../translated_images/map.e963a6a51349425ab107b38f6c7307eb4c0d0c7ccdd2e81a5e1919292bab9ac7.pt.png)
> Dica: [visite este mapa online](https://scikit-learn.org/stable/tutorial/machine_learning_map/) e clique ao longo do caminho para ler a documenta√ß√£o.

### O plano

Este mapa √© muito √∫til uma vez que voc√™ tenha uma compreens√£o clara dos seus dados, pois voc√™ pode 'caminhar' ao longo de seus caminhos at√© uma decis√£o:

- Temos mais de 50 amostras
- Queremos prever uma categoria
- Temos dados rotulados
- Temos menos de 100K amostras
- ‚ú® Podemos escolher um SVC Linear
- Se isso n√£o funcionar, j√° que temos dados num√©ricos
    - Podemos tentar um ‚ú® Classificador KNeighbors 
      - Se isso n√£o funcionar, tente ‚ú® SVC e ‚ú® Classificadores de Conjunto

Este √© um caminho muito √∫til a seguir.

## Exerc√≠cio - dividir os dados

Seguindo este caminho, devemos come√ßar importando algumas bibliotecas para usar.

1. Importe as bibliotecas necess√°rias:

    ```python
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.linear_model import LogisticRegression
    from sklearn.svm import SVC
    from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier
    from sklearn.model_selection import train_test_split, cross_val_score
    from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve
    import numpy as np
    ```

1. Divida seus dados de treinamento e teste:

    ```python
    X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)
    ```

## Classificador SVC Linear

A clusteriza√ß√£o Support-Vector (SVC) √© um membro da fam√≠lia de t√©cnicas de ML das M√°quinas de Vetores de Suporte (aprenda mais sobre elas abaixo). Neste m√©todo, voc√™ pode escolher um 'kernel' para decidir como agrupar os r√≥tulos. O par√¢metro 'C' refere-se √† 'regulariza√ß√£o', que regula a influ√™ncia dos par√¢metros. O kernel pode ser um dos [v√°rios](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html#sklearn.svm.SVC); aqui o configuramos como 'linear' para garantir que aproveitemos o SVC linear. A probabilidade padr√£o √© 'false'; aqui a configuramos como 'true' para coletar estimativas de probabilidade. Definimos o estado aleat√≥rio como '0' para embaralhar os dados e obter probabilidades.

### Exerc√≠cio - aplique um SVC linear

Comece criando um array de classificadores. Voc√™ adicionar√° progressivamente a este array √† medida que testamos. 

1. Comece com um SVC Linear:

    ```python
    C = 10
    # Create different classifiers.
    classifiers = {
        'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0)
    }
    ```

2. Treine seu modelo usando o SVC Linear e imprima um relat√≥rio:

    ```python
    n_classifiers = len(classifiers)
    
    for index, (name, classifier) in enumerate(classifiers.items()):
        classifier.fit(X_train, np.ravel(y_train))
    
        y_pred = classifier.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        print("Accuracy (train) for %s: %0.1f%% " % (name, accuracy * 100))
        print(classification_report(y_test,y_pred))
    ```

    O resultado √© bastante bom:

    ```output
    Accuracy (train) for Linear SVC: 78.6% 
                  precision    recall  f1-score   support
    
         chinese       0.71      0.67      0.69       242
          indian       0.88      0.86      0.87       234
        japanese       0.79      0.74      0.76       254
          korean       0.85      0.81      0.83       242
            thai       0.71      0.86      0.78       227
    
        accuracy                           0.79      1199
       macro avg       0.79      0.79      0.79      1199
    weighted avg       0.79      0.79      0.79      1199
    ```

## Classificador K-Neighbors

K-Neighbors √© parte da fam√≠lia de m√©todos de ML "neighbors", que pode ser usada tanto para aprendizado supervisionado quanto n√£o supervisionado. Neste m√©todo, um n√∫mero predefinido de pontos √© criado e dados s√£o coletados ao redor desses pontos de modo que r√≥tulos generalizados possam ser previstos para os dados.

### Exerc√≠cio - aplique o classificador K-Neighbors

O classificador anterior foi bom e funcionou bem com os dados, mas talvez possamos obter uma precis√£o melhor. Tente um classificador K-Neighbors.

1. Adicione uma linha ao seu array de classificadores (adicione uma v√≠rgula ap√≥s o item SVC Linear):

    ```python
    'KNN classifier': KNeighborsClassifier(C),
    ```

    O resultado √© um pouco pior:

    ```output
    Accuracy (train) for KNN classifier: 73.8% 
                  precision    recall  f1-score   support
    
         chinese       0.64      0.67      0.66       242
          indian       0.86      0.78      0.82       234
        japanese       0.66      0.83      0.74       254
          korean       0.94      0.58      0.72       242
            thai       0.71      0.82      0.76       227
    
        accuracy                           0.74      1199
       macro avg       0.76      0.74      0.74      1199
    weighted avg       0.76      0.74      0.74      1199
    ```

    ‚úÖ Aprenda sobre [K-Neighbors](https://scikit-learn.org/stable/modules/neighbors.html#neighbors)

## Classificador Support Vector

Os classificadores Support-Vector s√£o parte da fam√≠lia de m√©todos de ML [Support-Vector Machine](https://wikipedia.org/wiki/Support-vector_machine) que s√£o usados para tarefas de classifica√ß√£o e regress√£o. SVMs "mapeiam exemplos de treinamento para pontos no espa√ßo" para maximizar a dist√¢ncia entre duas categorias. Dados subsequentes s√£o mapeados para este espa√ßo para que sua categoria possa ser prevista.

### Exerc√≠cio - aplique um classificador Support Vector

Vamos tentar uma precis√£o um pouco melhor com um classificador Support Vector.

1. Adicione uma v√≠rgula ap√≥s o item K-Neighbors e, em seguida, adicione esta linha:

    ```python
    'SVC': SVC(),
    ```

    O resultado √© bastante bom!

    ```output
    Accuracy (train) for SVC: 83.2% 
                  precision    recall  f1-score   support
    
         chinese       0.79      0.74      0.76       242
          indian       0.88      0.90      0.89       234
        japanese       0.87      0.81      0.84       254
          korean       0.91      0.82      0.86       242
            thai       0.74      0.90      0.81       227
    
        accuracy                           0.83      1199
       macro avg       0.84      0.83      0.83      1199
    weighted avg       0.84      0.83      0.83      1199
    ```

    ‚úÖ Aprenda sobre [Support-Vectors](https://scikit-learn.org/stable/modules/svm.html#svm)

## Classificadores de Conjunto

Vamos seguir o caminho at√© o fim, mesmo que o teste anterior tenha sido bastante bom. Vamos tentar alguns 'Classificadores de Conjunto', especificamente Random Forest e AdaBoost:

```python
  'RFST': RandomForestClassifier(n_estimators=100),
  'ADA': AdaBoostClassifier(n_estimators=100)
```

O resultado √© muito bom, especialmente para Random Forest:

```output
Accuracy (train) for RFST: 84.5% 
              precision    recall  f1-score   support

     chinese       0.80      0.77      0.78       242
      indian       0.89      0.92      0.90       234
    japanese       0.86      0.84      0.85       254
      korean       0.88      0.83      0.85       242
        thai       0.80      0.87      0.83       227

    accuracy                           0.84      1199
   macro avg       0.85      0.85      0.84      1199
weighted avg       0.85      0.84      0.84      1199

Accuracy (train) for ADA: 72.4% 
              precision    recall  f1-score   support

     chinese       0.64      0.49      0.56       242
      indian       0.91      0.83      0.87       234
    japanese       0.68      0.69      0.69       254
      korean       0.73      0.79      0.76       242
        thai       0.67      0.83      0.74       227

    accuracy                           0.72      1199
   macro avg       0.73      0.73      0.72      1199
weighted avg       0.73      0.72      0.72      1199
```

‚úÖ Aprenda sobre [Classificadores de Conjunto](https://scikit-learn.org/stable/modules/ensemble.html)

Este m√©todo de Aprendizado de M√°quina "combina as previs√µes de v√°rios estimadores base" para melhorar a qualidade do modelo. No nosso exemplo, usamos Random Trees e AdaBoost. 

- [Random Forest](https://scikit-learn.org/stable/modules/ensemble.html#forest), um m√©todo de m√©dia, constr√≥i uma 'floresta' de '√°rvores de decis√£o' infundidas com aleatoriedade para evitar overfitting. O par√¢metro n_estimators √© definido como o n√∫mero de √°rvores.

- [AdaBoost](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html) ajusta um classificador a um conjunto de dados e, em seguida, ajusta c√≥pias desse classificador ao mesmo conjunto de dados. Ele foca nos pesos dos itens classificados incorretamente e ajusta o ajuste para o pr√≥ximo classificador para corrigir.

---

## üöÄDesafio

Cada uma dessas t√©cnicas tem um grande n√∫mero de par√¢metros que voc√™ pode ajustar. Pesquise os par√¢metros padr√£o de cada um e pense sobre o que ajustar esses par√¢metros significaria para a qualidade do modelo.

## [Quiz p√≥s-aula](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/24/)

## Revis√£o e Autoestudo

H√° muita terminologia t√©cnica nessas li√ß√µes, ent√£o reserve um minuto para revisar [esta lista](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) de termos √∫teis!

## Tarefa 

[Brincadeira com par√¢metros](assignment.md)

**Isen√ß√£o de responsabilidade**:  
Este documento foi traduzido utilizando servi√ßos de tradu√ß√£o autom√°tica baseados em IA. Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional por um humano. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes equivocadas que possam surgir do uso desta tradu√ß√£o.