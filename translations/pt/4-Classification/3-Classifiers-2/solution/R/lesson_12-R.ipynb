{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "lesson_12-R.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "ir",
   "display_name": "R"
  },
  "language_info": {
   "name": "R"
  },
  "coopTranslator": {
   "original_hash": "fab50046ca413a38939d579f8432274f",
   "translation_date": "2025-09-03T20:30:42+00:00",
   "source_file": "4-Classification/3-Classifiers-2/solution/R/lesson_12-R.ipynb",
   "language_code": "pt"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jsFutf_ygqSx"
   },
   "source": [
    "# Construir um modelo de classifica√ß√£o: Deliciosas Cozinhas Asi√°ticas e Indianas\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HD54bEefgtNO"
   },
   "source": [
    "## Classificadores de culin√°ria 2\n",
    "\n",
    "Nesta segunda li√ß√£o sobre classifica√ß√£o, vamos explorar `mais formas` de classificar dados categ√≥ricos. Tamb√©m aprenderemos sobre as implica√ß√µes de escolher um classificador em vez de outro.\n",
    "\n",
    "### [**Question√°rio pr√©-aula**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/23/)\n",
    "\n",
    "### **Pr√©-requisitos**\n",
    "\n",
    "Assumimos que voc√™ completou as li√ß√µes anteriores, j√° que vamos utilizar alguns conceitos aprendidos anteriormente.\n",
    "\n",
    "Para esta li√ß√£o, precisaremos dos seguintes pacotes:\n",
    "\n",
    "-   `tidyverse`: O [tidyverse](https://www.tidyverse.org/) √© uma [cole√ß√£o de pacotes R](https://www.tidyverse.org/packages) projetada para tornar a ci√™ncia de dados mais r√°pida, f√°cil e divertida!\n",
    "\n",
    "-   `tidymodels`: O [tidymodels](https://www.tidymodels.org/) √© uma [estrutura de pacotes](https://www.tidymodels.org/packages/) para modelagem e aprendizagem de m√°quina.\n",
    "\n",
    "-   `themis`: O [pacote themis](https://themis.tidymodels.org/) fornece passos extras de receitas para lidar com dados desbalanceados.\n",
    "\n",
    "Voc√™ pode instal√°-los com o seguinte comando:\n",
    "\n",
    "`install.packages(c(\"tidyverse\", \"tidymodels\", \"kernlab\", \"themis\", \"ranger\", \"xgboost\", \"kknn\"))`\n",
    "\n",
    "Alternativamente, o script abaixo verifica se voc√™ possui os pacotes necess√°rios para completar este m√≥dulo e os instala caso estejam ausentes.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vZ57IuUxgyQt"
   },
   "source": [
    "suppressWarnings(if (!require(\"pacman\"))install.packages(\"pacman\"))\n",
    "\n",
    "pacman::p_load(tidyverse, tidymodels, themis, kernlab, ranger, xgboost, kknn)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z22M-pj4g07x"
   },
   "source": [
    "## **1. Um mapa de classifica√ß√£o**\n",
    "\n",
    "Na nossa [li√ß√£o anterior](https://github.com/microsoft/ML-For-Beginners/tree/main/4-Classification/2-Classifiers-1), tent√°mos responder √† pergunta: como escolher entre v√°rios modelos? Em grande parte, isso depende das caracter√≠sticas dos dados e do tipo de problema que queremos resolver (por exemplo, classifica√ß√£o ou regress√£o?).\n",
    "\n",
    "Anteriormente, aprendemos sobre as v√°rias op√ß√µes dispon√≠veis para classificar dados utilizando o guia da Microsoft. O framework de Machine Learning em Python, Scikit-learn, oferece um guia semelhante, mas mais detalhado, que pode ajudar ainda mais a restringir os seus estimadores (outro termo para classificadores):\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/map.png\"\n",
    "   width=\"700\"/>\n",
    "   <figcaption></figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u1i3xRIVg7vG"
   },
   "source": [
    "> Dica: [visite este mapa online](https://scikit-learn.org/stable/tutorial/machine_learning_map/) e clique ao longo do caminho para ler a documenta√ß√£o.\n",
    ">\n",
    "> O [site de refer√™ncia do Tidymodels](https://www.tidymodels.org/find/parsnip/#models) tamb√©m oferece uma excelente documenta√ß√£o sobre diferentes tipos de modelos.\n",
    "\n",
    "### **O plano** üó∫Ô∏è\n",
    "\n",
    "Este mapa √© muito √∫til quando se tem uma compreens√£o clara dos seus dados, pois pode 'percorrer' os seus caminhos at√© chegar a uma decis√£o:\n",
    "\n",
    "-   Temos \\>50 amostras\n",
    "\n",
    "-   Queremos prever uma categoria\n",
    "\n",
    "-   Temos dados rotulados\n",
    "\n",
    "-   Temos menos de 100K amostras\n",
    "\n",
    "-   ‚ú® Podemos escolher um Linear SVC\n",
    "\n",
    "-   Se isso n√£o funcionar, como temos dados num√©ricos\n",
    "\n",
    "    -   Podemos tentar um ‚ú® KNeighbors Classifier\n",
    "\n",
    "        -   Se isso n√£o funcionar, tentar ‚ú® SVC e ‚ú® Ensemble Classifiers\n",
    "\n",
    "Este √© um caminho muito √∫til para seguir. Agora, vamos direto ao assunto utilizando o framework de modelagem [tidymodels](https://www.tidymodels.org/): uma cole√ß√£o consistente e flex√≠vel de pacotes R desenvolvidos para incentivar boas pr√°ticas estat√≠sticas üòä.\n",
    "\n",
    "## 2. Dividir os dados e lidar com conjuntos de dados desequilibrados.\n",
    "\n",
    "Nas nossas li√ß√µes anteriores, aprendemos que havia um conjunto de ingredientes comuns entre as nossas cozinhas. Al√©m disso, havia uma distribui√ß√£o bastante desigual no n√∫mero de cozinhas.\n",
    "\n",
    "Vamos lidar com isso da seguinte forma:\n",
    "\n",
    "-   Eliminando os ingredientes mais comuns que criam confus√£o entre cozinhas distintas, usando `dplyr::select()`.\n",
    "\n",
    "-   Utilizando uma `recipe` que pr√©-processa os dados para prepar√°-los para a modelagem, aplicando um algoritmo de `over-sampling`.\n",
    "\n",
    "J√° vimos isso na li√ß√£o anterior, ent√£o deve ser tranquilo ü•≥!\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6tj_rN00hClA"
   },
   "source": [
    "# Load the core Tidyverse and Tidymodels packages\n",
    "library(tidyverse)\n",
    "library(tidymodels)\n",
    "\n",
    "# Load the original cuisines data\n",
    "df <- read_csv(file = \"https://raw.githubusercontent.com/microsoft/ML-For-Beginners/main/4-Classification/data/cuisines.csv\")\n",
    "\n",
    "# Drop id column, rice, garlic and ginger from our original data set\n",
    "df_select <- df %>% \n",
    "  select(-c(1, rice, garlic, ginger)) %>%\n",
    "  # Encode cuisine column as categorical\n",
    "  mutate(cuisine = factor(cuisine))\n",
    "\n",
    "\n",
    "# Create data split specification\n",
    "set.seed(2056)\n",
    "cuisines_split <- initial_split(data = df_select,\n",
    "                                strata = cuisine,\n",
    "                                prop = 0.7)\n",
    "\n",
    "# Extract the data in each split\n",
    "cuisines_train <- training(cuisines_split)\n",
    "cuisines_test <- testing(cuisines_split)\n",
    "\n",
    "# Display distribution of cuisines in the training set\n",
    "cuisines_train %>% \n",
    "  count(cuisine) %>% \n",
    "  arrange(desc(n))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFin5yw3hHb1"
   },
   "source": [
    "### Lidar com dados desequilibrados\n",
    "\n",
    "Dados desequilibrados frequentemente t√™m efeitos negativos no desempenho do modelo. Muitos modelos funcionam melhor quando o n√∫mero de observa√ß√µes √© igual e, por isso, tendem a ter dificuldades com dados desequilibrados.\n",
    "\n",
    "Existem principalmente duas formas de lidar com conjuntos de dados desequilibrados:\n",
    "\n",
    "-   adicionar observa√ß√µes √† classe minorit√°ria: `Over-sampling`, por exemplo, utilizando um algoritmo SMOTE que gera novos exemplos sint√©ticos da classe minorit√°ria com base nos vizinhos mais pr√≥ximos desses casos.\n",
    "\n",
    "-   remover observa√ß√µes da classe majorit√°ria: `Under-sampling`\n",
    "\n",
    "Na nossa li√ß√£o anterior, demonstr√°mos como lidar com conjuntos de dados desequilibrados utilizando uma `recipe`. Uma recipe pode ser vista como um plano que descreve quais passos devem ser aplicados a um conjunto de dados para prepar√°-lo para an√°lise. No nosso caso, queremos ter uma distribui√ß√£o igual no n√∫mero de nossas cozinhas para o nosso `training set`. Vamos come√ßar!\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cRzTnHolhLWd"
   },
   "source": [
    "# Load themis package for dealing with imbalanced data\n",
    "library(themis)\n",
    "\n",
    "# Create a recipe for preprocessing training data\n",
    "cuisines_recipe <- recipe(cuisine ~ ., data = cuisines_train) %>%\n",
    "  step_smote(cuisine) \n",
    "\n",
    "# Print recipe\n",
    "cuisines_recipe"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KxOQ2ORhhO81"
   },
   "source": [
    "Agora estamos prontos para treinar modelos üë©‚Äçüíªüë®‚Äçüíª!\n",
    "\n",
    "## 3. Para al√©m dos modelos de regress√£o multinomial\n",
    "\n",
    "Na nossa li√ß√£o anterior, analis√°mos os modelos de regress√£o multinomial. Vamos explorar alguns modelos mais flex√≠veis para classifica√ß√£o.\n",
    "\n",
    "### M√°quinas de Vetores de Suporte\n",
    "\n",
    "No contexto de classifica√ß√£o, `M√°quinas de Vetores de Suporte` s√£o uma t√©cnica de aprendizagem autom√°tica que tenta encontrar um *hiperplano* que \"melhor\" separa as classes. Vamos observar um exemplo simples:\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/svm.png\"\n",
    "   width=\"300\"/>\n",
    "   <figcaption>https://commons.wikimedia.org/w/index.php?curid=22877598</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4Wsd0vZhXYu"
   },
   "source": [
    "H1~ n√£o separa as classes. H2~ separa, mas apenas com uma margem pequena. H3~ separa-as com a margem m√°xima.\n",
    "\n",
    "#### Classificador Linear de Vetores de Suporte\n",
    "\n",
    "O clustering de Vetores de Suporte (SVC) √© uma t√©cnica derivada da fam√≠lia de m√°quinas de Vetores de Suporte (SVM) em Aprendizagem Autom√°tica. No SVC, o hiperplano √© escolhido para separar corretamente `a maioria` das observa√ß√µes de treino, mas `pode classificar incorretamente` algumas observa√ß√µes. Ao permitir que alguns pontos fiquem do lado errado, o SVM torna-se mais robusto a outliers, proporcionando assim uma melhor generaliza√ß√£o para novos dados. O par√¢metro que regula esta viola√ß√£o √© chamado de `cost`, que tem um valor padr√£o de 1 (consulte `help(\"svm_poly\")`).\n",
    "\n",
    "Vamos criar um SVC linear definindo `degree = 1` num modelo SVM polinomial.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vJpp6nuChlBz"
   },
   "source": [
    "# Make a linear SVC specification\n",
    "svc_linear_spec <- svm_poly(degree = 1) %>% \n",
    "  set_engine(\"kernlab\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle specification and recipe into a worklow\n",
    "svc_linear_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(svc_linear_spec)\n",
    "\n",
    "# Print out workflow\n",
    "svc_linear_wf"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDs8cWNkhoqu"
   },
   "source": [
    "Agora que captur√°mos os passos de pr√©-processamento e a especifica√ß√£o do modelo num *workflow*, podemos avan√ßar e treinar o SVC linear, avaliando os resultados ao mesmo tempo. Para m√©tricas de desempenho, vamos criar um conjunto de m√©tricas que avalie: `accuracy`, `sensitivity`, `Positive Predicted Value` e `F Measure`.\n",
    "\n",
    "> `augment()` ir√° adicionar coluna(s) com as previs√µes aos dados fornecidos.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "81wiqcwuhrnq"
   },
   "source": [
    "# Train a linear SVC model\n",
    "svc_linear_fit <- svc_linear_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "# Create a metric set\n",
    "eval_metrics <- metric_set(ppv, sens, accuracy, f_meas)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "svc_linear_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0UFQvHf-huo3"
   },
   "source": [
    "#### M√°quina de Vetores de Suporte\n",
    "\n",
    "A m√°quina de vetores de suporte (SVM) √© uma extens√£o do classificador de vetores de suporte para acomodar uma fronteira n√£o linear entre as classes. Essencialmente, as SVMs utilizam o *truque do kernel* para ampliar o espa√ßo de caracter√≠sticas e assim se adaptar a rela√ß√µes n√£o lineares entre as classes. Uma fun√ß√£o kernel popular e extremamente flex√≠vel usada pelas SVMs √© a *fun√ß√£o de base radial.* Vamos ver como ela se comporta com os nossos dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-KX4S8mzhzmp"
   },
   "source": [
    "set.seed(2056)\n",
    "\n",
    "# Make an RBF SVM specification\n",
    "svm_rbf_spec <- svm_rbf() %>% \n",
    "  set_engine(\"kernlab\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle specification and recipe into a worklow\n",
    "svm_rbf_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(svm_rbf_spec)\n",
    "\n",
    "\n",
    "# Train an RBF model\n",
    "svm_rbf_fit <- svm_rbf_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "svm_rbf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QBFSa7WSh4HQ"
   },
   "source": [
    "Muito melhor ü§©!\n",
    "\n",
    "> ‚úÖ Por favor veja:\n",
    ">\n",
    "> -   [*Support Vector Machines*](https://bradleyboehmke.github.io/HOML/svm.html), Hands-on Machine Learning with R\n",
    ">\n",
    "> -   [*Support Vector Machines*](https://www.statlearning.com/), An Introduction to Statistical Learning with Applications in R\n",
    ">\n",
    "> para leitura adicional.\n",
    "\n",
    "### Classificadores de Vizinhos Mais Pr√≥ximos\n",
    "\n",
    "O algoritmo *K*-nearest neighbor (KNN) prev√™ cada observa√ß√£o com base na sua *semelhan√ßa* com outras observa√ß√µes.\n",
    "\n",
    "Vamos ajustar um ao nosso conjunto de dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "k4BxxBcdh9Ka"
   },
   "source": [
    "# Make a KNN specification\n",
    "knn_spec <- nearest_neighbor() %>% \n",
    "  set_engine(\"kknn\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "knn_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(knn_spec)\n",
    "\n",
    "# Train a boosted tree model\n",
    "knn_wf_fit <- knn_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "knn_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HaegQseriAcj"
   },
   "source": [
    "Parece que este modelo n√£o est√° a ter um desempenho muito bom. Provavelmente, alterar os argumentos do modelo (ver `help(\"nearest_neighbor\")`) ir√° melhorar o desempenho do modelo. Certifique-se de experimentar.\n",
    "\n",
    "> ‚úÖ Por favor veja:\n",
    ">\n",
    "> -   [Hands-on Machine Learning with R](https://bradleyboehmke.github.io/HOML/)\n",
    ">\n",
    "> -   [An Introduction to Statistical Learning with Applications in R](https://www.statlearning.com/)\n",
    ">\n",
    "> para aprender mais sobre classificadores *K*-Nearest Neighbors.\n",
    "\n",
    "### Classificadores em ensemble\n",
    "\n",
    "Os algoritmos de ensemble funcionam combinando m√∫ltiplos estimadores base para produzir um modelo otimizado, seja atrav√©s de:\n",
    "\n",
    "`bagging`: aplica√ß√£o de uma *fun√ß√£o de m√©dia* a uma cole√ß√£o de modelos base\n",
    "\n",
    "`boosting`: constru√ß√£o de uma sequ√™ncia de modelos que se complementam para melhorar o desempenho preditivo.\n",
    "\n",
    "Vamos come√ßar por experimentar um modelo Random Forest, que constr√≥i uma grande cole√ß√£o de √°rvores de decis√£o e depois aplica uma fun√ß√£o de m√©dia para obter um modelo geral melhor.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "49DPoVs6iK1M"
   },
   "source": [
    "# Make a random forest specification\n",
    "rf_spec <- rand_forest() %>% \n",
    "  set_engine(\"ranger\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "rf_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(rf_spec)\n",
    "\n",
    "# Train a random forest model\n",
    "rf_wf_fit <- rf_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "rf_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGVYwC_aiUWc"
   },
   "source": [
    "Bom trabalho üëè!\n",
    "\n",
    "Vamos tamb√©m experimentar com um modelo de √Årvore Refor√ßada.\n",
    "\n",
    "√Årvore Refor√ßada define um m√©todo de conjunto que cria uma s√©rie de √°rvores de decis√£o sequenciais, onde cada √°rvore depende dos resultados das √°rvores anteriores, numa tentativa de reduzir o erro de forma incremental. Este m√©todo foca-se nos pesos dos itens classificados incorretamente e ajusta o modelo do pr√≥ximo classificador para corrigir.\n",
    "\n",
    "Existem diferentes formas de ajustar este modelo (veja `help(\"boost_tree\")`). Neste exemplo, vamos ajustar √Årvores Refor√ßadas atrav√©s do motor `xgboost`.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Py1YWo-micWs"
   },
   "source": [
    "# Make a boosted tree specification\n",
    "boost_spec <- boost_tree(trees = 200) %>% \n",
    "  set_engine(\"xgboost\") %>% \n",
    "  set_mode(\"classification\")\n",
    "\n",
    "# Bundle recipe and model specification into a workflow\n",
    "boost_wf <- workflow() %>% \n",
    "  add_recipe(cuisines_recipe) %>% \n",
    "  add_model(boost_spec)\n",
    "\n",
    "# Train a boosted tree model\n",
    "boost_wf_fit <- boost_wf %>% \n",
    "  fit(data = cuisines_train)\n",
    "\n",
    "\n",
    "# Make predictions and Evaluate model performance\n",
    "boost_wf_fit %>% \n",
    "  augment(new_data = cuisines_test) %>% \n",
    "  eval_metrics(truth = cuisine, estimate = .pred_class)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNQnbuejigZM"
   },
   "source": [
    "> ‚úÖ Por favor veja:\n",
    ">\n",
    "> -   [Machine Learning for Social Scientists](https://cimentadaj.github.io/ml_socsci/tree-based-methods.html#random-forests)\n",
    ">\n",
    "> -   [Hands-on Machine Learning with R](https://bradleyboehmke.github.io/HOML/)\n",
    ">\n",
    "> -   [An Introduction to Statistical Learning with Applications in R](https://www.statlearning.com/)\n",
    ">\n",
    "> -   <https://algotech.netlify.app/blog/xgboost/> - Explora o modelo AdaBoost, que √© uma boa alternativa ao xgboost.\n",
    ">\n",
    "> para aprender mais sobre classificadores Ensemble.\n",
    "\n",
    "## 4. Extra - comparando m√∫ltiplos modelos\n",
    "\n",
    "Test√°mos v√°rios modelos neste laborat√≥rio üôå. Pode tornar-se cansativo ou trabalhoso criar muitos fluxos de trabalho a partir de diferentes conjuntos de pr√©-processadores e/ou especifica√ß√µes de modelos e depois calcular as m√©tricas de desempenho uma a uma.\n",
    "\n",
    "Vamos ver se conseguimos resolver isso criando uma fun√ß√£o que ajusta uma lista de fluxos de trabalho no conjunto de treino e depois retorna as m√©tricas de desempenho com base no conjunto de teste. Vamos usar `map()` e `map_dfr()` do pacote [purrr](https://purrr.tidyverse.org/) para aplicar fun√ß√µes a cada elemento de uma lista.\n",
    "\n",
    "> As fun√ß√µes [`map()`](https://purrr.tidyverse.org/reference/map.html) permitem substituir muitos ciclos \"for\" por c√≥digo que √© mais conciso e mais f√°cil de ler. O melhor lugar para aprender sobre as fun√ß√µes [`map()`](https://purrr.tidyverse.org/reference/map.html) √© o [cap√≠tulo de itera√ß√£o](http://r4ds.had.co.nz/iteration.html) em R for Data Science.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Qzb7LyZnimd2"
   },
   "source": [
    "set.seed(2056)\n",
    "\n",
    "# Create a metric set\n",
    "eval_metrics <- metric_set(ppv, sens, accuracy, f_meas)\n",
    "\n",
    "# Define a function that returns performance metrics\n",
    "compare_models <- function(workflow_list, train_set, test_set){\n",
    "  \n",
    "  suppressWarnings(\n",
    "    # Fit each model to the train_set\n",
    "    map(workflow_list, fit, data = train_set) %>% \n",
    "    # Make predictions on the test set\n",
    "      map_dfr(augment, new_data = test_set, .id = \"model\") %>%\n",
    "    # Select desired columns\n",
    "      select(model, cuisine, .pred_class) %>% \n",
    "    # Evaluate model performance\n",
    "      group_by(model) %>% \n",
    "      eval_metrics(truth = cuisine, estimate = .pred_class) %>% \n",
    "      ungroup()\n",
    "  )\n",
    "  \n",
    "} # End of function"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fwa712sNisDA"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3i4VJOi2iu-a"
   },
   "source": [
    "# Make a list of workflows\n",
    "workflow_list <- list(\n",
    "  \"svc\" = svc_linear_wf,\n",
    "  \"svm\" = svm_rbf_wf,\n",
    "  \"knn\" = knn_wf,\n",
    "  \"random_forest\" = rf_wf,\n",
    "  \"xgboost\" = boost_wf)\n",
    "\n",
    "# Call the function\n",
    "set.seed(2056)\n",
    "perf_metrics <- compare_models(workflow_list = workflow_list, train_set = cuisines_train, test_set = cuisines_test)\n",
    "\n",
    "# Print out performance metrics\n",
    "perf_metrics %>% \n",
    "  group_by(.metric) %>% \n",
    "  arrange(desc(.estimate)) %>% \n",
    "  slice_head(n=7)\n",
    "\n",
    "# Compare accuracy\n",
    "perf_metrics %>% \n",
    "  filter(.metric == \"accuracy\") %>% \n",
    "  arrange(desc(.estimate))\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuWK_lEli4nW"
   },
   "source": [
    "O pacote [**workflowset**](https://workflowsets.tidymodels.org/) permite aos utilizadores criar e ajustar facilmente um grande n√∫mero de modelos, mas foi principalmente concebido para funcionar com t√©cnicas de reamostragem, como a `valida√ß√£o cruzada`, uma abordagem que ainda iremos abordar.\n",
    "\n",
    "## **üöÄDesafio**\n",
    "\n",
    "Cada uma destas t√©cnicas tem um grande n√∫mero de par√¢metros que podem ser ajustados, como por exemplo `cost` em SVMs, `neighbors` em KNN, `mtry` (Preditores Selecionados Aleatoriamente) em Random Forest.\n",
    "\n",
    "Pesquise os par√¢metros padr√£o de cada t√©cnica e reflita sobre o que ajustar esses par√¢metros significaria para a qualidade do modelo.\n",
    "\n",
    "Para saber mais sobre um modelo espec√≠fico e os seus par√¢metros, utilize: `help(\"model\")`, por exemplo, `help(\"rand_forest\")`.\n",
    "\n",
    "> Na pr√°tica, geralmente *estimamos* os *melhores valores* para estes par√¢metros treinando v√°rios modelos num `conjunto de dados simulado` e medindo o desempenho de todos esses modelos. Este processo √© chamado de **otimiza√ß√£o**.\n",
    "\n",
    "### [**Question√°rio p√≥s-aula**](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/24/)\n",
    "\n",
    "### **Revis√£o & Estudo Individual**\n",
    "\n",
    "H√° muito jarg√£o nestas li√ß√µes, por isso reserve um momento para rever [esta lista](https://docs.microsoft.com/dotnet/machine-learning/resources/glossary?WT.mc_id=academic-77952-leestott) de terminologia √∫til!\n",
    "\n",
    "#### AGRADECIMENTOS A:\n",
    "\n",
    "[`Allison Horst`](https://twitter.com/allison_horst/) por criar as ilustra√ß√µes incr√≠veis que tornam o R mais acolhedor e envolvente. Encontre mais ilustra√ß√µes na sua [galeria](https://www.google.com/url?q=https://github.com/allisonhorst/stats-illustrations&sa=D&source=editors&ust=1626380772530000&usg=AOvVaw3zcfyCizFQZpkSLzxiiQEM).\n",
    "\n",
    "[Cassie Breviu](https://www.twitter.com/cassieview) e [Jen Looper](https://www.twitter.com/jenlooper) por criarem a vers√£o original deste m√≥dulo em Python ‚ô•Ô∏è\n",
    "\n",
    "Boas aprendizagens,\n",
    "\n",
    "[Eric](https://twitter.com/ericntay), Embaixador Estudante Gold da Microsoft Learn.\n",
    "\n",
    "<p >\n",
    "   <img src=\"../../images/r_learners_sm.jpeg\"\n",
    "   width=\"569\"/>\n",
    "   <figcaption>Arte por @allison_horst</figcaption>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Aviso Legal**:  \nEste documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, √© importante ter em conta que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorit√°ria. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes da utiliza√ß√£o desta tradu√ß√£o.\n"
   ]
  }
 ]
}