# Tarefas e t√©cnicas comuns de processamento de linguagem natural

Para a maioria das tarefas de *processamento de linguagem natural*, o texto a ser processado deve ser dividido, examinado e os resultados armazenados ou cruzados com regras e conjuntos de dados. Essas tarefas permitem que o programador derive o _significado_ ou _inten√ß√£o_ ou apenas a _frequ√™ncia_ de termos e palavras em um texto.

## [Quiz pr√©-aula](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/33/)

Vamos descobrir t√©cnicas comuns usadas no processamento de texto. Combinadas com aprendizado de m√°quina, essas t√©cnicas ajudam voc√™ a analisar grandes quantidades de texto de forma eficiente. Antes de aplicar ML a essas tarefas, no entanto, vamos entender os problemas enfrentados por um especialista em NLP.

## Tarefas comuns de NLP

Existem diferentes maneiras de analisar um texto com o qual voc√™ est√° trabalhando. Existem tarefas que voc√™ pode realizar e, por meio dessas tarefas, voc√™ pode avaliar a compreens√£o do texto e tirar conclus√µes. Normalmente, voc√™ realiza essas tarefas em sequ√™ncia.

### Tokeniza√ß√£o

Provavelmente, a primeira coisa que a maioria dos algoritmos de NLP precisa fazer √© dividir o texto em tokens ou palavras. Embora isso pare√ßa simples, ter que considerar a pontua√ß√£o e os delimitadores de palavras e frases de diferentes idiomas pode tornar a tarefa complicada. Voc√™ pode precisar usar v√°rios m√©todos para determinar as demarca√ß√µes.

![tokeniza√ß√£o](../../../../translated_images/tokenization.1641a160c66cd2d93d4524e8114e93158a9ce0eba3ecf117bae318e8a6ad3487.pt.png)
> Tokenizando uma frase de **Orgulho e Preconceito**. Infogr√°fico por [Jen Looper](https://twitter.com/jenlooper)

### Embeddings

[Word embeddings](https://wikipedia.org/wiki/Word_embedding) s√£o uma maneira de converter seus dados textuais em forma num√©rica. Os embeddings s√£o feitos de maneira que palavras com significados semelhantes ou palavras usadas juntas se agrupem.

![embeddings de palavras](../../../../translated_images/embedding.2cf8953c4b3101d188c2f61a5de5b6f53caaa5ad4ed99236d42bc3b6bd6a1fe2.pt.png)
> "Eu tenho o maior respeito pelos seus nervos, eles s√£o meus velhos amigos." - Embeddings de palavras para uma frase em **Orgulho e Preconceito**. Infogr√°fico por [Jen Looper](https://twitter.com/jenlooper)

‚úÖ Experimente [esta ferramenta interessante](https://projector.tensorflow.org/) para experimentar com embeddings de palavras. Clicar em uma palavra mostra grupos de palavras semelhantes: 'brinquedo' se agrupa com 'disney', 'lego', 'playstation' e 'console'.

### An√°lise Sint√°tica e Marca√ß√£o de Partes do Discurso

Cada palavra que foi tokenizada pode ser marcada como uma parte do discurso - um substantivo, verbo ou adjetivo. A frase `the quick red fox jumped over the lazy brown dog` pode ser marcada como fox = substantivo, jumped = verbo.

![an√°lise sint√°tica](../../../../translated_images/parse.d0c5bbe1106eae8fe7d60a183cd1736c8b6cec907f38000366535f84f3036101.pt.png)

> Analisando uma frase de **Orgulho e Preconceito**. Infogr√°fico por [Jen Looper](https://twitter.com/jenlooper)

A an√°lise sint√°tica √© reconhecer quais palavras est√£o relacionadas entre si em uma frase - por exemplo, `the quick red fox jumped` √© uma sequ√™ncia de adjetivo-substantivo-verbo que √© separada da sequ√™ncia `lazy brown dog`.

### Frequ√™ncias de Palavras e Frases

Um procedimento √∫til ao analisar um grande corpo de texto √© construir um dicion√°rio de cada palavra ou frase de interesse e com que frequ√™ncia ela aparece. A frase `the quick red fox jumped over the lazy brown dog` tem uma frequ√™ncia de palavra de 2 para the.

Vamos olhar um texto de exemplo onde contamos a frequ√™ncia das palavras. O poema "Os Vencedores" de Rudyard Kipling cont√©m o seguinte verso:

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

Como as frequ√™ncias de frases podem ser insens√≠veis ou sens√≠veis a mai√∫sculas conforme necess√°rio, a frase `a friend` has a frequency of 2 and `the` has a frequency of 6, and `travels` √© 2.

### N-grams

Um texto pode ser dividido em sequ√™ncias de palavras de um comprimento definido, uma √∫nica palavra (unigrama), duas palavras (bigrama), tr√™s palavras (trigrama) ou qualquer n√∫mero de palavras (n-grams).

Por exemplo, `the quick red fox jumped over the lazy brown dog` com uma pontua√ß√£o de n-gram de 2 produz os seguintes n-grams:

1. the quick 
2. quick red 
3. red fox
4. fox jumped 
5. jumped over 
6. over the 
7. the lazy 
8. lazy brown 
9. brown dog

Pode ser mais f√°cil visualizar isso como uma caixa deslizante sobre a frase. Aqui est√° para n-grams de 3 palavras, o n-gram est√° em negrito em cada frase:

1.   <u>**the quick red**</u> fox jumped over the lazy brown dog
2.   the **<u>quick red fox</u>** jumped over the lazy brown dog
3.   the quick **<u>red fox jumped</u>** over the lazy brown dog
4.   the quick red **<u>fox jumped over</u>** the lazy brown dog
5.   the quick red fox **<u>jumped over the</u>** lazy brown dog
6.   the quick red fox jumped **<u>over the lazy</u>** brown dog
7.   the quick red fox jumped over <u>**the lazy brown**</u> dog
8.   the quick red fox jumped over the **<u>lazy brown dog</u>**

![janela deslizante de n-grams](../../../../6-NLP/2-Tasks/images/n-grams.gif)

> Valor de n-gram de 3: Infogr√°fico por [Jen Looper](https://twitter.com/jenlooper)

### Extra√ß√£o de Frases Nominais

Na maioria das frases, h√° um substantivo que √© o sujeito ou objeto da frase. Em ingl√™s, √© frequentemente identific√°vel por ter 'a' ou 'an' ou 'the' precedendo-o. Identificar o sujeito ou objeto de uma frase "extraindo a frase nominal" √© uma tarefa comum em NLP ao tentar entender o significado de uma frase.

‚úÖ Na frase "Eu n√£o consigo fixar na hora, ou no local, ou na apar√™ncia ou nas palavras, que estabeleceram a funda√ß√£o. Faz muito tempo. Eu estava no meio antes de saber que havia come√ßado.", voc√™ consegue identificar as frases nominais?

Na frase `the quick red fox jumped over the lazy brown dog` existem 2 frases nominais: **quick red fox** e **lazy brown dog**.

### An√°lise de Sentimento

Uma frase ou texto pode ser analisado quanto ao sentimento, ou qu√£o *positivo* ou *negativo* ele √©. O sentimento √© medido em *polaridade* e *objetividade/subjetividade*. A polaridade √© medida de -1.0 a 1.0 (negativo a positivo) e de 0.0 a 1.0 (mais objetivo a mais subjetivo).

‚úÖ Mais tarde, voc√™ aprender√° que existem diferentes maneiras de determinar o sentimento usando aprendizado de m√°quina, mas uma maneira √© ter uma lista de palavras e frases que s√£o categorizadas como positivas ou negativas por um especialista humano e aplicar esse modelo ao texto para calcular uma pontua√ß√£o de polaridade. Voc√™ consegue ver como isso funcionaria em algumas circunst√¢ncias e menos bem em outras?

### Infla√ß√£o

A inflex√£o permite que voc√™ pegue uma palavra e obtenha o singular ou plural da palavra.

### Lematiza√ß√£o

Um *lema* √© a raiz ou palavra principal para um conjunto de palavras, por exemplo, *flew*, *flies*, *flying* t√™m um lema do verbo *fly*.

Existem tamb√©m bancos de dados √∫teis dispon√≠veis para o pesquisador de NLP, notavelmente:

### WordNet

[WordNet](https://wordnet.princeton.edu/) √© um banco de dados de palavras, sin√¥nimos, ant√¥nimos e muitos outros detalhes para cada palavra em muitos idiomas diferentes. √â incrivelmente √∫til ao tentar construir tradu√ß√µes, verificadores de ortografia ou ferramentas de linguagem de qualquer tipo.

## Bibliotecas de NLP

Felizmente, voc√™ n√£o precisa construir todas essas t√©cnicas sozinho, pois existem excelentes bibliotecas Python dispon√≠veis que tornam isso muito mais acess√≠vel para desenvolvedores que n√£o s√£o especializados em processamento de linguagem natural ou aprendizado de m√°quina. As pr√≥ximas li√ß√µes incluem mais exemplos disso, mas aqui voc√™ aprender√° alguns exemplos √∫teis para ajud√°-lo na pr√≥xima tarefa.

### Exerc√≠cio - usando `TextBlob` library

Let's use a library called TextBlob as it contains helpful APIs for tackling these types of tasks. TextBlob "stands on the giant shoulders of [NLTK](https://nltk.org) and [pattern](https://github.com/clips/pattern), and plays nicely with both." It has a considerable amount of ML embedded in its API.

> Note: A useful [Quick Start](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart) guide is available for TextBlob that is recommended for experienced Python developers 

When attempting to identify *noun phrases*, TextBlob offers several options of extractors to find noun phrases. 

1. Take a look at `ConllExtractor`.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > O que est√° acontecendo aqui? [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) √© "Um extrator de frases nominais que usa an√°lise de segmentos treinada com o corpus de treinamento ConLL-2000." ConLL-2000 refere-se √† Confer√™ncia de 2000 sobre Aprendizado de Linguagem Natural Computacional. A cada ano, a confer√™ncia hospedava um workshop para enfrentar um problema espinhoso de NLP, e em 2000 foi a fragmenta√ß√£o nominal. Um modelo foi treinado no Wall Street Journal, com "se√ß√µes 15-18 como dados de treinamento (211727 tokens) e se√ß√£o 20 como dados de teste (47377 tokens)". Voc√™ pode ver os procedimentos utilizados [aqui](https://www.clips.uantwerpen.be/conll2000/chunking/) e os [resultados](https://ifarm.nl/erikt/research/np-chunking.html).

### Desafio - melhorando seu bot com NLP

Na li√ß√£o anterior, voc√™ construiu um bot de perguntas e respostas muito simples. Agora, voc√™ far√° com que Marvin seja um pouco mais simp√°tico analisando sua entrada para sentimento e imprimindo uma resposta que corresponda ao sentimento. Voc√™ tamb√©m precisar√° identificar uma `noun_phrase` e perguntar sobre isso.

Seus passos ao construir um bot de conversa melhor:

1. Imprima instru√ß√µes orientando o usu√°rio sobre como interagir com o bot
2. Inicie o loop 
   1. Aceite a entrada do usu√°rio
   2. Se o usu√°rio pediu para sair, saia
   3. Processem a entrada do usu√°rio e determine a resposta de sentimento apropriada
   4. Se uma frase nominal for detectada no sentimento, pluralize-a e pergunte mais sobre esse t√≥pico
   5. Imprima a resposta
3. Volte ao passo 2

Aqui est√° o trecho de c√≥digo para determinar o sentimento usando TextBlob. Observe que h√° apenas quatro *gradientes* de resposta de sentimento (voc√™ pode ter mais se quiser):

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

Aqui est√° uma sa√≠da de exemplo para gui√°-lo (a entrada do usu√°rio est√° nas linhas que come√ßam com >):

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

Uma poss√≠vel solu√ß√£o para a tarefa est√° [aqui](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/2-Tasks/solution/bot.py)

‚úÖ Verifica√ß√£o de Conhecimento

1. Voc√™ acha que as respostas simp√°ticas "enganariam" algu√©m a pensar que o bot realmente os entendeu?
2. A identifica√ß√£o da frase nominal torna o bot mais "cr√≠vel"?
3. Por que extrair uma "frase nominal" de uma frase √© algo √∫til a se fazer?

---

Implemente o bot na verifica√ß√£o de conhecimento anterior e teste-o em um amigo. Ele consegue engan√°-los? Voc√™ consegue tornar seu bot mais "cr√≠vel"?

## üöÄDesafio

Pegue uma tarefa na verifica√ß√£o de conhecimento anterior e tente implement√°-la. Teste o bot em um amigo. Ele consegue engan√°-los? Voc√™ consegue tornar seu bot mais "cr√≠vel"?

## [Quiz p√≥s-aula](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/34/)

## Revis√£o e Autoestudo

Nas pr√≥ximas li√ß√µes, voc√™ aprender√° mais sobre an√°lise de sentimento. Pesquise essa t√©cnica interessante em artigos como estes no [KDNuggets](https://www.kdnuggets.com/tag/nlp)

## Tarefa 

[Fa√ßa um bot responder](assignment.md)

**Isen√ß√£o de responsabilidade**:  
Este documento foi traduzido utilizando servi√ßos de tradu√ß√£o autom√°tica baseados em IA. Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional por um humano. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes erradas decorrentes do uso desta tradu√ß√£o.