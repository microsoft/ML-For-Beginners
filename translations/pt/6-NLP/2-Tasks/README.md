<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6534e145d52a3890590d27be75386e5d",
  "translation_date": "2025-09-03T18:47:40+00:00",
  "source_file": "6-NLP/2-Tasks/README.md",
  "language_code": "pt"
}
-->
# Tarefas e t√©cnicas comuns de processamento de linguagem natural

Para a maioria das tarefas de *processamento de linguagem natural*, o texto a ser processado deve ser dividido, examinado e os resultados armazenados ou cruzados com regras e conjuntos de dados. Essas tarefas permitem ao programador derivar o _significado_, a _inten√ß√£o_ ou apenas a _frequ√™ncia_ de termos e palavras em um texto.

## [Question√°rio pr√©-aula](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/33/)

Vamos explorar t√©cnicas comuns usadas no processamento de texto. Combinadas com aprendizado de m√°quina, essas t√©cnicas ajudam a analisar grandes volumes de texto de forma eficiente. Antes de aplicar ML a essas tarefas, no entanto, vamos entender os problemas enfrentados por um especialista em NLP.

## Tarefas comuns em NLP

Existem diferentes maneiras de analisar um texto com o qual voc√™ est√° trabalhando. H√° tarefas que voc√™ pode realizar e, por meio delas, √© poss√≠vel compreender o texto e tirar conclus√µes. Normalmente, essas tarefas s√£o realizadas em sequ√™ncia.

### Tokeniza√ß√£o

Provavelmente, a primeira coisa que a maioria dos algoritmos de NLP precisa fazer √© dividir o texto em tokens ou palavras. Embora isso pare√ßa simples, lidar com pontua√ß√£o e delimitadores de palavras e frases em diferentes idiomas pode tornar o processo complicado. Pode ser necess√°rio usar v√°rios m√©todos para determinar as demarca√ß√µes.

![tokeniza√ß√£o](../../../../translated_images/tokenization.1641a160c66cd2d93d4524e8114e93158a9ce0eba3ecf117bae318e8a6ad3487.pt.png)
> Tokenizando uma frase de **Orgulho e Preconceito**. Infogr√°fico por [Jen Looper](https://twitter.com/jenlooper)

### Embeddings

[Word embeddings](https://wikipedia.org/wiki/Word_embedding) s√£o uma forma de converter seus dados textuais em valores num√©ricos. Os embeddings s√£o feitos de maneira que palavras com significados semelhantes ou usadas juntas fiquem agrupadas.

![word embeddings](../../../../translated_images/embedding.2cf8953c4b3101d188c2f61a5de5b6f53caaa5ad4ed99236d42bc3b6bd6a1fe2.pt.png)
> "Tenho o maior respeito pelos seus nervos, eles s√£o meus velhos amigos." - Word embeddings para uma frase de **Orgulho e Preconceito**. Infogr√°fico por [Jen Looper](https://twitter.com/jenlooper)

‚úÖ Experimente [esta ferramenta interessante](https://projector.tensorflow.org/) para explorar word embeddings. Ao clicar em uma palavra, aparecem clusters de palavras semelhantes: 'toy' agrupa-se com 'disney', 'lego', 'playstation' e 'console'.

### Parsing e Marca√ß√£o de Partes do Discurso

Cada palavra que foi tokenizada pode ser marcada como uma parte do discurso - um substantivo, verbo ou adjetivo. A frase `the quick red fox jumped over the lazy brown dog` pode ser marcada como POS, por exemplo, fox = substantivo, jumped = verbo.

![parsing](../../../../translated_images/parse.d0c5bbe1106eae8fe7d60a183cd1736c8b6cec907f38000366535f84f3036101.pt.png)

> Parsing de uma frase de **Orgulho e Preconceito**. Infogr√°fico por [Jen Looper](https://twitter.com/jenlooper)

Parsing √© o reconhecimento de quais palavras est√£o relacionadas umas √†s outras em uma frase - por exemplo, `the quick red fox jumped` √© uma sequ√™ncia de adjetivo-substantivo-verbo que √© separada da sequ√™ncia `lazy brown dog`.

### Frequ√™ncia de Palavras e Frases

Um procedimento √∫til ao analisar um grande corpo de texto √© construir um dicion√°rio de cada palavra ou frase de interesse e quantas vezes ela aparece. A frase `the quick red fox jumped over the lazy brown dog` tem uma frequ√™ncia de palavras de 2 para "the".

Vamos analisar um texto de exemplo onde contamos a frequ√™ncia das palavras. O poema "The Winners" de Rudyard Kipling cont√©m o seguinte verso:

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

Como as frequ√™ncias de frases podem ser sens√≠veis ou n√£o a mai√∫sculas, a frase `a friend` tem uma frequ√™ncia de 2, `the` tem uma frequ√™ncia de 6 e `travels` tem uma frequ√™ncia de 2.

### N-grams

Um texto pode ser dividido em sequ√™ncias de palavras de um comprimento definido: uma √∫nica palavra (unigrama), duas palavras (bigramas), tr√™s palavras (trigramas) ou qualquer n√∫mero de palavras (n-grams).

Por exemplo, `the quick red fox jumped over the lazy brown dog` com um valor de n-gram de 2 produz os seguintes n-grams:

1. the quick  
2. quick red  
3. red fox  
4. fox jumped  
5. jumped over  
6. over the  
7. the lazy  
8. lazy brown  
9. brown dog  

Pode ser mais f√°cil visualizar isso como uma janela deslizante sobre a frase. Aqui est√° para n-grams de 3 palavras, o n-gram est√° em negrito em cada frase:

1.   <u>**the quick red**</u> fox jumped over the lazy brown dog  
2.   the **<u>quick red fox</u>** jumped over the lazy brown dog  
3.   the quick **<u>red fox jumped</u>** over the lazy brown dog  
4.   the quick red **<u>fox jumped over</u>** the lazy brown dog  
5.   the quick red fox **<u>jumped over the</u>** lazy brown dog  
6.   the quick red fox jumped **<u>over the lazy</u>** brown dog  
7.   the quick red fox jumped over <u>**the lazy brown**</u> dog  
8.   the quick red fox jumped over the **<u>lazy brown dog</u>**  

![janela deslizante de n-grams](../../../../6-NLP/2-Tasks/images/n-grams.gif)

> Valor de n-gram de 3: Infogr√°fico por [Jen Looper](https://twitter.com/jenlooper)

### Extra√ß√£o de Frases Nominais

Na maioria das frases, h√° um substantivo que √© o sujeito ou objeto da frase. Em ingl√™s, ele geralmente pode ser identificado por ter 'a', 'an' ou 'the' antes dele. Identificar o sujeito ou objeto de uma frase por meio da 'extra√ß√£o da frase nominal' √© uma tarefa comum em NLP ao tentar entender o significado de uma frase.

‚úÖ Na frase "I cannot fix on the hour, or the spot, or the look or the words, which laid the foundation. It is too long ago. I was in the middle before I knew that I had begun.", consegue identificar as frases nominais?

Na frase `the quick red fox jumped over the lazy brown dog` h√° 2 frases nominais: **quick red fox** e **lazy brown dog**.

### An√°lise de Sentimento

Uma frase ou texto pode ser analisado para determinar o sentimento, ou qu√£o *positivo* ou *negativo* ele √©. O sentimento √© medido em *polaridade* e *objetividade/subjetividade*. A polaridade √© medida de -1.0 a 1.0 (negativo a positivo) e de 0.0 a 1.0 (mais objetivo a mais subjetivo).

‚úÖ Mais tarde, voc√™ aprender√° que existem diferentes maneiras de determinar o sentimento usando aprendizado de m√°quina, mas uma delas √© ter uma lista de palavras e frases categorizadas como positivas ou negativas por um especialista humano e aplicar esse modelo ao texto para calcular um escore de polaridade. Consegue perceber como isso funcionaria em algumas circunst√¢ncias e menos em outras?

### Flex√£o

A flex√£o permite que voc√™ pegue uma palavra e obtenha sua forma singular ou plural.

### Lematiza√ß√£o

Um *lema* √© a raiz ou palavra principal de um conjunto de palavras, por exemplo, *flew*, *flies*, *flying* t√™m como lema o verbo *fly*.

Existem tamb√©m bancos de dados √∫teis dispon√≠veis para pesquisadores de NLP, como:

### WordNet

[WordNet](https://wordnet.princeton.edu/) √© um banco de dados de palavras, sin√¥nimos, ant√¥nimos e muitos outros detalhes para cada palavra em v√°rios idiomas. √â incrivelmente √∫til ao tentar construir tradu√ß√µes, verificadores ortogr√°ficos ou ferramentas de linguagem de qualquer tipo.

## Bibliotecas de NLP

Felizmente, voc√™ n√£o precisa construir todas essas t√©cnicas sozinho, pois existem excelentes bibliotecas Python dispon√≠veis que tornam o NLP muito mais acess√≠vel para desenvolvedores que n√£o s√£o especializados em processamento de linguagem natural ou aprendizado de m√°quina. As pr√≥ximas li√ß√µes incluem mais exemplos dessas bibliotecas, mas aqui voc√™ aprender√° alguns exemplos √∫teis para ajud√°-lo na pr√≥xima tarefa.

### Exerc√≠cio - usando a biblioteca `TextBlob`

Vamos usar uma biblioteca chamada TextBlob, que cont√©m APIs √∫teis para lidar com esses tipos de tarefas. TextBlob "se baseia nos ombros gigantes do [NLTK](https://nltk.org) e [pattern](https://github.com/clips/pattern), e funciona bem com ambos." Ela possui uma quantidade consider√°vel de ML embutida em sua API.

> Nota: Um [Guia de In√≠cio R√°pido](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart) √∫til est√° dispon√≠vel para TextBlob e √© recomendado para desenvolvedores Python experientes.

Ao tentar identificar *frases nominais*, TextBlob oferece v√°rias op√ß√µes de extratores para encontrar frases nominais.

1. Veja o `ConllExtractor`.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > O que est√° acontecendo aqui? [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) √© "Um extrator de frases nominais que usa chunk parsing treinado com o corpus de treinamento ConLL-2000." ConLL-2000 refere-se √† Confer√™ncia de Aprendizado Computacional de Linguagem Natural de 2000. Cada ano, a confer√™ncia hospedava um workshop para abordar um problema dif√≠cil de NLP, e em 2000 foi o chunking de frases nominais. Um modelo foi treinado no Wall Street Journal, com "se√ß√µes 15-18 como dados de treinamento (211727 tokens) e se√ß√£o 20 como dados de teste (47377 tokens)". Voc√™ pode conferir os procedimentos usados [aqui](https://www.clips.uantwerpen.be/conll2000/chunking/) e os [resultados](https://ifarm.nl/erikt/research/np-chunking.html).

### Desafio - melhorando seu bot com NLP

Na li√ß√£o anterior, voc√™ construiu um bot de perguntas e respostas muito simples. Agora, voc√™ tornar√° Marvin um pouco mais simp√°tico ao analisar sua entrada para determinar o sentimento e imprimir uma resposta que corresponda ao sentimento. Voc√™ tamb√©m precisar√° identificar uma `noun_phrase` e perguntar sobre ela.

Seus passos ao construir um bot de conversa√ß√£o melhor:

1. Imprimir instru√ß√µes orientando o usu√°rio sobre como interagir com o bot  
2. Iniciar o loop  
   1. Aceitar entrada do usu√°rio  
   2. Se o usu√°rio pedir para sair, ent√£o sair  
   3. Processar a entrada do usu√°rio e determinar uma resposta de sentimento apropriada  
   4. Se uma frase nominal for detectada no sentimento, pluraliz√°-la e pedir mais informa√ß√µes sobre esse t√≥pico  
   5. Imprimir resposta  
3. Voltar ao passo 2  

Aqui est√° o trecho de c√≥digo para determinar o sentimento usando TextBlob. Note que h√° apenas quatro *gradientes* de resposta de sentimento (voc√™ pode ter mais, se quiser):

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

Aqui est√° um exemplo de sa√≠da para orient√°-lo (entrada do usu√°rio est√° nas linhas come√ßando com >):

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

Uma poss√≠vel solu√ß√£o para a tarefa est√° [aqui](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/2-Tasks/solution/bot.py)

‚úÖ Verifica√ß√£o de Conhecimento

1. Voc√™ acha que as respostas simp√°ticas poderiam 'enganar' algu√©m a pensar que o bot realmente os entende?  
2. Identificar a frase nominal torna o bot mais 'cr√≠vel'?  
3. Por que extrair uma 'frase nominal' de uma frase seria algo √∫til?  

---

Implemente o bot na verifica√ß√£o de conhecimento anterior e teste-o com um amigo. Ele consegue engan√°-lo? Voc√™ consegue tornar seu bot mais 'cr√≠vel'?

## üöÄDesafio

Escolha uma tarefa na verifica√ß√£o de conhecimento anterior e tente implement√°-la. Teste o bot com um amigo. Ele consegue engan√°-lo? Voc√™ consegue tornar seu bot mais 'cr√≠vel'?

## [Question√°rio p√≥s-aula](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/34/)

## Revis√£o e Autoestudo

Nas pr√≥ximas li√ß√µes, voc√™ aprender√° mais sobre an√°lise de sentimento. Pesquise essa t√©cnica interessante em artigos como estes no [KDNuggets](https://www.kdnuggets.com/tag/nlp)

## Tarefa 

[Fa√ßa um bot responder](assignment.md)

---

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte oficial. Para informa√ß√µes cr√≠ticas, recomenda-se uma tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas resultantes do uso desta tradu√ß√£o.