<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "5f3cb462e3122e1afe7ab0050ccf2bd3",
  "translation_date": "2025-09-05T08:50:27+00:00",
  "source_file": "6-NLP/2-Tasks/README.md",
  "language_code": "pt"
}
-->
# Tarefas e t√©cnicas comuns de processamento de linguagem natural

Para a maioria das tarefas de *processamento de linguagem natural*, o texto a ser processado deve ser dividido, examinado e os resultados armazenados ou cruzados com regras e conjuntos de dados. Essas tarefas permitem ao programador derivar o _significado_, a _inten√ß√£o_ ou apenas a _frequ√™ncia_ de termos e palavras em um texto.

## [Question√°rio pr√©-aula](https://ff-quizzes.netlify.app/en/ml/)

Vamos explorar t√©cnicas comuns usadas no processamento de texto. Combinadas com aprendizagem autom√°tica, essas t√©cnicas ajudam a analisar grandes volumes de texto de forma eficiente. Antes de aplicar ML a essas tarefas, no entanto, vamos entender os problemas enfrentados por um especialista em NLP.

## Tarefas comuns em NLP

Existem diferentes maneiras de analisar um texto com o qual voc√™ est√° trabalhando. H√° tarefas que voc√™ pode realizar e, atrav√©s delas, √© poss√≠vel compreender o texto e tirar conclus√µes. Normalmente, essas tarefas s√£o realizadas em sequ√™ncia.

### Tokeniza√ß√£o

Provavelmente, a primeira coisa que a maioria dos algoritmos de NLP precisa fazer √© dividir o texto em tokens ou palavras. Embora isso pare√ßa simples, lidar com pontua√ß√£o e delimitadores de palavras e frases em diferentes idiomas pode tornar o processo complicado. Pode ser necess√°rio usar v√°rios m√©todos para determinar as demarca√ß√µes.

![tokeniza√ß√£o](../../../../6-NLP/2-Tasks/images/tokenization.png)
> Tokenizando uma frase de **Orgulho e Preconceito**. Infogr√°fico por [Jen Looper](https://twitter.com/jenlooper)

### Embeddings

[Word embeddings](https://wikipedia.org/wiki/Word_embedding) s√£o uma forma de converter seus dados textuais em valores num√©ricos. Os embeddings s√£o feitos de maneira que palavras com significados semelhantes ou usadas juntas fiquem agrupadas.

![word embeddings](../../../../6-NLP/2-Tasks/images/embedding.png)
> "Tenho o maior respeito pelos seus nervos, eles s√£o meus velhos amigos." - Word embeddings para uma frase de **Orgulho e Preconceito**. Infogr√°fico por [Jen Looper](https://twitter.com/jenlooper)

‚úÖ Experimente [esta ferramenta interessante](https://projector.tensorflow.org/) para explorar word embeddings. Ao clicar em uma palavra, aparecem clusters de palavras semelhantes: 'brinquedo' agrupa-se com 'disney', 'lego', 'playstation' e 'console'.

### Parsing & Marca√ß√£o de Partes do Discurso

Cada palavra que foi tokenizada pode ser marcada como uma parte do discurso - substantivo, verbo ou adjetivo. A frase `a r√°pida raposa vermelha saltou sobre o c√£o castanho pregui√ßoso` pode ser marcada como POS, por exemplo, raposa = substantivo, saltou = verbo.

![parsing](../../../../6-NLP/2-Tasks/images/parse.png)

> Parsing de uma frase de **Orgulho e Preconceito**. Infogr√°fico por [Jen Looper](https://twitter.com/jenlooper)

Parsing √© o reconhecimento de quais palavras est√£o relacionadas umas √†s outras em uma frase - por exemplo, `a r√°pida raposa vermelha saltou` √© uma sequ√™ncia de adjetivo-substantivo-verbo que √© separada da sequ√™ncia `c√£o castanho pregui√ßoso`.

### Frequ√™ncia de Palavras e Frases

Um procedimento √∫til ao analisar um grande corpo de texto √© construir um dicion√°rio de cada palavra ou frase de interesse e quantas vezes ela aparece. A frase `a r√°pida raposa vermelha saltou sobre o c√£o castanho pregui√ßoso` tem uma frequ√™ncia de palavras de 2 para "a".

Vamos analisar um texto de exemplo onde contamos a frequ√™ncia de palavras. O poema The Winners de Rudyard Kipling cont√©m o seguinte verso:

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

Como as frequ√™ncias de frases podem ser sens√≠veis ou n√£o a mai√∫sculas, a frase `um amigo` tem uma frequ√™ncia de 2, `o` tem uma frequ√™ncia de 6 e `viaja` tem uma frequ√™ncia de 2.

### N-grams

Um texto pode ser dividido em sequ√™ncias de palavras de um comprimento definido, uma √∫nica palavra (unigrama), duas palavras (bigramas), tr√™s palavras (trigramas) ou qualquer n√∫mero de palavras (n-grams).

Por exemplo, `a r√°pida raposa vermelha saltou sobre o c√£o castanho pregui√ßoso` com um valor de n-gram de 2 produz os seguintes n-grams:

1. a r√°pida  
2. r√°pida raposa  
3. raposa vermelha  
4. vermelha saltou  
5. saltou sobre  
6. sobre o  
7. o c√£o  
8. c√£o castanho  
9. castanho pregui√ßoso  

Pode ser mais f√°cil visualizar isso como uma janela deslizante sobre a frase. Aqui est√° para n-grams de 3 palavras, o n-gram est√° em negrito em cada frase:

1.   <u>**a r√°pida raposa**</u> vermelha saltou sobre o c√£o castanho pregui√ßoso  
2.   a **<u>r√°pida raposa vermelha</u>** saltou sobre o c√£o castanho pregui√ßoso  
3.   a r√°pida **<u>raposa vermelha saltou</u>** sobre o c√£o castanho pregui√ßoso  
4.   a r√°pida raposa **<u>vermelha saltou sobre</u>** o c√£o castanho pregui√ßoso  
5.   a r√°pida raposa vermelha **<u>saltou sobre o</u>** c√£o castanho pregui√ßoso  
6.   a r√°pida raposa vermelha saltou **<u>sobre o c√£o</u>** castanho pregui√ßoso  
7.   a r√°pida raposa vermelha saltou sobre <u>**o c√£o castanho**</u> pregui√ßoso  
8.   a r√°pida raposa vermelha saltou sobre o **<u>c√£o castanho pregui√ßoso</u>**

![janela deslizante de n-grams](../../../../6-NLP/2-Tasks/images/n-grams.gif)

> Valor de n-gram de 3: Infogr√°fico por [Jen Looper](https://twitter.com/jenlooper)

### Extra√ß√£o de Frases Nominais

Na maioria das frases, h√° um substantivo que √© o sujeito ou objeto da frase. Em ingl√™s, muitas vezes √© identific√°vel por ter 'a', 'an' ou 'the' antes dele. Identificar o sujeito ou objeto de uma frase atrav√©s da 'extra√ß√£o da frase nominal' √© uma tarefa comum em NLP ao tentar entender o significado de uma frase.

‚úÖ Na frase "N√£o consigo fixar a hora, ou o local, ou o olhar ou as palavras, que lan√ßaram a base. Faz muito tempo. Eu estava no meio antes de perceber que tinha come√ßado.", consegue identificar as frases nominais?

Na frase `a r√°pida raposa vermelha saltou sobre o c√£o castanho pregui√ßoso` h√° 2 frases nominais: **r√°pida raposa vermelha** e **c√£o castanho pregui√ßoso**.

### An√°lise de Sentimento

Uma frase ou texto pode ser analisado para determinar o sentimento, ou qu√£o *positivo* ou *negativo* ele √©. O sentimento √© medido em *polaridade* e *objetividade/subjetividade*. A polaridade √© medida de -1.0 a 1.0 (negativo a positivo) e de 0.0 a 1.0 (mais objetivo a mais subjetivo).

‚úÖ Mais tarde, aprender√° que existem diferentes maneiras de determinar o sentimento usando aprendizagem autom√°tica, mas uma delas √© ter uma lista de palavras e frases categorizadas como positivas ou negativas por um especialista humano e aplicar esse modelo ao texto para calcular um score de polaridade. Consegue perceber como isso funcionaria em algumas circunst√¢ncias e menos em outras?

### Flex√£o

A flex√£o permite que voc√™ pegue uma palavra e obtenha o singular ou plural dela.

### Lematiza√ß√£o

Um *lema* √© a raiz ou palavra principal de um conjunto de palavras, por exemplo, *voou*, *voa*, *voando* t√™m como lema o verbo *voar*.

Existem tamb√©m bases de dados √∫teis dispon√≠veis para o pesquisador de NLP, como:

### WordNet

[WordNet](https://wordnet.princeton.edu/) √© uma base de dados de palavras, sin√¥nimos, ant√¥nimos e muitos outros detalhes para cada palavra em v√°rios idiomas. √â incrivelmente √∫til ao tentar construir tradu√ß√µes, verificadores ortogr√°ficos ou ferramentas de linguagem de qualquer tipo.

## Bibliotecas de NLP

Felizmente, voc√™ n√£o precisa construir todas essas t√©cnicas sozinho, pois existem excelentes bibliotecas Python dispon√≠veis que tornam o NLP muito mais acess√≠vel para desenvolvedores que n√£o s√£o especializados em processamento de linguagem natural ou aprendizagem autom√°tica. As pr√≥ximas li√ß√µes incluem mais exemplos dessas bibliotecas, mas aqui aprender√° alguns exemplos √∫teis para ajud√°-lo na pr√≥xima tarefa.

### Exerc√≠cio - usando a biblioteca `TextBlob`

Vamos usar uma biblioteca chamada TextBlob, pois ela cont√©m APIs √∫teis para lidar com esses tipos de tarefas. TextBlob "baseia-se nos ombros gigantes do [NLTK](https://nltk.org) e [pattern](https://github.com/clips/pattern), e funciona bem com ambos." Ela possui uma quantidade consider√°vel de ML embutida em sua API.

> Nota: Um [Guia de Introdu√ß√£o](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart) √∫til est√° dispon√≠vel para TextBlob e √© recomendado para desenvolvedores Python experientes.

Ao tentar identificar *frases nominais*, TextBlob oferece v√°rias op√ß√µes de extratores para encontrar frases nominais.

1. Veja o `ConllExtractor`.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > O que est√° acontecendo aqui? [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) √© "Um extrator de frases nominais que usa chunk parsing treinado com o corpus de treinamento ConLL-2000." ConLL-2000 refere-se √† Confer√™ncia de Aprendizagem Computacional de Linguagem Natural de 2000. Cada ano a confer√™ncia hospedava um workshop para resolver um problema dif√≠cil de NLP, e em 2000 foi chunking de frases nominais. Um modelo foi treinado no Wall Street Journal, com "as se√ß√µes 15-18 como dados de treinamento (211727 tokens) e a se√ß√£o 20 como dados de teste (47377 tokens)". Pode consultar os procedimentos usados [aqui](https://www.clips.uantwerpen.be/conll2000/chunking/) e os [resultados](https://ifarm.nl/erikt/research/np-chunking.html).

### Desafio - melhorando seu bot com NLP

Na li√ß√£o anterior, voc√™ construiu um bot de perguntas e respostas muito simples. Agora, tornar√° Marvin um pouco mais simp√°tico ao analisar sua entrada para sentimento e imprimir uma resposta que corresponda ao sentimento. Tamb√©m precisar√° identificar uma `noun_phrase` e perguntar sobre ela.

Os passos para construir um bot conversacional melhor:

1. Imprimir instru√ß√µes aconselhando o utilizador sobre como interagir com o bot  
2. Iniciar loop  
   1. Aceitar entrada do utilizador  
   2. Se o utilizador pedir para sair, ent√£o sair  
   3. Processar a entrada do utilizador e determinar a resposta de sentimento apropriada  
   4. Se uma frase nominal for detectada no sentimento, pluraliz√°-la e pedir mais informa√ß√µes sobre esse t√≥pico  
   5. Imprimir resposta  
3. Voltar ao passo 2  

Aqui est√° o trecho de c√≥digo para determinar o sentimento usando TextBlob. Note que h√° apenas quatro *gradientes* de resposta de sentimento (poderia haver mais, se desejar):

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

Aqui est√° um exemplo de sa√≠da para orient√°-lo (entrada do utilizador est√° nas linhas que come√ßam com >):

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

Uma poss√≠vel solu√ß√£o para a tarefa est√° [aqui](https://github.com/microsoft/ML-For-Beginners/blob/main/6-NLP/2-Tasks/solution/bot.py)

‚úÖ Verifica√ß√£o de Conhecimento

1. Acha que as respostas simp√°ticas poderiam 'enganar' algu√©m a pensar que o bot realmente os compreendeu?  
2. Identificar a frase nominal torna o bot mais 'cr√≠vel'?  
3. Por que extrair uma 'frase nominal' de uma frase seria algo √∫til?

---

Implemente o bot na verifica√ß√£o de conhecimento anterior e teste-o com um amigo. Ele consegue engan√°-lo? Consegue tornar seu bot mais 'cr√≠vel'?

## üöÄDesafio

Escolha uma tarefa na verifica√ß√£o de conhecimento anterior e tente implement√°-la. Teste o bot com um amigo. Ele consegue engan√°-lo? Consegue tornar seu bot mais 'cr√≠vel'?

## [Question√°rio p√≥s-aula](https://ff-quizzes.netlify.app/en/ml/)

## Revis√£o & Autoestudo

Nas pr√≥ximas li√ß√µes, aprender√° mais sobre an√°lise de sentimento. Pesquise esta t√©cnica interessante em artigos como estes no [KDNuggets](https://www.kdnuggets.com/tag/nlp)

## Tarefa 

[Fazer um bot responder](assignment.md)

---

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original no seu idioma nativo deve ser considerado a fonte oficial. Para informa√ß√µes cr√≠ticas, recomenda-se uma tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas resultantes do uso desta tradu√ß√£o.