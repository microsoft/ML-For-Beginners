# P√≥s-escrito: Depura√ß√£o de Modelos em Aprendizado de M√°quina usando componentes do painel de IA Respons√°vel

## [Quiz pr√©-aula](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/5/)

## Introdu√ß√£o

O aprendizado de m√°quina impacta nossas vidas cotidianas. A IA est√° se infiltrando em alguns dos sistemas mais importantes que nos afetam como indiv√≠duos e nossa sociedade, desde sa√∫de, finan√ßas, educa√ß√£o at√© emprego. Por exemplo, sistemas e modelos est√£o envolvidos em tarefas di√°rias de tomada de decis√£o, como diagn√≥sticos de sa√∫de ou detec√ß√£o de fraudes. Consequentemente, os avan√ßos em IA, juntamente com a ado√ß√£o acelerada, est√£o sendo confrontados com expectativas sociais em evolu√ß√£o e crescente regulamenta√ß√£o em resposta. Vemos constantemente √°reas onde os sistemas de IA continuam a n√£o atender √†s expectativas; eles exp√µem novos desafios; e os governos est√£o come√ßando a regular solu√ß√µes de IA. Portanto, √© importante que esses modelos sejam analisados para fornecer resultados justos, confi√°veis, inclusivos, transparentes e respons√°veis para todos.

Neste curr√≠culo, vamos explorar ferramentas pr√°ticas que podem ser usadas para avaliar se um modelo apresenta problemas de IA respons√°vel. As t√©cnicas tradicionais de depura√ß√£o de aprendizado de m√°quina tendem a ser baseadas em c√°lculos quantitativos, como precis√£o agregada ou perda de erro m√©dia. Imagine o que pode acontecer quando os dados que voc√™ est√° usando para construir esses modelos carecem de certas demografias, como ra√ßa, g√™nero, vis√£o pol√≠tica, religi√£o, ou representam desproporcionalmente essas demografias. E quando a sa√≠da do modelo √© interpretada para favorecer alguma demografia? Isso pode introduzir uma super ou sub-representa√ß√£o desses grupos de caracter√≠sticas sens√≠veis, resultando em problemas de justi√ßa, inclus√£o ou confiabilidade do modelo. Outro fator √© que os modelos de aprendizado de m√°quina s√£o considerados caixas-pretas, o que torna dif√≠cil entender e explicar o que impulsiona a previs√£o de um modelo. Todos esses s√£o desafios que cientistas de dados e desenvolvedores de IA enfrentam quando n√£o t√™m ferramentas adequadas para depurar e avaliar a justi√ßa ou confiabilidade de um modelo.

Nesta li√ß√£o, voc√™ aprender√° sobre a depura√ß√£o de seus modelos usando:

- **An√°lise de Erros**: identificar onde na distribui√ß√£o de seus dados o modelo apresenta altas taxas de erro.
- **Vis√£o Geral do Modelo**: realizar an√°lise comparativa entre diferentes coortes de dados para descobrir disparidades nas m√©tricas de desempenho do seu modelo.
- **An√°lise de Dados**: investigar onde pode haver super ou sub-representa√ß√£o de seus dados que pode enviesar seu modelo para favorecer uma demografia em rela√ß√£o a outra.
- **Import√¢ncia das Caracter√≠sticas**: entender quais caracter√≠sticas est√£o impulsionando as previs√µes do seu modelo em n√≠vel global ou local.

## Pr√©-requisito

Como pr√©-requisito, por favor, fa√ßa a revis√£o [Ferramentas de IA Respons√°vel para desenvolvedores](https://www.microsoft.com/ai/ai-lab-responsible-ai-dashboard)

> ![Gif sobre Ferramentas de IA Respons√°vel](../../../../9-Real-World/2-Debugging-ML-Models/images/rai-overview.gif)

## An√°lise de Erros

As m√©tricas de desempenho tradicionais usadas para medir a precis√£o s√£o, na maioria, c√°lculos baseados em previs√µes corretas versus incorretas. Por exemplo, determinar que um modelo √© preciso 89% das vezes com uma perda de erro de 0,001 pode ser considerado um bom desempenho. Os erros frequentemente n√£o est√£o distribu√≠dos uniformemente em seu conjunto de dados subjacente. Voc√™ pode obter uma pontua√ß√£o de precis√£o de modelo de 89%, mas descobrir que h√° diferentes regi√µes de seus dados para as quais o modelo est√° falhando 42% das vezes. A consequ√™ncia desses padr√µes de falha com certos grupos de dados pode levar a problemas de justi√ßa ou confiabilidade. √â essencial entender as √°reas onde o modelo est√° se saindo bem ou n√£o. As regi√µes de dados onde h√° um alto n√∫mero de imprecis√µes em seu modelo podem se revelar uma demografia de dados importante.

![Analisar e depurar erros do modelo](../../../../translated_images/ea-error-distribution.117452e1177c1dd84fab2369967a68bcde787c76c6ea7fdb92fcf15d1fce8206.pt.png)

O componente de An√°lise de Erros no painel de RAI ilustra como a falha do modelo est√° distribu√≠da entre v√°rias coortes com uma visualiza√ß√£o em √°rvore. Isso √© √∫til para identificar caracter√≠sticas ou √°reas onde h√° uma alta taxa de erro em seu conjunto de dados. Ao ver de onde a maioria das imprecis√µes do modelo est√° vindo, voc√™ pode come√ßar a investigar a causa raiz. Voc√™ tamb√©m pode criar coortes de dados para realizar an√°lises. Essas coortes de dados ajudam no processo de depura√ß√£o para determinar por que o desempenho do modelo √© bom em uma coorte, mas err√¥neo em outra.

![An√°lise de Erros](../../../../translated_images/ea-error-cohort.6886209ea5d438c4daa8bfbf5ce3a7042586364dd3eccda4a4e3d05623ac702a.pt.png)

Os indicadores visuais no mapa da √°rvore ajudam a localizar as √°reas problem√°ticas mais rapidamente. Por exemplo, quanto mais escura a sombra de vermelho que um n√≥ da √°rvore possui, maior a taxa de erro.

O mapa de calor √© outra funcionalidade de visualiza√ß√£o que os usu√°rios podem usar para investigar a taxa de erro usando uma ou duas caracter√≠sticas para encontrar um contribuinte para os erros do modelo em todo o conjunto de dados ou coortes.

![Mapa de Calor da An√°lise de Erros](../../../../translated_images/ea-heatmap.8d27185e28cee3830c85e1b2e9df9d2d5e5c8c940f41678efdb68753f2f7e56c.pt.png)

Use a an√°lise de erros quando precisar:

* Obter uma compreens√£o profunda de como as falhas do modelo est√£o distribu√≠das em um conjunto de dados e em v√°rias dimens√µes de entrada e caracter√≠sticas.
* Desmembrar as m√©tricas de desempenho agregadas para descobrir automaticamente coortes err√¥neas que informem suas etapas de mitiga√ß√£o direcionadas.

## Vis√£o Geral do Modelo

Avaliar o desempenho de um modelo de aprendizado de m√°quina requer uma compreens√£o hol√≠stica de seu comportamento. Isso pode ser alcan√ßado revisando mais de uma m√©trica, como taxa de erro, precis√£o, recall, precis√£o ou MAE (Erro Absoluto M√©dio), para encontrar disparidades entre as m√©tricas de desempenho. Uma m√©trica de desempenho pode parecer √≥tima, mas imprecis√µes podem ser expostas em outra m√©trica. Al√©m disso, comparar as m√©tricas em busca de disparidades em todo o conjunto de dados ou coortes ajuda a esclarecer onde o modelo est√° se saindo bem ou n√£o. Isso √© especialmente importante para ver o desempenho do modelo entre caracter√≠sticas sens√≠veis e insens√≠veis (por exemplo, ra√ßa do paciente, g√™nero ou idade) para descobrir potenciais injusti√ßas que o modelo possa ter. Por exemplo, descobrir que o modelo √© mais err√¥neo em uma coorte que possui caracter√≠sticas sens√≠veis pode revelar potenciais injusti√ßas que o modelo possa ter.

O componente Vis√£o Geral do Modelo do painel de RAI ajuda n√£o apenas na an√°lise das m√©tricas de desempenho da representa√ß√£o de dados em uma coorte, mas tamb√©m oferece aos usu√°rios a capacidade de comparar o comportamento do modelo entre diferentes coortes.

![Coortes de Dados - vis√£o geral do modelo no painel RAI](../../../../translated_images/model-overview-dataset-cohorts.dfa463fb527a35a0afc01b7b012fc87bf2cad756763f3652bbd810cac5d6cf33.pt.png)

A funcionalidade de an√°lise baseada em caracter√≠sticas do componente permite que os usu√°rios reduzam subgrupos de dados dentro de uma caracter√≠stica espec√≠fica para identificar anomalias em um n√≠vel mais granular. Por exemplo, o painel possui intelig√™ncia embutida para gerar automaticamente coortes para uma caracter√≠stica selecionada pelo usu√°rio (por exemplo, *"time_in_hospital < 3"* ou *"time_in_hospital >= 7"*). Isso permite que um usu√°rio isole uma caracter√≠stica espec√≠fica de um grupo de dados maior para ver se ela √© um influenciador chave dos resultados err√¥neos do modelo.

![Coortes de Caracter√≠sticas - vis√£o geral do modelo no painel RAI](../../../../translated_images/model-overview-feature-cohorts.c5104d575ffd0c80b7ad8ede7703fab6166bfc6f9125dd395dcc4ace2f522f70.pt.png)

O componente Vis√£o Geral do Modelo suporta duas classes de m√©tricas de disparidade:

**Disparidade no desempenho do modelo**: Esses conjuntos de m√©tricas calculam a disparidade (diferen√ßa) nos valores da m√©trica de desempenho selecionada entre subgrupos de dados. Aqui est√£o alguns exemplos:

* Disparidade na taxa de precis√£o
* Disparidade na taxa de erro
* Disparidade na precis√£o
* Disparidade no recall
* Disparidade no erro absoluto m√©dio (MAE)

**Disparidade na taxa de sele√ß√£o**: Essa m√©trica cont√©m a diferen√ßa na taxa de sele√ß√£o (previs√£o favor√°vel) entre subgrupos. Um exemplo disso √© a disparidade nas taxas de aprova√ß√£o de empr√©stimos. A taxa de sele√ß√£o significa a fra√ß√£o de pontos de dados em cada classe classificados como 1 (na classifica√ß√£o bin√°ria) ou a distribui√ß√£o dos valores de previs√£o (na regress√£o).

## An√°lise de Dados

> "Se voc√™ torturar os dados por tempo suficiente, eles confessar√£o qualquer coisa" - Ronald Coase

Essa afirma√ß√£o parece extrema, mas √© verdade que os dados podem ser manipulados para apoiar qualquer conclus√£o. Tal manipula√ß√£o pode, √†s vezes, ocorrer involuntariamente. Como seres humanos, todos temos preconceitos, e muitas vezes √© dif√≠cil saber conscientemente quando voc√™ est√° introduzindo vi√©s nos dados. Garantir a justi√ßa em IA e aprendizado de m√°quina continua a ser um desafio complexo.

Os dados s√£o um grande ponto cego para as m√©tricas de desempenho tradicionais do modelo. Voc√™ pode ter altas pontua√ß√µes de precis√£o, mas isso nem sempre reflete o vi√©s subjacente dos dados que pode estar em seu conjunto de dados. Por exemplo, se um conjunto de dados de funcion√°rios tem 27% de mulheres em cargos executivos em uma empresa e 73% de homens no mesmo n√≠vel, um modelo de IA de an√∫ncios de emprego treinado com esses dados pode direcionar principalmente um p√∫blico masculino para cargos de n√≠vel s√™nior. Ter esse desequil√≠brio nos dados enviesou a previs√£o do modelo para favorecer um g√™nero. Isso revela um problema de justi√ßa onde h√° um vi√©s de g√™nero no modelo de IA.

O componente de An√°lise de Dados no painel de RAI ajuda a identificar √°reas onde h√° uma super- e sub-representa√ß√£o no conjunto de dados. Ele ajuda os usu√°rios a diagnosticar a causa raiz dos erros e problemas de justi√ßa introduzidos por desequil√≠brios nos dados ou falta de representa√ß√£o de um grupo de dados espec√≠fico. Isso d√° aos usu√°rios a capacidade de visualizar conjuntos de dados com base em resultados previstos e reais, grupos de erro e caracter√≠sticas espec√≠ficas. √Äs vezes, descobrir um grupo de dados sub-representado tamb√©m pode revelar que o modelo n√£o est√° aprendendo bem, resultando em altas imprecis√µes. Ter um modelo que possui vi√©s nos dados n√£o √© apenas um problema de justi√ßa, mas demonstra que o modelo n√£o √© inclusivo ou confi√°vel.

![Componente de An√°lise de Dados no Painel RAI](../../../../translated_images/dataanalysis-cover.8d6d0683a70a5c1e274e5a94b27a71137e3d0a3b707761d7170eb340dd07f11d.pt.png)

Use a an√°lise de dados quando precisar:

* Explorar as estat√≠sticas do seu conjunto de dados selecionando diferentes filtros para dividir seus dados em diferentes dimens√µes (tamb√©m conhecidas como coortes).
* Compreender a distribui√ß√£o do seu conjunto de dados entre diferentes coortes e grupos de caracter√≠sticas.
* Determinar se suas descobertas relacionadas √† justi√ßa, an√°lise de erros e causalidade (derivadas de outros componentes do painel) s√£o resultado da distribui√ß√£o do seu conjunto de dados.
* Decidir em quais √°reas coletar mais dados para mitigar erros que surgem de problemas de representa√ß√£o, ru√≠do de r√≥tulo, ru√≠do de caracter√≠stica, vi√©s de r√≥tulo e fatores semelhantes.

## Interpretabilidade do Modelo

Modelos de aprendizado de m√°quina tendem a ser caixas-pretas. Entender quais caracter√≠sticas de dados chave impulsionam a previs√£o de um modelo pode ser desafiador. √â importante fornecer transpar√™ncia sobre por que um modelo faz uma certa previs√£o. Por exemplo, se um sistema de IA prev√™ que um paciente diab√©tico est√° em risco de ser readmitido em um hospital em menos de 30 dias, ele deve ser capaz de fornecer dados de suporte que levaram √† sua previs√£o. Ter indicadores de dados de suporte traz transpar√™ncia para ajudar cl√≠nicos ou hospitais a tomar decis√µes bem informadas. Al√©m disso, ser capaz de explicar por que um modelo fez uma previs√£o para um paciente individual permite responsabilidade em rela√ß√£o √†s regulamenta√ß√µes de sa√∫de. Quando voc√™ est√° usando modelos de aprendizado de m√°quina de maneiras que afetam a vida das pessoas, √© crucial entender e explicar o que influencia o comportamento de um modelo. A explicabilidade e interpretabilidade do modelo ajudam a responder perguntas em cen√°rios como:

* Depura√ß√£o do modelo: Por que meu modelo cometeu esse erro? Como posso melhorar meu modelo?
* Colabora√ß√£o humano-IA: Como posso entender e confiar nas decis√µes do modelo?
* Conformidade regulat√≥ria: Meu modelo satisfaz os requisitos legais?

O componente de Import√¢ncia das Caracter√≠sticas do painel de RAI ajuda voc√™ a depurar e obter uma compreens√£o abrangente de como um modelo faz previs√µes. √â tamb√©m uma ferramenta √∫til para profissionais de aprendizado de m√°quina e tomadores de decis√£o explicarem e mostrarem evid√™ncias das caracter√≠sticas que influenciam o comportamento de um modelo para conformidade regulat√≥ria. Em seguida, os usu√°rios podem explorar explica√ß√µes globais e locais para validar quais caracter√≠sticas impulsionam a previs√£o de um modelo. As explica√ß√µes globais listam as principais caracter√≠sticas que afetaram a previs√£o geral de um modelo. As explica√ß√µes locais exibem quais caracter√≠sticas levaram √† previs√£o de um modelo para um caso individual. A capacidade de avaliar explica√ß√µes locais tamb√©m √© √∫til na depura√ß√£o ou auditoria de um caso espec√≠fico para entender melhor e interpretar por que um modelo fez uma previs√£o precisa ou imprecisa.

![Componente de Import√¢ncia das Caracter√≠sticas do painel RAI](../../../../translated_images/9-feature-importance.cd3193b4bba3fd4bccd415f566c2437fb3298c4824a3dabbcab15270d783606e.pt.png)

* Explica√ß√µes globais: Por exemplo, quais caracter√≠sticas afetam o comportamento geral de um modelo de readmiss√£o hospitalar para diab√©ticos?
* Explica√ß√µes locais: Por exemplo, por que um paciente diab√©tico com mais de 60 anos e com hospitaliza√ß√µes anteriores foi previsto para ser readmitido ou n√£o readmitido em um hospital dentro de 30 dias?

No processo de depura√ß√£o de exame do desempenho de um modelo em diferentes coortes, a Import√¢ncia das Caracter√≠sticas mostra qual n√≠vel de impacto uma caracter√≠stica tem entre as coortes. Ela ajuda a revelar anomalias ao comparar o n√≠vel de influ√™ncia que a caracter√≠stica tem na condu√ß√£o das previs√µes err√¥neas de um modelo. O componente de Import√¢ncia das Caracter√≠sticas pode mostrar quais valores em uma caracter√≠stica influenciaram positiva ou negativamente o resultado do modelo. Por exemplo, se um modelo fez uma previs√£o imprecisa, o componente d√° a voc√™ a capacidade de detalhar e identificar quais caracter√≠sticas ou valores de caracter√≠sticas impulsionaram a previs√£o. Esse n√≠vel de detalhe ajuda n√£o apenas na depura√ß√£o, mas fornece transpar√™ncia e responsabilidade em situa√ß√µes de auditoria. Por fim, o componente pode ajud√°-lo a identificar problemas de justi√ßa. Para ilustrar, se uma caracter√≠stica sens√≠vel, como etnia ou g√™nero, for altamente influente na condu√ß√£o da previs√£o de um modelo, isso pode ser um sinal de vi√©s racial ou de g√™nero no modelo.

![Import√¢ncia das caracter√≠sticas](../../../../translated_images/9-features-influence.3ead3d3f68a84029f1e40d3eba82107445d3d3b6975d4682b23d8acc905da6d0.pt.png)

Use a interpretabilidade quando precisar:

* Determinar qu√£o confi√°veis s√£o as previs√µes do seu sistema de IA, entendendo quais caracter√≠sticas s√£o mais importantes para as previs√µes.
* Abordar a depura√ß√£o do seu modelo entendendo-o primeiro e identificando se o modelo est√° usando caracter√≠sticas saud√°veis ou meramente correla√ß√µes falsas.
* Descobrir potenciais fontes de injusti√ßa entendendo se o modelo est√° baseando previs√µes em caracter√≠sticas sens√≠veis ou em caracter√≠sticas que est√£o altamente correlacionadas a elas.
* Construir confian√ßa do usu√°rio nas decis√µes do seu modelo gerando explica√ß√µes locais para ilustrar seus resultados.
* Completar uma auditoria regulat√≥ria de um sistema de IA para validar modelos e monitorar o impacto das decis√µes do modelo sobre os humanos.

## Conclus√£o

Todos os componentes do painel de RAI s√£o ferramentas pr√°ticas para ajud√°-lo a construir modelos de aprendizado de m√°quina que sejam menos prejudiciais e mais confi√°veis para a sociedade. Isso melhora a preven√ß√£o de amea√ßas aos direitos humanos; a discrimina√ß√£o ou exclus√£o de certos grupos de oportunidades de vida; e o risco de les√µes f√≠sicas ou psicol√≥gicas. Tamb√©m ajuda a construir confian√ßa nas decis√µes do seu modelo gerando explica√ß√µes locais para ilustrar seus resultados. Alguns dos danos potenciais podem ser classificados como:

- **Aloca√ß√£o**, se um g√™nero ou etnia, por exemplo, for favorecido em rela√ß√£o a outro.
- **Qualidade do servi√ßo**. Se voc√™ treinar os dados para um cen√°rio espec√≠fico, mas a realidade for muito mais complexa, isso leva a um servi√ßo de baixo desempenho.
- **Estereotipagem**. Associar um determinado grupo a atributos pr√©-designados.
- **Denigra√ß√£o**. Criticar e rotular injustamente algo ou algu√©m.
- **Super- ou sub-representa√ß√£o**. A ideia √© que um determinado grupo n√£o √© visto em uma determinada profiss√£o, e qualquer servi√ßo ou fun√ß√£o que continue promovendo isso est√° contribuindo para o dano.

### Painel Azure RAI

O [Painel Azure RAI](https://learn.microsoft.com/en-us/azure/machine-learning/concept-responsible-ai-dashboard?WT.mc_id=aiml-90525-ruyakubu) √© constru√≠do com ferramentas de c√≥digo aberto desenvolvidas por institui√ß√µes acad√™micas e organiza√ß√µes l√≠deres, incluindo a Microsoft, que s√£o instrumentais para cientistas de dados e desenvolvedores de IA para entender melhor o comportamento do modelo, descobrir e mitigar problemas indesej√°veis de modelos de IA.

- Aprenda a usar os diferentes componentes consultando a [documenta√ß√£o do painel RAI.](https://learn.microsoft.com/en-us/azure/machine-learning/how-to-responsible-ai-dashboard?WT.mc_id=aiml-90525-ruyakubu)

- Confira alguns [notebooks de amostra do painel RAI](https://github.com/Azure/RAI-vNext-Preview/tree/main/examples/notebooks) para depurar cen√°rios de IA respons√°vel no Azure Machine Learning.

---

## üöÄ Desafio

Para evitar que vieses estat√≠sticos ou de dados sejam introduzidos em primeiro lugar, devemos:

- ter uma diversidade de origens e perspectivas entre as pessoas que trabalham em sistemas
- investir em conjuntos de dados que reflitam a diversidade da nossa sociedade
- desenvolver melhores m√©todos para detectar e corrigir vi√©s quando ele ocorrer

Pense em cen√°rios da vida real onde a injusti√ßa √© evidente na constru√ß√£o e uso de modelos. O que mais devemos considerar?

## [Quiz p√≥s-aula](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/6/)

## Revis√£o e Autoestudo

Nesta li√ß√£o, voc√™ aprendeu algumas das ferramentas pr√°ticas de incorpora√ß√£o de IA respons√°vel em aprendizado de m√°quina.

Assista a este workshop para se aprofundar nos t√≥picos:

- Painel de IA Respons√°vel: Um ponto de encontro para operacionalizar RAI na pr√°tica por Besmira Nushi e Mehrnoosh Sameki

[![Painel de IA Respons√°vel: Um ponto de encontro para operacionalizar RAI na pr√°tica](https://img.youtube.com/vi/f1oaDNl3djg/0.jpg)](https://www.youtube.com/watch?v=f1oaDNl3djg "Painel de IA Respons√°vel: Um ponto de encontro para operacionalizar RAI na pr√°tica")

> üé• Clique na imagem acima para ver o v√≠deo: Painel de IA Respons√°vel: Um ponto de encontro para operacionalizar RAI na pr√°tica por Besmira Nushi e Mehrnoosh Sameki

Referencie os seguintes materiais para aprender mais sobre IA respons√°vel e como construir modelos

**Aviso Legal**:  
Este documento foi traduzido utilizando servi√ßos de tradu√ß√£o autom√°tica baseados em IA. Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original em sua l√≠ngua nativa deve ser considerado a fonte autoritativa. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes err√¥neas decorrentes do uso desta tradu√ß√£o.