<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "1f2b7441745eb52e25745423b247016b",
  "translation_date": "2025-08-29T14:17:56+00:00",
  "source_file": "8-Reinforcement/2-Gym/assignment.md",
  "language_code": "ar"
}
-->
# تدريب سيارة الجبل

[OpenAI Gym](http://gym.openai.com) تم تصميمه بحيث توفر جميع البيئات نفس واجهة البرمجة - أي نفس الطرق `reset`, `step` و `render`، ونفس التجريدات لمساحة **الإجراءات** ومساحة **الملاحظات**. لذلك يجب أن يكون من الممكن تكييف نفس خوارزميات التعلم المعزز مع بيئات مختلفة مع تغييرات بسيطة في الكود.

## بيئة سيارة الجبل

[بيئة سيارة الجبل](https://gym.openai.com/envs/MountainCar-v0/) تحتوي على سيارة عالقة في وادٍ:

الهدف هو الخروج من الوادي والوصول إلى العلم، عن طريق القيام بأحد الإجراءات التالية في كل خطوة:

| القيمة | المعنى |
|---|---|
| 0 | التسارع إلى اليسار |
| 1 | عدم التسارع |
| 2 | التسارع إلى اليمين |

الحيلة الرئيسية في هذه المشكلة هي أن محرك السيارة ليس قويًا بما يكفي لتسلق الجبل في محاولة واحدة. لذلك، الطريقة الوحيدة للنجاح هي القيادة ذهابًا وإيابًا لبناء الزخم.

مساحة الملاحظات تتكون فقط من قيمتين:

| الرقم | الملاحظة  | الحد الأدنى | الحد الأقصى |
|-----|--------------|-----|-----|
|  0  | موقع السيارة | -1.2| 0.6 |
|  1  | سرعة السيارة | -0.07 | 0.07 |

نظام المكافآت لسيارة الجبل معقد نوعًا ما:

 * يتم منح مكافأة قدرها 0 إذا وصل الوكيل إلى العلم (الموقع = 0.5) على قمة الجبل.
 * يتم منح مكافأة قدرها -1 إذا كان موقع الوكيل أقل من 0.5.

تنتهي الحلقة إذا كان موقع السيارة أكثر من 0.5، أو إذا تجاوز طول الحلقة 200.

## التعليمات

قم بتكييف خوارزمية التعلم المعزز الخاصة بنا لحل مشكلة سيارة الجبل. ابدأ بالكود الموجود في [notebook.ipynb](notebook.ipynb)، استبدل البيئة الجديدة، غيّر وظائف تقسيم الحالة، وحاول جعل الخوارزمية الحالية تتدرب مع تعديلات بسيطة في الكود. قم بتحسين النتيجة عن طريق ضبط معلمات الضبط.

> **ملاحظة**: من المحتمل أن يكون ضبط معلمات الضبط ضروريًا لجعل الخوارزمية تتقارب.

## التقييم

| المعايير | مثالي | كافٍ | يحتاج إلى تحسين |
| -------- | --------- | -------- | ----------------- |
|          | تم تكييف خوارزمية Q-Learning بنجاح من مثال CartPole، مع تعديلات بسيطة في الكود، وهي قادرة على حل مشكلة الوصول إلى العلم في أقل من 200 خطوة. | تم اعتماد خوارزمية Q-Learning جديدة من الإنترنت، ولكنها موثقة جيدًا؛ أو تم اعتماد الخوارزمية الحالية، ولكنها لم تصل إلى النتائج المطلوبة. | لم يتمكن الطالب من اعتماد أي خوارزمية بنجاح، ولكنه قام بخطوات كبيرة نحو الحل (تنفيذ تقسيم الحالة، هيكل بيانات Q-Table، إلخ). |

---

**إخلاء المسؤولية**:  
تمت ترجمة هذا المستند باستخدام خدمة الترجمة الآلية [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو عدم دقة. يجب اعتبار المستند الأصلي بلغته الأصلية هو المصدر الموثوق. للحصول على معلومات حساسة أو هامة، يُوصى بالاستعانة بترجمة بشرية احترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسيرات خاطئة تنشأ عن استخدام هذه الترجمة.