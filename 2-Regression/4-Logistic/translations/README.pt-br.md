# Regress√£o log√≠stica para prever categorias

![Infogr√°fico de regress√£o log√≠stica versus regress√£o linear](../images/logistic-linear.png)
> Infogr√°fico por [Dasani Madipalli](https://twitter.com/dasani_decoded)
## [Question√°rio inicial](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/15?loc=ptbr)

> ### [Esta li√ßao est√° dispon√≠vel em R!](../solution/R/lesson_4-R.ipynb)

## Introdu√ß√£o

Nesta li√ß√£o final sobre Regress√£o, uma das t√©cnicas b√°sicas do ML _cl√°ssico_, vamos estudar a Regress√£o Log√≠stica. Essa t√©cnica serve para descobrir padr√µes e prever categorias bin√°rias. Este doce √© de chocolate ou n√£o? Esta doen√ßa √© contagiosa ou n√£o? Este cliente vai escolher este produto ou n√£o?

Voc√™ ir√° aprender:

- Uma nova biblioteca para visualiza√ß√£o de dados
- T√©cnicas de regress√£o log√≠stica

‚úÖ Aprofunde seu conhecimento de como trabalhar com este tipo de regress√£o neste [m√≥dulo](https://docs.microsoft.com/learn/modules/train-evaluate-classification-models?WT.mc_id=academic-77952-leestott).

## Pr√©-requisito

Tendo trabalhado com os dados das ab√≥boras, estamos familiarizados o suficiente com eles para perceber que h√° uma categoria bin√°ria com a qual podemos trabalhar: `Color` (cor).

Vamos construir um modelo de regress√£o log√≠stica para prever _qual a cor que a ab√≥bora provavelmente ter√°_ (laranja üéÉ ou branca üëª), com base em algumas colunas.

> Por que estamos falando de classifica√ß√£o bin√°ria em um grupo de li√ß√µes sobre regress√£o? Apenas por conveni√™ncia lingu√≠stica, regress√£o log√≠stica √© [um m√©todo de classifica√ß√£o](https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression), mesmo sendo linear. Vamos aprender outros modos de classificar dados em li√ß√µes mais a frente.

## Defina a pergunta

Para esta li√ß√£o, expressaremos 'Orange' (Laranja) ou 'Not Orange' (N√£o Laranja) como um dado bin√°rio. Existe uma categoria 'striped' (listrada) em nosso conjunto de dados, mas h√° poucas inst√¢ncias dela, ent√£o n√£o a usaremos. Ela desaparece assim que removemos os valores nulos no conjunto de dados.

> üéÉ Curiosidade: podemos chamar as ab√≥boras brancas de 'ab√≥boras fantasmas'. Elas n√£o s√£o f√°ceis de esculpir, por isso n√£o s√£o t√£o populares quanto as laranjas mas s√£o legais tamb√©m!

## Sobre a regress√£o log√≠stica

A regress√£o log√≠stica difere da regress√£o linear em alguns aspectos importantes.

### Classifica√ß√£o bin√°ria

A regress√£o log√≠stica oferece uma previs√£o sobre uma categoria bin√°ria ("laranja ou n√£o laranja"), enquanto a linear √© capaz de prever valores cont√≠nuos, por exemplo: _quanto o pre√ßo de uma ab√≥bora vai subir_ dada sua origem e a √©poca de colheita.

![Modelo de classifica√ß√£o de ab√≥boras](../images/pumpkin-classifier.png)
> Infogr√°fico por [Dasani Madipalli](https://twitter.com/dasani_decoded)

### Outros tipos de classifica√ß√µes

Existem outros tipos de regress√£o log√≠stica, incluindo multinomial e ordinal:

- **Multinomial**, que envolve ter mais de uma categoria - "Laranja, Branco e Listrado".
- **Ordinal**, que envolve categorias ordenadas. √â √∫til se quisermos ordenar nossos resultados logicamente, como nossas ab√≥boras que s√£o ordenadas por um n√∫mero finito de tamanhos (mini, sm, med, lg, xl, xxl).

![Regress√£o multinomial versus ordina](../images/multinomial-ordinal.png)
> Infogr√°fico por [Dasani Madipalli](https://twitter.com/dasani_decoded)

### Continua sendo linear

Embora esse tipo de regress√£o esteja relacionado a "previs√µes de categoria", ele funciona ainda melhor quando h√° uma rela√ß√£o linear clara entre a vari√°vel dependente (cor) e as outras vari√°veis ‚Äã‚Äãindependentes (o resto do conjunto de dados, como o nome da cidade e as dimens√µes). √â bom saber se existe alguma rela√ß√£o linear entre essas vari√°veis previamente.

### Vari√°veis ‚Äã‚ÄãN√ÉO devem ser correlacionadas

Lembra como a regress√£o linear funcionou melhor com vari√°veis ‚Äã‚Äãcorrelacionadas? A regress√£o log√≠stica √© o oposto: as vari√°veis ‚Äã‚Äãn√£o precisam disso. Logo, funciona para dados que t√™m correla√ß√µes baixas.

### Voc√™ precisar√° de muitos dados. E tratados.

A regress√£o log√≠stica fornecer√° resultados mais precisos se voc√™ usar mais dados; portanto, tenha em mente que, como o conjunto de dados das ab√≥boras √© pequeno, talvez n√£o sirva para esta tarefa.

‚úÖ Pense sobre os tipos de dados que funcionariam bem com regress√£o log√≠stica.

## Exerc√≠cio - Organizar os dados

Primeiro, limpamos os dados eliminando os valores nulos e selecionando apenas algumas das colunas:

1. Adicione o seguinte c√≥digo:

    ```python
    from sklearn.preprocessing import LabelEncoder
    
    new_columns = ['Color','Origin','Item Size','Variety','City Name','Package']
    
    new_pumpkins = pumpkins.drop([c for c in pumpkins.columns if c not in new_columns], axis=1)
    
    new_pumpkins.dropna(inplace=True)
    
    new_pumpkins = new_pumpkins.apply(LabelEncoder().fit_transform)
    ```

    Voc√™ pode usar o c√≥digo abaixo dar uma espiada em como est√° seu _dataframe_:

    ```python
    new_pumpkins.info
    ```

### Visualiza√ß√£o: _side-by-side grid_ (grade lado-a-lado)

Ap√≥s carregar mais uma vez seu [_notebook_](../notebook.ipynb) com os dados das ab√≥boras e trat√°-los para preservar um conjunto de dados contendo algumas colunas, incluindo `Color`, vamos visualizar o _dataframe_ no _notebook_ usando uma biblioteca diferente: a [Seaborn](https://seaborn.pydata.org/index.html).

Seaborn oferece algumas maneiras interessantes de visualizar dados. Por exemplo, voc√™ pode comparar as distribui√ß√µes dos dados para cada ponto em uma grade lado-a-lado.

1. Crie a grade instanciando um `PairGrid`, usando nossos dados de ab√≥boras `new_pumpkins`, seguido pela chamada da fun√ß√£o `map()`:

    ```python
    import seaborn as sns
    
    g = sns.PairGrid(new_pumpkins)
    g.map(sns.scatterplot)
    ```

    ![Uma grade para visualiza√ß√£o de dados](../images/grid.png)

    Olhando os dados lado a lado, voc√™ pode ver como os dados da coluna `Color` se relacionam com as outras colunas.

    ‚úÖ Consegue imaginar o que podemos explorar, dada essa grade de gr√°ficos de dispers√£o?

### Gr√°fico _swarm_

Como `Color` √© uma categoria bin√°ria (laranja ou n√£o), ela √© chamada de 'dado categ√≥rico' e precisa de 'uma [abordagem mais especializada](https://seaborn.pydata.org/tutorial/categorical.html?highlight=bar) para visualiza√ß√£o'. Existem outras maneiras de visualizar a rela√ß√£o desta coluna com as outras.

As colunas ‚Äã‚Äãpodem ser visualizadas lado a lado com os gr√°ficos Seaborn.

1. Experimente um gr√°fico _swarm_ para mostrar a distribui√ß√£o de valores:

    ```python
    sns.swarmplot(x="Color", y="Item Size", data=new_pumpkins)
    ```

    ![Dados visualizados num gr√°fico _swarm_](../images/swarm.png)

### Gr√°fico violino

Um gr√°fico do tipo "violino" √© √∫til para visualizar como os dados s√£o distribu√≠dos nas duas categorias. Plotagens semelhantes a violino n√£o funcionam t√£o bem com conjuntos de dados menores porque a distribui√ß√£o √© exibida de forma mais "uniforme".

1. Use como par√¢metros `x=Color`, `kind="violin"` e chame a fun√ß√£o `catplot()`:

    ```python
    sns.catplot(x="Color", y="Item Size",
                kind="violin", data=new_pumpkins)
    ```

    ![Gr√°fico violino](../images/violin.png)

    ‚úÖ Tente criar este gr√°fico e outros gr√°ficos Seaborn, usando outras colunas.

Agora podemos imaginar a rela√ß√£o entre as duas categorias bin√°rias de cor e tamanho (_item size_). Vamos explorar a regress√£o log√≠stica para prever a cor de uma ab√≥bora em particular.

> **üßÆ Me mostre a matem√°tica** 
>
> Voc√™ se lembra como a regress√£o linear costumava usar m√≠nimos quadrados comuns para chegar a um valor? A regress√£o log√≠stica depende do conceito de 'probabilidade m√°xima' usando [fun√ß√µes sigm√≥ide](https://wikipedia.org/wiki/Sigmoid_function). Uma 'fun√ß√£o sigm√≥ide' em um gr√°fico parece estar na forma de um 'S'. Ela pega um valor e o mapeia para algo entre 0 e 1. Sua curva tamb√©m √© chamada de 'curva log√≠stica'. Sua f√≥rmula √© assim:
>
> ![logistic function](../images/sigmoid.png)
>
> o ponto m√©dio do sigm√≥ide encontra-se no eixo X. `L` √© o valor m√°ximo da curva e `k` √© a inclina√ß√£o da curva. Se o resultado da fun√ß√£o for maior que 0.5, o valor atribu√≠do √† fun√ß√£o ser√° classificado como '1'. Caso contr√°rio, ser√° classificado como '0'.

## Construindo um modelo

Construir um modelo para encontrar classifica√ß√µes bin√°rias √© muito simples no Scikit-learn.

1. Selecione as colunas que deseja usar em seu modelo de classifica√ß√£o e divida os conjuntos de dados em conjuntos de treinamento e teste chamando `train_test_split()`:

    ```python
    from sklearn.model_selection import train_test_split
    
    Selected_features = ['Origin','Item Size','Variety','City Name','Package']
    
    X = new_pumpkins[Selected_features]
    y = new_pumpkins['Color']
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)
    
    ```

1. Usando seus dados de treinamento, treine seu modelo chamando a fun√ß√£o `fit()`, e imprima o resultado:

    ```python
    from sklearn.model_selection import train_test_split
    from sklearn.metrics import accuracy_score, classification_report 
    from sklearn.linear_model import LogisticRegression
    
    model = LogisticRegression()
    model.fit(X_train, y_train)
    predictions = model.predict(X_test)
    
    print(classification_report(y_test, predictions))
    print('Predicted labels: ', predictions)
    print('Accuracy: ', accuracy_score(y_test, predictions))
    ```

    Veja o placar do seu modelo. Nada mal, especialmente com apenas 1000 linhas de dados:

    ```output
                       precision    recall  f1-score   support
    
               0       0.85      0.95      0.90       166
               1       0.38      0.15      0.22        33
    
        accuracy                           0.82       199
       macro avg       0.62      0.55      0.56       199
    weighted avg       0.77      0.82      0.78       199
    
    Predicted labels:  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0
     0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
     1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1
     0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1
     0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
     0 0 0 1 0 1 0 0 1 0 0 0 1 0]
    ```

## Melhor compreens√£o usando Matriz de Confus√£o

Embora voc√™ possa obter os [valores](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html?highlight=classification_report#sklearn.metrics.classification_report) de um relat√≥rio de *placar* do seu modelo como na *impress√£o* acima, voc√™ pode entender melhor o desempenho do seu modelo com uma [matriz de confus√£o](https://scikit-learn.org/stable/modules/model_evaluation.html#confusion-matrix).

> üéì Uma '[matriz de confus√£o](https://wikipedia.org/wiki/Confusion_matrix)' (ou 'matriz de erro') √© uma tabela que expressa os verdadeiros e falsos positivos e negativos, medindo a acur√°cia das previs√µes.

1. Para obter a matriz de confus√£o, chame a fun√ß√£o `confusion_matrix()`:

    ```python
    from sklearn.metrics import confusion_matrix
    confusion_matrix(y_test, predictions)
    ```

    D√™ uma olhada na matriz de confus√£o do seu modelo:

    ```output
    array([[162,   4],
           [ 33,   0]])
    ```

> Na Scikit-learn, as linhas nas matrizes de confus√£o (eixo 0) s√£o classes reais e colunas (eixo 1) s√£o classes previstas.

> |       |   0   |   1   |
> | :---: | :---: | :---: |
> |   0   |  TP (True Positive = Verdadeiro Positivo)   |  FN (False Negative = Falso Negativo)   |
> |   1   |  FP (False Positive = Falso Positivo)   |  TN (True Negative = Verdadeiro Negativo)  |

O que est√° acontecendo aqui? Supondo que nosso modelo tenha que classificar as ab√≥boras entre duas categorias bin√°rias, categoria 'laranja' e categoria 'n√£o laranja':

- Se o seu modelo prev√™ que uma ab√≥bora n√£o √© laranja e ela pertence √† categoria 'n√£o laranja', chamamos isso de verdadeiro negativo.
- Se o seu modelo prev√™ que uma ab√≥bora √© laranja e ela pertence √† categoria 'n√£o laranja', chamamos isso de falso positivo.
- Se o seu modelo prev√™ que uma ab√≥bora n√£o √© laranja e ela pertence √† categoria 'laranja', chamamos isso de falso negativo.
- Se o seu modelo prev√™ que uma ab√≥bora √© laranja e ela pertence √† categoria 'laranja', chamamos isso de verdadeiro positivo.

Podemos perceber que √© melhor ter um n√∫mero maior de positivos e negativos verdadeiros e um n√∫mero menor de positivos e negativos falsos pois, isso significa que o modelo tem um desempenho melhor.

‚úÖ Pergunta: Com base na matriz de confus√£o, o modelo √© bom ou n√£o? Resposta: nada mal; existem muitos verdadeiros positivos (162) e poucos falsos negativos (4).

Vamos revisitar os termos que vimos anteriormente com a ajuda da matriz de confus√£o de TP / TN e FP / FN:

üéì Precision: TP / (TP + FP). Raz√£o de dados relevantes que foram previstos corretamente entre todos os dados do conjunto.

üéì Recall: TP / (TP + FN). A propor√ß√£o dos dados relevantes que foram previstos, estando rotulados corretamente ou n√£o.

üéì f1-score (pontua√ß√£o f1): (2 * precision * recall)/(precision + recall). Uma m√©dia ponderada entre _precision_ e _recall_. 1 √© bom e 0 √© ruim.

üéì Support (suporte): O n√∫mero de ocorr√™ncias de cada classe.

üéì Accuracy (acur√°cia): (TP + TN) / (TP + TN + FP + FN). Porcentagem de classes previstas corretamente para uma amostra.

üéì Macro avg (m√©dia macro): M√©dia simples (n√£o ponderada) das m√©tricas de cada classe.

üéì Weighted Avg (m√©dia Ponderada): M√©dia ponderada dos valores de _Support_ de cada classe.

Como a matriz de confus√£o se relaciona com _precision_ (precis√£o) e _recall_ (cobertura)? A matriz de confus√£o mostrada acima possui valores de precis√£o (0.83) e _recall_ (0.98), pois:

Precision = TP / (TP + FP) = 162 / (162 + 33) = 0.8307692307692308

Recall = TP / (TP + FN) = 162 / (162 + 4) = 0.9759036144578314

‚úÖ Voc√™ consegue perceber qual m√©trica deve ser usada se quiser que seu modelo reduza o n√∫mero de falsos negativos?

## Visualizando a curva ROC de um modelo

O modelo constru√≠do n√£o √© ruim. A acur√°cia √© de cerca de 80%, ent√£o ele pode ser usado para prever a cor de uma ab√≥bora com base em algumas colunas.

Vamos usar mais um tipo de visualiza√ß√£o utilizando a ROC:

```python
from sklearn.metrics import roc_curve, roc_auc_score

y_scores = model.predict_proba(X_test)
# calculate ROC curve
fpr, tpr, thresholds = roc_curve(y_test, y_scores[:,1])
sns.lineplot([0, 1], [0, 1])
sns.lineplot(fpr, tpr)
```
Usando a Seaborn novamente, plote a [Receiving Operating Characteristic](https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html?highlight=roc) (Caracter√≠stica de Opera√ß√£o do Receptor) do modelo ou ROC. As curvas ROC s√£o muito usadas para obter uma vis√£o da sa√≠da de um classificador em termos de seus verdadeiros versus falsos positivos. "As curvas ROC normalmente apresentam taxa de verdadeiro positivo no eixo Y e taxa de falso positivo no eixo X." Assim, a inclina√ß√£o da curva e o espa√ßo entre a linha do ponto m√©dio e a curva s√£o importantes: precisamos de uma curva que sobe e passa pela linha. No nosso caso, existem falsos positivos no come√ßo e, em seguida, a linha avan√ßa corretamente:

![ROC](../images/ROC.png)

Por fim, usamos a [API `roc_auc_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html?highlight=roc_auc#sklearn.metrics.roc_auc_score) da Scikit-learn para calcular a 'Area Under the Curve' (√°rea sob a curva) ou AUC:

```python
auc = roc_auc_score(y_test,y_scores[:,1])
print(auc)
```
O resultado √© `0.6976998904709748`. Sabendo que a AUC varia de 0 a 1, o ideal √© uma pontua√ß√£o alta, pois um modelo que est√° 100% correto em suas previs√µes ter√° uma AUC de 1; neste caso, o modelo √© _muito bom_.

Em outras li√ß√µes sobre classifica√ß√£o, voc√™ aprender√° como iterar para melhorar as pontua√ß√µes do seu modelo. Mas por enquanto, parab√©ns! Voc√™ concluiu as li√ß√µes sobre regress√£o!

---
## üöÄDesafio

Ainda h√° muito sobre regress√£o log√≠stica! E a melhor maneira de aprender √© experimentando. Encontre um conjunto de dados para este tipo de an√°lise e construa um modelo com ele. O que voc√™ aprendeu? dica: tente o [Kaggle](https://www.kaggle.com/search?q=logistic+regression+datasets) para conjuntos de dados interessantes.

## [Question√°rio para fixa√ß√£o](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/16?loc=ptbr)

## Revis√£o e Auto Aprendizagem

Leia as primeiras p√°ginas [deste artigo de Stanford](https://web.stanford.edu/~jurafsky/slp3/5.pdf) sobre alguns usos pr√°ticos da regress√£o log√≠stica. Pense nas tarefas mais adequadas para um ou outro tipo de tarefa de regress√£o que estudamos at√© agora. O que funcionaria melhor?

## Tarefa

[Refazendo a regress√£o](assignment.pt-br.md)
