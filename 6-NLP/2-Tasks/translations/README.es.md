# Tareas y t√©cnicas comunes del procesamiento del lenguaje natural

Para la mayor√≠a de tareas de *procesamiento del lenguaje natural*, el texto a ser procesado debe ser partido en bloques, examinado y los resultados almacenados y tener referencias cruzadas con reglas y conjuntos de datos. Esta tareas, le permiten al programador obtener el _significado_, _intenci√≥n_ o s√≥lo la _frecuencia_ de los t√©rminos y palabras en un texto.

## [Examen previo a la lecci√≥n](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/33?loc=es)

Descubramos t√©cnicas comunes usadas en el procesamiento de texto. Combinadas con el aprendizaje autom√°tico, estas t√©cnicas te ayudan a analizar grandes cantidades de texto de forma eficiente, Antes de aplicar aprendizaje autom√°tico a estas tareas, primero entendamos los problemas encontrados por un especialista del procesamiento del lenguaje natural.

## Tareas comunes al procesamiento del lenguaje natural

Existen distintas forma de analizar un texto en el cual trabajas. Hay tareas que puedes realizar y a trav√©s de estas tareas eres capaz de estimar la comprensi√≥n del texto y sacar conclusiones. Usualmente llevas a cabo estas tareas en secuencia.

### Tokenizaci√≥n

Probablemente la primer cosa que la mayor√≠a de los algoritmos tiene que hacer es dividir el texto en `tokens`, o palabras. Aunque esto suena simple, teniendo en cuenta la puntuaci√≥n y distintas palabras y delimitadoras de oraciones en los diferentes idiomas puede hacerlo dif√≠cil. Puede que tengas que usar varios m√©todos para determinar la separaci√≥n.

![Tokenizaci√≥n](../images/tokenization.png)
> Tokenizando una oraci√≥n de **Orgullo y Prejuicio**. Infograf√≠a de [Jen Looper](https://twitter.com/jenlooper)

### Incrustaciones

[Las incrustaciones de palabras](https://wikipedia.org/wiki/Word_embedding) son una forma de convertir num√©ricamente tus datos de texto. Las incrustaciones se realizan de tal forma que las palabras con significado similar o palabras que se usan juntas son agrupadas.

![Incrustaciones de palabras](../images/embedding.png)
> "I have the highest respect for your nerves, they are my old friends." - Palabras incrustadas para una oraci√≥n en **Orgullo y Prejuicio**. Infograf√≠a de [Jen Looper](https://twitter.com/jenlooper)

‚úÖ Prueba [esta herramienta interesante](https://projector.tensorflow.org/) par aexperimentar con palabras embebidas. Dando cic en una palabra se muestran grupos de palabras similares: 'toy' se agrupa con 'disney', 'lego', 'playstation', y 'console'.

### Parseo y etiquetado de parte del discurso

Cada palabra que ha sido tokenizada puede ser etiquetada como parte de un discurso - un sustantivo, verbo o adjetivo. La oraci√≥n `the quick red fox jumped over the lazy brown dog` puede ser etiquetada como parte del discurso como fox = noun, jumped = verb.

![Parseo](../images/parse.png)

> Analizando una oraci√≥n de **Orgullo y Prejuicio**. Infograf√≠a de [Jen Looper](https://twitter.com/jenlooper)

El parseo es reconocer qu√© palabras est√°n relacionadas con otras en una oraci√≥n - por ejemplo `the quick red fox jumped` es una secuencia adjetivo-sustantivo-verbo que est√° separada de la secuencia `lazy brown dog`.

### Frecuencias de palabras y frases

Un procedimiento √∫til cuando analizas un gran bloque de texto es construir un diccionario de cada palabra o frase de inter√©s y qu√© tan frecuente aparece. La frase `the quick red fox jumped over the lazy brown dog` tiene una frecuencia de palabra de 2 para `the`.

Veamos un texto de ejemplo donde contamos las frecuencias de las palabras. El poema The Winners de Rudyard Kipling contiene el siguiente verso:

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

Como las frecuencias de frases pueden distinguir entre may√∫sculas y min√∫sculas seg√∫n se requiera, la frase `a friend` tiene una frecuencia de 2, `the` tiene una frecuencia de 6, y `travels` es 2.

### N-gramas

Un texto puede ser dividido en secuencias de palabras de una longitud definida, una palabra simple (unigrama), dos palabras (bigramas), tres palabras (trigramas) o cualquier n√∫mero de palabras (n-gramas).

Por ejemplo `the quick red fox jumped over the lazy brown dog` con un n-grama de puntaje 2 produce los siguientes n-gramas:

1. the quick
2. quick red
3. red fox
4. fox jumped
5. jumped over
6. over the
7. the lazy
8. lazy brown
9. brown dog

Podr√≠a ser m√°s f√°cil visualizarlo como una caja deslizante sobre la oraci√≥n. Aqu√≠ se presenta para n-gramas de 3 palabras, el n-grama est√° en negritas en cada oraci√≥n:

1.   <u>**the quick red**</u> fox jumped over the lazy brown dog
2.   the **<u>quick red fox</u>** jumped over the lazy brown dog
3.   the quick **<u>red fox jumped</u>** over the lazy brown dog
4.   the quick red **<u>fox jumped over</u>** the lazy brown dog
5.   the quick red fox **<u>jumped over the</u>** lazy brown dog
6.   the quick red fox jumped **<u>over the lazy</u>** brown dog
7.   the quick red fox jumped over <u>**the lazy brown**</u> dog
8.   the quick red fox jumped over the **<u>lazy brown dog</u>**

![Ventana deslizante de n-gramas](../images/n-grams.gif)

> N-grama de valor 3: Infograf√≠a de [Jen Looper](https://twitter.com/jenlooper)

### Extracci√≥n de frases nominales

En la mayor√≠a de las oraciones, hay un sustantivo que es el sujeto u objeto de la oraci√≥n. En Ingl√©s, se suele identificar como al tener 'a', 'an' o 'the' precedi√©ndole. Identificar el sujeto u objeto de una oraci√≥n al 'extraer la frase nominal' es una tarea com√∫n del procesamiento del lenguaje natural al intentar comprender el significado de una oraci√≥n.

‚úÖ En la oraci√≥n "I cannot fix on the hour, or the spot, or the look or the words, which laid the foundation. It is too long ago. I was in the middle before I knew that I had begun.", ¬øpuedes identificar las frases nominales?

En la oraci√≥n `the quick red fox jumped over the lazy brown dog` hay 2 frases nominales: **quick red fox** y **lazy brown dog**.

### An√°lisis de sentimiento

Una oraci√≥n o texto puede ser analizado por sentimiento, o que tan *positivo* o *negativo* es. El sentimiento se mide en *polaridad* y *objetividad/subjetividad*. La polaridad se mide de -1.0 a 1.0 (negativo a positivo) y 0.0 a 1.0 (de m√°s objetivo a m√°s subjetivo).

‚úÖ M√°s adelante aprender√°s que hay distintas formas de determinar el sentimiento usando aprendizaje autom√°tico, pero una forma es tener una lista de palabras  y frase que son categorizadas como positivas o negativas por un humano experto y aplica ese modelo al texto para calcular un puntaje de polaridad. ¬øPuedes ver c√≥mo esto podr√≠a funcionar mejor en ciertas circunstancias y peor en otras?

### Inflexi√≥n

La inflexi√≥n te permite tomar una palabra y obtener el singular o plural de la misma.

### Lematizaci√≥n

Un *lema* es la ra√≠z o palabra principal para un conjunto de palabras, por ejemplo *flew*, *flies*, *flying* tiene como lema el verbo *fly*.

Tambi√©n hay bases de datos √∫tiles para el investigador del procesamiento del lenguaje natural, notablemente:

### WordNet

[WordNet](https://wordnet.princeton.edu/) es una base de datos de palabras, sin√≥nimos ant√≥nimos y muchos otros detalles para cada palabra en distintos idiomas. Es incre√≠blemente √∫til al intentar construir traducciones, correctores ortogr√°ficos, o herramientas de idioma de cualquier tipo.

## Bibliotecas NLP

Afortunadamente, no tienes que construir todas estas t√©cnicas por ti mismo, ya que existen excelentes bibliotecas Python disponibles que hacen mucho m√°s accesible a los desarrolladores que no est√°n especializados en el procesamiento de lenguaje natural o aprendizaje autom√°tico. Las siguientes lecciones incluyen m√°s ejemplos de estos, pero aqu√≠ aprender√°s algunos ejemplos √∫tiles para ayudarte con las siguientes tareas.

### Ejercicio - usando la biblioteca `TextBlob`

Usemos una biblioteca llamada TextBlob ya que contiene APIs √∫tiles para abordar este tipo de tareas. TextBlob "se para sobre hombros de gigantes como [NLTK](https://nltk.org) y [pattern](https://github.com/clips/pattern), y se integran bien con ambos." Tiene una cantidad considerable de aprendizaje autom√°tico embebido en su API.

> Nota: Hay una gu√≠a de [Inicio r√°pido](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart) √∫til disponible para TextBlob que es recomendada por desarrolladores Python experimentados.

Al intentar identificar *frases nominales*, TextBlob ofrece varias opciones de extractores para encontrar frases nominales.

1. Da un vistazo a `ConllExtractor`.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > ¬øQu√© pasa aqu√≠? [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) es "un extractor de frases nominales que usa el an√°lisis de fragmentos entrenado con el corpus de entrenamiento ConLL-2000." ConLL-2000 se refiere a la conferencia en aprendizaje de lenguaje natural computacional del 2000. Cada a√±o la conferencia organiza un talle para abordar un problema dif√≠cil del procesamiento del lenguaje natural, y en el 2000 fue de fragmentaci√≥n de sustantivos. Se entren√≥ un modelo en el Wall Street Journal, con las "secciones 15 a 18 como datos de entrenamiento (211727 tokens) y la secci√≥n 20 como datos de prueba (47377 tokens)". Puedes revisar los procedimientos usados [aqu√≠](https://www.clips.uantwerpen.be/conll2000/chunking/) y los [resultados](https://ifarm.nl/erikt/research/np-chunking.html).

### Desaf√≠o - Mejora tu bot con procesamiento del lenguaje natural

En la lecci√≥n anterior construiste un bot de preguntas y respuestas muy simple. Ahora, har√°s a Marvin un poco m√°s comprensivo al analizar tu entrada para sentimiento e imprimir una respuesta para emparejar el sentimiento. Tambi√©n necesitar√°s identificar `noun_phrase` y preguntar al respecto.

Tus pasos al construir un mejor bot conversacional:

1. Imprime las instrucciones avisando al usuario c√≥mo interactuar con el bot
2. Inicia el ciclo
   1. Acepta la entrada del usuario
   2. Si el usuario pidi√≥ salir, entonces sal del programa
   3. Procesa la entrada del usuario y determina la respuesta de sentimiento apropiada
   4. Si se detect√≥ una frase nominal en el sentimiento, plural√≠zalo y pide m√°s entradas de ese tema
   5. Imprime la respuesta
3. Regresa al paso 2

Aqu√≠ tienes el fragmento de c√≥digo para determinar el sentimiento usando TextBlob. Nota que s√≥lo hay 4 *gradientes* de respuesta de sentimiento (podr√≠as tener m√°s si quisieras):

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

Aqu√≠ est√° una salida de muestra para guiarte (la entrada del usuario est√° en las l√≠neas que comienzan con >):

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

Una posible soluci√≥n a esta tarea esta [aqu√≠](../solution/bot.py)

‚úÖ Revisi√≥n de conocimiento

1. ¬øPiensas que las respuestas comprensivas 'enga√±ar√≠an' a alguien a creer que el bot en realidad les entendi√≥?
2. ¬øEl identificar la frane nominal hace al bot m√°s 'cre√≠ble'?
3. ¬øPor qu√© extraer una 'frase nominal' de una oraci√≥n es algo √∫til?

---

Implementa el bot con la revisi√≥n de conocimiento anterior y pru√©balo con un amigo. ¬øPudo enga√±arlo? ¬øPuedes hacer a tu bot m√°s 'cre√≠ble'?

## üöÄDesaf√≠o

Toma una tarea de la revisi√≥n de conocimiento previo y trata de implementarla. Prueba el bot con un amigo. ¬øPudo enga√±arlo? ¬øPuedes hacer a tu bot m√°s 'cre√≠ble'?

## [Examen posterior a la lectura](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/34?loc=es)

## Revisi√≥n y autoestudio

En las siguientes lecciones aprender√°s m√°s acerca del an√°lisis de sentimiento. Investiga esta t√©cnica interesante en art√≠culos como estos en [KDNuggets](https://www.kdnuggets.com/tag/nlp)

## Asignaci√≥n

[Haz que un bot responda](assignment.es.md)
