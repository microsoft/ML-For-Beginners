# T√©cnicas e tarefas frequentes do Processamento de Linguagem Natural

Para a maioria das tarefas de *processamento de linguagem natural*, o texto a ser processado precisa ser quebrado em partes e examinado, e os resultados precisam ser guardados ou cruzados com regras e data sets. Estas tarefas permitem que o programador obtenha _significado_, _intencionalidade_ ou a _frequ√™ncia_ de termos e palavras em um texto.

## [Teste pr√©-aula](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/33?loc=ptbr)

Vamos descobrir t√©cnicas frequentemente usadas no processamento de texto. Combinadas com aprendizado de m√°quina, estas t√©cnicas ajudam voc√™ a analisar grandes quantidades de texto com efici√™ncia. Contudo, antes de aplicar o aprendizado de m√°quina para estas tarefas, vamos entender os problemas enfrentados por um especialista de PLN (ou NLP).

## Tarefas frequentes para o PLN

Existem diferentes formas de analisar um texto em que voc√™ est√° trabalhando. Existem algumas tarefas que voc√™ pode executar e atrav√©s destas voc√™ pode obter um entendimento melhor do texto e chegar a conclus√µes. Voc√™ geralmente as realiza em uma sequ√™ncia.

### Tokeniza√ß√£o

Provavelmente a primeira coisa que a maioria dos algoritmos de PLN precisa √© fazer um split (quebra) do texto em tokens, que, na pr√°tica, s√£o palavras. Apesar de parecer simples, considerar pontua√ß√£o e delimitadores de palavras e ora√ß√µes de diferentes linguagens pode ser trabalhoso. Voc√™ pode ter que usar v√°rios m√©todos para determinar os delimitadores.

![tokeniza√ß√£o](../images/tokenization.png)
> Tokenizando uma frase de **Orgulho e preconceito**. Infogr√°fico por [Jen Looper](https://twitter.com/jenlooper)

### Embeddings

[Word embeddings](https://wikipedia.org/wiki/Word_embedding) (em portugu√™s, podemos dizer vetores de palavras - apesar de o termo mais comum ser word embeddings) s√£o uma forma de converter seus dados textuais em dados num√©ricos. Os embeddings s√£o feitos de tal forma que as palavras com significado parecido ou palavras usadas em conjunto ficam agrupadas em clusters.

![word embeddings](../images/embedding.png)
> "I have the highest respect for your nerves, they are my old friends." - Word embeddings de uma frase em **Orgulho e Preconceito**. Infogr√°fico por [Jen Looper](https://twitter.com/jenlooper)

‚úÖ Tente esta [ferramenta interessante](https://projector.tensorflow.org/) para experimentar com word embeddings. Clicar em uma palavra mostra o cluster (agrupamento) de palavras parecidas: 'brinquedo' est√° agrupado com 'disney', 'lego', 'playstation', e 'console'.

### Parsing & Marca√ß√£o de Partes da Fala (Part of Speech Tagging - POS)

Toda palavra tokenizada pode ser marcada como parte da fala - um substantivo, verbo, ou adjetivo. A frase `A r√°pida raposa pula por cima do pregui√ßoso c√£o marrom` pode ser marcada com partes da fala da seguinte forma: raposa = substantivo, pula = verbo.

![parsing/an√°lise sint√°tica](../images/parse.png)

> Parseando/analisando sintaticamente uma frase de **Orgulho e Preconceito**. Infogr√°fico por [Jen Looper](https://twitter.com/jenlooper)

Parsear √© reconhecer quais palavras se relacionam entre si em uma frase - por exemplo, `A r√°pida raposa pula` √© uma sequ√™ncia com adjetivo-substantivo-verbo que difere da sequ√™ncia `pregui√ßoso c√£o marrom`.  

### Frequ√™ncia de palavras e frases

Um procedimento √∫til ao analisar um texto grande √© construir um dicion√°rio com toda palavra/frase de interesse e com a frequ√™ncia ela aparece. A frase `A r√°pida raposa pula por cima do pregui√ßoso c√£o marrom` tem uma frequ√™ncia de 1 para a palavra raposa.

Vamos observar um exemplo de texto onde contamos a frequ√™ncia de palavras. O poema The Winners de Rudyard Kipling cont√©m o seguinte verso:

> O poema n√£o foi traduzido, por√©m, basta observar as frequ√™ncias.

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

Dependendo do caso, pode ser necess√°rio que a frequ√™ncia de express√µes considere varia√ß√µes de letras mai√∫sculas e min√∫sculas (case sensitive) ou n√£o (case insensitive). Se desconsiderarmos a diferen√ßa entre mai√∫sculas e min√∫sculas, a express√£o `a friend` possui frequ√™ncia de 2 no poema e `the` tem frequ√™ncia de 6, e a de `travels` √© 2.

### N-gramas

Um texto pode ser dividido em sequ√™ncias de palavras de certo tamanho, uma √∫nica palavra (unigrama), duas palavras (bigrama), tr√™s palavras (trigrama) ou qualquer n√∫mero de palavras (n-gramas).

Por exemplo, `A r√°pida raposa pula por cima do pregui√ßoso c√£o marrom` com um n-grama de tamanho 2 produz os seguintes n-gramas:

1. a r√°pida 
2. r√°pida raposa 
3. raposa pula
4. pula por 
5. por cima 
6. cima do 
7. do pregui√ßoso 
8. pregui√ßoso c√£o 
9. c√£o marrom

Pode ser mais f√°cil visualizar o n-grama como uma caixa que desliza sobre a frase. Aqui est√° um exemplo dos n-gramas de 3 palavras, o n-grama est√° em negrito em cada frase:

A r√°pida raposa pula por cima do pregui√ßoso c√£o marrom

1.   <u>**A r√°pida raposa**</u> pula por cima do pregui√ßoso c√£o marrom
2.   A **<u>r√°pida raposa pula</u>** por cima do pregui√ßoso c√£o marrom
3.   A r√°pida **<u>raposa pula por</u>** cima do pregui√ßoso c√£o marrom
4.   A r√°pida raposa **<u>pula por cima</u>** do pregui√ßoso c√£o marrom
5.   A r√°pida raposa pula **<u>por cima do</u>** pregui√ßoso c√£o marrom
6.   A r√°pida raposa pula por **<u>cima do pregui√ßoso</u>** c√£o marrom
7.   A r√°pida raposa pula por cima **<u>do pregui√ßoso c√£o</u>** marrom
8.   A r√°pida raposa pula por cima do **<u>pregui√ßoso c√£o marrom</u>**

![janela deslizante do n-gramas](../images/n-grams.gif)

> N-grama de tamanho 3: Infogr√°fico por [Jen Looper](https://twitter.com/jenlooper)

### Extra√ß√£o de sujeito e objeto

Na maioria das frases, existe um substantivo que √© o sujeito ou o objeto da ora√ß√£o. Em portugu√™s (e em ingl√™s tamb√©m), geralmente √© poss√≠vel identific√°-los por serem precedidos por palavras como "a(s)" e "o(s)". Identificar o sujeito ou o objeto de uma ora√ß√£o √© uma tarefa comum em PLN quando o objetivo √© entender o significado de uma frase.

‚úÖ Nas frases "N√£o sei precisar a hora, ou o lugar, ou o olhar, ou as palavras que lan√ßaram as bases. Faz muito tempo. Eu j√° estava no meio antes de me dar conta de que havia come√ßado.", voc√™ consegue identificar os sujeitos e os objetos?

Na frase `A r√°pida raposa pula por cima do pregui√ßoso c√£o marrom` existem dois substantivos **raposa** e **c√£o**, que, respectivamente, s√£o sujeito e objeto.

### An√°lise de sentimento

Uma frase ou texto pode ser analisado para encontrar sentimento, ou avaliar o qu√£o *positivo* ou *negativo* √©. Sentimento √© medido em *polaridade* e *objetividade/subjetividade*. Polaridade √© medida de -1.0 a 1.0 (negativo a positivo) e objetividade/subjetividade √© medida de 0.0 a 1.0 (mais objetivo a mais subjetivo).

‚úÖ Mais tarde voc√™ ir√° aprender que existem diferentes formas de se determinar sentimento usando aprendizado de m√°quina (machine learning), mas um jeito de fazer √© ter uma lista de palavras e frases categorizadas como positivas ou negativas por um especialista humano e aplicar este modelo ao texto para calcular a pontua√ß√£o da polaridade. Voc√™ consegue perceber como isso poderia funcionar melhor em alguns casos e pior em outros?

### Inflex√£o/flex√£o

A inflex√£o/flex√£o √© a varia√ß√£o de uma palavra. Exemplos incluem flex√£o de n√∫mero (singular/plural), g√™nero (feminino/masculino) e grau (aumentativo/diminutivo).

### Lematiza√ß√£o

Um *lema* √© uma palavra (ou conjunto de palavras) que √© raiz ou termo base, como, por exemplo, *voa*, *voou*, *voando* s√£o varia√ß√µes (lexemas) do verbo *voar*.

Tamb√©m existem databases √∫teis dispon√≠veis para pesquisadores de PLN, particularmente:

### WordNet

[WordNet](https://wordnet.princeton.edu/) √© uma database de palavras, sin√¥nimos, ant√¥nimos e muitos outros detalhes para todas as palavras em muitas linguagens diferentes. √â incrivelmente √∫til quando estamos tentando construir tradutores, verificadores de ortografia ou ferramentas de linguagem de qualquer tipo.

## Bibliotecas de PLN

Por sorte, voc√™ n√£o precisa criar estas t√©cnicas por si s√≥, j√° que existem excelentes bibliotecas de Python dispon√≠veis, que tornam o PLN muito mais acess√≠vel para desenvolvedores que n√£o s√£o especializados em processamento de linguagem natural ou machine learning. As pr√≥ximas aulas incluem mais exemplos delas, mas aqui voc√™ ir√° aprender alguns exemplos √∫teis para te ajudar na pr√≥xima tarefa.

### Exerc√≠cio - usando a biblioteca `TextBlob`

Iremos utilizar uma biblioteca chamada TextBlob, pois ela cont√©m APIs convenientes para lidar com esse tipo de tarefa. O TextBlob "se apoia nos ombros dos gigantes [NLTK](https://nltk.org) e [pattern](https://github.com/clips/pattern), e funciona bem com ambos". Existe uma quantidade consider√°vel de aprendizado de m√°quina embutido em sua API.

> Nota: Um guia inicial ([Quick Start](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart)) est√° dispon√≠vel para o TextBlob e √© recomendado para desenvolvedores Python.

Quando estiver tentando identificar *sujeitos e objetos*, o TextBlob oferece diversas op√ß√µes de extratores para encontrar ambos. 

1. Obeserve o `ConllExtractor`.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > O que est√° acontecendo aqui? O [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor) √© "um extrator de sujeito e objeto que usa parsing/an√°lise sint√°tica de chunks, e √© treinado com o ConLL-2000 training corpus." O nome ConLL-2000 √© em refer√™ncia √† confer√™ncia 2000 Conference on Computational Natural Language Learning. Todo ano a confer√™ncia sedia um workshop para lidar com um problema dif√≠cil de NLP e, em 2000, foi o noun phrase chunking (divis√£o da frase em subcomponentes - como substantivos e verbos). Um modelo foi treinado no Wall Street Journal, com "se√ß√µes 15-18 como dados de treino (211727 tokens) e a se√ß√£o 20 como dados de teste (47377 tokens)". Voc√™ pode ver os procedimentos utilizados [aqui](https://www.clips.uantwerpen.be/conll2000/chunking/) e os resultados [aqui](https://ifarm.nl/erikt/research/np-chunking.html).

### Desafio - melhorando seu bot com PLN

Na aula anterior voc√™ construiu um bot de perguntas e respostas bastante simples. Agora, voc√™ vai fazer Marvin um pouco mais simp√°tico ao analisar seu input em busca do sentimento e imprimindo a resposta de forma a combinar com ele. Voc√™ tamb√©m vai precisar identificar um `sujeito ou objeto` e perguntar sobre.

Seus passos quando estiver construindo um bot de conversa√ß√£o s√£o:

1. Imprima instru√ß√µes indicando como o usu√°rio pode interagir com o bot
2. Comece um loop (la√ßo)
   1. Aceite o input do usu√°rio
   2. Se o usu√°rio pedir para sair, ent√£o sair
   3. Processar o input do usu√°rio e determinar resposta adequada de acordo com o sentimento expressado no input
   4. Se um sujeito ou objeto for identificado no sentimento, torne o bot mais variado e pergunte por mais inputs sobre aquele t√≥pico
   5. Imprima a resposta
3. Voltar para o passo 2 (continuando o loop/la√ßo)


Aqui est√° um trecho de c√≥digo que determina o sentimento usando TextBlob. Note que s√≥ existem quatro *gradientes* de resposta a sentimento (voc√™ pode ter mais, se quiser):

> √â feita uma divis√£o por valor de polaridade. Se estiver no intervalo, retorna respostas correspondentes: "Nossa, isso parece terr√≠vel", "Hmm, isso n√£o parece muito bom", "Bom, isso parece positivo" e "Uau, isso soa √≥timo"

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

Aqui est√£o alguns outputs de exemplo para te guiar (input do usu√°rio est√° nas linhas que come√ßam com >):

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

Uma poss√≠vel resposta para a tarefa est√° [aqui](../solution/bot.py)

‚úÖ Checagem de conhecimento

1. Voc√™ acha que respostas simp√°ticas conseguiriam convencer uma pessoa a achar que o bot realmente entendeu o que ela disse?
2. Ser√° que identificar sujeito e objeto tornam o bot mais convincente?
3. Porque voc√™ acha que extrair o sujeito e o objeto de uma ora√ß√£o √© algo √∫til a se fazer?

---


## üöÄDesafio

Implemente o bot discutido acima da se√ß√£o checagem de conhecimento e teste-o em amigos. O bot consegue engan√°-los? Voc√™ consegue fazer seu bot mais convincente?

## [Teste p√≥s-aula](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/34?loc=ptbr)

## Revis√£o & Autoestudo

Nas pr√≥ximas aulas voc√™ vai aprender mais sobre an√°lise de sentimento. Pesquise sobre esta t√©cnica interessante em artigos como estes no [KDNuggets](https://www.kdnuggets.com/tag/nlp).

## Tarefa

[Fa√ßa um bot responder](assignment.pt-br.md)
