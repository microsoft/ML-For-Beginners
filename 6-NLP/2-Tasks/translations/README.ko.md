# ì¼ë°˜ì ì¸ natural language processing ì‘ì—…ê³¼ ê¸°ìˆ 

ëŒ€ë¶€ë¶„ *natural language processing* ì‘ì—…ìœ¼ë¡œ, ì²˜ë¦¬í•œ í…ìŠ¤íŠ¸ë¥¼ ë¶„í•´í•˜ê³ , ê²€ì‚¬í•˜ê³ , ê·¸ë¦¬ê³  ê²°ê³¼ë¥¼ ì €ì¥í•˜ê±°ë‚˜ ë£°ê³¼ ë°ì´í„°ì…‹ì„ ì„œë¡œ ì°¸ì¡°í–ˆìŠµë‹ˆë‹¤. ì´ ì‘ì—…ë“¤ë¡œ, í”„ë¡œê·¸ë˜ë¨¸ê°€ _meaning_ ë˜ëŠ” _intent_ ë˜ëŠ” ì˜¤ì§ í…ìŠ¤íŠ¸ì— ìˆëŠ” ìš©ì–´ì™€ ë‹¨ì–´ì˜ _frequency_ ë§Œ ëŒì–´ë‚¼ ìˆ˜ ìˆê²Œ í•©ë‹ˆë‹¤.

## [ê°•ì˜ ì „ í€´ì¦ˆ](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/33/)

í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ë©° ì‚¬ìš©í–ˆë˜ ì¼ë°˜ì ì¸ ê¸°ìˆ ì„ ì°¾ì•„ë´…ë‹ˆë‹¤. ë¨¸ì‹ ëŸ¬ë‹ì— ê²°í•©ëœ, ì´ ê¸°ìˆ ì€ íš¨ìœ¨ì ìœ¼ë¡œ ë§ì€ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ëŠ”ë° ë„ì™€ì¤ë‹ˆë‹¤. ê·¸ëŸ¬ë‚˜, ì´ ì‘ì—…ì— MLì„ ì ìš©í•˜ê¸° ì „ì—, NLP ìŠ¤í˜ì…œë¦¬ìŠ¤íŠ¸ê°€ ì¼ìœ¼í‚¨ ë¬¸ì œë¥¼ ì´í•´í•©ë‹ˆë‹¤.

## NLPì˜ ê³µí†µ ì‘ì—…

ì‘ì—…í•˜ê³  ìˆëŠ” í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ëŠ” ë‹¤ì–‘í•œ ë°©ì‹ì´ ìˆìŠµë‹ˆë‹¤. ì§„í–‰í•  ì‘ì—…ê³¼ ì´ ì‘ì—…ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì´í•´ë„ë¡œ ì¸¡ì •í•˜ê³  ê²°ë¡ ì„ ì§€ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ëŒ€ë¶€ë¶„ ìˆœì„œëŒ€ë¡œ ì‘ì—…í•©ë‹ˆë‹¤.

### Tokenization

ì•„ë§ˆ ë§ì€ NLP ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ ì²˜ìŒ í•  ì¼ì€ í† í°ì´ë‚˜, ë‹¨ì–´ë¡œ í…ìŠ¤íŠ¸ë¥¼ ë‚˜ëˆ„ëŠ” ê²ƒì…ë‹ˆë‹¤. ê°„ë‹¨í•˜ê²Œ ë“¤ë¦¬ì§€ë§Œ, ë¬¸ì¥ ë¶€í˜¸ì™€ ë‹¤ë¥¸ ì–¸ì–´ì˜ ë‹¨ì–´ì™€ ë¬¸ì¥ êµ¬ë¶„ ê¸°í˜¸ë¥¼ ê³ ë ¤í•˜ëŠ” ê±´ ê¹Œë‹¤ë¡œìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![tokenization](../images/tokenization.png)
> Tokenizing a sentence from **Pride and Prejudice**. Infographic by [Jen Looper](https://twitter.com/jenlooper)

### Embeddings

[Word embeddings](https://wikipedia.org/wiki/Word_embedding)ì€ í…ìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìˆ«ìì²˜ëŸ¼ ë³€í™˜í•˜ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. Embeddingsì€ ì˜ë¯¸ê°€ ë¹„ìŠ·í•œ ë‹¨ì–´ì´ê±°ë‚˜ clusterì™€ ë‹¨ì–´ë¥¼ í•¨ê»˜ ì“°ëŠ” ë°©ì‹ìœ¼ë¡œ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.

![word embeddings](../images/embedding.png)
> "I have the highest respect for your nerves, they are my old friends." - Word embeddings for a sentence in **Pride and Prejudice**. Infographic by [Jen Looper](https://twitter.com/jenlooper)

âœ… [this interesting tool](https://projector.tensorflow.org/)ë¡œ ë‹¨ì–´ embeddingsë¥¼ ì‹¤í—˜í•´ë´…ë‹ˆë‹¤. í•˜ë‚˜ì˜ ë‹¨ì–´ë¥¼ í´ë¦­í•˜ë©´ ë¹„ìŠ·í•œ ë‹¨ì–´ì˜ í´ëŸ¬ìŠ¤í„°ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤: 'disney', 'lego', 'playstation', ê·¸ë¦¬ê³  'console'ì´ 'toy' í´ëŸ¬ìŠ¤í„°ì— ìˆìˆìŠµë‹ˆë‹¤.

### íŒŒì‹± & Part-of-speech Tagging

í† í°í™”ëœ ëª¨ë“  ë‹¨ì–´ëŠ” í’ˆì‚¬ë¥¼ ëª…ì‚¬, ë™ì‚¬, í˜•ìš©ì‚¬ë¡œ í…Œê·¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `the quick red fox jumped over the lazy brown dog` ë¬¸ì¥ì€ fox = noun, jumped = verbë¡œ POS íƒœê·¸ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

![parsing](../images/parse.png)

> Parsing a sentence from **Pride and Prejudice**. Infographic by [Jen Looper](https://twitter.com/jenlooper)

íŒŒì‹±ì€ ë¬¸ì¥ì—ì„œ ê°ì ë‹¨ì–´ë“¤ì´ ê´€ë ¨ìˆëŠ”ì§€ ì¸ì‹í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì˜ˆì‹œë¡œ `the quick red fox jumped`ëŠ” `lazy brown dog` ì‹œí€€ìŠ¤ì™€ ë‚˜ëˆ ì§„ í˜•ìš©ì‚¬-ëª…ì‚¬-ë™ì‚¬ ì‹œí€€ìŠ¤ ì…ë‹ˆë‹¤.

### ë‹¨ì–´ì™€ êµ¬ë¬¸ ë¹ˆë„

í…ìŠ¤íŠ¸ì˜ ë§ì€ ë¶„ëŸ‰ì„ ë¶„ì„í•  ë•Œ ìœ ìš©í•œ ìˆœì„œëŠ” í¥ë¯¸ìˆëŠ” ëª¨ë“  ë‹¨ì–´ ë˜ëŠ” ìì£¼ ë‚˜ì˜¤ëŠ” ì‚¬ì „ì„ ë§Œë“œëŠ” ê²ƒì…ë‹ˆë‹¤. `the quick red fox jumped over the lazy brown dog` ë¬¸êµ¬ëŠ” ë‹¨ì–´ ë¹ˆë„ê°€ 2 ì…ë‹ˆë‹¤.

ë‹¨ì–´ ë¹ˆë„ë¥¼ ì„¸ëŠ” ì˜ˆì‹œë¥¼ ì°¾ì•„ë´…ë‹ˆë‹¤. Rudyard Kiplingì˜ ì‹œì¸ The WinnersëŠ” ë‹¤ìŒì„ ë‹´ê³  ìˆìŠµë‹ˆë‹¤:

```output
What the moral? Who rides may read.
When the night is thick and the tracks are blind
A friend at a pinch is a friend, indeed,
But a fool to wait for the laggard behind.
Down to Gehenna or up to the Throne,
He travels the fastest who travels alone.
```

êµ¬ë¬¸ ë¹ˆë„ëŠ” í•„ìš”ì— ì˜í•´ì„œ ëŒ€ì†Œë¬¸ìë¥¼ êµ¬ë¶„í•˜ì§€ ì•Šê±°ë‚˜ êµ¬ë¶„í•˜ë¯€ë¡œ, `a friend`ëŠ” ë¹ˆë„ 2ì´ê³  `the`ëŠ” ë¹ˆë„ 6, ê·¸ë¦¬ê³  `travels`ëŠ” 2ì…ë‹ˆë‹¤.

### N-grams

í…ìŠ¤íŠ¸ëŠ” ì§€ì •í•œ ê¸¸ì´ì˜ ë‹¨ì–´ ì‹œí€€ìŠ¤, í•œ ë‹¨ì–´(unigram), ë‘ ë‹¨ì–´(bigrams), ì„¸ ë‹¨ì–´(trigrams) ë˜ëŠ” ëª¨ë“  ìˆ˜ì˜ ë‹¨ì–´(n-grams)ë¡œ ë‚˜ëˆŒ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

ì˜ˆì‹œë¡œ n-gram 2ì ì¸ `the quick red fox jumped over the lazy brown dog`ëŠ” ë‹¤ìŒ n-gramsì„ ë§Œë“­ë‹ˆë‹¤:

1. the quick 
2. quick red 
3. red fox
4. fox jumped 
5. jumped over 
6. over the 
7. the lazy 
8. lazy brown 
9. brown dog

ë¬¸ì¥ ìœ„ ìŠ¬ë¼ì´ë“œ ë°•ìŠ¤ë¡œ ì‹œê°í™”í•˜ëŠ” ê²Œ ì‰¬ìš¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì—¬ê¸°ëŠ” 3 ë‹¨ì–´ë¡œ ì´ë£¨ì–´ì§„ n-gramsì´ë©°, n-gramì€ ê° ë¬¸ì¥ì—ì„œ ë³¼ë“œì²´ë¡œ ìˆìŠµë‹ˆë‹¤:

1.   <u>**the quick red**</u> fox jumped over the lazy brown dog
2.   the **<u>quick red fox</u>** jumped over the lazy brown dog
3.   the quick **<u>red fox jumped</u>** over the lazy brown dog
4.   the quick red **<u>fox jumped over</u>** the lazy brown dog
5.   the quick red fox **<u>jumped over the</u>** lazy brown dog
6.   the quick red fox jumped **<u>over the lazy</u>** brown dog
7.   the quick red fox jumped over <u>**the lazy brown**</u> dog
8.   the quick red fox jumped over the **<u>lazy brown dog</u>**

![n-grams sliding window](../images/n-grams.gif)

> N-gram value of 3: Infographic by [Jen Looper](https://twitter.com/jenlooper)

### Noun phrase ì¶”ì¶œ 

ëŒ€ë¶€ë¶„ ë¬¸ì¥ì—ì„œ, ë¬¸ì¥ì˜ ì£¼ì–´ë‚˜, ëª©ì ì–´ì¸ ëª…ì‚¬ê°€ ìˆìŠµë‹ˆë‹¤. ì˜ì–´ì—ì„œ, ìì£¼  'a' ë˜ëŠ” 'an' ë˜ëŠ” 'the'ê°€ ì•ì— ì˜¤ê²Œ ê°€ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤. "noun phrase ì¶”ì¶œ'ë¡œ ë¬¸ì¥ì˜ ì£¼ì–´ ë˜ëŠ” ëª©ì ì–´ë¥¼ ê°€ë ¤ë‚´ë ¤ í•˜ëŠ” ê²ƒì€ NLPì—ì„œ ë¬¸ì¥ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•  ë•Œ ì¼ë°˜ì ì¸ ì‘ì—…ì…ë‹ˆë‹¤.

âœ… "I cannot fix on the hour, or the spot, or the look or the words, which laid the foundation. It is too long ago. I was in the middle before I knew that I had begun." ë¬¸ì¥ì—ì„œ, noun phrasesë¥¼ ê°€ë ¤ë‚¼ ìˆ˜ ìˆë‚˜ìš”?

`the quick red fox jumped over the lazy brown dog` ë¬¸ì¥ì—ì„œ noun phrases 2ê°œê°€ ìˆìŠµë‹ˆë‹¤: **quick red fox** ì™€ **lazy brown dog**.

### ê°ì • ë¶„ì„

ë¬¸ì¥ì´ë‚˜ í…ìŠ¤íŠ¸ëŠ” ê°ì •ì´ë‚˜, *positive* ë˜ëŠ” *negative*ì¸ì§€ ë¶„ì„í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê°ì •ì€ *polarity* ì™€ *objectivity/subjectivity*ë¡œ ì¸¡ì •ë©ë‹ˆë‹¤. PolarityëŠ” -1.0 ì—ì„œ 1.0 (negative ì—ì„œ positive) ì´ë©° 0.0 ì—ì„œ 1.0 (ê°€ì¥ ê°ê´€ì ì—ì„œ ê°€ì¥ ì£¼ê´€ì ìœ¼ë¡œ)ìœ¼ë¡œ ì¸¡ì •ë©ë‹ˆë‹¤.

âœ… ë‚˜ì¤‘ì— ë¨¸ì‹ ëŸ¬ë‹ìœ¼ë¡œ ê°ì •ì„ íŒë‹¨í•˜ëŠ” ë‹¤ë¥¸ ë°©ì‹ì„ ë°°ìš¸ ìˆ˜ ìˆì§€ë§Œ, í•˜ë‚˜ì˜ ë°©ì‹ì€ ì „ë¬¸ê°€ê°€ positive ë˜ëŠ” negativeë¡œ ë¶„ë¥˜ëœ ë‹¨ì–´ì™€ êµ¬ë¶„ì˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ê°€ì§€ê³  polarity ì ìˆ˜ë¥¼ ê³„ì‚°í•œ í…ìŠ¤íŠ¸ë¡œ ëª¨ë¸ì„ ì ìš©í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì¼ë¶€ ìƒí™©ì—ì„œ ì–´ë–»ê²Œ ì‘ë™í•˜ê³  ë‹¤ë¥¸ ìƒí™©ì—ì„œë„ ì˜ ë™ì‘í•˜ëŠ”ì§€ ë³¼ ìˆ˜ ìˆë‚˜ìš”?

### Inflection

Inflectionì€ ë‹¨ì–´ë¥¼ ê°€ì ¸ì™€ì„œ ë‹¨ìˆ˜ë‚˜ ë³µìˆ˜ ë‹¨ì–´ë¥¼ ì–»ê²Œ ë©ë‹ˆë‹¤.

### Lemmatization

*lemma*ëŠ” ë‹¨ì–´ ì„¸íŠ¸ì—ì„œ ì–´ì›ì´ë‚˜ í‘œì œì–´ê³ , ì˜ˆì‹œë¡œ *flew*, *flies*, *flying*ì€ *fly* ë™ì‚¬ì˜ lemmaë¥¼ ê°€ì§€ê³  ìˆìŠµë‹ˆë‹¤.

íŠ¹íˆ, NLP ì—°êµ¬ì›ì´ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ìœ ìš©í•œ ë°ì´í„°ë² ì´ìŠ¤ë„ ìˆìŠµë‹ˆë‹¤:

### WordNet

[WordNet](https://wordnet.princeton.edu/)ì€ ë‹¤ì–‘í•œ ì–¸ì–´ë¡œ ëª¨ë“  ë‹¨ì–´ë¥¼ ë‹¨ì–´, ë™ì˜ì–´, ë°˜ì˜ì–´ ê·¸ë¦¬ê³  ë‹¤ì–‘í•œ ê¸°íƒ€ ë‚´ìš©ìœ¼ë¡œ ì´ë£¬ ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤. ë²ˆì—­, ë§ì¶¤ë²• ê²€ì‚¬, ë˜ëŠ” ëª¨ë“  íƒ€ì…ì˜ ì–¸ì–´ ë„êµ¬ë¥¼ ë§Œë“œë ¤ê³  ì‹œë„í•  ë•Œ ë§¤ìš° ìœ ìš©í•©ë‹ˆë‹¤.

## NLP ë¼ì´ë¸ŒëŸ¬ë¦¬

ìš´ ì¢‹ê²Œ, í›Œë¥­í•œ Python ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ natural language processingì´ë‚˜ ë¨¸ì‹ ëŸ¬ë‹ì— ì „ë¬¸ì ì´ì§€ ì•Šì€ ê°œë°œìë„ ì‰½ê²Œ ì ‘ê·¼í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì´ ê¸°ìˆ ì„ ìŠ¤ìŠ¤ë¡œ ë‹¤ ë§Œë“¤ì§€ ì•Šì•„ë„ ë©ë‹ˆë‹¤. ë‹¤ìŒ ê°•ì˜ì—ì„œ ë” ë§ì€ ì˜ˆì‹œë¥¼ í¬í•¨í•˜ì§€ë§Œ, ì—¬ê¸°ì—ì„œ ë‹¤ìŒ ì‘ì—…ì— ë„ì›€ì´ ë  ëª‡ ìœ ìš©í•œ ì˜ˆì‹œë¥¼ ë°°ìš¸ ì˜ˆì •ì…ë‹ˆë‹¤.

### ì—°ìŠµ - `TextBlob` ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‚¬ìš©

ì´ íƒ€ì…ì˜ ì‘ì—…ì„ ì²˜ë¦¬í•˜ëŠ” ìœ ìš©í•œ APIë¥¼ í¬í•¨í•œ TextBlobì´ë¼ê³  ë¶ˆë¦¬ëŠ” ë¼ì´ë¸Œë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. TextBlobì€ "stands on the giant shoulders of [NLTK](https://nltk.org) and [pattern](https://github.com/clips/pattern), and plays nicely with both."ì´ë©°  APIì—ì„œ ìƒë‹¹íˆ ë§ì´ MLì´ ë…¹ì•„ë“¤ì–´ì¡ŒìŠµë‹ˆë‹¤.

> ë…¸íŠ¸: ì˜í•˜ëŠ” Python ê°œë°œìë¥¼ ìœ„í•´ì„œ ì¶”ì²œí•˜ëŠ” TextBlobì˜ ìœ ìš©í•œ [Quick Start](https://textblob.readthedocs.io/en/dev/quickstart.html#quickstart) ê°€ì´ë“œê°€ ì¡´ì¬í•©ë‹ˆë‹¤

*noun phrases* ì‹ë³„í•˜ë ¤ê³  ì‹œë„í•˜ëŠ” ìˆœê°„, TextBlobì€ noun phrasesë¥¼ ì°¾ê³ ì ëª‡ ì¶”ì¶œ ì˜µì…˜ì„ ì œê³µí•©ë‹ˆë‹¤.

1. `ConllExtractor` ë´…ë‹ˆë‹¤.

    ```python
    from textblob import TextBlob
    from textblob.np_extractors import ConllExtractor
    # import and create a Conll extractor to use later 
    extractor = ConllExtractor()
    
    # later when you need a noun phrase extractor:
    user_input = input("> ")
    user_input_blob = TextBlob(user_input, np_extractor=extractor)  # note non-default extractor specified
    np = user_input_blob.noun_phrases                                    
    ```

    > ì–´ë–¤ ì¼ì´ ìƒê¸°ë‚˜ìš”? [ConllExtractor](https://textblob.readthedocs.io/en/dev/api_reference.html?highlight=Conll#textblob.en.np_extractors.ConllExtractor)ëŠ” "A noun phrase extractor that uses chunk parsing trained with the ConLL-2000 training corpus."ì…ë‹ˆë‹¤. ConLL-2000ì€ 2000 Conference on Computational Natural Language Learningì„ ì˜ë¯¸í•©ë‹ˆë‹¤. ë§¤ë…„ ê¹Œë‹¤ë¡œìš´ NLP ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ì›Œí¬ìˆì„ í˜¸ìŠ¤íŠ¸í•˜ëŠ” ì»¨í¼ëŸ°ìŠ¤ì´ë©°, 2000ë…„ì—ëŠ” noun chunkingì´ì—ˆìŠµë‹ˆë‹¤. ëª¨ë¸ì€ "sections 15-18 as training data (211727 tokens) and section 20 as test data (47377 tokens)"ë¡œ Wall Street Journalì—ì„œ í›ˆë ¨ë˜ì—ˆìŠµë‹ˆë‹¤. [here](https://www.clips.uantwerpen.be/conll2000/chunking/)ì—ì„œ ì‚¬ìš©í•œ ìˆœì„œì™€ [results](https://ifarm.nl/erikt/research/np-chunking.html)ë¥¼ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

### ë„ì „ - NLPë¡œ ë´‡ ê°œì„ í•˜ê¸°

ì´ì „ ê°•ì˜ì—ì„œ ë§¤ìš° ê°„ë‹¨í•œ Q&A ë´‡ì„ ë§Œë“¤ì—ˆìŠµë‹ˆë‹¤. ì´ì œ, ê°ì •ì„ ë„£ì–´ì„œ ë¶„ì„í•˜ê³  ê°ì •ê³¼ ë§ëŠ” ì‘ë‹µì„ ì¶œë ¥í•˜ì—¬ Marvinì„ ì¢€ ë” ê°ì„±ì ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤. ë˜ `noun_phrase`ë¥¼ ì‹ë³„í•˜ê³  ë¬¼ì–´ë³¼ í•„ìš”ê°€ ìˆìŠµë‹ˆë‹¤.

ë” ì¢‹ì€ ëŒ€í™” ë´‡ì„ ë§Œë“¤ ë•Œ ë‹¨ê³„ê°€ ìˆìŠµë‹ˆë‹¤:

1. ì‚¬ìš©ìì—ê²Œ ë´‡ê³¼ ìƒí˜¸ì‘ìš©í•˜ëŠ” ë°©ì‹ ì¶œë ¥
2. ë°˜ë³µ ì‹œì‘
   1. ì‚¬ìš©ì ì…ë ¥ ìŠ¹ì¸
   2. ë§Œì•½ ì‚¬ìš©ìê°€ ì¢…ë£Œ ìš”ì²­í•˜ë©´, ì¢…ë£Œ
   3. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬í•˜ê³  ì ì ˆí•œ ê°ì • ì‘ë‹µ ê²°ì •
   4. ë§Œì•½ ê°ì •ì—ì„œ noun phrase íƒì§€ë˜ë©´, ë³µìˆ˜í˜• ë³€ê²½í•˜ê³  ì´ í† í”½ì—ì„œ ì…ë ¥ ì¶”ê°€ ìš”ì²­
   5. ì‘ë‹µ ì¶œë ¥
3. 2 ë‹¨ê³„ë¡œ ëŒì•„ê°€ì„œ ë°˜ë³µ

ì—¬ê¸° TextBlobìœ¼ë¡œ ê°ì •ì„ íƒì§€í•˜ëŠ” ì½”ë“œ ìŠ¤ë‹ˆí«ì´ ìˆìŠµë‹ˆë‹¤. ê°ì • ì‘ë‹µì— 4ê°œ *gradients*ë§Œ ìˆë‹¤ëŠ” ì ì„ ì°¸ê³ í•©ë‹ˆë‹¤ (ì¢‹ì•„í•˜ëŠ” ê²½ìš° ë” ê°€ì§ˆ ìˆ˜ ìˆìŒ):

```python
if user_input_blob.polarity <= -0.5:
  response = "Oh dear, that sounds bad. "
elif user_input_blob.polarity <= 0:
  response = "Hmm, that's not great. "
elif user_input_blob.polarity <= 0.5:
  response = "Well, that sounds positive. "
elif user_input_blob.polarity <= 1:
  response = "Wow, that sounds great. "
```

ì—¬ê¸°ëŠ” ê°€ì´ë“œí•  ì•½ê°„ì˜ ìƒ˜í”Œ ì¶œë ¥ì´ ìˆìŠµë‹ˆë‹¤ (ì‚¬ìš©ì ì…ë ¥ì€ ë¼ì¸ ì‹œì‘ì— > ìˆìŠµë‹ˆë‹¤):

```output
Hello, I am Marvin, the friendly robot.
You can end this conversation at any time by typing 'bye'
After typing each answer, press 'enter'
How are you today?
> I am ok
Well, that sounds positive. Can you tell me more?
> I went for a walk and saw a lovely cat
Well, that sounds positive. Can you tell me more about lovely cats?
> cats are the best. But I also have a cool dog
Wow, that sounds great. Can you tell me more about cool dogs?
> I have an old hounddog but he is sick
Hmm, that's not great. Can you tell me more about old hounddogs?
> bye
It was nice talking to you, goodbye!
```

ì‘ì—…ì— ëŒ€í•œ í•˜ë‚˜ì˜ ê°€ëŠ¥í•œ ì†”ë£¨ì…˜ì€ [here](../solution/bot.py) ìˆìŠµë‹ˆë‹¤.

âœ… ì§€ì‹ ì ê²€

1. ë´‡ì´ ê·¸ ì‚¬ëŒë“¤ì„ ì‹¤ì œë¡œ ì´í•´í–ˆë‹¤ê³  ìƒê°í•  ìˆ˜ ìˆê²Œ ê°ì„±ì ì¸ ë°˜ì‘ìœ¼ë¡œ 'trick'í•  ìˆ˜ ìˆë‹¤ê³  ìƒê°í•˜ë‚˜ìš”?
2. noun phraseë¥¼ ì‹ë³„í•˜ë©´ ë´‡ì„ ë” 'ë¯¿ì„' ìˆ˜ ìˆë‚˜ìš”?
3. ë¬¸ì¥ì—ì„œ 'noun phrase'ë¥¼ ì¶”ì¶œí•˜ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¸ê°€ìš”?

---

ì´ì „ì˜ ì§€ì‹ ì ê²€ì—ì„œ ë´‡ì„ êµ¬í˜„í•˜ê³  ì¹œêµ¬ì—ê²Œ í…ŒìŠ¤íŠ¸í•´ë´…ë‹ˆë‹¤. ê·¸ë“¤ì„ ì†ì¼ ìˆ˜ ìˆë‚˜ìš”? ì¢€ ë” 'ë¯¿ì„ ìˆ˜'ìˆê²Œ ë´‡ì„ ë§Œë“¤ ìˆ˜ ìˆë‚˜ìš”?

## ğŸš€ ë„ì „

ì´ì „ì˜ ì§€ì‹ ì ê²€ì—ì„œ ì‘ì—…í•˜ê³  êµ¬í˜„í•©ë‹ˆë‹¤. ì¹œêµ¬ì—ê²Œ ë´‡ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤. ê·¸ë“¤ì„ ì†ì¼ ìˆ˜ ìˆë‚˜ìš”? ì¢€ ë” 'ë¯¿ì„ ìˆ˜'ìˆê²Œ ë´‡ì„ ë§Œë“¤ ìˆ˜ ìˆë‚˜ìš”?

## [ê°•ì˜ í›„ í€´ì¦ˆ](https://gray-sand-07a10f403.1.azurestaticapps.net/quiz/34/)

## ê²€í†  & ìê¸°ì£¼ë„ í•™ìŠµ

ë‹¤ìŒ ëª‡ ê°•ì˜ì—ì„œ ê°ì • ë¶„ì„ì— ëŒ€í•˜ì—¬ ë” ë°°ìš¸ ì˜ˆì •ì…ë‹ˆë‹¤. [KDNuggets](https://www.kdnuggets.com/tag/nlp) ê°™ì€ ì•„í‹°í´ì—ì„œ í¥ë¯¸ë¡œìš´ ê¸°ìˆ ì„ ì—°êµ¬í•©ë‹ˆë‹¤.

## ê³¼ì œ 

[Make a bot talk back](../assignment.md)
